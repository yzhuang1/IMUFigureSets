2025-10-13 10:57:11,172 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-13 10:57:11,309 - INFO - __main__ - Logging system initialized successfully
2025-10-13 10:57:11,309 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-10-13 10:57:11,309 - INFO - __main__ - Starting real data processing from data/dataset3/ directory
2025-10-13 10:57:11,310 - INFO - __main__ - Found 4 data files: ['sleep_sample.csv', 'X.npy', 'y.npy', 'sleep_metadata.json']
2025-10-13 10:57:11,310 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-10-13 10:57:11,310 - INFO - __main__ - Attempting to load: X.npy
2025-10-13 10:57:18,192 - INFO - __main__ - Successfully loaded NPY data: X(89283, 6, 6000), y(89283,)
2025-10-13 10:57:38,408 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (89283, 6, 6000), device: cuda
2025-10-13 10:57:38,417 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-10-13 10:57:38,423 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-10-13 10:57:38,423 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-10-13 10:57:38,470 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-13 10:57:38,470 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (89283, 6, 6000), 'dtype': 'float32', 'feature_count': 6000, 'sample_count': 89283, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-10-13 10:57:38,485 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-10-13 10:57:38,485 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-10-13 10:57:38,485 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-10-13 10:57:38,485 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-10-13 10:57:38,487 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-10-13 10:57:38,487 - INFO - data_splitting - Input data shape: X=(89283, 6, 6000), y=(89283,)
2025-10-13 10:57:38,493 - INFO - data_splitting - Class distribution: [20758 11387 28006 17266 11866]
2025-10-13 10:57:52,356 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.8602182913059842), np.int64(1): np.float64(1.5682722656786057), np.int64(2): np.float64(0.6375808971211783), np.int64(3): np.float64(1.03420814479638), np.int64(4): np.float64(1.5048722675796682)}
2025-10-13 10:57:52,370 - INFO - class_balancing - Class imbalance analysis:
2025-10-13 10:57:52,370 - INFO - class_balancing -   Strategy: mild_imbalance
2025-10-13 10:57:52,370 - INFO - class_balancing -   Imbalance ratio: 2.46
2025-10-13 10:57:52,371 - INFO - class_balancing -   Recommendations: Standard training should work, Consider class_weight='balanced'
2025-10-13 10:57:52,371 - INFO - data_splitting - Final splits - Train: 57140, Val: 14286, Test: 17857
2025-10-13 10:57:52,371 - INFO - data_splitting - Train class distribution: [13285  7287 17924 11050  7594]
2025-10-13 10:57:52,371 - INFO - data_splitting - Val class distribution: [3321 1822 4481 2763 1899]
2025-10-13 10:57:52,371 - INFO - data_splitting - Test class distribution: [4152 2278 5601 3453 2373]
2025-10-13 10:57:52,371 - INFO - data_splitting - Recommended balancing strategy: mild_imbalance
2025-10-13 10:57:56,950 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 6000]), std shape: torch.Size([1, 6000])
2025-10-13 10:57:56,991 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-10-13 10:57:56,991 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-10-13 10:57:57,003 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-10-13 10:57:57,004 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-10-13 10:57:57,004 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-10-13 10:57:57,004 - INFO - _models.ai_code_generator - Conducting literature review before code generation...
2025-10-13 11:00:19,679 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-13 11:00:19,717 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-10-13 11:00:19,717 - INFO - _models.ai_code_generator - Prompt length: 5079 characters
2025-10-13 11:00:19,717 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-10-13 11:00:19,717 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-10-13 11:00:19,717 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-10-13 11:03:44,983 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-13 11:03:45,016 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-10-13 11:03:45,016 - WARNING - _models.ai_code_generator - Initial JSON parse failed: Expecting ',' delimiter: line 58 column 17 (char 14251), attempting to fix common issues
2025-10-13 11:03:45,018 - INFO - _models.ai_code_generator - Successfully fixed JSON formatting issues
2025-10-13 11:03:45,018 - INFO - _models.ai_code_generator - AI generated training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:03:45,018 - INFO - _models.ai_code_generator - Confidence: 0.82
2025-10-13 11:03:45,018 - INFO - _models.ai_code_generator - Literature review informed code generation (confidence: 0.78)
2025-10-13 11:03:45,018 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:03:45,018 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'channel_multiplier', 'kernel_size1', 'stride1', 'kernel_size2', 'stride2', 'gcn_hidden', 'label_smoothing', 'grad_clip_norm', 'use_amp', 'calibrate_batches', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations']
2025-10-13 11:03:45,018 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.82
2025-10-13 11:03:45,019 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-10-13 11:03:45,032 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions/training_function_torch_tensor_MixSleepTinyGCN__MixSleepNet-inspired_1760371425.json
2025-10-13 11:03:45,032 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_torch_tensor_MixSleepTinyGCN__MixSleepNet-inspired_1760371425.json
2025-10-13 11:03:45,032 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-10-13 11:03:45,032 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:03:45,032 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-10-13 11:03:45,032 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-10-13 11:03:45,034 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-10-13 11:03:45,035 - INFO - package_installer - Available packages: {'torch'}
2025-10-13 11:03:45,035 - INFO - package_installer - Missing packages: set()
2025-10-13 11:03:45,035 - INFO - package_installer - ‚úÖ All required packages are already available
2025-10-13 11:03:45,035 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-10-13 11:03:45,035 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-13 11:03:45,035 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 57140 samples (using bo_sample_num=100000000000000)
2025-10-13 11:03:45,035 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'channel_multiplier', 'kernel_size1', 'stride1', 'kernel_size2', 'stride2', 'gcn_hidden', 'label_smoothing', 'grad_clip_norm', 'use_amp', 'calibrate_batches', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations']
2025-10-13 11:03:45,036 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-13 11:03:45,036 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-13 11:03:45,036 - INFO - _models.training_function_executor - Using BO subset for optimization: 57140 samples (bo_sample_num=100000000000000)
2025-10-13 11:03:47,807 - INFO - _models.training_function_executor - BO splits - Train: 45712, Val: 11428
2025-10-13 11:03:48,960 - INFO - bo.run_bo - Converted GPT search space: 19 parameters
2025-10-13 11:03:48,960 - INFO - bo.run_bo - Using GPT-generated search space
2025-10-13 11:03:48,961 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-10-13 11:03:48,963 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-10-13 11:03:48,963 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-10-13 11:03:48,964 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 1 (NaN monitoring active)
2025-10-13 11:03:48,964 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:03:48,964 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:03:48,964 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002452612631133679, 'batch_size': 32, 'epochs': 12, 'weight_decay': 6.251373574521747e-05, 'dropout': 0.06240745617697462, 'channel_multiplier': 3, 'kernel_size1': 118, 'stride1': 14, 'kernel_size2': 18, 'stride2': 6, 'gcn_hidden': 7, 'label_smoothing': 0.02857336358438816, 'grad_clip_norm': 3.254442364744265, 'use_amp': True, 'calibrate_batches': 95, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:03:48,965 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002452612631133679, 'batch_size': 32, 'epochs': 12, 'weight_decay': 6.251373574521747e-05, 'dropout': 0.06240745617697462, 'channel_multiplier': 3, 'kernel_size1': 118, 'stride1': 14, 'kernel_size2': 18, 'stride2': 6, 'gcn_hidden': 7, 'label_smoothing': 0.02857336358438816, 'grad_clip_norm': 3.254442364744265, 'use_amp': True, 'calibrate_batches': 95, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:03:56,812 - INFO - _models.training_function_executor - Epoch 001/012 - train_loss: 1.2408 - val_loss: 1.1567 - val_acc: 0.5460
2025-10-13 11:03:59,164 - INFO - _models.training_function_executor - Epoch 002/012 - train_loss: 1.1157 - val_loss: 1.1273 - val_acc: 0.5475
2025-10-13 11:04:01,543 - INFO - _models.training_function_executor - Epoch 003/012 - train_loss: 1.0912 - val_loss: 1.0949 - val_acc: 0.5559
2025-10-13 11:04:03,899 - INFO - _models.training_function_executor - Epoch 004/012 - train_loss: 1.0785 - val_loss: 1.0695 - val_acc: 0.5788
2025-10-13 11:04:06,291 - INFO - _models.training_function_executor - Epoch 005/012 - train_loss: 1.0692 - val_loss: 1.1319 - val_acc: 0.5792
2025-10-13 11:04:08,644 - INFO - _models.training_function_executor - Epoch 006/012 - train_loss: 1.0622 - val_loss: 1.0565 - val_acc: 0.5998
2025-10-13 11:04:10,999 - INFO - _models.training_function_executor - Epoch 007/012 - train_loss: 1.0550 - val_loss: 1.0322 - val_acc: 0.6275
2025-10-13 11:04:13,338 - INFO - _models.training_function_executor - Epoch 008/012 - train_loss: 1.0465 - val_loss: 1.0196 - val_acc: 0.6066
2025-10-13 11:04:15,693 - INFO - _models.training_function_executor - Epoch 009/012 - train_loss: 1.0443 - val_loss: 1.0233 - val_acc: 0.6266
2025-10-13 11:04:18,040 - INFO - _models.training_function_executor - Epoch 010/012 - train_loss: 1.0440 - val_loss: 1.0376 - val_acc: 0.6072
2025-10-13 11:04:20,416 - INFO - _models.training_function_executor - Epoch 011/012 - train_loss: 1.0397 - val_loss: 1.0700 - val_acc: 0.5977
2025-10-13 11:04:22,779 - INFO - _models.training_function_executor - Epoch 012/012 - train_loss: 1.0404 - val_loss: 1.0833 - val_acc: 0.5830
2025-10-13 11:04:24,480 - INFO - _models.training_function_executor - Model: 43 parameters, 0.0KB storage
2025-10-13 11:04:24,480 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2407504368546045, 1.1156657301215471, 1.0912443193723407, 1.078524057582245, 1.069234702317582, 1.0621509939213085, 1.054991155268222, 1.046513918441703, 1.0442736158013803, 1.044025256494396, 1.0397066943996804, 1.0403534040653], 'val_losses': [1.1566582449591574, 1.1272875333441525, 1.0948504373916264, 1.0695360549313229, 1.1318777438682153, 1.0564667775074335, 1.0321661417076209, 1.019570910434102, 1.023336085482081, 1.0376058283242722, 1.069988755734183, 1.083349067554801], 'val_acc': [0.5460273013650683, 0.5475148757437872, 0.5559152957647883, 0.5788414420721036, 0.5791914595729787, 0.5998424921246063, 0.6274938746937346, 0.6065803290164509, 0.626618830941547, 0.6071928596429822, 0.5976548827441373, 0.5830416520826042], 'final_state_dict_size_bytes': 1348, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002452612631133679, 'batch_size': 32, 'epochs': 12, 'weight_decay': 6.251373574521747e-05, 'dropout': 0.06240745617697462, 'channel_multiplier': 3, 'kernel_size1': 118, 'stride1': 14, 'kernel_size2': 18, 'stride2': 6, 'gcn_hidden': 7, 'label_smoothing': 0.02857336358438816, 'grad_clip_norm': 3.254442364744265, 'use_amp': True, 'calibrate_batches': 95, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 43, 'model_storage_size_kb': 0.046191406250000004, 'model_size_validation': 'PASS'}
2025-10-13 11:04:24,480 - INFO - _models.training_function_executor - BO Objective: base=0.5830, size_penalty=0.0000, final=0.5830
2025-10-13 11:04:24,480 - INFO - _models.training_function_executor - Model: 43 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 11:04:24,480 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 35.517s
2025-10-13 11:04:24,481 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5830
2025-10-13 11:04:24,481 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-13 11:04:24,481 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.002452612631133679, 'batch_size': 32, 'epochs': np.int64(12), 'weight_decay': 6.251373574521747e-05, 'dropout': 0.06240745617697462, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(118), 'stride1': np.int64(14), 'kernel_size2': np.int64(18), 'stride2': np.int64(6), 'gcn_hidden': np.int64(7), 'label_smoothing': 0.02857336358438816, 'grad_clip_norm': 3.254442364744265, 'use_amp': True, 'calibrate_batches': np.int64(95), 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, value=0.5830
2025-10-13 11:04:24,481 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.002452612631133679, 'batch_size': 32, 'epochs': np.int64(12), 'weight_decay': 6.251373574521747e-05, 'dropout': 0.06240745617697462, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(118), 'stride1': np.int64(14), 'kernel_size2': np.int64(18), 'stride2': np.int64(6), 'gcn_hidden': np.int64(7), 'label_smoothing': 0.02857336358438816, 'grad_clip_norm': 3.254442364744265, 'use_amp': True, 'calibrate_batches': np.int64(95), 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True} -> 0.5830
2025-10-13 11:04:24,481 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-10-13 11:04:24,481 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 11:04:24,481 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 2 (NaN monitoring active)
2025-10-13 11:04:24,482 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:04:24,482 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:04:24,482 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.179499475211679e-05, 'batch_size': 64, 'epochs': 48, 'weight_decay': 1.1727009450102243e-06, 'dropout': 0.2099098641033557, 'channel_multiplier': 7, 'kernel_size1': 73, 'stride1': 15, 'kernel_size2': 23, 'stride2': 8, 'gcn_hidden': 18, 'label_smoothing': 0.12367720186661749, 'grad_clip_norm': 1.9123099563358141, 'use_amp': False, 'calibrate_batches': 128, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:04:24,483 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.179499475211679e-05, 'batch_size': 64, 'epochs': 48, 'weight_decay': 1.1727009450102243e-06, 'dropout': 0.2099098641033557, 'channel_multiplier': 7, 'kernel_size1': 73, 'stride1': 15, 'kernel_size2': 23, 'stride2': 8, 'gcn_hidden': 18, 'label_smoothing': 0.12367720186661749, 'grad_clip_norm': 1.9123099563358141, 'use_amp': False, 'calibrate_batches': 128, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:04:28,799 - INFO - _models.training_function_executor - Epoch 001/048 - train_loss: 1.5952 - val_loss: 1.5602 - val_acc: 0.4261
2025-10-13 11:04:30,173 - INFO - _models.training_function_executor - Epoch 002/048 - train_loss: 1.5233 - val_loss: 1.5012 - val_acc: 0.4225
2025-10-13 11:04:31,575 - INFO - _models.training_function_executor - Epoch 003/048 - train_loss: 1.4768 - val_loss: 1.4771 - val_acc: 0.4396
2025-10-13 11:04:32,962 - INFO - _models.training_function_executor - Epoch 004/048 - train_loss: 1.4562 - val_loss: 1.4602 - val_acc: 0.4580
2025-10-13 11:04:34,395 - INFO - _models.training_function_executor - Epoch 005/048 - train_loss: 1.4452 - val_loss: 1.4565 - val_acc: 0.4562
2025-10-13 11:04:35,782 - INFO - _models.training_function_executor - Epoch 006/048 - train_loss: 1.4361 - val_loss: 1.4539 - val_acc: 0.4497
2025-10-13 11:04:37,193 - INFO - _models.training_function_executor - Epoch 007/048 - train_loss: 1.4291 - val_loss: 1.4497 - val_acc: 0.4514
2025-10-13 11:04:38,628 - INFO - _models.training_function_executor - Epoch 008/048 - train_loss: 1.4227 - val_loss: 1.4305 - val_acc: 0.4635
2025-10-13 11:04:40,059 - INFO - _models.training_function_executor - Epoch 009/048 - train_loss: 1.4164 - val_loss: 1.4207 - val_acc: 0.4651
2025-10-13 11:04:41,471 - INFO - _models.training_function_executor - Epoch 010/048 - train_loss: 1.4117 - val_loss: 1.4551 - val_acc: 0.4291
2025-10-13 11:04:42,906 - INFO - _models.training_function_executor - Epoch 011/048 - train_loss: 1.4079 - val_loss: 1.4198 - val_acc: 0.4609
2025-10-13 11:04:44,337 - INFO - _models.training_function_executor - Epoch 012/048 - train_loss: 1.4025 - val_loss: 1.4145 - val_acc: 0.4622
2025-10-13 11:04:45,761 - INFO - _models.training_function_executor - Epoch 013/048 - train_loss: 1.3982 - val_loss: 1.4017 - val_acc: 0.4704
2025-10-13 11:04:47,197 - INFO - _models.training_function_executor - Epoch 014/048 - train_loss: 1.3937 - val_loss: 1.4208 - val_acc: 0.4533
2025-10-13 11:04:48,646 - INFO - _models.training_function_executor - Epoch 015/048 - train_loss: 1.3903 - val_loss: 1.4031 - val_acc: 0.4638
2025-10-13 11:04:50,102 - INFO - _models.training_function_executor - Epoch 016/048 - train_loss: 1.3871 - val_loss: 1.3964 - val_acc: 0.4697
2025-10-13 11:04:51,516 - INFO - _models.training_function_executor - Epoch 017/048 - train_loss: 1.3831 - val_loss: 1.3863 - val_acc: 0.4710
2025-10-13 11:04:52,963 - INFO - _models.training_function_executor - Epoch 018/048 - train_loss: 1.3803 - val_loss: 1.4126 - val_acc: 0.4546
2025-10-13 11:04:54,401 - INFO - _models.training_function_executor - Epoch 019/048 - train_loss: 1.3766 - val_loss: 1.4067 - val_acc: 0.4609
2025-10-13 11:04:55,849 - INFO - _models.training_function_executor - Epoch 020/048 - train_loss: 1.3731 - val_loss: 1.3733 - val_acc: 0.4751
2025-10-13 11:04:57,299 - INFO - _models.training_function_executor - Epoch 021/048 - train_loss: 1.3693 - val_loss: 1.3752 - val_acc: 0.4756
2025-10-13 11:04:58,727 - INFO - _models.training_function_executor - Epoch 022/048 - train_loss: 1.3673 - val_loss: 1.3684 - val_acc: 0.4759
2025-10-13 11:05:00,188 - INFO - _models.training_function_executor - Epoch 023/048 - train_loss: 1.3632 - val_loss: 1.3659 - val_acc: 0.4765
2025-10-13 11:05:01,643 - INFO - _models.training_function_executor - Epoch 024/048 - train_loss: 1.3609 - val_loss: 1.4784 - val_acc: 0.3821
2025-10-13 11:05:03,091 - INFO - _models.training_function_executor - Epoch 025/048 - train_loss: 1.3569 - val_loss: 1.3626 - val_acc: 0.4800
2025-10-13 11:05:04,551 - INFO - _models.training_function_executor - Epoch 026/048 - train_loss: 1.3541 - val_loss: 1.4613 - val_acc: 0.3948
2025-10-13 11:05:05,991 - INFO - _models.training_function_executor - Epoch 027/048 - train_loss: 1.3518 - val_loss: 1.3496 - val_acc: 0.4833
2025-10-13 11:05:07,423 - INFO - _models.training_function_executor - Epoch 028/048 - train_loss: 1.3487 - val_loss: 1.3513 - val_acc: 0.4875
2025-10-13 11:05:08,894 - INFO - _models.training_function_executor - Epoch 029/048 - train_loss: 1.3480 - val_loss: 1.5201 - val_acc: 0.3421
2025-10-13 11:05:10,339 - INFO - _models.training_function_executor - Epoch 030/048 - train_loss: 1.3463 - val_loss: 1.3369 - val_acc: 0.4951
2025-10-13 11:05:11,777 - INFO - _models.training_function_executor - Epoch 031/048 - train_loss: 1.3425 - val_loss: 1.3458 - val_acc: 0.4876
2025-10-13 11:05:13,206 - INFO - _models.training_function_executor - Epoch 032/048 - train_loss: 1.3439 - val_loss: 1.3359 - val_acc: 0.4954
2025-10-13 11:05:14,657 - INFO - _models.training_function_executor - Epoch 033/048 - train_loss: 1.3380 - val_loss: 1.3423 - val_acc: 0.4887
2025-10-13 11:05:16,110 - INFO - _models.training_function_executor - Epoch 034/048 - train_loss: 1.3359 - val_loss: 1.3375 - val_acc: 0.4936
2025-10-13 11:05:17,576 - INFO - _models.training_function_executor - Epoch 035/048 - train_loss: 1.3332 - val_loss: 1.3370 - val_acc: 0.4918
2025-10-13 11:05:19,034 - INFO - _models.training_function_executor - Epoch 036/048 - train_loss: 1.3359 - val_loss: 1.4937 - val_acc: 0.3629
2025-10-13 11:05:20,454 - INFO - _models.training_function_executor - Epoch 037/048 - train_loss: 1.3321 - val_loss: 1.3481 - val_acc: 0.4833
2025-10-13 11:05:21,910 - INFO - _models.training_function_executor - Epoch 038/048 - train_loss: 1.3295 - val_loss: 1.3453 - val_acc: 0.4806
2025-10-13 11:05:23,365 - INFO - _models.training_function_executor - Epoch 039/048 - train_loss: 1.3285 - val_loss: 1.4816 - val_acc: 0.3709
2025-10-13 11:05:24,840 - INFO - _models.training_function_executor - Epoch 040/048 - train_loss: 1.3257 - val_loss: 1.3308 - val_acc: 0.4937
2025-10-13 11:05:26,309 - INFO - _models.training_function_executor - Epoch 041/048 - train_loss: 1.3247 - val_loss: 1.3265 - val_acc: 0.4983
2025-10-13 11:05:27,774 - INFO - _models.training_function_executor - Epoch 042/048 - train_loss: 1.3228 - val_loss: 1.3484 - val_acc: 0.4786
2025-10-13 11:05:29,235 - INFO - _models.training_function_executor - Epoch 043/048 - train_loss: 1.3225 - val_loss: 1.3532 - val_acc: 0.4750
2025-10-13 11:05:30,693 - INFO - _models.training_function_executor - Epoch 044/048 - train_loss: 1.3209 - val_loss: 1.3319 - val_acc: 0.4889
2025-10-13 11:05:32,118 - INFO - _models.training_function_executor - Epoch 045/048 - train_loss: 1.3191 - val_loss: 1.4740 - val_acc: 0.3800
2025-10-13 11:05:33,564 - INFO - _models.training_function_executor - Epoch 046/048 - train_loss: 1.3187 - val_loss: 1.3212 - val_acc: 0.5004
2025-10-13 11:05:35,021 - INFO - _models.training_function_executor - Epoch 047/048 - train_loss: 1.3161 - val_loss: 1.3958 - val_acc: 0.4391
2025-10-13 11:05:36,484 - INFO - _models.training_function_executor - Epoch 048/048 - train_loss: 1.3143 - val_loss: 1.3245 - val_acc: 0.4973
2025-10-13 11:05:37,588 - INFO - _models.training_function_executor - Model: 1,793 parameters, 3.9KB storage
2025-10-13 11:05:37,588 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5952029017914748, 1.5233483380857447, 1.4767995423522913, 1.4562280189753163, 1.4452402821194679, 1.4361193604430913, 1.4290745798257167, 1.4226571250137099, 1.4164207163164153, 1.4117383845085274, 1.4079235051118038, 1.4025008077174164, 1.3981772208906447, 1.3936635053862965, 1.390296263047186, 1.3870854353545887, 1.3830797592576334, 1.3803048739702, 1.3765819888870992, 1.3730615358232492, 1.3693099750018762, 1.3673408312692399, 1.3632220790483838, 1.3609175944937497, 1.3569020133440755, 1.354130634445388, 1.3518079961143177, 1.3486856357342805, 1.3480025794817343, 1.3463175252137336, 1.342512363022259, 1.3438963651406752, 1.338005809087957, 1.3359016717878054, 1.3332391694829646, 1.3359075093711636, 1.3320903914518025, 1.3294874090475763, 1.3285234907018082, 1.3257183561301706, 1.324744206397818, 1.3227803203915232, 1.3224577347966062, 1.3208520322735593, 1.3190736833217889, 1.3186544941403793, 1.3161245614947412, 1.3142867792224318], 'val_losses': [1.5602230340565757, 1.5011580654654337, 1.477147817695145, 1.460173040868354, 1.456469871633154, 1.4538557700523347, 1.4496743422435805, 1.430478624751779, 1.420651461346232, 1.4551059424480777, 1.4197976028414343, 1.4145151952116648, 1.401693321375902, 1.4208039922817712, 1.4030926848859857, 1.3964221773341188, 1.3862914058099813, 1.412561879652048, 1.4067133726421086, 1.3733291542525887, 1.3752051821362525, 1.3684310716559598, 1.365922915714372, 1.4783747290496774, 1.3625942608840322, 1.461298600960579, 1.3496184836412002, 1.3513142584836437, 1.5201486379148077, 1.3368727530388302, 1.345765606773705, 1.3359218796191619, 1.342272806468025, 1.3374549692896307, 1.3369561710431102, 1.4936872177037235, 1.3481205724359686, 1.3453294933781075, 1.4815752836720777, 1.3308138838588752, 1.3264977598173617, 1.3483792308497604, 1.3531792955795785, 1.3318745771570977, 1.4740132007892623, 1.321239621730213, 1.395835167092379, 1.3244849761382742], 'val_acc': [0.42605880294014703, 0.42247112355617783, 0.4396219810990549, 0.45799789989499473, 0.4562478123906195, 0.44968498424921244, 0.45143507175358766, 0.4635106755337767, 0.46508575428771437, 0.42912145607280366, 0.46088554427721384, 0.46219810990549526, 0.4704235211760588, 0.45327266363318164, 0.46377318865943296, 0.4697234861743087, 0.4710360518025901, 0.45458522926146305, 0.46088554427721384, 0.4750612530626531, 0.4755862793139657, 0.47593629681484073, 0.47654882744137206, 0.382131606580329, 0.4800490024501225, 0.39481974098704936, 0.48328666433321665, 0.4874868743437172, 0.34214210710535525, 0.4950997549877494, 0.48757437871893594, 0.49536226811340567, 0.48871193559677983, 0.49361218060903045, 0.49177458872943647, 0.3628806440322016, 0.48328666433321665, 0.48057402870143506, 0.3709310465523276, 0.4936996849842492, 0.49833741687084354, 0.47856142807140356, 0.47497374868743436, 0.48888694434721736, 0.38003150157507876, 0.5004375218760938, 0.43909695484774236, 0.4972873643682184], 'final_state_dict_size_bytes': 3794, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.179499475211679e-05, 'batch_size': 64, 'epochs': 48, 'weight_decay': 1.1727009450102243e-06, 'dropout': 0.2099098641033557, 'channel_multiplier': 7, 'kernel_size1': 73, 'stride1': 15, 'kernel_size2': 23, 'stride2': 8, 'gcn_hidden': 18, 'label_smoothing': 0.12367720186661749, 'grad_clip_norm': 1.9123099563358141, 'use_amp': False, 'calibrate_batches': 128, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 1793, 'model_storage_size_kb': 3.8521484375000004, 'model_size_validation': 'PASS'}
2025-10-13 11:05:37,588 - INFO - _models.training_function_executor - BO Objective: base=0.4973, size_penalty=0.0000, final=0.4973
2025-10-13 11:05:37,588 - INFO - _models.training_function_executor - Model: 1,793 parameters, 3.9KB (PASS 256KB limit)
2025-10-13 11:05:37,589 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 73.107s
2025-10-13 11:05:37,589 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.4973
2025-10-13 11:05:37,589 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-13 11:05:37,589 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 8.179499475211679e-05, 'batch_size': 64, 'epochs': np.int64(48), 'weight_decay': 1.1727009450102243e-06, 'dropout': 0.2099098641033557, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(73), 'stride1': np.int64(15), 'kernel_size2': np.int64(23), 'stride2': np.int64(8), 'gcn_hidden': np.int64(18), 'label_smoothing': 0.12367720186661749, 'grad_clip_norm': 1.9123099563358141, 'use_amp': False, 'calibrate_batches': np.int64(128), 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, value=0.4973
2025-10-13 11:05:37,589 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 8.179499475211679e-05, 'batch_size': 64, 'epochs': np.int64(48), 'weight_decay': 1.1727009450102243e-06, 'dropout': 0.2099098641033557, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(73), 'stride1': np.int64(15), 'kernel_size2': np.int64(23), 'stride2': np.int64(8), 'gcn_hidden': np.int64(18), 'label_smoothing': 0.12367720186661749, 'grad_clip_norm': 1.9123099563358141, 'use_amp': False, 'calibrate_batches': np.int64(128), 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True} -> 0.4973
2025-10-13 11:05:37,590 - INFO - bo.run_bo - üîçBO Trial 3: Initial random exploration
2025-10-13 11:05:37,590 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 11:05:37,590 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 3 (NaN monitoring active)
2025-10-13 11:05:37,590 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:05:37,590 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:05:37,590 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007025166339242166, 'batch_size': 128, 'epochs': 54, 'weight_decay': 1.43301094556357e-05, 'dropout': 0.006386500888085679, 'channel_multiplier': 2, 'kernel_size1': 115, 'stride1': 15, 'kernel_size2': 54, 'stride2': 5, 'gcn_hidden': 10, 'label_smoothing': 0.1219993315565242, 'grad_clip_norm': 4.165974558680823, 'use_amp': True, 'calibrate_batches': 88, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:05:37,591 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007025166339242166, 'batch_size': 128, 'epochs': 54, 'weight_decay': 1.43301094556357e-05, 'dropout': 0.006386500888085679, 'channel_multiplier': 2, 'kernel_size1': 115, 'stride1': 15, 'kernel_size2': 54, 'stride2': 5, 'gcn_hidden': 10, 'label_smoothing': 0.1219993315565242, 'grad_clip_norm': 4.165974558680823, 'use_amp': True, 'calibrate_batches': 88, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:05:41,952 - INFO - _models.training_function_executor - Epoch 001/054 - train_loss: 1.4306 - val_loss: 1.3643 - val_acc: 0.4831
2025-10-13 11:05:43,525 - INFO - _models.training_function_executor - Epoch 002/054 - train_loss: 1.3154 - val_loss: 1.2534 - val_acc: 0.5425
2025-10-13 11:05:45,059 - INFO - _models.training_function_executor - Epoch 003/054 - train_loss: 1.2077 - val_loss: 1.2063 - val_acc: 0.5851
2025-10-13 11:05:46,537 - INFO - _models.training_function_executor - Epoch 004/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:48,014 - INFO - _models.training_function_executor - Epoch 005/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:49,491 - INFO - _models.training_function_executor - Epoch 006/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:51,009 - INFO - _models.training_function_executor - Epoch 007/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:52,503 - INFO - _models.training_function_executor - Epoch 008/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:54,026 - INFO - _models.training_function_executor - Epoch 009/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:55,527 - INFO - _models.training_function_executor - Epoch 010/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:57,034 - INFO - _models.training_function_executor - Epoch 011/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:58,527 - INFO - _models.training_function_executor - Epoch 012/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:05:59,998 - INFO - _models.training_function_executor - Epoch 013/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:01,531 - INFO - _models.training_function_executor - Epoch 014/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:03,034 - INFO - _models.training_function_executor - Epoch 015/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:04,559 - INFO - _models.training_function_executor - Epoch 016/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:06,086 - INFO - _models.training_function_executor - Epoch 017/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:07,598 - INFO - _models.training_function_executor - Epoch 018/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:09,123 - INFO - _models.training_function_executor - Epoch 019/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:10,671 - INFO - _models.training_function_executor - Epoch 020/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:12,190 - INFO - _models.training_function_executor - Epoch 021/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:13,676 - INFO - _models.training_function_executor - Epoch 022/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:15,191 - INFO - _models.training_function_executor - Epoch 023/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:16,710 - INFO - _models.training_function_executor - Epoch 024/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:18,221 - INFO - _models.training_function_executor - Epoch 025/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:19,723 - INFO - _models.training_function_executor - Epoch 026/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:21,239 - INFO - _models.training_function_executor - Epoch 027/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:22,754 - INFO - _models.training_function_executor - Epoch 028/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:24,267 - INFO - _models.training_function_executor - Epoch 029/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:25,787 - INFO - _models.training_function_executor - Epoch 030/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:27,302 - INFO - _models.training_function_executor - Epoch 031/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:28,805 - INFO - _models.training_function_executor - Epoch 032/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:30,339 - INFO - _models.training_function_executor - Epoch 033/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:31,843 - INFO - _models.training_function_executor - Epoch 034/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:33,348 - INFO - _models.training_function_executor - Epoch 035/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:34,859 - INFO - _models.training_function_executor - Epoch 036/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:36,393 - INFO - _models.training_function_executor - Epoch 037/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:37,910 - INFO - _models.training_function_executor - Epoch 038/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:39,429 - INFO - _models.training_function_executor - Epoch 039/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:40,955 - INFO - _models.training_function_executor - Epoch 040/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:42,481 - INFO - _models.training_function_executor - Epoch 041/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:44,003 - INFO - _models.training_function_executor - Epoch 042/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:45,528 - INFO - _models.training_function_executor - Epoch 043/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:47,086 - INFO - _models.training_function_executor - Epoch 044/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:48,577 - INFO - _models.training_function_executor - Epoch 045/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:50,079 - INFO - _models.training_function_executor - Epoch 046/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:51,597 - INFO - _models.training_function_executor - Epoch 047/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:53,120 - INFO - _models.training_function_executor - Epoch 048/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:54,635 - INFO - _models.training_function_executor - Epoch 049/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:56,141 - INFO - _models.training_function_executor - Epoch 050/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:57,674 - INFO - _models.training_function_executor - Epoch 051/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:06:59,178 - INFO - _models.training_function_executor - Epoch 052/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:07:00,698 - INFO - _models.training_function_executor - Epoch 053/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:07:02,223 - INFO - _models.training_function_executor - Epoch 054/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:07:03,341 - INFO - _models.training_function_executor - Model: 1,505 parameters, 3.2KB storage
2025-10-13 11:07:03,342 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4305990560930177, 1.3153825690790537, 1.2077465708288313, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.3643209745636093, 1.2533702695540794, 1.2062581239315777, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.48311165558277913, 0.5425271263563178, 0.5850542527126357, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'final_state_dict_size_bytes': 3098, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007025166339242166, 'batch_size': 128, 'epochs': 54, 'weight_decay': 1.43301094556357e-05, 'dropout': 0.006386500888085679, 'channel_multiplier': 2, 'kernel_size1': 115, 'stride1': 15, 'kernel_size2': 54, 'stride2': 5, 'gcn_hidden': 10, 'label_smoothing': 0.1219993315565242, 'grad_clip_norm': 4.165974558680823, 'use_amp': True, 'calibrate_batches': 88, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1505, 'model_storage_size_kb': 3.2333984375000004, 'model_size_validation': 'PASS'}
2025-10-13 11:07:03,342 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-13 11:07:03,342 - INFO - _models.training_function_executor - Model: 1,505 parameters, 3.2KB (PASS 256KB limit)
2025-10-13 11:07:03,342 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 85.752s
2025-10-13 11:07:03,422 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-13 11:07:03,422 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.080s
2025-10-13 11:07:03,423 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 0.007025166339242166, 'batch_size': 128, 'epochs': np.int64(54), 'weight_decay': 1.43301094556357e-05, 'dropout': 0.006386500888085679, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(115), 'stride1': np.int64(15), 'kernel_size2': np.int64(54), 'stride2': np.int64(5), 'gcn_hidden': np.int64(10), 'label_smoothing': 0.1219993315565242, 'grad_clip_norm': 4.165974558680823, 'use_amp': True, 'calibrate_batches': np.int64(88), 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, value=0.2325
2025-10-13 11:07:03,423 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 0.007025166339242166, 'batch_size': 128, 'epochs': np.int64(54), 'weight_decay': 1.43301094556357e-05, 'dropout': 0.006386500888085679, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(115), 'stride1': np.int64(15), 'kernel_size2': np.int64(54), 'stride2': np.int64(5), 'gcn_hidden': np.int64(10), 'label_smoothing': 0.1219993315565242, 'grad_clip_norm': 4.165974558680823, 'use_amp': True, 'calibrate_batches': np.int64(88), 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False} -> 0.2325
2025-10-13 11:07:03,423 - INFO - bo.run_bo - üîçBO Trial 4: Using RF surrogate + Expected Improvement
2025-10-13 11:07:03,423 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:07:03,423 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 4 (NaN monitoring active)
2025-10-13 11:07:03,423 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:07:03,423 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:07:03,423 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0004366473592979637, 'batch_size': 96, 'epochs': 45, 'weight_decay': 0.0004941316844097349, 'dropout': 0.2971973547808882, 'channel_multiplier': 4, 'kernel_size1': 33, 'stride1': 8, 'kernel_size2': 41, 'stride2': 7, 'gcn_hidden': 8, 'label_smoothing': 0.07524142492975758, 'grad_clip_norm': 0.22071351829919986, 'use_amp': True, 'calibrate_batches': 54, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:07:03,424 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0004366473592979637, 'batch_size': 96, 'epochs': 45, 'weight_decay': 0.0004941316844097349, 'dropout': 0.2971973547808882, 'channel_multiplier': 4, 'kernel_size1': 33, 'stride1': 8, 'kernel_size2': 41, 'stride2': 7, 'gcn_hidden': 8, 'label_smoothing': 0.07524142492975758, 'grad_clip_norm': 0.22071351829919986, 'use_amp': True, 'calibrate_batches': 54, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:07:07,745 - INFO - _models.training_function_executor - Epoch 001/045 - train_loss: 1.5605 - val_loss: 1.5417 - val_acc: 0.3240
2025-10-13 11:07:09,209 - INFO - _models.training_function_executor - Epoch 002/045 - train_loss: 1.4774 - val_loss: 1.4800 - val_acc: 0.3746
2025-10-13 11:07:10,675 - INFO - _models.training_function_executor - Epoch 003/045 - train_loss: 1.4558 - val_loss: 1.4669 - val_acc: 0.3781
2025-10-13 11:07:12,146 - INFO - _models.training_function_executor - Epoch 004/045 - train_loss: 1.4442 - val_loss: 1.4580 - val_acc: 0.3786
2025-10-13 11:07:13,626 - INFO - _models.training_function_executor - Epoch 005/045 - train_loss: 1.4297 - val_loss: 1.4472 - val_acc: 0.3888
2025-10-13 11:07:15,087 - INFO - _models.training_function_executor - Epoch 006/045 - train_loss: 1.4024 - val_loss: 1.4620 - val_acc: 0.4164
2025-10-13 11:07:16,560 - INFO - _models.training_function_executor - Epoch 007/045 - train_loss: 1.3456 - val_loss: 1.3551 - val_acc: 0.5061
2025-10-13 11:07:18,052 - INFO - _models.training_function_executor - Epoch 008/045 - train_loss: 1.2949 - val_loss: 1.3659 - val_acc: 0.4744
2025-10-13 11:07:19,551 - INFO - _models.training_function_executor - Epoch 009/045 - train_loss: 1.2572 - val_loss: 1.3004 - val_acc: 0.5037
2025-10-13 11:07:21,059 - INFO - _models.training_function_executor - Epoch 010/045 - train_loss: 1.2360 - val_loss: 1.3311 - val_acc: 0.4783
2025-10-13 11:07:22,550 - INFO - _models.training_function_executor - Epoch 011/045 - train_loss: 1.2226 - val_loss: 1.3288 - val_acc: 0.4732
2025-10-13 11:07:24,060 - INFO - _models.training_function_executor - Epoch 012/045 - train_loss: 1.2123 - val_loss: 1.2799 - val_acc: 0.5109
2025-10-13 11:07:25,552 - INFO - _models.training_function_executor - Epoch 013/045 - train_loss: 1.2070 - val_loss: 1.2628 - val_acc: 0.5246
2025-10-13 11:07:27,031 - INFO - _models.training_function_executor - Epoch 014/045 - train_loss: 1.2020 - val_loss: 1.2556 - val_acc: 0.5229
2025-10-13 11:07:28,499 - INFO - _models.training_function_executor - Epoch 015/045 - train_loss: 1.1962 - val_loss: 1.2605 - val_acc: 0.5090
2025-10-13 11:07:29,975 - INFO - _models.training_function_executor - Epoch 016/045 - train_loss: 1.1917 - val_loss: 1.2399 - val_acc: 0.5271
2025-10-13 11:07:31,479 - INFO - _models.training_function_executor - Epoch 017/045 - train_loss: 1.1894 - val_loss: 1.2304 - val_acc: 0.5326
2025-10-13 11:07:32,991 - INFO - _models.training_function_executor - Epoch 018/045 - train_loss: 1.1809 - val_loss: 1.2311 - val_acc: 0.5330
2025-10-13 11:07:34,478 - INFO - _models.training_function_executor - Epoch 019/045 - train_loss: 1.1783 - val_loss: 1.2655 - val_acc: 0.5164
2025-10-13 11:07:35,973 - INFO - _models.training_function_executor - Epoch 020/045 - train_loss: 1.1707 - val_loss: 1.2193 - val_acc: 0.5488
2025-10-13 11:07:37,506 - INFO - _models.training_function_executor - Epoch 021/045 - train_loss: 1.1699 - val_loss: 1.2533 - val_acc: 0.5355
2025-10-13 11:07:38,994 - INFO - _models.training_function_executor - Epoch 022/045 - train_loss: 1.1678 - val_loss: 1.2336 - val_acc: 0.5518
2025-10-13 11:07:40,485 - INFO - _models.training_function_executor - Epoch 023/045 - train_loss: 1.1620 - val_loss: 1.1952 - val_acc: 0.5687
2025-10-13 11:07:41,987 - INFO - _models.training_function_executor - Epoch 024/045 - train_loss: 1.1590 - val_loss: 1.1981 - val_acc: 0.5634
2025-10-13 11:07:43,482 - INFO - _models.training_function_executor - Epoch 025/045 - train_loss: 1.1559 - val_loss: 1.2074 - val_acc: 0.5623
2025-10-13 11:07:44,972 - INFO - _models.training_function_executor - Epoch 026/045 - train_loss: 1.1532 - val_loss: 1.1888 - val_acc: 0.5492
2025-10-13 11:07:46,474 - INFO - _models.training_function_executor - Epoch 027/045 - train_loss: 1.1542 - val_loss: 1.2039 - val_acc: 0.5688
2025-10-13 11:07:48,004 - INFO - _models.training_function_executor - Epoch 028/045 - train_loss: 1.1498 - val_loss: 1.2133 - val_acc: 0.5454
2025-10-13 11:07:49,487 - INFO - _models.training_function_executor - Epoch 029/045 - train_loss: 1.1478 - val_loss: 1.1756 - val_acc: 0.5598
2025-10-13 11:07:50,975 - INFO - _models.training_function_executor - Epoch 030/045 - train_loss: 1.1444 - val_loss: 1.2167 - val_acc: 0.5554
2025-10-13 11:07:52,488 - INFO - _models.training_function_executor - Epoch 031/045 - train_loss: 1.1380 - val_loss: 1.1656 - val_acc: 0.5758
2025-10-13 11:07:54,002 - INFO - _models.training_function_executor - Epoch 032/045 - train_loss: 1.1394 - val_loss: 1.2042 - val_acc: 0.5661
2025-10-13 11:07:55,491 - INFO - _models.training_function_executor - Epoch 033/045 - train_loss: 1.1342 - val_loss: 1.1709 - val_acc: 0.5651
2025-10-13 11:07:56,998 - INFO - _models.training_function_executor - Epoch 034/045 - train_loss: 1.1313 - val_loss: 1.1729 - val_acc: 0.5929
2025-10-13 11:07:58,514 - INFO - _models.training_function_executor - Epoch 035/045 - train_loss: 1.1317 - val_loss: 1.1894 - val_acc: 0.5526
2025-10-13 11:07:59,999 - INFO - _models.training_function_executor - Epoch 036/045 - train_loss: 1.1280 - val_loss: 1.1417 - val_acc: 0.5950
2025-10-13 11:08:01,539 - INFO - _models.training_function_executor - Epoch 037/045 - train_loss: 1.1269 - val_loss: 1.1639 - val_acc: 0.5826
2025-10-13 11:08:03,027 - INFO - _models.training_function_executor - Epoch 038/045 - train_loss: 1.1241 - val_loss: 1.1615 - val_acc: 0.5940
2025-10-13 11:08:04,517 - INFO - _models.training_function_executor - Epoch 039/045 - train_loss: 1.1196 - val_loss: 1.1356 - val_acc: 0.6170
2025-10-13 11:08:06,021 - INFO - _models.training_function_executor - Epoch 040/045 - train_loss: 1.1162 - val_loss: 1.1645 - val_acc: 0.6035
2025-10-13 11:08:07,526 - INFO - _models.training_function_executor - Epoch 041/045 - train_loss: 1.1165 - val_loss: 1.1864 - val_acc: 0.5406
2025-10-13 11:08:09,037 - INFO - _models.training_function_executor - Epoch 042/045 - train_loss: 1.1143 - val_loss: 1.2135 - val_acc: 0.5412
2025-10-13 11:08:10,526 - INFO - _models.training_function_executor - Epoch 043/045 - train_loss: 1.1140 - val_loss: 1.1615 - val_acc: 0.5797
2025-10-13 11:08:12,038 - INFO - _models.training_function_executor - Epoch 044/045 - train_loss: 1.1127 - val_loss: 1.1686 - val_acc: 0.5892
2025-10-13 11:08:13,556 - INFO - _models.training_function_executor - Epoch 045/045 - train_loss: 1.1102 - val_loss: 1.1405 - val_acc: 0.6179
2025-10-13 11:08:14,854 - INFO - _models.training_function_executor - Model: 1,371 parameters, 1.5KB storage
2025-10-13 11:08:14,855 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5605478732787024, 1.477435604275045, 1.4557743545675095, 1.444230998442813, 1.429651272684951, 1.4023689071240022, 1.3456378344434685, 1.294913943973003, 1.257153657586749, 1.2359734056377312, 1.2225973245602701, 1.2123227799568803, 1.2070429233308018, 1.2019885178208143, 1.196207468185051, 1.1917063691710357, 1.1893790543475766, 1.1809226522756116, 1.178256935659388, 1.1706744532590152, 1.169869584222753, 1.1678066407211352, 1.1619722387946734, 1.1590017229683716, 1.1558619268632326, 1.1532105891738773, 1.1541636861367872, 1.1497769825183974, 1.1477694694170553, 1.1443548503771586, 1.1380104483696893, 1.1393736433974504, 1.1342013925783359, 1.13134279017854, 1.1317365427804986, 1.127979029380737, 1.1269440938010264, 1.1241005126270833, 1.1195785378842324, 1.1161751085367493, 1.1165131821180083, 1.114281037991223, 1.1140271060567741, 1.112735828570565, 1.1102190348999377], 'val_losses': [1.54170229182946, 1.480029207282355, 1.4668750817599645, 1.4580022995814936, 1.4471867298971408, 1.4620186913293018, 1.3550731311280033, 1.3659464985831118, 1.300408853114298, 1.3311458186832892, 1.3288048320105328, 1.2798944160076218, 1.262766365659458, 1.2555788900621045, 1.2605450748354143, 1.2399483480193125, 1.2303558861746169, 1.231077237065789, 1.2655021463360117, 1.2192716822158551, 1.2532898611566758, 1.233618796163812, 1.1951713647131408, 1.1981275385394978, 1.2073929129591512, 1.1887761826777232, 1.203877260478844, 1.213263942263199, 1.1755716446024327, 1.2167489361337402, 1.1655863718340602, 1.204165720672594, 1.1709174325844187, 1.1728984671620417, 1.1894386169332118, 1.1417462427715426, 1.1638992321754111, 1.161471920535829, 1.13560043355156, 1.1645109520369072, 1.1864172427187778, 1.2135392653804415, 1.1614999354490667, 1.168561574458909, 1.1405007968968681], 'val_acc': [0.32402870143507173, 0.3746062303115156, 0.378106405320266, 0.3786314315715786, 0.38878193909695485, 0.4164333216660833, 0.5061253062653133, 0.4744487224361218, 0.503675183759188, 0.4782989149457473, 0.47322366118305914, 0.5109380469023451, 0.5245887294364718, 0.5229261463073154, 0.5090129506475324, 0.5271263563178159, 0.5325516275813791, 0.5329891494574729, 0.5163633181659083, 0.5488274413720686, 0.535526776338817, 0.5518025901295065, 0.5686909345467274, 0.563353167658383, 0.5623031151557578, 0.5491774588729437, 0.5687784389219461, 0.545414770738537, 0.5597654882744137, 0.5553902695134757, 0.575778788939447, 0.5660658032901645, 0.5651032551627582, 0.5929296464823242, 0.5525901295064753, 0.5950297514875744, 0.5826041302065104, 0.5939796989849493, 0.6169933496674834, 0.6035176758837942, 0.5406020301015051, 0.5412145607280364, 0.5797164858242912, 0.5891669583479174, 0.617868393419671], 'final_state_dict_size_bytes': 5740, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0004366473592979637, 'batch_size': 96, 'epochs': 45, 'weight_decay': 0.0004941316844097349, 'dropout': 0.2971973547808882, 'channel_multiplier': 4, 'kernel_size1': 33, 'stride1': 8, 'kernel_size2': 41, 'stride2': 7, 'gcn_hidden': 8, 'label_smoothing': 0.07524142492975758, 'grad_clip_norm': 0.22071351829919986, 'use_amp': True, 'calibrate_batches': 54, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1371, 'model_storage_size_kb': 1.4727539062500001, 'model_size_validation': 'PASS'}
2025-10-13 11:08:14,855 - INFO - _models.training_function_executor - BO Objective: base=0.6179, size_penalty=0.0000, final=0.6179
2025-10-13 11:08:14,855 - INFO - _models.training_function_executor - Model: 1,371 parameters, 1.5KB (PASS 256KB limit)
2025-10-13 11:08:14,855 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 71.432s
2025-10-13 11:08:14,932 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6179
2025-10-13 11:08:14,932 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.077s
2025-10-13 11:08:14,932 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 0.0004366473592979637, 'batch_size': np.int64(96), 'epochs': np.int64(45), 'weight_decay': 0.0004941316844097349, 'dropout': 0.2971973547808882, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(33), 'stride1': np.int64(8), 'kernel_size2': np.int64(41), 'stride2': np.int64(7), 'gcn_hidden': np.int64(8), 'label_smoothing': 0.07524142492975758, 'grad_clip_norm': 0.22071351829919986, 'use_amp': np.True_, 'calibrate_batches': np.int64(54), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.6179
2025-10-13 11:08:14,932 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 0.0004366473592979637, 'batch_size': np.int64(96), 'epochs': np.int64(45), 'weight_decay': 0.0004941316844097349, 'dropout': 0.2971973547808882, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(33), 'stride1': np.int64(8), 'kernel_size2': np.int64(41), 'stride2': np.int64(7), 'gcn_hidden': np.int64(8), 'label_smoothing': 0.07524142492975758, 'grad_clip_norm': 0.22071351829919986, 'use_amp': np.True_, 'calibrate_batches': np.int64(54), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.6179
2025-10-13 11:08:14,932 - INFO - bo.run_bo - üîçBO Trial 5: Using RF surrogate + Expected Improvement
2025-10-13 11:08:14,932 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:08:14,932 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 5 (NaN monitoring active)
2025-10-13 11:08:14,932 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:08:14,932 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:08:14,932 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004363085276094088, 'batch_size': 48, 'epochs': 52, 'weight_decay': 5.801169261802538e-06, 'dropout': 0.22877818210041828, 'channel_multiplier': 8, 'kernel_size1': 88, 'stride1': 10, 'kernel_size2': 45, 'stride2': 2, 'gcn_hidden': 9, 'label_smoothing': 0.12529957772082456, 'grad_clip_norm': 3.998387697574235, 'use_amp': True, 'calibrate_batches': 128, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:08:14,933 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004363085276094088, 'batch_size': 48, 'epochs': 52, 'weight_decay': 5.801169261802538e-06, 'dropout': 0.22877818210041828, 'channel_multiplier': 8, 'kernel_size1': 88, 'stride1': 10, 'kernel_size2': 45, 'stride2': 2, 'gcn_hidden': 9, 'label_smoothing': 0.12529957772082456, 'grad_clip_norm': 3.998387697574235, 'use_amp': True, 'calibrate_batches': 128, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:08:20,051 - INFO - _models.training_function_executor - Epoch 001/052 - train_loss: 1.2754 - val_loss: 1.2285 - val_acc: 0.5697
2025-10-13 11:08:22,394 - INFO - _models.training_function_executor - Epoch 002/052 - train_loss: 1.1948 - val_loss: 1.2714 - val_acc: 0.5676
2025-10-13 11:08:24,797 - INFO - _models.training_function_executor - Epoch 003/052 - train_loss: 1.1740 - val_loss: 1.1629 - val_acc: 0.6477
2025-10-13 11:08:27,189 - INFO - _models.training_function_executor - Epoch 004/052 - train_loss: 1.1635 - val_loss: 1.1699 - val_acc: 0.6119
2025-10-13 11:08:29,598 - INFO - _models.training_function_executor - Epoch 005/052 - train_loss: 1.1550 - val_loss: 1.1493 - val_acc: 0.6111
2025-10-13 11:08:31,993 - INFO - _models.training_function_executor - Epoch 006/052 - train_loss: 1.1462 - val_loss: 1.1463 - val_acc: 0.6131
2025-10-13 11:08:34,411 - INFO - _models.training_function_executor - Epoch 007/052 - train_loss: 1.1421 - val_loss: 1.2010 - val_acc: 0.6194
2025-10-13 11:08:36,801 - INFO - _models.training_function_executor - Epoch 008/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:39,232 - INFO - _models.training_function_executor - Epoch 009/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:41,640 - INFO - _models.training_function_executor - Epoch 010/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:44,083 - INFO - _models.training_function_executor - Epoch 011/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:46,478 - INFO - _models.training_function_executor - Epoch 012/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:48,882 - INFO - _models.training_function_executor - Epoch 013/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:51,297 - INFO - _models.training_function_executor - Epoch 014/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:53,701 - INFO - _models.training_function_executor - Epoch 015/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:56,128 - INFO - _models.training_function_executor - Epoch 016/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:08:58,526 - INFO - _models.training_function_executor - Epoch 017/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:00,910 - INFO - _models.training_function_executor - Epoch 018/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:03,309 - INFO - _models.training_function_executor - Epoch 019/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:05,720 - INFO - _models.training_function_executor - Epoch 020/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:08,113 - INFO - _models.training_function_executor - Epoch 021/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:10,542 - INFO - _models.training_function_executor - Epoch 022/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:12,948 - INFO - _models.training_function_executor - Epoch 023/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:15,338 - INFO - _models.training_function_executor - Epoch 024/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:17,744 - INFO - _models.training_function_executor - Epoch 025/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:20,152 - INFO - _models.training_function_executor - Epoch 026/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:22,587 - INFO - _models.training_function_executor - Epoch 027/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:24,987 - INFO - _models.training_function_executor - Epoch 028/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:27,396 - INFO - _models.training_function_executor - Epoch 029/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:29,800 - INFO - _models.training_function_executor - Epoch 030/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:32,215 - INFO - _models.training_function_executor - Epoch 031/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:34,621 - INFO - _models.training_function_executor - Epoch 032/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:36,987 - INFO - _models.training_function_executor - Epoch 033/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:39,350 - INFO - _models.training_function_executor - Epoch 034/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:41,752 - INFO - _models.training_function_executor - Epoch 035/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:44,135 - INFO - _models.training_function_executor - Epoch 036/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:46,533 - INFO - _models.training_function_executor - Epoch 037/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:48,915 - INFO - _models.training_function_executor - Epoch 038/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:51,336 - INFO - _models.training_function_executor - Epoch 039/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:53,756 - INFO - _models.training_function_executor - Epoch 040/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:56,171 - INFO - _models.training_function_executor - Epoch 041/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:09:58,565 - INFO - _models.training_function_executor - Epoch 042/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:00,980 - INFO - _models.training_function_executor - Epoch 043/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:03,357 - INFO - _models.training_function_executor - Epoch 044/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:05,784 - INFO - _models.training_function_executor - Epoch 045/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:08,177 - INFO - _models.training_function_executor - Epoch 046/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:10,562 - INFO - _models.training_function_executor - Epoch 047/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:12,947 - INFO - _models.training_function_executor - Epoch 048/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:15,382 - INFO - _models.training_function_executor - Epoch 049/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:17,778 - INFO - _models.training_function_executor - Epoch 050/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:20,171 - INFO - _models.training_function_executor - Epoch 051/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:22,567 - INFO - _models.training_function_executor - Epoch 052/052 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:10:24,003 - INFO - _models.training_function_executor - Model: 2,972 parameters, 3.2KB storage
2025-10-13 11:10:24,003 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2754154190718396, 1.1948288758401067, 1.1740007968603168, 1.1634870783240385, 1.1549847027326656, 1.146164807294439, 1.1420661986896448, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.2285201168577697, 1.271433372409101, 1.1629298344165828, 1.1698926272490744, 1.1492516570964142, 1.1462709322691715, 1.2009898106410113, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5697409870493525, 0.5676408820441022, 0.6477073853692684, 0.6119180959047953, 0.6111305565278264, 0.6131431571578579, 0.6194434721736087, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'final_state_dict_size_bytes': 12336, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004363085276094088, 'batch_size': 48, 'epochs': 52, 'weight_decay': 5.801169261802538e-06, 'dropout': 0.22877818210041828, 'channel_multiplier': 8, 'kernel_size1': 88, 'stride1': 10, 'kernel_size2': 45, 'stride2': 2, 'gcn_hidden': 9, 'label_smoothing': 0.12529957772082456, 'grad_clip_norm': 3.998387697574235, 'use_amp': True, 'calibrate_batches': 128, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 2972, 'model_storage_size_kb': 3.1925781250000003, 'model_size_validation': 'PASS'}
2025-10-13 11:10:24,003 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-13 11:10:24,003 - INFO - _models.training_function_executor - Model: 2,972 parameters, 3.2KB (PASS 256KB limit)
2025-10-13 11:10:24,003 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 129.071s
2025-10-13 11:10:24,081 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-13 11:10:24,081 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.077s
2025-10-13 11:10:24,081 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 0.004363085276094088, 'batch_size': np.int64(48), 'epochs': np.int64(52), 'weight_decay': 5.801169261802538e-06, 'dropout': 0.22877818210041828, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(88), 'stride1': np.int64(10), 'kernel_size2': np.int64(45), 'stride2': np.int64(2), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.12529957772082456, 'grad_clip_norm': 3.998387697574235, 'use_amp': np.True_, 'calibrate_batches': np.int64(128), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.2325
2025-10-13 11:10:24,081 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 0.004363085276094088, 'batch_size': np.int64(48), 'epochs': np.int64(52), 'weight_decay': 5.801169261802538e-06, 'dropout': 0.22877818210041828, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(88), 'stride1': np.int64(10), 'kernel_size2': np.int64(45), 'stride2': np.int64(2), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.12529957772082456, 'grad_clip_norm': 3.998387697574235, 'use_amp': np.True_, 'calibrate_batches': np.int64(128), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.2325
2025-10-13 11:10:24,081 - INFO - bo.run_bo - üîçBO Trial 6: Using RF surrogate + Expected Improvement
2025-10-13 11:10:24,081 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:10:24,081 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 6 (NaN monitoring active)
2025-10-13 11:10:24,081 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:10:24,081 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:10:24,081 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004628199672772807, 'batch_size': 128, 'epochs': 28, 'weight_decay': 6.309987305543909e-05, 'dropout': 0.021681528320780834, 'channel_multiplier': 8, 'kernel_size1': 58, 'stride1': 7, 'kernel_size2': 39, 'stride2': 5, 'gcn_hidden': 23, 'label_smoothing': 0.010932162193587815, 'grad_clip_norm': 4.720835953566235, 'use_amp': False, 'calibrate_batches': 38, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:10:24,082 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004628199672772807, 'batch_size': 128, 'epochs': 28, 'weight_decay': 6.309987305543909e-05, 'dropout': 0.021681528320780834, 'channel_multiplier': 8, 'kernel_size1': 58, 'stride1': 7, 'kernel_size2': 39, 'stride2': 5, 'gcn_hidden': 23, 'label_smoothing': 0.010932162193587815, 'grad_clip_norm': 4.720835953566235, 'use_amp': False, 'calibrate_batches': 38, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:10:28,709 - INFO - _models.training_function_executor - Epoch 001/028 - train_loss: 1.1437 - val_loss: 1.2983 - val_acc: 0.4687
2025-10-13 11:10:30,544 - INFO - _models.training_function_executor - Epoch 002/028 - train_loss: 1.0140 - val_loss: 1.4881 - val_acc: 0.4541
2025-10-13 11:10:32,369 - INFO - _models.training_function_executor - Epoch 003/028 - train_loss: 0.9858 - val_loss: 0.9851 - val_acc: 0.6047
2025-10-13 11:10:34,184 - INFO - _models.training_function_executor - Epoch 004/028 - train_loss: 0.9697 - val_loss: 1.0242 - val_acc: 0.5919
2025-10-13 11:10:36,005 - INFO - _models.training_function_executor - Epoch 005/028 - train_loss: 0.9695 - val_loss: 1.3440 - val_acc: 0.4682
2025-10-13 11:10:37,827 - INFO - _models.training_function_executor - Epoch 006/028 - train_loss: 0.9515 - val_loss: 1.1844 - val_acc: 0.5759
2025-10-13 11:10:39,659 - INFO - _models.training_function_executor - Epoch 007/028 - train_loss: 0.9274 - val_loss: 0.9443 - val_acc: 0.6556
2025-10-13 11:10:41,478 - INFO - _models.training_function_executor - Epoch 008/028 - train_loss: 0.9229 - val_loss: 0.9446 - val_acc: 0.6501
2025-10-13 11:10:43,305 - INFO - _models.training_function_executor - Epoch 009/028 - train_loss: 0.9126 - val_loss: 0.9221 - val_acc: 0.6589
2025-10-13 11:10:45,128 - INFO - _models.training_function_executor - Epoch 010/028 - train_loss: 0.9078 - val_loss: 1.1914 - val_acc: 0.5562
2025-10-13 11:10:46,965 - INFO - _models.training_function_executor - Epoch 011/028 - train_loss: 0.8991 - val_loss: 0.9321 - val_acc: 0.6450
2025-10-13 11:10:48,782 - INFO - _models.training_function_executor - Epoch 012/028 - train_loss: 0.9029 - val_loss: 0.8925 - val_acc: 0.6740
2025-10-13 11:10:50,602 - INFO - _models.training_function_executor - Epoch 013/028 - train_loss: 0.8937 - val_loss: 0.9179 - val_acc: 0.6509
2025-10-13 11:10:52,426 - INFO - _models.training_function_executor - Epoch 014/028 - train_loss: 0.8815 - val_loss: 0.9658 - val_acc: 0.6089
2025-10-13 11:10:54,244 - INFO - _models.training_function_executor - Epoch 015/028 - train_loss: 0.8843 - val_loss: 0.9422 - val_acc: 0.6250
2025-10-13 11:10:56,067 - INFO - _models.training_function_executor - Epoch 016/028 - train_loss: 0.8744 - val_loss: 0.8881 - val_acc: 0.6674
2025-10-13 11:10:57,891 - INFO - _models.training_function_executor - Epoch 017/028 - train_loss: 0.8702 - val_loss: 0.9021 - val_acc: 0.6357
2025-10-13 11:10:59,715 - INFO - _models.training_function_executor - Epoch 018/028 - train_loss: 0.8662 - val_loss: 0.9889 - val_acc: 0.6062
2025-10-13 11:11:01,536 - INFO - _models.training_function_executor - Epoch 019/028 - train_loss: 0.8623 - val_loss: 0.9537 - val_acc: 0.6236
2025-10-13 11:11:03,356 - INFO - _models.training_function_executor - Epoch 020/028 - train_loss: 0.8601 - val_loss: 0.8939 - val_acc: 0.6574
2025-10-13 11:11:05,193 - INFO - _models.training_function_executor - Epoch 021/028 - train_loss: 0.8579 - val_loss: 0.8441 - val_acc: 0.6874
2025-10-13 11:11:07,015 - INFO - _models.training_function_executor - Epoch 022/028 - train_loss: 0.8577 - val_loss: 0.9551 - val_acc: 0.6297
2025-10-13 11:11:08,840 - INFO - _models.training_function_executor - Epoch 023/028 - train_loss: 0.8450 - val_loss: 0.8955 - val_acc: 0.6519
2025-10-13 11:11:10,661 - INFO - _models.training_function_executor - Epoch 024/028 - train_loss: 0.8410 - val_loss: 0.9001 - val_acc: 0.6583
2025-10-13 11:11:12,481 - INFO - _models.training_function_executor - Epoch 025/028 - train_loss: 0.8340 - val_loss: 0.8505 - val_acc: 0.6868
2025-10-13 11:11:14,294 - INFO - _models.training_function_executor - Epoch 026/028 - train_loss: 0.8278 - val_loss: 0.8665 - val_acc: 0.6677
2025-10-13 11:11:16,128 - INFO - _models.training_function_executor - Epoch 027/028 - train_loss: 0.8268 - val_loss: 0.8782 - val_acc: 0.6494
2025-10-13 11:11:17,943 - INFO - _models.training_function_executor - Epoch 028/028 - train_loss: 0.8181 - val_loss: 0.9259 - val_acc: 0.6532
2025-10-13 11:11:19,373 - INFO - _models.training_function_executor - Model: 59 parameters, 0.1KB storage
2025-10-13 11:11:19,373 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1436992323936848, 1.013950828826632, 0.9857848969463873, 0.9697001271620054, 0.9695005493227485, 0.9514531401599835, 0.927352968988028, 0.9229022581175903, 0.912580177714702, 0.9077723515922471, 0.8990879479429293, 0.9029496263948653, 0.8937440690436812, 0.8814735602239315, 0.8842585981413749, 0.8744132467237519, 0.8702214342921106, 0.8661977174735211, 0.8622741194968045, 0.8600981993236282, 0.8579122689081565, 0.8577119133294693, 0.845042986013608, 0.8410287342331899, 0.8339646694373951, 0.8278214773974888, 0.8267924812109603, 0.8181413776982194], 'val_losses': [1.2982513541561096, 1.4881425699154565, 0.9851431643833511, 1.0242355514498995, 1.344008416698911, 1.1843565691589766, 0.9442934775878218, 0.9446314052138497, 0.9221133432648672, 1.1913689971596033, 0.9320735152801685, 0.8924668004223213, 0.9178622966468606, 0.9658258295910401, 0.9421936339083609, 0.8881169601383015, 0.9020727224019511, 0.9889066178856256, 0.9537469495790674, 0.8938704666909447, 0.8440661576397568, 0.9550918513425881, 0.8955426075093847, 0.9000873019906412, 0.850502811656534, 0.8665305537947167, 0.8782092948288696, 0.9258539114208709], 'val_acc': [0.46867343367168357, 0.4540602030101505, 0.6047427371368569, 0.591879593979699, 0.46823591179558977, 0.5758662933146658, 0.6555827791389569, 0.650070003500175, 0.6589079453972698, 0.5561778088904445, 0.6449947497374868, 0.6739586979348967, 0.6508575428771438, 0.6089429471473574, 0.6249562478123907, 0.6673958697934896, 0.6357192859642982, 0.6062303115155758, 0.6235561778088905, 0.6574203710185509, 0.6874343717185859, 0.6296814840742037, 0.651907595379769, 0.6582954147707385, 0.6868218410920546, 0.6677458872943647, 0.6493699684984249, 0.6532201610080504], 'final_state_dict_size_bytes': 2720, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004628199672772807, 'batch_size': 128, 'epochs': 28, 'weight_decay': 6.309987305543909e-05, 'dropout': 0.021681528320780834, 'channel_multiplier': 8, 'kernel_size1': 58, 'stride1': 7, 'kernel_size2': 39, 'stride2': 5, 'gcn_hidden': 23, 'label_smoothing': 0.010932162193587815, 'grad_clip_norm': 4.720835953566235, 'use_amp': False, 'calibrate_batches': 38, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 59, 'model_storage_size_kb': 0.06337890625, 'model_size_validation': 'PASS'}
2025-10-13 11:11:19,373 - INFO - _models.training_function_executor - BO Objective: base=0.6532, size_penalty=0.0000, final=0.6532
2025-10-13 11:11:19,373 - INFO - _models.training_function_executor - Model: 59 parameters, 0.1KB (PASS 256KB limit)
2025-10-13 11:11:19,373 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 55.292s
2025-10-13 11:11:19,451 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6532
2025-10-13 11:11:19,451 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.077s
2025-10-13 11:11:19,451 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.004628199672772807, 'batch_size': np.int64(128), 'epochs': np.int64(28), 'weight_decay': 6.309987305543909e-05, 'dropout': 0.021681528320780834, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(58), 'stride1': np.int64(7), 'kernel_size2': np.int64(39), 'stride2': np.int64(5), 'gcn_hidden': np.int64(23), 'label_smoothing': 0.010932162193587815, 'grad_clip_norm': 4.720835953566235, 'use_amp': np.False_, 'calibrate_batches': np.int64(38), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.6532
2025-10-13 11:11:19,451 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.004628199672772807, 'batch_size': np.int64(128), 'epochs': np.int64(28), 'weight_decay': 6.309987305543909e-05, 'dropout': 0.021681528320780834, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(58), 'stride1': np.int64(7), 'kernel_size2': np.int64(39), 'stride2': np.int64(5), 'gcn_hidden': np.int64(23), 'label_smoothing': 0.010932162193587815, 'grad_clip_norm': 4.720835953566235, 'use_amp': np.False_, 'calibrate_batches': np.int64(38), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.6532
2025-10-13 11:11:19,452 - INFO - bo.run_bo - üîçBO Trial 7: Using RF surrogate + Expected Improvement
2025-10-13 11:11:19,452 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:11:19,452 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 7 (NaN monitoring active)
2025-10-13 11:11:19,452 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:11:19,452 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:11:19,452 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0019397468718711213, 'batch_size': 16, 'epochs': 38, 'weight_decay': 0.000793037657181025, 'dropout': 0.3753854199797957, 'channel_multiplier': 2, 'kernel_size1': 116, 'stride1': 12, 'kernel_size2': 29, 'stride2': 7, 'gcn_hidden': 22, 'label_smoothing': 0.056319130597265885, 'grad_clip_norm': 3.8020669647557, 'use_amp': False, 'calibrate_batches': 83, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:11:19,453 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0019397468718711213, 'batch_size': 16, 'epochs': 38, 'weight_decay': 0.000793037657181025, 'dropout': 0.3753854199797957, 'channel_multiplier': 2, 'kernel_size1': 116, 'stride1': 12, 'kernel_size2': 29, 'stride2': 7, 'gcn_hidden': 22, 'label_smoothing': 0.056319130597265885, 'grad_clip_norm': 3.8020669647557, 'use_amp': False, 'calibrate_batches': 83, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:11:26,192 - INFO - _models.training_function_executor - Epoch 001/038 - train_loss: 1.4148 - val_loss: 1.4185 - val_acc: 0.4379
2025-10-13 11:11:30,148 - INFO - _models.training_function_executor - Epoch 002/038 - train_loss: 1.3916 - val_loss: 1.3871 - val_acc: 0.4451
2025-10-13 11:11:34,115 - INFO - _models.training_function_executor - Epoch 003/038 - train_loss: 1.3702 - val_loss: 1.3765 - val_acc: 0.4358
2025-10-13 11:11:38,107 - INFO - _models.training_function_executor - Epoch 004/038 - train_loss: 1.3579 - val_loss: 1.7205 - val_acc: 0.2304
2025-10-13 11:11:42,057 - INFO - _models.training_function_executor - Epoch 005/038 - train_loss: 1.3564 - val_loss: 1.3816 - val_acc: 0.4364
2025-10-13 11:11:46,007 - INFO - _models.training_function_executor - Epoch 006/038 - train_loss: 1.3535 - val_loss: 1.3611 - val_acc: 0.4387
2025-10-13 11:11:49,958 - INFO - _models.training_function_executor - Epoch 007/038 - train_loss: 1.3485 - val_loss: 1.4894 - val_acc: 0.3737
2025-10-13 11:11:53,956 - INFO - _models.training_function_executor - Epoch 008/038 - train_loss: 1.3481 - val_loss: 1.6961 - val_acc: 0.2307
2025-10-13 11:11:57,844 - INFO - _models.training_function_executor - Epoch 009/038 - train_loss: 1.3457 - val_loss: 1.4393 - val_acc: 0.4056
2025-10-13 11:12:01,779 - INFO - _models.training_function_executor - Epoch 010/038 - train_loss: 1.3433 - val_loss: 1.3978 - val_acc: 0.4290
2025-10-13 11:12:05,686 - INFO - _models.training_function_executor - Epoch 011/038 - train_loss: 1.3425 - val_loss: 1.4155 - val_acc: 0.4193
2025-10-13 11:12:09,615 - INFO - _models.training_function_executor - Epoch 012/038 - train_loss: 1.3416 - val_loss: 1.4092 - val_acc: 0.4205
2025-10-13 11:12:13,528 - INFO - _models.training_function_executor - Epoch 013/038 - train_loss: 1.3420 - val_loss: 1.3604 - val_acc: 0.4458
2025-10-13 11:12:17,460 - INFO - _models.training_function_executor - Epoch 014/038 - train_loss: 1.3412 - val_loss: 1.4061 - val_acc: 0.4310
2025-10-13 11:12:21,403 - INFO - _models.training_function_executor - Epoch 015/038 - train_loss: 1.3380 - val_loss: 1.3668 - val_acc: 0.4400
2025-10-13 11:12:25,356 - INFO - _models.training_function_executor - Epoch 016/038 - train_loss: 1.3323 - val_loss: 1.5029 - val_acc: 0.3914
2025-10-13 11:12:29,285 - INFO - _models.training_function_executor - Epoch 017/038 - train_loss: 1.3304 - val_loss: 1.3800 - val_acc: 0.4454
2025-10-13 11:12:33,232 - INFO - _models.training_function_executor - Epoch 018/038 - train_loss: 1.3263 - val_loss: 1.3806 - val_acc: 0.4341
2025-10-13 11:12:37,181 - INFO - _models.training_function_executor - Epoch 019/038 - train_loss: 1.2674 - val_loss: 1.4174 - val_acc: 0.4240
2025-10-13 11:12:41,046 - INFO - _models.training_function_executor - Epoch 020/038 - train_loss: 1.2262 - val_loss: 1.3124 - val_acc: 0.5020
2025-10-13 11:12:44,948 - INFO - _models.training_function_executor - Epoch 021/038 - train_loss: 1.2070 - val_loss: 1.3745 - val_acc: 0.4407
2025-10-13 11:12:48,873 - INFO - _models.training_function_executor - Epoch 022/038 - train_loss: 1.1928 - val_loss: 1.4200 - val_acc: 0.4057
2025-10-13 11:12:52,733 - INFO - _models.training_function_executor - Epoch 023/038 - train_loss: 1.1899 - val_loss: 1.2422 - val_acc: 0.5145
2025-10-13 11:12:56,632 - INFO - _models.training_function_executor - Epoch 024/038 - train_loss: 1.1857 - val_loss: 1.3331 - val_acc: 0.4591
2025-10-13 11:13:00,507 - INFO - _models.training_function_executor - Epoch 025/038 - train_loss: 1.1794 - val_loss: 1.2984 - val_acc: 0.4899
2025-10-13 11:13:04,416 - INFO - _models.training_function_executor - Epoch 026/038 - train_loss: 1.1769 - val_loss: 1.2884 - val_acc: 0.5056
2025-10-13 11:13:08,375 - INFO - _models.training_function_executor - Epoch 027/038 - train_loss: 1.1794 - val_loss: 1.3084 - val_acc: 0.4827
2025-10-13 11:13:12,224 - INFO - _models.training_function_executor - Epoch 028/038 - train_loss: 1.1780 - val_loss: 1.4419 - val_acc: 0.3905
2025-10-13 11:13:16,098 - INFO - _models.training_function_executor - Epoch 029/038 - train_loss: 1.1721 - val_loss: 1.3135 - val_acc: 0.4691
2025-10-13 11:13:20,049 - INFO - _models.training_function_executor - Epoch 030/038 - train_loss: 1.1703 - val_loss: 1.3364 - val_acc: 0.4513
2025-10-13 11:13:23,975 - INFO - _models.training_function_executor - Epoch 031/038 - train_loss: 1.1695 - val_loss: 1.3447 - val_acc: 0.4394
2025-10-13 11:13:27,925 - INFO - _models.training_function_executor - Epoch 032/038 - train_loss: 1.1755 - val_loss: 1.2618 - val_acc: 0.5062
2025-10-13 11:13:31,787 - INFO - _models.training_function_executor - Epoch 033/038 - train_loss: 1.1707 - val_loss: 1.2537 - val_acc: 0.5109
2025-10-13 11:13:35,740 - INFO - _models.training_function_executor - Epoch 034/038 - train_loss: 1.1709 - val_loss: 1.5116 - val_acc: 0.3887
2025-10-13 11:13:39,672 - INFO - _models.training_function_executor - Epoch 035/038 - train_loss: 1.1719 - val_loss: 1.3272 - val_acc: 0.4581
2025-10-13 11:13:43,562 - INFO - _models.training_function_executor - Epoch 036/038 - train_loss: 1.1682 - val_loss: 1.4719 - val_acc: 0.3886
2025-10-13 11:13:47,537 - INFO - _models.training_function_executor - Epoch 037/038 - train_loss: 1.1679 - val_loss: 1.2775 - val_acc: 0.4868
2025-10-13 11:13:51,499 - INFO - _models.training_function_executor - Epoch 038/038 - train_loss: 1.1662 - val_loss: 1.2467 - val_acc: 0.5201
2025-10-13 11:13:52,623 - INFO - _models.training_function_executor - Model: 1,319 parameters, 2.8KB storage
2025-10-13 11:13:52,623 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4147724025433908, 1.3915730251646725, 1.370171936859315, 1.3578504498371262, 1.3564076894306827, 1.3535312253944014, 1.3484518742870109, 1.348114673203424, 1.345653538775686, 1.3432893788309668, 1.3425471730319027, 1.3415729937371483, 1.3419676749156328, 1.3412305798862711, 1.3380151948062615, 1.3322960778178976, 1.3304422677376908, 1.326294585379179, 1.2674028673161983, 1.2262012896773111, 1.2070240746188672, 1.1928263030396002, 1.1898591797335982, 1.185660517295007, 1.1793929703343278, 1.1769481783235327, 1.1793503586045087, 1.1779842270518, 1.1720757537844468, 1.1702950987567173, 1.1695272592051196, 1.1754655160393213, 1.170673339505441, 1.1708644164747652, 1.1718563680303318, 1.1682319281023619, 1.1678561265960121, 1.166188067809076], 'val_losses': [1.4184551708006468, 1.3870743920346595, 1.376497638738777, 1.7204925599613932, 1.3815581816078109, 1.3611276101348364, 1.4893709916437594, 1.6960683925443067, 1.4392990971262487, 1.3977648232172617, 1.4154722543709086, 1.4092317284259255, 1.3603725410817926, 1.4060957215655965, 1.366792586536561, 1.5028638452093293, 1.3800139025370057, 1.380594498008792, 1.417395746119589, 1.312417258154816, 1.3744540943480221, 1.420011129669681, 1.2422448171574543, 1.3331308381141045, 1.2984380083022353, 1.2884064195746094, 1.3083616316548001, 1.441948359480762, 1.3134946047237464, 1.3364043615896635, 1.3446695748683994, 1.2617765572424071, 1.253708146629861, 1.511632662325169, 1.327196726775645, 1.4718723993515026, 1.2775074003416214, 1.2466846506496305], 'val_acc': [0.4378718935946797, 0.44513475673783687, 0.4357717885894295, 0.23039901995099754, 0.4363843192159608, 0.4387469373468673, 0.37373118655932797, 0.23074903745187259, 0.40558277913895696, 0.4290339516975849, 0.41932096604830243, 0.4205460273013651, 0.44583479173958696, 0.4310465523276164, 0.43997199859992997, 0.3914070703535177, 0.44539726986349315, 0.43410920546027304, 0.42395869793489677, 0.5020126006300315, 0.44067203360168006, 0.4056702835141757, 0.5145257262863143, 0.4591354567728386, 0.4899369968498425, 0.5056002800140007, 0.4826741337066853, 0.3905320266013301, 0.4691109555477774, 0.45126006300315014, 0.43935946797339864, 0.506212810640532, 0.5108505425271264, 0.3886944347217361, 0.4580854042702135, 0.38860693034651733, 0.4867868393419671, 0.520126006300315], 'final_state_dict_size_bytes': 2726, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0019397468718711213, 'batch_size': 16, 'epochs': 38, 'weight_decay': 0.000793037657181025, 'dropout': 0.3753854199797957, 'channel_multiplier': 2, 'kernel_size1': 116, 'stride1': 12, 'kernel_size2': 29, 'stride2': 7, 'gcn_hidden': 22, 'label_smoothing': 0.056319130597265885, 'grad_clip_norm': 3.8020669647557, 'use_amp': False, 'calibrate_batches': 83, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 1319, 'model_storage_size_kb': 2.8337890625, 'model_size_validation': 'PASS'}
2025-10-13 11:13:52,623 - INFO - _models.training_function_executor - BO Objective: base=0.5201, size_penalty=0.0000, final=0.5201
2025-10-13 11:13:52,624 - INFO - _models.training_function_executor - Model: 1,319 parameters, 2.8KB (PASS 256KB limit)
2025-10-13 11:13:52,624 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 153.172s
2025-10-13 11:13:52,701 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5201
2025-10-13 11:13:52,701 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.077s
2025-10-13 11:13:52,701 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 0.0019397468718711213, 'batch_size': np.int64(16), 'epochs': np.int64(38), 'weight_decay': 0.000793037657181025, 'dropout': 0.3753854199797957, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(116), 'stride1': np.int64(12), 'kernel_size2': np.int64(29), 'stride2': np.int64(7), 'gcn_hidden': np.int64(22), 'label_smoothing': 0.056319130597265885, 'grad_clip_norm': 3.8020669647557, 'use_amp': np.False_, 'calibrate_batches': np.int64(83), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.5201
2025-10-13 11:13:52,701 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 0.0019397468718711213, 'batch_size': np.int64(16), 'epochs': np.int64(38), 'weight_decay': 0.000793037657181025, 'dropout': 0.3753854199797957, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(116), 'stride1': np.int64(12), 'kernel_size2': np.int64(29), 'stride2': np.int64(7), 'gcn_hidden': np.int64(22), 'label_smoothing': 0.056319130597265885, 'grad_clip_norm': 3.8020669647557, 'use_amp': np.False_, 'calibrate_batches': np.int64(83), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.5201
2025-10-13 11:13:52,701 - INFO - bo.run_bo - üîçBO Trial 8: Using RF surrogate + Expected Improvement
2025-10-13 11:13:52,701 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:13:52,701 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 8 (NaN monitoring active)
2025-10-13 11:13:52,701 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:13:52,701 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:13:52,701 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00011438532069322815, 'batch_size': 128, 'epochs': 51, 'weight_decay': 0.00034117922978326484, 'dropout': 0.04082284074934327, 'channel_multiplier': 4, 'kernel_size1': 49, 'stride1': 5, 'kernel_size2': 46, 'stride2': 2, 'gcn_hidden': 20, 'label_smoothing': 0.05233907927974509, 'grad_clip_norm': 2.4814563410141166, 'use_amp': False, 'calibrate_batches': 51, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:13:52,703 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00011438532069322815, 'batch_size': 128, 'epochs': 51, 'weight_decay': 0.00034117922978326484, 'dropout': 0.04082284074934327, 'channel_multiplier': 4, 'kernel_size1': 49, 'stride1': 5, 'kernel_size2': 46, 'stride2': 2, 'gcn_hidden': 20, 'label_smoothing': 0.05233907927974509, 'grad_clip_norm': 2.4814563410141166, 'use_amp': False, 'calibrate_batches': 51, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:13:57,366 - INFO - _models.training_function_executor - Epoch 001/051 - train_loss: 1.5725 - val_loss: 1.5600 - val_acc: 0.3141
2025-10-13 11:13:59,249 - INFO - _models.training_function_executor - Epoch 002/051 - train_loss: 1.5166 - val_loss: 1.5097 - val_acc: 0.3492
2025-10-13 11:14:01,144 - INFO - _models.training_function_executor - Epoch 003/051 - train_loss: 1.4432 - val_loss: 1.4443 - val_acc: 0.4405
2025-10-13 11:14:03,032 - INFO - _models.training_function_executor - Epoch 004/051 - train_loss: 1.3758 - val_loss: 1.3859 - val_acc: 0.4743
2025-10-13 11:14:04,918 - INFO - _models.training_function_executor - Epoch 005/051 - train_loss: 1.3187 - val_loss: 1.3532 - val_acc: 0.4871
2025-10-13 11:14:06,798 - INFO - _models.training_function_executor - Epoch 006/051 - train_loss: 1.2755 - val_loss: 1.3072 - val_acc: 0.5122
2025-10-13 11:14:08,671 - INFO - _models.training_function_executor - Epoch 007/051 - train_loss: 1.2462 - val_loss: 1.2599 - val_acc: 0.5338
2025-10-13 11:14:10,552 - INFO - _models.training_function_executor - Epoch 008/051 - train_loss: 1.2229 - val_loss: 1.2526 - val_acc: 0.5443
2025-10-13 11:14:12,431 - INFO - _models.training_function_executor - Epoch 009/051 - train_loss: 1.2073 - val_loss: 1.2989 - val_acc: 0.5063
2025-10-13 11:14:14,312 - INFO - _models.training_function_executor - Epoch 010/051 - train_loss: 1.1919 - val_loss: 1.2242 - val_acc: 0.5330
2025-10-13 11:14:16,195 - INFO - _models.training_function_executor - Epoch 011/051 - train_loss: 1.1841 - val_loss: 1.2759 - val_acc: 0.4926
2025-10-13 11:14:18,083 - INFO - _models.training_function_executor - Epoch 012/051 - train_loss: 1.1747 - val_loss: 1.2224 - val_acc: 0.5274
2025-10-13 11:14:19,961 - INFO - _models.training_function_executor - Epoch 013/051 - train_loss: 1.1686 - val_loss: 1.3723 - val_acc: 0.4527
2025-10-13 11:14:21,836 - INFO - _models.training_function_executor - Epoch 014/051 - train_loss: 1.1637 - val_loss: 1.2207 - val_acc: 0.5230
2025-10-13 11:14:23,724 - INFO - _models.training_function_executor - Epoch 015/051 - train_loss: 1.1577 - val_loss: 1.1623 - val_acc: 0.5579
2025-10-13 11:14:25,605 - INFO - _models.training_function_executor - Epoch 016/051 - train_loss: 1.1540 - val_loss: 1.1598 - val_acc: 0.5568
2025-10-13 11:14:27,481 - INFO - _models.training_function_executor - Epoch 017/051 - train_loss: 1.1496 - val_loss: 1.2565 - val_acc: 0.4996
2025-10-13 11:14:29,368 - INFO - _models.training_function_executor - Epoch 018/051 - train_loss: 1.1469 - val_loss: 1.1824 - val_acc: 0.5733
2025-10-13 11:14:31,249 - INFO - _models.training_function_executor - Epoch 019/051 - train_loss: 1.1450 - val_loss: 1.1563 - val_acc: 0.5600
2025-10-13 11:14:33,140 - INFO - _models.training_function_executor - Epoch 020/051 - train_loss: 1.1388 - val_loss: 1.1737 - val_acc: 0.5466
2025-10-13 11:14:35,025 - INFO - _models.training_function_executor - Epoch 021/051 - train_loss: 1.1371 - val_loss: 1.1397 - val_acc: 0.5636
2025-10-13 11:14:36,918 - INFO - _models.training_function_executor - Epoch 022/051 - train_loss: 1.1309 - val_loss: 1.2965 - val_acc: 0.4788
2025-10-13 11:14:38,797 - INFO - _models.training_function_executor - Epoch 023/051 - train_loss: 1.1304 - val_loss: 1.1288 - val_acc: 0.5933
2025-10-13 11:14:40,684 - INFO - _models.training_function_executor - Epoch 024/051 - train_loss: 1.1257 - val_loss: 1.1675 - val_acc: 0.5722
2025-10-13 11:14:42,565 - INFO - _models.training_function_executor - Epoch 025/051 - train_loss: 1.1220 - val_loss: 1.1666 - val_acc: 0.5392
2025-10-13 11:14:44,445 - INFO - _models.training_function_executor - Epoch 026/051 - train_loss: 1.1193 - val_loss: 1.2104 - val_acc: 0.5366
2025-10-13 11:14:46,333 - INFO - _models.training_function_executor - Epoch 027/051 - train_loss: 1.1165 - val_loss: 1.1232 - val_acc: 0.5669
2025-10-13 11:14:48,228 - INFO - _models.training_function_executor - Epoch 028/051 - train_loss: 1.1130 - val_loss: 1.1564 - val_acc: 0.5600
2025-10-13 11:14:50,119 - INFO - _models.training_function_executor - Epoch 029/051 - train_loss: 1.1135 - val_loss: 1.2196 - val_acc: 0.5196
2025-10-13 11:14:52,002 - INFO - _models.training_function_executor - Epoch 030/051 - train_loss: 1.1107 - val_loss: 1.1650 - val_acc: 0.5680
2025-10-13 11:14:53,894 - INFO - _models.training_function_executor - Epoch 031/051 - train_loss: 1.1063 - val_loss: 1.2322 - val_acc: 0.5250
2025-10-13 11:14:55,789 - INFO - _models.training_function_executor - Epoch 032/051 - train_loss: 1.1051 - val_loss: 1.1839 - val_acc: 0.5323
2025-10-13 11:14:57,693 - INFO - _models.training_function_executor - Epoch 033/051 - train_loss: 1.1015 - val_loss: 1.1829 - val_acc: 0.5458
2025-10-13 11:14:59,582 - INFO - _models.training_function_executor - Epoch 034/051 - train_loss: 1.0992 - val_loss: 1.1035 - val_acc: 0.5873
2025-10-13 11:15:01,475 - INFO - _models.training_function_executor - Epoch 035/051 - train_loss: 1.0988 - val_loss: 1.1949 - val_acc: 0.5530
2025-10-13 11:15:03,368 - INFO - _models.training_function_executor - Epoch 036/051 - train_loss: 1.0955 - val_loss: 1.1021 - val_acc: 0.5879
2025-10-13 11:15:05,274 - INFO - _models.training_function_executor - Epoch 037/051 - train_loss: 1.0964 - val_loss: 1.0892 - val_acc: 0.6096
2025-10-13 11:15:07,166 - INFO - _models.training_function_executor - Epoch 038/051 - train_loss: 1.0915 - val_loss: 1.0906 - val_acc: 0.6000
2025-10-13 11:15:09,072 - INFO - _models.training_function_executor - Epoch 039/051 - train_loss: 1.0911 - val_loss: 1.0841 - val_acc: 0.6079
2025-10-13 11:15:10,959 - INFO - _models.training_function_executor - Epoch 040/051 - train_loss: 1.0878 - val_loss: 1.0933 - val_acc: 0.6032
2025-10-13 11:15:12,849 - INFO - _models.training_function_executor - Epoch 041/051 - train_loss: 1.0868 - val_loss: 1.0761 - val_acc: 0.6187
2025-10-13 11:15:14,745 - INFO - _models.training_function_executor - Epoch 042/051 - train_loss: 1.0845 - val_loss: 1.1047 - val_acc: 0.5916
2025-10-13 11:15:16,630 - INFO - _models.training_function_executor - Epoch 043/051 - train_loss: 1.0827 - val_loss: 1.3061 - val_acc: 0.4771
2025-10-13 11:15:18,515 - INFO - _models.training_function_executor - Epoch 044/051 - train_loss: 1.0810 - val_loss: 1.0945 - val_acc: 0.6005
2025-10-13 11:15:20,410 - INFO - _models.training_function_executor - Epoch 045/051 - train_loss: 1.0809 - val_loss: 1.1793 - val_acc: 0.5297
2025-10-13 11:15:22,301 - INFO - _models.training_function_executor - Epoch 046/051 - train_loss: 1.0781 - val_loss: 1.0965 - val_acc: 0.5995
2025-10-13 11:15:24,207 - INFO - _models.training_function_executor - Epoch 047/051 - train_loss: 1.0773 - val_loss: 1.2139 - val_acc: 0.5226
2025-10-13 11:15:26,095 - INFO - _models.training_function_executor - Epoch 048/051 - train_loss: 1.0756 - val_loss: 1.0847 - val_acc: 0.6168
2025-10-13 11:15:27,984 - INFO - _models.training_function_executor - Epoch 049/051 - train_loss: 1.0739 - val_loss: 1.0655 - val_acc: 0.6313
2025-10-13 11:15:29,879 - INFO - _models.training_function_executor - Epoch 050/051 - train_loss: 1.0755 - val_loss: 1.1333 - val_acc: 0.6047
2025-10-13 11:15:31,769 - INFO - _models.training_function_executor - Epoch 051/051 - train_loss: 1.0744 - val_loss: 1.2036 - val_acc: 0.5318
2025-10-13 11:15:33,499 - INFO - _models.training_function_executor - Model: 56 parameters, 0.1KB storage
2025-10-13 11:15:33,499 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5724635581516244, 1.5166362592879399, 1.443161510486556, 1.3758159144424582, 1.3186510831774805, 1.2755319322369756, 1.246245886297296, 1.2228604299353685, 1.2072569147289571, 1.1918851312824925, 1.1840578257140473, 1.1746961473584134, 1.168589780161253, 1.1637146377797138, 1.1576553853525329, 1.1539971945708891, 1.149574112049299, 1.1469164968246257, 1.1449914390405742, 1.1388216113393275, 1.1371203017143006, 1.1309062209127665, 1.1303555693374383, 1.125730389558981, 1.1219605523304044, 1.1192555765943757, 1.1164691728605938, 1.1130356011292215, 1.1134662085327185, 1.1107298477070708, 1.1062911742627308, 1.1051265364724687, 1.1014956570522827, 1.0992405884617227, 1.0987926457868742, 1.0954679796901832, 1.0963695584204718, 1.0915065966246635, 1.091051385542042, 1.0877534874594625, 1.0868251712997352, 1.0844614061392976, 1.0827344793266962, 1.0810419994924383, 1.0809391734480733, 1.0780992721776925, 1.0772857644109823, 1.0756487010616, 1.0738838533442214, 1.0754654351589268, 1.0744408956557085], 'val_losses': [1.5599686863291375, 1.5096744752072102, 1.4442589040982543, 1.3858817846240137, 1.353189084009979, 1.3072252729200258, 1.2599338303506895, 1.252590849009852, 1.298924354268489, 1.224154346131928, 1.2758911705367584, 1.2223881017840488, 1.3723073404570496, 1.2207290842101672, 1.1623480235691626, 1.1597747813582964, 1.2565192690586602, 1.1823842779172231, 1.1563129389582292, 1.173711907542332, 1.1397446961014013, 1.296471562258714, 1.1287820951730836, 1.1674566916915392, 1.1665738318656598, 1.210410578542128, 1.1232476603705273, 1.156387487741296, 1.2195799611521885, 1.1650143699459066, 1.232154290743712, 1.1838847936597536, 1.1828912784471601, 1.1034679874741284, 1.1948589182918123, 1.10211233672121, 1.0892046246446845, 1.0905892706267852, 1.0840620319034655, 1.0933445471752596, 1.0760976425367175, 1.104689643564114, 1.3060729954265238, 1.0945122428068883, 1.1792644713364742, 1.09650349754698, 1.2139363390271964, 1.0847487275234085, 1.0655124753682315, 1.1332675519004585, 1.2036361910055933], 'val_acc': [0.31414070703535174, 0.3492299614980749, 0.44049702485124254, 0.4742737136856843, 0.48713685684284214, 0.5121631081554078, 0.5337766888344417, 0.544277213860693, 0.5063003150157508, 0.5329891494574729, 0.4926496324816241, 0.5273888694434722, 0.4527476373818691, 0.5230136506825341, 0.5579278963948198, 0.5567903395169759, 0.4995624781239062, 0.5733286664333217, 0.56002800140007, 0.5466398319915996, 0.5636156807840392, 0.47882394119705984, 0.5932796639831992, 0.5721911095554778, 0.5392019600980049, 0.5365768288414421, 0.5668533426671334, 0.56002800140007, 0.5196009800490025, 0.5679908995449773, 0.5250262513125656, 0.5322891144557228, 0.545764788239412, 0.5873293664683235, 0.5530276513825692, 0.587854392719636, 0.6095554777738887, 0.6000175008750438, 0.6078928946447323, 0.6031676583829192, 0.6186559327966399, 0.5916170808540427, 0.4770738536926846, 0.6005425271263564, 0.52966398319916, 0.5994924746237312, 0.5225761288064403, 0.6168183409170459, 0.6313440672033601, 0.6047427371368569, 0.5317640882044102], 'final_state_dict_size_bytes': 1790, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00011438532069322815, 'batch_size': 128, 'epochs': 51, 'weight_decay': 0.00034117922978326484, 'dropout': 0.04082284074934327, 'channel_multiplier': 4, 'kernel_size1': 49, 'stride1': 5, 'kernel_size2': 46, 'stride2': 2, 'gcn_hidden': 20, 'label_smoothing': 0.05233907927974509, 'grad_clip_norm': 2.4814563410141166, 'use_amp': False, 'calibrate_batches': 51, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 56, 'model_storage_size_kb': 0.06015625000000001, 'model_size_validation': 'PASS'}
2025-10-13 11:15:33,499 - INFO - _models.training_function_executor - BO Objective: base=0.5318, size_penalty=0.0000, final=0.5318
2025-10-13 11:15:33,499 - INFO - _models.training_function_executor - Model: 56 parameters, 0.1KB (PASS 256KB limit)
2025-10-13 11:15:33,499 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 100.798s
2025-10-13 11:15:33,581 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5318
2025-10-13 11:15:33,581 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.080s
2025-10-13 11:15:33,581 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 0.00011438532069322815, 'batch_size': np.int64(128), 'epochs': np.int64(51), 'weight_decay': 0.00034117922978326484, 'dropout': 0.04082284074934327, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(49), 'stride1': np.int64(5), 'kernel_size2': np.int64(46), 'stride2': np.int64(2), 'gcn_hidden': np.int64(20), 'label_smoothing': 0.05233907927974509, 'grad_clip_norm': 2.4814563410141166, 'use_amp': np.False_, 'calibrate_batches': np.int64(51), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.5318
2025-10-13 11:15:33,581 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 0.00011438532069322815, 'batch_size': np.int64(128), 'epochs': np.int64(51), 'weight_decay': 0.00034117922978326484, 'dropout': 0.04082284074934327, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(49), 'stride1': np.int64(5), 'kernel_size2': np.int64(46), 'stride2': np.int64(2), 'gcn_hidden': np.int64(20), 'label_smoothing': 0.05233907927974509, 'grad_clip_norm': 2.4814563410141166, 'use_amp': np.False_, 'calibrate_batches': np.int64(51), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.5318
2025-10-13 11:15:33,581 - INFO - bo.run_bo - üîçBO Trial 9: Using RF surrogate + Expected Improvement
2025-10-13 11:15:33,581 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:15:33,581 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 9 (NaN monitoring active)
2025-10-13 11:15:33,581 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:15:33,581 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:15:33,581 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.006090612754359839, 'batch_size': 48, 'epochs': 24, 'weight_decay': 4.923067128056138e-05, 'dropout': 0.04519712488936195, 'channel_multiplier': 6, 'kernel_size1': 51, 'stride1': 7, 'kernel_size2': 8, 'stride2': 6, 'gcn_hidden': 21, 'label_smoothing': 0.16351379290239976, 'grad_clip_norm': 4.996644125456917, 'use_amp': False, 'calibrate_batches': 13, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:15:33,582 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.006090612754359839, 'batch_size': 48, 'epochs': 24, 'weight_decay': 4.923067128056138e-05, 'dropout': 0.04519712488936195, 'channel_multiplier': 6, 'kernel_size1': 51, 'stride1': 7, 'kernel_size2': 8, 'stride2': 6, 'gcn_hidden': 21, 'label_smoothing': 0.16351379290239976, 'grad_clip_norm': 4.996644125456917, 'use_amp': False, 'calibrate_batches': 13, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:15:37,929 - INFO - _models.training_function_executor - Epoch 001/024 - train_loss: 1.2907 - val_loss: 1.2622 - val_acc: 0.5646
2025-10-13 11:15:39,517 - INFO - _models.training_function_executor - Epoch 002/024 - train_loss: 1.2044 - val_loss: 1.1951 - val_acc: 0.6098
2025-10-13 11:15:41,089 - INFO - _models.training_function_executor - Epoch 003/024 - train_loss: 1.1835 - val_loss: 1.3627 - val_acc: 0.4916
2025-10-13 11:15:42,676 - INFO - _models.training_function_executor - Epoch 004/024 - train_loss: 1.1716 - val_loss: 1.1767 - val_acc: 0.6509
2025-10-13 11:15:44,245 - INFO - _models.training_function_executor - Epoch 005/024 - train_loss: 1.1577 - val_loss: 1.1984 - val_acc: 0.6060
2025-10-13 11:15:45,830 - INFO - _models.training_function_executor - Epoch 006/024 - train_loss: 1.1458 - val_loss: 1.2122 - val_acc: 0.6061
2025-10-13 11:15:47,392 - INFO - _models.training_function_executor - Epoch 007/024 - train_loss: 1.1396 - val_loss: 1.1090 - val_acc: 0.6840
2025-10-13 11:15:48,964 - INFO - _models.training_function_executor - Epoch 008/024 - train_loss: 1.1334 - val_loss: 1.1206 - val_acc: 0.6686
2025-10-13 11:15:50,535 - INFO - _models.training_function_executor - Epoch 009/024 - train_loss: 1.1250 - val_loss: 1.1083 - val_acc: 0.6859
2025-10-13 11:15:52,112 - INFO - _models.training_function_executor - Epoch 010/024 - train_loss: 1.1180 - val_loss: 1.1499 - val_acc: 0.6526
2025-10-13 11:15:53,688 - INFO - _models.training_function_executor - Epoch 011/024 - train_loss: 1.1112 - val_loss: 1.1236 - val_acc: 0.6578
2025-10-13 11:15:55,284 - INFO - _models.training_function_executor - Epoch 012/024 - train_loss: 1.1050 - val_loss: 1.1104 - val_acc: 0.6704
2025-10-13 11:15:56,861 - INFO - _models.training_function_executor - Epoch 013/024 - train_loss: 1.0990 - val_loss: 1.1356 - val_acc: 0.6516
2025-10-13 11:15:58,446 - INFO - _models.training_function_executor - Epoch 014/024 - train_loss: 1.0924 - val_loss: 1.0864 - val_acc: 0.6844
2025-10-13 11:16:00,034 - INFO - _models.training_function_executor - Epoch 015/024 - train_loss: 1.0873 - val_loss: 1.1032 - val_acc: 0.6782
2025-10-13 11:16:01,603 - INFO - _models.training_function_executor - Epoch 016/024 - train_loss: 1.0830 - val_loss: 1.0778 - val_acc: 0.6917
2025-10-13 11:16:03,183 - INFO - _models.training_function_executor - Epoch 017/024 - train_loss: 1.0823 - val_loss: 1.0835 - val_acc: 0.6951
2025-10-13 11:16:04,786 - INFO - _models.training_function_executor - Epoch 018/024 - train_loss: 1.0803 - val_loss: 1.2637 - val_acc: 0.5292
2025-10-13 11:16:06,363 - INFO - _models.training_function_executor - Epoch 019/024 - train_loss: 1.0744 - val_loss: 1.1002 - val_acc: 0.6793
2025-10-13 11:16:07,949 - INFO - _models.training_function_executor - Epoch 020/024 - train_loss: 1.0744 - val_loss: 1.1313 - val_acc: 0.6594
2025-10-13 11:16:09,523 - INFO - _models.training_function_executor - Epoch 021/024 - train_loss: 1.0709 - val_loss: 1.0772 - val_acc: 0.6914
2025-10-13 11:16:11,090 - INFO - _models.training_function_executor - Epoch 022/024 - train_loss: 1.0697 - val_loss: 1.0694 - val_acc: 0.7048
2025-10-13 11:16:12,665 - INFO - _models.training_function_executor - Epoch 023/024 - train_loss: 1.0674 - val_loss: 1.0860 - val_acc: 0.6886
2025-10-13 11:16:14,241 - INFO - _models.training_function_executor - Epoch 024/024 - train_loss: 1.0684 - val_loss: 1.0837 - val_acc: 0.6837
2025-10-13 11:16:15,356 - INFO - _models.training_function_executor - Model: 992 parameters, 4.3KB storage
2025-10-13 11:16:15,356 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2907246492273707, 1.2043812554492623, 1.1834719102617157, 1.1715681072002446, 1.1577299007553299, 1.1457519772005198, 1.139574759587317, 1.1334332852126587, 1.1250004744170887, 1.1180101220616938, 1.1112037798012309, 1.1049728456142693, 1.0990337622011297, 1.0924060399356237, 1.0872839898715956, 1.0830165333876378, 1.0823083420629305, 1.080345723755843, 1.0744222894514361, 1.0744026663380983, 1.0708724547817776, 1.0696697945064042, 1.0674311559351333, 1.068362442834585], 'val_losses': [1.2621704584074305, 1.19514699135788, 1.362728237855422, 1.17671979854772, 1.1983677513915674, 1.2121746858433906, 1.1089674690865452, 1.1206285595101078, 1.1082801606882942, 1.1498820208401626, 1.1236176456568914, 1.1104231346392073, 1.135583736114582, 1.086381489887578, 1.1032413242578423, 1.0777693585912205, 1.0835102526591631, 1.2637025039847765, 1.1001536785241897, 1.1313096208926219, 1.077221709112208, 1.0693760993892094, 1.0859634193624697, 1.0836748129678098], 'val_acc': [0.5645782289114456, 0.609817990899545, 0.49159957997899895, 0.6509450472523626, 0.6059677983899195, 0.6060553027651383, 0.6840217010850542, 0.6686209310465523, 0.685946797339867, 0.652607630381519, 0.6577703885194259, 0.6703710185509275, 0.6515575778788939, 0.6843717185859293, 0.6781589079453972, 0.6917220861043052, 0.6951347567378369, 0.5292264613230662, 0.6792964648232411, 0.6594329716485824, 0.6913720686034301, 0.7048477423871193, 0.6885719285964298, 0.6836716835841792], 'final_state_dict_size_bytes': 4320, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.006090612754359839, 'batch_size': 48, 'epochs': 24, 'weight_decay': 4.923067128056138e-05, 'dropout': 0.04519712488936195, 'channel_multiplier': 6, 'kernel_size1': 51, 'stride1': 7, 'kernel_size2': 8, 'stride2': 6, 'gcn_hidden': 21, 'label_smoothing': 0.16351379290239976, 'grad_clip_norm': 4.996644125456917, 'use_amp': False, 'calibrate_batches': 13, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 992, 'model_storage_size_kb': 4.2625, 'model_size_validation': 'PASS'}
2025-10-13 11:16:15,356 - INFO - _models.training_function_executor - BO Objective: base=0.6837, size_penalty=0.0000, final=0.6837
2025-10-13 11:16:15,356 - INFO - _models.training_function_executor - Model: 992 parameters, 4.3KB (PASS 256KB limit)
2025-10-13 11:16:15,356 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 41.775s
2025-10-13 11:16:15,438 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6837
2025-10-13 11:16:15,439 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.082s
2025-10-13 11:16:15,439 - INFO - bo.run_bo - Recorded observation #9: hparams={'lr': 0.006090612754359839, 'batch_size': np.int64(48), 'epochs': np.int64(24), 'weight_decay': 4.923067128056138e-05, 'dropout': 0.04519712488936195, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(51), 'stride1': np.int64(7), 'kernel_size2': np.int64(8), 'stride2': np.int64(6), 'gcn_hidden': np.int64(21), 'label_smoothing': 0.16351379290239976, 'grad_clip_norm': 4.996644125456917, 'use_amp': np.False_, 'calibrate_batches': np.int64(13), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6837
2025-10-13 11:16:15,439 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'lr': 0.006090612754359839, 'batch_size': np.int64(48), 'epochs': np.int64(24), 'weight_decay': 4.923067128056138e-05, 'dropout': 0.04519712488936195, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(51), 'stride1': np.int64(7), 'kernel_size2': np.int64(8), 'stride2': np.int64(6), 'gcn_hidden': np.int64(21), 'label_smoothing': 0.16351379290239976, 'grad_clip_norm': 4.996644125456917, 'use_amp': np.False_, 'calibrate_batches': np.int64(13), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6837
2025-10-13 11:16:15,439 - INFO - bo.run_bo - üîçBO Trial 10: Using RF surrogate + Expected Improvement
2025-10-13 11:16:15,439 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:16:15,439 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 10 (NaN monitoring active)
2025-10-13 11:16:15,439 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:16:15,439 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:16:15,439 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0004915918908970642, 'batch_size': 32, 'epochs': 29, 'weight_decay': 2.9723854876156074e-05, 'dropout': 0.010872266201081972, 'channel_multiplier': 3, 'kernel_size1': 32, 'stride1': 5, 'kernel_size2': 41, 'stride2': 5, 'gcn_hidden': 4, 'label_smoothing': 0.11329409804105917, 'grad_clip_norm': 1.6875219625431206, 'use_amp': True, 'calibrate_batches': 62, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:16:15,440 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0004915918908970642, 'batch_size': 32, 'epochs': 29, 'weight_decay': 2.9723854876156074e-05, 'dropout': 0.010872266201081972, 'channel_multiplier': 3, 'kernel_size1': 32, 'stride1': 5, 'kernel_size2': 41, 'stride2': 5, 'gcn_hidden': 4, 'label_smoothing': 0.11329409804105917, 'grad_clip_norm': 1.6875219625431206, 'use_amp': True, 'calibrate_batches': 62, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:16:20,901 - INFO - _models.training_function_executor - Epoch 001/029 - train_loss: 1.5108 - val_loss: 1.4474 - val_acc: 0.4334
2025-10-13 11:16:23,572 - INFO - _models.training_function_executor - Epoch 002/029 - train_loss: 1.3721 - val_loss: 1.3572 - val_acc: 0.4929
2025-10-13 11:16:26,235 - INFO - _models.training_function_executor - Epoch 003/029 - train_loss: 1.3237 - val_loss: 1.3226 - val_acc: 0.5278
2025-10-13 11:16:28,944 - INFO - _models.training_function_executor - Epoch 004/029 - train_loss: 1.2985 - val_loss: 1.2753 - val_acc: 0.5525
2025-10-13 11:16:31,661 - INFO - _models.training_function_executor - Epoch 005/029 - train_loss: 1.2791 - val_loss: 1.2589 - val_acc: 0.5587
2025-10-13 11:16:34,331 - INFO - _models.training_function_executor - Epoch 006/029 - train_loss: 1.2643 - val_loss: 1.4955 - val_acc: 0.3801
2025-10-13 11:16:37,029 - INFO - _models.training_function_executor - Epoch 007/029 - train_loss: 1.2487 - val_loss: 1.2304 - val_acc: 0.5664
2025-10-13 11:16:39,721 - INFO - _models.training_function_executor - Epoch 008/029 - train_loss: 1.2378 - val_loss: 1.2162 - val_acc: 0.5656
2025-10-13 11:16:42,403 - INFO - _models.training_function_executor - Epoch 009/029 - train_loss: 1.2284 - val_loss: 1.2484 - val_acc: 0.5418
2025-10-13 11:16:45,068 - INFO - _models.training_function_executor - Epoch 010/029 - train_loss: 1.2199 - val_loss: 1.2030 - val_acc: 0.5857
2025-10-13 11:16:47,757 - INFO - _models.training_function_executor - Epoch 011/029 - train_loss: 1.2163 - val_loss: 1.2661 - val_acc: 0.5115
2025-10-13 11:16:50,399 - INFO - _models.training_function_executor - Epoch 012/029 - train_loss: 1.2112 - val_loss: 1.2070 - val_acc: 0.5825
2025-10-13 11:16:53,107 - INFO - _models.training_function_executor - Epoch 013/029 - train_loss: 1.2065 - val_loss: 1.1853 - val_acc: 0.5853
2025-10-13 11:16:55,781 - INFO - _models.training_function_executor - Epoch 014/029 - train_loss: 1.2007 - val_loss: 1.1835 - val_acc: 0.5910
2025-10-13 11:16:58,461 - INFO - _models.training_function_executor - Epoch 015/029 - train_loss: 1.2005 - val_loss: 1.1816 - val_acc: 0.5860
2025-10-13 11:17:01,194 - INFO - _models.training_function_executor - Epoch 016/029 - train_loss: 1.1966 - val_loss: 1.1798 - val_acc: 0.5734
2025-10-13 11:17:03,873 - INFO - _models.training_function_executor - Epoch 017/029 - train_loss: 1.1963 - val_loss: 1.1852 - val_acc: 0.5627
2025-10-13 11:17:06,561 - INFO - _models.training_function_executor - Epoch 018/029 - train_loss: 1.1947 - val_loss: 1.2351 - val_acc: 0.5410
2025-10-13 11:17:09,242 - INFO - _models.training_function_executor - Epoch 019/029 - train_loss: 1.1943 - val_loss: 1.1734 - val_acc: 0.5951
2025-10-13 11:17:11,920 - INFO - _models.training_function_executor - Epoch 020/029 - train_loss: 1.1942 - val_loss: 1.1715 - val_acc: 0.5987
2025-10-13 11:17:14,619 - INFO - _models.training_function_executor - Epoch 021/029 - train_loss: 1.1899 - val_loss: 1.2024 - val_acc: 0.5775
2025-10-13 11:17:17,286 - INFO - _models.training_function_executor - Epoch 022/029 - train_loss: 1.1915 - val_loss: 1.1845 - val_acc: 0.5855
2025-10-13 11:17:19,958 - INFO - _models.training_function_executor - Epoch 023/029 - train_loss: 1.1927 - val_loss: 1.1625 - val_acc: 0.5957
2025-10-13 11:17:22,672 - INFO - _models.training_function_executor - Epoch 024/029 - train_loss: 1.1903 - val_loss: 1.1704 - val_acc: 0.5969
2025-10-13 11:17:25,347 - INFO - _models.training_function_executor - Epoch 025/029 - train_loss: 1.1893 - val_loss: 1.1589 - val_acc: 0.5959
2025-10-13 11:17:28,043 - INFO - _models.training_function_executor - Epoch 026/029 - train_loss: 1.1898 - val_loss: 1.3131 - val_acc: 0.4809
2025-10-13 11:17:30,754 - INFO - _models.training_function_executor - Epoch 027/029 - train_loss: 1.1873 - val_loss: 1.1724 - val_acc: 0.5984
2025-10-13 11:17:33,444 - INFO - _models.training_function_executor - Epoch 028/029 - train_loss: 1.1872 - val_loss: 1.1798 - val_acc: 0.5838
2025-10-13 11:17:36,149 - INFO - _models.training_function_executor - Epoch 029/029 - train_loss: 1.1901 - val_loss: 1.1739 - val_acc: 0.5993
2025-10-13 11:17:37,257 - INFO - _models.training_function_executor - Model: 1,059 parameters, 4.6KB storage
2025-10-13 11:17:37,258 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.510759982563709, 1.3720994667861692, 1.3236787521551237, 1.298532191172404, 1.2790678381127079, 1.2643313167142751, 1.2486631284446035, 1.2377525805842846, 1.228421785341596, 1.2198760206982269, 1.216309371009589, 1.2111792989156027, 1.2064756796332476, 1.2007446961674941, 1.2004619567678823, 1.1965596805429977, 1.1962635661907284, 1.1946515152618773, 1.194296500129553, 1.1941582685923886, 1.1898969935502963, 1.1914829067053976, 1.1926964153807857, 1.1903113314936034, 1.1892889235292567, 1.189813191380833, 1.1872759383585139, 1.1872319621892922, 1.1901281396116792], 'val_losses': [1.4474042737070898, 1.3572103787353083, 1.3225538793626597, 1.2753020538748, 1.2588961425677103, 1.4954895591835982, 1.2304436017217693, 1.2162395161183763, 1.2483541474794648, 1.2030018295572487, 1.2660747108486177, 1.207042913733974, 1.1852972166163545, 1.1835375044952543, 1.1816180243039824, 1.1797709107440713, 1.1852162383760152, 1.2350754743695551, 1.1734177505465124, 1.1714619024675295, 1.2024149954381589, 1.1844659071516064, 1.16247135790904, 1.1703781980211434, 1.1588676905857336, 1.3130892814353166, 1.172436105816941, 1.1797591877183924, 1.173876933964725], 'val_acc': [0.43340917045852295, 0.49291214560728036, 0.527826391319566, 0.5525026251312566, 0.5587154357717886, 0.3801190059502975, 0.5664158207910396, 0.5656282814140707, 0.5418270913545677, 0.585666783339167, 0.5114630731536577, 0.5825166258312916, 0.585316765838292, 0.5910045502275114, 0.586016800840042, 0.5734161708085405, 0.5627406370318516, 0.5410395519775989, 0.5951172558627932, 0.5987049352467624, 0.5775288764438222, 0.5854917745887295, 0.5957297864893245, 0.5968673433671684, 0.595904795239762, 0.4809240462023101, 0.5984424221211061, 0.583829191459573, 0.5993174658732937], 'final_state_dict_size_bytes': 4444, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0004915918908970642, 'batch_size': 32, 'epochs': 29, 'weight_decay': 2.9723854876156074e-05, 'dropout': 0.010872266201081972, 'channel_multiplier': 3, 'kernel_size1': 32, 'stride1': 5, 'kernel_size2': 41, 'stride2': 5, 'gcn_hidden': 4, 'label_smoothing': 0.11329409804105917, 'grad_clip_norm': 1.6875219625431206, 'use_amp': True, 'calibrate_batches': 62, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1059, 'model_storage_size_kb': 4.550390625, 'model_size_validation': 'PASS'}
2025-10-13 11:17:37,258 - INFO - _models.training_function_executor - BO Objective: base=0.5993, size_penalty=0.0000, final=0.5993
2025-10-13 11:17:37,258 - INFO - _models.training_function_executor - Model: 1,059 parameters, 4.6KB (PASS 256KB limit)
2025-10-13 11:17:37,258 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 81.819s
2025-10-13 11:17:37,341 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5993
2025-10-13 11:17:37,341 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.083s
2025-10-13 11:17:37,341 - INFO - bo.run_bo - Recorded observation #10: hparams={'lr': 0.0004915918908970642, 'batch_size': np.int64(32), 'epochs': np.int64(29), 'weight_decay': 2.9723854876156074e-05, 'dropout': 0.010872266201081972, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(32), 'stride1': np.int64(5), 'kernel_size2': np.int64(41), 'stride2': np.int64(5), 'gcn_hidden': np.int64(4), 'label_smoothing': 0.11329409804105917, 'grad_clip_norm': 1.6875219625431206, 'use_amp': np.True_, 'calibrate_batches': np.int64(62), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.5993
2025-10-13 11:17:37,342 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'lr': 0.0004915918908970642, 'batch_size': np.int64(32), 'epochs': np.int64(29), 'weight_decay': 2.9723854876156074e-05, 'dropout': 0.010872266201081972, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(32), 'stride1': np.int64(5), 'kernel_size2': np.int64(41), 'stride2': np.int64(5), 'gcn_hidden': np.int64(4), 'label_smoothing': 0.11329409804105917, 'grad_clip_norm': 1.6875219625431206, 'use_amp': np.True_, 'calibrate_batches': np.int64(62), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.5993
2025-10-13 11:17:37,342 - INFO - bo.run_bo - üîçBO Trial 11: Using RF surrogate + Expected Improvement
2025-10-13 11:17:37,342 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:17:37,342 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 11 (NaN monitoring active)
2025-10-13 11:17:37,342 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:17:37,342 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:17:37,342 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.006340202304755549, 'batch_size': 96, 'epochs': 11, 'weight_decay': 1.8840667852971345e-06, 'dropout': 0.07724429894493788, 'channel_multiplier': 4, 'kernel_size1': 48, 'stride1': 5, 'kernel_size2': 27, 'stride2': 5, 'gcn_hidden': 18, 'label_smoothing': 0.07392906077863091, 'grad_clip_norm': 3.0260727818390016, 'use_amp': False, 'calibrate_batches': 22, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:17:37,343 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.006340202304755549, 'batch_size': 96, 'epochs': 11, 'weight_decay': 1.8840667852971345e-06, 'dropout': 0.07724429894493788, 'channel_multiplier': 4, 'kernel_size1': 48, 'stride1': 5, 'kernel_size2': 27, 'stride2': 5, 'gcn_hidden': 18, 'label_smoothing': 0.07392906077863091, 'grad_clip_norm': 3.0260727818390016, 'use_amp': False, 'calibrate_batches': 22, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:17:41,686 - INFO - _models.training_function_executor - Epoch 001/011 - train_loss: 1.2104 - val_loss: 1.1620 - val_acc: 0.5739
2025-10-13 11:17:43,158 - INFO - _models.training_function_executor - Epoch 002/011 - train_loss: 1.1213 - val_loss: 1.1389 - val_acc: 0.6032
2025-10-13 11:17:44,666 - INFO - _models.training_function_executor - Epoch 003/011 - train_loss: 1.1001 - val_loss: 1.1019 - val_acc: 0.6236
2025-10-13 11:17:46,146 - INFO - _models.training_function_executor - Epoch 004/011 - train_loss: 1.0830 - val_loss: 1.1500 - val_acc: 0.5883
2025-10-13 11:17:47,642 - INFO - _models.training_function_executor - Epoch 005/011 - train_loss: 1.0700 - val_loss: 1.0541 - val_acc: 0.6274
2025-10-13 11:17:49,155 - INFO - _models.training_function_executor - Epoch 006/011 - train_loss: 1.0605 - val_loss: 1.0620 - val_acc: 0.6402
2025-10-13 11:17:50,643 - INFO - _models.training_function_executor - Epoch 007/011 - train_loss: 1.0495 - val_loss: 1.0572 - val_acc: 0.6459
2025-10-13 11:17:52,147 - INFO - _models.training_function_executor - Epoch 008/011 - train_loss: 1.0409 - val_loss: 1.0525 - val_acc: 0.6192
2025-10-13 11:17:53,626 - INFO - _models.training_function_executor - Epoch 009/011 - train_loss: 1.0344 - val_loss: 1.0511 - val_acc: 0.6325
2025-10-13 11:17:55,137 - INFO - _models.training_function_executor - Epoch 010/011 - train_loss: 1.0326 - val_loss: 1.0151 - val_acc: 0.6590
2025-10-13 11:17:56,663 - INFO - _models.training_function_executor - Epoch 011/011 - train_loss: 1.0273 - val_loss: 1.1160 - val_acc: 0.6261
2025-10-13 11:17:57,762 - INFO - _models.training_function_executor - Model: 1,235 parameters, 5.3KB storage
2025-10-13 11:17:57,762 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.210422037613321, 1.1212547824730772, 1.1000722615419254, 1.0829639231820685, 1.0700152062184751, 1.0605229836349768, 1.049455262185979, 1.0409082941212853, 1.0344075661336454, 1.03259829670389, 1.0272519720322526], 'val_losses': [1.161984442704868, 1.1389250547517877, 1.1018658388649871, 1.1499615168713337, 1.054068668889215, 1.061979827698937, 1.057241084027382, 1.052470899020453, 1.0511237785955556, 1.0151149985003314, 1.1159734104661871], 'val_acc': [0.5738536926846343, 0.6031676583829192, 0.6236436821841093, 0.5882919145957298, 0.6274063703185159, 0.640182009100455, 0.6458697934896744, 0.6191809590479525, 0.632481624081204, 0.6589954497724886, 0.6260938046902345], 'final_state_dict_size_bytes': 5196, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.006340202304755549, 'batch_size': 96, 'epochs': 11, 'weight_decay': 1.8840667852971345e-06, 'dropout': 0.07724429894493788, 'channel_multiplier': 4, 'kernel_size1': 48, 'stride1': 5, 'kernel_size2': 27, 'stride2': 5, 'gcn_hidden': 18, 'label_smoothing': 0.07392906077863091, 'grad_clip_norm': 3.0260727818390016, 'use_amp': False, 'calibrate_batches': 22, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1235, 'model_storage_size_kb': 5.306640625, 'model_size_validation': 'PASS'}
2025-10-13 11:17:57,762 - INFO - _models.training_function_executor - BO Objective: base=0.6261, size_penalty=0.0000, final=0.6261
2025-10-13 11:17:57,762 - INFO - _models.training_function_executor - Model: 1,235 parameters, 5.3KB (PASS 256KB limit)
2025-10-13 11:17:57,762 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 20.421s
2025-10-13 11:17:57,848 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6261
2025-10-13 11:17:57,848 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.085s
2025-10-13 11:17:57,848 - INFO - bo.run_bo - Recorded observation #11: hparams={'lr': 0.006340202304755549, 'batch_size': np.int64(96), 'epochs': np.int64(11), 'weight_decay': 1.8840667852971345e-06, 'dropout': 0.07724429894493788, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(48), 'stride1': np.int64(5), 'kernel_size2': np.int64(27), 'stride2': np.int64(5), 'gcn_hidden': np.int64(18), 'label_smoothing': 0.07392906077863091, 'grad_clip_norm': 3.0260727818390016, 'use_amp': np.False_, 'calibrate_batches': np.int64(22), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.6261
2025-10-13 11:17:57,848 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 11: {'lr': 0.006340202304755549, 'batch_size': np.int64(96), 'epochs': np.int64(11), 'weight_decay': 1.8840667852971345e-06, 'dropout': 0.07724429894493788, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(48), 'stride1': np.int64(5), 'kernel_size2': np.int64(27), 'stride2': np.int64(5), 'gcn_hidden': np.int64(18), 'label_smoothing': 0.07392906077863091, 'grad_clip_norm': 3.0260727818390016, 'use_amp': np.False_, 'calibrate_batches': np.int64(22), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.6261
2025-10-13 11:17:57,848 - INFO - bo.run_bo - üîçBO Trial 12: Using RF surrogate + Expected Improvement
2025-10-13 11:17:57,848 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:17:57,849 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 12 (NaN monitoring active)
2025-10-13 11:17:57,849 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:17:57,849 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:17:57,849 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003644299122857688, 'batch_size': 128, 'epochs': 9, 'weight_decay': 2.841068446455399e-06, 'dropout': 0.08010524629485054, 'channel_multiplier': 5, 'kernel_size1': 100, 'stride1': 5, 'kernel_size2': 35, 'stride2': 5, 'gcn_hidden': 13, 'label_smoothing': 0.17837138965665222, 'grad_clip_norm': 1.5145488649391228, 'use_amp': False, 'calibrate_batches': 44, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:17:57,850 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003644299122857688, 'batch_size': 128, 'epochs': 9, 'weight_decay': 2.841068446455399e-06, 'dropout': 0.08010524629485054, 'channel_multiplier': 5, 'kernel_size1': 100, 'stride1': 5, 'kernel_size2': 35, 'stride2': 5, 'gcn_hidden': 13, 'label_smoothing': 0.17837138965665222, 'grad_clip_norm': 1.5145488649391228, 'use_amp': False, 'calibrate_batches': 44, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:18:02,493 - INFO - _models.training_function_executor - Epoch 001/009 - train_loss: 1.3794 - val_loss: 1.2959 - val_acc: 0.5482
2025-10-13 11:18:04,298 - INFO - _models.training_function_executor - Epoch 002/009 - train_loss: 1.2665 - val_loss: 1.2482 - val_acc: 0.5974
2025-10-13 11:18:06,105 - INFO - _models.training_function_executor - Epoch 003/009 - train_loss: 1.2447 - val_loss: 1.2732 - val_acc: 0.5578
2025-10-13 11:18:07,908 - INFO - _models.training_function_executor - Epoch 004/009 - train_loss: 1.2277 - val_loss: 1.2371 - val_acc: 0.6062
2025-10-13 11:18:09,707 - INFO - _models.training_function_executor - Epoch 005/009 - train_loss: 1.2163 - val_loss: 1.1976 - val_acc: 0.6278
2025-10-13 11:18:11,515 - INFO - _models.training_function_executor - Epoch 006/009 - train_loss: 1.2064 - val_loss: 1.2973 - val_acc: 0.5428
2025-10-13 11:18:13,324 - INFO - _models.training_function_executor - Epoch 007/009 - train_loss: 1.2006 - val_loss: 1.2869 - val_acc: 0.5319
2025-10-13 11:18:15,126 - INFO - _models.training_function_executor - Epoch 008/009 - train_loss: 1.1965 - val_loss: 1.1872 - val_acc: 0.6410
2025-10-13 11:18:16,925 - INFO - _models.training_function_executor - Epoch 009/009 - train_loss: 1.1904 - val_loss: 1.2981 - val_acc: 0.5374
2025-10-13 11:18:18,022 - INFO - _models.training_function_executor - Model: 1,919 parameters, 8.2KB storage
2025-10-13 11:18:18,022 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3793691478077665, 1.2664594450404187, 1.244707190702543, 1.227736946666078, 1.2162767619906416, 1.2064039759757763, 1.2006285134670323, 1.1964529711005987, 1.190350461181411], 'val_losses': [1.2958838614209114, 1.248237527414014, 1.2731942754130618, 1.2370791850408809, 1.1975767888261757, 1.2973318822658433, 1.2868965838729063, 1.1872449731092416, 1.2980540895278445], 'val_acc': [0.5482149107455373, 0.597392369618481, 0.557840392019601, 0.6062303115155758, 0.6278438921946097, 0.5427896394819741, 0.531851592579629, 0.6409695484774238, 0.5373643682184109], 'final_state_dict_size_bytes': 7980, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003644299122857688, 'batch_size': 128, 'epochs': 9, 'weight_decay': 2.841068446455399e-06, 'dropout': 0.08010524629485054, 'channel_multiplier': 5, 'kernel_size1': 100, 'stride1': 5, 'kernel_size2': 35, 'stride2': 5, 'gcn_hidden': 13, 'label_smoothing': 0.17837138965665222, 'grad_clip_norm': 1.5145488649391228, 'use_amp': False, 'calibrate_batches': 44, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1919, 'model_storage_size_kb': 8.245703125, 'model_size_validation': 'PASS'}
2025-10-13 11:18:18,022 - INFO - _models.training_function_executor - BO Objective: base=0.5374, size_penalty=0.0000, final=0.5374
2025-10-13 11:18:18,022 - INFO - _models.training_function_executor - Model: 1,919 parameters, 8.2KB (PASS 256KB limit)
2025-10-13 11:18:18,022 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 20.174s
2025-10-13 11:18:18,110 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5374
2025-10-13 11:18:18,110 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.086s
2025-10-13 11:18:18,110 - INFO - bo.run_bo - Recorded observation #12: hparams={'lr': 0.003644299122857688, 'batch_size': np.int64(128), 'epochs': np.int64(9), 'weight_decay': 2.841068446455399e-06, 'dropout': 0.08010524629485054, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(100), 'stride1': np.int64(5), 'kernel_size2': np.int64(35), 'stride2': np.int64(5), 'gcn_hidden': np.int64(13), 'label_smoothing': 0.17837138965665222, 'grad_clip_norm': 1.5145488649391228, 'use_amp': np.False_, 'calibrate_batches': np.int64(44), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.5374
2025-10-13 11:18:18,110 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 12: {'lr': 0.003644299122857688, 'batch_size': np.int64(128), 'epochs': np.int64(9), 'weight_decay': 2.841068446455399e-06, 'dropout': 0.08010524629485054, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(100), 'stride1': np.int64(5), 'kernel_size2': np.int64(35), 'stride2': np.int64(5), 'gcn_hidden': np.int64(13), 'label_smoothing': 0.17837138965665222, 'grad_clip_norm': 1.5145488649391228, 'use_amp': np.False_, 'calibrate_batches': np.int64(44), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.5374
2025-10-13 11:18:18,110 - INFO - bo.run_bo - üîçBO Trial 13: Using RF surrogate + Expected Improvement
2025-10-13 11:18:18,110 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:18:18,110 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 13 (NaN monitoring active)
2025-10-13 11:18:18,110 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:18:18,110 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:18:18,110 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.008645790735057397, 'batch_size': 64, 'epochs': 6, 'weight_decay': 1.7200005011255186e-05, 'dropout': 0.32086870630983355, 'channel_multiplier': 3, 'kernel_size1': 35, 'stride1': 10, 'kernel_size2': 62, 'stride2': 7, 'gcn_hidden': 19, 'label_smoothing': 7.590457355390879e-05, 'grad_clip_norm': 4.512683165942999, 'use_amp': False, 'calibrate_batches': 28, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:18:18,111 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.008645790735057397, 'batch_size': 64, 'epochs': 6, 'weight_decay': 1.7200005011255186e-05, 'dropout': 0.32086870630983355, 'channel_multiplier': 3, 'kernel_size1': 35, 'stride1': 10, 'kernel_size2': 62, 'stride2': 7, 'gcn_hidden': 19, 'label_smoothing': 7.590457355390879e-05, 'grad_clip_norm': 4.512683165942999, 'use_amp': False, 'calibrate_batches': 28, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:18:22,428 - INFO - _models.training_function_executor - Epoch 001/006 - train_loss: 1.2385 - val_loss: 1.1404 - val_acc: 0.5352
2025-10-13 11:18:23,908 - INFO - _models.training_function_executor - Epoch 002/006 - train_loss: 1.0900 - val_loss: 1.1505 - val_acc: 0.5225
2025-10-13 11:18:25,371 - INFO - _models.training_function_executor - Epoch 003/006 - train_loss: 1.0630 - val_loss: 1.0407 - val_acc: 0.5753
2025-10-13 11:18:26,846 - INFO - _models.training_function_executor - Epoch 004/006 - train_loss: 1.0500 - val_loss: 1.2099 - val_acc: 0.4931
2025-10-13 11:18:28,327 - INFO - _models.training_function_executor - Epoch 005/006 - train_loss: 1.0235 - val_loss: 1.0161 - val_acc: 0.6150
2025-10-13 11:18:29,795 - INFO - _models.training_function_executor - Epoch 006/006 - train_loss: 0.9944 - val_loss: 1.0073 - val_acc: 0.5834
2025-10-13 11:18:30,987 - INFO - _models.training_function_executor - Model: 55 parameters, 0.1KB storage
2025-10-13 11:18:30,987 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2384508719259015, 1.090034527715203, 1.0630388412393805, 1.0499933263326717, 1.0235113740009072, 0.9944173578703617], 'val_losses': [1.1403591467193428, 1.1504610473558041, 1.0407006539871195, 1.209864946983893, 1.0160926478619254, 1.0073060539580743], 'val_acc': [0.5351767588379419, 0.5224886244312216, 0.5752537626881344, 0.4930871543577179, 0.6149807490374519, 0.5833916695834792], 'final_state_dict_size_bytes': 1690, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.008645790735057397, 'batch_size': 64, 'epochs': 6, 'weight_decay': 1.7200005011255186e-05, 'dropout': 0.32086870630983355, 'channel_multiplier': 3, 'kernel_size1': 35, 'stride1': 10, 'kernel_size2': 62, 'stride2': 7, 'gcn_hidden': 19, 'label_smoothing': 7.590457355390879e-05, 'grad_clip_norm': 4.512683165942999, 'use_amp': False, 'calibrate_batches': 28, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 55, 'model_storage_size_kb': 0.05908203125000001, 'model_size_validation': 'PASS'}
2025-10-13 11:18:30,987 - INFO - _models.training_function_executor - BO Objective: base=0.5834, size_penalty=0.0000, final=0.5834
2025-10-13 11:18:30,987 - INFO - _models.training_function_executor - Model: 55 parameters, 0.1KB (PASS 256KB limit)
2025-10-13 11:18:30,987 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 12.877s
2025-10-13 11:18:31,076 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5834
2025-10-13 11:18:31,076 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.089s
2025-10-13 11:18:31,077 - INFO - bo.run_bo - Recorded observation #13: hparams={'lr': 0.008645790735057397, 'batch_size': np.int64(64), 'epochs': np.int64(6), 'weight_decay': 1.7200005011255186e-05, 'dropout': 0.32086870630983355, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(35), 'stride1': np.int64(10), 'kernel_size2': np.int64(62), 'stride2': np.int64(7), 'gcn_hidden': np.int64(19), 'label_smoothing': 7.590457355390879e-05, 'grad_clip_norm': 4.512683165942999, 'use_amp': np.False_, 'calibrate_batches': np.int64(28), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.5834
2025-10-13 11:18:31,077 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 13: {'lr': 0.008645790735057397, 'batch_size': np.int64(64), 'epochs': np.int64(6), 'weight_decay': 1.7200005011255186e-05, 'dropout': 0.32086870630983355, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(35), 'stride1': np.int64(10), 'kernel_size2': np.int64(62), 'stride2': np.int64(7), 'gcn_hidden': np.int64(19), 'label_smoothing': 7.590457355390879e-05, 'grad_clip_norm': 4.512683165942999, 'use_amp': np.False_, 'calibrate_batches': np.int64(28), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.5834
2025-10-13 11:18:31,077 - INFO - bo.run_bo - üîçBO Trial 14: Using RF surrogate + Expected Improvement
2025-10-13 11:18:31,077 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:18:31,077 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 14 (NaN monitoring active)
2025-10-13 11:18:31,077 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:18:31,077 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:18:31,077 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.3453395317204254e-05, 'batch_size': 48, 'epochs': 20, 'weight_decay': 2.132633396308578e-06, 'dropout': 0.16611635906219505, 'channel_multiplier': 6, 'kernel_size1': 45, 'stride1': 11, 'kernel_size2': 22, 'stride2': 2, 'gcn_hidden': 16, 'label_smoothing': 0.13273695300815544, 'grad_clip_norm': 4.123940945033103, 'use_amp': True, 'calibrate_batches': 127, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:18:31,078 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.3453395317204254e-05, 'batch_size': 48, 'epochs': 20, 'weight_decay': 2.132633396308578e-06, 'dropout': 0.16611635906219505, 'channel_multiplier': 6, 'kernel_size1': 45, 'stride1': 11, 'kernel_size2': 22, 'stride2': 2, 'gcn_hidden': 16, 'label_smoothing': 0.13273695300815544, 'grad_clip_norm': 4.123940945033103, 'use_amp': True, 'calibrate_batches': 127, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:18:35,722 - INFO - _models.training_function_executor - Epoch 001/020 - train_loss: 1.6038 - val_loss: 1.5951 - val_acc: 0.2890
2025-10-13 11:18:37,577 - INFO - _models.training_function_executor - Epoch 002/020 - train_loss: 1.5888 - val_loss: 1.5824 - val_acc: 0.3137
2025-10-13 11:18:39,420 - INFO - _models.training_function_executor - Epoch 003/020 - train_loss: 1.5771 - val_loss: 1.5713 - val_acc: 0.3137
2025-10-13 11:18:41,277 - INFO - _models.training_function_executor - Epoch 004/020 - train_loss: 1.5671 - val_loss: 1.5621 - val_acc: 0.3137
2025-10-13 11:18:43,130 - INFO - _models.training_function_executor - Epoch 005/020 - train_loss: 1.5584 - val_loss: 1.5543 - val_acc: 0.3139
2025-10-13 11:18:44,992 - INFO - _models.training_function_executor - Epoch 006/020 - train_loss: 1.5507 - val_loss: 1.5461 - val_acc: 0.3138
2025-10-13 11:18:46,820 - INFO - _models.training_function_executor - Epoch 007/020 - train_loss: 1.5434 - val_loss: 1.5428 - val_acc: 0.3139
2025-10-13 11:18:48,679 - INFO - _models.training_function_executor - Epoch 008/020 - train_loss: 1.5365 - val_loss: 1.5369 - val_acc: 0.3173
2025-10-13 11:18:50,528 - INFO - _models.training_function_executor - Epoch 009/020 - train_loss: 1.5299 - val_loss: 1.5330 - val_acc: 0.3240
2025-10-13 11:18:52,360 - INFO - _models.training_function_executor - Epoch 010/020 - train_loss: 1.5224 - val_loss: 1.5232 - val_acc: 0.3449
2025-10-13 11:18:54,206 - INFO - _models.training_function_executor - Epoch 011/020 - train_loss: 1.5154 - val_loss: 1.5198 - val_acc: 0.3448
2025-10-13 11:18:56,036 - INFO - _models.training_function_executor - Epoch 012/020 - train_loss: 1.5079 - val_loss: 1.5107 - val_acc: 0.3487
2025-10-13 11:18:57,901 - INFO - _models.training_function_executor - Epoch 013/020 - train_loss: 1.5013 - val_loss: 1.5071 - val_acc: 0.3834
2025-10-13 11:18:59,760 - INFO - _models.training_function_executor - Epoch 014/020 - train_loss: 1.4941 - val_loss: 1.5013 - val_acc: 0.3870
2025-10-13 11:19:01,611 - INFO - _models.training_function_executor - Epoch 015/020 - train_loss: 1.4873 - val_loss: 1.5029 - val_acc: 0.3855
2025-10-13 11:19:03,456 - INFO - _models.training_function_executor - Epoch 016/020 - train_loss: 1.4801 - val_loss: 1.4965 - val_acc: 0.3906
2025-10-13 11:19:05,304 - INFO - _models.training_function_executor - Epoch 017/020 - train_loss: 1.4734 - val_loss: 1.4931 - val_acc: 0.3905
2025-10-13 11:19:07,145 - INFO - _models.training_function_executor - Epoch 018/020 - train_loss: 1.4671 - val_loss: 1.4974 - val_acc: 0.3781
2025-10-13 11:19:09,034 - INFO - _models.training_function_executor - Epoch 019/020 - train_loss: 1.4600 - val_loss: 1.4896 - val_acc: 0.3899
2025-10-13 11:19:10,896 - INFO - _models.training_function_executor - Epoch 020/020 - train_loss: 1.4541 - val_loss: 1.4704 - val_acc: 0.4354
2025-10-13 11:19:11,981 - INFO - _models.training_function_executor - Model: 1,395 parameters, 6.0KB storage
2025-10-13 11:19:11,981 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6037959785865328, 1.5888448250973854, 1.5770568344031426, 1.567096697687477, 1.5584492233194251, 1.550656675499638, 1.5434212794368987, 1.5364714248805436, 1.5298575010590092, 1.5223720106245715, 1.5153895659091217, 1.5079264382528266, 1.5012981469371665, 1.4940815387925444, 1.4873280211850235, 1.4801231578049812, 1.4734061365157605, 1.4670644524967833, 1.4600467603858385, 1.4541065466750283], 'val_losses': [1.5951208296796848, 1.5824236007766537, 1.5712672793702476, 1.5621175158887548, 1.5543128317120947, 1.5461285125971425, 1.5427787745378632, 1.5369011332699165, 1.5329920073092964, 1.5231753351140114, 1.5198485069772267, 1.5107433498010046, 1.507090093749864, 1.5013412350243023, 1.5028843431152328, 1.496522641323812, 1.4930685032569824, 1.4974412667738795, 1.4895704406351737, 1.4703728690779956], 'val_acc': [0.2890269513475674, 0.31370318515925794, 0.31370318515925794, 0.31370318515925794, 0.31387819390969546, 0.3137906895344767, 0.31387819390969546, 0.31729086454322714, 0.32402870143507173, 0.34485474273713684, 0.3447672383619181, 0.3487049352467623, 0.3833566678333917, 0.38703185159257963, 0.3855442772138607, 0.39061953097654883, 0.3905320266013301, 0.378106405320266, 0.38991949597479875, 0.43542177108855445], 'final_state_dict_size_bytes': 5932, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.3453395317204254e-05, 'batch_size': 48, 'epochs': 20, 'weight_decay': 2.132633396308578e-06, 'dropout': 0.16611635906219505, 'channel_multiplier': 6, 'kernel_size1': 45, 'stride1': 11, 'kernel_size2': 22, 'stride2': 2, 'gcn_hidden': 16, 'label_smoothing': 0.13273695300815544, 'grad_clip_norm': 4.123940945033103, 'use_amp': True, 'calibrate_batches': 127, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1395, 'model_storage_size_kb': 5.994140625000001, 'model_size_validation': 'PASS'}
2025-10-13 11:19:11,981 - INFO - _models.training_function_executor - BO Objective: base=0.4354, size_penalty=0.0000, final=0.4354
2025-10-13 11:19:11,981 - INFO - _models.training_function_executor - Model: 1,395 parameters, 6.0KB (PASS 256KB limit)
2025-10-13 11:19:11,981 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 40.904s
2025-10-13 11:19:12,202 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.4354
2025-10-13 11:19:12,202 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.221s
2025-10-13 11:19:12,202 - INFO - bo.run_bo - Recorded observation #14: hparams={'lr': 1.3453395317204254e-05, 'batch_size': np.int64(48), 'epochs': np.int64(20), 'weight_decay': 2.132633396308578e-06, 'dropout': 0.16611635906219505, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(45), 'stride1': np.int64(11), 'kernel_size2': np.int64(22), 'stride2': np.int64(2), 'gcn_hidden': np.int64(16), 'label_smoothing': 0.13273695300815544, 'grad_clip_norm': 4.123940945033103, 'use_amp': np.True_, 'calibrate_batches': np.int64(127), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.4354
2025-10-13 11:19:12,202 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 14: {'lr': 1.3453395317204254e-05, 'batch_size': np.int64(48), 'epochs': np.int64(20), 'weight_decay': 2.132633396308578e-06, 'dropout': 0.16611635906219505, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(45), 'stride1': np.int64(11), 'kernel_size2': np.int64(22), 'stride2': np.int64(2), 'gcn_hidden': np.int64(16), 'label_smoothing': 0.13273695300815544, 'grad_clip_norm': 4.123940945033103, 'use_amp': np.True_, 'calibrate_batches': np.int64(127), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.4354
2025-10-13 11:19:12,203 - INFO - bo.run_bo - üîçBO Trial 15: Using RF surrogate + Expected Improvement
2025-10-13 11:19:12,203 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:19:12,203 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 15 (NaN monitoring active)
2025-10-13 11:19:12,203 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:19:12,203 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:19:12,203 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009949379806566057, 'batch_size': 96, 'epochs': 54, 'weight_decay': 4.168908010234268e-05, 'dropout': 0.06270159719557583, 'channel_multiplier': 2, 'kernel_size1': 39, 'stride1': 7, 'kernel_size2': 11, 'stride2': 2, 'gcn_hidden': 10, 'label_smoothing': 0.04873321439793815, 'grad_clip_norm': 3.6166022735912913, 'use_amp': True, 'calibrate_batches': 9, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:19:12,204 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009949379806566057, 'batch_size': 96, 'epochs': 54, 'weight_decay': 4.168908010234268e-05, 'dropout': 0.06270159719557583, 'channel_multiplier': 2, 'kernel_size1': 39, 'stride1': 7, 'kernel_size2': 11, 'stride2': 2, 'gcn_hidden': 10, 'label_smoothing': 0.04873321439793815, 'grad_clip_norm': 3.6166022735912913, 'use_amp': True, 'calibrate_batches': 9, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:19:16,560 - INFO - _models.training_function_executor - Epoch 001/054 - train_loss: 1.4232 - val_loss: 1.4060 - val_acc: 0.4400
2025-10-13 11:19:18,054 - INFO - _models.training_function_executor - Epoch 002/054 - train_loss: 1.3930 - val_loss: 1.3975 - val_acc: 0.4405
2025-10-13 11:19:19,544 - INFO - _models.training_function_executor - Epoch 003/054 - train_loss: 1.3396 - val_loss: 1.2216 - val_acc: 0.5113
2025-10-13 11:19:21,054 - INFO - _models.training_function_executor - Epoch 004/054 - train_loss: 1.1672 - val_loss: 1.1603 - val_acc: 0.5512
2025-10-13 11:19:22,539 - INFO - _models.training_function_executor - Epoch 005/054 - train_loss: 1.1459 - val_loss: 1.1723 - val_acc: 0.5424
2025-10-13 11:19:24,065 - INFO - _models.training_function_executor - Epoch 006/054 - train_loss: 1.1379 - val_loss: 1.2116 - val_acc: 0.5537
2025-10-13 11:19:25,590 - INFO - _models.training_function_executor - Epoch 007/054 - train_loss: 1.1262 - val_loss: 1.1511 - val_acc: 0.5702
2025-10-13 11:19:27,091 - INFO - _models.training_function_executor - Epoch 008/054 - train_loss: 1.1138 - val_loss: 1.1999 - val_acc: 0.5199
2025-10-13 11:19:28,616 - INFO - _models.training_function_executor - Epoch 009/054 - train_loss: 1.1093 - val_loss: 1.2159 - val_acc: 0.5079
2025-10-13 11:19:30,122 - INFO - _models.training_function_executor - Epoch 010/054 - train_loss: 1.0999 - val_loss: 1.0882 - val_acc: 0.5920
2025-10-13 11:19:31,634 - INFO - _models.training_function_executor - Epoch 011/054 - train_loss: 1.0893 - val_loss: 1.1505 - val_acc: 0.5984
2025-10-13 11:19:33,139 - INFO - _models.training_function_executor - Epoch 012/054 - train_loss: 1.0780 - val_loss: 1.0977 - val_acc: 0.6050
2025-10-13 11:19:34,663 - INFO - _models.training_function_executor - Epoch 013/054 - train_loss: 1.0623 - val_loss: 1.1657 - val_acc: 0.5609
2025-10-13 11:19:36,172 - INFO - _models.training_function_executor - Epoch 014/054 - train_loss: 1.0588 - val_loss: 1.0847 - val_acc: 0.5947
2025-10-13 11:19:37,674 - INFO - _models.training_function_executor - Epoch 015/054 - train_loss: 1.0452 - val_loss: 1.0824 - val_acc: 0.6007
2025-10-13 11:19:39,199 - INFO - _models.training_function_executor - Epoch 016/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:40,715 - INFO - _models.training_function_executor - Epoch 017/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:42,222 - INFO - _models.training_function_executor - Epoch 018/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:43,745 - INFO - _models.training_function_executor - Epoch 019/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:45,265 - INFO - _models.training_function_executor - Epoch 020/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:46,789 - INFO - _models.training_function_executor - Epoch 021/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:48,302 - INFO - _models.training_function_executor - Epoch 022/054 - train_loss: 1.0097 - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:49,826 - INFO - _models.training_function_executor - Epoch 023/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:51,323 - INFO - _models.training_function_executor - Epoch 024/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:52,842 - INFO - _models.training_function_executor - Epoch 025/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:54,397 - INFO - _models.training_function_executor - Epoch 026/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:55,925 - INFO - _models.training_function_executor - Epoch 027/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:57,457 - INFO - _models.training_function_executor - Epoch 028/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:19:58,978 - INFO - _models.training_function_executor - Epoch 029/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:00,484 - INFO - _models.training_function_executor - Epoch 030/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:02,009 - INFO - _models.training_function_executor - Epoch 031/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:03,528 - INFO - _models.training_function_executor - Epoch 032/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:05,062 - INFO - _models.training_function_executor - Epoch 033/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:06,612 - INFO - _models.training_function_executor - Epoch 034/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:08,122 - INFO - _models.training_function_executor - Epoch 035/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:09,658 - INFO - _models.training_function_executor - Epoch 036/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:11,166 - INFO - _models.training_function_executor - Epoch 037/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:12,687 - INFO - _models.training_function_executor - Epoch 038/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:14,260 - INFO - _models.training_function_executor - Epoch 039/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:15,773 - INFO - _models.training_function_executor - Epoch 040/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:17,316 - INFO - _models.training_function_executor - Epoch 041/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:18,842 - INFO - _models.training_function_executor - Epoch 042/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:20,357 - INFO - _models.training_function_executor - Epoch 043/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:21,865 - INFO - _models.training_function_executor - Epoch 044/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:23,377 - INFO - _models.training_function_executor - Epoch 045/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:24,927 - INFO - _models.training_function_executor - Epoch 046/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:26,468 - INFO - _models.training_function_executor - Epoch 047/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:27,999 - INFO - _models.training_function_executor - Epoch 048/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:29,515 - INFO - _models.training_function_executor - Epoch 049/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:31,003 - INFO - _models.training_function_executor - Epoch 050/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:32,530 - INFO - _models.training_function_executor - Epoch 051/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:34,010 - INFO - _models.training_function_executor - Epoch 052/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:35,528 - INFO - _models.training_function_executor - Epoch 053/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:37,020 - INFO - _models.training_function_executor - Epoch 054/054 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:20:38,128 - INFO - _models.training_function_executor - Model: 533 parameters, 2.3KB storage
2025-10-13 11:20:38,128 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4232442953972955, 1.3929623515613436, 1.3395757199919303, 1.1671999435471536, 1.1458877227420694, 1.1378731022441892, 1.126155550679336, 1.1137631617103125, 1.1093009049382543, 1.0998774079705687, 1.0893119712955768, 1.0780164793858713, 1.062285952835931, 1.0587903907510172, 1.0452207910626512, nan, nan, nan, nan, nan, nan, 1.0097075190041755, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.4059941756545893, 1.397517438989692, 1.2215553259657612, 1.1602791676289308, 1.1723437886743808, 1.2116355134925936, 1.1510750652819945, 1.1999029294151837, 1.2159254694469, 1.088246520349184, 1.1504897061535893, 1.0977244630409029, 1.1657337590368804, 1.08469566970928, 1.0823557540007642, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.43997199859992997, 0.44049702485124254, 0.5112880644032202, 0.5511900595029752, 0.5424396219810991, 0.5537276863843192, 0.5701785089254463, 0.5198634931746587, 0.5078753937696885, 0.5919670983549178, 0.5983549177458873, 0.6050052502625132, 0.5609030451522576, 0.5946797339866994, 0.6007175358767939, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'final_state_dict_size_bytes': 2292, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009949379806566057, 'batch_size': 96, 'epochs': 54, 'weight_decay': 4.168908010234268e-05, 'dropout': 0.06270159719557583, 'channel_multiplier': 2, 'kernel_size1': 39, 'stride1': 7, 'kernel_size2': 11, 'stride2': 2, 'gcn_hidden': 10, 'label_smoothing': 0.04873321439793815, 'grad_clip_norm': 3.6166022735912913, 'use_amp': True, 'calibrate_batches': 9, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 533, 'model_storage_size_kb': 2.2902343750000003, 'model_size_validation': 'PASS'}
2025-10-13 11:20:38,128 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-13 11:20:38,128 - INFO - _models.training_function_executor - Model: 533 parameters, 2.3KB (PASS 256KB limit)
2025-10-13 11:20:38,128 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 85.925s
2025-10-13 11:20:38,219 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-13 11:20:38,219 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.090s
2025-10-13 11:20:38,219 - INFO - bo.run_bo - Recorded observation #15: hparams={'lr': 0.009949379806566057, 'batch_size': np.int64(96), 'epochs': np.int64(54), 'weight_decay': 4.168908010234268e-05, 'dropout': 0.06270159719557583, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(39), 'stride1': np.int64(7), 'kernel_size2': np.int64(11), 'stride2': np.int64(2), 'gcn_hidden': np.int64(10), 'label_smoothing': 0.04873321439793815, 'grad_clip_norm': 3.6166022735912913, 'use_amp': np.True_, 'calibrate_batches': np.int64(9), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.2325
2025-10-13 11:20:38,219 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 15: {'lr': 0.009949379806566057, 'batch_size': np.int64(96), 'epochs': np.int64(54), 'weight_decay': 4.168908010234268e-05, 'dropout': 0.06270159719557583, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(39), 'stride1': np.int64(7), 'kernel_size2': np.int64(11), 'stride2': np.int64(2), 'gcn_hidden': np.int64(10), 'label_smoothing': 0.04873321439793815, 'grad_clip_norm': 3.6166022735912913, 'use_amp': np.True_, 'calibrate_batches': np.int64(9), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.2325
2025-10-13 11:20:38,219 - INFO - bo.run_bo - üîçBO Trial 16: Using RF surrogate + Expected Improvement
2025-10-13 11:20:38,219 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:20:38,219 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 16 (NaN monitoring active)
2025-10-13 11:20:38,220 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:20:38,220 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:20:38,220 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004559163151496965, 'batch_size': 64, 'epochs': 47, 'weight_decay': 2.9461042102996285e-06, 'dropout': 0.0021778481188787784, 'channel_multiplier': 7, 'kernel_size1': 37, 'stride1': 5, 'kernel_size2': 49, 'stride2': 6, 'gcn_hidden': 8, 'label_smoothing': 0.03650446790199074, 'grad_clip_norm': 2.5836894967648845, 'use_amp': True, 'calibrate_batches': 11, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:20:38,221 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004559163151496965, 'batch_size': 64, 'epochs': 47, 'weight_decay': 2.9461042102996285e-06, 'dropout': 0.0021778481188787784, 'channel_multiplier': 7, 'kernel_size1': 37, 'stride1': 5, 'kernel_size2': 49, 'stride2': 6, 'gcn_hidden': 8, 'label_smoothing': 0.03650446790199074, 'grad_clip_norm': 2.5836894967648845, 'use_amp': True, 'calibrate_batches': 11, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:20:43,564 - INFO - _models.training_function_executor - Epoch 001/047 - train_loss: 1.2093 - val_loss: 1.1225 - val_acc: 0.5759
2025-10-13 11:20:46,180 - INFO - _models.training_function_executor - Epoch 002/047 - train_loss: 1.0644 - val_loss: 1.0716 - val_acc: 0.5949
2025-10-13 11:20:48,774 - INFO - _models.training_function_executor - Epoch 003/047 - train_loss: 1.0288 - val_loss: 1.2994 - val_acc: 0.4600
2025-10-13 11:20:51,350 - INFO - _models.training_function_executor - Epoch 004/047 - train_loss: 0.9991 - val_loss: 0.9817 - val_acc: 0.6223
2025-10-13 11:20:53,979 - INFO - _models.training_function_executor - Epoch 005/047 - train_loss: 0.9819 - val_loss: 1.0634 - val_acc: 0.6015
2025-10-13 11:20:56,577 - INFO - _models.training_function_executor - Epoch 006/047 - train_loss: 0.9592 - val_loss: 0.9705 - val_acc: 0.6499
2025-10-13 11:20:59,133 - INFO - _models.training_function_executor - Epoch 007/047 - train_loss: 0.9505 - val_loss: 1.4036 - val_acc: 0.4814
2025-10-13 11:21:01,703 - INFO - _models.training_function_executor - Epoch 008/047 - train_loss: 0.9408 - val_loss: 1.1411 - val_acc: 0.5572
2025-10-13 11:21:04,284 - INFO - _models.training_function_executor - Epoch 009/047 - train_loss: 0.9259 - val_loss: 0.9918 - val_acc: 0.6230
2025-10-13 11:21:06,884 - INFO - _models.training_function_executor - Epoch 010/047 - train_loss: 0.9200 - val_loss: 1.0180 - val_acc: 0.6079
2025-10-13 11:21:09,475 - INFO - _models.training_function_executor - Epoch 011/047 - train_loss: 0.9148 - val_loss: 0.9410 - val_acc: 0.6657
2025-10-13 11:21:12,080 - INFO - _models.training_function_executor - Epoch 012/047 - train_loss: 0.8991 - val_loss: 1.2931 - val_acc: 0.5566
2025-10-13 11:21:14,644 - INFO - _models.training_function_executor - Epoch 013/047 - train_loss: 0.8878 - val_loss: 1.0262 - val_acc: 0.5949
2025-10-13 11:21:17,217 - INFO - _models.training_function_executor - Epoch 014/047 - train_loss: 0.8767 - val_loss: 0.9486 - val_acc: 0.6635
2025-10-13 11:21:19,830 - INFO - _models.training_function_executor - Epoch 015/047 - train_loss: 0.8699 - val_loss: 1.5381 - val_acc: 0.4556
2025-10-13 11:21:22,416 - INFO - _models.training_function_executor - Epoch 016/047 - train_loss: 0.8661 - val_loss: 1.1018 - val_acc: 0.5936
2025-10-13 11:21:25,017 - INFO - _models.training_function_executor - Epoch 017/047 - train_loss: 0.8595 - val_loss: 0.9609 - val_acc: 0.6535
2025-10-13 11:21:27,594 - INFO - _models.training_function_executor - Epoch 018/047 - train_loss: 0.8563 - val_loss: 1.3735 - val_acc: 0.5712
2025-10-13 11:21:30,193 - INFO - _models.training_function_executor - Epoch 019/047 - train_loss: 0.8535 - val_loss: 0.9327 - val_acc: 0.6628
2025-10-13 11:21:32,785 - INFO - _models.training_function_executor - Epoch 020/047 - train_loss: 0.8501 - val_loss: 0.9345 - val_acc: 0.6925
2025-10-13 11:21:35,387 - INFO - _models.training_function_executor - Epoch 021/047 - train_loss: 0.8452 - val_loss: 1.5913 - val_acc: 0.4754
2025-10-13 11:21:37,969 - INFO - _models.training_function_executor - Epoch 022/047 - train_loss: 0.8412 - val_loss: 1.2161 - val_acc: 0.6015
2025-10-13 11:21:40,558 - INFO - _models.training_function_executor - Epoch 023/047 - train_loss: 0.8371 - val_loss: 1.2747 - val_acc: 0.6014
2025-10-13 11:21:43,147 - INFO - _models.training_function_executor - Epoch 024/047 - train_loss: 0.8340 - val_loss: 0.9648 - val_acc: 0.6493
2025-10-13 11:21:45,728 - INFO - _models.training_function_executor - Epoch 025/047 - train_loss: 0.8305 - val_loss: 1.0866 - val_acc: 0.6030
2025-10-13 11:21:48,307 - INFO - _models.training_function_executor - Epoch 026/047 - train_loss: 0.8270 - val_loss: 0.9782 - val_acc: 0.6672
2025-10-13 11:21:50,888 - INFO - _models.training_function_executor - Epoch 027/047 - train_loss: 0.8244 - val_loss: 1.0254 - val_acc: 0.6355
2025-10-13 11:21:53,473 - INFO - _models.training_function_executor - Epoch 028/047 - train_loss: 0.8224 - val_loss: 0.9655 - val_acc: 0.6345
2025-10-13 11:21:56,055 - INFO - _models.training_function_executor - Epoch 029/047 - train_loss: 0.8206 - val_loss: 1.1390 - val_acc: 0.6186
2025-10-13 11:21:58,626 - INFO - _models.training_function_executor - Epoch 030/047 - train_loss: 0.8184 - val_loss: 1.0510 - val_acc: 0.6431
2025-10-13 11:22:01,216 - INFO - _models.training_function_executor - Epoch 031/047 - train_loss: 0.8106 - val_loss: 1.0776 - val_acc: 0.6211
2025-10-13 11:22:03,798 - INFO - _models.training_function_executor - Epoch 032/047 - train_loss: 0.8105 - val_loss: 0.9824 - val_acc: 0.6226
2025-10-13 11:22:06,386 - INFO - _models.training_function_executor - Epoch 033/047 - train_loss: 0.8020 - val_loss: 0.9468 - val_acc: 0.6493
2025-10-13 11:22:08,969 - INFO - _models.training_function_executor - Epoch 034/047 - train_loss: 0.7994 - val_loss: 0.9745 - val_acc: 0.6723
2025-10-13 11:22:11,549 - INFO - _models.training_function_executor - Epoch 035/047 - train_loss: 0.7994 - val_loss: 0.8244 - val_acc: 0.7165
2025-10-13 11:22:14,165 - INFO - _models.training_function_executor - Epoch 036/047 - train_loss: 0.7984 - val_loss: 0.9625 - val_acc: 0.6783
2025-10-13 11:22:16,751 - INFO - _models.training_function_executor - Epoch 037/047 - train_loss: 0.7945 - val_loss: 1.0755 - val_acc: 0.5872
2025-10-13 11:22:19,320 - INFO - _models.training_function_executor - Epoch 038/047 - train_loss: 0.7925 - val_loss: 1.1124 - val_acc: 0.6709
2025-10-13 11:22:21,916 - INFO - _models.training_function_executor - Epoch 039/047 - train_loss: 0.7900 - val_loss: 1.2410 - val_acc: 0.5943
2025-10-13 11:22:24,519 - INFO - _models.training_function_executor - Epoch 040/047 - train_loss: 0.7867 - val_loss: 0.8970 - val_acc: 0.6733
2025-10-13 11:22:27,087 - INFO - _models.training_function_executor - Epoch 041/047 - train_loss: 0.7891 - val_loss: 1.1963 - val_acc: 0.5857
2025-10-13 11:22:29,662 - INFO - _models.training_function_executor - Epoch 042/047 - train_loss: 0.7827 - val_loss: 0.9466 - val_acc: 0.6782
2025-10-13 11:22:32,247 - INFO - _models.training_function_executor - Epoch 043/047 - train_loss: 0.7809 - val_loss: 1.2601 - val_acc: 0.6022
2025-10-13 11:22:34,811 - INFO - _models.training_function_executor - Epoch 044/047 - train_loss: 0.7792 - val_loss: 0.8947 - val_acc: 0.6831
2025-10-13 11:22:37,389 - INFO - _models.training_function_executor - Epoch 045/047 - train_loss: 0.7762 - val_loss: 0.9211 - val_acc: 0.6824
2025-10-13 11:22:39,978 - INFO - _models.training_function_executor - Epoch 046/047 - train_loss: 0.7780 - val_loss: 1.1401 - val_acc: 0.6530
2025-10-13 11:22:42,583 - INFO - _models.training_function_executor - Epoch 047/047 - train_loss: 0.7755 - val_loss: 1.8760 - val_acc: 0.4131
2025-10-13 11:22:43,699 - INFO - _models.training_function_executor - Model: 2,529 parameters, 10.9KB storage
2025-10-13 11:22:43,699 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2093271534886025, 1.0643825231417936, 1.028770077257754, 0.9990704395907051, 0.981862768494336, 0.9592069711224533, 0.9504837674780829, 0.9407730146350667, 0.9259152124509721, 0.919966212218568, 0.9147638259419704, 0.8990796168951208, 0.8878222306291248, 0.8766647757747852, 0.8699382085836889, 0.8660977279384694, 0.8595355681535202, 0.8562780811438663, 0.8534741940763725, 0.8500884544152583, 0.8452158444070466, 0.8411989470315973, 0.8371098253081886, 0.8340338413056937, 0.8304809331059414, 0.826990323130134, 0.8244344065312034, 0.8223743257006858, 0.8205617661237466, 0.8183566223168899, 0.8105699682219027, 0.8104871360830882, 0.802045118821264, 0.7994387880838706, 0.7993603651032065, 0.7983915208101189, 0.7944522234873627, 0.7924510914419012, 0.7899847759581297, 0.7867083110131706, 0.7890708740874942, 0.7827228852656908, 0.7809306095019478, 0.7791500607695161, 0.776183379606054, 0.7780020060470816, 0.7754626599775146], 'val_losses': [1.1224914061927194, 1.0716355646411815, 1.2994259262902779, 0.9816718922238855, 1.0634208575052777, 0.9705435665161992, 1.403618607147198, 1.1410816220249127, 0.9917704944306835, 1.0179693357569795, 0.9409521765169832, 1.293138387197375, 1.0262167734994645, 0.9485603221697034, 1.538122900307575, 1.101818404332883, 0.9609199351767038, 1.3735480332316157, 0.9327345409717099, 0.9344745172584729, 1.5912816178602567, 1.2160983391061795, 1.2747361091704563, 0.9648262511444626, 1.0865743379305826, 0.9782088468406098, 1.0254494435394148, 0.9655189362697181, 1.138966362543944, 1.0509562337986855, 1.0776013926187928, 0.9823556854710698, 0.946824217472704, 0.9745157105045632, 0.8244407850835638, 0.9624857823248714, 1.0754981176144685, 1.112429962151527, 1.2410476727630861, 0.8969561655620699, 1.1962718633575626, 0.9466494245465752, 1.2601232910056108, 0.8947457753364382, 0.9210968123977736, 1.1400826542703764, 1.8759976396370401], 'val_acc': [0.5758662933146658, 0.5948547427371369, 0.46001050052502623, 0.6223311165558278, 0.6015050752537627, 0.6498949947497374, 0.4814490724536227, 0.5572278613930697, 0.6230311515575779, 0.6078928946447323, 0.6657332866643332, 0.5566153307665384, 0.5948547427371369, 0.6635456772838642, 0.4556352817640882, 0.5936296814840742, 0.6534826741337066, 0.5712285614280714, 0.6627581379068953, 0.692509625481274, 0.47541127056352817, 0.6015050752537627, 0.601417570878544, 0.6492824641232061, 0.6029926496324817, 0.6672208610430521, 0.6355442772138606, 0.6344942247112355, 0.6185684284214211, 0.6430696534826741, 0.6211060553027652, 0.6225936296814841, 0.6492824641232061, 0.6722961148057403, 0.7164858242912145, 0.6783339166958348, 0.5871543577178859, 0.6708960448022401, 0.5943297164858243, 0.6733461673083654, 0.585666783339167, 0.678246412320616, 0.6022051102555128, 0.6830591529576479, 0.6823591179558978, 0.6529576478823941, 0.4131081554077704], 'final_state_dict_size_bytes': 10516, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004559163151496965, 'batch_size': 64, 'epochs': 47, 'weight_decay': 2.9461042102996285e-06, 'dropout': 0.0021778481188787784, 'channel_multiplier': 7, 'kernel_size1': 37, 'stride1': 5, 'kernel_size2': 49, 'stride2': 6, 'gcn_hidden': 8, 'label_smoothing': 0.03650446790199074, 'grad_clip_norm': 2.5836894967648845, 'use_amp': True, 'calibrate_batches': 11, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 2529, 'model_storage_size_kb': 10.866796875, 'model_size_validation': 'PASS'}
2025-10-13 11:22:43,699 - INFO - _models.training_function_executor - BO Objective: base=0.4131, size_penalty=0.0000, final=0.4131
2025-10-13 11:22:43,699 - INFO - _models.training_function_executor - Model: 2,529 parameters, 10.9KB (PASS 256KB limit)
2025-10-13 11:22:43,699 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 125.480s
2025-10-13 11:22:43,789 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.4131
2025-10-13 11:22:43,789 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.090s
2025-10-13 11:22:43,789 - INFO - bo.run_bo - Recorded observation #16: hparams={'lr': 0.004559163151496965, 'batch_size': np.int64(64), 'epochs': np.int64(47), 'weight_decay': 2.9461042102996285e-06, 'dropout': 0.0021778481188787784, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(37), 'stride1': np.int64(5), 'kernel_size2': np.int64(49), 'stride2': np.int64(6), 'gcn_hidden': np.int64(8), 'label_smoothing': 0.03650446790199074, 'grad_clip_norm': 2.5836894967648845, 'use_amp': np.True_, 'calibrate_batches': np.int64(11), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.4131
2025-10-13 11:22:43,790 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 16: {'lr': 0.004559163151496965, 'batch_size': np.int64(64), 'epochs': np.int64(47), 'weight_decay': 2.9461042102996285e-06, 'dropout': 0.0021778481188787784, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(37), 'stride1': np.int64(5), 'kernel_size2': np.int64(49), 'stride2': np.int64(6), 'gcn_hidden': np.int64(8), 'label_smoothing': 0.03650446790199074, 'grad_clip_norm': 2.5836894967648845, 'use_amp': np.True_, 'calibrate_batches': np.int64(11), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.4131
2025-10-13 11:22:43,790 - INFO - bo.run_bo - üîçBO Trial 17: Using RF surrogate + Expected Improvement
2025-10-13 11:22:43,790 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:22:43,790 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 17 (NaN monitoring active)
2025-10-13 11:22:43,790 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:22:43,790 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:22:43,790 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00932001288353657, 'batch_size': 16, 'epochs': 26, 'weight_decay': 0.00024387670451666858, 'dropout': 0.3669850027520252, 'channel_multiplier': 2, 'kernel_size1': 58, 'stride1': 6, 'kernel_size2': 49, 'stride2': 3, 'gcn_hidden': 8, 'label_smoothing': 0.11300399704895751, 'grad_clip_norm': 4.361576076095175, 'use_amp': False, 'calibrate_batches': 15, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:22:43,791 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00932001288353657, 'batch_size': 16, 'epochs': 26, 'weight_decay': 0.00024387670451666858, 'dropout': 0.3669850027520252, 'channel_multiplier': 2, 'kernel_size1': 58, 'stride1': 6, 'kernel_size2': 49, 'stride2': 3, 'gcn_hidden': 8, 'label_smoothing': 0.11300399704895751, 'grad_clip_norm': 4.361576076095175, 'use_amp': False, 'calibrate_batches': 15, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:22:50,576 - INFO - _models.training_function_executor - Epoch 001/026 - train_loss: 1.3999 - val_loss: 1.5670 - val_acc: 0.2986
2025-10-13 11:22:54,565 - INFO - _models.training_function_executor - Epoch 002/026 - train_loss: 1.2647 - val_loss: 1.4023 - val_acc: 0.4602
2025-10-13 11:22:58,494 - INFO - _models.training_function_executor - Epoch 003/026 - train_loss: 1.2176 - val_loss: 1.2226 - val_acc: 0.5783
2025-10-13 11:23:02,452 - INFO - _models.training_function_executor - Epoch 004/026 - train_loss: 1.2000 - val_loss: 1.3936 - val_acc: 0.4744
2025-10-13 11:23:06,385 - INFO - _models.training_function_executor - Epoch 005/026 - train_loss: 1.1844 - val_loss: 1.2192 - val_acc: 0.5913
2025-10-13 11:23:10,370 - INFO - _models.training_function_executor - Epoch 006/026 - train_loss: 1.1749 - val_loss: 1.3661 - val_acc: 0.4828
2025-10-13 11:23:14,365 - INFO - _models.training_function_executor - Epoch 007/026 - train_loss: 1.1707 - val_loss: 1.3571 - val_acc: 0.4372
2025-10-13 11:23:18,390 - INFO - _models.training_function_executor - Epoch 008/026 - train_loss: 1.1614 - val_loss: 1.3865 - val_acc: 0.4966
2025-10-13 11:23:22,368 - INFO - _models.training_function_executor - Epoch 009/026 - train_loss: 1.1633 - val_loss: 1.2903 - val_acc: 0.5531
2025-10-13 11:23:26,318 - INFO - _models.training_function_executor - Epoch 010/026 - train_loss: 1.1557 - val_loss: 1.3813 - val_acc: 0.4758
2025-10-13 11:23:30,334 - INFO - _models.training_function_executor - Epoch 011/026 - train_loss: 1.1521 - val_loss: 1.3344 - val_acc: 0.4941
2025-10-13 11:23:34,306 - INFO - _models.training_function_executor - Epoch 012/026 - train_loss: 1.1470 - val_loss: 1.3616 - val_acc: 0.4990
2025-10-13 11:23:38,249 - INFO - _models.training_function_executor - Epoch 013/026 - train_loss: 1.1472 - val_loss: 1.2664 - val_acc: 0.5560
2025-10-13 11:23:42,175 - INFO - _models.training_function_executor - Epoch 014/026 - train_loss: 1.1459 - val_loss: 1.2945 - val_acc: 0.5127
2025-10-13 11:23:46,187 - INFO - _models.training_function_executor - Epoch 015/026 - train_loss: 1.1432 - val_loss: 1.1988 - val_acc: 0.5860
2025-10-13 11:23:50,110 - INFO - _models.training_function_executor - Epoch 016/026 - train_loss: 1.1444 - val_loss: 1.2188 - val_acc: 0.5814
2025-10-13 11:23:54,074 - INFO - _models.training_function_executor - Epoch 017/026 - train_loss: 1.1404 - val_loss: 1.2463 - val_acc: 0.5665
2025-10-13 11:23:58,000 - INFO - _models.training_function_executor - Epoch 018/026 - train_loss: 1.1376 - val_loss: 1.2458 - val_acc: 0.5682
2025-10-13 11:24:01,905 - INFO - _models.training_function_executor - Epoch 019/026 - train_loss: 1.1334 - val_loss: 1.2191 - val_acc: 0.5670
2025-10-13 11:24:05,817 - INFO - _models.training_function_executor - Epoch 020/026 - train_loss: 1.1403 - val_loss: 1.4555 - val_acc: 0.3558
2025-10-13 11:24:09,826 - INFO - _models.training_function_executor - Epoch 021/026 - train_loss: 1.1352 - val_loss: 1.2419 - val_acc: 0.5706
2025-10-13 11:24:13,824 - INFO - _models.training_function_executor - Epoch 022/026 - train_loss: 1.1353 - val_loss: 1.3080 - val_acc: 0.5108
2025-10-13 11:24:17,702 - INFO - _models.training_function_executor - Epoch 023/026 - train_loss: 1.1331 - val_loss: 1.2262 - val_acc: 0.5705
2025-10-13 11:24:21,623 - INFO - _models.training_function_executor - Epoch 024/026 - train_loss: 1.1310 - val_loss: 1.3393 - val_acc: 0.4944
2025-10-13 11:24:25,546 - INFO - _models.training_function_executor - Epoch 025/026 - train_loss: 1.1300 - val_loss: 1.2389 - val_acc: 0.5815
2025-10-13 11:24:29,471 - INFO - _models.training_function_executor - Epoch 026/026 - train_loss: 1.1245 - val_loss: 1.2047 - val_acc: 0.5921
2025-10-13 11:24:30,625 - INFO - _models.training_function_executor - Model: 44 parameters, 0.0KB storage
2025-10-13 11:24:30,625 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.399890217782736, 1.2646901695762516, 1.2176424907478036, 1.1999614483666745, 1.1844172378415865, 1.1748835328036686, 1.1707123183978785, 1.1614132691272538, 1.1632714433022466, 1.1557156004019455, 1.1521040503695832, 1.1470166202562857, 1.1472238039778462, 1.1459232459629087, 1.1432204366272716, 1.1444377240744095, 1.1404036356929637, 1.1375578472069356, 1.133383767689113, 1.14034605877442, 1.135200165392095, 1.1353438868153791, 1.1330646239129822, 1.1309604503743749, 1.130007566398451, 1.1244605967411847], 'val_losses': [1.5669692090060856, 1.402293757287447, 1.222633343123455, 1.3935582011072294, 1.21918921521547, 1.3661426380876482, 1.3571434321835778, 1.3865180285109646, 1.2903499961692135, 1.3813355833990908, 1.3343802231944522, 1.3616277006150628, 1.2664404846297554, 1.294505133009641, 1.19884699695712, 1.2187845158460133, 1.2462995423484524, 1.2458204124038104, 1.2191406107048994, 1.4555344624998354, 1.2419138735184354, 1.3079848755561767, 1.226209108838678, 1.3393117364027887, 1.2388683130451545, 1.2046718261731768], 'val_acc': [0.29856492824641234, 0.46018550927546376, 0.5783164158207911, 0.4744487224361218, 0.5912670633531677, 0.48284914245712285, 0.4371718585929297, 0.4965873293664683, 0.5531151557577879, 0.4757612880644032, 0.494137206860343, 0.49903745187259363, 0.556002800140007, 0.5126881344067203, 0.586016800840042, 0.5813790689534477, 0.5665033251662583, 0.5681659082954148, 0.5670283514175709, 0.35579278963948197, 0.5706160308015401, 0.5107630381519076, 0.5705285264263213, 0.4943997199859993, 0.5814665733286665, 0.5921421071053553], 'final_state_dict_size_bytes': 1232, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00932001288353657, 'batch_size': 16, 'epochs': 26, 'weight_decay': 0.00024387670451666858, 'dropout': 0.3669850027520252, 'channel_multiplier': 2, 'kernel_size1': 58, 'stride1': 6, 'kernel_size2': 49, 'stride2': 3, 'gcn_hidden': 8, 'label_smoothing': 0.11300399704895751, 'grad_clip_norm': 4.361576076095175, 'use_amp': False, 'calibrate_batches': 15, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 44, 'model_storage_size_kb': 0.047265625000000006, 'model_size_validation': 'PASS'}
2025-10-13 11:24:30,625 - INFO - _models.training_function_executor - BO Objective: base=0.5921, size_penalty=0.0000, final=0.5921
2025-10-13 11:24:30,625 - INFO - _models.training_function_executor - Model: 44 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 11:24:30,625 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 106.836s
2025-10-13 11:24:30,718 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5921
2025-10-13 11:24:30,718 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.092s
2025-10-13 11:24:30,718 - INFO - bo.run_bo - Recorded observation #17: hparams={'lr': 0.00932001288353657, 'batch_size': np.int64(16), 'epochs': np.int64(26), 'weight_decay': 0.00024387670451666858, 'dropout': 0.3669850027520252, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(58), 'stride1': np.int64(6), 'kernel_size2': np.int64(49), 'stride2': np.int64(3), 'gcn_hidden': np.int64(8), 'label_smoothing': 0.11300399704895751, 'grad_clip_norm': 4.361576076095175, 'use_amp': np.False_, 'calibrate_batches': np.int64(15), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.5921
2025-10-13 11:24:30,718 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 17: {'lr': 0.00932001288353657, 'batch_size': np.int64(16), 'epochs': np.int64(26), 'weight_decay': 0.00024387670451666858, 'dropout': 0.3669850027520252, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(58), 'stride1': np.int64(6), 'kernel_size2': np.int64(49), 'stride2': np.int64(3), 'gcn_hidden': np.int64(8), 'label_smoothing': 0.11300399704895751, 'grad_clip_norm': 4.361576076095175, 'use_amp': np.False_, 'calibrate_batches': np.int64(15), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.5921
2025-10-13 11:24:30,718 - INFO - bo.run_bo - üîçBO Trial 18: Using RF surrogate + Expected Improvement
2025-10-13 11:24:30,718 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:24:30,718 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 18 (NaN monitoring active)
2025-10-13 11:24:30,718 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:24:30,718 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:24:30,718 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.008425733929674977, 'batch_size': 32, 'epochs': 32, 'weight_decay': 1.0144969042042207e-06, 'dropout': 0.008202135338853191, 'channel_multiplier': 8, 'kernel_size1': 59, 'stride1': 7, 'kernel_size2': 55, 'stride2': 3, 'gcn_hidden': 8, 'label_smoothing': 0.1996206048536298, 'grad_clip_norm': 1.4920950437335203, 'use_amp': True, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:24:30,719 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.008425733929674977, 'batch_size': 32, 'epochs': 32, 'weight_decay': 1.0144969042042207e-06, 'dropout': 0.008202135338853191, 'channel_multiplier': 8, 'kernel_size1': 59, 'stride1': 7, 'kernel_size2': 55, 'stride2': 3, 'gcn_hidden': 8, 'label_smoothing': 0.1996206048536298, 'grad_clip_norm': 1.4920950437335203, 'use_amp': True, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:24:36,993 - INFO - _models.training_function_executor - Epoch 001/032 - train_loss: 1.3214 - val_loss: 1.3490 - val_acc: 0.5291
2025-10-13 11:24:40,395 - INFO - _models.training_function_executor - Epoch 002/032 - train_loss: 1.2530 - val_loss: 1.2393 - val_acc: 0.6173
2025-10-13 11:24:43,813 - INFO - _models.training_function_executor - Epoch 003/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:24:47,229 - INFO - _models.training_function_executor - Epoch 004/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:24:50,650 - INFO - _models.training_function_executor - Epoch 005/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:24:54,067 - INFO - _models.training_function_executor - Epoch 006/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:24:57,477 - INFO - _models.training_function_executor - Epoch 007/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:00,875 - INFO - _models.training_function_executor - Epoch 008/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:04,289 - INFO - _models.training_function_executor - Epoch 009/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:07,706 - INFO - _models.training_function_executor - Epoch 010/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:11,099 - INFO - _models.training_function_executor - Epoch 011/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:14,322 - INFO - _models.training_function_executor - Epoch 012/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:17,488 - INFO - _models.training_function_executor - Epoch 013/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:20,673 - INFO - _models.training_function_executor - Epoch 014/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:23,832 - INFO - _models.training_function_executor - Epoch 015/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:27,011 - INFO - _models.training_function_executor - Epoch 016/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:30,193 - INFO - _models.training_function_executor - Epoch 017/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:33,335 - INFO - _models.training_function_executor - Epoch 018/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:36,562 - INFO - _models.training_function_executor - Epoch 019/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:39,757 - INFO - _models.training_function_executor - Epoch 020/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:42,936 - INFO - _models.training_function_executor - Epoch 021/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:46,130 - INFO - _models.training_function_executor - Epoch 022/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:49,305 - INFO - _models.training_function_executor - Epoch 023/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:52,479 - INFO - _models.training_function_executor - Epoch 024/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:55,656 - INFO - _models.training_function_executor - Epoch 025/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:25:58,857 - INFO - _models.training_function_executor - Epoch 026/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:26:02,039 - INFO - _models.training_function_executor - Epoch 027/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:26:05,202 - INFO - _models.training_function_executor - Epoch 028/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:26:08,383 - INFO - _models.training_function_executor - Epoch 029/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:26:11,568 - INFO - _models.training_function_executor - Epoch 030/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:26:14,762 - INFO - _models.training_function_executor - Epoch 031/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:26:17,935 - INFO - _models.training_function_executor - Epoch 032/032 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:26:19,037 - INFO - _models.training_function_executor - Model: 3,263 parameters, 14.0KB storage
2025-10-13 11:26:19,037 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3214183575547072, 1.2530189851050533, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.349024697246358, 1.2392589382078834, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5290514525726286, 0.6172558627931397, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'final_state_dict_size_bytes': 13500, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.008425733929674977, 'batch_size': 32, 'epochs': 32, 'weight_decay': 1.0144969042042207e-06, 'dropout': 0.008202135338853191, 'channel_multiplier': 8, 'kernel_size1': 59, 'stride1': 7, 'kernel_size2': 55, 'stride2': 3, 'gcn_hidden': 8, 'label_smoothing': 0.1996206048536298, 'grad_clip_norm': 1.4920950437335203, 'use_amp': True, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 3263, 'model_storage_size_kb': 14.020703125, 'model_size_validation': 'PASS'}
2025-10-13 11:26:19,037 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-13 11:26:19,037 - INFO - _models.training_function_executor - Model: 3,263 parameters, 14.0KB (PASS 256KB limit)
2025-10-13 11:26:19,037 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 108.319s
2025-10-13 11:26:19,131 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-13 11:26:19,132 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-13 11:26:19,132 - INFO - bo.run_bo - Recorded observation #18: hparams={'lr': 0.008425733929674977, 'batch_size': np.int64(32), 'epochs': np.int64(32), 'weight_decay': 1.0144969042042207e-06, 'dropout': 0.008202135338853191, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(59), 'stride1': np.int64(7), 'kernel_size2': np.int64(55), 'stride2': np.int64(3), 'gcn_hidden': np.int64(8), 'label_smoothing': 0.1996206048536298, 'grad_clip_norm': 1.4920950437335203, 'use_amp': np.True_, 'calibrate_batches': np.int64(32), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.2325
2025-10-13 11:26:19,132 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 18: {'lr': 0.008425733929674977, 'batch_size': np.int64(32), 'epochs': np.int64(32), 'weight_decay': 1.0144969042042207e-06, 'dropout': 0.008202135338853191, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(59), 'stride1': np.int64(7), 'kernel_size2': np.int64(55), 'stride2': np.int64(3), 'gcn_hidden': np.int64(8), 'label_smoothing': 0.1996206048536298, 'grad_clip_norm': 1.4920950437335203, 'use_amp': np.True_, 'calibrate_batches': np.int64(32), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.2325
2025-10-13 11:26:19,132 - INFO - bo.run_bo - üîçBO Trial 19: Using RF surrogate + Expected Improvement
2025-10-13 11:26:19,132 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:26:19,132 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 19 (NaN monitoring active)
2025-10-13 11:26:19,132 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:26:19,132 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:26:19,132 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009133383487802621, 'batch_size': 64, 'epochs': 30, 'weight_decay': 0.00012151558272100467, 'dropout': 0.04906655517506701, 'channel_multiplier': 8, 'kernel_size1': 40, 'stride1': 4, 'kernel_size2': 61, 'stride2': 5, 'gcn_hidden': 19, 'label_smoothing': 0.12239888004538904, 'grad_clip_norm': 0.06977979809373759, 'use_amp': True, 'calibrate_batches': 62, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:26:19,133 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009133383487802621, 'batch_size': 64, 'epochs': 30, 'weight_decay': 0.00012151558272100467, 'dropout': 0.04906655517506701, 'channel_multiplier': 8, 'kernel_size1': 40, 'stride1': 4, 'kernel_size2': 61, 'stride2': 5, 'gcn_hidden': 19, 'label_smoothing': 0.12239888004538904, 'grad_clip_norm': 0.06977979809373759, 'use_amp': True, 'calibrate_batches': 62, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:26:25,295 - INFO - _models.training_function_executor - Epoch 001/030 - train_loss: 1.2501 - val_loss: 1.2812 - val_acc: 0.4905
2025-10-13 11:26:28,646 - INFO - _models.training_function_executor - Epoch 002/030 - train_loss: 1.1637 - val_loss: 1.1619 - val_acc: 0.5881
2025-10-13 11:26:32,016 - INFO - _models.training_function_executor - Epoch 003/030 - train_loss: 1.1304 - val_loss: 1.1032 - val_acc: 0.6420
2025-10-13 11:26:35,393 - INFO - _models.training_function_executor - Epoch 004/030 - train_loss: 1.1121 - val_loss: 1.2023 - val_acc: 0.5846
2025-10-13 11:26:38,764 - INFO - _models.training_function_executor - Epoch 005/030 - train_loss: 1.1015 - val_loss: 1.1075 - val_acc: 0.6324
2025-10-13 11:26:42,153 - INFO - _models.training_function_executor - Epoch 006/030 - train_loss: 1.0733 - val_loss: 1.1233 - val_acc: 0.6030
2025-10-13 11:26:45,518 - INFO - _models.training_function_executor - Epoch 007/030 - train_loss: 1.0496 - val_loss: 1.0576 - val_acc: 0.6711
2025-10-13 11:26:48,910 - INFO - _models.training_function_executor - Epoch 008/030 - train_loss: 1.0343 - val_loss: 1.0573 - val_acc: 0.6783
2025-10-13 11:26:52,305 - INFO - _models.training_function_executor - Epoch 009/030 - train_loss: 1.0231 - val_loss: 1.0185 - val_acc: 0.6908
2025-10-13 11:26:55,685 - INFO - _models.training_function_executor - Epoch 010/030 - train_loss: 1.0133 - val_loss: 1.2900 - val_acc: 0.5354
2025-10-13 11:26:59,072 - INFO - _models.training_function_executor - Epoch 011/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:02,482 - INFO - _models.training_function_executor - Epoch 012/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:05,848 - INFO - _models.training_function_executor - Epoch 013/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:09,221 - INFO - _models.training_function_executor - Epoch 014/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:12,628 - INFO - _models.training_function_executor - Epoch 015/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:16,022 - INFO - _models.training_function_executor - Epoch 016/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:19,386 - INFO - _models.training_function_executor - Epoch 017/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:22,780 - INFO - _models.training_function_executor - Epoch 018/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:26,134 - INFO - _models.training_function_executor - Epoch 019/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:29,515 - INFO - _models.training_function_executor - Epoch 020/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:32,900 - INFO - _models.training_function_executor - Epoch 021/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:36,272 - INFO - _models.training_function_executor - Epoch 022/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:39,669 - INFO - _models.training_function_executor - Epoch 023/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:43,062 - INFO - _models.training_function_executor - Epoch 024/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:46,441 - INFO - _models.training_function_executor - Epoch 025/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:49,819 - INFO - _models.training_function_executor - Epoch 026/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:53,199 - INFO - _models.training_function_executor - Epoch 027/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:27:56,610 - INFO - _models.training_function_executor - Epoch 028/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:28:00,011 - INFO - _models.training_function_executor - Epoch 029/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:28:03,407 - INFO - _models.training_function_executor - Epoch 030/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:28:04,553 - INFO - _models.training_function_executor - Model: 3,602 parameters, 15.5KB storage
2025-10-13 11:28:04,553 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.250140117856227, 1.163727778548914, 1.1303802690265643, 1.1120629637317303, 1.1014776585358275, 1.073346446434184, 1.049591557104186, 1.034335186942958, 1.023075460511402, 1.0133482322519294, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.2811742470236895, 1.1618967007873022, 1.103229432578349, 1.2023019706364233, 1.1074838570710617, 1.1233374628521655, 1.057622624019413, 1.0572930674975178, 1.018460403425025, 1.2899633175766798, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.49046202310115505, 0.5881169058452923, 0.642019600980049, 0.5846167308365419, 0.6323941197059852, 0.6029926496324817, 0.6710710535526776, 0.6783339166958348, 0.6907595379768988, 0.5353517675883794, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'final_state_dict_size_bytes': 7436, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009133383487802621, 'batch_size': 64, 'epochs': 30, 'weight_decay': 0.00012151558272100467, 'dropout': 0.04906655517506701, 'channel_multiplier': 8, 'kernel_size1': 40, 'stride1': 4, 'kernel_size2': 61, 'stride2': 5, 'gcn_hidden': 19, 'label_smoothing': 0.12239888004538904, 'grad_clip_norm': 0.06977979809373759, 'use_amp': True, 'calibrate_batches': 62, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 3602, 'model_storage_size_kb': 15.477343750000001, 'model_size_validation': 'PASS'}
2025-10-13 11:28:04,553 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-13 11:28:04,553 - INFO - _models.training_function_executor - Model: 3,602 parameters, 15.5KB (PASS 256KB limit)
2025-10-13 11:28:04,553 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 105.421s
2025-10-13 11:28:04,648 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-13 11:28:04,648 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-13 11:28:04,648 - INFO - bo.run_bo - Recorded observation #19: hparams={'lr': 0.009133383487802621, 'batch_size': np.int64(64), 'epochs': np.int64(30), 'weight_decay': 0.00012151558272100467, 'dropout': 0.04906655517506701, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(40), 'stride1': np.int64(4), 'kernel_size2': np.int64(61), 'stride2': np.int64(5), 'gcn_hidden': np.int64(19), 'label_smoothing': 0.12239888004538904, 'grad_clip_norm': 0.06977979809373759, 'use_amp': np.True_, 'calibrate_batches': np.int64(62), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.2325
2025-10-13 11:28:04,648 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 19: {'lr': 0.009133383487802621, 'batch_size': np.int64(64), 'epochs': np.int64(30), 'weight_decay': 0.00012151558272100467, 'dropout': 0.04906655517506701, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(40), 'stride1': np.int64(4), 'kernel_size2': np.int64(61), 'stride2': np.int64(5), 'gcn_hidden': np.int64(19), 'label_smoothing': 0.12239888004538904, 'grad_clip_norm': 0.06977979809373759, 'use_amp': np.True_, 'calibrate_batches': np.int64(62), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.2325
2025-10-13 11:28:04,649 - INFO - bo.run_bo - üîçBO Trial 20: Using RF surrogate + Expected Improvement
2025-10-13 11:28:04,649 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:28:04,649 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 20 (NaN monitoring active)
2025-10-13 11:28:04,649 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:28:04,649 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:28:04,649 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0077432758201777824, 'batch_size': 16, 'epochs': 23, 'weight_decay': 3.5463063866518388e-06, 'dropout': 0.003967263143682365, 'channel_multiplier': 4, 'kernel_size1': 34, 'stride1': 11, 'kernel_size2': 43, 'stride2': 6, 'gcn_hidden': 9, 'label_smoothing': 0.07737418761207225, 'grad_clip_norm': 4.234779596118415, 'use_amp': False, 'calibrate_batches': 76, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:28:04,650 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0077432758201777824, 'batch_size': 16, 'epochs': 23, 'weight_decay': 3.5463063866518388e-06, 'dropout': 0.003967263143682365, 'channel_multiplier': 4, 'kernel_size1': 34, 'stride1': 11, 'kernel_size2': 43, 'stride2': 6, 'gcn_hidden': 9, 'label_smoothing': 0.07737418761207225, 'grad_clip_norm': 4.234779596118415, 'use_amp': False, 'calibrate_batches': 76, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:28:11,413 - INFO - _models.training_function_executor - Epoch 001/023 - train_loss: 1.2559 - val_loss: 1.2059 - val_acc: 0.5588
2025-10-13 11:28:15,391 - INFO - _models.training_function_executor - Epoch 002/023 - train_loss: 1.1482 - val_loss: 1.1716 - val_acc: 0.5558
2025-10-13 11:28:19,375 - INFO - _models.training_function_executor - Epoch 003/023 - train_loss: 1.1234 - val_loss: 1.6065 - val_acc: 0.4464
2025-10-13 11:28:23,319 - INFO - _models.training_function_executor - Epoch 004/023 - train_loss: 1.1073 - val_loss: 1.1297 - val_acc: 0.5938
2025-10-13 11:28:27,249 - INFO - _models.training_function_executor - Epoch 005/023 - train_loss: 1.0910 - val_loss: 1.0863 - val_acc: 0.6244
2025-10-13 11:28:31,203 - INFO - _models.training_function_executor - Epoch 006/023 - train_loss: 1.0735 - val_loss: 1.1385 - val_acc: 0.5851
2025-10-13 11:28:35,128 - INFO - _models.training_function_executor - Epoch 007/023 - train_loss: 1.0547 - val_loss: 1.1079 - val_acc: 0.6147
2025-10-13 11:28:39,085 - INFO - _models.training_function_executor - Epoch 008/023 - train_loss: 1.0412 - val_loss: 1.0364 - val_acc: 0.6529
2025-10-13 11:28:43,025 - INFO - _models.training_function_executor - Epoch 009/023 - train_loss: 1.0270 - val_loss: 0.9774 - val_acc: 0.6719
2025-10-13 11:28:46,907 - INFO - _models.training_function_executor - Epoch 010/023 - train_loss: 1.0249 - val_loss: 0.9726 - val_acc: 0.6852
2025-10-13 11:28:50,843 - INFO - _models.training_function_executor - Epoch 011/023 - train_loss: 1.0107 - val_loss: 1.0041 - val_acc: 0.6585
2025-10-13 11:28:54,786 - INFO - _models.training_function_executor - Epoch 012/023 - train_loss: 1.0173 - val_loss: 0.9864 - val_acc: 0.6646
2025-10-13 11:28:58,736 - INFO - _models.training_function_executor - Epoch 013/023 - train_loss: 1.0035 - val_loss: 1.0377 - val_acc: 0.6399
2025-10-13 11:29:02,661 - INFO - _models.training_function_executor - Epoch 014/023 - train_loss: 1.0025 - val_loss: 1.0293 - val_acc: 0.6561
2025-10-13 11:29:06,591 - INFO - _models.training_function_executor - Epoch 015/023 - train_loss: 0.9988 - val_loss: 1.1287 - val_acc: 0.6028
2025-10-13 11:29:10,536 - INFO - _models.training_function_executor - Epoch 016/023 - train_loss: 0.9960 - val_loss: 1.0764 - val_acc: 0.6109
2025-10-13 11:29:14,486 - INFO - _models.training_function_executor - Epoch 017/023 - train_loss: 0.9950 - val_loss: 0.9538 - val_acc: 0.6819
2025-10-13 11:29:18,433 - INFO - _models.training_function_executor - Epoch 018/023 - train_loss: 0.9924 - val_loss: 0.9659 - val_acc: 0.6771
2025-10-13 11:29:22,422 - INFO - _models.training_function_executor - Epoch 019/023 - train_loss: 0.9903 - val_loss: 0.9914 - val_acc: 0.6623
2025-10-13 11:29:26,374 - INFO - _models.training_function_executor - Epoch 020/023 - train_loss: 0.9931 - val_loss: 0.9866 - val_acc: 0.6686
2025-10-13 11:29:30,312 - INFO - _models.training_function_executor - Epoch 021/023 - train_loss: 0.9899 - val_loss: 1.1312 - val_acc: 0.5845
2025-10-13 11:29:34,255 - INFO - _models.training_function_executor - Epoch 022/023 - train_loss: 0.9926 - val_loss: 0.9556 - val_acc: 0.6805
2025-10-13 11:29:38,243 - INFO - _models.training_function_executor - Epoch 023/023 - train_loss: 0.9878 - val_loss: 0.9767 - val_acc: 0.6743
2025-10-13 11:29:39,410 - INFO - _models.training_function_executor - Model: 1,436 parameters, 6.2KB storage
2025-10-13 11:29:39,410 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2559097196240503, 1.1482148562897991, 1.1234070314658369, 1.1073047121713577, 1.0909776331704941, 1.0734803869376284, 1.0547054413318802, 1.0411723735952527, 1.0269601539710955, 1.0248872200675807, 1.0107426406371665, 1.017343345496218, 1.003547105394463, 1.002535697626909, 0.9987934331898928, 0.9959941784276551, 0.995031271796148, 0.9923898857249887, 0.9902786420156875, 0.9930790723893123, 0.9898779031318261, 0.992596229891031, 0.9878471683779921], 'val_losses': [1.205941189345172, 1.171592802278721, 1.6065243608182989, 1.12974850798471, 1.086264809737641, 1.138527379571703, 1.107926581929854, 1.0364067190628934, 0.9773743123410672, 0.972555206691547, 1.0040816628394695, 0.9864205179992238, 1.0376591163370883, 1.0292842227927779, 1.128669947730022, 1.0764475842643795, 0.9537882506117188, 0.9659198856579077, 0.9914102358420829, 0.9866338803044641, 1.131162351668194, 0.9556497121174351, 0.9766789096028479], 'val_acc': [0.5588029401470074, 0.5558277913895695, 0.4463598179908995, 0.5938046902345118, 0.6244312215610781, 0.5851417570878544, 0.6147182359117956, 0.6528701435071753, 0.6719460973048652, 0.6851592579628981, 0.658470423521176, 0.6645957297864893, 0.6399194959747987, 0.6561078053902695, 0.6028176408820441, 0.6108680434021702, 0.681921596079804, 0.6771088554427721, 0.6623206160308015, 0.6686209310465523, 0.5845292264613231, 0.6805215260763038, 0.6743087154357718], 'final_state_dict_size_bytes': 6000, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0077432758201777824, 'batch_size': 16, 'epochs': 23, 'weight_decay': 3.5463063866518388e-06, 'dropout': 0.003967263143682365, 'channel_multiplier': 4, 'kernel_size1': 34, 'stride1': 11, 'kernel_size2': 43, 'stride2': 6, 'gcn_hidden': 9, 'label_smoothing': 0.07737418761207225, 'grad_clip_norm': 4.234779596118415, 'use_amp': False, 'calibrate_batches': 76, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1436, 'model_storage_size_kb': 6.1703125000000005, 'model_size_validation': 'PASS'}
2025-10-13 11:29:39,410 - INFO - _models.training_function_executor - BO Objective: base=0.6743, size_penalty=0.0000, final=0.6743
2025-10-13 11:29:39,410 - INFO - _models.training_function_executor - Model: 1,436 parameters, 6.2KB (PASS 256KB limit)
2025-10-13 11:29:39,410 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 94.762s
2025-10-13 11:29:39,510 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6743
2025-10-13 11:29:39,510 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.099s
2025-10-13 11:29:39,510 - INFO - bo.run_bo - Recorded observation #20: hparams={'lr': 0.0077432758201777824, 'batch_size': np.int64(16), 'epochs': np.int64(23), 'weight_decay': 3.5463063866518388e-06, 'dropout': 0.003967263143682365, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(34), 'stride1': np.int64(11), 'kernel_size2': np.int64(43), 'stride2': np.int64(6), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.07737418761207225, 'grad_clip_norm': 4.234779596118415, 'use_amp': np.False_, 'calibrate_batches': np.int64(76), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6743
2025-10-13 11:29:39,510 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 20: {'lr': 0.0077432758201777824, 'batch_size': np.int64(16), 'epochs': np.int64(23), 'weight_decay': 3.5463063866518388e-06, 'dropout': 0.003967263143682365, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(34), 'stride1': np.int64(11), 'kernel_size2': np.int64(43), 'stride2': np.int64(6), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.07737418761207225, 'grad_clip_norm': 4.234779596118415, 'use_amp': np.False_, 'calibrate_batches': np.int64(76), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6743
2025-10-13 11:29:39,510 - INFO - bo.run_bo - üîçBO Trial 21: Using RF surrogate + Expected Improvement
2025-10-13 11:29:39,510 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:29:39,510 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 21 (NaN monitoring active)
2025-10-13 11:29:39,510 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:29:39,510 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:29:39,511 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009260130591941782, 'batch_size': 16, 'epochs': 13, 'weight_decay': 0.0002870652098613211, 'dropout': 0.02607187229697137, 'channel_multiplier': 8, 'kernel_size1': 36, 'stride1': 12, 'kernel_size2': 19, 'stride2': 2, 'gcn_hidden': 24, 'label_smoothing': 0.050253186481227306, 'grad_clip_norm': 2.8884055935229225, 'use_amp': False, 'calibrate_batches': 43, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:29:39,512 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009260130591941782, 'batch_size': 16, 'epochs': 13, 'weight_decay': 0.0002870652098613211, 'dropout': 0.02607187229697137, 'channel_multiplier': 8, 'kernel_size1': 36, 'stride1': 12, 'kernel_size2': 19, 'stride2': 2, 'gcn_hidden': 24, 'label_smoothing': 0.050253186481227306, 'grad_clip_norm': 2.8884055935229225, 'use_amp': False, 'calibrate_batches': 43, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:29:46,264 - INFO - _models.training_function_executor - Epoch 001/013 - train_loss: 1.1787 - val_loss: 1.1828 - val_acc: 0.5543
2025-10-13 11:29:50,248 - INFO - _models.training_function_executor - Epoch 002/013 - train_loss: 1.0673 - val_loss: 1.0177 - val_acc: 0.6421
2025-10-13 11:29:54,231 - INFO - _models.training_function_executor - Epoch 003/013 - train_loss: 0.9954 - val_loss: 0.9849 - val_acc: 0.6495
2025-10-13 11:29:58,247 - INFO - _models.training_function_executor - Epoch 004/013 - train_loss: 0.9607 - val_loss: 1.0147 - val_acc: 0.6276
2025-10-13 11:30:02,191 - INFO - _models.training_function_executor - Epoch 005/013 - train_loss: 0.9452 - val_loss: 0.9816 - val_acc: 0.6488
2025-10-13 11:30:06,122 - INFO - _models.training_function_executor - Epoch 006/013 - train_loss: 0.9389 - val_loss: 1.0028 - val_acc: 0.6503
2025-10-13 11:30:10,032 - INFO - _models.training_function_executor - Epoch 007/013 - train_loss: 0.9295 - val_loss: 1.0342 - val_acc: 0.6494
2025-10-13 11:30:13,980 - INFO - _models.training_function_executor - Epoch 008/013 - train_loss: 0.9306 - val_loss: 0.9036 - val_acc: 0.7008
2025-10-13 11:30:17,963 - INFO - _models.training_function_executor - Epoch 009/013 - train_loss: 0.9150 - val_loss: 1.0449 - val_acc: 0.6376
2025-10-13 11:30:21,879 - INFO - _models.training_function_executor - Epoch 010/013 - train_loss: 0.9115 - val_loss: 0.9643 - val_acc: 0.6691
2025-10-13 11:30:25,750 - INFO - _models.training_function_executor - Epoch 011/013 - train_loss: 0.9085 - val_loss: 0.9923 - val_acc: 0.6607
2025-10-13 11:30:29,634 - INFO - _models.training_function_executor - Epoch 012/013 - train_loss: 0.9007 - val_loss: 0.8868 - val_acc: 0.6968
2025-10-13 11:30:33,501 - INFO - _models.training_function_executor - Epoch 013/013 - train_loss: 0.8947 - val_loss: 0.8968 - val_acc: 0.6967
2025-10-13 11:30:34,726 - INFO - _models.training_function_executor - Model: 60 parameters, 0.3KB storage
2025-10-13 11:30:34,726 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.178734449352215, 1.0672981714634866, 0.9954348480968489, 0.9606993280176437, 0.945189353027751, 0.9388753551889392, 0.9295425728917914, 0.930623078068779, 0.9150171018185046, 0.9114822502898969, 0.9085435380479194, 0.9007419272761767, 0.8946708492832999], 'val_losses': [1.182785563715947, 1.0176539045553505, 0.9848722020854556, 1.0147072267690904, 0.9815581808317195, 1.0028052055047114, 1.0342429545028333, 0.9035807300123002, 1.0449336670393872, 0.9643088711655803, 0.992266540807738, 0.8867848528654041, 0.8968023889583018], 'val_acc': [0.5543402170108506, 0.6421071053552677, 0.6495449772488624, 0.6275813790689534, 0.6487574378718935, 0.6503325166258312, 0.6493699684984249, 0.7008225411270563, 0.6376443822191109, 0.6691459572978649, 0.660658032901645, 0.6967973398669933, 0.6967098354917746], 'final_state_dict_size_bytes': 1632, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009260130591941782, 'batch_size': 16, 'epochs': 13, 'weight_decay': 0.0002870652098613211, 'dropout': 0.02607187229697137, 'channel_multiplier': 8, 'kernel_size1': 36, 'stride1': 12, 'kernel_size2': 19, 'stride2': 2, 'gcn_hidden': 24, 'label_smoothing': 0.050253186481227306, 'grad_clip_norm': 2.8884055935229225, 'use_amp': False, 'calibrate_batches': 43, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 60, 'model_storage_size_kb': 0.2578125, 'model_size_validation': 'PASS'}
2025-10-13 11:30:34,726 - INFO - _models.training_function_executor - BO Objective: base=0.6967, size_penalty=0.0000, final=0.6967
2025-10-13 11:30:34,726 - INFO - _models.training_function_executor - Model: 60 parameters, 0.3KB (PASS 256KB limit)
2025-10-13 11:30:34,726 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 55.216s
2025-10-13 11:30:34,825 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6967
2025-10-13 11:30:34,825 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-10-13 11:30:34,825 - INFO - bo.run_bo - Recorded observation #21: hparams={'lr': 0.009260130591941782, 'batch_size': np.int64(16), 'epochs': np.int64(13), 'weight_decay': 0.0002870652098613211, 'dropout': 0.02607187229697137, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(36), 'stride1': np.int64(12), 'kernel_size2': np.int64(19), 'stride2': np.int64(2), 'gcn_hidden': np.int64(24), 'label_smoothing': 0.050253186481227306, 'grad_clip_norm': 2.8884055935229225, 'use_amp': np.False_, 'calibrate_batches': np.int64(43), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.6967
2025-10-13 11:30:34,825 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 21: {'lr': 0.009260130591941782, 'batch_size': np.int64(16), 'epochs': np.int64(13), 'weight_decay': 0.0002870652098613211, 'dropout': 0.02607187229697137, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(36), 'stride1': np.int64(12), 'kernel_size2': np.int64(19), 'stride2': np.int64(2), 'gcn_hidden': np.int64(24), 'label_smoothing': 0.050253186481227306, 'grad_clip_norm': 2.8884055935229225, 'use_amp': np.False_, 'calibrate_batches': np.int64(43), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.6967
2025-10-13 11:30:34,825 - INFO - bo.run_bo - üîçBO Trial 22: Using RF surrogate + Expected Improvement
2025-10-13 11:30:34,825 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:30:34,825 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 22 (NaN monitoring active)
2025-10-13 11:30:34,825 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:30:34,825 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:30:34,825 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007514783428739052, 'batch_size': 32, 'epochs': 14, 'weight_decay': 2.822213005688774e-06, 'dropout': 0.01947530470275263, 'channel_multiplier': 3, 'kernel_size1': 32, 'stride1': 15, 'kernel_size2': 22, 'stride2': 8, 'gcn_hidden': 24, 'label_smoothing': 0.09422310447805304, 'grad_clip_norm': 1.3789741958369675, 'use_amp': True, 'calibrate_batches': 78, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:30:34,826 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007514783428739052, 'batch_size': 32, 'epochs': 14, 'weight_decay': 2.822213005688774e-06, 'dropout': 0.01947530470275263, 'channel_multiplier': 3, 'kernel_size1': 32, 'stride1': 15, 'kernel_size2': 22, 'stride2': 8, 'gcn_hidden': 24, 'label_smoothing': 0.09422310447805304, 'grad_clip_norm': 1.3789741958369675, 'use_amp': True, 'calibrate_batches': 78, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:30:40,001 - INFO - _models.training_function_executor - Epoch 001/014 - train_loss: 1.3474 - val_loss: 1.2900 - val_acc: 0.5228
2025-10-13 11:30:42,368 - INFO - _models.training_function_executor - Epoch 002/014 - train_loss: 1.2046 - val_loss: 1.2204 - val_acc: 0.5435
2025-10-13 11:30:44,765 - INFO - _models.training_function_executor - Epoch 003/014 - train_loss: 1.1764 - val_loss: 1.1367 - val_acc: 0.5884
2025-10-13 11:30:47,134 - INFO - _models.training_function_executor - Epoch 004/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:30:49,500 - INFO - _models.training_function_executor - Epoch 005/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:30:51,903 - INFO - _models.training_function_executor - Epoch 006/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:30:54,311 - INFO - _models.training_function_executor - Epoch 007/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:30:56,717 - INFO - _models.training_function_executor - Epoch 008/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:30:59,096 - INFO - _models.training_function_executor - Epoch 009/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:31:01,486 - INFO - _models.training_function_executor - Epoch 010/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:31:03,886 - INFO - _models.training_function_executor - Epoch 011/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:31:06,277 - INFO - _models.training_function_executor - Epoch 012/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:31:08,532 - INFO - _models.training_function_executor - Epoch 013/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:31:10,727 - INFO - _models.training_function_executor - Epoch 014/014 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:31:11,861 - INFO - _models.training_function_executor - Model: 917 parameters, 3.9KB storage
2025-10-13 11:31:11,861 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.347372881757825, 1.2045962565588626, 1.176356706412305, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.2899726357625254, 1.2203737657137754, 1.1366826826598955, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5227511375568779, 0.5434896744837242, 0.5883794189709486, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'final_state_dict_size_bytes': 1946, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007514783428739052, 'batch_size': 32, 'epochs': 14, 'weight_decay': 2.822213005688774e-06, 'dropout': 0.01947530470275263, 'channel_multiplier': 3, 'kernel_size1': 32, 'stride1': 15, 'kernel_size2': 22, 'stride2': 8, 'gcn_hidden': 24, 'label_smoothing': 0.09422310447805304, 'grad_clip_norm': 1.3789741958369675, 'use_amp': True, 'calibrate_batches': 78, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 917, 'model_storage_size_kb': 3.940234375, 'model_size_validation': 'PASS'}
2025-10-13 11:31:11,861 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-13 11:31:11,861 - INFO - _models.training_function_executor - Model: 917 parameters, 3.9KB (PASS 256KB limit)
2025-10-13 11:31:11,861 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 37.036s
2025-10-13 11:31:11,956 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-13 11:31:11,956 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-13 11:31:11,956 - INFO - bo.run_bo - Recorded observation #22: hparams={'lr': 0.007514783428739052, 'batch_size': np.int64(32), 'epochs': np.int64(14), 'weight_decay': 2.822213005688774e-06, 'dropout': 0.01947530470275263, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(32), 'stride1': np.int64(15), 'kernel_size2': np.int64(22), 'stride2': np.int64(8), 'gcn_hidden': np.int64(24), 'label_smoothing': 0.09422310447805304, 'grad_clip_norm': 1.3789741958369675, 'use_amp': np.True_, 'calibrate_batches': np.int64(78), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.2325
2025-10-13 11:31:11,956 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 22: {'lr': 0.007514783428739052, 'batch_size': np.int64(32), 'epochs': np.int64(14), 'weight_decay': 2.822213005688774e-06, 'dropout': 0.01947530470275263, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(32), 'stride1': np.int64(15), 'kernel_size2': np.int64(22), 'stride2': np.int64(8), 'gcn_hidden': np.int64(24), 'label_smoothing': 0.09422310447805304, 'grad_clip_norm': 1.3789741958369675, 'use_amp': np.True_, 'calibrate_batches': np.int64(78), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.2325
2025-10-13 11:31:11,957 - INFO - bo.run_bo - üîçBO Trial 23: Using RF surrogate + Expected Improvement
2025-10-13 11:31:11,957 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:31:11,957 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 23 (NaN monitoring active)
2025-10-13 11:31:11,957 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:31:11,957 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:31:11,957 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009589984050958502, 'batch_size': 48, 'epochs': 48, 'weight_decay': 8.130211990887778e-05, 'dropout': 0.02907266029049916, 'channel_multiplier': 7, 'kernel_size1': 46, 'stride1': 15, 'kernel_size2': 40, 'stride2': 3, 'gcn_hidden': 24, 'label_smoothing': 0.020332436993392804, 'grad_clip_norm': 3.7136215066311786, 'use_amp': False, 'calibrate_batches': 20, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:31:11,958 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009589984050958502, 'batch_size': 48, 'epochs': 48, 'weight_decay': 8.130211990887778e-05, 'dropout': 0.02907266029049916, 'channel_multiplier': 7, 'kernel_size1': 46, 'stride1': 15, 'kernel_size2': 40, 'stride2': 3, 'gcn_hidden': 24, 'label_smoothing': 0.020332436993392804, 'grad_clip_norm': 3.7136215066311786, 'use_amp': False, 'calibrate_batches': 20, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:31:16,451 - INFO - _models.training_function_executor - Epoch 001/048 - train_loss: 1.1660 - val_loss: 1.0796 - val_acc: 0.5676
2025-10-13 11:31:18,186 - INFO - _models.training_function_executor - Epoch 002/048 - train_loss: 1.0376 - val_loss: 1.0422 - val_acc: 0.5846
2025-10-13 11:31:19,931 - INFO - _models.training_function_executor - Epoch 003/048 - train_loss: 0.9912 - val_loss: 0.9642 - val_acc: 0.6193
2025-10-13 11:31:21,648 - INFO - _models.training_function_executor - Epoch 004/048 - train_loss: 0.9612 - val_loss: 1.0565 - val_acc: 0.5886
2025-10-13 11:31:23,370 - INFO - _models.training_function_executor - Epoch 005/048 - train_loss: 0.9325 - val_loss: 1.0286 - val_acc: 0.5836
2025-10-13 11:31:25,093 - INFO - _models.training_function_executor - Epoch 006/048 - train_loss: 0.9151 - val_loss: 1.0314 - val_acc: 0.5890
2025-10-13 11:31:26,823 - INFO - _models.training_function_executor - Epoch 007/048 - train_loss: 0.9039 - val_loss: 1.3444 - val_acc: 0.4999
2025-10-13 11:31:28,561 - INFO - _models.training_function_executor - Epoch 008/048 - train_loss: 0.8935 - val_loss: 0.9245 - val_acc: 0.6400
2025-10-13 11:31:30,290 - INFO - _models.training_function_executor - Epoch 009/048 - train_loss: 0.8862 - val_loss: 0.9797 - val_acc: 0.6448
2025-10-13 11:31:32,016 - INFO - _models.training_function_executor - Epoch 010/048 - train_loss: 0.8804 - val_loss: 0.9183 - val_acc: 0.6421
2025-10-13 11:31:33,737 - INFO - _models.training_function_executor - Epoch 011/048 - train_loss: 0.8730 - val_loss: 0.8434 - val_acc: 0.6791
2025-10-13 11:31:35,462 - INFO - _models.training_function_executor - Epoch 012/048 - train_loss: 0.8624 - val_loss: 1.2961 - val_acc: 0.5641
2025-10-13 11:31:37,190 - INFO - _models.training_function_executor - Epoch 013/048 - train_loss: 0.8594 - val_loss: 0.9171 - val_acc: 0.6475
2025-10-13 11:31:38,921 - INFO - _models.training_function_executor - Epoch 014/048 - train_loss: 0.8494 - val_loss: 1.0010 - val_acc: 0.6082
2025-10-13 11:31:40,643 - INFO - _models.training_function_executor - Epoch 015/048 - train_loss: 0.8408 - val_loss: 1.0869 - val_acc: 0.5803
2025-10-13 11:31:42,383 - INFO - _models.training_function_executor - Epoch 016/048 - train_loss: 0.8249 - val_loss: 1.4055 - val_acc: 0.5117
2025-10-13 11:31:44,116 - INFO - _models.training_function_executor - Epoch 017/048 - train_loss: 0.8202 - val_loss: 1.2957 - val_acc: 0.5494
2025-10-13 11:31:45,854 - INFO - _models.training_function_executor - Epoch 018/048 - train_loss: 0.8157 - val_loss: 1.6498 - val_acc: 0.5264
2025-10-13 11:31:47,584 - INFO - _models.training_function_executor - Epoch 019/048 - train_loss: 0.8144 - val_loss: 0.8677 - val_acc: 0.6733
2025-10-13 11:31:49,325 - INFO - _models.training_function_executor - Epoch 020/048 - train_loss: 0.8143 - val_loss: 1.4290 - val_acc: 0.4295
2025-10-13 11:31:51,049 - INFO - _models.training_function_executor - Epoch 021/048 - train_loss: 0.8062 - val_loss: 0.9220 - val_acc: 0.6565
2025-10-13 11:31:52,793 - INFO - _models.training_function_executor - Epoch 022/048 - train_loss: 0.8095 - val_loss: 0.9055 - val_acc: 0.6461
2025-10-13 11:31:54,519 - INFO - _models.training_function_executor - Epoch 023/048 - train_loss: 0.8010 - val_loss: 0.9125 - val_acc: 0.6600
2025-10-13 11:31:56,248 - INFO - _models.training_function_executor - Epoch 024/048 - train_loss: 0.8019 - val_loss: 1.2834 - val_acc: 0.6418
2025-10-13 11:31:57,975 - INFO - _models.training_function_executor - Epoch 025/048 - train_loss: 0.8006 - val_loss: 0.8521 - val_acc: 0.6847
2025-10-13 11:31:59,720 - INFO - _models.training_function_executor - Epoch 026/048 - train_loss: 0.7971 - val_loss: 0.8848 - val_acc: 0.6435
2025-10-13 11:32:01,467 - INFO - _models.training_function_executor - Epoch 027/048 - train_loss: 0.7994 - val_loss: 1.2473 - val_acc: 0.5724
2025-10-13 11:32:03,188 - INFO - _models.training_function_executor - Epoch 028/048 - train_loss: 0.7973 - val_loss: 0.9398 - val_acc: 0.6596
2025-10-13 11:32:04,912 - INFO - _models.training_function_executor - Epoch 029/048 - train_loss: 0.7912 - val_loss: 1.5866 - val_acc: 0.6185
2025-10-13 11:32:06,654 - INFO - _models.training_function_executor - Epoch 030/048 - train_loss: 0.7954 - val_loss: 0.7879 - val_acc: 0.7127
2025-10-13 11:32:08,375 - INFO - _models.training_function_executor - Epoch 031/048 - train_loss: 0.7943 - val_loss: 0.7699 - val_acc: 0.7215
2025-10-13 11:32:10,120 - INFO - _models.training_function_executor - Epoch 032/048 - train_loss: 0.7844 - val_loss: 0.9522 - val_acc: 0.6422
2025-10-13 11:32:11,851 - INFO - _models.training_function_executor - Epoch 033/048 - train_loss: 0.7858 - val_loss: 0.8392 - val_acc: 0.6885
2025-10-13 11:32:13,575 - INFO - _models.training_function_executor - Epoch 034/048 - train_loss: 0.7878 - val_loss: 1.1386 - val_acc: 0.6048
2025-10-13 11:32:15,298 - INFO - _models.training_function_executor - Epoch 035/048 - train_loss: 0.7848 - val_loss: 2.0629 - val_acc: 0.5663
2025-10-13 11:32:17,038 - INFO - _models.training_function_executor - Epoch 036/048 - train_loss: 0.7850 - val_loss: 0.9004 - val_acc: 0.6503
2025-10-13 11:32:18,761 - INFO - _models.training_function_executor - Epoch 037/048 - train_loss: 0.7827 - val_loss: 0.8726 - val_acc: 0.6619
2025-10-13 11:32:20,477 - INFO - _models.training_function_executor - Epoch 038/048 - train_loss: 0.7853 - val_loss: 1.4789 - val_acc: 0.5798
2025-10-13 11:32:22,192 - INFO - _models.training_function_executor - Epoch 039/048 - train_loss: 0.7775 - val_loss: 1.2558 - val_acc: 0.5988
2025-10-13 11:32:23,905 - INFO - _models.training_function_executor - Epoch 040/048 - train_loss: 0.7852 - val_loss: 0.8089 - val_acc: 0.6987
2025-10-13 11:32:25,633 - INFO - _models.training_function_executor - Epoch 041/048 - train_loss: 0.7814 - val_loss: 2.2670 - val_acc: 0.5618
2025-10-13 11:32:27,365 - INFO - _models.training_function_executor - Epoch 042/048 - train_loss: 0.7857 - val_loss: 1.0059 - val_acc: 0.6372
2025-10-13 11:32:29,100 - INFO - _models.training_function_executor - Epoch 043/048 - train_loss: 0.7782 - val_loss: 0.8124 - val_acc: 0.7017
2025-10-13 11:32:30,833 - INFO - _models.training_function_executor - Epoch 044/048 - train_loss: 0.7779 - val_loss: 1.0952 - val_acc: 0.6327
2025-10-13 11:32:32,557 - INFO - _models.training_function_executor - Epoch 045/048 - train_loss: 0.7796 - val_loss: 0.8698 - val_acc: 0.6761
2025-10-13 11:32:34,295 - INFO - _models.training_function_executor - Epoch 046/048 - train_loss: 0.7745 - val_loss: 0.8197 - val_acc: 0.6853
2025-10-13 11:32:36,018 - INFO - _models.training_function_executor - Epoch 047/048 - train_loss: 0.7766 - val_loss: 0.7672 - val_acc: 0.7247
2025-10-13 11:32:37,739 - INFO - _models.training_function_executor - Epoch 048/048 - train_loss: 0.7732 - val_loss: 1.3128 - val_acc: 0.5817
2025-10-13 11:32:38,968 - INFO - _models.training_function_executor - Model: 60 parameters, 0.3KB storage
2025-10-13 11:32:38,968 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1660063546939792, 1.0376352932138546, 0.9911711889002596, 0.9612043019062079, 0.9324698297969937, 0.9150646895138917, 0.9038736928289571, 0.8935014261705374, 0.8861918408093771, 0.880415402052909, 0.8729867036938459, 0.8624035146297339, 0.8593811158079094, 0.8493622031752613, 0.8407977353162102, 0.82493574253362, 0.820200307347535, 0.8157409159065669, 0.8143751267415476, 0.8143397742607896, 0.8061719749371906, 0.8095247082706928, 0.8009816799958269, 0.8018853392453306, 0.8006350298444416, 0.7970993613337235, 0.799415010190903, 0.7973089671902694, 0.7911533308083418, 0.7954424595056734, 0.7943128785512895, 0.7843923306064585, 0.7857991777018813, 0.7877872949156429, 0.7847997116320693, 0.7850062088362186, 0.7826610028764607, 0.7853301532063236, 0.7774988433093845, 0.7851525953402668, 0.7814337309524234, 0.7856866291635805, 0.7781954996436469, 0.7778628248725273, 0.7796035602996514, 0.7744754421093433, 0.776608648659426, 0.7732023750104227], 'val_losses': [1.0796392854377446, 1.0421727504561655, 0.9642427078610247, 1.0564931599794254, 1.0285830109278806, 1.0314025735996968, 1.3443887656829054, 0.9244583253056009, 0.9797439437918952, 0.9182887650637682, 0.843446769412264, 1.2961295996882258, 0.9170890415636943, 1.001020781990528, 1.086923238798835, 1.4054853733828487, 1.2956868896836538, 1.6497974118278458, 0.8676911002695873, 1.4290038119841173, 0.9220427022265687, 0.9055190724553784, 0.9124827385157357, 1.2834136380071108, 0.8520566112184842, 0.884820444791685, 1.2472856850485556, 0.9397561257437137, 1.5866317296720778, 0.7879370143040519, 0.7699009368041616, 0.9522065570356966, 0.8391910630545918, 1.1386250271261427, 2.0629008695258935, 0.9004020370676002, 0.872598003727763, 1.4789360120532644, 1.2558173678285975, 0.8088941633555286, 2.2669765397014423, 1.0059096957988827, 0.8124082824505414, 1.095217727221181, 0.8698202733564594, 0.8196538640437194, 0.7671587119934481, 1.3127971899271595], 'val_acc': [0.5675533776688835, 0.5846167308365419, 0.6192684634231712, 0.5885544277213861, 0.5835666783339167, 0.5889919495974799, 0.49991249562478124, 0.6400070003500175, 0.6448197409870493, 0.6421071053552677, 0.6791214560728036, 0.564053202660133, 0.6475323766188309, 0.6082429121456073, 0.5803290164508226, 0.511725586279314, 0.5493524676233812, 0.5264263213160658, 0.6732586629331466, 0.4294714735736787, 0.6564578228911445, 0.6461323066153307, 0.6600455022751137, 0.6417570878543927, 0.6847217360868043, 0.6435071753587679, 0.5723661183059153, 0.6596079803990199, 0.6184809240462024, 0.7127231361568078, 0.7214735736786839, 0.6421946097304865, 0.688484424221211, 0.6048302415120757, 0.5663283164158208, 0.6503325166258312, 0.6618830941547077, 0.57980399019951, 0.5987924396219811, 0.6987224361218061, 0.5617780889044452, 0.6372068603430171, 0.7016975848792439, 0.6326566328316415, 0.6761463073153657, 0.6853342667133356, 0.7247112355617781, 0.5817290864543228], 'final_state_dict_size_bytes': 2436, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009589984050958502, 'batch_size': 48, 'epochs': 48, 'weight_decay': 8.130211990887778e-05, 'dropout': 0.02907266029049916, 'channel_multiplier': 7, 'kernel_size1': 46, 'stride1': 15, 'kernel_size2': 40, 'stride2': 3, 'gcn_hidden': 24, 'label_smoothing': 0.020332436993392804, 'grad_clip_norm': 3.7136215066311786, 'use_amp': False, 'calibrate_batches': 20, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 60, 'model_storage_size_kb': 0.2578125, 'model_size_validation': 'PASS'}
2025-10-13 11:32:38,968 - INFO - _models.training_function_executor - BO Objective: base=0.5817, size_penalty=0.0000, final=0.5817
2025-10-13 11:32:38,968 - INFO - _models.training_function_executor - Model: 60 parameters, 0.3KB (PASS 256KB limit)
2025-10-13 11:32:38,968 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 87.011s
2025-10-13 11:32:39,065 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5817
2025-10-13 11:32:39,065 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.097s
2025-10-13 11:32:39,065 - INFO - bo.run_bo - Recorded observation #23: hparams={'lr': 0.009589984050958502, 'batch_size': np.int64(48), 'epochs': np.int64(48), 'weight_decay': 8.130211990887778e-05, 'dropout': 0.02907266029049916, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(46), 'stride1': np.int64(15), 'kernel_size2': np.int64(40), 'stride2': np.int64(3), 'gcn_hidden': np.int64(24), 'label_smoothing': 0.020332436993392804, 'grad_clip_norm': 3.7136215066311786, 'use_amp': np.False_, 'calibrate_batches': np.int64(20), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.5817
2025-10-13 11:32:39,065 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 23: {'lr': 0.009589984050958502, 'batch_size': np.int64(48), 'epochs': np.int64(48), 'weight_decay': 8.130211990887778e-05, 'dropout': 0.02907266029049916, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(46), 'stride1': np.int64(15), 'kernel_size2': np.int64(40), 'stride2': np.int64(3), 'gcn_hidden': np.int64(24), 'label_smoothing': 0.020332436993392804, 'grad_clip_norm': 3.7136215066311786, 'use_amp': np.False_, 'calibrate_batches': np.int64(20), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.5817
2025-10-13 11:32:39,065 - INFO - bo.run_bo - üîçBO Trial 24: Using RF surrogate + Expected Improvement
2025-10-13 11:32:39,065 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:32:39,066 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 24 (NaN monitoring active)
2025-10-13 11:32:39,066 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:32:39,066 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:32:39,066 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009214310660721994, 'batch_size': 128, 'epochs': 35, 'weight_decay': 5.758100135236693e-05, 'dropout': 0.019031091568823037, 'channel_multiplier': 4, 'kernel_size1': 86, 'stride1': 8, 'kernel_size2': 19, 'stride2': 4, 'gcn_hidden': 16, 'label_smoothing': 0.054880147519057086, 'grad_clip_norm': 4.634304089397337, 'use_amp': False, 'calibrate_batches': 117, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:32:39,067 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009214310660721994, 'batch_size': 128, 'epochs': 35, 'weight_decay': 5.758100135236693e-05, 'dropout': 0.019031091568823037, 'channel_multiplier': 4, 'kernel_size1': 86, 'stride1': 8, 'kernel_size2': 19, 'stride2': 4, 'gcn_hidden': 16, 'label_smoothing': 0.054880147519057086, 'grad_clip_norm': 4.634304089397337, 'use_amp': False, 'calibrate_batches': 117, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:32:43,374 - INFO - _models.training_function_executor - Epoch 001/035 - train_loss: 1.3571 - val_loss: 1.2771 - val_acc: 0.4986
2025-10-13 11:32:44,902 - INFO - _models.training_function_executor - Epoch 002/035 - train_loss: 1.1796 - val_loss: 1.4235 - val_acc: 0.4502
2025-10-13 11:32:46,436 - INFO - _models.training_function_executor - Epoch 003/035 - train_loss: 1.1039 - val_loss: 1.1085 - val_acc: 0.6159
2025-10-13 11:32:47,938 - INFO - _models.training_function_executor - Epoch 004/035 - train_loss: 1.0836 - val_loss: 1.0843 - val_acc: 0.6344
2025-10-13 11:32:49,438 - INFO - _models.training_function_executor - Epoch 005/035 - train_loss: 1.0620 - val_loss: 1.1494 - val_acc: 0.5396
2025-10-13 11:32:50,952 - INFO - _models.training_function_executor - Epoch 006/035 - train_loss: 1.0522 - val_loss: 1.0911 - val_acc: 0.6022
2025-10-13 11:32:52,472 - INFO - _models.training_function_executor - Epoch 007/035 - train_loss: 1.0458 - val_loss: 1.0599 - val_acc: 0.6067
2025-10-13 11:32:53,985 - INFO - _models.training_function_executor - Epoch 008/035 - train_loss: 1.0367 - val_loss: 1.1346 - val_acc: 0.5748
2025-10-13 11:32:55,511 - INFO - _models.training_function_executor - Epoch 009/035 - train_loss: 1.0365 - val_loss: 1.0874 - val_acc: 0.5932
2025-10-13 11:32:57,029 - INFO - _models.training_function_executor - Epoch 010/035 - train_loss: 1.0310 - val_loss: 1.0882 - val_acc: 0.6029
2025-10-13 11:32:58,558 - INFO - _models.training_function_executor - Epoch 011/035 - train_loss: 1.0237 - val_loss: 1.0453 - val_acc: 0.6177
2025-10-13 11:33:00,081 - INFO - _models.training_function_executor - Epoch 012/035 - train_loss: 1.0191 - val_loss: 1.0081 - val_acc: 0.6445
2025-10-13 11:33:01,596 - INFO - _models.training_function_executor - Epoch 013/035 - train_loss: 1.0193 - val_loss: 0.9969 - val_acc: 0.6551
2025-10-13 11:33:03,140 - INFO - _models.training_function_executor - Epoch 014/035 - train_loss: 1.0095 - val_loss: 1.0385 - val_acc: 0.6229
2025-10-13 11:33:04,665 - INFO - _models.training_function_executor - Epoch 015/035 - train_loss: 1.0014 - val_loss: 0.9914 - val_acc: 0.6403
2025-10-13 11:33:06,196 - INFO - _models.training_function_executor - Epoch 016/035 - train_loss: 0.9986 - val_loss: 1.0336 - val_acc: 0.6294
2025-10-13 11:33:07,723 - INFO - _models.training_function_executor - Epoch 017/035 - train_loss: 0.9899 - val_loss: 1.0190 - val_acc: 0.6320
2025-10-13 11:33:09,241 - INFO - _models.training_function_executor - Epoch 018/035 - train_loss: 0.9848 - val_loss: 1.0275 - val_acc: 0.6372
2025-10-13 11:33:10,764 - INFO - _models.training_function_executor - Epoch 019/035 - train_loss: 0.9821 - val_loss: 0.9825 - val_acc: 0.6496
2025-10-13 11:33:12,298 - INFO - _models.training_function_executor - Epoch 020/035 - train_loss: 0.9711 - val_loss: 1.0645 - val_acc: 0.6273
2025-10-13 11:33:13,826 - INFO - _models.training_function_executor - Epoch 021/035 - train_loss: 0.9724 - val_loss: 0.9803 - val_acc: 0.6588
2025-10-13 11:33:15,368 - INFO - _models.training_function_executor - Epoch 022/035 - train_loss: 0.9632 - val_loss: 0.9590 - val_acc: 0.6655
2025-10-13 11:33:16,900 - INFO - _models.training_function_executor - Epoch 023/035 - train_loss: 0.9594 - val_loss: 0.9956 - val_acc: 0.6512
2025-10-13 11:33:18,442 - INFO - _models.training_function_executor - Epoch 024/035 - train_loss: 0.9507 - val_loss: 0.9772 - val_acc: 0.6502
2025-10-13 11:33:19,989 - INFO - _models.training_function_executor - Epoch 025/035 - train_loss: 0.9497 - val_loss: 0.9397 - val_acc: 0.6722
2025-10-13 11:33:21,539 - INFO - _models.training_function_executor - Epoch 026/035 - train_loss: 0.9471 - val_loss: 0.9359 - val_acc: 0.6768
2025-10-13 11:33:23,101 - INFO - _models.training_function_executor - Epoch 027/035 - train_loss: 0.9355 - val_loss: 1.0422 - val_acc: 0.6194
2025-10-13 11:33:24,609 - INFO - _models.training_function_executor - Epoch 028/035 - train_loss: 0.9393 - val_loss: 0.9351 - val_acc: 0.6798
2025-10-13 11:33:26,129 - INFO - _models.training_function_executor - Epoch 029/035 - train_loss: 0.9337 - val_loss: 0.9065 - val_acc: 0.6903
2025-10-13 11:33:27,680 - INFO - _models.training_function_executor - Epoch 030/035 - train_loss: 0.9279 - val_loss: 0.9026 - val_acc: 0.6964
2025-10-13 11:33:29,226 - INFO - _models.training_function_executor - Epoch 031/035 - train_loss: 0.9285 - val_loss: 0.9110 - val_acc: 0.6871
2025-10-13 11:33:30,780 - INFO - _models.training_function_executor - Epoch 032/035 - train_loss: 0.9257 - val_loss: 0.9157 - val_acc: 0.6902
2025-10-13 11:33:32,303 - INFO - _models.training_function_executor - Epoch 033/035 - train_loss: 0.9188 - val_loss: 0.9158 - val_acc: 0.6894
2025-10-13 11:33:33,847 - INFO - _models.training_function_executor - Epoch 034/035 - train_loss: 0.9142 - val_loss: 0.9358 - val_acc: 0.6840
2025-10-13 11:33:35,343 - INFO - _models.training_function_executor - Epoch 035/035 - train_loss: 0.9046 - val_loss: 1.0437 - val_acc: 0.5974
2025-10-13 11:33:36,456 - INFO - _models.training_function_executor - Model: 1,249 parameters, 5.4KB storage
2025-10-13 11:33:36,456 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3571159866334344, 1.1795954096972379, 1.1038533136232942, 1.0835690030193763, 1.062004616763736, 1.0521999887123281, 1.0458270817066682, 1.0366516775045105, 1.0365058367052902, 1.0309706370147076, 1.0236702821953212, 1.019105623433504, 1.0192508291104978, 1.0095490281883135, 1.0013744934355415, 0.998626609135642, 0.9898958132740163, 0.9848242416471963, 0.9821101687444354, 0.9710577150137223, 0.9723913170551144, 0.9632126788263518, 0.9593581605883883, 0.950722609777988, 0.9496615185034956, 0.9470676193297389, 0.9355179154459814, 0.9393355907324022, 0.9337449599530758, 0.9278537975268887, 0.9284569891257681, 0.9257461639981108, 0.9187538621932174, 0.9141552104455923, 0.9046336263053101], 'val_losses': [1.2771456555799459, 1.4234771922955698, 1.1085165650601732, 1.0843414783394332, 1.1494183730611778, 1.091109794130015, 1.0599322598590524, 1.1345710184009166, 1.0874007190905295, 1.088183244709206, 1.045345325882217, 1.0081180463856987, 0.996927878678909, 1.0384640170846071, 0.9913840437002185, 1.0335981926385613, 1.0190443400114952, 1.0274730400059413, 0.9825235230546336, 1.0644892923140135, 0.9802895222337754, 0.9589730865019871, 0.9955701850117359, 0.9771633402300666, 0.9397182704103048, 0.9359451021228505, 1.042190060066434, 0.9350842373914389, 0.9065223298875611, 0.9025972171141878, 0.9110165630389979, 0.9157436994726857, 0.9158465738349917, 0.935838165506851, 1.0436601600823887], 'val_acc': [0.4985999299964998, 0.450210010500525, 0.6158557927896395, 0.6344067203360167, 0.53955197759888, 0.6022051102555128, 0.6066678333916696, 0.5748162408120406, 0.5931921596079804, 0.6029051452572629, 0.6176933846692335, 0.6444697234861743, 0.6551452572628631, 0.6229436471823592, 0.6402695134756737, 0.6294189709485474, 0.6320441022051102, 0.6372068603430171, 0.6496324816240812, 0.6273188659432971, 0.6588204410220511, 0.6654707735386769, 0.6512075603780189, 0.6501575078753937, 0.6722086104305215, 0.6768463423171158, 0.6194434721736087, 0.6798214910745537, 0.690322016100805, 0.6964473223661183, 0.6870843542177109, 0.6902345117255863, 0.6893594679733986, 0.6840217010850542, 0.597392369618481], 'final_state_dict_size_bytes': 2634, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009214310660721994, 'batch_size': 128, 'epochs': 35, 'weight_decay': 5.758100135236693e-05, 'dropout': 0.019031091568823037, 'channel_multiplier': 4, 'kernel_size1': 86, 'stride1': 8, 'kernel_size2': 19, 'stride2': 4, 'gcn_hidden': 16, 'label_smoothing': 0.054880147519057086, 'grad_clip_norm': 4.634304089397337, 'use_amp': False, 'calibrate_batches': 117, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 1249, 'model_storage_size_kb': 5.366796875, 'model_size_validation': 'PASS'}
2025-10-13 11:33:36,456 - INFO - _models.training_function_executor - BO Objective: base=0.5974, size_penalty=0.0000, final=0.5974
2025-10-13 11:33:36,456 - INFO - _models.training_function_executor - Model: 1,249 parameters, 5.4KB (PASS 256KB limit)
2025-10-13 11:33:36,456 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 57.390s
2025-10-13 11:33:36,579 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5974
2025-10-13 11:33:36,579 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.122s
2025-10-13 11:33:36,579 - INFO - bo.run_bo - Recorded observation #24: hparams={'lr': 0.009214310660721994, 'batch_size': np.int64(128), 'epochs': np.int64(35), 'weight_decay': 5.758100135236693e-05, 'dropout': 0.019031091568823037, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(86), 'stride1': np.int64(8), 'kernel_size2': np.int64(19), 'stride2': np.int64(4), 'gcn_hidden': np.int64(16), 'label_smoothing': 0.054880147519057086, 'grad_clip_norm': 4.634304089397337, 'use_amp': np.False_, 'calibrate_batches': np.int64(117), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.5974
2025-10-13 11:33:36,579 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 24: {'lr': 0.009214310660721994, 'batch_size': np.int64(128), 'epochs': np.int64(35), 'weight_decay': 5.758100135236693e-05, 'dropout': 0.019031091568823037, 'channel_multiplier': np.int64(4), 'kernel_size1': np.int64(86), 'stride1': np.int64(8), 'kernel_size2': np.int64(19), 'stride2': np.int64(4), 'gcn_hidden': np.int64(16), 'label_smoothing': 0.054880147519057086, 'grad_clip_norm': 4.634304089397337, 'use_amp': np.False_, 'calibrate_batches': np.int64(117), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.5974
2025-10-13 11:33:36,579 - INFO - bo.run_bo - üîçBO Trial 25: Using RF surrogate + Expected Improvement
2025-10-13 11:33:36,579 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:33:36,580 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 25 (NaN monitoring active)
2025-10-13 11:33:36,580 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:33:36,580 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:33:36,580 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009609673364936504, 'batch_size': 48, 'epochs': 21, 'weight_decay': 2.153388071072438e-06, 'dropout': 0.0026150007171443783, 'channel_multiplier': 5, 'kernel_size1': 127, 'stride1': 8, 'kernel_size2': 39, 'stride2': 6, 'gcn_hidden': 12, 'label_smoothing': 0.17220115298076819, 'grad_clip_norm': 2.700996203158019, 'use_amp': False, 'calibrate_batches': 28, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:33:36,581 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009609673364936504, 'batch_size': 48, 'epochs': 21, 'weight_decay': 2.153388071072438e-06, 'dropout': 0.0026150007171443783, 'channel_multiplier': 5, 'kernel_size1': 127, 'stride1': 8, 'kernel_size2': 39, 'stride2': 6, 'gcn_hidden': 12, 'label_smoothing': 0.17220115298076819, 'grad_clip_norm': 2.700996203158019, 'use_amp': False, 'calibrate_batches': 28, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:33:41,264 - INFO - _models.training_function_executor - Epoch 001/021 - train_loss: 1.2888 - val_loss: 1.2427 - val_acc: 0.6015
2025-10-13 11:33:43,163 - INFO - _models.training_function_executor - Epoch 002/021 - train_loss: 1.2098 - val_loss: 1.3441 - val_acc: 0.4967
2025-10-13 11:33:45,059 - INFO - _models.training_function_executor - Epoch 003/021 - train_loss: 1.1922 - val_loss: 1.2127 - val_acc: 0.5956
2025-10-13 11:33:46,953 - INFO - _models.training_function_executor - Epoch 004/021 - train_loss: 1.1724 - val_loss: 1.2437 - val_acc: 0.5753
2025-10-13 11:33:48,849 - INFO - _models.training_function_executor - Epoch 005/021 - train_loss: 1.1583 - val_loss: 1.1898 - val_acc: 0.6219
2025-10-13 11:33:50,729 - INFO - _models.training_function_executor - Epoch 006/021 - train_loss: 1.1505 - val_loss: 1.1322 - val_acc: 0.6774
2025-10-13 11:33:52,625 - INFO - _models.training_function_executor - Epoch 007/021 - train_loss: 1.1423 - val_loss: 1.1384 - val_acc: 0.6647
2025-10-13 11:33:54,513 - INFO - _models.training_function_executor - Epoch 008/021 - train_loss: 1.1367 - val_loss: 1.1320 - val_acc: 0.6656
2025-10-13 11:33:56,383 - INFO - _models.training_function_executor - Epoch 009/021 - train_loss: 1.1274 - val_loss: 1.1222 - val_acc: 0.6968
2025-10-13 11:33:58,294 - INFO - _models.training_function_executor - Epoch 010/021 - train_loss: 1.1262 - val_loss: 1.1197 - val_acc: 0.6964
2025-10-13 11:34:00,186 - INFO - _models.training_function_executor - Epoch 011/021 - train_loss: 1.1151 - val_loss: 1.1956 - val_acc: 0.6283
2025-10-13 11:34:02,045 - INFO - _models.training_function_executor - Epoch 012/021 - train_loss: 1.1108 - val_loss: 1.2746 - val_acc: 0.5378
2025-10-13 11:34:03,945 - INFO - _models.training_function_executor - Epoch 013/021 - train_loss: 1.1052 - val_loss: 1.1848 - val_acc: 0.6434
2025-10-13 11:34:05,862 - INFO - _models.training_function_executor - Epoch 014/021 - train_loss: 1.1023 - val_loss: 1.2662 - val_acc: 0.6403
2025-10-13 11:34:07,743 - INFO - _models.training_function_executor - Epoch 015/021 - train_loss: 1.1001 - val_loss: 1.0861 - val_acc: 0.7006
2025-10-13 11:34:09,638 - INFO - _models.training_function_executor - Epoch 016/021 - train_loss: 1.0904 - val_loss: 1.2035 - val_acc: 0.6426
2025-10-13 11:34:11,528 - INFO - _models.training_function_executor - Epoch 017/021 - train_loss: 1.0895 - val_loss: 1.1399 - val_acc: 0.6681
2025-10-13 11:34:13,417 - INFO - _models.training_function_executor - Epoch 018/021 - train_loss: 1.0871 - val_loss: 1.1176 - val_acc: 0.6769
2025-10-13 11:34:15,314 - INFO - _models.training_function_executor - Epoch 019/021 - train_loss: 1.0833 - val_loss: 1.1534 - val_acc: 0.6546
2025-10-13 11:34:17,198 - INFO - _models.training_function_executor - Epoch 020/021 - train_loss: 1.0794 - val_loss: 1.1795 - val_acc: 0.6327
2025-10-13 11:34:19,087 - INFO - _models.training_function_executor - Epoch 021/021 - train_loss: 1.0756 - val_loss: 1.2991 - val_acc: 0.5633
2025-10-13 11:34:20,186 - INFO - _models.training_function_executor - Model: 2,189 parameters, 9.4KB storage
2025-10-13 11:34:20,186 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2888071751068804, 1.2097636604793096, 1.1921778591437735, 1.1724036352426637, 1.1582723989284744, 1.1504988441068391, 1.1423228388279938, 1.1366517558396594, 1.1274470962508392, 1.1261504055905434, 1.1151297505101334, 1.1107722950599224, 1.1051852172139562, 1.1022939609613376, 1.1001133246775645, 1.0904159840479322, 1.0895485696276876, 1.0871166310236928, 1.0832848173361123, 1.079439663098415, 1.0755817757480663], 'val_losses': [1.242748788177529, 1.3441002270872457, 1.2127191003152529, 1.2436908050396245, 1.1897550217121433, 1.1321857206296537, 1.1383886154106042, 1.1319694583299988, 1.1222305387561038, 1.1196542597334411, 1.195590605884321, 1.2746183155172974, 1.1848200037214862, 1.2662010137585022, 1.0860562669592468, 1.2035231059107447, 1.1399220100515657, 1.117640312564177, 1.1534073595237933, 1.1795220168520615, 1.299082181901835], 'val_acc': [0.6015050752537627, 0.4966748337416871, 0.5956422821141057, 0.5752537626881344, 0.621893594679734, 0.6773713685684284, 0.664683234161708, 0.6655582779138957, 0.6967973398669933, 0.6964473223661183, 0.6282814140707035, 0.5378018900945047, 0.6434196709835491, 0.6402695134756737, 0.7005600280014, 0.6426321316065803, 0.6680959047952397, 0.6769338466923346, 0.6546202310115505, 0.6327441372068603, 0.5632656632831642], 'final_state_dict_size_bytes': 4538, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009609673364936504, 'batch_size': 48, 'epochs': 21, 'weight_decay': 2.153388071072438e-06, 'dropout': 0.0026150007171443783, 'channel_multiplier': 5, 'kernel_size1': 127, 'stride1': 8, 'kernel_size2': 39, 'stride2': 6, 'gcn_hidden': 12, 'label_smoothing': 0.17220115298076819, 'grad_clip_norm': 2.700996203158019, 'use_amp': False, 'calibrate_batches': 28, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 2189, 'model_storage_size_kb': 9.405859375, 'model_size_validation': 'PASS'}
2025-10-13 11:34:20,186 - INFO - _models.training_function_executor - BO Objective: base=0.5633, size_penalty=0.0000, final=0.5633
2025-10-13 11:34:20,186 - INFO - _models.training_function_executor - Model: 2,189 parameters, 9.4KB (PASS 256KB limit)
2025-10-13 11:34:20,186 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 43.607s
2025-10-13 11:34:20,283 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5633
2025-10-13 11:34:20,283 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.097s
2025-10-13 11:34:20,283 - INFO - bo.run_bo - Recorded observation #25: hparams={'lr': 0.009609673364936504, 'batch_size': np.int64(48), 'epochs': np.int64(21), 'weight_decay': 2.153388071072438e-06, 'dropout': 0.0026150007171443783, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(127), 'stride1': np.int64(8), 'kernel_size2': np.int64(39), 'stride2': np.int64(6), 'gcn_hidden': np.int64(12), 'label_smoothing': 0.17220115298076819, 'grad_clip_norm': 2.700996203158019, 'use_amp': np.False_, 'calibrate_batches': np.int64(28), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.5633
2025-10-13 11:34:20,283 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 25: {'lr': 0.009609673364936504, 'batch_size': np.int64(48), 'epochs': np.int64(21), 'weight_decay': 2.153388071072438e-06, 'dropout': 0.0026150007171443783, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(127), 'stride1': np.int64(8), 'kernel_size2': np.int64(39), 'stride2': np.int64(6), 'gcn_hidden': np.int64(12), 'label_smoothing': 0.17220115298076819, 'grad_clip_norm': 2.700996203158019, 'use_amp': np.False_, 'calibrate_batches': np.int64(28), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.5633
2025-10-13 11:34:20,284 - INFO - bo.run_bo - üîçBO Trial 26: Using RF surrogate + Expected Improvement
2025-10-13 11:34:20,284 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:34:20,284 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 26 (NaN monitoring active)
2025-10-13 11:34:20,284 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:34:20,284 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:34:20,284 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007818479120708991, 'batch_size': 96, 'epochs': 7, 'weight_decay': 4.230264288914653e-06, 'dropout': 0.009053343996743736, 'channel_multiplier': 7, 'kernel_size1': 81, 'stride1': 9, 'kernel_size2': 64, 'stride2': 4, 'gcn_hidden': 11, 'label_smoothing': 0.029820639958436583, 'grad_clip_norm': 4.540625298238656, 'use_amp': False, 'calibrate_batches': 114, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:34:20,285 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007818479120708991, 'batch_size': 96, 'epochs': 7, 'weight_decay': 4.230264288914653e-06, 'dropout': 0.009053343996743736, 'channel_multiplier': 7, 'kernel_size1': 81, 'stride1': 9, 'kernel_size2': 64, 'stride2': 4, 'gcn_hidden': 11, 'label_smoothing': 0.029820639958436583, 'grad_clip_norm': 4.540625298238656, 'use_amp': False, 'calibrate_batches': 114, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:34:25,133 - INFO - _models.training_function_executor - Epoch 001/007 - train_loss: 1.3590 - val_loss: 1.2000 - val_acc: 0.5437
2025-10-13 11:34:27,170 - INFO - _models.training_function_executor - Epoch 002/007 - train_loss: 1.1210 - val_loss: 1.1528 - val_acc: 0.5734
2025-10-13 11:34:29,213 - INFO - _models.training_function_executor - Epoch 003/007 - train_loss: 1.0538 - val_loss: 1.0915 - val_acc: 0.5743
2025-10-13 11:34:31,260 - INFO - _models.training_function_executor - Epoch 004/007 - train_loss: 1.0154 - val_loss: 1.9486 - val_acc: 0.2963
2025-10-13 11:34:33,297 - INFO - _models.training_function_executor - Epoch 005/007 - train_loss: 0.9869 - val_loss: 1.0445 - val_acc: 0.5895
2025-10-13 11:34:35,346 - INFO - _models.training_function_executor - Epoch 006/007 - train_loss: 0.9754 - val_loss: 0.9903 - val_acc: 0.6191
2025-10-13 11:34:37,396 - INFO - _models.training_function_executor - Epoch 007/007 - train_loss: 0.9596 - val_loss: 0.9240 - val_acc: 0.6528
2025-10-13 11:34:38,478 - INFO - _models.training_function_executor - Model: 3,465 parameters, 14.9KB storage
2025-10-13 11:34:38,478 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3589982753622811, 1.1209534920718147, 1.0537756798273206, 1.015379264924674, 0.9868509948858649, 0.9754183492670536, 0.9596228904977812], 'val_losses': [1.2000333689541762, 1.1528147270848879, 1.0914939780480635, 1.948608928891717, 1.0445057443901504, 0.9903409205661355, 0.9239738217633547], 'val_acc': [0.5436646832341617, 0.5734161708085405, 0.5742912145607281, 0.29628981449072456, 0.5895169758487925, 0.6190934546727337, 0.6527826391319566], 'final_state_dict_size_bytes': 14260, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007818479120708991, 'batch_size': 96, 'epochs': 7, 'weight_decay': 4.230264288914653e-06, 'dropout': 0.009053343996743736, 'channel_multiplier': 7, 'kernel_size1': 81, 'stride1': 9, 'kernel_size2': 64, 'stride2': 4, 'gcn_hidden': 11, 'label_smoothing': 0.029820639958436583, 'grad_clip_norm': 4.540625298238656, 'use_amp': False, 'calibrate_batches': 114, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 3465, 'model_storage_size_kb': 14.888671875000002, 'model_size_validation': 'PASS'}
2025-10-13 11:34:38,478 - INFO - _models.training_function_executor - BO Objective: base=0.6528, size_penalty=0.0000, final=0.6528
2025-10-13 11:34:38,478 - INFO - _models.training_function_executor - Model: 3,465 parameters, 14.9KB (PASS 256KB limit)
2025-10-13 11:34:38,478 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 18.195s
2025-10-13 11:34:38,576 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6528
2025-10-13 11:34:38,577 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-10-13 11:34:38,577 - INFO - bo.run_bo - Recorded observation #26: hparams={'lr': 0.007818479120708991, 'batch_size': np.int64(96), 'epochs': np.int64(7), 'weight_decay': 4.230264288914653e-06, 'dropout': 0.009053343996743736, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(81), 'stride1': np.int64(9), 'kernel_size2': np.int64(64), 'stride2': np.int64(4), 'gcn_hidden': np.int64(11), 'label_smoothing': 0.029820639958436583, 'grad_clip_norm': 4.540625298238656, 'use_amp': np.False_, 'calibrate_batches': np.int64(114), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6528
2025-10-13 11:34:38,577 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 26: {'lr': 0.007818479120708991, 'batch_size': np.int64(96), 'epochs': np.int64(7), 'weight_decay': 4.230264288914653e-06, 'dropout': 0.009053343996743736, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(81), 'stride1': np.int64(9), 'kernel_size2': np.int64(64), 'stride2': np.int64(4), 'gcn_hidden': np.int64(11), 'label_smoothing': 0.029820639958436583, 'grad_clip_norm': 4.540625298238656, 'use_amp': np.False_, 'calibrate_batches': np.int64(114), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6528
2025-10-13 11:34:38,577 - INFO - bo.run_bo - üîçBO Trial 27: Using RF surrogate + Expected Improvement
2025-10-13 11:34:38,577 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:34:38,577 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 27 (NaN monitoring active)
2025-10-13 11:34:38,577 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:34:38,577 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:34:38,577 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.005665573942827502, 'batch_size': 16, 'epochs': 53, 'weight_decay': 9.09930192157574e-06, 'dropout': 0.00014756387147434326, 'channel_multiplier': 2, 'kernel_size1': 89, 'stride1': 13, 'kernel_size2': 24, 'stride2': 5, 'gcn_hidden': 20, 'label_smoothing': 0.12899449572271135, 'grad_clip_norm': 4.228747851809172, 'use_amp': False, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:34:38,578 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.005665573942827502, 'batch_size': 16, 'epochs': 53, 'weight_decay': 9.09930192157574e-06, 'dropout': 0.00014756387147434326, 'channel_multiplier': 2, 'kernel_size1': 89, 'stride1': 13, 'kernel_size2': 24, 'stride2': 5, 'gcn_hidden': 20, 'label_smoothing': 0.12899449572271135, 'grad_clip_norm': 4.228747851809172, 'use_amp': False, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:34:45,355 - INFO - _models.training_function_executor - Epoch 001/053 - train_loss: 1.3800 - val_loss: 1.2608 - val_acc: 0.5487
2025-10-13 11:34:49,324 - INFO - _models.training_function_executor - Epoch 002/053 - train_loss: 1.2611 - val_loss: 1.2277 - val_acc: 0.5610
2025-10-13 11:34:53,240 - INFO - _models.training_function_executor - Epoch 003/053 - train_loss: 1.2413 - val_loss: 1.2167 - val_acc: 0.5779
2025-10-13 11:34:57,169 - INFO - _models.training_function_executor - Epoch 004/053 - train_loss: 1.2252 - val_loss: 1.2696 - val_acc: 0.5418
2025-10-13 11:35:01,112 - INFO - _models.training_function_executor - Epoch 005/053 - train_loss: 1.2087 - val_loss: 1.2022 - val_acc: 0.5980
2025-10-13 11:35:05,092 - INFO - _models.training_function_executor - Epoch 006/053 - train_loss: 1.1956 - val_loss: 1.2019 - val_acc: 0.5816
2025-10-13 11:35:09,064 - INFO - _models.training_function_executor - Epoch 007/053 - train_loss: 1.1854 - val_loss: 1.1540 - val_acc: 0.6126
2025-10-13 11:35:13,024 - INFO - _models.training_function_executor - Epoch 008/053 - train_loss: 1.1793 - val_loss: 1.1402 - val_acc: 0.6355
2025-10-13 11:35:17,010 - INFO - _models.training_function_executor - Epoch 009/053 - train_loss: 1.1708 - val_loss: 1.1754 - val_acc: 0.5985
2025-10-13 11:35:20,918 - INFO - _models.training_function_executor - Epoch 010/053 - train_loss: 1.1635 - val_loss: 1.1583 - val_acc: 0.6049
2025-10-13 11:35:24,796 - INFO - _models.training_function_executor - Epoch 011/053 - train_loss: 1.1548 - val_loss: 1.1676 - val_acc: 0.6071
2025-10-13 11:35:28,742 - INFO - _models.training_function_executor - Epoch 012/053 - train_loss: 1.1481 - val_loss: 1.1076 - val_acc: 0.6523
2025-10-13 11:35:32,736 - INFO - _models.training_function_executor - Epoch 013/053 - train_loss: 1.1393 - val_loss: 1.1453 - val_acc: 0.6098
2025-10-13 11:35:36,679 - INFO - _models.training_function_executor - Epoch 014/053 - train_loss: 1.1345 - val_loss: 1.1046 - val_acc: 0.6411
2025-10-13 11:35:40,674 - INFO - _models.training_function_executor - Epoch 015/053 - train_loss: 1.1295 - val_loss: 1.2010 - val_acc: 0.5893
2025-10-13 11:35:44,649 - INFO - _models.training_function_executor - Epoch 016/053 - train_loss: 1.1232 - val_loss: 1.0983 - val_acc: 0.6608
2025-10-13 11:35:48,653 - INFO - _models.training_function_executor - Epoch 017/053 - train_loss: 1.1179 - val_loss: 1.1130 - val_acc: 0.6673
2025-10-13 11:35:52,602 - INFO - _models.training_function_executor - Epoch 018/053 - train_loss: 1.1164 - val_loss: 1.1123 - val_acc: 0.6526
2025-10-13 11:35:56,541 - INFO - _models.training_function_executor - Epoch 019/053 - train_loss: 1.1142 - val_loss: 1.1055 - val_acc: 0.6660
2025-10-13 11:36:00,517 - INFO - _models.training_function_executor - Epoch 020/053 - train_loss: 1.1128 - val_loss: 1.1597 - val_acc: 0.6450
2025-10-13 11:36:04,500 - INFO - _models.training_function_executor - Epoch 021/053 - train_loss: 1.1104 - val_loss: 1.4906 - val_acc: 0.5035
2025-10-13 11:36:08,436 - INFO - _models.training_function_executor - Epoch 022/053 - train_loss: 1.1087 - val_loss: 1.1238 - val_acc: 0.6731
2025-10-13 11:36:12,368 - INFO - _models.training_function_executor - Epoch 023/053 - train_loss: 1.1062 - val_loss: 1.2535 - val_acc: 0.6656
2025-10-13 11:36:16,363 - INFO - _models.training_function_executor - Epoch 024/053 - train_loss: 1.1046 - val_loss: 1.1958 - val_acc: 0.6767
2025-10-13 11:36:20,276 - INFO - _models.training_function_executor - Epoch 025/053 - train_loss: 1.1066 - val_loss: 1.1230 - val_acc: 0.6700
2025-10-13 11:36:24,198 - INFO - _models.training_function_executor - Epoch 026/053 - train_loss: 1.1031 - val_loss: 1.1276 - val_acc: 0.6681
2025-10-13 11:36:28,130 - INFO - _models.training_function_executor - Epoch 027/053 - train_loss: 1.1045 - val_loss: 1.3455 - val_acc: 0.5473
2025-10-13 11:36:32,046 - INFO - _models.training_function_executor - Epoch 028/053 - train_loss: 1.1050 - val_loss: 1.1178 - val_acc: 0.6806
2025-10-13 11:36:35,995 - INFO - _models.training_function_executor - Epoch 029/053 - train_loss: 1.1006 - val_loss: 1.1398 - val_acc: 0.6534
2025-10-13 11:36:39,944 - INFO - _models.training_function_executor - Epoch 030/053 - train_loss: 1.0996 - val_loss: 1.1378 - val_acc: 0.6796
2025-10-13 11:36:43,805 - INFO - _models.training_function_executor - Epoch 031/053 - train_loss: 1.1010 - val_loss: 1.2722 - val_acc: 0.5525
2025-10-13 11:36:47,738 - INFO - _models.training_function_executor - Epoch 032/053 - train_loss: 1.0984 - val_loss: 1.1095 - val_acc: 0.6355
2025-10-13 11:36:51,684 - INFO - _models.training_function_executor - Epoch 033/053 - train_loss: 1.0967 - val_loss: 1.0998 - val_acc: 0.6481
2025-10-13 11:36:55,600 - INFO - _models.training_function_executor - Epoch 034/053 - train_loss: 1.0928 - val_loss: 1.2497 - val_acc: 0.5674
2025-10-13 11:36:59,561 - INFO - _models.training_function_executor - Epoch 035/053 - train_loss: 1.0968 - val_loss: 1.0524 - val_acc: 0.6756
2025-10-13 11:37:03,498 - INFO - _models.training_function_executor - Epoch 036/053 - train_loss: 1.0965 - val_loss: 1.0652 - val_acc: 0.6754
2025-10-13 11:37:07,454 - INFO - _models.training_function_executor - Epoch 037/053 - train_loss: 1.0926 - val_loss: 1.0960 - val_acc: 0.6526
2025-10-13 11:37:11,397 - INFO - _models.training_function_executor - Epoch 038/053 - train_loss: 1.0933 - val_loss: 1.0627 - val_acc: 0.6744
2025-10-13 11:37:15,319 - INFO - _models.training_function_executor - Epoch 039/053 - train_loss: 1.0899 - val_loss: 1.0607 - val_acc: 0.6696
2025-10-13 11:37:19,212 - INFO - _models.training_function_executor - Epoch 040/053 - train_loss: 1.0875 - val_loss: 1.0557 - val_acc: 0.6838
2025-10-13 11:37:23,140 - INFO - _models.training_function_executor - Epoch 041/053 - train_loss: 1.0932 - val_loss: 1.0587 - val_acc: 0.6782
2025-10-13 11:37:27,074 - INFO - _models.training_function_executor - Epoch 042/053 - train_loss: 1.0882 - val_loss: 1.0943 - val_acc: 0.6484
2025-10-13 11:37:31,005 - INFO - _models.training_function_executor - Epoch 043/053 - train_loss: 1.0911 - val_loss: 1.0756 - val_acc: 0.6635
2025-10-13 11:37:35,001 - INFO - _models.training_function_executor - Epoch 044/053 - train_loss: 1.0888 - val_loss: 1.2078 - val_acc: 0.5683
2025-10-13 11:37:38,890 - INFO - _models.training_function_executor - Epoch 045/053 - train_loss: 1.0911 - val_loss: 1.0534 - val_acc: 0.6801
2025-10-13 11:37:42,850 - INFO - _models.training_function_executor - Epoch 046/053 - train_loss: 1.0863 - val_loss: 1.0964 - val_acc: 0.6474
2025-10-13 11:37:46,788 - INFO - _models.training_function_executor - Epoch 047/053 - train_loss: 1.0867 - val_loss: 1.2214 - val_acc: 0.5580
2025-10-13 11:37:50,741 - INFO - _models.training_function_executor - Epoch 048/053 - train_loss: 1.0861 - val_loss: 1.0422 - val_acc: 0.6880
2025-10-13 11:37:54,697 - INFO - _models.training_function_executor - Epoch 049/053 - train_loss: 1.0841 - val_loss: 1.0665 - val_acc: 0.6737
2025-10-13 11:37:58,631 - INFO - _models.training_function_executor - Epoch 050/053 - train_loss: 1.0860 - val_loss: 1.0877 - val_acc: 0.6554
2025-10-13 11:38:02,573 - INFO - _models.training_function_executor - Epoch 051/053 - train_loss: 1.0850 - val_loss: 1.0501 - val_acc: 0.6887
2025-10-13 11:38:06,473 - INFO - _models.training_function_executor - Epoch 052/053 - train_loss: 1.0848 - val_loss: 1.0938 - val_acc: 0.6418
2025-10-13 11:38:10,392 - INFO - _models.training_function_executor - Epoch 053/053 - train_loss: 1.0835 - val_loss: 1.1272 - val_acc: 0.6418
2025-10-13 11:38:11,518 - INFO - _models.training_function_executor - Model: 1,079 parameters, 4.6KB storage
2025-10-13 11:38:11,518 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3799857990617388, 1.2610821956556746, 1.2413127828737551, 1.2251619468796784, 1.2087466437832475, 1.1955740695697343, 1.185389880058354, 1.1793372658194468, 1.1707859581944655, 1.1635162604201454, 1.1548355713064202, 1.1480875316724353, 1.1392626443399931, 1.1345252062333895, 1.1295377041311334, 1.1232259573951484, 1.117940146918058, 1.1164356144024519, 1.1142287626940761, 1.1128004439276835, 1.11044536952919, 1.1086527429388084, 1.106244855174077, 1.1045612072585804, 1.1066247587192297, 1.1031318906307388, 1.1044779757665595, 1.105046672590721, 1.1006425891800447, 1.0996174455773884, 1.1010470484619088, 1.0984261446079258, 1.0966667246267767, 1.0928096965680307, 1.0968193113282296, 1.096454394543801, 1.0925647120480777, 1.0932908285360967, 1.0899059424293513, 1.0875170660219202, 1.0931964521855377, 1.088166161938735, 1.091137655952989, 1.0887918972368211, 1.091131625974099, 1.0862932130511842, 1.0867019387696812, 1.086114277988203, 1.0840857910408939, 1.0859976254604395, 1.085034535800739, 1.0847545715741942, 1.0834541227753278], 'val_losses': [1.260791899901735, 1.2277223929934957, 1.2166885611140565, 1.2695625666183403, 1.2021662603527838, 1.201919425314108, 1.1539520630479319, 1.1401742668388855, 1.175374003319545, 1.1583170347126956, 1.167561707669386, 1.1075523643173202, 1.1453183846829194, 1.1045522401914507, 1.2010178800475402, 1.0982990454325612, 1.1130152849371633, 1.1123148439896036, 1.1055085775440792, 1.159660622044631, 1.4905927655243731, 1.1237943076486558, 1.2535451724056101, 1.1957977890843148, 1.1229810590171547, 1.1275791298229043, 1.345495483989602, 1.1177983294010663, 1.139789191584175, 1.1377921073971655, 1.2721602130612168, 1.1095311519437876, 1.0997924550997447, 1.2497300080665559, 1.0524184079615853, 1.0651617871742796, 1.0960210178505094, 1.062709465200433, 1.0607118983555808, 1.0557124134874194, 1.0587294557147149, 1.0943103661101559, 1.0756425158853167, 1.2078376881801711, 1.0534163367760778, 1.0963516347175468, 1.2214011386177697, 1.0422193023513404, 1.066535994624357, 1.087730445184197, 1.0500806293205485, 1.0938321562509332, 1.1272305352394925], 'val_acc': [0.5487399369968499, 0.5609905495274764, 0.5778788939446973, 0.5418270913545677, 0.5980049002450123, 0.5815540777038852, 0.6126181309065454, 0.6355442772138606, 0.5985299264963249, 0.6049177458872944, 0.6071053552677634, 0.652257612880644, 0.609817990899545, 0.6410570528526426, 0.5892544627231362, 0.6608330416520826, 0.6673083654182709, 0.652607630381519, 0.6659957997899895, 0.6449947497374868, 0.5035001750087504, 0.6730836541827091, 0.6656457822891144, 0.6766713335666783, 0.6700210010500525, 0.6680959047952397, 0.5473398669933497, 0.6806090304515225, 0.6533951697584879, 0.6795589779488974, 0.5525026251312566, 0.6355442772138606, 0.6481449072453622, 0.567378368918446, 0.6756212810640532, 0.6754462723136156, 0.652607630381519, 0.6743962198109905, 0.6695834791739587, 0.6838466923346167, 0.6781589079453972, 0.6484074203710185, 0.6634581729086454, 0.5682534126706336, 0.68008400420021, 0.6473573678683934, 0.5580154007700385, 0.6880469023451172, 0.6736961848092404, 0.6554077703885194, 0.6886594329716486, 0.6417570878543927, 0.6417570878543927], 'final_state_dict_size_bytes': 4476, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.005665573942827502, 'batch_size': 16, 'epochs': 53, 'weight_decay': 9.09930192157574e-06, 'dropout': 0.00014756387147434326, 'channel_multiplier': 2, 'kernel_size1': 89, 'stride1': 13, 'kernel_size2': 24, 'stride2': 5, 'gcn_hidden': 20, 'label_smoothing': 0.12899449572271135, 'grad_clip_norm': 4.228747851809172, 'use_amp': False, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1079, 'model_storage_size_kb': 4.636328125, 'model_size_validation': 'PASS'}
2025-10-13 11:38:11,518 - INFO - _models.training_function_executor - BO Objective: base=0.6418, size_penalty=0.0000, final=0.6418
2025-10-13 11:38:11,519 - INFO - _models.training_function_executor - Model: 1,079 parameters, 4.6KB (PASS 256KB limit)
2025-10-13 11:38:11,519 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 212.941s
2025-10-13 11:38:11,616 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6418
2025-10-13 11:38:11,616 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.097s
2025-10-13 11:38:11,616 - INFO - bo.run_bo - Recorded observation #27: hparams={'lr': 0.005665573942827502, 'batch_size': np.int64(16), 'epochs': np.int64(53), 'weight_decay': 9.09930192157574e-06, 'dropout': 0.00014756387147434326, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(89), 'stride1': np.int64(13), 'kernel_size2': np.int64(24), 'stride2': np.int64(5), 'gcn_hidden': np.int64(20), 'label_smoothing': 0.12899449572271135, 'grad_clip_norm': 4.228747851809172, 'use_amp': np.False_, 'calibrate_batches': np.int64(32), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6418
2025-10-13 11:38:11,616 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 27: {'lr': 0.005665573942827502, 'batch_size': np.int64(16), 'epochs': np.int64(53), 'weight_decay': 9.09930192157574e-06, 'dropout': 0.00014756387147434326, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(89), 'stride1': np.int64(13), 'kernel_size2': np.int64(24), 'stride2': np.int64(5), 'gcn_hidden': np.int64(20), 'label_smoothing': 0.12899449572271135, 'grad_clip_norm': 4.228747851809172, 'use_amp': np.False_, 'calibrate_batches': np.int64(32), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6418
2025-10-13 11:38:11,617 - INFO - bo.run_bo - üîçBO Trial 28: Using RF surrogate + Expected Improvement
2025-10-13 11:38:11,617 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:38:11,617 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 28 (NaN monitoring active)
2025-10-13 11:38:11,617 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:38:11,617 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:38:11,617 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007072364974975574, 'batch_size': 96, 'epochs': 12, 'weight_decay': 3.454260854508384e-05, 'dropout': 0.06914426210872905, 'channel_multiplier': 7, 'kernel_size1': 40, 'stride1': 16, 'kernel_size2': 60, 'stride2': 7, 'gcn_hidden': 24, 'label_smoothing': 0.198654370581458, 'grad_clip_norm': 4.568726363573492, 'use_amp': False, 'calibrate_batches': 14, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:38:11,618 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007072364974975574, 'batch_size': 96, 'epochs': 12, 'weight_decay': 3.454260854508384e-05, 'dropout': 0.06914426210872905, 'channel_multiplier': 7, 'kernel_size1': 40, 'stride1': 16, 'kernel_size2': 60, 'stride2': 7, 'gcn_hidden': 24, 'label_smoothing': 0.198654370581458, 'grad_clip_norm': 4.568726363573492, 'use_amp': False, 'calibrate_batches': 14, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:38:15,939 - INFO - _models.training_function_executor - Epoch 001/012 - train_loss: 1.3289 - val_loss: 1.2594 - val_acc: 0.5998
2025-10-13 11:38:17,387 - INFO - _models.training_function_executor - Epoch 002/012 - train_loss: 1.2555 - val_loss: 1.2448 - val_acc: 0.5931
2025-10-13 11:38:18,834 - INFO - _models.training_function_executor - Epoch 003/012 - train_loss: 1.2381 - val_loss: 1.2446 - val_acc: 0.6003
2025-10-13 11:38:20,270 - INFO - _models.training_function_executor - Epoch 004/012 - train_loss: 1.2267 - val_loss: 1.2216 - val_acc: 0.6064
2025-10-13 11:38:21,724 - INFO - _models.training_function_executor - Epoch 005/012 - train_loss: 1.2200 - val_loss: 1.2805 - val_acc: 0.5478
2025-10-13 11:38:23,208 - INFO - _models.training_function_executor - Epoch 006/012 - train_loss: 1.2144 - val_loss: 1.2542 - val_acc: 0.5981
2025-10-13 11:38:24,681 - INFO - _models.training_function_executor - Epoch 007/012 - train_loss: 1.2098 - val_loss: 1.2154 - val_acc: 0.6106
2025-10-13 11:38:26,153 - INFO - _models.training_function_executor - Epoch 008/012 - train_loss: 1.2072 - val_loss: 1.4488 - val_acc: 0.3897
2025-10-13 11:38:27,645 - INFO - _models.training_function_executor - Epoch 009/012 - train_loss: 1.2028 - val_loss: 1.1998 - val_acc: 0.6555
2025-10-13 11:38:29,117 - INFO - _models.training_function_executor - Epoch 010/012 - train_loss: 1.1996 - val_loss: 1.2688 - val_acc: 0.5637
2025-10-13 11:38:30,593 - INFO - _models.training_function_executor - Epoch 011/012 - train_loss: 1.2008 - val_loss: 1.2041 - val_acc: 0.6371
2025-10-13 11:38:32,098 - INFO - _models.training_function_executor - Epoch 012/012 - train_loss: 1.1958 - val_loss: 1.2888 - val_acc: 0.5438
2025-10-13 11:38:33,209 - INFO - _models.training_function_executor - Model: 3,233 parameters, 13.9KB storage
2025-10-13 11:38:33,209 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3288597317062394, 1.2554934447905715, 1.238148690438329, 1.2267170796913411, 1.2199764082304114, 1.2143868475390933, 1.2098302596676045, 1.2071519631958942, 1.2028477575380903, 1.1995522349624312, 1.2007597278872695, 1.195787413453238], 'val_losses': [1.259423148394215, 1.2447562669180556, 1.2446341407979165, 1.2216459100046981, 1.2805057511615052, 1.25421212964597, 1.2154157156496979, 1.4487952524271301, 1.1998458630478712, 1.2688030236911474, 1.204061587665479, 1.2888141982322563], 'val_acc': [0.5998424921246063, 0.5931046552327617, 0.6002800140007001, 0.6064053202660133, 0.5477773888694435, 0.598092404620231, 0.6106055302765139, 0.3897444872243612, 0.6554952747637381, 0.563703185159258, 0.6371193559677983, 0.5438396919845992], 'final_state_dict_size_bytes': 13332, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007072364974975574, 'batch_size': 96, 'epochs': 12, 'weight_decay': 3.454260854508384e-05, 'dropout': 0.06914426210872905, 'channel_multiplier': 7, 'kernel_size1': 40, 'stride1': 16, 'kernel_size2': 60, 'stride2': 7, 'gcn_hidden': 24, 'label_smoothing': 0.198654370581458, 'grad_clip_norm': 4.568726363573492, 'use_amp': False, 'calibrate_batches': 14, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 3233, 'model_storage_size_kb': 13.891796875, 'model_size_validation': 'PASS'}
2025-10-13 11:38:33,209 - INFO - _models.training_function_executor - BO Objective: base=0.5438, size_penalty=0.0000, final=0.5438
2025-10-13 11:38:33,209 - INFO - _models.training_function_executor - Model: 3,233 parameters, 13.9KB (PASS 256KB limit)
2025-10-13 11:38:33,209 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 21.592s
2025-10-13 11:38:33,307 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5438
2025-10-13 11:38:33,308 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-10-13 11:38:33,308 - INFO - bo.run_bo - Recorded observation #28: hparams={'lr': 0.007072364974975574, 'batch_size': np.int64(96), 'epochs': np.int64(12), 'weight_decay': 3.454260854508384e-05, 'dropout': 0.06914426210872905, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(40), 'stride1': np.int64(16), 'kernel_size2': np.int64(60), 'stride2': np.int64(7), 'gcn_hidden': np.int64(24), 'label_smoothing': 0.198654370581458, 'grad_clip_norm': 4.568726363573492, 'use_amp': np.False_, 'calibrate_batches': np.int64(14), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.5438
2025-10-13 11:38:33,308 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 28: {'lr': 0.007072364974975574, 'batch_size': np.int64(96), 'epochs': np.int64(12), 'weight_decay': 3.454260854508384e-05, 'dropout': 0.06914426210872905, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(40), 'stride1': np.int64(16), 'kernel_size2': np.int64(60), 'stride2': np.int64(7), 'gcn_hidden': np.int64(24), 'label_smoothing': 0.198654370581458, 'grad_clip_norm': 4.568726363573492, 'use_amp': np.False_, 'calibrate_batches': np.int64(14), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.5438
2025-10-13 11:38:33,308 - INFO - bo.run_bo - üîçBO Trial 29: Using RF surrogate + Expected Improvement
2025-10-13 11:38:33,308 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:38:33,308 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 29 (NaN monitoring active)
2025-10-13 11:38:33,308 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:38:33,308 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:38:33,308 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004730464042970288, 'batch_size': 48, 'epochs': 53, 'weight_decay': 3.6867277195566805e-05, 'dropout': 0.012008529666809367, 'channel_multiplier': 5, 'kernel_size1': 77, 'stride1': 5, 'kernel_size2': 33, 'stride2': 3, 'gcn_hidden': 11, 'label_smoothing': 0.04023096423790627, 'grad_clip_norm': 0.1795878949452612, 'use_amp': False, 'calibrate_batches': 47, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:38:33,309 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004730464042970288, 'batch_size': 48, 'epochs': 53, 'weight_decay': 3.6867277195566805e-05, 'dropout': 0.012008529666809367, 'channel_multiplier': 5, 'kernel_size1': 77, 'stride1': 5, 'kernel_size2': 33, 'stride2': 3, 'gcn_hidden': 11, 'label_smoothing': 0.04023096423790627, 'grad_clip_norm': 0.1795878949452612, 'use_amp': False, 'calibrate_batches': 47, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:38:38,074 - INFO - _models.training_function_executor - Epoch 001/053 - train_loss: 1.1595 - val_loss: 1.0782 - val_acc: 0.5747
2025-10-13 11:38:40,133 - INFO - _models.training_function_executor - Epoch 002/053 - train_loss: 1.0600 - val_loss: 1.0434 - val_acc: 0.6024
2025-10-13 11:38:42,177 - INFO - _models.training_function_executor - Epoch 003/053 - train_loss: 1.0384 - val_loss: 1.0207 - val_acc: 0.6343
2025-10-13 11:38:44,251 - INFO - _models.training_function_executor - Epoch 004/053 - train_loss: 1.0260 - val_loss: 1.0582 - val_acc: 0.6222
2025-10-13 11:38:46,313 - INFO - _models.training_function_executor - Epoch 005/053 - train_loss: 1.0129 - val_loss: 0.9723 - val_acc: 0.6621
2025-10-13 11:38:48,391 - INFO - _models.training_function_executor - Epoch 006/053 - train_loss: 1.0064 - val_loss: 1.0522 - val_acc: 0.6030
2025-10-13 11:38:50,469 - INFO - _models.training_function_executor - Epoch 007/053 - train_loss: 0.9986 - val_loss: 1.0263 - val_acc: 0.6244
2025-10-13 11:38:52,566 - INFO - _models.training_function_executor - Epoch 008/053 - train_loss: 0.9882 - val_loss: 0.9816 - val_acc: 0.6238
2025-10-13 11:38:54,637 - INFO - _models.training_function_executor - Epoch 009/053 - train_loss: 0.9855 - val_loss: 1.0379 - val_acc: 0.6269
2025-10-13 11:38:56,698 - INFO - _models.training_function_executor - Epoch 010/053 - train_loss: 0.9787 - val_loss: 0.9487 - val_acc: 0.6625
2025-10-13 11:38:58,788 - INFO - _models.training_function_executor - Epoch 011/053 - train_loss: 0.9758 - val_loss: 0.9764 - val_acc: 0.6467
2025-10-13 11:39:00,873 - INFO - _models.training_function_executor - Epoch 012/053 - train_loss: 0.9672 - val_loss: 1.0243 - val_acc: 0.6225
2025-10-13 11:39:02,956 - INFO - _models.training_function_executor - Epoch 013/053 - train_loss: 0.9609 - val_loss: 1.0500 - val_acc: 0.6108
2025-10-13 11:39:05,023 - INFO - _models.training_function_executor - Epoch 014/053 - train_loss: 0.9546 - val_loss: 0.9851 - val_acc: 0.6390
2025-10-13 11:39:07,103 - INFO - _models.training_function_executor - Epoch 015/053 - train_loss: 0.9522 - val_loss: 0.9692 - val_acc: 0.6516
2025-10-13 11:39:09,189 - INFO - _models.training_function_executor - Epoch 016/053 - train_loss: 0.9460 - val_loss: 0.9463 - val_acc: 0.6684
2025-10-13 11:39:11,261 - INFO - _models.training_function_executor - Epoch 017/053 - train_loss: 0.9381 - val_loss: 0.9698 - val_acc: 0.6476
2025-10-13 11:39:13,351 - INFO - _models.training_function_executor - Epoch 018/053 - train_loss: 0.9381 - val_loss: 0.9334 - val_acc: 0.6718
2025-10-13 11:39:15,413 - INFO - _models.training_function_executor - Epoch 019/053 - train_loss: 0.9268 - val_loss: 0.8922 - val_acc: 0.6907
2025-10-13 11:39:17,492 - INFO - _models.training_function_executor - Epoch 020/053 - train_loss: 0.9221 - val_loss: 0.9370 - val_acc: 0.6670
2025-10-13 11:39:19,582 - INFO - _models.training_function_executor - Epoch 021/053 - train_loss: 0.9187 - val_loss: 0.8767 - val_acc: 0.7072
2025-10-13 11:39:21,675 - INFO - _models.training_function_executor - Epoch 022/053 - train_loss: 0.9138 - val_loss: 0.9838 - val_acc: 0.6523
2025-10-13 11:39:23,753 - INFO - _models.training_function_executor - Epoch 023/053 - train_loss: 0.9054 - val_loss: 1.1296 - val_acc: 0.5711
2025-10-13 11:39:25,838 - INFO - _models.training_function_executor - Epoch 024/053 - train_loss: 0.9004 - val_loss: 0.9095 - val_acc: 0.6885
2025-10-13 11:39:27,910 - INFO - _models.training_function_executor - Epoch 025/053 - train_loss: 0.8904 - val_loss: 1.2846 - val_acc: 0.4596
2025-10-13 11:39:29,971 - INFO - _models.training_function_executor - Epoch 026/053 - train_loss: 0.8914 - val_loss: 0.9518 - val_acc: 0.6585
2025-10-13 11:39:32,049 - INFO - _models.training_function_executor - Epoch 027/053 - train_loss: 0.8805 - val_loss: 0.8496 - val_acc: 0.7100
2025-10-13 11:39:34,123 - INFO - _models.training_function_executor - Epoch 028/053 - train_loss: 0.8813 - val_loss: 0.8805 - val_acc: 0.6929
2025-10-13 11:39:36,194 - INFO - _models.training_function_executor - Epoch 029/053 - train_loss: 0.8744 - val_loss: 0.8563 - val_acc: 0.7078
2025-10-13 11:39:38,271 - INFO - _models.training_function_executor - Epoch 030/053 - train_loss: 0.8739 - val_loss: 0.9927 - val_acc: 0.6348
2025-10-13 11:39:40,346 - INFO - _models.training_function_executor - Epoch 031/053 - train_loss: 0.8679 - val_loss: 1.0049 - val_acc: 0.6250
2025-10-13 11:39:42,422 - INFO - _models.training_function_executor - Epoch 032/053 - train_loss: 0.8589 - val_loss: 0.9266 - val_acc: 0.6680
2025-10-13 11:39:44,488 - INFO - _models.training_function_executor - Epoch 033/053 - train_loss: 0.8549 - val_loss: 0.9872 - val_acc: 0.6264
2025-10-13 11:39:46,561 - INFO - _models.training_function_executor - Epoch 034/053 - train_loss: 0.8479 - val_loss: 0.9896 - val_acc: 0.6371
2025-10-13 11:39:48,647 - INFO - _models.training_function_executor - Epoch 035/053 - train_loss: 0.8413 - val_loss: 0.8799 - val_acc: 0.6866
2025-10-13 11:39:50,729 - INFO - _models.training_function_executor - Epoch 036/053 - train_loss: 0.8373 - val_loss: 1.0931 - val_acc: 0.6112
2025-10-13 11:39:52,817 - INFO - _models.training_function_executor - Epoch 037/053 - train_loss: 0.8347 - val_loss: 0.8939 - val_acc: 0.6880
2025-10-13 11:39:54,896 - INFO - _models.training_function_executor - Epoch 038/053 - train_loss: 0.8409 - val_loss: 0.9864 - val_acc: 0.6355
2025-10-13 11:39:56,955 - INFO - _models.training_function_executor - Epoch 039/053 - train_loss: 0.8329 - val_loss: 0.8596 - val_acc: 0.7053
2025-10-13 11:39:59,032 - INFO - _models.training_function_executor - Epoch 040/053 - train_loss: 0.8314 - val_loss: 0.8446 - val_acc: 0.7087
2025-10-13 11:40:01,132 - INFO - _models.training_function_executor - Epoch 041/053 - train_loss: 0.8301 - val_loss: 0.8580 - val_acc: 0.7024
2025-10-13 11:40:03,224 - INFO - _models.training_function_executor - Epoch 042/053 - train_loss: 0.8319 - val_loss: 0.9923 - val_acc: 0.6284
2025-10-13 11:40:05,318 - INFO - _models.training_function_executor - Epoch 043/053 - train_loss: 0.8265 - val_loss: 0.8669 - val_acc: 0.7041
2025-10-13 11:40:07,407 - INFO - _models.training_function_executor - Epoch 044/053 - train_loss: 0.8263 - val_loss: 0.8039 - val_acc: 0.7286
2025-10-13 11:40:09,486 - INFO - _models.training_function_executor - Epoch 045/053 - train_loss: 0.8232 - val_loss: 0.8332 - val_acc: 0.7159
2025-10-13 11:40:11,561 - INFO - _models.training_function_executor - Epoch 046/053 - train_loss: 0.8202 - val_loss: 0.8055 - val_acc: 0.7274
2025-10-13 11:40:13,643 - INFO - _models.training_function_executor - Epoch 047/053 - train_loss: 0.8218 - val_loss: 1.0347 - val_acc: 0.6304
2025-10-13 11:40:15,735 - INFO - _models.training_function_executor - Epoch 048/053 - train_loss: 0.8231 - val_loss: 2.3175 - val_acc: 0.3154
2025-10-13 11:40:17,816 - INFO - _models.training_function_executor - Epoch 049/053 - train_loss: 0.8207 - val_loss: 0.8438 - val_acc: 0.7079
2025-10-13 11:40:19,878 - INFO - _models.training_function_executor - Epoch 050/053 - train_loss: 0.8223 - val_loss: 0.7751 - val_acc: 0.7491
2025-10-13 11:40:21,953 - INFO - _models.training_function_executor - Epoch 051/053 - train_loss: 0.8135 - val_loss: 0.8808 - val_acc: 0.6853
2025-10-13 11:40:24,060 - INFO - _models.training_function_executor - Epoch 052/053 - train_loss: 0.8151 - val_loss: 0.8247 - val_acc: 0.7148
2025-10-13 11:40:26,144 - INFO - _models.training_function_executor - Epoch 053/053 - train_loss: 0.8174 - val_loss: 1.0456 - val_acc: 0.6306
2025-10-13 11:40:27,253 - INFO - _models.training_function_executor - Model: 1,697 parameters, 7.3KB storage
2025-10-13 11:40:27,254 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1594678397607587, 1.0599574404326944, 1.0384472933606663, 1.0259657997454135, 1.0129055931595685, 1.0064116604978237, 0.9985754940532328, 0.9881623756188715, 0.9855187165182205, 0.9786812214322302, 0.9757798520426338, 0.9671705483055048, 0.960947865658721, 0.954551764852232, 0.9521813871228783, 0.946014166253824, 0.938139207345604, 0.9381146419077517, 0.9268318034153031, 0.9220505064919898, 0.9186901417611402, 0.9137603792227937, 0.9054471032578586, 0.9004322905660636, 0.8904403773979745, 0.8913853995900993, 0.8804586699971128, 0.8812704179977093, 0.8744061790357155, 0.8739482438518402, 0.8678738743139807, 0.8589487181579395, 0.8548768726019413, 0.84788671038891, 0.8412580634899226, 0.8373336842062593, 0.8346845768822378, 0.8409145355099433, 0.8329038503998679, 0.8314013422098784, 0.8301228242693225, 0.8319115483723281, 0.8264580915597589, 0.8262544054228983, 0.8231872705925917, 0.8201877083401184, 0.8217873932767006, 0.8230558709953062, 0.8206797203985928, 0.8222928193949051, 0.8135084383213149, 0.8151430809960984, 0.8173899569626576], 'val_losses': [1.0781873792545504, 1.0433783600661652, 1.0206555738747851, 1.058231445451195, 0.9723017257662724, 1.0522034758239682, 1.0262923826902615, 0.9816462904329604, 1.0379419581306786, 0.9487454699685535, 0.9763772185757563, 1.0243498387769006, 1.0500305977408435, 0.9851420452263457, 0.969211965997527, 0.9462540996713075, 0.9697640959015666, 0.9334264371751445, 0.8921859826414077, 0.9369799798712432, 0.8766843214041711, 0.983813298345238, 1.1296115826175144, 0.9095286935369661, 1.2845852642281306, 0.9518275072535394, 0.8495604854010601, 0.8805372433767562, 0.856327282118138, 0.9926843755846888, 1.004925098626147, 0.9266146954265057, 0.9871572017002073, 0.9896421613374455, 0.8799189137210786, 1.0930507124450852, 0.8939097492603894, 0.986415777583618, 0.8595780838942002, 0.8445709283050641, 0.8580107406423273, 0.9923233889723976, 0.866879026957396, 0.803931263847538, 0.8331770962211774, 0.8054703365350295, 1.0346582407378884, 2.3175163275719024, 0.8438013520406016, 0.7750728336255117, 0.8808096721742301, 0.8247446847370884, 1.0456077710372984], 'val_acc': [0.5747287364368219, 0.6023801190059503, 0.634319215960798, 0.6221561078053903, 0.6620581029051452, 0.6029926496324817, 0.6244312215610781, 0.6238186909345468, 0.6268813440672033, 0.662495624781239, 0.6466573328666433, 0.6225061253062654, 0.6107805390269514, 0.6390444522226111, 0.6515575778788939, 0.668358417920896, 0.6476198809940497, 0.6717710885544277, 0.6906720336016801, 0.6670458522926146, 0.7072103605180259, 0.652257612880644, 0.5710535526776339, 0.688484424221211, 0.45957297864893243, 0.658470423521176, 0.7100105005250262, 0.6929471473573678, 0.7078228911445572, 0.6347567378368918, 0.6249562478123907, 0.668008400420021, 0.6264438221911095, 0.6371193559677983, 0.6865593279663983, 0.6112180609030452, 0.6879593979698985, 0.6354567728386419, 0.7052852642632131, 0.7086979348967448, 0.702397619880994, 0.6283689184459222, 0.7041477073853692, 0.7285614280714036, 0.7158732936646832, 0.7274238711935597, 0.6303815190759537, 0.3153657682884144, 0.707910395519776, 0.7491249562478124, 0.6853342667133356, 0.7148232411620581, 0.6305565278263913], 'final_state_dict_size_bytes': 7092, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004730464042970288, 'batch_size': 48, 'epochs': 53, 'weight_decay': 3.6867277195566805e-05, 'dropout': 0.012008529666809367, 'channel_multiplier': 5, 'kernel_size1': 77, 'stride1': 5, 'kernel_size2': 33, 'stride2': 3, 'gcn_hidden': 11, 'label_smoothing': 0.04023096423790627, 'grad_clip_norm': 0.1795878949452612, 'use_amp': False, 'calibrate_batches': 47, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1697, 'model_storage_size_kb': 7.291796875, 'model_size_validation': 'PASS'}
2025-10-13 11:40:27,254 - INFO - _models.training_function_executor - BO Objective: base=0.6306, size_penalty=0.0000, final=0.6306
2025-10-13 11:40:27,254 - INFO - _models.training_function_executor - Model: 1,697 parameters, 7.3KB (PASS 256KB limit)
2025-10-13 11:40:27,254 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 113.946s
2025-10-13 11:40:27,353 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6306
2025-10-13 11:40:27,353 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.099s
2025-10-13 11:40:27,353 - INFO - bo.run_bo - Recorded observation #29: hparams={'lr': 0.004730464042970288, 'batch_size': np.int64(48), 'epochs': np.int64(53), 'weight_decay': 3.6867277195566805e-05, 'dropout': 0.012008529666809367, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(77), 'stride1': np.int64(5), 'kernel_size2': np.int64(33), 'stride2': np.int64(3), 'gcn_hidden': np.int64(11), 'label_smoothing': 0.04023096423790627, 'grad_clip_norm': 0.1795878949452612, 'use_amp': np.False_, 'calibrate_batches': np.int64(47), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6306
2025-10-13 11:40:27,353 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 29: {'lr': 0.004730464042970288, 'batch_size': np.int64(48), 'epochs': np.int64(53), 'weight_decay': 3.6867277195566805e-05, 'dropout': 0.012008529666809367, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(77), 'stride1': np.int64(5), 'kernel_size2': np.int64(33), 'stride2': np.int64(3), 'gcn_hidden': np.int64(11), 'label_smoothing': 0.04023096423790627, 'grad_clip_norm': 0.1795878949452612, 'use_amp': np.False_, 'calibrate_batches': np.int64(47), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6306
2025-10-13 11:40:27,353 - INFO - bo.run_bo - üîçBO Trial 30: Using RF surrogate + Expected Improvement
2025-10-13 11:40:27,353 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:40:27,353 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 30 (NaN monitoring active)
2025-10-13 11:40:27,353 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:40:27,353 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:40:27,353 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.005837283268812692, 'batch_size': 48, 'epochs': 6, 'weight_decay': 0.000664981363356268, 'dropout': 0.008877916792412368, 'channel_multiplier': 2, 'kernel_size1': 75, 'stride1': 12, 'kernel_size2': 60, 'stride2': 3, 'gcn_hidden': 20, 'label_smoothing': 0.12305729061197866, 'grad_clip_norm': 1.012161419334617, 'use_amp': False, 'calibrate_batches': 60, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:40:27,354 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.005837283268812692, 'batch_size': 48, 'epochs': 6, 'weight_decay': 0.000664981363356268, 'dropout': 0.008877916792412368, 'channel_multiplier': 2, 'kernel_size1': 75, 'stride1': 12, 'kernel_size2': 60, 'stride2': 3, 'gcn_hidden': 20, 'label_smoothing': 0.12305729061197866, 'grad_clip_norm': 1.012161419334617, 'use_amp': False, 'calibrate_batches': 60, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:40:31,784 - INFO - _models.training_function_executor - Epoch 001/006 - train_loss: 1.3446 - val_loss: 1.3055 - val_acc: 0.5123
2025-10-13 11:40:33,423 - INFO - _models.training_function_executor - Epoch 002/006 - train_loss: 1.2291 - val_loss: 1.5229 - val_acc: 0.4348
2025-10-13 11:40:35,076 - INFO - _models.training_function_executor - Epoch 003/006 - train_loss: 1.2165 - val_loss: 1.2309 - val_acc: 0.5717
2025-10-13 11:40:36,721 - INFO - _models.training_function_executor - Epoch 004/006 - train_loss: 1.2084 - val_loss: 1.2367 - val_acc: 0.5592
2025-10-13 11:40:38,349 - INFO - _models.training_function_executor - Epoch 005/006 - train_loss: 1.2017 - val_loss: 1.7535 - val_acc: 0.3002
2025-10-13 11:40:39,994 - INFO - _models.training_function_executor - Epoch 006/006 - train_loss: 1.1822 - val_loss: 1.3336 - val_acc: 0.5232
2025-10-13 11:40:41,082 - INFO - _models.training_function_executor - Model: 1,427 parameters, 6.1KB storage
2025-10-13 11:40:41,082 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3445625548017246, 1.2291493684960948, 1.2164568016902109, 1.208402632540408, 1.2016828788257288, 1.1822122544477902], 'val_losses': [1.3055418942164072, 1.5228681833876736, 1.2309401214310536, 1.23668861739653, 1.7534843737068484, 1.3335871154877286], 'val_acc': [0.5123381169058453, 0.4348092404620231, 0.5716660833041652, 0.5591529576478824, 0.3002275113755688, 0.5231886594329717], 'final_state_dict_size_bytes': 5868, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.005837283268812692, 'batch_size': 48, 'epochs': 6, 'weight_decay': 0.000664981363356268, 'dropout': 0.008877916792412368, 'channel_multiplier': 2, 'kernel_size1': 75, 'stride1': 12, 'kernel_size2': 60, 'stride2': 3, 'gcn_hidden': 20, 'label_smoothing': 0.12305729061197866, 'grad_clip_norm': 1.012161419334617, 'use_amp': False, 'calibrate_batches': 60, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1427, 'model_storage_size_kb': 6.131640625, 'model_size_validation': 'PASS'}
2025-10-13 11:40:41,082 - INFO - _models.training_function_executor - BO Objective: base=0.5232, size_penalty=0.0000, final=0.5232
2025-10-13 11:40:41,082 - INFO - _models.training_function_executor - Model: 1,427 parameters, 6.1KB (PASS 256KB limit)
2025-10-13 11:40:41,082 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 13.729s
2025-10-13 11:40:41,183 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5232
2025-10-13 11:40:41,183 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.100s
2025-10-13 11:40:41,183 - INFO - bo.run_bo - Recorded observation #30: hparams={'lr': 0.005837283268812692, 'batch_size': np.int64(48), 'epochs': np.int64(6), 'weight_decay': 0.000664981363356268, 'dropout': 0.008877916792412368, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(75), 'stride1': np.int64(12), 'kernel_size2': np.int64(60), 'stride2': np.int64(3), 'gcn_hidden': np.int64(20), 'label_smoothing': 0.12305729061197866, 'grad_clip_norm': 1.012161419334617, 'use_amp': np.False_, 'calibrate_batches': np.int64(60), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.5232
2025-10-13 11:40:41,183 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 30: {'lr': 0.005837283268812692, 'batch_size': np.int64(48), 'epochs': np.int64(6), 'weight_decay': 0.000664981363356268, 'dropout': 0.008877916792412368, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(75), 'stride1': np.int64(12), 'kernel_size2': np.int64(60), 'stride2': np.int64(3), 'gcn_hidden': np.int64(20), 'label_smoothing': 0.12305729061197866, 'grad_clip_norm': 1.012161419334617, 'use_amp': np.False_, 'calibrate_batches': np.int64(60), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.5232
2025-10-13 11:40:41,183 - INFO - bo.run_bo - üîçBO Trial 31: Using RF surrogate + Expected Improvement
2025-10-13 11:40:41,183 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:40:41,184 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 31 (NaN monitoring active)
2025-10-13 11:40:41,184 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:40:41,184 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:40:41,184 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004212504743774932, 'batch_size': 128, 'epochs': 50, 'weight_decay': 4.85236221622707e-06, 'dropout': 0.0036233486985449933, 'channel_multiplier': 6, 'kernel_size1': 43, 'stride1': 4, 'kernel_size2': 63, 'stride2': 5, 'gcn_hidden': 14, 'label_smoothing': 0.03758401418749118, 'grad_clip_norm': 4.762030591320324, 'use_amp': False, 'calibrate_batches': 101, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:40:41,185 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004212504743774932, 'batch_size': 128, 'epochs': 50, 'weight_decay': 4.85236221622707e-06, 'dropout': 0.0036233486985449933, 'channel_multiplier': 6, 'kernel_size1': 43, 'stride1': 4, 'kernel_size2': 63, 'stride2': 5, 'gcn_hidden': 14, 'label_smoothing': 0.03758401418749118, 'grad_clip_norm': 4.762030591320324, 'use_amp': False, 'calibrate_batches': 101, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:40:46,713 - INFO - _models.training_function_executor - Epoch 001/050 - train_loss: 1.2782 - val_loss: 1.1487 - val_acc: 0.5727
2025-10-13 11:40:49,473 - INFO - _models.training_function_executor - Epoch 002/050 - train_loss: 1.0780 - val_loss: 1.0857 - val_acc: 0.5746
2025-10-13 11:40:52,242 - INFO - _models.training_function_executor - Epoch 003/050 - train_loss: 1.0349 - val_loss: 1.0562 - val_acc: 0.5865
2025-10-13 11:40:55,011 - INFO - _models.training_function_executor - Epoch 004/050 - train_loss: 0.9972 - val_loss: 1.0031 - val_acc: 0.6257
2025-10-13 11:40:57,771 - INFO - _models.training_function_executor - Epoch 005/050 - train_loss: 0.9678 - val_loss: 1.3280 - val_acc: 0.4681
2025-10-13 11:41:00,538 - INFO - _models.training_function_executor - Epoch 006/050 - train_loss: 0.9478 - val_loss: 1.0435 - val_acc: 0.5869
2025-10-13 11:41:03,295 - INFO - _models.training_function_executor - Epoch 007/050 - train_loss: 0.9382 - val_loss: 1.4181 - val_acc: 0.4513
2025-10-13 11:41:06,065 - INFO - _models.training_function_executor - Epoch 008/050 - train_loss: 0.9351 - val_loss: 1.4701 - val_acc: 0.4802
2025-10-13 11:41:08,822 - INFO - _models.training_function_executor - Epoch 009/050 - train_loss: 0.9258 - val_loss: 0.9957 - val_acc: 0.6082
2025-10-13 11:41:11,583 - INFO - _models.training_function_executor - Epoch 010/050 - train_loss: 0.9177 - val_loss: 0.9599 - val_acc: 0.6447
2025-10-13 11:41:14,327 - INFO - _models.training_function_executor - Epoch 011/050 - train_loss: 0.9067 - val_loss: 1.0040 - val_acc: 0.6068
2025-10-13 11:41:17,092 - INFO - _models.training_function_executor - Epoch 012/050 - train_loss: 0.9028 - val_loss: 1.2885 - val_acc: 0.5132
2025-10-13 11:41:19,845 - INFO - _models.training_function_executor - Epoch 013/050 - train_loss: 0.8971 - val_loss: 0.9118 - val_acc: 0.6733
2025-10-13 11:41:22,609 - INFO - _models.training_function_executor - Epoch 014/050 - train_loss: 0.8900 - val_loss: 1.1453 - val_acc: 0.5795
2025-10-13 11:41:25,376 - INFO - _models.training_function_executor - Epoch 015/050 - train_loss: 0.8902 - val_loss: 1.1280 - val_acc: 0.5670
2025-10-13 11:41:28,138 - INFO - _models.training_function_executor - Epoch 016/050 - train_loss: 0.8809 - val_loss: 1.2115 - val_acc: 0.5088
2025-10-13 11:41:30,902 - INFO - _models.training_function_executor - Epoch 017/050 - train_loss: 0.8757 - val_loss: 1.1844 - val_acc: 0.5856
2025-10-13 11:41:33,661 - INFO - _models.training_function_executor - Epoch 018/050 - train_loss: 0.8648 - val_loss: 1.1499 - val_acc: 0.5638
2025-10-13 11:41:36,424 - INFO - _models.training_function_executor - Epoch 019/050 - train_loss: 0.8644 - val_loss: 0.9098 - val_acc: 0.6644
2025-10-13 11:41:39,184 - INFO - _models.training_function_executor - Epoch 020/050 - train_loss: 0.8565 - val_loss: 1.1048 - val_acc: 0.5855
2025-10-13 11:41:41,943 - INFO - _models.training_function_executor - Epoch 021/050 - train_loss: 0.8531 - val_loss: 1.0511 - val_acc: 0.5911
2025-10-13 11:41:44,706 - INFO - _models.training_function_executor - Epoch 022/050 - train_loss: 0.8476 - val_loss: 0.9485 - val_acc: 0.6429
2025-10-13 11:41:47,465 - INFO - _models.training_function_executor - Epoch 023/050 - train_loss: 0.8449 - val_loss: 0.9182 - val_acc: 0.6599
2025-10-13 11:41:50,224 - INFO - _models.training_function_executor - Epoch 024/050 - train_loss: 0.8447 - val_loss: 0.8805 - val_acc: 0.6906
2025-10-13 11:41:52,979 - INFO - _models.training_function_executor - Epoch 025/050 - train_loss: 0.8377 - val_loss: 0.8652 - val_acc: 0.7042
2025-10-13 11:41:55,743 - INFO - _models.training_function_executor - Epoch 026/050 - train_loss: 0.8348 - val_loss: 1.1906 - val_acc: 0.5848
2025-10-13 11:41:58,518 - INFO - _models.training_function_executor - Epoch 027/050 - train_loss: 0.8328 - val_loss: 0.8815 - val_acc: 0.6970
2025-10-13 11:42:01,291 - INFO - _models.training_function_executor - Epoch 028/050 - train_loss: 0.8266 - val_loss: 1.1645 - val_acc: 0.5924
2025-10-13 11:42:04,054 - INFO - _models.training_function_executor - Epoch 029/050 - train_loss: 0.8199 - val_loss: 0.8681 - val_acc: 0.6824
2025-10-13 11:42:06,816 - INFO - _models.training_function_executor - Epoch 030/050 - train_loss: 0.8240 - val_loss: 0.9114 - val_acc: 0.6749
2025-10-13 11:42:09,574 - INFO - _models.training_function_executor - Epoch 031/050 - train_loss: 0.8195 - val_loss: 0.8590 - val_acc: 0.7118
2025-10-13 11:42:12,330 - INFO - _models.training_function_executor - Epoch 032/050 - train_loss: 0.8150 - val_loss: 1.4264 - val_acc: 0.5452
2025-10-13 11:42:15,087 - INFO - _models.training_function_executor - Epoch 033/050 - train_loss: 0.8136 - val_loss: 1.2128 - val_acc: 0.6067
2025-10-13 11:42:17,845 - INFO - _models.training_function_executor - Epoch 034/050 - train_loss: 0.8058 - val_loss: 1.3459 - val_acc: 0.5542
2025-10-13 11:42:20,612 - INFO - _models.training_function_executor - Epoch 035/050 - train_loss: 0.8029 - val_loss: 0.9995 - val_acc: 0.6376
2025-10-13 11:42:23,378 - INFO - _models.training_function_executor - Epoch 036/050 - train_loss: 0.7997 - val_loss: 1.4324 - val_acc: 0.5665
2025-10-13 11:42:26,135 - INFO - _models.training_function_executor - Epoch 037/050 - train_loss: 0.7974 - val_loss: 1.2136 - val_acc: 0.5486
2025-10-13 11:42:28,891 - INFO - _models.training_function_executor - Epoch 038/050 - train_loss: 0.7941 - val_loss: 1.6212 - val_acc: 0.5637
2025-10-13 11:42:31,664 - INFO - _models.training_function_executor - Epoch 039/050 - train_loss: 0.7912 - val_loss: 0.9581 - val_acc: 0.6756
2025-10-13 11:42:34,434 - INFO - _models.training_function_executor - Epoch 040/050 - train_loss: 0.7852 - val_loss: 1.2424 - val_acc: 0.5977
2025-10-13 11:42:37,205 - INFO - _models.training_function_executor - Epoch 041/050 - train_loss: 0.7852 - val_loss: 1.0610 - val_acc: 0.6645
2025-10-13 11:42:39,961 - INFO - _models.training_function_executor - Epoch 042/050 - train_loss: 0.7792 - val_loss: 1.4878 - val_acc: 0.5024
2025-10-13 11:42:42,734 - INFO - _models.training_function_executor - Epoch 043/050 - train_loss: 0.7791 - val_loss: 0.8952 - val_acc: 0.6859
2025-10-13 11:42:45,487 - INFO - _models.training_function_executor - Epoch 044/050 - train_loss: 0.7808 - val_loss: 1.2473 - val_acc: 0.4982
2025-10-13 11:42:48,263 - INFO - _models.training_function_executor - Epoch 045/050 - train_loss: 0.7771 - val_loss: 0.8920 - val_acc: 0.7007
2025-10-13 11:42:51,022 - INFO - _models.training_function_executor - Epoch 046/050 - train_loss: 0.7754 - val_loss: 1.2682 - val_acc: 0.6334
2025-10-13 11:42:53,783 - INFO - _models.training_function_executor - Epoch 047/050 - train_loss: 0.7749 - val_loss: 0.8895 - val_acc: 0.6884
2025-10-13 11:42:56,545 - INFO - _models.training_function_executor - Epoch 048/050 - train_loss: 0.7701 - val_loss: 1.9516 - val_acc: 0.4404
2025-10-13 11:42:59,294 - INFO - _models.training_function_executor - Epoch 049/050 - train_loss: 0.7690 - val_loss: 1.3608 - val_acc: 0.6148
2025-10-13 11:43:02,053 - INFO - _models.training_function_executor - Epoch 050/050 - train_loss: 0.7690 - val_loss: 1.2253 - val_acc: 0.6142
2025-10-13 11:43:03,164 - INFO - _models.training_function_executor - Model: 2,833 parameters, 12.2KB storage
2025-10-13 11:43:03,164 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2782269190940816, 1.0779562782982575, 1.034889766207766, 0.9971919385628305, 0.9677566163265334, 0.9477568320306732, 0.9381975931515425, 0.9350513360239135, 0.925803278579051, 0.9177349745956049, 0.9066754459792349, 0.9028416803386355, 0.8970922693782308, 0.8900142271784915, 0.8901910588672038, 0.8809275670947835, 0.8757063231770292, 0.864764785950193, 0.8643528945303314, 0.8564801853688647, 0.8531249359349167, 0.8475816375232051, 0.8449478140234489, 0.8447437144093551, 0.8377056015843815, 0.8348478502562966, 0.8327853598918454, 0.8266349313640494, 0.8199156073368968, 0.8239711597953011, 0.8195081294563462, 0.8150013369574262, 0.8135722852646157, 0.8058097511477765, 0.8029221068698709, 0.7996736591747686, 0.7974095772645421, 0.794059384774611, 0.7911995070607336, 0.7851749675066103, 0.7851830535432364, 0.7792407029527111, 0.7790534122448348, 0.7808327074855368, 0.7770946398455654, 0.7753647112287255, 0.7749069570076395, 0.7700607573439452, 0.769035468161586, 0.7690101368968871], 'val_losses': [1.1487207297557795, 1.0857083268794807, 1.0561619639438393, 1.0031139873982644, 1.3279594319409993, 1.043518420487465, 1.418052922273208, 1.4700507944098378, 0.9957178945427889, 0.9599290726941743, 1.004047834376668, 1.2884889700882578, 0.9118323299406623, 1.1452505336510455, 1.1279704865351148, 1.2115023564240879, 1.1843652579181045, 1.149861021395701, 0.9098241271194896, 1.104835985171699, 1.0511149527686936, 0.948503623736418, 0.9181690203546852, 0.8805171884061742, 0.8651944041502488, 1.190550932360146, 0.8814661882747333, 1.1645349837451036, 0.8680605783636102, 0.9114240348276493, 0.8590358750445466, 1.426374682146726, 1.2128103426548413, 1.3458568975564105, 0.9995299747117884, 1.432420767517744, 1.2135998746670331, 1.6211722828852033, 0.958118814165291, 1.2423776129471242, 1.0609552754694906, 1.4877535041746328, 0.8951604328749686, 1.247320448763937, 0.8919576194096913, 1.2681952023113947, 0.8895084467182887, 1.9516287189619834, 1.3607760812587826, 1.225312435130452], 'val_acc': [0.5727161358067904, 0.5746412320616031, 0.5864543227161358, 0.6256562828141407, 0.468148407420371, 0.5868918445922297, 0.4513475673783689, 0.48022401120056, 0.6082429121456073, 0.6447322366118305, 0.6067553377668884, 0.5132131606580329, 0.6732586629331466, 0.579453972698635, 0.5670283514175709, 0.5088379418970949, 0.5855792789639482, 0.5637906895344768, 0.6644207210360518, 0.5854917745887295, 0.5910920546027302, 0.6428946447322366, 0.6598704935246762, 0.6905845292264613, 0.704235211760588, 0.5847917395869794, 0.6969723486174308, 0.5924046202310116, 0.6823591179558978, 0.6749212460623031, 0.7118480924046202, 0.5452397619880994, 0.6066678333916696, 0.554165208260413, 0.6375568778438921, 0.5665033251662583, 0.5485649282464123, 0.563703185159258, 0.6756212810640532, 0.597742387119356, 0.6645082254112705, 0.5023626181309065, 0.685946797339867, 0.498162408120406, 0.7007350367518376, 0.6333566678333916, 0.6883969198459923, 0.4404095204760238, 0.6148057402870144, 0.6141932096604831], 'final_state_dict_size_bytes': 11684, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004212504743774932, 'batch_size': 128, 'epochs': 50, 'weight_decay': 4.85236221622707e-06, 'dropout': 0.0036233486985449933, 'channel_multiplier': 6, 'kernel_size1': 43, 'stride1': 4, 'kernel_size2': 63, 'stride2': 5, 'gcn_hidden': 14, 'label_smoothing': 0.03758401418749118, 'grad_clip_norm': 4.762030591320324, 'use_amp': False, 'calibrate_batches': 101, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 2833, 'model_storage_size_kb': 12.173046875, 'model_size_validation': 'PASS'}
2025-10-13 11:43:03,164 - INFO - _models.training_function_executor - BO Objective: base=0.6142, size_penalty=0.0000, final=0.6142
2025-10-13 11:43:03,164 - INFO - _models.training_function_executor - Model: 2,833 parameters, 12.2KB (PASS 256KB limit)
2025-10-13 11:43:03,164 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 141.981s
2025-10-13 11:43:03,266 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6142
2025-10-13 11:43:03,266 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.100s
2025-10-13 11:43:03,266 - INFO - bo.run_bo - Recorded observation #31: hparams={'lr': 0.004212504743774932, 'batch_size': np.int64(128), 'epochs': np.int64(50), 'weight_decay': 4.85236221622707e-06, 'dropout': 0.0036233486985449933, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(43), 'stride1': np.int64(4), 'kernel_size2': np.int64(63), 'stride2': np.int64(5), 'gcn_hidden': np.int64(14), 'label_smoothing': 0.03758401418749118, 'grad_clip_norm': 4.762030591320324, 'use_amp': np.False_, 'calibrate_batches': np.int64(101), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6142
2025-10-13 11:43:03,266 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 31: {'lr': 0.004212504743774932, 'batch_size': np.int64(128), 'epochs': np.int64(50), 'weight_decay': 4.85236221622707e-06, 'dropout': 0.0036233486985449933, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(43), 'stride1': np.int64(4), 'kernel_size2': np.int64(63), 'stride2': np.int64(5), 'gcn_hidden': np.int64(14), 'label_smoothing': 0.03758401418749118, 'grad_clip_norm': 4.762030591320324, 'use_amp': np.False_, 'calibrate_batches': np.int64(101), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6142
2025-10-13 11:43:03,267 - INFO - bo.run_bo - üîçBO Trial 32: Using RF surrogate + Expected Improvement
2025-10-13 11:43:03,267 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:43:03,267 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 32 (NaN monitoring active)
2025-10-13 11:43:03,267 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:43:03,267 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:43:03,267 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007527056066683356, 'batch_size': 64, 'epochs': 59, 'weight_decay': 0.00018506518072479084, 'dropout': 0.25473063821257746, 'channel_multiplier': 1, 'kernel_size1': 37, 'stride1': 6, 'kernel_size2': 13, 'stride2': 2, 'gcn_hidden': 14, 'label_smoothing': 0.02288916654004907, 'grad_clip_norm': 4.209706934329977, 'use_amp': False, 'calibrate_batches': 59, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:43:03,268 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007527056066683356, 'batch_size': 64, 'epochs': 59, 'weight_decay': 0.00018506518072479084, 'dropout': 0.25473063821257746, 'channel_multiplier': 1, 'kernel_size1': 37, 'stride1': 6, 'kernel_size2': 13, 'stride2': 2, 'gcn_hidden': 14, 'label_smoothing': 0.02288916654004907, 'grad_clip_norm': 4.209706934329977, 'use_amp': False, 'calibrate_batches': 59, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:43:07,579 - INFO - _models.training_function_executor - Epoch 001/059 - train_loss: 1.3399 - val_loss: 1.1980 - val_acc: 0.5378
2025-10-13 11:43:09,039 - INFO - _models.training_function_executor - Epoch 002/059 - train_loss: 1.1530 - val_loss: 1.1323 - val_acc: 0.5567
2025-10-13 11:43:10,519 - INFO - _models.training_function_executor - Epoch 003/059 - train_loss: 1.1260 - val_loss: 1.1714 - val_acc: 0.5249
2025-10-13 11:43:12,021 - INFO - _models.training_function_executor - Epoch 004/059 - train_loss: 1.1100 - val_loss: 1.1193 - val_acc: 0.5842
2025-10-13 11:43:13,503 - INFO - _models.training_function_executor - Epoch 005/059 - train_loss: 1.1051 - val_loss: 1.0955 - val_acc: 0.6021
2025-10-13 11:43:14,990 - INFO - _models.training_function_executor - Epoch 006/059 - train_loss: 1.1041 - val_loss: 1.9175 - val_acc: 0.3301
2025-10-13 11:43:16,481 - INFO - _models.training_function_executor - Epoch 007/059 - train_loss: 1.1002 - val_loss: 1.6478 - val_acc: 0.3878
2025-10-13 11:43:17,984 - INFO - _models.training_function_executor - Epoch 008/059 - train_loss: 1.0986 - val_loss: 1.1447 - val_acc: 0.5436
2025-10-13 11:43:19,477 - INFO - _models.training_function_executor - Epoch 009/059 - train_loss: 1.0894 - val_loss: 1.5088 - val_acc: 0.4049
2025-10-13 11:43:20,978 - INFO - _models.training_function_executor - Epoch 010/059 - train_loss: 1.0905 - val_loss: 1.1140 - val_acc: 0.5490
2025-10-13 11:43:22,476 - INFO - _models.training_function_executor - Epoch 011/059 - train_loss: 1.0864 - val_loss: 1.0874 - val_acc: 0.5641
2025-10-13 11:43:23,979 - INFO - _models.training_function_executor - Epoch 012/059 - train_loss: 1.0867 - val_loss: 1.1733 - val_acc: 0.5083
2025-10-13 11:43:25,483 - INFO - _models.training_function_executor - Epoch 013/059 - train_loss: 1.0869 - val_loss: 1.0963 - val_acc: 0.5584
2025-10-13 11:43:26,993 - INFO - _models.training_function_executor - Epoch 014/059 - train_loss: 1.0850 - val_loss: 1.1285 - val_acc: 0.5424
2025-10-13 11:43:28,503 - INFO - _models.training_function_executor - Epoch 015/059 - train_loss: 1.0797 - val_loss: 1.1180 - val_acc: 0.5462
2025-10-13 11:43:29,999 - INFO - _models.training_function_executor - Epoch 016/059 - train_loss: 1.0798 - val_loss: 1.3371 - val_acc: 0.4436
2025-10-13 11:43:31,508 - INFO - _models.training_function_executor - Epoch 017/059 - train_loss: 1.0762 - val_loss: 1.2827 - val_acc: 0.4526
2025-10-13 11:43:33,025 - INFO - _models.training_function_executor - Epoch 018/059 - train_loss: 1.0764 - val_loss: 1.3113 - val_acc: 0.4598
2025-10-13 11:43:34,522 - INFO - _models.training_function_executor - Epoch 019/059 - train_loss: 1.0788 - val_loss: 1.1162 - val_acc: 0.5487
2025-10-13 11:43:36,014 - INFO - _models.training_function_executor - Epoch 020/059 - train_loss: 1.0754 - val_loss: 1.3975 - val_acc: 0.4296
2025-10-13 11:43:37,525 - INFO - _models.training_function_executor - Epoch 021/059 - train_loss: 1.0775 - val_loss: 1.1146 - val_acc: 0.5359
2025-10-13 11:43:39,029 - INFO - _models.training_function_executor - Epoch 022/059 - train_loss: 1.0695 - val_loss: 1.1537 - val_acc: 0.5190
2025-10-13 11:43:40,515 - INFO - _models.training_function_executor - Epoch 023/059 - train_loss: 1.0701 - val_loss: 1.1736 - val_acc: 0.5088
2025-10-13 11:43:42,029 - INFO - _models.training_function_executor - Epoch 024/059 - train_loss: 1.0725 - val_loss: 1.1613 - val_acc: 0.5206
2025-10-13 11:43:43,529 - INFO - _models.training_function_executor - Epoch 025/059 - train_loss: 1.0723 - val_loss: 1.1011 - val_acc: 0.5557
2025-10-13 11:43:45,042 - INFO - _models.training_function_executor - Epoch 026/059 - train_loss: 1.0722 - val_loss: 1.3439 - val_acc: 0.4426
2025-10-13 11:43:46,523 - INFO - _models.training_function_executor - Epoch 027/059 - train_loss: 1.0634 - val_loss: 1.2133 - val_acc: 0.5007
2025-10-13 11:43:48,053 - INFO - _models.training_function_executor - Epoch 028/059 - train_loss: 1.0624 - val_loss: 1.1484 - val_acc: 0.5224
2025-10-13 11:43:49,554 - INFO - _models.training_function_executor - Epoch 029/059 - train_loss: 1.0639 - val_loss: 1.2652 - val_acc: 0.4978
2025-10-13 11:43:51,063 - INFO - _models.training_function_executor - Epoch 030/059 - train_loss: 1.0653 - val_loss: 1.1494 - val_acc: 0.5256
2025-10-13 11:43:52,574 - INFO - _models.training_function_executor - Epoch 031/059 - train_loss: 1.0624 - val_loss: 1.1222 - val_acc: 0.5338
2025-10-13 11:43:54,079 - INFO - _models.training_function_executor - Epoch 032/059 - train_loss: 1.0602 - val_loss: 1.1648 - val_acc: 0.5246
2025-10-13 11:43:55,581 - INFO - _models.training_function_executor - Epoch 033/059 - train_loss: 1.0597 - val_loss: 1.1745 - val_acc: 0.5148
2025-10-13 11:43:57,086 - INFO - _models.training_function_executor - Epoch 034/059 - train_loss: 1.0605 - val_loss: 1.1895 - val_acc: 0.5164
2025-10-13 11:43:58,602 - INFO - _models.training_function_executor - Epoch 035/059 - train_loss: 1.0633 - val_loss: 1.1485 - val_acc: 0.5256
2025-10-13 11:44:00,114 - INFO - _models.training_function_executor - Epoch 036/059 - train_loss: 1.0600 - val_loss: 1.2811 - val_acc: 0.4920
2025-10-13 11:44:01,612 - INFO - _models.training_function_executor - Epoch 037/059 - train_loss: 1.0599 - val_loss: 1.1465 - val_acc: 0.5185
2025-10-13 11:44:03,115 - INFO - _models.training_function_executor - Epoch 038/059 - train_loss: 1.0590 - val_loss: 1.1608 - val_acc: 0.5193
2025-10-13 11:44:04,630 - INFO - _models.training_function_executor - Epoch 039/059 - train_loss: 1.0570 - val_loss: 1.5002 - val_acc: 0.3117
2025-10-13 11:44:06,134 - INFO - _models.training_function_executor - Epoch 040/059 - train_loss: 1.0560 - val_loss: 1.2558 - val_acc: 0.4907
2025-10-13 11:44:07,655 - INFO - _models.training_function_executor - Epoch 041/059 - train_loss: 1.0592 - val_loss: 1.1611 - val_acc: 0.5131
2025-10-13 11:44:09,193 - INFO - _models.training_function_executor - Epoch 042/059 - train_loss: 1.0546 - val_loss: 1.2051 - val_acc: 0.4954
2025-10-13 11:44:10,699 - INFO - _models.training_function_executor - Epoch 043/059 - train_loss: 1.0554 - val_loss: 1.1728 - val_acc: 0.5102
2025-10-13 11:44:12,214 - INFO - _models.training_function_executor - Epoch 044/059 - train_loss: 1.0503 - val_loss: 1.1425 - val_acc: 0.5270
2025-10-13 11:44:13,731 - INFO - _models.training_function_executor - Epoch 045/059 - train_loss: 1.0540 - val_loss: 1.1588 - val_acc: 0.5252
2025-10-13 11:44:15,232 - INFO - _models.training_function_executor - Epoch 046/059 - train_loss: 1.0497 - val_loss: 1.2733 - val_acc: 0.4881
2025-10-13 11:44:16,736 - INFO - _models.training_function_executor - Epoch 047/059 - train_loss: 1.0547 - val_loss: 1.1418 - val_acc: 0.5340
2025-10-13 11:44:18,252 - INFO - _models.training_function_executor - Epoch 048/059 - train_loss: 1.0588 - val_loss: 1.1694 - val_acc: 0.4996
2025-10-13 11:44:19,762 - INFO - _models.training_function_executor - Epoch 049/059 - train_loss: 1.0529 - val_loss: 1.1366 - val_acc: 0.5224
2025-10-13 11:44:21,265 - INFO - _models.training_function_executor - Epoch 050/059 - train_loss: 1.0533 - val_loss: 1.1835 - val_acc: 0.5183
2025-10-13 11:44:22,793 - INFO - _models.training_function_executor - Epoch 051/059 - train_loss: 1.0560 - val_loss: 1.1621 - val_acc: 0.5158
2025-10-13 11:44:24,302 - INFO - _models.training_function_executor - Epoch 052/059 - train_loss: 1.0527 - val_loss: 1.1502 - val_acc: 0.4960
2025-10-13 11:44:25,788 - INFO - _models.training_function_executor - Epoch 053/059 - train_loss: 1.0537 - val_loss: 1.1403 - val_acc: 0.5317
2025-10-13 11:44:27,287 - INFO - _models.training_function_executor - Epoch 054/059 - train_loss: 1.0542 - val_loss: 1.1838 - val_acc: 0.4950
2025-10-13 11:44:28,800 - INFO - _models.training_function_executor - Epoch 055/059 - train_loss: 1.0504 - val_loss: 1.1558 - val_acc: 0.5246
2025-10-13 11:44:30,343 - INFO - _models.training_function_executor - Epoch 056/059 - train_loss: 1.0503 - val_loss: 1.1886 - val_acc: 0.4956
2025-10-13 11:44:31,872 - INFO - _models.training_function_executor - Epoch 057/059 - train_loss: 1.0534 - val_loss: 1.1502 - val_acc: 0.5117
2025-10-13 11:44:33,394 - INFO - _models.training_function_executor - Epoch 058/059 - train_loss: 1.0518 - val_loss: 1.1977 - val_acc: 0.4823
2025-10-13 11:44:34,903 - INFO - _models.training_function_executor - Epoch 059/059 - train_loss: 1.0528 - val_loss: 1.2941 - val_acc: 0.4524
2025-10-13 11:44:36,018 - INFO - _models.training_function_executor - Model: 477 parameters, 2.0KB storage
2025-10-13 11:44:36,019 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3399297715401708, 1.1529686031201356, 1.1260136579106979, 1.1099974988096863, 1.105123650539493, 1.1041221982497287, 1.1001957261274442, 1.0986370245476558, 1.0893546395423657, 1.0904711737764603, 1.0863575493492443, 1.0866872148577216, 1.0868682715289444, 1.0849530074535485, 1.0797282331549791, 1.0797651386945282, 1.0762001474211589, 1.076447977734313, 1.0788014346918193, 1.0754086072519187, 1.077549596996127, 1.069507161720591, 1.07006324674852, 1.0725420194361484, 1.0722908841007275, 1.0721978063052628, 1.0633889826853709, 1.0623715104112101, 1.0639073096833782, 1.0652916842421578, 1.0623749987746103, 1.0601543298041358, 1.0596512739667536, 1.0605450435497563, 1.0632799572989704, 1.0599673694357574, 1.0598930470543722, 1.0589827809836174, 1.0569782334271953, 1.056031257487862, 1.0591918280544421, 1.0545774530104335, 1.0553551151237581, 1.0503210436434107, 1.0539812556004082, 1.0496608114843398, 1.054684967772711, 1.0587871489009115, 1.052898550475858, 1.0533148297530852, 1.0560449765285163, 1.0527174603826397, 1.053698960742543, 1.0542162754838602, 1.050415945086481, 1.0502736742028331, 1.0533545007645604, 1.0518193288328432, 1.0527654191936109], 'val_losses': [1.198033642551888, 1.1322840377923113, 1.1713646097453607, 1.1192607095202325, 1.0955491865436473, 1.9175311815584295, 1.6478051346500813, 1.1447341882310467, 1.5088225009769336, 1.1140267196801479, 1.0874370549331815, 1.1732710289045527, 1.096257170722916, 1.1284624774597056, 1.118021407701521, 1.3371368906570558, 1.282684598680055, 1.3113085533882465, 1.1162106258117281, 1.3974582414173105, 1.1145835915019056, 1.1537416880891003, 1.173568647184028, 1.1612520125682513, 1.1011313020577997, 1.3438775299477501, 1.2133151087929495, 1.1484243250994737, 1.2651888756306389, 1.1494176667346627, 1.1222227325295917, 1.1648255695110024, 1.1745099183100272, 1.1894517885374363, 1.1485492725826285, 1.2811140109076549, 1.1464584855963227, 1.1607822501913918, 1.500188338034713, 1.2557604967984528, 1.1611108258340506, 1.2050650384320134, 1.1727612019836966, 1.142502008095295, 1.158779279101675, 1.2733448223922483, 1.141753118272674, 1.1694421280836533, 1.1365722698225689, 1.1834640202090003, 1.1621245695320426, 1.1501507316388406, 1.1403384135659858, 1.1838464181574233, 1.155803199535406, 1.1886381858873083, 1.15020537956386, 1.1976616666331172, 1.2941424998112145], 'val_acc': [0.5378018900945047, 0.5567028351417571, 0.5249387469373469, 0.5841792089604481, 0.6021176058802941, 0.33006650332516624, 0.3878193909695485, 0.543577178858943, 0.4048827441372069, 0.5490024501225061, 0.5641407070353518, 0.5083129156457823, 0.5583654182709136, 0.5423521176058803, 0.5462023101155058, 0.44364718235911793, 0.45257262863143155, 0.4598354917745887, 0.5486524326216311, 0.42964648232411623, 0.535876793839692, 0.5189884494224711, 0.5087504375218761, 0.5205635281764088, 0.5557402870143507, 0.4425971298564928, 0.5007000350017501, 0.5224011200560028, 0.497812390619531, 0.525638781939097, 0.5337766888344417, 0.5245887294364718, 0.5147882394119706, 0.5163633181659083, 0.5255512775638782, 0.49203710185509275, 0.5184634231711586, 0.5192509625481274, 0.3116905845292265, 0.49072453622681134, 0.5131256562828141, 0.49544977248862443, 0.510238011900595, 0.5269513475673784, 0.5252012600630032, 0.4880994049702485, 0.5339516975848793, 0.49964998249912496, 0.5224011200560028, 0.518288414420721, 0.515750787539377, 0.495974798739937, 0.5316765838291915, 0.4950122506125306, 0.5245887294364718, 0.49562478123906195, 0.511725586279314, 0.4823241162058103, 0.45239761988099403], 'final_state_dict_size_bytes': 1018, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007527056066683356, 'batch_size': 64, 'epochs': 59, 'weight_decay': 0.00018506518072479084, 'dropout': 0.25473063821257746, 'channel_multiplier': 1, 'kernel_size1': 37, 'stride1': 6, 'kernel_size2': 13, 'stride2': 2, 'gcn_hidden': 14, 'label_smoothing': 0.02288916654004907, 'grad_clip_norm': 4.209706934329977, 'use_amp': False, 'calibrate_batches': 59, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 477, 'model_storage_size_kb': 2.049609375, 'model_size_validation': 'PASS'}
2025-10-13 11:44:36,019 - INFO - _models.training_function_executor - BO Objective: base=0.4524, size_penalty=0.0000, final=0.4524
2025-10-13 11:44:36,019 - INFO - _models.training_function_executor - Model: 477 parameters, 2.0KB (PASS 256KB limit)
2025-10-13 11:44:36,019 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 92.752s
2025-10-13 11:44:36,242 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.4524
2025-10-13 11:44:36,243 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.224s
2025-10-13 11:44:36,243 - INFO - bo.run_bo - Recorded observation #32: hparams={'lr': 0.007527056066683356, 'batch_size': np.int64(64), 'epochs': np.int64(59), 'weight_decay': 0.00018506518072479084, 'dropout': 0.25473063821257746, 'channel_multiplier': np.int64(1), 'kernel_size1': np.int64(37), 'stride1': np.int64(6), 'kernel_size2': np.int64(13), 'stride2': np.int64(2), 'gcn_hidden': np.int64(14), 'label_smoothing': 0.02288916654004907, 'grad_clip_norm': 4.209706934329977, 'use_amp': np.False_, 'calibrate_batches': np.int64(59), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.4524
2025-10-13 11:44:36,243 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 32: {'lr': 0.007527056066683356, 'batch_size': np.int64(64), 'epochs': np.int64(59), 'weight_decay': 0.00018506518072479084, 'dropout': 0.25473063821257746, 'channel_multiplier': np.int64(1), 'kernel_size1': np.int64(37), 'stride1': np.int64(6), 'kernel_size2': np.int64(13), 'stride2': np.int64(2), 'gcn_hidden': np.int64(14), 'label_smoothing': 0.02288916654004907, 'grad_clip_norm': 4.209706934329977, 'use_amp': np.False_, 'calibrate_batches': np.int64(59), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.4524
2025-10-13 11:44:36,243 - INFO - bo.run_bo - üîçBO Trial 33: Using RF surrogate + Expected Improvement
2025-10-13 11:44:36,243 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:44:36,243 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 33 (NaN monitoring active)
2025-10-13 11:44:36,243 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:44:36,243 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:44:36,243 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00020114610882689067, 'batch_size': 16, 'epochs': 17, 'weight_decay': 3.330907036515918e-05, 'dropout': 0.013385202694787782, 'channel_multiplier': 7, 'kernel_size1': 100, 'stride1': 4, 'kernel_size2': 8, 'stride2': 2, 'gcn_hidden': 11, 'label_smoothing': 0.09723342260525476, 'grad_clip_norm': 3.776243804364198, 'use_amp': False, 'calibrate_batches': 86, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:44:36,244 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00020114610882689067, 'batch_size': 16, 'epochs': 17, 'weight_decay': 3.330907036515918e-05, 'dropout': 0.013385202694787782, 'channel_multiplier': 7, 'kernel_size1': 100, 'stride1': 4, 'kernel_size2': 8, 'stride2': 2, 'gcn_hidden': 11, 'label_smoothing': 0.09723342260525476, 'grad_clip_norm': 3.776243804364198, 'use_amp': False, 'calibrate_batches': 86, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:44:43,066 - INFO - _models.training_function_executor - Epoch 001/017 - train_loss: 1.5083 - val_loss: 1.4911 - val_acc: 0.3837
2025-10-13 11:44:47,079 - INFO - _models.training_function_executor - Epoch 002/017 - train_loss: 1.4326 - val_loss: 1.4162 - val_acc: 0.4198
2025-10-13 11:44:51,048 - INFO - _models.training_function_executor - Epoch 003/017 - train_loss: 1.3497 - val_loss: 1.3294 - val_acc: 0.5536
2025-10-13 11:44:55,044 - INFO - _models.training_function_executor - Epoch 004/017 - train_loss: 1.2843 - val_loss: 1.2542 - val_acc: 0.5550
2025-10-13 11:44:59,022 - INFO - _models.training_function_executor - Epoch 005/017 - train_loss: 1.2494 - val_loss: 1.2688 - val_acc: 0.5347
2025-10-13 11:45:02,976 - INFO - _models.training_function_executor - Epoch 006/017 - train_loss: 1.2313 - val_loss: 1.2303 - val_acc: 0.5627
2025-10-13 11:45:06,932 - INFO - _models.training_function_executor - Epoch 007/017 - train_loss: 1.2232 - val_loss: 1.2503 - val_acc: 0.5693
2025-10-13 11:45:10,918 - INFO - _models.training_function_executor - Epoch 008/017 - train_loss: 1.2141 - val_loss: 1.2037 - val_acc: 0.5815
2025-10-13 11:45:14,915 - INFO - _models.training_function_executor - Epoch 009/017 - train_loss: 1.2087 - val_loss: 1.3261 - val_acc: 0.5265
2025-10-13 11:45:18,878 - INFO - _models.training_function_executor - Epoch 010/017 - train_loss: 1.2024 - val_loss: 1.4174 - val_acc: 0.4163
2025-10-13 11:45:22,898 - INFO - _models.training_function_executor - Epoch 011/017 - train_loss: 1.2004 - val_loss: 1.1869 - val_acc: 0.5711
2025-10-13 11:45:26,884 - INFO - _models.training_function_executor - Epoch 012/017 - train_loss: 1.1933 - val_loss: 1.1883 - val_acc: 0.6007
2025-10-13 11:45:30,877 - INFO - _models.training_function_executor - Epoch 013/017 - train_loss: 1.1885 - val_loss: 1.1882 - val_acc: 0.6021
2025-10-13 11:45:34,860 - INFO - _models.training_function_executor - Epoch 014/017 - train_loss: 1.1849 - val_loss: 1.2681 - val_acc: 0.5313
2025-10-13 11:45:38,752 - INFO - _models.training_function_executor - Epoch 015/017 - train_loss: 1.1841 - val_loss: 1.1954 - val_acc: 0.5668
2025-10-13 11:45:42,673 - INFO - _models.training_function_executor - Epoch 016/017 - train_loss: 1.1769 - val_loss: 1.2033 - val_acc: 0.5620
2025-10-13 11:45:46,588 - INFO - _models.training_function_executor - Epoch 017/017 - train_loss: 1.1755 - val_loss: 1.1662 - val_acc: 0.6044
2025-10-13 11:45:47,696 - INFO - _models.training_function_executor - Model: 1,227 parameters, 5.3KB storage
2025-10-13 11:45:47,697 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.508254737006145, 1.4325925355446603, 1.3496503317568909, 1.2842717179894907, 1.24941847682792, 1.2312563737664641, 1.2231905789153326, 1.2140809640752548, 1.2087130668616437, 1.2023590549247682, 1.2003514111396687, 1.1933155557389103, 1.188517822683546, 1.184943098557926, 1.184117448092091, 1.176947104668008, 1.1755195767845272], 'val_losses': [1.4911417801729816, 1.416230384102642, 1.3293715221797582, 1.254183953109637, 1.2688476324999378, 1.2302845414384995, 1.250321366881256, 1.2037449785992946, 1.3260732058423943, 1.417414903140043, 1.186863151512907, 1.1883100171084164, 1.1881740128280485, 1.2681487778662635, 1.1953668099080594, 1.2032877877745798, 1.1662214942691123], 'val_acc': [0.3837066853342667, 0.41975848792439624, 0.5535526776338817, 0.5550402520126007, 0.5346517325866293, 0.5626531326566329, 0.5693034651732587, 0.5814665733286665, 0.5265138256912846, 0.41634581729086456, 0.5710535526776339, 0.6007175358767939, 0.6021176058802941, 0.5313265663283164, 0.5667658382919146, 0.5620406020301015, 0.6043927196359818], 'final_state_dict_size_bytes': 2662, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00020114610882689067, 'batch_size': 16, 'epochs': 17, 'weight_decay': 3.330907036515918e-05, 'dropout': 0.013385202694787782, 'channel_multiplier': 7, 'kernel_size1': 100, 'stride1': 4, 'kernel_size2': 8, 'stride2': 2, 'gcn_hidden': 11, 'label_smoothing': 0.09723342260525476, 'grad_clip_norm': 3.776243804364198, 'use_amp': False, 'calibrate_batches': 86, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1227, 'model_storage_size_kb': 5.272265625, 'model_size_validation': 'PASS'}
2025-10-13 11:45:47,697 - INFO - _models.training_function_executor - BO Objective: base=0.6044, size_penalty=0.0000, final=0.6044
2025-10-13 11:45:47,697 - INFO - _models.training_function_executor - Model: 1,227 parameters, 5.3KB (PASS 256KB limit)
2025-10-13 11:45:47,697 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 71.454s
2025-10-13 11:45:47,798 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6044
2025-10-13 11:45:47,798 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-10-13 11:45:47,798 - INFO - bo.run_bo - Recorded observation #33: hparams={'lr': 0.00020114610882689067, 'batch_size': np.int64(16), 'epochs': np.int64(17), 'weight_decay': 3.330907036515918e-05, 'dropout': 0.013385202694787782, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(100), 'stride1': np.int64(4), 'kernel_size2': np.int64(8), 'stride2': np.int64(2), 'gcn_hidden': np.int64(11), 'label_smoothing': 0.09723342260525476, 'grad_clip_norm': 3.776243804364198, 'use_amp': np.False_, 'calibrate_batches': np.int64(86), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6044
2025-10-13 11:45:47,798 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 33: {'lr': 0.00020114610882689067, 'batch_size': np.int64(16), 'epochs': np.int64(17), 'weight_decay': 3.330907036515918e-05, 'dropout': 0.013385202694787782, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(100), 'stride1': np.int64(4), 'kernel_size2': np.int64(8), 'stride2': np.int64(2), 'gcn_hidden': np.int64(11), 'label_smoothing': 0.09723342260525476, 'grad_clip_norm': 3.776243804364198, 'use_amp': np.False_, 'calibrate_batches': np.int64(86), 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6044
2025-10-13 11:45:47,798 - INFO - bo.run_bo - üîçBO Trial 34: Using RF surrogate + Expected Improvement
2025-10-13 11:45:47,799 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:45:47,799 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 34 (NaN monitoring active)
2025-10-13 11:45:47,799 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:45:47,799 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:45:47,799 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.006159683919505516, 'batch_size': 64, 'epochs': 59, 'weight_decay': 5.149255649228264e-06, 'dropout': 0.01793289707169983, 'channel_multiplier': 3, 'kernel_size1': 79, 'stride1': 8, 'kernel_size2': 28, 'stride2': 2, 'gcn_hidden': 10, 'label_smoothing': 0.05081374946620848, 'grad_clip_norm': 4.967372765118303, 'use_amp': False, 'calibrate_batches': 114, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:45:47,800 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.006159683919505516, 'batch_size': 64, 'epochs': 59, 'weight_decay': 5.149255649228264e-06, 'dropout': 0.01793289707169983, 'channel_multiplier': 3, 'kernel_size1': 79, 'stride1': 8, 'kernel_size2': 28, 'stride2': 2, 'gcn_hidden': 10, 'label_smoothing': 0.05081374946620848, 'grad_clip_norm': 4.967372765118303, 'use_amp': False, 'calibrate_batches': 114, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:45:52,115 - INFO - _models.training_function_executor - Epoch 001/059 - train_loss: 1.3957 - val_loss: 1.4357 - val_acc: 0.4096
2025-10-13 11:45:53,590 - INFO - _models.training_function_executor - Epoch 002/059 - train_loss: 1.3321 - val_loss: 1.8046 - val_acc: 0.2374
2025-10-13 11:45:55,061 - INFO - _models.training_function_executor - Epoch 003/059 - train_loss: 1.3074 - val_loss: 1.3520 - val_acc: 0.4424
2025-10-13 11:45:56,535 - INFO - _models.training_function_executor - Epoch 004/059 - train_loss: 1.1734 - val_loss: 1.1462 - val_acc: 0.5656
2025-10-13 11:45:58,022 - INFO - _models.training_function_executor - Epoch 005/059 - train_loss: 1.1333 - val_loss: 1.1132 - val_acc: 0.5981
2025-10-13 11:45:59,486 - INFO - _models.training_function_executor - Epoch 006/059 - train_loss: 1.1130 - val_loss: 1.2190 - val_acc: 0.5183
2025-10-13 11:46:00,970 - INFO - _models.training_function_executor - Epoch 007/059 - train_loss: 1.0896 - val_loss: 1.1422 - val_acc: 0.5582
2025-10-13 11:46:02,451 - INFO - _models.training_function_executor - Epoch 008/059 - train_loss: 1.0680 - val_loss: 1.0933 - val_acc: 0.5811
2025-10-13 11:46:03,935 - INFO - _models.training_function_executor - Epoch 009/059 - train_loss: 1.0342 - val_loss: 1.0562 - val_acc: 0.6557
2025-10-13 11:46:05,407 - INFO - _models.training_function_executor - Epoch 010/059 - train_loss: 1.0132 - val_loss: 1.0372 - val_acc: 0.6230
2025-10-13 11:46:06,893 - INFO - _models.training_function_executor - Epoch 011/059 - train_loss: 0.9974 - val_loss: 0.9974 - val_acc: 0.6390
2025-10-13 11:46:08,393 - INFO - _models.training_function_executor - Epoch 012/059 - train_loss: 0.9870 - val_loss: 1.0437 - val_acc: 0.6363
2025-10-13 11:46:09,877 - INFO - _models.training_function_executor - Epoch 013/059 - train_loss: 0.9766 - val_loss: 1.1475 - val_acc: 0.6145
2025-10-13 11:46:11,360 - INFO - _models.training_function_executor - Epoch 014/059 - train_loss: 0.9785 - val_loss: 1.0112 - val_acc: 0.6504
2025-10-13 11:46:12,840 - INFO - _models.training_function_executor - Epoch 015/059 - train_loss: 0.9690 - val_loss: 1.0776 - val_acc: 0.5956
2025-10-13 11:46:14,352 - INFO - _models.training_function_executor - Epoch 016/059 - train_loss: 0.9668 - val_loss: 0.9494 - val_acc: 0.6807
2025-10-13 11:46:15,855 - INFO - _models.training_function_executor - Epoch 017/059 - train_loss: 0.9597 - val_loss: 0.9720 - val_acc: 0.6656
2025-10-13 11:46:17,351 - INFO - _models.training_function_executor - Epoch 018/059 - train_loss: 0.9527 - val_loss: 0.9721 - val_acc: 0.6690
2025-10-13 11:46:18,828 - INFO - _models.training_function_executor - Epoch 019/059 - train_loss: 0.9540 - val_loss: 1.0849 - val_acc: 0.6187
2025-10-13 11:46:20,303 - INFO - _models.training_function_executor - Epoch 020/059 - train_loss: 0.9492 - val_loss: 0.9967 - val_acc: 0.6425
2025-10-13 11:46:21,801 - INFO - _models.training_function_executor - Epoch 021/059 - train_loss: 0.9453 - val_loss: 1.0246 - val_acc: 0.6350
2025-10-13 11:46:23,299 - INFO - _models.training_function_executor - Epoch 022/059 - train_loss: 0.9432 - val_loss: 1.0025 - val_acc: 0.6634
2025-10-13 11:46:24,800 - INFO - _models.training_function_executor - Epoch 023/059 - train_loss: 0.9373 - val_loss: 1.2208 - val_acc: 0.5978
2025-10-13 11:46:26,282 - INFO - _models.training_function_executor - Epoch 024/059 - train_loss: 0.9350 - val_loss: 0.9309 - val_acc: 0.6878
2025-10-13 11:46:27,770 - INFO - _models.training_function_executor - Epoch 025/059 - train_loss: 0.9266 - val_loss: 1.0765 - val_acc: 0.5816
2025-10-13 11:46:29,246 - INFO - _models.training_function_executor - Epoch 026/059 - train_loss: 0.9269 - val_loss: 0.9764 - val_acc: 0.6681
2025-10-13 11:46:30,742 - INFO - _models.training_function_executor - Epoch 027/059 - train_loss: 0.9188 - val_loss: 1.0237 - val_acc: 0.6335
2025-10-13 11:46:32,266 - INFO - _models.training_function_executor - Epoch 028/059 - train_loss: 0.9153 - val_loss: 0.9510 - val_acc: 0.6710
2025-10-13 11:46:33,751 - INFO - _models.training_function_executor - Epoch 029/059 - train_loss: 0.9202 - val_loss: 0.9497 - val_acc: 0.6600
2025-10-13 11:46:35,253 - INFO - _models.training_function_executor - Epoch 030/059 - train_loss: 0.9151 - val_loss: 0.8892 - val_acc: 0.7107
2025-10-13 11:46:36,758 - INFO - _models.training_function_executor - Epoch 031/059 - train_loss: 0.9097 - val_loss: 0.9690 - val_acc: 0.6558
2025-10-13 11:46:38,244 - INFO - _models.training_function_executor - Epoch 032/059 - train_loss: 0.9088 - val_loss: 0.9873 - val_acc: 0.6518
2025-10-13 11:46:39,747 - INFO - _models.training_function_executor - Epoch 033/059 - train_loss: 0.9070 - val_loss: 1.0460 - val_acc: 0.6112
2025-10-13 11:46:41,250 - INFO - _models.training_function_executor - Epoch 034/059 - train_loss: 0.9109 - val_loss: 0.9222 - val_acc: 0.6868
2025-10-13 11:46:42,756 - INFO - _models.training_function_executor - Epoch 035/059 - train_loss: 0.8995 - val_loss: 1.0245 - val_acc: 0.6276
2025-10-13 11:46:44,247 - INFO - _models.training_function_executor - Epoch 036/059 - train_loss: 0.8993 - val_loss: 1.1474 - val_acc: 0.5990
2025-10-13 11:46:45,734 - INFO - _models.training_function_executor - Epoch 037/059 - train_loss: 0.8960 - val_loss: 0.8928 - val_acc: 0.7008
2025-10-13 11:46:47,258 - INFO - _models.training_function_executor - Epoch 038/059 - train_loss: 0.9004 - val_loss: 1.0667 - val_acc: 0.6138
2025-10-13 11:46:48,745 - INFO - _models.training_function_executor - Epoch 039/059 - train_loss: 0.8904 - val_loss: 1.0265 - val_acc: 0.6396
2025-10-13 11:46:50,243 - INFO - _models.training_function_executor - Epoch 040/059 - train_loss: 0.8923 - val_loss: 0.9669 - val_acc: 0.6531
2025-10-13 11:46:51,746 - INFO - _models.training_function_executor - Epoch 041/059 - train_loss: 0.8884 - val_loss: 0.9564 - val_acc: 0.6576
2025-10-13 11:46:53,238 - INFO - _models.training_function_executor - Epoch 042/059 - train_loss: 0.8922 - val_loss: 1.0505 - val_acc: 0.6213
2025-10-13 11:46:54,715 - INFO - _models.training_function_executor - Epoch 043/059 - train_loss: 0.8905 - val_loss: 0.9270 - val_acc: 0.6746
2025-10-13 11:46:56,207 - INFO - _models.training_function_executor - Epoch 044/059 - train_loss: 0.8859 - val_loss: 0.9866 - val_acc: 0.6555
2025-10-13 11:46:57,721 - INFO - _models.training_function_executor - Epoch 045/059 - train_loss: 0.8810 - val_loss: 2.0173 - val_acc: 0.3761
2025-10-13 11:46:59,242 - INFO - _models.training_function_executor - Epoch 046/059 - train_loss: 0.8913 - val_loss: 0.9357 - val_acc: 0.6734
2025-10-13 11:47:00,748 - INFO - _models.training_function_executor - Epoch 047/059 - train_loss: 0.8837 - val_loss: 0.8598 - val_acc: 0.7219
2025-10-13 11:47:02,270 - INFO - _models.training_function_executor - Epoch 048/059 - train_loss: 0.8820 - val_loss: 1.0328 - val_acc: 0.6158
2025-10-13 11:47:03,766 - INFO - _models.training_function_executor - Epoch 049/059 - train_loss: 0.8796 - val_loss: 1.0945 - val_acc: 0.6023
2025-10-13 11:47:05,282 - INFO - _models.training_function_executor - Epoch 050/059 - train_loss: 0.8809 - val_loss: 0.9658 - val_acc: 0.6695
2025-10-13 11:47:06,799 - INFO - _models.training_function_executor - Epoch 051/059 - train_loss: 0.8820 - val_loss: 0.8729 - val_acc: 0.7125
2025-10-13 11:47:08,323 - INFO - _models.training_function_executor - Epoch 052/059 - train_loss: 0.8760 - val_loss: 0.8798 - val_acc: 0.7055
2025-10-13 11:47:09,835 - INFO - _models.training_function_executor - Epoch 053/059 - train_loss: 0.8765 - val_loss: 0.8777 - val_acc: 0.7093
2025-10-13 11:47:11,320 - INFO - _models.training_function_executor - Epoch 054/059 - train_loss: 0.8789 - val_loss: 0.8745 - val_acc: 0.7019
2025-10-13 11:47:12,835 - INFO - _models.training_function_executor - Epoch 055/059 - train_loss: 0.8775 - val_loss: 1.0143 - val_acc: 0.6285
2025-10-13 11:47:14,347 - INFO - _models.training_function_executor - Epoch 056/059 - train_loss: 0.8733 - val_loss: 2.4586 - val_acc: 0.2594
2025-10-13 11:47:15,812 - INFO - _models.training_function_executor - Epoch 057/059 - train_loss: 0.8718 - val_loss: 0.9431 - val_acc: 0.6701
2025-10-13 11:47:17,340 - INFO - _models.training_function_executor - Epoch 058/059 - train_loss: 0.8757 - val_loss: 1.1308 - val_acc: 0.6250
2025-10-13 11:47:18,839 - INFO - _models.training_function_executor - Epoch 059/059 - train_loss: 0.8765 - val_loss: 0.9020 - val_acc: 0.6862
2025-10-13 11:47:20,303 - INFO - _models.training_function_executor - Model: 1,167 parameters, 1.3KB storage
2025-10-13 11:47:20,303 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3956825644727098, 1.3320796627826443, 1.3073905133934007, 1.1733591109253454, 1.1332582960939925, 1.1129569661003917, 1.0895608810014894, 1.067973722934222, 1.0342371920250828, 1.0131926842824037, 0.9973706012845331, 0.9869772660010421, 0.9765946063955305, 0.9785197970330569, 0.9690363052052386, 0.9667900527403994, 0.9596799632907956, 0.9527271705404795, 0.9539802383408498, 0.9491814809701724, 0.9452948481376495, 0.9431782220684234, 0.9372576202259725, 0.9350487074528201, 0.9265730300482061, 0.9269145177217643, 0.9187553476778243, 0.9152863981175514, 0.9201601761848642, 0.9151375081558347, 0.9097182017587723, 0.9088294457254353, 0.9070282066289803, 0.9109283781235227, 0.8995114935416628, 0.8993201454410947, 0.8959662261691843, 0.9004194133340958, 0.8904162227877963, 0.8922959229810112, 0.8884442377057074, 0.8922116319992177, 0.8905002033539405, 0.885869201680852, 0.8810061276021602, 0.8913226683614636, 0.8837297289864684, 0.8819575578881845, 0.8795955746082897, 0.8809364240904726, 0.8819663473096894, 0.8760181277374892, 0.8765252375460856, 0.8789093317499852, 0.8775010070351816, 0.8733160945139943, 0.8718186309799099, 0.8756978616332274, 0.8765290487801483], 'val_losses': [1.4356741634414962, 1.8045661235798645, 1.3520465472965422, 1.146156959238276, 1.1131558183777528, 1.219011657839686, 1.1422186008399293, 1.0933268822946038, 1.0562242458114517, 1.0371578078525319, 0.9973691177818798, 1.043673158609913, 1.1475052116298576, 1.0112439643931965, 1.0776455355224637, 0.9494154133035622, 0.9719770871387063, 0.972142131607308, 1.0849380002474092, 0.9966523758715001, 1.0245692732036218, 1.0024854580672589, 1.220775286384425, 0.9308570450654929, 1.076478584062231, 0.9764394740520927, 1.0236506179616633, 0.9510325462533579, 0.9496977257903824, 0.8891859159296027, 0.969022589106221, 0.987345742269709, 1.0459993419256668, 0.9221779428080825, 1.0244700442171615, 1.147444862354707, 0.8928017250132135, 1.0666517860037403, 1.026546500219012, 0.9668597608835997, 0.9563660020172324, 1.0504745023418316, 0.9270196618589855, 0.986563955147783, 2.017262283721753, 0.9357270027817568, 0.8598316991333366, 1.0328327450336674, 1.0944541959775926, 0.9657603663750616, 0.872942940167376, 0.8798027990537797, 0.8776533456586397, 0.874519827839875, 1.0142908531508747, 2.4585953498996553, 0.9431206493432763, 1.1307927784404013, 0.9019705654233746], 'val_acc': [0.40960798039901997, 0.23739936996849842, 0.4424221211060553, 0.5656282814140707, 0.598092404620231, 0.518288414420721, 0.558190409520476, 0.5811165558277914, 0.6556702835141757, 0.6230311515575779, 0.6390444522226111, 0.6363318165908295, 0.6144557227861394, 0.65042002100105, 0.595554777738887, 0.6806965348267413, 0.6656457822891144, 0.6689709485474273, 0.6186559327966399, 0.6424571228561428, 0.6350192509625481, 0.6633706685334266, 0.5978298914945748, 0.687784389219461, 0.581641582079104, 0.6680959047952397, 0.6335316765838291, 0.6709835491774588, 0.6600455022751137, 0.7107105355267763, 0.6557577878893944, 0.6518200910045502, 0.6112180609030452, 0.6868218410920546, 0.6275813790689534, 0.5989674483724187, 0.7008225411270563, 0.613843192159608, 0.6395694784739236, 0.6531326566328316, 0.6575953797689884, 0.6212810640532027, 0.674571228561428, 0.6554952747637381, 0.3760938046902345, 0.6734336716835841, 0.7219110955547777, 0.6157682884144208, 0.6022926146307316, 0.6694959747987399, 0.7124606230311515, 0.7055477773888694, 0.7093104655232761, 0.7018725936296815, 0.628456422821141, 0.2593629681484074, 0.6701085054252712, 0.6250437521876093, 0.6862093104655232], 'final_state_dict_size_bytes': 4876, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.006159683919505516, 'batch_size': 64, 'epochs': 59, 'weight_decay': 5.149255649228264e-06, 'dropout': 0.01793289707169983, 'channel_multiplier': 3, 'kernel_size1': 79, 'stride1': 8, 'kernel_size2': 28, 'stride2': 2, 'gcn_hidden': 10, 'label_smoothing': 0.05081374946620848, 'grad_clip_norm': 4.967372765118303, 'use_amp': False, 'calibrate_batches': 114, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1167, 'model_storage_size_kb': 1.25361328125, 'model_size_validation': 'PASS'}
2025-10-13 11:47:20,303 - INFO - _models.training_function_executor - BO Objective: base=0.6862, size_penalty=0.0000, final=0.6862
2025-10-13 11:47:20,303 - INFO - _models.training_function_executor - Model: 1,167 parameters, 1.3KB (PASS 256KB limit)
2025-10-13 11:47:20,303 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 92.505s
2025-10-13 11:47:20,406 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6862
2025-10-13 11:47:20,406 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-13 11:47:20,406 - INFO - bo.run_bo - Recorded observation #34: hparams={'lr': 0.006159683919505516, 'batch_size': np.int64(64), 'epochs': np.int64(59), 'weight_decay': 5.149255649228264e-06, 'dropout': 0.01793289707169983, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(79), 'stride1': np.int64(8), 'kernel_size2': np.int64(28), 'stride2': np.int64(2), 'gcn_hidden': np.int64(10), 'label_smoothing': 0.05081374946620848, 'grad_clip_norm': 4.967372765118303, 'use_amp': np.False_, 'calibrate_batches': np.int64(114), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.6862
2025-10-13 11:47:20,406 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 34: {'lr': 0.006159683919505516, 'batch_size': np.int64(64), 'epochs': np.int64(59), 'weight_decay': 5.149255649228264e-06, 'dropout': 0.01793289707169983, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(79), 'stride1': np.int64(8), 'kernel_size2': np.int64(28), 'stride2': np.int64(2), 'gcn_hidden': np.int64(10), 'label_smoothing': 0.05081374946620848, 'grad_clip_norm': 4.967372765118303, 'use_amp': np.False_, 'calibrate_batches': np.int64(114), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.6862
2025-10-13 11:47:20,407 - INFO - bo.run_bo - üîçBO Trial 35: Using RF surrogate + Expected Improvement
2025-10-13 11:47:20,407 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:47:20,407 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 35 (NaN monitoring active)
2025-10-13 11:47:20,407 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:47:20,407 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:47:20,407 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0009367396815964243, 'batch_size': 128, 'epochs': 54, 'weight_decay': 1.205112490681421e-06, 'dropout': 0.006194292847850093, 'channel_multiplier': 2, 'kernel_size1': 53, 'stride1': 6, 'kernel_size2': 30, 'stride2': 8, 'gcn_hidden': 17, 'label_smoothing': 0.03698263615528362, 'grad_clip_norm': 4.962538596935051, 'use_amp': False, 'calibrate_batches': 12, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:47:20,408 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0009367396815964243, 'batch_size': 128, 'epochs': 54, 'weight_decay': 1.205112490681421e-06, 'dropout': 0.006194292847850093, 'channel_multiplier': 2, 'kernel_size1': 53, 'stride1': 6, 'kernel_size2': 30, 'stride2': 8, 'gcn_hidden': 17, 'label_smoothing': 0.03698263615528362, 'grad_clip_norm': 4.962538596935051, 'use_amp': False, 'calibrate_batches': 12, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:47:24,728 - INFO - _models.training_function_executor - Epoch 001/054 - train_loss: 1.5217 - val_loss: 1.4654 - val_acc: 0.3981
2025-10-13 11:47:26,225 - INFO - _models.training_function_executor - Epoch 002/054 - train_loss: 1.4243 - val_loss: 1.6066 - val_acc: 0.3148
2025-10-13 11:47:27,735 - INFO - _models.training_function_executor - Epoch 003/054 - train_loss: 1.4018 - val_loss: 1.4072 - val_acc: 0.4226
2025-10-13 11:47:29,255 - INFO - _models.training_function_executor - Epoch 004/054 - train_loss: 1.3922 - val_loss: 1.3886 - val_acc: 0.4338
2025-10-13 11:47:30,777 - INFO - _models.training_function_executor - Epoch 005/054 - train_loss: 1.3781 - val_loss: 1.3889 - val_acc: 0.4171
2025-10-13 11:47:32,305 - INFO - _models.training_function_executor - Epoch 006/054 - train_loss: 1.3687 - val_loss: 1.3998 - val_acc: 0.4092
2025-10-13 11:47:33,805 - INFO - _models.training_function_executor - Epoch 007/054 - train_loss: 1.3574 - val_loss: 1.3903 - val_acc: 0.4122
2025-10-13 11:47:35,324 - INFO - _models.training_function_executor - Epoch 008/054 - train_loss: 1.3477 - val_loss: 1.3893 - val_acc: 0.4138
2025-10-13 11:47:36,846 - INFO - _models.training_function_executor - Epoch 009/054 - train_loss: 1.3364 - val_loss: 1.3671 - val_acc: 0.4058
2025-10-13 11:47:38,392 - INFO - _models.training_function_executor - Epoch 010/054 - train_loss: 1.3136 - val_loss: 1.3797 - val_acc: 0.4435
2025-10-13 11:47:39,906 - INFO - _models.training_function_executor - Epoch 011/054 - train_loss: 1.2474 - val_loss: 1.2133 - val_acc: 0.5102
2025-10-13 11:47:41,446 - INFO - _models.training_function_executor - Epoch 012/054 - train_loss: 1.1884 - val_loss: 1.2001 - val_acc: 0.5179
2025-10-13 11:47:42,990 - INFO - _models.training_function_executor - Epoch 013/054 - train_loss: 1.1624 - val_loss: 1.1648 - val_acc: 0.5256
2025-10-13 11:47:44,530 - INFO - _models.training_function_executor - Epoch 014/054 - train_loss: 1.1443 - val_loss: 1.1502 - val_acc: 0.5405
2025-10-13 11:47:46,058 - INFO - _models.training_function_executor - Epoch 015/054 - train_loss: 1.1305 - val_loss: 1.1383 - val_acc: 0.5475
2025-10-13 11:47:47,569 - INFO - _models.training_function_executor - Epoch 016/054 - train_loss: 1.1195 - val_loss: 1.3639 - val_acc: 0.4607
2025-10-13 11:47:49,086 - INFO - _models.training_function_executor - Epoch 017/054 - train_loss: 1.1114 - val_loss: 1.1321 - val_acc: 0.5733
2025-10-13 11:47:50,617 - INFO - _models.training_function_executor - Epoch 018/054 - train_loss: 1.1058 - val_loss: 1.1064 - val_acc: 0.5848
2025-10-13 11:47:52,135 - INFO - _models.training_function_executor - Epoch 019/054 - train_loss: 1.0973 - val_loss: 1.0820 - val_acc: 0.6062
2025-10-13 11:47:53,667 - INFO - _models.training_function_executor - Epoch 020/054 - train_loss: 1.0918 - val_loss: 1.1077 - val_acc: 0.5875
2025-10-13 11:47:55,200 - INFO - _models.training_function_executor - Epoch 021/054 - train_loss: 1.0862 - val_loss: 1.2012 - val_acc: 0.5368
2025-10-13 11:47:56,734 - INFO - _models.training_function_executor - Epoch 022/054 - train_loss: 1.0802 - val_loss: 1.0741 - val_acc: 0.6118
2025-10-13 11:47:58,280 - INFO - _models.training_function_executor - Epoch 023/054 - train_loss: 1.0780 - val_loss: 1.0643 - val_acc: 0.5956
2025-10-13 11:47:59,814 - INFO - _models.training_function_executor - Epoch 024/054 - train_loss: 1.0743 - val_loss: 1.0876 - val_acc: 0.5920
2025-10-13 11:48:01,339 - INFO - _models.training_function_executor - Epoch 025/054 - train_loss: 1.0734 - val_loss: 1.0909 - val_acc: 0.5833
2025-10-13 11:48:02,879 - INFO - _models.training_function_executor - Epoch 026/054 - train_loss: 1.0678 - val_loss: 1.0554 - val_acc: 0.6175
2025-10-13 11:48:04,404 - INFO - _models.training_function_executor - Epoch 027/054 - train_loss: 1.0687 - val_loss: 1.0705 - val_acc: 0.5962
2025-10-13 11:48:05,976 - INFO - _models.training_function_executor - Epoch 028/054 - train_loss: 1.0651 - val_loss: 1.0855 - val_acc: 0.5711
2025-10-13 11:48:07,484 - INFO - _models.training_function_executor - Epoch 029/054 - train_loss: 1.0639 - val_loss: 1.0928 - val_acc: 0.5891
2025-10-13 11:48:08,999 - INFO - _models.training_function_executor - Epoch 030/054 - train_loss: 1.0590 - val_loss: 1.4721 - val_acc: 0.3270
2025-10-13 11:48:10,527 - INFO - _models.training_function_executor - Epoch 031/054 - train_loss: 1.0555 - val_loss: 1.1367 - val_acc: 0.5440
2025-10-13 11:48:12,055 - INFO - _models.training_function_executor - Epoch 032/054 - train_loss: 1.0507 - val_loss: 1.1384 - val_acc: 0.5680
2025-10-13 11:48:13,597 - INFO - _models.training_function_executor - Epoch 033/054 - train_loss: 1.0446 - val_loss: 1.0640 - val_acc: 0.6055
2025-10-13 11:48:15,112 - INFO - _models.training_function_executor - Epoch 034/054 - train_loss: 1.0390 - val_loss: 1.0568 - val_acc: 0.5892
2025-10-13 11:48:16,619 - INFO - _models.training_function_executor - Epoch 035/054 - train_loss: 1.0335 - val_loss: 1.0524 - val_acc: 0.6145
2025-10-13 11:48:18,159 - INFO - _models.training_function_executor - Epoch 036/054 - train_loss: 1.0317 - val_loss: 1.0560 - val_acc: 0.6094
2025-10-13 11:48:19,689 - INFO - _models.training_function_executor - Epoch 037/054 - train_loss: 1.0252 - val_loss: 1.0493 - val_acc: 0.6092
2025-10-13 11:48:21,230 - INFO - _models.training_function_executor - Epoch 038/054 - train_loss: 1.0187 - val_loss: 1.2375 - val_acc: 0.4926
2025-10-13 11:48:22,761 - INFO - _models.training_function_executor - Epoch 039/054 - train_loss: 1.0158 - val_loss: 1.0224 - val_acc: 0.6401
2025-10-13 11:48:24,318 - INFO - _models.training_function_executor - Epoch 040/054 - train_loss: 1.0114 - val_loss: 1.0177 - val_acc: 0.6411
2025-10-13 11:48:25,840 - INFO - _models.training_function_executor - Epoch 041/054 - train_loss: 1.0097 - val_loss: 1.0301 - val_acc: 0.6313
2025-10-13 11:48:27,368 - INFO - _models.training_function_executor - Epoch 042/054 - train_loss: 1.0050 - val_loss: 1.0372 - val_acc: 0.6083
2025-10-13 11:48:28,902 - INFO - _models.training_function_executor - Epoch 043/054 - train_loss: 1.0048 - val_loss: 1.0175 - val_acc: 0.6299
2025-10-13 11:48:30,429 - INFO - _models.training_function_executor - Epoch 044/054 - train_loss: 1.0030 - val_loss: 1.0254 - val_acc: 0.6457
2025-10-13 11:48:31,948 - INFO - _models.training_function_executor - Epoch 045/054 - train_loss: 0.9994 - val_loss: 1.0126 - val_acc: 0.6461
2025-10-13 11:48:33,488 - INFO - _models.training_function_executor - Epoch 046/054 - train_loss: 0.9957 - val_loss: 1.0444 - val_acc: 0.6158
2025-10-13 11:48:35,026 - INFO - _models.training_function_executor - Epoch 047/054 - train_loss: 0.9958 - val_loss: 1.0002 - val_acc: 0.6530
2025-10-13 11:48:36,548 - INFO - _models.training_function_executor - Epoch 048/054 - train_loss: 0.9966 - val_loss: 1.0041 - val_acc: 0.6341
2025-10-13 11:48:38,074 - INFO - _models.training_function_executor - Epoch 049/054 - train_loss: 0.9940 - val_loss: 0.9924 - val_acc: 0.6507
2025-10-13 11:48:39,604 - INFO - _models.training_function_executor - Epoch 050/054 - train_loss: 0.9909 - val_loss: 1.0158 - val_acc: 0.6115
2025-10-13 11:48:41,137 - INFO - _models.training_function_executor - Epoch 051/054 - train_loss: 0.9898 - val_loss: 0.9952 - val_acc: 0.6543
2025-10-13 11:48:42,684 - INFO - _models.training_function_executor - Epoch 052/054 - train_loss: 0.9886 - val_loss: 1.0080 - val_acc: 0.6308
2025-10-13 11:48:44,218 - INFO - _models.training_function_executor - Epoch 053/054 - train_loss: 0.9881 - val_loss: 1.0607 - val_acc: 0.6180
2025-10-13 11:48:45,738 - INFO - _models.training_function_executor - Epoch 054/054 - train_loss: 0.9887 - val_loss: 0.9953 - val_acc: 0.6468
2025-10-13 11:48:46,844 - INFO - _models.training_function_executor - Model: 908 parameters, 3.9KB storage
2025-10-13 11:48:46,844 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.521687464318494, 1.4243092343320702, 1.4018054317668638, 1.3922449375809511, 1.3781062689201373, 1.3686823229460938, 1.3573875815291734, 1.34774880134688, 1.3364218052425791, 1.3136318153462128, 1.2473937776233084, 1.1884126565570718, 1.1624049857065817, 1.1443295754625282, 1.1304789227457952, 1.1194663546825565, 1.111356223426501, 1.1057754051948203, 1.097258096355469, 1.0917911503254052, 1.0861507568861748, 1.0801500417070453, 1.077994080869977, 1.0743197256508181, 1.0734422837765767, 1.0677730942632002, 1.0686936764438377, 1.065062522053677, 1.0639415039730773, 1.0590330339579637, 1.0555135845762473, 1.0506726905604447, 1.0446269573095506, 1.0389960372118336, 1.033489479190785, 1.031704868058621, 1.0252388187501245, 1.0187203269301905, 1.0158481939630906, 1.0114488292082566, 1.0097265351598899, 1.0049564719492212, 1.0047545407800604, 1.0029620369873473, 0.9993794465507291, 0.9956993352795215, 0.9957950471955493, 0.9966246925495202, 0.9939553009115987, 0.990906048079742, 0.9897707107812322, 0.9885987040877217, 0.9880798537705301, 0.9886775983977993], 'val_losses': [1.4654170719109343, 1.6065943580763633, 1.4071765962830365, 1.3885832593121394, 1.3889246682917107, 1.399792876575725, 1.390335894315277, 1.3893143274920112, 1.3671419427325602, 1.3796933136663947, 1.2132697056171817, 1.2001066472841635, 1.1647927035891512, 1.1502361159079302, 1.1383189133593032, 1.3639127225945953, 1.132082884612933, 1.106390792171063, 1.0820250078894935, 1.1076654151139411, 1.2011984152772186, 1.0740638582865842, 1.0643242064747396, 1.0875552716604011, 1.0909384994353286, 1.0553877700823022, 1.070529763165328, 1.085546140992896, 1.0928036175618692, 1.472078809839969, 1.1367062173358702, 1.1383844127511493, 1.0639689659630038, 1.056826384200222, 1.0524495950227524, 1.0560377152349134, 1.0492558344118987, 1.2374616409457977, 1.0223629929863325, 1.0176883925079756, 1.030055028765528, 1.03719969429167, 1.0175493876751294, 1.0253621197514573, 1.0125505196117712, 1.0444491244213623, 1.0001707789695133, 1.0041411878514381, 0.9924004957898747, 1.0158489057138995, 0.9951691246967362, 1.0080326664977697, 1.0607200954441929, 0.9953424686896538], 'val_acc': [0.3980574028701435, 0.31475323766188307, 0.42264613230661535, 0.433759187959398, 0.4171333566678334, 0.40917045852292616, 0.4122331116555828, 0.4138081904095205, 0.4057577878893945, 0.4434721736086804, 0.510238011900595, 0.5178508925446272, 0.5255512775638782, 0.5405145257262863, 0.5475148757437872, 0.4607105355267763, 0.5733286664333217, 0.5847917395869794, 0.6062303115155758, 0.587504375218761, 0.5368393419670984, 0.6118305915295765, 0.5956422821141057, 0.5919670983549178, 0.5833041652082605, 0.617518375918796, 0.5961673083654183, 0.5710535526776339, 0.5890794539726987, 0.3270038501925096, 0.5440147007350368, 0.5679908995449773, 0.6055302765138257, 0.5891669583479174, 0.6145432271613581, 0.6093804690234512, 0.6092054602730137, 0.4926496324816241, 0.6400945047252362, 0.6411445572278613, 0.6313440672033601, 0.6083304165208261, 0.6298564928246412, 0.6456947847392369, 0.6461323066153307, 0.6157682884144208, 0.6530451522576128, 0.6341442072103605, 0.6506825341267063, 0.6114805740287015, 0.6542702135106755, 0.6308190409520475, 0.6180434021701086, 0.6468323416170808], 'final_state_dict_size_bytes': 3792, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0009367396815964243, 'batch_size': 128, 'epochs': 54, 'weight_decay': 1.205112490681421e-06, 'dropout': 0.006194292847850093, 'channel_multiplier': 2, 'kernel_size1': 53, 'stride1': 6, 'kernel_size2': 30, 'stride2': 8, 'gcn_hidden': 17, 'label_smoothing': 0.03698263615528362, 'grad_clip_norm': 4.962538596935051, 'use_amp': False, 'calibrate_batches': 12, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 908, 'model_storage_size_kb': 3.9015625000000003, 'model_size_validation': 'PASS'}
2025-10-13 11:48:46,844 - INFO - _models.training_function_executor - BO Objective: base=0.6468, size_penalty=0.0000, final=0.6468
2025-10-13 11:48:46,844 - INFO - _models.training_function_executor - Model: 908 parameters, 3.9KB (PASS 256KB limit)
2025-10-13 11:48:46,844 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 86.437s
2025-10-13 11:48:46,947 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6468
2025-10-13 11:48:46,947 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-13 11:48:46,947 - INFO - bo.run_bo - Recorded observation #35: hparams={'lr': 0.0009367396815964243, 'batch_size': np.int64(128), 'epochs': np.int64(54), 'weight_decay': 1.205112490681421e-06, 'dropout': 0.006194292847850093, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(53), 'stride1': np.int64(6), 'kernel_size2': np.int64(30), 'stride2': np.int64(8), 'gcn_hidden': np.int64(17), 'label_smoothing': 0.03698263615528362, 'grad_clip_norm': 4.962538596935051, 'use_amp': np.False_, 'calibrate_batches': np.int64(12), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.6468
2025-10-13 11:48:46,947 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 35: {'lr': 0.0009367396815964243, 'batch_size': np.int64(128), 'epochs': np.int64(54), 'weight_decay': 1.205112490681421e-06, 'dropout': 0.006194292847850093, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(53), 'stride1': np.int64(6), 'kernel_size2': np.int64(30), 'stride2': np.int64(8), 'gcn_hidden': np.int64(17), 'label_smoothing': 0.03698263615528362, 'grad_clip_norm': 4.962538596935051, 'use_amp': np.False_, 'calibrate_batches': np.int64(12), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.6468
2025-10-13 11:48:46,948 - INFO - bo.run_bo - üîçBO Trial 36: Using RF surrogate + Expected Improvement
2025-10-13 11:48:46,948 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:48:46,948 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 36 (NaN monitoring active)
2025-10-13 11:48:46,948 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:48:46,948 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:48:46,948 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007325922372954892, 'batch_size': 48, 'epochs': 60, 'weight_decay': 1.7618229803300074e-06, 'dropout': 0.02453921237825645, 'channel_multiplier': 8, 'kernel_size1': 50, 'stride1': 10, 'kernel_size2': 29, 'stride2': 8, 'gcn_hidden': 15, 'label_smoothing': 0.012499038579141123, 'grad_clip_norm': 2.8533224776948214, 'use_amp': False, 'calibrate_batches': 127, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:48:46,949 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007325922372954892, 'batch_size': 48, 'epochs': 60, 'weight_decay': 1.7618229803300074e-06, 'dropout': 0.02453921237825645, 'channel_multiplier': 8, 'kernel_size1': 50, 'stride1': 10, 'kernel_size2': 29, 'stride2': 8, 'gcn_hidden': 15, 'label_smoothing': 0.012499038579141123, 'grad_clip_norm': 2.8533224776948214, 'use_amp': False, 'calibrate_batches': 127, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:48:51,520 - INFO - _models.training_function_executor - Epoch 001/060 - train_loss: 1.1311 - val_loss: 1.0183 - val_acc: 0.5948
2025-10-13 11:48:53,311 - INFO - _models.training_function_executor - Epoch 002/060 - train_loss: 1.0137 - val_loss: 0.9896 - val_acc: 0.6073
2025-10-13 11:48:55,124 - INFO - _models.training_function_executor - Epoch 003/060 - train_loss: 0.9809 - val_loss: 0.9993 - val_acc: 0.6186
2025-10-13 11:48:56,913 - INFO - _models.training_function_executor - Epoch 004/060 - train_loss: 0.9605 - val_loss: 1.3491 - val_acc: 0.3691
2025-10-13 11:48:58,711 - INFO - _models.training_function_executor - Epoch 005/060 - train_loss: 0.9484 - val_loss: 0.9724 - val_acc: 0.6154
2025-10-13 11:49:00,504 - INFO - _models.training_function_executor - Epoch 006/060 - train_loss: 0.9247 - val_loss: 1.0477 - val_acc: 0.5837
2025-10-13 11:49:02,318 - INFO - _models.training_function_executor - Epoch 007/060 - train_loss: 0.9155 - val_loss: 1.0582 - val_acc: 0.5766
2025-10-13 11:49:04,127 - INFO - _models.training_function_executor - Epoch 008/060 - train_loss: 0.8998 - val_loss: 1.2569 - val_acc: 0.4530
2025-10-13 11:49:05,932 - INFO - _models.training_function_executor - Epoch 009/060 - train_loss: 0.8808 - val_loss: 1.0327 - val_acc: 0.5766
2025-10-13 11:49:07,744 - INFO - _models.training_function_executor - Epoch 010/060 - train_loss: 0.8805 - val_loss: 0.8696 - val_acc: 0.6614
2025-10-13 11:49:09,553 - INFO - _models.training_function_executor - Epoch 011/060 - train_loss: 0.8673 - val_loss: 0.9711 - val_acc: 0.6220
2025-10-13 11:49:11,338 - INFO - _models.training_function_executor - Epoch 012/060 - train_loss: 0.8616 - val_loss: 0.8586 - val_acc: 0.6751
2025-10-13 11:49:13,136 - INFO - _models.training_function_executor - Epoch 013/060 - train_loss: 0.8478 - val_loss: 0.8498 - val_acc: 0.6756
2025-10-13 11:49:14,946 - INFO - _models.training_function_executor - Epoch 014/060 - train_loss: 0.8457 - val_loss: 0.8804 - val_acc: 0.6742
2025-10-13 11:49:16,740 - INFO - _models.training_function_executor - Epoch 015/060 - train_loss: 0.8412 - val_loss: 0.8588 - val_acc: 0.6733
2025-10-13 11:49:18,551 - INFO - _models.training_function_executor - Epoch 016/060 - train_loss: 0.8335 - val_loss: 0.8920 - val_acc: 0.6588
2025-10-13 11:49:20,376 - INFO - _models.training_function_executor - Epoch 017/060 - train_loss: 0.8217 - val_loss: 0.8691 - val_acc: 0.6670
2025-10-13 11:49:22,186 - INFO - _models.training_function_executor - Epoch 018/060 - train_loss: 0.8156 - val_loss: 0.9097 - val_acc: 0.6602
2025-10-13 11:49:24,013 - INFO - _models.training_function_executor - Epoch 019/060 - train_loss: 0.8123 - val_loss: 0.9682 - val_acc: 0.6376
2025-10-13 11:49:25,821 - INFO - _models.training_function_executor - Epoch 020/060 - train_loss: 0.8025 - val_loss: 0.7995 - val_acc: 0.6944
2025-10-13 11:49:27,614 - INFO - _models.training_function_executor - Epoch 021/060 - train_loss: 0.7972 - val_loss: 0.8141 - val_acc: 0.6893
2025-10-13 11:49:29,424 - INFO - _models.training_function_executor - Epoch 022/060 - train_loss: 0.8047 - val_loss: 0.9996 - val_acc: 0.6229
2025-10-13 11:49:31,225 - INFO - _models.training_function_executor - Epoch 023/060 - train_loss: 0.7903 - val_loss: 0.8468 - val_acc: 0.6836
2025-10-13 11:49:33,032 - INFO - _models.training_function_executor - Epoch 024/060 - train_loss: 0.7913 - val_loss: 0.9116 - val_acc: 0.6621
2025-10-13 11:49:34,848 - INFO - _models.training_function_executor - Epoch 025/060 - train_loss: 0.7843 - val_loss: 1.0266 - val_acc: 0.6017
2025-10-13 11:49:36,647 - INFO - _models.training_function_executor - Epoch 026/060 - train_loss: 0.7852 - val_loss: 1.2356 - val_acc: 0.5636
2025-10-13 11:49:38,426 - INFO - _models.training_function_executor - Epoch 027/060 - train_loss: 0.7851 - val_loss: 0.9157 - val_acc: 0.6525
2025-10-13 11:49:40,238 - INFO - _models.training_function_executor - Epoch 028/060 - train_loss: 0.7790 - val_loss: 0.8598 - val_acc: 0.6672
2025-10-13 11:49:42,043 - INFO - _models.training_function_executor - Epoch 029/060 - train_loss: 0.7734 - val_loss: 0.8279 - val_acc: 0.6860
2025-10-13 11:49:43,863 - INFO - _models.training_function_executor - Epoch 030/060 - train_loss: 0.7741 - val_loss: 0.8505 - val_acc: 0.6825
2025-10-13 11:49:45,687 - INFO - _models.training_function_executor - Epoch 031/060 - train_loss: 0.7729 - val_loss: 0.8228 - val_acc: 0.6765
2025-10-13 11:49:47,491 - INFO - _models.training_function_executor - Epoch 032/060 - train_loss: 0.7723 - val_loss: 0.9399 - val_acc: 0.6490
2025-10-13 11:49:49,319 - INFO - _models.training_function_executor - Epoch 033/060 - train_loss: 0.7678 - val_loss: 0.7755 - val_acc: 0.7115
2025-10-13 11:49:51,144 - INFO - _models.training_function_executor - Epoch 034/060 - train_loss: 0.7690 - val_loss: 0.8213 - val_acc: 0.6838
2025-10-13 11:49:52,957 - INFO - _models.training_function_executor - Epoch 035/060 - train_loss: 0.7665 - val_loss: 0.8672 - val_acc: 0.6727
2025-10-13 11:49:54,765 - INFO - _models.training_function_executor - Epoch 036/060 - train_loss: 0.7610 - val_loss: 0.7800 - val_acc: 0.7068
2025-10-13 11:49:56,560 - INFO - _models.training_function_executor - Epoch 037/060 - train_loss: 0.7595 - val_loss: 0.7559 - val_acc: 0.7141
2025-10-13 11:49:58,371 - INFO - _models.training_function_executor - Epoch 038/060 - train_loss: 0.7582 - val_loss: 0.7987 - val_acc: 0.7055
2025-10-13 11:50:00,186 - INFO - _models.training_function_executor - Epoch 039/060 - train_loss: 0.7586 - val_loss: 0.7924 - val_acc: 0.6970
2025-10-13 11:50:01,989 - INFO - _models.training_function_executor - Epoch 040/060 - train_loss: 0.7571 - val_loss: 0.9003 - val_acc: 0.6453
2025-10-13 11:50:03,778 - INFO - _models.training_function_executor - Epoch 041/060 - train_loss: 0.7551 - val_loss: 0.7780 - val_acc: 0.7116
2025-10-13 11:50:05,593 - INFO - _models.training_function_executor - Epoch 042/060 - train_loss: 0.7522 - val_loss: 0.8306 - val_acc: 0.6820
2025-10-13 11:50:07,395 - INFO - _models.training_function_executor - Epoch 043/060 - train_loss: 0.7526 - val_loss: 0.7851 - val_acc: 0.7040
2025-10-13 11:50:09,198 - INFO - _models.training_function_executor - Epoch 044/060 - train_loss: 0.7522 - val_loss: 0.9564 - val_acc: 0.6396
2025-10-13 11:50:11,012 - INFO - _models.training_function_executor - Epoch 045/060 - train_loss: 0.7540 - val_loss: 0.7733 - val_acc: 0.7105
2025-10-13 11:50:12,830 - INFO - _models.training_function_executor - Epoch 046/060 - train_loss: 0.7492 - val_loss: 0.8010 - val_acc: 0.7072
2025-10-13 11:50:14,646 - INFO - _models.training_function_executor - Epoch 047/060 - train_loss: 0.7459 - val_loss: 0.8352 - val_acc: 0.6874
2025-10-13 11:50:16,454 - INFO - _models.training_function_executor - Epoch 048/060 - train_loss: 0.7446 - val_loss: 0.7938 - val_acc: 0.7020
2025-10-13 11:50:18,259 - INFO - _models.training_function_executor - Epoch 049/060 - train_loss: 0.7515 - val_loss: 0.9318 - val_acc: 0.6454
2025-10-13 11:50:20,062 - INFO - _models.training_function_executor - Epoch 050/060 - train_loss: 0.7496 - val_loss: 1.0464 - val_acc: 0.5949
2025-10-13 11:50:21,876 - INFO - _models.training_function_executor - Epoch 051/060 - train_loss: 0.7506 - val_loss: 1.0470 - val_acc: 0.5855
2025-10-13 11:50:23,681 - INFO - _models.training_function_executor - Epoch 052/060 - train_loss: 0.7521 - val_loss: 0.7758 - val_acc: 0.7082
2025-10-13 11:50:25,482 - INFO - _models.training_function_executor - Epoch 053/060 - train_loss: 0.7460 - val_loss: 1.1741 - val_acc: 0.5906
2025-10-13 11:50:27,284 - INFO - _models.training_function_executor - Epoch 054/060 - train_loss: 0.7478 - val_loss: 0.9025 - val_acc: 0.6489
2025-10-13 11:50:29,109 - INFO - _models.training_function_executor - Epoch 055/060 - train_loss: 0.7477 - val_loss: 0.7531 - val_acc: 0.7218
2025-10-13 11:50:30,926 - INFO - _models.training_function_executor - Epoch 056/060 - train_loss: 0.7467 - val_loss: 1.3006 - val_acc: 0.4959
2025-10-13 11:50:32,743 - INFO - _models.training_function_executor - Epoch 057/060 - train_loss: 0.7448 - val_loss: 0.7992 - val_acc: 0.7064
2025-10-13 11:50:34,559 - INFO - _models.training_function_executor - Epoch 058/060 - train_loss: 0.7470 - val_loss: 0.7998 - val_acc: 0.7018
2025-10-13 11:50:36,373 - INFO - _models.training_function_executor - Epoch 059/060 - train_loss: 0.7466 - val_loss: 0.8354 - val_acc: 0.6865
2025-10-13 11:50:38,170 - INFO - _models.training_function_executor - Epoch 060/060 - train_loss: 0.7472 - val_loss: 0.8791 - val_acc: 0.6602
2025-10-13 11:50:39,282 - INFO - _models.training_function_executor - Model: 2,066 parameters, 8.9KB storage
2025-10-13 11:50:39,282 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1311349064727159, 1.0136529085600254, 0.9808636355491881, 0.9604525398365217, 0.9484078659225186, 0.9247285536965333, 0.9154634877105755, 0.8998169271229112, 0.8807559553501194, 0.880499496216285, 0.8673034576757161, 0.8615923164960676, 0.8478083828758184, 0.8456528702314642, 0.8412378771053898, 0.8335307568238672, 0.8217199400437641, 0.8156150430075806, 0.8122777000022677, 0.8024604301749722, 0.7971880259549738, 0.8046869098681189, 0.7902648915329052, 0.7913436400210228, 0.7843455040646801, 0.7851765111563378, 0.7850797908953699, 0.778998850962479, 0.7734342512339197, 0.7740841676064792, 0.7728958384615998, 0.7723491633318086, 0.7678085190560545, 0.7690108727962353, 0.7664512528128085, 0.7610269235196045, 0.7595334874715761, 0.758157806647671, 0.7586235942271442, 0.7570940074509243, 0.755081448379329, 0.7521952107042794, 0.7525810158185956, 0.752191805405595, 0.7539713004793702, 0.749188973472216, 0.7458680084546964, 0.7446308130874975, 0.7515071392434854, 0.7496491882677548, 0.7505975681082285, 0.7520694091034636, 0.7460445745199095, 0.747806556165573, 0.7477454618010689, 0.7466611137100563, 0.7448397912593584, 0.7470265123699777, 0.7466006750488015, 0.7472295795949055], 'val_losses': [1.018346641586926, 0.9896476708136116, 0.9992793415199429, 1.3491435401039937, 0.9724234944045815, 1.0477129542038996, 1.0581817476116029, 1.2568543982497453, 1.0327111427960047, 0.8695671815616833, 0.9710958163179966, 0.8586148897229603, 0.8497609183176607, 0.8804315073238956, 0.858787848225915, 0.8920078291983132, 0.869131401009104, 0.9096580823902322, 0.9682157611070833, 0.7994722645308615, 0.8140842587976219, 0.9995915745370322, 0.8467872301556658, 0.9116317422021967, 1.0266401118275832, 1.235604693161928, 0.9157045094083146, 0.859761812833376, 0.8279228913938411, 0.8504819590226729, 0.8227756066592706, 0.9399289318135788, 0.7755439049470746, 0.8213378793925391, 0.8671689701739582, 0.7800416348695671, 0.7558832720813945, 0.798712298905136, 0.7923500060117199, 0.9002609950577333, 0.7779571831247212, 0.8306257613772565, 0.7850533489543406, 0.956413928052951, 0.7733017558353866, 0.801047952996295, 0.8352280380553118, 0.7938011537951776, 0.9317671742771404, 1.0464479393127877, 1.0469504983474376, 0.7757815986318859, 1.1741488760569982, 0.9024976291229226, 0.7530506570980938, 1.3005962605696688, 0.7991775161931262, 0.7997922585859222, 0.83544072282452, 0.8790807274617137], 'val_acc': [0.5947672383619181, 0.607280364018201, 0.6185684284214211, 0.36909345467273363, 0.6154182709135457, 0.5836541827091355, 0.5765663283164159, 0.45301015050752536, 0.5765663283164159, 0.6614455722786139, 0.6219810990549528, 0.6750962548127406, 0.6756212810640532, 0.674221211060553, 0.6733461673083654, 0.6588204410220511, 0.6670458522926146, 0.6602205110255512, 0.6375568778438921, 0.6944347217360868, 0.6892719635981799, 0.6229436471823592, 0.6835841792089604, 0.662145607280364, 0.6016800840042003, 0.5636156807840392, 0.6525201260063003, 0.6672208610430521, 0.6860343017150857, 0.6825341267063353, 0.6764963248162408, 0.6490199509975498, 0.7114980749037452, 0.6838466923346167, 0.6727336366818341, 0.7067728386419321, 0.714123206160308, 0.7055477773888694, 0.6969723486174308, 0.6453447672383619, 0.7115855792789639, 0.6820091004550227, 0.7039726986349317, 0.6395694784739236, 0.7105355267763388, 0.7072103605180259, 0.6874343717185859, 0.7019600980049002, 0.6454322716135806, 0.5949422471123557, 0.5854917745887295, 0.7081729086454323, 0.5905670283514176, 0.6489324466223311, 0.721823591179559, 0.49588729436471823, 0.706422821141057, 0.7017850892544627, 0.6864718235911795, 0.6602205110255512], 'final_state_dict_size_bytes': 8712, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007325922372954892, 'batch_size': 48, 'epochs': 60, 'weight_decay': 1.7618229803300074e-06, 'dropout': 0.02453921237825645, 'channel_multiplier': 8, 'kernel_size1': 50, 'stride1': 10, 'kernel_size2': 29, 'stride2': 8, 'gcn_hidden': 15, 'label_smoothing': 0.012499038579141123, 'grad_clip_norm': 2.8533224776948214, 'use_amp': False, 'calibrate_batches': 127, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 2066, 'model_storage_size_kb': 8.877343750000001, 'model_size_validation': 'PASS'}
2025-10-13 11:50:39,282 - INFO - _models.training_function_executor - BO Objective: base=0.6602, size_penalty=0.0000, final=0.6602
2025-10-13 11:50:39,282 - INFO - _models.training_function_executor - Model: 2,066 parameters, 8.9KB (PASS 256KB limit)
2025-10-13 11:50:39,282 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 112.334s
2025-10-13 11:50:39,384 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6602
2025-10-13 11:50:39,384 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-13 11:50:39,384 - INFO - bo.run_bo - Recorded observation #36: hparams={'lr': 0.007325922372954892, 'batch_size': np.int64(48), 'epochs': np.int64(60), 'weight_decay': 1.7618229803300074e-06, 'dropout': 0.02453921237825645, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(50), 'stride1': np.int64(10), 'kernel_size2': np.int64(29), 'stride2': np.int64(8), 'gcn_hidden': np.int64(15), 'label_smoothing': 0.012499038579141123, 'grad_clip_norm': 2.8533224776948214, 'use_amp': np.False_, 'calibrate_batches': np.int64(127), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6602
2025-10-13 11:50:39,384 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 36: {'lr': 0.007325922372954892, 'batch_size': np.int64(48), 'epochs': np.int64(60), 'weight_decay': 1.7618229803300074e-06, 'dropout': 0.02453921237825645, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(50), 'stride1': np.int64(10), 'kernel_size2': np.int64(29), 'stride2': np.int64(8), 'gcn_hidden': np.int64(15), 'label_smoothing': 0.012499038579141123, 'grad_clip_norm': 2.8533224776948214, 'use_amp': np.False_, 'calibrate_batches': np.int64(127), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6602
2025-10-13 11:50:39,385 - INFO - bo.run_bo - üîçBO Trial 37: Using RF surrogate + Expected Improvement
2025-10-13 11:50:39,385 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:50:39,385 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 37 (NaN monitoring active)
2025-10-13 11:50:39,385 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:50:39,385 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:50:39,385 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0003840625795839734, 'batch_size': 96, 'epochs': 36, 'weight_decay': 2.7704081562632178e-05, 'dropout': 0.03857186534963986, 'channel_multiplier': 5, 'kernel_size1': 55, 'stride1': 11, 'kernel_size2': 40, 'stride2': 4, 'gcn_hidden': 7, 'label_smoothing': 0.09612974045022461, 'grad_clip_norm': 4.49546624541286, 'use_amp': True, 'calibrate_batches': 42, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:50:39,386 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0003840625795839734, 'batch_size': 96, 'epochs': 36, 'weight_decay': 2.7704081562632178e-05, 'dropout': 0.03857186534963986, 'channel_multiplier': 5, 'kernel_size1': 55, 'stride1': 11, 'kernel_size2': 40, 'stride2': 4, 'gcn_hidden': 7, 'label_smoothing': 0.09612974045022461, 'grad_clip_norm': 4.49546624541286, 'use_amp': True, 'calibrate_batches': 42, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:50:43,695 - INFO - _models.training_function_executor - Epoch 001/036 - train_loss: 1.5196 - val_loss: 1.4618 - val_acc: 0.4300
2025-10-13 11:50:45,172 - INFO - _models.training_function_executor - Epoch 002/036 - train_loss: 1.3519 - val_loss: 1.3140 - val_acc: 0.5360
2025-10-13 11:50:46,655 - INFO - _models.training_function_executor - Epoch 003/036 - train_loss: 1.2621 - val_loss: 1.2624 - val_acc: 0.5747
2025-10-13 11:50:48,146 - INFO - _models.training_function_executor - Epoch 004/036 - train_loss: 1.2288 - val_loss: 1.3587 - val_acc: 0.4955
2025-10-13 11:50:49,633 - INFO - _models.training_function_executor - Epoch 005/036 - train_loss: 1.2123 - val_loss: 1.2562 - val_acc: 0.5270
2025-10-13 11:50:51,134 - INFO - _models.training_function_executor - Epoch 006/036 - train_loss: 1.1996 - val_loss: 1.2183 - val_acc: 0.5506
2025-10-13 11:50:52,651 - INFO - _models.training_function_executor - Epoch 007/036 - train_loss: 1.1889 - val_loss: 1.2007 - val_acc: 0.5583
2025-10-13 11:50:54,166 - INFO - _models.training_function_executor - Epoch 008/036 - train_loss: 1.1828 - val_loss: 1.1952 - val_acc: 0.5558
2025-10-13 11:50:55,674 - INFO - _models.training_function_executor - Epoch 009/036 - train_loss: 1.1760 - val_loss: 1.1743 - val_acc: 0.5667
2025-10-13 11:50:57,181 - INFO - _models.training_function_executor - Epoch 010/036 - train_loss: 1.1695 - val_loss: 1.1729 - val_acc: 0.5995
2025-10-13 11:50:58,686 - INFO - _models.training_function_executor - Epoch 011/036 - train_loss: 1.1638 - val_loss: 1.2176 - val_acc: 0.5494
2025-10-13 11:51:00,185 - INFO - _models.training_function_executor - Epoch 012/036 - train_loss: 1.1569 - val_loss: 1.1712 - val_acc: 0.5842
2025-10-13 11:51:01,696 - INFO - _models.training_function_executor - Epoch 013/036 - train_loss: 1.1524 - val_loss: 1.1719 - val_acc: 0.5981
2025-10-13 11:51:03,198 - INFO - _models.training_function_executor - Epoch 014/036 - train_loss: 1.1477 - val_loss: 1.1472 - val_acc: 0.6121
2025-10-13 11:51:04,708 - INFO - _models.training_function_executor - Epoch 015/036 - train_loss: 1.1440 - val_loss: 1.2295 - val_acc: 0.5534
2025-10-13 11:51:06,228 - INFO - _models.training_function_executor - Epoch 016/036 - train_loss: 1.1412 - val_loss: 1.2124 - val_acc: 0.5342
2025-10-13 11:51:07,750 - INFO - _models.training_function_executor - Epoch 017/036 - train_loss: 1.1373 - val_loss: 1.2389 - val_acc: 0.5430
2025-10-13 11:51:09,266 - INFO - _models.training_function_executor - Epoch 018/036 - train_loss: 1.1346 - val_loss: 1.1302 - val_acc: 0.6027
2025-10-13 11:51:10,776 - INFO - _models.training_function_executor - Epoch 019/036 - train_loss: 1.1325 - val_loss: 1.1277 - val_acc: 0.6146
2025-10-13 11:51:12,279 - INFO - _models.training_function_executor - Epoch 020/036 - train_loss: 1.1308 - val_loss: 1.1256 - val_acc: 0.6154
2025-10-13 11:51:13,796 - INFO - _models.training_function_executor - Epoch 021/036 - train_loss: 1.1269 - val_loss: 1.3100 - val_acc: 0.4931
2025-10-13 11:51:15,303 - INFO - _models.training_function_executor - Epoch 022/036 - train_loss: 1.1256 - val_loss: 1.1191 - val_acc: 0.6141
2025-10-13 11:51:16,822 - INFO - _models.training_function_executor - Epoch 023/036 - train_loss: 1.1222 - val_loss: 1.1293 - val_acc: 0.6154
2025-10-13 11:51:18,330 - INFO - _models.training_function_executor - Epoch 024/036 - train_loss: 1.1206 - val_loss: 1.1212 - val_acc: 0.6121
2025-10-13 11:51:19,840 - INFO - _models.training_function_executor - Epoch 025/036 - train_loss: 1.1165 - val_loss: 1.2402 - val_acc: 0.5516
2025-10-13 11:51:21,368 - INFO - _models.training_function_executor - Epoch 026/036 - train_loss: 1.1172 - val_loss: 1.1138 - val_acc: 0.6291
2025-10-13 11:51:22,889 - INFO - _models.training_function_executor - Epoch 027/036 - train_loss: 1.1160 - val_loss: 1.1217 - val_acc: 0.6128
2025-10-13 11:51:24,420 - INFO - _models.training_function_executor - Epoch 028/036 - train_loss: 1.1123 - val_loss: 1.1057 - val_acc: 0.6303
2025-10-13 11:51:25,919 - INFO - _models.training_function_executor - Epoch 029/036 - train_loss: 1.1113 - val_loss: 1.1241 - val_acc: 0.6237
2025-10-13 11:51:27,462 - INFO - _models.training_function_executor - Epoch 030/036 - train_loss: 1.1105 - val_loss: 1.3828 - val_acc: 0.4373
2025-10-13 11:51:28,971 - INFO - _models.training_function_executor - Epoch 031/036 - train_loss: 1.1081 - val_loss: 1.1103 - val_acc: 0.6326
2025-10-13 11:51:30,472 - INFO - _models.training_function_executor - Epoch 032/036 - train_loss: 1.1071 - val_loss: 1.1301 - val_acc: 0.6430
2025-10-13 11:51:31,978 - INFO - _models.training_function_executor - Epoch 033/036 - train_loss: 1.1042 - val_loss: 1.1046 - val_acc: 0.6320
2025-10-13 11:51:33,497 - INFO - _models.training_function_executor - Epoch 034/036 - train_loss: 1.1067 - val_loss: 1.1165 - val_acc: 0.6412
2025-10-13 11:51:35,026 - INFO - _models.training_function_executor - Epoch 035/036 - train_loss: 1.1026 - val_loss: 1.1001 - val_acc: 0.6498
2025-10-13 11:51:36,524 - INFO - _models.training_function_executor - Epoch 036/036 - train_loss: 1.1009 - val_loss: 1.1244 - val_acc: 0.6194
2025-10-13 11:51:37,774 - INFO - _models.training_function_executor - Model: 1,727 parameters, 1.9KB storage
2025-10-13 11:51:37,774 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.519622396246136, 1.3518739059165845, 1.2621241808772128, 1.228839213797209, 1.2123469357562306, 1.199605138559712, 1.1889115587414083, 1.1827543790748498, 1.1759795505849473, 1.1695178427143784, 1.1637790942467465, 1.1569384417835966, 1.1523978682635838, 1.1477124696851069, 1.143979210201827, 1.141199932634142, 1.1373399583284447, 1.134551852534691, 1.1324759907850988, 1.1307607758157856, 1.1269325635464074, 1.1256182426166235, 1.1222481292404827, 1.1205604038832695, 1.1165148909374847, 1.1172439031847967, 1.1159873533632774, 1.1123264890306264, 1.111274565355236, 1.1104780863664097, 1.108091886722837, 1.1070727699070824, 1.104197830347736, 1.1066571068505036, 1.1026202544575185, 1.1009361576191146], 'val_losses': [1.461837586089786, 1.3140114700623147, 1.2624290351230112, 1.3587458443299514, 1.2561918456611993, 1.2183005850674766, 1.2006523087177403, 1.1952301327231718, 1.1742627624869555, 1.1728508477866921, 1.217635797377771, 1.171162313792436, 1.1718512027047505, 1.1471976396876447, 1.2294949374083752, 1.212381177529364, 1.2389479681124502, 1.1302213440168392, 1.1276601883010677, 1.125586355487742, 1.3099512330168062, 1.119102103897104, 1.1293487478729558, 1.1211819595751498, 1.2401938146755418, 1.113825217635222, 1.1216601870007392, 1.1056693817378342, 1.1240958153972018, 1.3828240055532193, 1.1103433160711762, 1.1301110283995492, 1.1045876249676199, 1.116524312894245, 1.1001065149772906, 1.1244140961055868], 'val_acc': [0.4299964998249913, 0.5359642982149108, 0.5747287364368219, 0.4955372768638432, 0.5269513475673784, 0.5505775288764438, 0.5582779138956948, 0.5558277913895695, 0.5666783339166959, 0.5994924746237312, 0.5493524676233812, 0.5841792089604481, 0.598092404620231, 0.6120931046552328, 0.5533776688834442, 0.5342142107105355, 0.5429646482324116, 0.6027301365068254, 0.6146307315365769, 0.6154182709135457, 0.4930871543577179, 0.6141057052852643, 0.6154182709135457, 0.6120931046552328, 0.551627581379069, 0.6290689534476723, 0.6127931396569829, 0.630294014700735, 0.623731186559328, 0.43725936296814844, 0.6325691284564228, 0.6429821491074553, 0.6320441022051102, 0.6412320616030801, 0.6498074903745187, 0.61935596779839], 'final_state_dict_size_bytes': 7212, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0003840625795839734, 'batch_size': 96, 'epochs': 36, 'weight_decay': 2.7704081562632178e-05, 'dropout': 0.03857186534963986, 'channel_multiplier': 5, 'kernel_size1': 55, 'stride1': 11, 'kernel_size2': 40, 'stride2': 4, 'gcn_hidden': 7, 'label_smoothing': 0.09612974045022461, 'grad_clip_norm': 4.49546624541286, 'use_amp': True, 'calibrate_batches': 42, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1727, 'model_storage_size_kb': 1.85517578125, 'model_size_validation': 'PASS'}
2025-10-13 11:51:37,774 - INFO - _models.training_function_executor - BO Objective: base=0.6194, size_penalty=0.0000, final=0.6194
2025-10-13 11:51:37,774 - INFO - _models.training_function_executor - Model: 1,727 parameters, 1.9KB (PASS 256KB limit)
2025-10-13 11:51:37,774 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 58.389s
2025-10-13 11:51:37,878 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6194
2025-10-13 11:51:37,879 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-13 11:51:37,879 - INFO - bo.run_bo - Recorded observation #37: hparams={'lr': 0.0003840625795839734, 'batch_size': np.int64(96), 'epochs': np.int64(36), 'weight_decay': 2.7704081562632178e-05, 'dropout': 0.03857186534963986, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(55), 'stride1': np.int64(11), 'kernel_size2': np.int64(40), 'stride2': np.int64(4), 'gcn_hidden': np.int64(7), 'label_smoothing': 0.09612974045022461, 'grad_clip_norm': 4.49546624541286, 'use_amp': np.True_, 'calibrate_batches': np.int64(42), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.6194
2025-10-13 11:51:37,879 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 37: {'lr': 0.0003840625795839734, 'batch_size': np.int64(96), 'epochs': np.int64(36), 'weight_decay': 2.7704081562632178e-05, 'dropout': 0.03857186534963986, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(55), 'stride1': np.int64(11), 'kernel_size2': np.int64(40), 'stride2': np.int64(4), 'gcn_hidden': np.int64(7), 'label_smoothing': 0.09612974045022461, 'grad_clip_norm': 4.49546624541286, 'use_amp': np.True_, 'calibrate_batches': np.int64(42), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.6194
2025-10-13 11:51:37,879 - INFO - bo.run_bo - üîçBO Trial 38: Using RF surrogate + Expected Improvement
2025-10-13 11:51:37,879 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:51:37,879 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 38 (NaN monitoring active)
2025-10-13 11:51:37,879 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:51:37,879 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:51:37,879 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00015056882736063265, 'batch_size': 32, 'epochs': 54, 'weight_decay': 1.1238350907937736e-06, 'dropout': 0.009494726729111449, 'channel_multiplier': 1, 'kernel_size1': 37, 'stride1': 8, 'kernel_size2': 9, 'stride2': 3, 'gcn_hidden': 17, 'label_smoothing': 0.18285435958097745, 'grad_clip_norm': 4.001150107515064, 'use_amp': False, 'calibrate_batches': 117, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:51:37,880 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00015056882736063265, 'batch_size': 32, 'epochs': 54, 'weight_decay': 1.1238350907937736e-06, 'dropout': 0.009494726729111449, 'channel_multiplier': 1, 'kernel_size1': 37, 'stride1': 8, 'kernel_size2': 9, 'stride2': 3, 'gcn_hidden': 17, 'label_smoothing': 0.18285435958097745, 'grad_clip_norm': 4.001150107515064, 'use_amp': False, 'calibrate_batches': 117, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:51:42,764 - INFO - _models.training_function_executor - Epoch 001/054 - train_loss: 1.5861 - val_loss: 1.5529 - val_acc: 0.3224
2025-10-13 11:51:44,835 - INFO - _models.training_function_executor - Epoch 002/054 - train_loss: 1.5300 - val_loss: 1.5316 - val_acc: 0.3603
2025-10-13 11:51:46,956 - INFO - _models.training_function_executor - Epoch 003/054 - train_loss: 1.5026 - val_loss: 1.5225 - val_acc: 0.3525
2025-10-13 11:51:49,022 - INFO - _models.training_function_executor - Epoch 004/054 - train_loss: 1.4825 - val_loss: 1.4990 - val_acc: 0.3849
2025-10-13 11:51:51,106 - INFO - _models.training_function_executor - Epoch 005/054 - train_loss: 1.4636 - val_loss: 1.4687 - val_acc: 0.4789
2025-10-13 11:51:53,194 - INFO - _models.training_function_executor - Epoch 006/054 - train_loss: 1.4462 - val_loss: 1.4609 - val_acc: 0.4831
2025-10-13 11:51:55,273 - INFO - _models.training_function_executor - Epoch 007/054 - train_loss: 1.4316 - val_loss: 1.4429 - val_acc: 0.4982
2025-10-13 11:51:57,370 - INFO - _models.training_function_executor - Epoch 008/054 - train_loss: 1.4160 - val_loss: 1.4350 - val_acc: 0.4940
2025-10-13 11:51:59,476 - INFO - _models.training_function_executor - Epoch 009/054 - train_loss: 1.4022 - val_loss: 1.4902 - val_acc: 0.4101
2025-10-13 11:52:01,575 - INFO - _models.training_function_executor - Epoch 010/054 - train_loss: 1.3915 - val_loss: 1.3927 - val_acc: 0.5210
2025-10-13 11:52:03,694 - INFO - _models.training_function_executor - Epoch 011/054 - train_loss: 1.3797 - val_loss: 1.3834 - val_acc: 0.5252
2025-10-13 11:52:05,774 - INFO - _models.training_function_executor - Epoch 012/054 - train_loss: 1.3727 - val_loss: 1.4789 - val_acc: 0.4153
2025-10-13 11:52:07,863 - INFO - _models.training_function_executor - Epoch 013/054 - train_loss: 1.3678 - val_loss: 1.3647 - val_acc: 0.5324
2025-10-13 11:52:09,949 - INFO - _models.training_function_executor - Epoch 014/054 - train_loss: 1.3596 - val_loss: 1.3804 - val_acc: 0.5253
2025-10-13 11:52:12,047 - INFO - _models.training_function_executor - Epoch 015/054 - train_loss: 1.3547 - val_loss: 1.3527 - val_acc: 0.5550
2025-10-13 11:52:14,155 - INFO - _models.training_function_executor - Epoch 016/054 - train_loss: 1.3509 - val_loss: 1.3491 - val_acc: 0.5535
2025-10-13 11:52:16,281 - INFO - _models.training_function_executor - Epoch 017/054 - train_loss: 1.3458 - val_loss: 1.3557 - val_acc: 0.5467
2025-10-13 11:52:18,405 - INFO - _models.training_function_executor - Epoch 018/054 - train_loss: 1.3440 - val_loss: 1.3391 - val_acc: 0.5443
2025-10-13 11:52:20,492 - INFO - _models.training_function_executor - Epoch 019/054 - train_loss: 1.3416 - val_loss: 1.3788 - val_acc: 0.5071
2025-10-13 11:52:22,618 - INFO - _models.training_function_executor - Epoch 020/054 - train_loss: 1.3387 - val_loss: 1.3451 - val_acc: 0.5348
2025-10-13 11:52:24,694 - INFO - _models.training_function_executor - Epoch 021/054 - train_loss: 1.3372 - val_loss: 1.3370 - val_acc: 0.5449
2025-10-13 11:52:26,780 - INFO - _models.training_function_executor - Epoch 022/054 - train_loss: 1.3369 - val_loss: 1.3357 - val_acc: 0.5397
2025-10-13 11:52:28,878 - INFO - _models.training_function_executor - Epoch 023/054 - train_loss: 1.3337 - val_loss: 1.3446 - val_acc: 0.5417
2025-10-13 11:52:30,955 - INFO - _models.training_function_executor - Epoch 024/054 - train_loss: 1.3318 - val_loss: 1.3308 - val_acc: 0.5460
2025-10-13 11:52:33,043 - INFO - _models.training_function_executor - Epoch 025/054 - train_loss: 1.3298 - val_loss: 1.3473 - val_acc: 0.5501
2025-10-13 11:52:35,125 - INFO - _models.training_function_executor - Epoch 026/054 - train_loss: 1.3289 - val_loss: 1.4987 - val_acc: 0.3134
2025-10-13 11:52:37,215 - INFO - _models.training_function_executor - Epoch 027/054 - train_loss: 1.3269 - val_loss: 1.3266 - val_acc: 0.5500
2025-10-13 11:52:39,300 - INFO - _models.training_function_executor - Epoch 028/054 - train_loss: 1.3279 - val_loss: 1.3274 - val_acc: 0.5480
2025-10-13 11:52:41,387 - INFO - _models.training_function_executor - Epoch 029/054 - train_loss: 1.3259 - val_loss: 1.3359 - val_acc: 0.5282
2025-10-13 11:52:43,481 - INFO - _models.training_function_executor - Epoch 030/054 - train_loss: 1.3247 - val_loss: 1.3423 - val_acc: 0.5373
2025-10-13 11:52:45,556 - INFO - _models.training_function_executor - Epoch 031/054 - train_loss: 1.3254 - val_loss: 1.3270 - val_acc: 0.5480
2025-10-13 11:52:47,672 - INFO - _models.training_function_executor - Epoch 032/054 - train_loss: 1.3218 - val_loss: 1.3595 - val_acc: 0.5221
2025-10-13 11:52:49,792 - INFO - _models.training_function_executor - Epoch 033/054 - train_loss: 1.3209 - val_loss: 1.3157 - val_acc: 0.5535
2025-10-13 11:52:51,894 - INFO - _models.training_function_executor - Epoch 034/054 - train_loss: 1.3186 - val_loss: 1.3508 - val_acc: 0.5288
2025-10-13 11:52:54,006 - INFO - _models.training_function_executor - Epoch 035/054 - train_loss: 1.3170 - val_loss: 1.3169 - val_acc: 0.5516
2025-10-13 11:52:56,107 - INFO - _models.training_function_executor - Epoch 036/054 - train_loss: 1.3165 - val_loss: 1.3143 - val_acc: 0.5488
2025-10-13 11:52:58,199 - INFO - _models.training_function_executor - Epoch 037/054 - train_loss: 1.3157 - val_loss: 1.3173 - val_acc: 0.5462
2025-10-13 11:53:00,288 - INFO - _models.training_function_executor - Epoch 038/054 - train_loss: 1.3128 - val_loss: 1.3129 - val_acc: 0.5457
2025-10-13 11:53:02,352 - INFO - _models.training_function_executor - Epoch 039/054 - train_loss: 1.3115 - val_loss: 1.4548 - val_acc: 0.4391
2025-10-13 11:53:04,453 - INFO - _models.training_function_executor - Epoch 040/054 - train_loss: 1.3129 - val_loss: 1.3105 - val_acc: 0.5496
2025-10-13 11:53:06,515 - INFO - _models.training_function_executor - Epoch 041/054 - train_loss: 1.3094 - val_loss: 1.3199 - val_acc: 0.5481
2025-10-13 11:53:08,622 - INFO - _models.training_function_executor - Epoch 042/054 - train_loss: 1.3069 - val_loss: 1.4911 - val_acc: 0.4126
2025-10-13 11:53:10,714 - INFO - _models.training_function_executor - Epoch 043/054 - train_loss: 1.3076 - val_loss: 1.3049 - val_acc: 0.5516
2025-10-13 11:53:12,807 - INFO - _models.training_function_executor - Epoch 044/054 - train_loss: 1.3054 - val_loss: 1.3070 - val_acc: 0.5541
2025-10-13 11:53:14,880 - INFO - _models.training_function_executor - Epoch 045/054 - train_loss: 1.3045 - val_loss: 1.3079 - val_acc: 0.5487
2025-10-13 11:53:16,976 - INFO - _models.training_function_executor - Epoch 046/054 - train_loss: 1.3059 - val_loss: 1.3224 - val_acc: 0.5456
2025-10-13 11:53:19,082 - INFO - _models.training_function_executor - Epoch 047/054 - train_loss: 1.3033 - val_loss: 1.3034 - val_acc: 0.5500
2025-10-13 11:53:21,182 - INFO - _models.training_function_executor - Epoch 048/054 - train_loss: 1.3014 - val_loss: 1.3169 - val_acc: 0.5463
2025-10-13 11:53:23,294 - INFO - _models.training_function_executor - Epoch 049/054 - train_loss: 1.3004 - val_loss: 1.2961 - val_acc: 0.5538
2025-10-13 11:53:25,373 - INFO - _models.training_function_executor - Epoch 050/054 - train_loss: 1.2997 - val_loss: 1.2991 - val_acc: 0.5712
2025-10-13 11:53:27,463 - INFO - _models.training_function_executor - Epoch 051/054 - train_loss: 1.2985 - val_loss: 1.3268 - val_acc: 0.5416
2025-10-13 11:53:29,587 - INFO - _models.training_function_executor - Epoch 052/054 - train_loss: 1.2983 - val_loss: 1.2963 - val_acc: 0.5459
2025-10-13 11:53:31,665 - INFO - _models.training_function_executor - Epoch 053/054 - train_loss: 1.2958 - val_loss: 1.3980 - val_acc: 0.4673
2025-10-13 11:53:33,758 - INFO - _models.training_function_executor - Epoch 054/054 - train_loss: 1.2951 - val_loss: 1.2929 - val_acc: 0.5531
2025-10-13 11:53:34,871 - INFO - _models.training_function_executor - Model: 477 parameters, 2.0KB storage
2025-10-13 11:53:34,871 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.586124535161046, 1.5300097686659426, 1.5026354289029835, 1.4824812368450357, 1.4635513953742005, 1.4461901762037375, 1.431633014423596, 1.4160480954073758, 1.4021760204850604, 1.3915293952740277, 1.3797369713043892, 1.3726594944621118, 1.3677861147257344, 1.359555336408445, 1.3546521481743299, 1.3509049169408887, 1.3458159627887725, 1.3439634859374157, 1.3416215555209734, 1.3387331108467788, 1.3372121086728126, 1.3368545932956706, 1.3336900277783665, 1.3317720058459188, 1.3298304429786958, 1.328902890058844, 1.3269148664037205, 1.3278844414117832, 1.3259463746271478, 1.32465960276807, 1.325369284876502, 1.3218239882128364, 1.3209452475540113, 1.3185734554817512, 1.3170298088418881, 1.3165464890683327, 1.315741627041927, 1.3127525734826322, 1.3115001475431305, 1.3128773906992832, 1.309384999343637, 1.30686968016299, 1.307620580187201, 1.3053524495422903, 1.3044518140967092, 1.3059406885952227, 1.3032725025066179, 1.301445000189186, 1.3004174826651718, 1.2996703595350705, 1.2985343693602032, 1.298320257626174, 1.29578438016306, 1.2950820853170248], 'val_losses': [1.5528556053397287, 1.5316094914891314, 1.5225141747748054, 1.499040101932236, 1.4687389936904454, 1.4608839823726512, 1.4429328329378714, 1.4349985861219139, 1.4901915316736944, 1.3926906259818472, 1.3834201260634473, 1.4788942309914663, 1.3647282909671035, 1.3803856627357811, 1.352706485333708, 1.3491363490758594, 1.355692838929857, 1.3391239201225598, 1.3787930508280786, 1.3450628179831232, 1.336967181316572, 1.335737152912419, 1.3446471145364176, 1.330778610844023, 1.3472588472446445, 1.4986914272361758, 1.3266063765040803, 1.3273827276072971, 1.3359303067186974, 1.3422766095656467, 1.3269842035669441, 1.3594595023206284, 1.3157288764046338, 1.3508245518126603, 1.316881104620512, 1.314279534243436, 1.31726642117285, 1.3129032262772748, 1.4548229892478357, 1.3104527394255017, 1.3199272626423526, 1.4910711421806326, 1.3048589982726084, 1.3070437475063603, 1.3079130692543748, 1.3223845827692158, 1.3034116052688316, 1.316872492469104, 1.2961181088431881, 1.2991009898063892, 1.326778222098399, 1.2963355799258736, 1.3979769327609657, 1.2928846780345036], 'val_acc': [0.3223661183059153, 0.36034301715085754, 0.35246762338116905, 0.38493174658732937, 0.4789114455722786, 0.48311165558277913, 0.4982499124956248, 0.4939621981099055, 0.41013300665033253, 0.5210010500525026, 0.5252012600630032, 0.41529576478823943, 0.5323766188309416, 0.5252887644382219, 0.5550402520126007, 0.553465173258663, 0.5467273363668184, 0.544277213860693, 0.5070878543927196, 0.5348267413370669, 0.5448897444872244, 0.5397269863493175, 0.541739586979349, 0.5460273013650683, 0.5500525026251313, 0.31344067203360165, 0.5499649982499125, 0.5480399019950998, 0.528176408820441, 0.5372768638431922, 0.5480399019950998, 0.5220511025551278, 0.553465173258663, 0.5287889394469724, 0.551627581379069, 0.5488274413720686, 0.5462023101155058, 0.5456772838641932, 0.43909695484774236, 0.5496149807490375, 0.5481274063703185, 0.41258312915645784, 0.551627581379069, 0.5540777038851943, 0.5486524326216311, 0.5455897794889745, 0.5499649982499125, 0.5462898144907246, 0.553815190759538, 0.5712285614280714, 0.5415645782289115, 0.5458522926146308, 0.4672733636681834, 0.5531151557577879], 'final_state_dict_size_bytes': 2020, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00015056882736063265, 'batch_size': 32, 'epochs': 54, 'weight_decay': 1.1238350907937736e-06, 'dropout': 0.009494726729111449, 'channel_multiplier': 1, 'kernel_size1': 37, 'stride1': 8, 'kernel_size2': 9, 'stride2': 3, 'gcn_hidden': 17, 'label_smoothing': 0.18285435958097745, 'grad_clip_norm': 4.001150107515064, 'use_amp': False, 'calibrate_batches': 117, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 477, 'model_storage_size_kb': 2.049609375, 'model_size_validation': 'PASS'}
2025-10-13 11:53:34,871 - INFO - _models.training_function_executor - BO Objective: base=0.5531, size_penalty=0.0000, final=0.5531
2025-10-13 11:53:34,871 - INFO - _models.training_function_executor - Model: 477 parameters, 2.0KB (PASS 256KB limit)
2025-10-13 11:53:34,872 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 116.992s
2025-10-13 11:53:34,975 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5531
2025-10-13 11:53:34,975 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-13 11:53:34,975 - INFO - bo.run_bo - Recorded observation #38: hparams={'lr': 0.00015056882736063265, 'batch_size': np.int64(32), 'epochs': np.int64(54), 'weight_decay': 1.1238350907937736e-06, 'dropout': 0.009494726729111449, 'channel_multiplier': np.int64(1), 'kernel_size1': np.int64(37), 'stride1': np.int64(8), 'kernel_size2': np.int64(9), 'stride2': np.int64(3), 'gcn_hidden': np.int64(17), 'label_smoothing': 0.18285435958097745, 'grad_clip_norm': 4.001150107515064, 'use_amp': np.False_, 'calibrate_batches': np.int64(117), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.5531
2025-10-13 11:53:34,975 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 38: {'lr': 0.00015056882736063265, 'batch_size': np.int64(32), 'epochs': np.int64(54), 'weight_decay': 1.1238350907937736e-06, 'dropout': 0.009494726729111449, 'channel_multiplier': np.int64(1), 'kernel_size1': np.int64(37), 'stride1': np.int64(8), 'kernel_size2': np.int64(9), 'stride2': np.int64(3), 'gcn_hidden': np.int64(17), 'label_smoothing': 0.18285435958097745, 'grad_clip_norm': 4.001150107515064, 'use_amp': np.False_, 'calibrate_batches': np.int64(117), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.5531
2025-10-13 11:53:34,976 - INFO - bo.run_bo - üîçBO Trial 39: Using RF surrogate + Expected Improvement
2025-10-13 11:53:34,976 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:53:34,976 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 39 (NaN monitoring active)
2025-10-13 11:53:34,976 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:53:34,976 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:53:34,976 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007770636875419288, 'batch_size': 128, 'epochs': 55, 'weight_decay': 1.3887054065371488e-06, 'dropout': 0.002923646702616001, 'channel_multiplier': 2, 'kernel_size1': 96, 'stride1': 11, 'kernel_size2': 30, 'stride2': 5, 'gcn_hidden': 6, 'label_smoothing': 0.04945221207429055, 'grad_clip_norm': 4.91370980353307, 'use_amp': False, 'calibrate_batches': 111, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:53:34,977 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007770636875419288, 'batch_size': 128, 'epochs': 55, 'weight_decay': 1.3887054065371488e-06, 'dropout': 0.002923646702616001, 'channel_multiplier': 2, 'kernel_size1': 96, 'stride1': 11, 'kernel_size2': 30, 'stride2': 5, 'gcn_hidden': 6, 'label_smoothing': 0.04945221207429055, 'grad_clip_norm': 4.91370980353307, 'use_amp': False, 'calibrate_batches': 111, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 11:53:39,301 - INFO - _models.training_function_executor - Epoch 001/055 - train_loss: 1.4039 - val_loss: 1.4034 - val_acc: 0.4357
2025-10-13 11:53:40,807 - INFO - _models.training_function_executor - Epoch 002/055 - train_loss: 1.3242 - val_loss: 1.3050 - val_acc: 0.4895
2025-10-13 11:53:42,334 - INFO - _models.training_function_executor - Epoch 003/055 - train_loss: 1.2862 - val_loss: 1.2786 - val_acc: 0.4960
2025-10-13 11:53:43,862 - INFO - _models.training_function_executor - Epoch 004/055 - train_loss: 1.2610 - val_loss: 1.2529 - val_acc: 0.4933
2025-10-13 11:53:45,404 - INFO - _models.training_function_executor - Epoch 005/055 - train_loss: 1.1635 - val_loss: 1.1062 - val_acc: 0.5726
2025-10-13 11:53:46,932 - INFO - _models.training_function_executor - Epoch 006/055 - train_loss: 1.1057 - val_loss: 1.2199 - val_acc: 0.5260
2025-10-13 11:53:48,467 - INFO - _models.training_function_executor - Epoch 007/055 - train_loss: 1.0941 - val_loss: 1.2034 - val_acc: 0.5297
2025-10-13 11:53:50,010 - INFO - _models.training_function_executor - Epoch 008/055 - train_loss: 1.0807 - val_loss: 1.3796 - val_acc: 0.4199
2025-10-13 11:53:51,558 - INFO - _models.training_function_executor - Epoch 009/055 - train_loss: 1.0814 - val_loss: 1.0789 - val_acc: 0.5877
2025-10-13 11:53:53,093 - INFO - _models.training_function_executor - Epoch 010/055 - train_loss: 1.0700 - val_loss: 1.0589 - val_acc: 0.5955
2025-10-13 11:53:54,636 - INFO - _models.training_function_executor - Epoch 011/055 - train_loss: 1.0736 - val_loss: 1.0588 - val_acc: 0.5950
2025-10-13 11:53:56,176 - INFO - _models.training_function_executor - Epoch 012/055 - train_loss: 1.0652 - val_loss: 1.0650 - val_acc: 0.5897
2025-10-13 11:53:57,704 - INFO - _models.training_function_executor - Epoch 013/055 - train_loss: 1.0584 - val_loss: 1.0638 - val_acc: 0.5886
2025-10-13 11:53:59,225 - INFO - _models.training_function_executor - Epoch 014/055 - train_loss: 1.0590 - val_loss: 1.0485 - val_acc: 0.5973
2025-10-13 11:54:00,772 - INFO - _models.training_function_executor - Epoch 015/055 - train_loss: 1.0563 - val_loss: 1.0627 - val_acc: 0.5928
2025-10-13 11:54:02,325 - INFO - _models.training_function_executor - Epoch 016/055 - train_loss: 1.0537 - val_loss: 1.5724 - val_acc: 0.3434
2025-10-13 11:54:03,865 - INFO - _models.training_function_executor - Epoch 017/055 - train_loss: 1.0501 - val_loss: 1.0749 - val_acc: 0.5789
2025-10-13 11:54:05,429 - INFO - _models.training_function_executor - Epoch 018/055 - train_loss: 1.0509 - val_loss: 1.0398 - val_acc: 0.5944
2025-10-13 11:54:06,950 - INFO - _models.training_function_executor - Epoch 019/055 - train_loss: 1.0518 - val_loss: 1.3212 - val_acc: 0.4610
2025-10-13 11:54:08,488 - INFO - _models.training_function_executor - Epoch 020/055 - train_loss: 1.0483 - val_loss: 1.0915 - val_acc: 0.5747
2025-10-13 11:54:10,047 - INFO - _models.training_function_executor - Epoch 021/055 - train_loss: 1.0432 - val_loss: 1.0313 - val_acc: 0.6017
2025-10-13 11:54:11,590 - INFO - _models.training_function_executor - Epoch 022/055 - train_loss: 1.0463 - val_loss: 1.0844 - val_acc: 0.6051
2025-10-13 11:54:13,130 - INFO - _models.training_function_executor - Epoch 023/055 - train_loss: 1.0400 - val_loss: 1.0252 - val_acc: 0.5984
2025-10-13 11:54:14,666 - INFO - _models.training_function_executor - Epoch 024/055 - train_loss: 1.0389 - val_loss: 1.0462 - val_acc: 0.5928
2025-10-13 11:54:16,212 - INFO - _models.training_function_executor - Epoch 025/055 - train_loss: 1.0370 - val_loss: 1.0404 - val_acc: 0.5954
2025-10-13 11:54:17,732 - INFO - _models.training_function_executor - Epoch 026/055 - train_loss: 1.0361 - val_loss: 1.0092 - val_acc: 0.6166
2025-10-13 11:54:19,287 - INFO - _models.training_function_executor - Epoch 027/055 - train_loss: 1.0299 - val_loss: 1.0448 - val_acc: 0.5896
2025-10-13 11:54:20,817 - INFO - _models.training_function_executor - Epoch 028/055 - train_loss: 1.0314 - val_loss: 1.0142 - val_acc: 0.6186
2025-10-13 11:54:22,340 - INFO - _models.training_function_executor - Epoch 029/055 - train_loss: 1.0301 - val_loss: 1.0369 - val_acc: 0.6161
2025-10-13 11:54:23,891 - INFO - _models.training_function_executor - Epoch 030/055 - train_loss: 1.0274 - val_loss: 1.1374 - val_acc: 0.5597
2025-10-13 11:54:25,442 - INFO - _models.training_function_executor - Epoch 031/055 - train_loss: 1.0243 - val_loss: 1.0435 - val_acc: 0.6024
2025-10-13 11:54:26,982 - INFO - _models.training_function_executor - Epoch 032/055 - train_loss: 1.0250 - val_loss: 1.0263 - val_acc: 0.6337
2025-10-13 11:54:28,543 - INFO - _models.training_function_executor - Epoch 033/055 - train_loss: 1.0246 - val_loss: 1.0838 - val_acc: 0.5991
2025-10-13 11:54:30,084 - INFO - _models.training_function_executor - Epoch 034/055 - train_loss: 1.0214 - val_loss: 1.0003 - val_acc: 0.6348
2025-10-13 11:54:31,624 - INFO - _models.training_function_executor - Epoch 035/055 - train_loss: 1.0236 - val_loss: 1.0928 - val_acc: 0.5641
2025-10-13 11:54:33,151 - INFO - _models.training_function_executor - Epoch 036/055 - train_loss: 1.0191 - val_loss: 1.0404 - val_acc: 0.6151
2025-10-13 11:54:34,706 - INFO - _models.training_function_executor - Epoch 037/055 - train_loss: 1.0205 - val_loss: 0.9949 - val_acc: 0.6403
2025-10-13 11:54:36,269 - INFO - _models.training_function_executor - Epoch 038/055 - train_loss: 1.0188 - val_loss: 1.0502 - val_acc: 0.6011
2025-10-13 11:54:37,801 - INFO - _models.training_function_executor - Epoch 039/055 - train_loss: 1.0138 - val_loss: 1.1524 - val_acc: 0.5390
2025-10-13 11:54:39,341 - INFO - _models.training_function_executor - Epoch 040/055 - train_loss: 1.0162 - val_loss: 0.9928 - val_acc: 0.6440
2025-10-13 11:54:40,886 - INFO - _models.training_function_executor - Epoch 041/055 - train_loss: 1.0193 - val_loss: 1.0023 - val_acc: 0.6385
2025-10-13 11:54:42,421 - INFO - _models.training_function_executor - Epoch 042/055 - train_loss: 1.0120 - val_loss: 1.1520 - val_acc: 0.5426
2025-10-13 11:54:43,961 - INFO - _models.training_function_executor - Epoch 043/055 - train_loss: 1.0150 - val_loss: 1.0136 - val_acc: 0.6068
2025-10-13 11:54:45,494 - INFO - _models.training_function_executor - Epoch 044/055 - train_loss: 1.0112 - val_loss: 1.0314 - val_acc: 0.6112
2025-10-13 11:54:47,051 - INFO - _models.training_function_executor - Epoch 045/055 - train_loss: 1.0125 - val_loss: 0.9940 - val_acc: 0.6299
2025-10-13 11:54:48,571 - INFO - _models.training_function_executor - Epoch 046/055 - train_loss: 1.0119 - val_loss: 1.0179 - val_acc: 0.6152
2025-10-13 11:54:50,121 - INFO - _models.training_function_executor - Epoch 047/055 - train_loss: 1.0161 - val_loss: 1.0095 - val_acc: 0.6453
2025-10-13 11:54:51,696 - INFO - _models.training_function_executor - Epoch 048/055 - train_loss: 1.0114 - val_loss: 1.0108 - val_acc: 0.6377
2025-10-13 11:54:53,230 - INFO - _models.training_function_executor - Epoch 049/055 - train_loss: 1.0093 - val_loss: 0.9903 - val_acc: 0.6446
2025-10-13 11:54:54,769 - INFO - _models.training_function_executor - Epoch 050/055 - train_loss: 1.0073 - val_loss: 0.9926 - val_acc: 0.6252
2025-10-13 11:54:56,332 - INFO - _models.training_function_executor - Epoch 051/055 - train_loss: 1.0100 - val_loss: 0.9857 - val_acc: 0.6544
2025-10-13 11:54:57,878 - INFO - _models.training_function_executor - Epoch 052/055 - train_loss: 1.0070 - val_loss: 1.0083 - val_acc: 0.6232
2025-10-13 11:54:59,432 - INFO - _models.training_function_executor - Epoch 053/055 - train_loss: 1.0111 - val_loss: 1.0059 - val_acc: 0.6431
2025-10-13 11:55:00,992 - INFO - _models.training_function_executor - Epoch 054/055 - train_loss: 1.0110 - val_loss: 1.0211 - val_acc: 0.6287
2025-10-13 11:55:02,550 - INFO - _models.training_function_executor - Epoch 055/055 - train_loss: 1.0062 - val_loss: 1.0144 - val_acc: 0.6432
2025-10-13 11:55:03,668 - INFO - _models.training_function_executor - Model: 1,067 parameters, 4.6KB storage
2025-10-13 11:55:03,668 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.403852154460035, 1.324180732709693, 1.286173305438038, 1.2609899372415272, 1.1634666631803423, 1.1057410221814192, 1.0940737487304282, 1.0807016086528298, 1.0813640190831506, 1.0700001117020668, 1.073613291526116, 1.0652343257557566, 1.058427959294598, 1.0589775413243472, 1.056281666718958, 1.0536661671307022, 1.0500599408758908, 1.05094205790731, 1.0518413750825748, 1.0483427657336675, 1.043226059934331, 1.0463188739352014, 1.040004310718065, 1.0389329414080606, 1.037005827315921, 1.0360899569898958, 1.029902682631509, 1.0314144726437124, 1.0300930497693899, 1.0274303662514077, 1.0242620300987946, 1.025018301050188, 1.024556647116461, 1.021408318367545, 1.0236093367902723, 1.0191064765497568, 1.0204902902782735, 1.0188147604235995, 1.0138035724327452, 1.0161852665952256, 1.019273652452917, 1.0120053614692168, 1.0149911634564024, 1.0111911432034577, 1.0125485402452057, 1.0119149364455413, 1.0160685939975749, 1.0114482841501713, 1.0093062850283208, 1.0072691452682623, 1.0100012596645762, 1.0069530709540047, 1.0110507771857853, 1.0110273332832824, 1.006241100377706], 'val_losses': [1.4033546081822696, 1.3049725741408778, 1.278588345887822, 1.2529487966197665, 1.1061618505427167, 1.2198652750885817, 1.2033912851379016, 1.3795501780251251, 1.0789014667658527, 1.0588812108719143, 1.0587981333881147, 1.0650185328244246, 1.0637515930183126, 1.0485309204689723, 1.0626779504284642, 1.5724483368736404, 1.0748854732863922, 1.0398180581574512, 1.3211926551477702, 1.0914749179138434, 1.0313389855829787, 1.0843740258969583, 1.0251808880841686, 1.046228582015353, 1.040362280901387, 1.0091667112704963, 1.0447998053551053, 1.0141993833247456, 1.0368602270841347, 1.1374477095899358, 1.0434965538653118, 1.0263085183372938, 1.083767572357223, 1.0003383353243018, 1.0927731723772047, 1.0403947536036564, 0.9948788734428692, 1.050153658195605, 1.1523536452055394, 0.9927984310439887, 1.0023249522513928, 1.1519973989879915, 1.0136228321647578, 1.0313529035700424, 0.9940368282991061, 1.0178570391875612, 1.0095365698787353, 1.010776757609815, 0.9903442351435046, 0.992604532690786, 0.9857281248261556, 1.0082525908216797, 1.005912406318539, 1.0210940758999218, 1.0144473216230734], 'val_acc': [0.43568428421421074, 0.4894994749737487, 0.495974798739937, 0.49334966748337417, 0.5726286314315716, 0.525988799439972, 0.52966398319916, 0.41993349667483376, 0.5876793839691985, 0.5954672733636682, 0.5950297514875744, 0.58969198459923, 0.5886419320966049, 0.5973048652432622, 0.5927546377318866, 0.3433671683584179, 0.5789289464473224, 0.5944172208610431, 0.4609730486524326, 0.5747287364368219, 0.6016800840042003, 0.6050927546377319, 0.5983549177458873, 0.5927546377318866, 0.5953797689884495, 0.6165558277913896, 0.5896044802240112, 0.6185684284214211, 0.6161183059152958, 0.559677983899195, 0.6023801190059503, 0.6337066853342667, 0.5990549527476374, 0.6348442422121106, 0.564053202660133, 0.6150682534126707, 0.6402695134756737, 0.6010675533776689, 0.5390269513475674, 0.6440322016100805, 0.6385194259712985, 0.5426146307315366, 0.6067553377668884, 0.6112180609030452, 0.6299439971998599, 0.6151557577878894, 0.6452572628631431, 0.6377318865943297, 0.644557227861393, 0.6252187609380468, 0.6543577178858943, 0.6232061603080155, 0.6430696534826741, 0.6287189359467973, 0.6431571578578928], 'final_state_dict_size_bytes': 4428, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007770636875419288, 'batch_size': 128, 'epochs': 55, 'weight_decay': 1.3887054065371488e-06, 'dropout': 0.002923646702616001, 'channel_multiplier': 2, 'kernel_size1': 96, 'stride1': 11, 'kernel_size2': 30, 'stride2': 5, 'gcn_hidden': 6, 'label_smoothing': 0.04945221207429055, 'grad_clip_norm': 4.91370980353307, 'use_amp': False, 'calibrate_batches': 111, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 1067, 'model_storage_size_kb': 4.584765625, 'model_size_validation': 'PASS'}
2025-10-13 11:55:03,669 - INFO - _models.training_function_executor - BO Objective: base=0.6432, size_penalty=0.0000, final=0.6432
2025-10-13 11:55:03,669 - INFO - _models.training_function_executor - Model: 1,067 parameters, 4.6KB (PASS 256KB limit)
2025-10-13 11:55:03,669 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 88.693s
2025-10-13 11:55:03,772 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6432
2025-10-13 11:55:03,773 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-13 11:55:03,773 - INFO - bo.run_bo - Recorded observation #39: hparams={'lr': 0.007770636875419288, 'batch_size': np.int64(128), 'epochs': np.int64(55), 'weight_decay': 1.3887054065371488e-06, 'dropout': 0.002923646702616001, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(96), 'stride1': np.int64(11), 'kernel_size2': np.int64(30), 'stride2': np.int64(5), 'gcn_hidden': np.int64(6), 'label_smoothing': 0.04945221207429055, 'grad_clip_norm': 4.91370980353307, 'use_amp': np.False_, 'calibrate_batches': np.int64(111), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.6432
2025-10-13 11:55:03,773 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 39: {'lr': 0.007770636875419288, 'batch_size': np.int64(128), 'epochs': np.int64(55), 'weight_decay': 1.3887054065371488e-06, 'dropout': 0.002923646702616001, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(96), 'stride1': np.int64(11), 'kernel_size2': np.int64(30), 'stride2': np.int64(5), 'gcn_hidden': np.int64(6), 'label_smoothing': 0.04945221207429055, 'grad_clip_norm': 4.91370980353307, 'use_amp': np.False_, 'calibrate_batches': np.int64(111), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.6432
2025-10-13 11:55:03,773 - INFO - bo.run_bo - üîçBO Trial 40: Using RF surrogate + Expected Improvement
2025-10-13 11:55:03,773 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:55:03,773 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 40 (NaN monitoring active)
2025-10-13 11:55:03,773 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:55:03,773 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:55:03,773 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0011723515279533745, 'batch_size': 48, 'epochs': 8, 'weight_decay': 5.859935541290405e-06, 'dropout': 0.03573141677203631, 'channel_multiplier': 3, 'kernel_size1': 67, 'stride1': 12, 'kernel_size2': 8, 'stride2': 5, 'gcn_hidden': 17, 'label_smoothing': 0.0838996850429199, 'grad_clip_norm': 4.917668926419343, 'use_amp': True, 'calibrate_batches': 47, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:55:03,774 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0011723515279533745, 'batch_size': 48, 'epochs': 8, 'weight_decay': 5.859935541290405e-06, 'dropout': 0.03573141677203631, 'channel_multiplier': 3, 'kernel_size1': 67, 'stride1': 12, 'kernel_size2': 8, 'stride2': 5, 'gcn_hidden': 17, 'label_smoothing': 0.0838996850429199, 'grad_clip_norm': 4.917668926419343, 'use_amp': True, 'calibrate_batches': 47, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 11:55:08,373 - INFO - _models.training_function_executor - Epoch 001/008 - train_loss: 1.4408 - val_loss: 1.4058 - val_acc: 0.4486
2025-10-13 11:55:10,122 - INFO - _models.training_function_executor - Epoch 002/008 - train_loss: 1.3891 - val_loss: 1.4026 - val_acc: 0.4483
2025-10-13 11:55:11,889 - INFO - _models.training_function_executor - Epoch 003/008 - train_loss: 1.3687 - val_loss: 1.3778 - val_acc: 0.4603
2025-10-13 11:55:13,656 - INFO - _models.training_function_executor - Epoch 004/008 - train_loss: 1.3527 - val_loss: 1.6918 - val_acc: 0.2625
2025-10-13 11:55:15,422 - INFO - _models.training_function_executor - Epoch 005/008 - train_loss: 1.3407 - val_loss: 1.3327 - val_acc: 0.4821
2025-10-13 11:55:17,192 - INFO - _models.training_function_executor - Epoch 006/008 - train_loss: 1.3307 - val_loss: 1.3493 - val_acc: 0.4671
2025-10-13 11:55:18,959 - INFO - _models.training_function_executor - Epoch 007/008 - train_loss: 1.3199 - val_loss: 1.2812 - val_acc: 0.5111
2025-10-13 11:55:20,708 - INFO - _models.training_function_executor - Epoch 008/008 - train_loss: 1.2302 - val_loss: 1.2425 - val_acc: 0.5486
2025-10-13 11:55:21,926 - INFO - _models.training_function_executor - Model: 53 parameters, 0.2KB storage
2025-10-13 11:55:21,926 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4407976183141908, 1.3891453926572443, 1.3686928217920924, 1.3527089144159623, 1.3406948682349755, 1.3306784015207553, 1.319856257842561, 1.2302450898397124], 'val_losses': [1.405767041150615, 1.402594054458773, 1.377796101536749, 1.6918323969231814, 1.3326557577177909, 1.3493239301294975, 1.2812127707344192, 1.2425426862687967], 'val_acc': [0.4486349317465873, 0.44828491424571226, 0.4602730136506825, 0.2625131256562828, 0.48214910745537276, 0.4670983549177459, 0.5111130556527826, 0.5485649282464123], 'final_state_dict_size_bytes': 902, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0011723515279533745, 'batch_size': 48, 'epochs': 8, 'weight_decay': 5.859935541290405e-06, 'dropout': 0.03573141677203631, 'channel_multiplier': 3, 'kernel_size1': 67, 'stride1': 12, 'kernel_size2': 8, 'stride2': 5, 'gcn_hidden': 17, 'label_smoothing': 0.0838996850429199, 'grad_clip_norm': 4.917668926419343, 'use_amp': True, 'calibrate_batches': 47, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 53, 'model_storage_size_kb': 0.22773437500000002, 'model_size_validation': 'PASS'}
2025-10-13 11:55:21,926 - INFO - _models.training_function_executor - BO Objective: base=0.5486, size_penalty=0.0000, final=0.5486
2025-10-13 11:55:21,926 - INFO - _models.training_function_executor - Model: 53 parameters, 0.2KB (PASS 256KB limit)
2025-10-13 11:55:21,926 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 18.153s
2025-10-13 11:55:22,030 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5486
2025-10-13 11:55:22,030 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-13 11:55:22,031 - INFO - bo.run_bo - Recorded observation #40: hparams={'lr': 0.0011723515279533745, 'batch_size': np.int64(48), 'epochs': np.int64(8), 'weight_decay': 5.859935541290405e-06, 'dropout': 0.03573141677203631, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(67), 'stride1': np.int64(12), 'kernel_size2': np.int64(8), 'stride2': np.int64(5), 'gcn_hidden': np.int64(17), 'label_smoothing': 0.0838996850429199, 'grad_clip_norm': 4.917668926419343, 'use_amp': np.True_, 'calibrate_batches': np.int64(47), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.5486
2025-10-13 11:55:22,031 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 40: {'lr': 0.0011723515279533745, 'batch_size': np.int64(48), 'epochs': np.int64(8), 'weight_decay': 5.859935541290405e-06, 'dropout': 0.03573141677203631, 'channel_multiplier': np.int64(3), 'kernel_size1': np.int64(67), 'stride1': np.int64(12), 'kernel_size2': np.int64(8), 'stride2': np.int64(5), 'gcn_hidden': np.int64(17), 'label_smoothing': 0.0838996850429199, 'grad_clip_norm': 4.917668926419343, 'use_amp': np.True_, 'calibrate_batches': np.int64(47), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.5486
2025-10-13 11:55:22,031 - INFO - bo.run_bo - üîçBO Trial 41: Using RF surrogate + Expected Improvement
2025-10-13 11:55:22,031 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:55:22,031 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 41 (NaN monitoring active)
2025-10-13 11:55:22,031 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:55:22,031 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:55:22,031 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00016991541499366186, 'batch_size': 128, 'epochs': 57, 'weight_decay': 2.529749797175659e-05, 'dropout': 0.002257251564077212, 'channel_multiplier': 5, 'kernel_size1': 98, 'stride1': 10, 'kernel_size2': 12, 'stride2': 5, 'gcn_hidden': 15, 'label_smoothing': 0.003951910866526154, 'grad_clip_norm': 4.539463729323208, 'use_amp': True, 'calibrate_batches': 91, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:55:22,032 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00016991541499366186, 'batch_size': 128, 'epochs': 57, 'weight_decay': 2.529749797175659e-05, 'dropout': 0.002257251564077212, 'channel_multiplier': 5, 'kernel_size1': 98, 'stride1': 10, 'kernel_size2': 12, 'stride2': 5, 'gcn_hidden': 15, 'label_smoothing': 0.003951910866526154, 'grad_clip_norm': 4.539463729323208, 'use_amp': True, 'calibrate_batches': 91, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:55:26,377 - INFO - _models.training_function_executor - Epoch 001/057 - train_loss: 1.5603 - val_loss: 1.5493 - val_acc: 0.3982
2025-10-13 11:55:27,877 - INFO - _models.training_function_executor - Epoch 002/057 - train_loss: 1.5189 - val_loss: 1.4958 - val_acc: 0.3976
2025-10-13 11:55:29,394 - INFO - _models.training_function_executor - Epoch 003/057 - train_loss: 1.4624 - val_loss: 1.4231 - val_acc: 0.4576
2025-10-13 11:55:30,912 - INFO - _models.training_function_executor - Epoch 004/057 - train_loss: 1.3701 - val_loss: 1.3385 - val_acc: 0.5244
2025-10-13 11:55:32,426 - INFO - _models.training_function_executor - Epoch 005/057 - train_loss: 1.2894 - val_loss: 1.3477 - val_acc: 0.4556
2025-10-13 11:55:33,954 - INFO - _models.training_function_executor - Epoch 006/057 - train_loss: 1.2353 - val_loss: 1.2764 - val_acc: 0.4892
2025-10-13 11:55:35,449 - INFO - _models.training_function_executor - Epoch 007/057 - train_loss: 1.1976 - val_loss: 1.1962 - val_acc: 0.5759
2025-10-13 11:55:36,972 - INFO - _models.training_function_executor - Epoch 008/057 - train_loss: 1.1739 - val_loss: 1.1682 - val_acc: 0.5693
2025-10-13 11:55:38,492 - INFO - _models.training_function_executor - Epoch 009/057 - train_loss: 1.1530 - val_loss: 1.1592 - val_acc: 0.5521
2025-10-13 11:55:40,008 - INFO - _models.training_function_executor - Epoch 010/057 - train_loss: 1.1370 - val_loss: 1.1377 - val_acc: 0.5578
2025-10-13 11:55:41,529 - INFO - _models.training_function_executor - Epoch 011/057 - train_loss: 1.1252 - val_loss: 1.1342 - val_acc: 0.5484
2025-10-13 11:55:43,037 - INFO - _models.training_function_executor - Epoch 012/057 - train_loss: 1.1137 - val_loss: 1.3405 - val_acc: 0.4694
2025-10-13 11:55:44,555 - INFO - _models.training_function_executor - Epoch 013/057 - train_loss: 1.1038 - val_loss: 1.1063 - val_acc: 0.5584
2025-10-13 11:55:46,080 - INFO - _models.training_function_executor - Epoch 014/057 - train_loss: 1.0933 - val_loss: 1.0990 - val_acc: 0.5631
2025-10-13 11:55:47,603 - INFO - _models.training_function_executor - Epoch 015/057 - train_loss: 1.0864 - val_loss: 1.0900 - val_acc: 0.5832
2025-10-13 11:55:49,124 - INFO - _models.training_function_executor - Epoch 016/057 - train_loss: 1.0790 - val_loss: 1.0783 - val_acc: 0.5872
2025-10-13 11:55:50,629 - INFO - _models.training_function_executor - Epoch 017/057 - train_loss: 1.0735 - val_loss: 1.0821 - val_acc: 0.5671
2025-10-13 11:55:52,159 - INFO - _models.training_function_executor - Epoch 018/057 - train_loss: 1.0664 - val_loss: 1.0806 - val_acc: 0.5794
2025-10-13 11:55:53,668 - INFO - _models.training_function_executor - Epoch 019/057 - train_loss: 1.0593 - val_loss: 1.0683 - val_acc: 0.5759
2025-10-13 11:55:55,195 - INFO - _models.training_function_executor - Epoch 020/057 - train_loss: 1.0548 - val_loss: 1.0683 - val_acc: 0.5814
2025-10-13 11:55:56,724 - INFO - _models.training_function_executor - Epoch 021/057 - train_loss: 1.0498 - val_loss: 1.0605 - val_acc: 0.5904
2025-10-13 11:55:58,244 - INFO - _models.training_function_executor - Epoch 022/057 - train_loss: 1.0447 - val_loss: 1.0482 - val_acc: 0.5829
2025-10-13 11:55:59,767 - INFO - _models.training_function_executor - Epoch 023/057 - train_loss: 1.0377 - val_loss: 1.0649 - val_acc: 0.5588
2025-10-13 11:56:01,296 - INFO - _models.training_function_executor - Epoch 024/057 - train_loss: 1.0328 - val_loss: 1.0967 - val_acc: 0.5569
2025-10-13 11:56:02,807 - INFO - _models.training_function_executor - Epoch 025/057 - train_loss: 1.0287 - val_loss: 1.0581 - val_acc: 0.5714
2025-10-13 11:56:04,330 - INFO - _models.training_function_executor - Epoch 026/057 - train_loss: 1.0243 - val_loss: 1.0348 - val_acc: 0.5739
2025-10-13 11:56:05,844 - INFO - _models.training_function_executor - Epoch 027/057 - train_loss: 1.0213 - val_loss: 1.1102 - val_acc: 0.5668
2025-10-13 11:56:07,378 - INFO - _models.training_function_executor - Epoch 028/057 - train_loss: 1.0167 - val_loss: 1.0368 - val_acc: 0.5766
2025-10-13 11:56:08,886 - INFO - _models.training_function_executor - Epoch 029/057 - train_loss: 1.0130 - val_loss: 1.0201 - val_acc: 0.6103
2025-10-13 11:56:10,409 - INFO - _models.training_function_executor - Epoch 030/057 - train_loss: 1.0105 - val_loss: 1.2401 - val_acc: 0.4912
2025-10-13 11:56:11,942 - INFO - _models.training_function_executor - Epoch 031/057 - train_loss: 1.0070 - val_loss: 1.0279 - val_acc: 0.6009
2025-10-13 11:56:13,456 - INFO - _models.training_function_executor - Epoch 032/057 - train_loss: 1.0049 - val_loss: 1.0508 - val_acc: 0.5787
2025-10-13 11:56:14,959 - INFO - _models.training_function_executor - Epoch 033/057 - train_loss: 1.0000 - val_loss: 1.0077 - val_acc: 0.5926
2025-10-13 11:56:16,480 - INFO - _models.training_function_executor - Epoch 034/057 - train_loss: 0.9959 - val_loss: 1.0415 - val_acc: 0.5841
2025-10-13 11:56:18,006 - INFO - _models.training_function_executor - Epoch 035/057 - train_loss: 0.9950 - val_loss: 1.0006 - val_acc: 0.6019
2025-10-13 11:56:19,511 - INFO - _models.training_function_executor - Epoch 036/057 - train_loss: 0.9936 - val_loss: 1.0216 - val_acc: 0.6137
2025-10-13 11:56:21,032 - INFO - _models.training_function_executor - Epoch 037/057 - train_loss: 0.9917 - val_loss: 0.9924 - val_acc: 0.6221
2025-10-13 11:56:22,565 - INFO - _models.training_function_executor - Epoch 038/057 - train_loss: 0.9910 - val_loss: 1.1051 - val_acc: 0.5496
2025-10-13 11:56:24,080 - INFO - _models.training_function_executor - Epoch 039/057 - train_loss: 0.9875 - val_loss: 0.9940 - val_acc: 0.6047
2025-10-13 11:56:25,594 - INFO - _models.training_function_executor - Epoch 040/057 - train_loss: 0.9815 - val_loss: 1.0225 - val_acc: 0.6124
2025-10-13 11:56:27,116 - INFO - _models.training_function_executor - Epoch 041/057 - train_loss: 0.9823 - val_loss: 0.9844 - val_acc: 0.6035
2025-10-13 11:56:28,626 - INFO - _models.training_function_executor - Epoch 042/057 - train_loss: 0.9789 - val_loss: 1.0450 - val_acc: 0.5823
2025-10-13 11:56:30,136 - INFO - _models.training_function_executor - Epoch 043/057 - train_loss: 0.9770 - val_loss: 1.0095 - val_acc: 0.5975
2025-10-13 11:56:31,664 - INFO - _models.training_function_executor - Epoch 044/057 - train_loss: 0.9767 - val_loss: 0.9860 - val_acc: 0.6320
2025-10-13 11:56:33,181 - INFO - _models.training_function_executor - Epoch 045/057 - train_loss: 0.9741 - val_loss: 0.9715 - val_acc: 0.6203
2025-10-13 11:56:34,693 - INFO - _models.training_function_executor - Epoch 046/057 - train_loss: 0.9727 - val_loss: 0.9750 - val_acc: 0.6105
2025-10-13 11:56:36,202 - INFO - _models.training_function_executor - Epoch 047/057 - train_loss: 0.9708 - val_loss: 1.0361 - val_acc: 0.5927
2025-10-13 11:56:37,731 - INFO - _models.training_function_executor - Epoch 048/057 - train_loss: 0.9687 - val_loss: 0.9702 - val_acc: 0.6147
2025-10-13 11:56:39,252 - INFO - _models.training_function_executor - Epoch 049/057 - train_loss: 0.9679 - val_loss: 0.9771 - val_acc: 0.6133
2025-10-13 11:56:40,765 - INFO - _models.training_function_executor - Epoch 050/057 - train_loss: 0.9651 - val_loss: 0.9635 - val_acc: 0.6401
2025-10-13 11:56:42,298 - INFO - _models.training_function_executor - Epoch 051/057 - train_loss: 0.9631 - val_loss: 1.1860 - val_acc: 0.5092
2025-10-13 11:56:43,813 - INFO - _models.training_function_executor - Epoch 052/057 - train_loss: 0.9623 - val_loss: 1.1057 - val_acc: 0.5530
2025-10-13 11:56:45,330 - INFO - _models.training_function_executor - Epoch 053/057 - train_loss: 0.9619 - val_loss: 0.9644 - val_acc: 0.6161
2025-10-13 11:56:46,841 - INFO - _models.training_function_executor - Epoch 054/057 - train_loss: 0.9615 - val_loss: 1.0524 - val_acc: 0.5641
2025-10-13 11:56:48,362 - INFO - _models.training_function_executor - Epoch 055/057 - train_loss: 0.9578 - val_loss: 0.9914 - val_acc: 0.6243
2025-10-13 11:56:49,874 - INFO - _models.training_function_executor - Epoch 056/057 - train_loss: 0.9596 - val_loss: 0.9768 - val_acc: 0.6299
2025-10-13 11:56:51,371 - INFO - _models.training_function_executor - Epoch 057/057 - train_loss: 0.9566 - val_loss: 0.9636 - val_acc: 0.6388
2025-10-13 11:56:52,496 - INFO - _models.training_function_executor - Model: 1,241 parameters, 5.3KB storage
2025-10-13 11:56:52,496 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5602549110879254, 1.518850691259262, 1.4624017829614626, 1.3700977136590575, 1.2894242781628085, 1.2352990247504796, 1.1976442723204133, 1.1739101552612763, 1.1529934266083384, 1.1369720967574515, 1.1251941735318043, 1.1136657645913492, 1.1037539063444661, 1.0933379008922703, 1.086428239581716, 1.078976649481974, 1.073547283794482, 1.0663878261771784, 1.059325166836793, 1.0548062566739511, 1.0498477037361047, 1.044656253441005, 1.0377345800316329, 1.0327796185396332, 1.0287170805295198, 1.0242668667747543, 1.021341583884843, 1.0167073222319898, 1.0129747710989037, 1.0105081945605574, 1.0070139445497475, 1.0049250813935826, 1.0000317785178277, 0.9958897912506461, 0.9950403080021621, 0.9936051542290784, 0.9917289410431902, 0.9909893478970032, 0.9875347701077032, 0.9814816954922835, 0.982316378659204, 0.97893428401927, 0.9769738730451298, 0.9766561228535499, 0.9741186356269107, 0.9726704533466477, 0.970781004424691, 0.9687263212047093, 0.967866719999971, 0.9650545938890381, 0.963057003740585, 0.9623486375241251, 0.9619105673145071, 0.9615059349768054, 0.9577928977618486, 0.9595882908881525, 0.9566101853481155], 'val_losses': [1.5493133904677736, 1.495815501748827, 1.4231102401491724, 1.338462743343571, 1.3476895392254011, 1.2764373440654035, 1.1962289502664927, 1.1681504111461887, 1.159201693902034, 1.1377127649986873, 1.134186272400845, 1.3404747689149994, 1.1062651253430877, 1.0989609096782125, 1.0899946580702582, 1.0782709327410016, 1.0820602940895527, 1.080623821190783, 1.0682695857452937, 1.0682736063988258, 1.0604705011923914, 1.048191097177406, 1.0649122545090763, 1.0967272136609454, 1.05812506342752, 1.034833531050904, 1.1102449704935637, 1.0367588571288764, 1.020065915763983, 1.2401438752045195, 1.0278652152023742, 1.05083923987421, 1.0076734274469308, 1.0414868949133071, 1.000641172692456, 1.0215675273807807, 0.9924112696058482, 1.105066902494781, 0.9939925720276931, 1.0224525176189478, 0.9843889159842475, 1.044993672539481, 1.0095362343652956, 0.9860430339186351, 0.9715392005831619, 0.9749819734190827, 1.0360628926007114, 0.9701913571833396, 0.9771067255395336, 0.9634977538225991, 1.186032008281904, 1.1057471215912709, 0.9644016561952137, 1.0523893321190507, 0.9914295620379182, 0.9768011409334257, 0.9636143567806614], 'val_acc': [0.39823241162058104, 0.3976198809940497, 0.4575603780189009, 0.5244137206860343, 0.4556352817640882, 0.4892369618480924, 0.5758662933146658, 0.5693034651732587, 0.5520651032551628, 0.557840392019601, 0.5483899194959748, 0.46937346867343366, 0.5583654182709136, 0.5630906545327267, 0.5832166608330417, 0.5871543577178859, 0.5671158557927897, 0.5793664683234162, 0.5758662933146658, 0.5813790689534477, 0.5903920196009801, 0.5828666433321666, 0.5588029401470074, 0.5568778438921946, 0.571403570178509, 0.5738536926846343, 0.5667658382919146, 0.5765663283164159, 0.6103430171508576, 0.4912495624781239, 0.6008925446272314, 0.5786664333216661, 0.5925796289814491, 0.5840917045852293, 0.6018550927546378, 0.6136681834091705, 0.6220686034301716, 0.5496149807490375, 0.6047427371368569, 0.6123556177808891, 0.6035176758837942, 0.5823416170808541, 0.5974798739936997, 0.6320441022051102, 0.6203185159257963, 0.6105180259012951, 0.5926671333566679, 0.6147182359117956, 0.6133181659082955, 0.6400945047252362, 0.5091879593979699, 0.5530276513825692, 0.6161183059152958, 0.564053202660133, 0.6242562128106406, 0.6299439971998599, 0.6387819390969548], 'final_state_dict_size_bytes': 5268, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00016991541499366186, 'batch_size': 128, 'epochs': 57, 'weight_decay': 2.529749797175659e-05, 'dropout': 0.002257251564077212, 'channel_multiplier': 5, 'kernel_size1': 98, 'stride1': 10, 'kernel_size2': 12, 'stride2': 5, 'gcn_hidden': 15, 'label_smoothing': 0.003951910866526154, 'grad_clip_norm': 4.539463729323208, 'use_amp': True, 'calibrate_batches': 91, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1241, 'model_storage_size_kb': 5.3324218750000005, 'model_size_validation': 'PASS'}
2025-10-13 11:56:52,496 - INFO - _models.training_function_executor - BO Objective: base=0.6388, size_penalty=0.0000, final=0.6388
2025-10-13 11:56:52,496 - INFO - _models.training_function_executor - Model: 1,241 parameters, 5.3KB (PASS 256KB limit)
2025-10-13 11:56:52,496 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 90.465s
2025-10-13 11:56:52,601 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6388
2025-10-13 11:56:52,601 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-13 11:56:52,601 - INFO - bo.run_bo - Recorded observation #41: hparams={'lr': 0.00016991541499366186, 'batch_size': np.int64(128), 'epochs': np.int64(57), 'weight_decay': 2.529749797175659e-05, 'dropout': 0.002257251564077212, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(98), 'stride1': np.int64(10), 'kernel_size2': np.int64(12), 'stride2': np.int64(5), 'gcn_hidden': np.int64(15), 'label_smoothing': 0.003951910866526154, 'grad_clip_norm': 4.539463729323208, 'use_amp': np.True_, 'calibrate_batches': np.int64(91), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.6388
2025-10-13 11:56:52,601 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 41: {'lr': 0.00016991541499366186, 'batch_size': np.int64(128), 'epochs': np.int64(57), 'weight_decay': 2.529749797175659e-05, 'dropout': 0.002257251564077212, 'channel_multiplier': np.int64(5), 'kernel_size1': np.int64(98), 'stride1': np.int64(10), 'kernel_size2': np.int64(12), 'stride2': np.int64(5), 'gcn_hidden': np.int64(15), 'label_smoothing': 0.003951910866526154, 'grad_clip_norm': 4.539463729323208, 'use_amp': np.True_, 'calibrate_batches': np.int64(91), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.6388
2025-10-13 11:56:52,601 - INFO - bo.run_bo - üîçBO Trial 42: Using RF surrogate + Expected Improvement
2025-10-13 11:56:52,601 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:56:52,601 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 42 (NaN monitoring active)
2025-10-13 11:56:52,601 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:56:52,601 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:56:52,601 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0015411752701702732, 'batch_size': 96, 'epochs': 43, 'weight_decay': 0.0003193380733615681, 'dropout': 0.006995088206446011, 'channel_multiplier': 1, 'kernel_size1': 119, 'stride1': 9, 'kernel_size2': 30, 'stride2': 8, 'gcn_hidden': 10, 'label_smoothing': 0.02667393343662275, 'grad_clip_norm': 4.8915055584017395, 'use_amp': True, 'calibrate_batches': 121, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:56:52,602 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0015411752701702732, 'batch_size': 96, 'epochs': 43, 'weight_decay': 0.0003193380733615681, 'dropout': 0.006995088206446011, 'channel_multiplier': 1, 'kernel_size1': 119, 'stride1': 9, 'kernel_size2': 30, 'stride2': 8, 'gcn_hidden': 10, 'label_smoothing': 0.02667393343662275, 'grad_clip_norm': 4.8915055584017395, 'use_amp': True, 'calibrate_batches': 121, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 11:56:56,886 - INFO - _models.training_function_executor - Epoch 001/043 - train_loss: 1.4435 - val_loss: 1.3622 - val_acc: 0.4189
2025-10-13 11:56:58,374 - INFO - _models.training_function_executor - Epoch 002/043 - train_loss: 1.2764 - val_loss: 1.2799 - val_acc: 0.5266
2025-10-13 11:56:59,882 - INFO - _models.training_function_executor - Epoch 003/043 - train_loss: 1.2138 - val_loss: 1.2573 - val_acc: 0.4999
2025-10-13 11:57:01,368 - INFO - _models.training_function_executor - Epoch 004/043 - train_loss: 1.1834 - val_loss: 1.1579 - val_acc: 0.5655
2025-10-13 11:57:02,894 - INFO - _models.training_function_executor - Epoch 005/043 - train_loss: 1.1650 - val_loss: 1.1506 - val_acc: 0.5641
2025-10-13 11:57:04,391 - INFO - _models.training_function_executor - Epoch 006/043 - train_loss: 1.1525 - val_loss: 1.2575 - val_acc: 0.4783
2025-10-13 11:57:05,894 - INFO - _models.training_function_executor - Epoch 007/043 - train_loss: 1.1391 - val_loss: 1.1209 - val_acc: 0.5695
2025-10-13 11:57:07,405 - INFO - _models.training_function_executor - Epoch 008/043 - train_loss: 1.1324 - val_loss: 1.1163 - val_acc: 0.5669
2025-10-13 11:57:08,910 - INFO - _models.training_function_executor - Epoch 009/043 - train_loss: 1.1223 - val_loss: 1.3826 - val_acc: 0.4163
2025-10-13 11:57:10,423 - INFO - _models.training_function_executor - Epoch 010/043 - train_loss: 1.1170 - val_loss: 1.2082 - val_acc: 0.5046
2025-10-13 11:57:11,934 - INFO - _models.training_function_executor - Epoch 011/043 - train_loss: 1.1115 - val_loss: 1.0962 - val_acc: 0.5643
2025-10-13 11:57:13,450 - INFO - _models.training_function_executor - Epoch 012/043 - train_loss: 1.1010 - val_loss: 1.0827 - val_acc: 0.5796
2025-10-13 11:57:14,956 - INFO - _models.training_function_executor - Epoch 013/043 - train_loss: 1.0870 - val_loss: 1.0641 - val_acc: 0.5774
2025-10-13 11:57:16,466 - INFO - _models.training_function_executor - Epoch 014/043 - train_loss: 1.0781 - val_loss: 1.1849 - val_acc: 0.5216
2025-10-13 11:57:17,997 - INFO - _models.training_function_executor - Epoch 015/043 - train_loss: 1.0731 - val_loss: 1.0725 - val_acc: 0.5893
2025-10-13 11:57:19,513 - INFO - _models.training_function_executor - Epoch 016/043 - train_loss: 1.0669 - val_loss: 1.0602 - val_acc: 0.5840
2025-10-13 11:57:21,009 - INFO - _models.training_function_executor - Epoch 017/043 - train_loss: 1.0623 - val_loss: 1.0964 - val_acc: 0.5861
2025-10-13 11:57:22,530 - INFO - _models.training_function_executor - Epoch 018/043 - train_loss: 1.0600 - val_loss: 1.0499 - val_acc: 0.5914
2025-10-13 11:57:24,054 - INFO - _models.training_function_executor - Epoch 019/043 - train_loss: 1.0545 - val_loss: 1.0472 - val_acc: 0.6122
2025-10-13 11:57:25,562 - INFO - _models.training_function_executor - Epoch 020/043 - train_loss: 1.0527 - val_loss: 1.1016 - val_acc: 0.5868
2025-10-13 11:57:27,089 - INFO - _models.training_function_executor - Epoch 021/043 - train_loss: 1.0549 - val_loss: 1.0653 - val_acc: 0.6004
2025-10-13 11:57:28,615 - INFO - _models.training_function_executor - Epoch 022/043 - train_loss: 1.0505 - val_loss: 1.0360 - val_acc: 0.6097
2025-10-13 11:57:30,129 - INFO - _models.training_function_executor - Epoch 023/043 - train_loss: 1.0460 - val_loss: 1.0378 - val_acc: 0.5980
2025-10-13 11:57:31,645 - INFO - _models.training_function_executor - Epoch 024/043 - train_loss: 1.0427 - val_loss: 1.0283 - val_acc: 0.6053
2025-10-13 11:57:33,167 - INFO - _models.training_function_executor - Epoch 025/043 - train_loss: 1.0438 - val_loss: 1.0190 - val_acc: 0.6220
2025-10-13 11:57:34,682 - INFO - _models.training_function_executor - Epoch 026/043 - train_loss: 1.0385 - val_loss: 1.1347 - val_acc: 0.5416
2025-10-13 11:57:36,176 - INFO - _models.training_function_executor - Epoch 027/043 - train_loss: 1.0360 - val_loss: 1.0496 - val_acc: 0.5789
2025-10-13 11:57:37,687 - INFO - _models.training_function_executor - Epoch 028/043 - train_loss: 1.0391 - val_loss: 1.0411 - val_acc: 0.5953
2025-10-13 11:57:39,210 - INFO - _models.training_function_executor - Epoch 029/043 - train_loss: 1.0370 - val_loss: 1.0307 - val_acc: 0.5965
2025-10-13 11:57:40,718 - INFO - _models.training_function_executor - Epoch 030/043 - train_loss: 1.0353 - val_loss: 1.0085 - val_acc: 0.6218
2025-10-13 11:57:42,220 - INFO - _models.training_function_executor - Epoch 031/043 - train_loss: 1.0317 - val_loss: 1.0181 - val_acc: 0.6119
2025-10-13 11:57:43,741 - INFO - _models.training_function_executor - Epoch 032/043 - train_loss: 1.0289 - val_loss: 1.0226 - val_acc: 0.6025
2025-10-13 11:57:45,247 - INFO - _models.training_function_executor - Epoch 033/043 - train_loss: 1.0279 - val_loss: 1.0224 - val_acc: 0.6084
2025-10-13 11:57:46,762 - INFO - _models.training_function_executor - Epoch 034/043 - train_loss: 1.0248 - val_loss: 1.0027 - val_acc: 0.6215
2025-10-13 11:57:48,279 - INFO - _models.training_function_executor - Epoch 035/043 - train_loss: 1.0265 - val_loss: 0.9995 - val_acc: 0.6165
2025-10-13 11:57:49,810 - INFO - _models.training_function_executor - Epoch 036/043 - train_loss: 1.0232 - val_loss: 1.0825 - val_acc: 0.5732
2025-10-13 11:57:51,324 - INFO - _models.training_function_executor - Epoch 037/043 - train_loss: 1.0255 - val_loss: 1.0346 - val_acc: 0.5993
2025-10-13 11:57:52,827 - INFO - _models.training_function_executor - Epoch 038/043 - train_loss: 1.0240 - val_loss: 1.1615 - val_acc: 0.5291
2025-10-13 11:57:54,353 - INFO - _models.training_function_executor - Epoch 039/043 - train_loss: 1.0246 - val_loss: 1.0286 - val_acc: 0.5906
2025-10-13 11:57:55,862 - INFO - _models.training_function_executor - Epoch 040/043 - train_loss: 1.0206 - val_loss: 0.9985 - val_acc: 0.6097
2025-10-13 11:57:57,367 - INFO - _models.training_function_executor - Epoch 041/043 - train_loss: 1.0220 - val_loss: 0.9951 - val_acc: 0.6194
2025-10-13 11:57:58,926 - INFO - _models.training_function_executor - Epoch 042/043 - train_loss: 1.0205 - val_loss: 0.9971 - val_acc: 0.6128
2025-10-13 11:58:00,440 - INFO - _models.training_function_executor - Epoch 043/043 - train_loss: 1.0224 - val_loss: 1.0304 - val_acc: 0.5857
2025-10-13 11:58:01,565 - INFO - _models.training_function_executor - Model: 1,039 parameters, 4.5KB storage
2025-10-13 11:58:01,565 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4434522825560872, 1.2764482329181328, 1.2137939511874276, 1.183433364895536, 1.165049962451669, 1.1525475113467816, 1.13908807581273, 1.132410034542531, 1.1223179020579561, 1.1170148364221628, 1.1114786200311413, 1.1009574879455033, 1.0870426349970357, 1.078089194110861, 1.0731074156400662, 1.0668645377838406, 1.0623282381692967, 1.0599854480648607, 1.0545129758476335, 1.0526685862429375, 1.054887536984872, 1.0504517020735242, 1.0460152435770058, 1.0426626565951254, 1.04376172009656, 1.0385437141067297, 1.0360204523828924, 1.039100238481601, 1.037011939243374, 1.0352806410340525, 1.031720401525581, 1.0289390502294795, 1.0278763670499065, 1.0248222233408766, 1.0265301330380812, 1.0231674511949207, 1.0255128576240633, 1.0240024239774095, 1.0245815664269018, 1.0205756510142725, 1.0220455414855818, 1.0205193656201041, 1.0224019842711953], 'val_losses': [1.3621707889722452, 1.2799458141964468, 1.2572973486757129, 1.1578984997428545, 1.1506314398652404, 1.2574531972345706, 1.1208633037142541, 1.1163194350608796, 1.3826125699988936, 1.2081763837819004, 1.096232884698787, 1.0827230179606095, 1.0640513092894883, 1.184920946826541, 1.0725259525524722, 1.0602465202894333, 1.0964331664862148, 1.0498907118774938, 1.0472117065757482, 1.1016396824446515, 1.0652759773646947, 1.0360133916212622, 1.0377819194716926, 1.028256734100972, 1.0189835466118513, 1.13470570090604, 1.049623022223003, 1.0411399697189279, 1.030711896568902, 1.008466624362426, 1.0180767227562733, 1.022627629889948, 1.0224499415800543, 1.0027153284181696, 0.9995465967093559, 1.0824674087510395, 1.0346122017097006, 1.1614803849795419, 1.028574998369574, 0.9985045304780745, 0.9950834196849766, 0.9971174470269267, 1.0303783008674245], 'val_acc': [0.41888344417220863, 0.5266013300665033, 0.49991249562478124, 0.565540777038852, 0.5641407070353518, 0.4782989149457473, 0.5694784739236962, 0.5668533426671334, 0.4162583129156458, 0.5045502275113756, 0.5643157157857893, 0.5796289814490725, 0.5774413720686035, 0.521613580679034, 0.5892544627231362, 0.5840042002100105, 0.5861043052152608, 0.5913545677283865, 0.6121806090304516, 0.5868043402170109, 0.6003675183759188, 0.6097304865243263, 0.5980049002450123, 0.6052677633881695, 0.6219810990549528, 0.5415645782289115, 0.5789289464473224, 0.5952922646132307, 0.5965173258662934, 0.6218060903045153, 0.6119180959047953, 0.6024676233811691, 0.6084179208960449, 0.621543577178859, 0.6164683234161709, 0.5732411620581029, 0.5993174658732937, 0.5290514525726286, 0.5905670283514176, 0.6097304865243263, 0.61935596779839, 0.6127931396569829, 0.585666783339167], 'final_state_dict_size_bytes': 4268, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0015411752701702732, 'batch_size': 96, 'epochs': 43, 'weight_decay': 0.0003193380733615681, 'dropout': 0.006995088206446011, 'channel_multiplier': 1, 'kernel_size1': 119, 'stride1': 9, 'kernel_size2': 30, 'stride2': 8, 'gcn_hidden': 10, 'label_smoothing': 0.02667393343662275, 'grad_clip_norm': 4.8915055584017395, 'use_amp': True, 'calibrate_batches': 121, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1039, 'model_storage_size_kb': 4.464453125, 'model_size_validation': 'PASS'}
2025-10-13 11:58:01,565 - INFO - _models.training_function_executor - BO Objective: base=0.5857, size_penalty=0.0000, final=0.5857
2025-10-13 11:58:01,565 - INFO - _models.training_function_executor - Model: 1,039 parameters, 4.5KB (PASS 256KB limit)
2025-10-13 11:58:01,565 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 68.964s
2025-10-13 11:58:01,671 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5857
2025-10-13 11:58:01,671 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.105s
2025-10-13 11:58:01,671 - INFO - bo.run_bo - Recorded observation #42: hparams={'lr': 0.0015411752701702732, 'batch_size': np.int64(96), 'epochs': np.int64(43), 'weight_decay': 0.0003193380733615681, 'dropout': 0.006995088206446011, 'channel_multiplier': np.int64(1), 'kernel_size1': np.int64(119), 'stride1': np.int64(9), 'kernel_size2': np.int64(30), 'stride2': np.int64(8), 'gcn_hidden': np.int64(10), 'label_smoothing': 0.02667393343662275, 'grad_clip_norm': 4.8915055584017395, 'use_amp': np.True_, 'calibrate_batches': np.int64(121), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.5857
2025-10-13 11:58:01,671 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 42: {'lr': 0.0015411752701702732, 'batch_size': np.int64(96), 'epochs': np.int64(43), 'weight_decay': 0.0003193380733615681, 'dropout': 0.006995088206446011, 'channel_multiplier': np.int64(1), 'kernel_size1': np.int64(119), 'stride1': np.int64(9), 'kernel_size2': np.int64(30), 'stride2': np.int64(8), 'gcn_hidden': np.int64(10), 'label_smoothing': 0.02667393343662275, 'grad_clip_norm': 4.8915055584017395, 'use_amp': np.True_, 'calibrate_batches': np.int64(121), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.5857
2025-10-13 11:58:01,672 - INFO - bo.run_bo - üîçBO Trial 43: Using RF surrogate + Expected Improvement
2025-10-13 11:58:01,672 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 11:58:01,672 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 43 (NaN monitoring active)
2025-10-13 11:58:01,672 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 11:58:01,672 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 11:58:01,672 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002465679301196928, 'batch_size': 16, 'epochs': 27, 'weight_decay': 0.0003247782099294195, 'dropout': 0.013318066435425682, 'channel_multiplier': 1, 'kernel_size1': 86, 'stride1': 10, 'kernel_size2': 47, 'stride2': 8, 'gcn_hidden': 6, 'label_smoothing': 0.11353759815927096, 'grad_clip_norm': 4.365887905727153, 'use_amp': True, 'calibrate_batches': 95, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:58:01,673 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002465679301196928, 'batch_size': 16, 'epochs': 27, 'weight_decay': 0.0003247782099294195, 'dropout': 0.013318066435425682, 'channel_multiplier': 1, 'kernel_size1': 86, 'stride1': 10, 'kernel_size2': 47, 'stride2': 8, 'gcn_hidden': 6, 'label_smoothing': 0.11353759815927096, 'grad_clip_norm': 4.365887905727153, 'use_amp': True, 'calibrate_batches': 95, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 11:58:08,892 - INFO - _models.training_function_executor - Epoch 001/027 - train_loss: 1.4488 - val_loss: 1.6326 - val_acc: 0.2856
2025-10-13 11:58:13,329 - INFO - _models.training_function_executor - Epoch 002/027 - train_loss: 1.3377 - val_loss: 1.3027 - val_acc: 0.5179
2025-10-13 11:58:17,744 - INFO - _models.training_function_executor - Epoch 003/027 - train_loss: 1.2881 - val_loss: 1.3507 - val_acc: 0.5186
2025-10-13 11:58:22,175 - INFO - _models.training_function_executor - Epoch 004/027 - train_loss: 1.2649 - val_loss: 1.2582 - val_acc: 0.5417
2025-10-13 11:58:26,562 - INFO - _models.training_function_executor - Epoch 005/027 - train_loss: 1.2484 - val_loss: 1.2379 - val_acc: 0.5401
2025-10-13 11:58:30,986 - INFO - _models.training_function_executor - Epoch 006/027 - train_loss: 1.2359 - val_loss: 1.2202 - val_acc: 0.5773
2025-10-13 11:58:35,354 - INFO - _models.training_function_executor - Epoch 007/027 - train_loss: 1.2286 - val_loss: 1.3769 - val_acc: 0.4645
2025-10-13 11:58:39,734 - INFO - _models.training_function_executor - Epoch 008/027 - train_loss: 1.2239 - val_loss: 1.2575 - val_acc: 0.5122
2025-10-13 11:58:44,120 - INFO - _models.training_function_executor - Epoch 009/027 - train_loss: 1.2175 - val_loss: 1.3849 - val_acc: 0.4507
2025-10-13 11:58:48,526 - INFO - _models.training_function_executor - Epoch 010/027 - train_loss: 1.2189 - val_loss: 1.2196 - val_acc: 0.5535
2025-10-13 11:58:52,886 - INFO - _models.training_function_executor - Epoch 011/027 - train_loss: 1.2127 - val_loss: 1.2173 - val_acc: 0.5656
2025-10-13 11:58:57,340 - INFO - _models.training_function_executor - Epoch 012/027 - train_loss: 1.2109 - val_loss: 1.2013 - val_acc: 0.5580
2025-10-13 11:59:01,766 - INFO - _models.training_function_executor - Epoch 013/027 - train_loss: 1.2081 - val_loss: 1.1851 - val_acc: 0.5803
2025-10-13 11:59:06,172 - INFO - _models.training_function_executor - Epoch 014/027 - train_loss: 1.2087 - val_loss: 1.1893 - val_acc: 0.6037
2025-10-13 11:59:10,506 - INFO - _models.training_function_executor - Epoch 015/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:14,920 - INFO - _models.training_function_executor - Epoch 016/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:19,393 - INFO - _models.training_function_executor - Epoch 017/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:23,802 - INFO - _models.training_function_executor - Epoch 018/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:28,183 - INFO - _models.training_function_executor - Epoch 019/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:32,615 - INFO - _models.training_function_executor - Epoch 020/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:37,054 - INFO - _models.training_function_executor - Epoch 021/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:41,415 - INFO - _models.training_function_executor - Epoch 022/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:45,783 - INFO - _models.training_function_executor - Epoch 023/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:50,180 - INFO - _models.training_function_executor - Epoch 024/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:54,553 - INFO - _models.training_function_executor - Epoch 025/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 11:59:58,975 - INFO - _models.training_function_executor - Epoch 026/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:00:03,383 - INFO - _models.training_function_executor - Epoch 027/027 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:00:04,593 - INFO - _models.training_function_executor - Model: 911 parameters, 1.0KB storage
2025-10-13 12:00:04,593 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.448771331833508, 1.3376742631019642, 1.2880659111738622, 1.2649069427609403, 1.2483800014791933, 1.2358971054127552, 1.2286295252827693, 1.2238981258756512, 1.217546993237423, 1.2189089253226653, 1.2126507095452743, 1.2109275404122646, 1.2081301825256001, 1.208699169528622, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.632603334137139, 1.3026644140429793, 1.3506519492789921, 1.2582261949141291, 1.2378655883620826, 1.2201950681096905, 1.3769151673769258, 1.2574668128381128, 1.384867518942048, 1.2196290413733333, 1.2173332142420987, 1.201341089269353, 1.1851314367178147, 1.1893120415360101, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.2856142807140357, 0.517938396919846, 0.5186384319215961, 0.5416520826041302, 0.5400770038501925, 0.5772663633181659, 0.46447322366118304, 0.5121631081554078, 0.45073503675183757, 0.553465173258663, 0.5656282814140707, 0.5580154007700385, 0.5803290164508226, 0.6036926846342318, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'final_state_dict_size_bytes': 3756, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002465679301196928, 'batch_size': 16, 'epochs': 27, 'weight_decay': 0.0003247782099294195, 'dropout': 0.013318066435425682, 'channel_multiplier': 1, 'kernel_size1': 86, 'stride1': 10, 'kernel_size2': 47, 'stride2': 8, 'gcn_hidden': 6, 'label_smoothing': 0.11353759815927096, 'grad_clip_norm': 4.365887905727153, 'use_amp': True, 'calibrate_batches': 95, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 911, 'model_storage_size_kb': 0.9786132812500001, 'model_size_validation': 'PASS'}
2025-10-13 12:00:04,593 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-13 12:00:04,593 - INFO - _models.training_function_executor - Model: 911 parameters, 1.0KB (PASS 256KB limit)
2025-10-13 12:00:04,593 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 122.922s
2025-10-13 12:00:04,698 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-13 12:00:04,698 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-13 12:00:04,698 - INFO - bo.run_bo - Recorded observation #43: hparams={'lr': 0.002465679301196928, 'batch_size': np.int64(16), 'epochs': np.int64(27), 'weight_decay': 0.0003247782099294195, 'dropout': 0.013318066435425682, 'channel_multiplier': np.int64(1), 'kernel_size1': np.int64(86), 'stride1': np.int64(10), 'kernel_size2': np.int64(47), 'stride2': np.int64(8), 'gcn_hidden': np.int64(6), 'label_smoothing': 0.11353759815927096, 'grad_clip_norm': 4.365887905727153, 'use_amp': np.True_, 'calibrate_batches': np.int64(95), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.2325
2025-10-13 12:00:04,698 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 43: {'lr': 0.002465679301196928, 'batch_size': np.int64(16), 'epochs': np.int64(27), 'weight_decay': 0.0003247782099294195, 'dropout': 0.013318066435425682, 'channel_multiplier': np.int64(1), 'kernel_size1': np.int64(86), 'stride1': np.int64(10), 'kernel_size2': np.int64(47), 'stride2': np.int64(8), 'gcn_hidden': np.int64(6), 'label_smoothing': 0.11353759815927096, 'grad_clip_norm': 4.365887905727153, 'use_amp': np.True_, 'calibrate_batches': np.int64(95), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.2325
2025-10-13 12:00:04,698 - INFO - bo.run_bo - üîçBO Trial 44: Using RF surrogate + Expected Improvement
2025-10-13 12:00:04,699 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 12:00:04,699 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 44 (NaN monitoring active)
2025-10-13 12:00:04,699 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 12:00:04,699 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:00:04,699 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.008379565847641665, 'batch_size': 64, 'epochs': 29, 'weight_decay': 0.0003216831509807614, 'dropout': 0.026395191928506593, 'channel_multiplier': 2, 'kernel_size1': 40, 'stride1': 4, 'kernel_size2': 22, 'stride2': 5, 'gcn_hidden': 12, 'label_smoothing': 0.11444285425239749, 'grad_clip_norm': 4.27526839593882, 'use_amp': False, 'calibrate_batches': 97, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 12:00:04,700 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.008379565847641665, 'batch_size': 64, 'epochs': 29, 'weight_decay': 0.0003216831509807614, 'dropout': 0.026395191928506593, 'channel_multiplier': 2, 'kernel_size1': 40, 'stride1': 4, 'kernel_size2': 22, 'stride2': 5, 'gcn_hidden': 12, 'label_smoothing': 0.11444285425239749, 'grad_clip_norm': 4.27526839593882, 'use_amp': False, 'calibrate_batches': 97, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 12:00:08,909 - INFO - _models.training_function_executor - Epoch 001/029 - train_loss: 1.3308 - val_loss: 1.2220 - val_acc: 0.5404
2025-10-13 12:00:10,343 - INFO - _models.training_function_executor - Epoch 002/029 - train_loss: 1.1836 - val_loss: 1.2524 - val_acc: 0.5434
2025-10-13 12:00:11,778 - INFO - _models.training_function_executor - Epoch 003/029 - train_loss: 1.1616 - val_loss: 1.1571 - val_acc: 0.5993
2025-10-13 12:00:13,225 - INFO - _models.training_function_executor - Epoch 004/029 - train_loss: 1.1329 - val_loss: 1.3056 - val_acc: 0.5379
2025-10-13 12:00:14,678 - INFO - _models.training_function_executor - Epoch 005/029 - train_loss: 1.1178 - val_loss: 1.1410 - val_acc: 0.6199
2025-10-13 12:00:16,137 - INFO - _models.training_function_executor - Epoch 006/029 - train_loss: 1.1046 - val_loss: 1.1184 - val_acc: 0.6255
2025-10-13 12:00:17,621 - INFO - _models.training_function_executor - Epoch 007/029 - train_loss: 1.0993 - val_loss: 1.0877 - val_acc: 0.6473
2025-10-13 12:00:19,087 - INFO - _models.training_function_executor - Epoch 008/029 - train_loss: 1.0892 - val_loss: 1.1713 - val_acc: 0.5830
2025-10-13 12:00:20,541 - INFO - _models.training_function_executor - Epoch 009/029 - train_loss: 1.0808 - val_loss: 1.1222 - val_acc: 0.6145
2025-10-13 12:00:22,010 - INFO - _models.training_function_executor - Epoch 010/029 - train_loss: 1.0767 - val_loss: 1.0776 - val_acc: 0.6567
2025-10-13 12:00:23,486 - INFO - _models.training_function_executor - Epoch 011/029 - train_loss: 1.0701 - val_loss: 1.1107 - val_acc: 0.6317
2025-10-13 12:00:24,937 - INFO - _models.training_function_executor - Epoch 012/029 - train_loss: 1.0637 - val_loss: 1.0983 - val_acc: 0.6245
2025-10-13 12:00:26,402 - INFO - _models.training_function_executor - Epoch 013/029 - train_loss: 1.0591 - val_loss: 1.0734 - val_acc: 0.6720
2025-10-13 12:00:27,898 - INFO - _models.training_function_executor - Epoch 014/029 - train_loss: 1.0564 - val_loss: 1.2491 - val_acc: 0.5785
2025-10-13 12:00:29,372 - INFO - _models.training_function_executor - Epoch 015/029 - train_loss: 1.0505 - val_loss: 1.2825 - val_acc: 0.5750
2025-10-13 12:00:30,853 - INFO - _models.training_function_executor - Epoch 016/029 - train_loss: 1.0499 - val_loss: 1.0713 - val_acc: 0.6619
2025-10-13 12:00:32,342 - INFO - _models.training_function_executor - Epoch 017/029 - train_loss: 1.0426 - val_loss: 1.0330 - val_acc: 0.6851
2025-10-13 12:00:33,822 - INFO - _models.training_function_executor - Epoch 018/029 - train_loss: 1.0445 - val_loss: 1.0455 - val_acc: 0.6861
2025-10-13 12:00:35,269 - INFO - _models.training_function_executor - Epoch 019/029 - train_loss: 1.0416 - val_loss: 1.0815 - val_acc: 0.6424
2025-10-13 12:00:36,742 - INFO - _models.training_function_executor - Epoch 020/029 - train_loss: 1.0415 - val_loss: 1.1411 - val_acc: 0.5900
2025-10-13 12:00:38,219 - INFO - _models.training_function_executor - Epoch 021/029 - train_loss: 1.0354 - val_loss: 1.0673 - val_acc: 0.6616
2025-10-13 12:00:39,704 - INFO - _models.training_function_executor - Epoch 022/029 - train_loss: 1.0356 - val_loss: 1.2185 - val_acc: 0.6157
2025-10-13 12:00:41,163 - INFO - _models.training_function_executor - Epoch 023/029 - train_loss: 1.0359 - val_loss: 1.0355 - val_acc: 0.6790
2025-10-13 12:00:42,640 - INFO - _models.training_function_executor - Epoch 024/029 - train_loss: 1.0340 - val_loss: 1.1288 - val_acc: 0.6107
2025-10-13 12:00:44,105 - INFO - _models.training_function_executor - Epoch 025/029 - train_loss: 1.0318 - val_loss: 1.0220 - val_acc: 0.6892
2025-10-13 12:00:45,547 - INFO - _models.training_function_executor - Epoch 026/029 - train_loss: 1.0268 - val_loss: 1.0500 - val_acc: 0.6715
2025-10-13 12:00:47,022 - INFO - _models.training_function_executor - Epoch 027/029 - train_loss: 1.0291 - val_loss: 1.1185 - val_acc: 0.6360
2025-10-13 12:00:48,526 - INFO - _models.training_function_executor - Epoch 028/029 - train_loss: 1.0274 - val_loss: 1.0630 - val_acc: 0.6705
2025-10-13 12:00:50,005 - INFO - _models.training_function_executor - Epoch 029/029 - train_loss: 1.0287 - val_loss: 1.1719 - val_acc: 0.6066
2025-10-13 12:00:51,111 - INFO - _models.training_function_executor - Model: 689 parameters, 3.0KB storage
2025-10-13 12:00:51,111 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3308240372190785, 1.183638351840659, 1.161571907963751, 1.1328549725549555, 1.1178174195775294, 1.104557380127164, 1.0993110682941793, 1.0891503177408492, 1.0807866239864843, 1.0767075277768443, 1.070141459662972, 1.0636613450352446, 1.059135697210924, 1.05638214108157, 1.0505054582029028, 1.0499373635588136, 1.042569769901707, 1.0444502110743297, 1.0416209036794042, 1.0414958277447974, 1.0353605994445525, 1.0355579989916968, 1.0359345274786036, 1.0340266619523089, 1.0317804693216037, 1.026821648945206, 1.0290589412693214, 1.0273617234812527, 1.028672100782478], 'val_losses': [1.2219794768739674, 1.2524315177622398, 1.1571099083866738, 1.3055942330612433, 1.1410224068027133, 1.1183785893176876, 1.0877079125839302, 1.1712733582679233, 1.1222121132225436, 1.0776219790241373, 1.110688585186906, 1.0982772592151335, 1.073425057387494, 1.2490793209539914, 1.2824736680023145, 1.0712749587934585, 1.0329870822590717, 1.0454878299687766, 1.0815020644001332, 1.1410517241097764, 1.067303821011611, 1.2184728646470318, 1.0355489590304023, 1.1287589795029493, 1.0220469711208244, 1.0499961437943686, 1.1184844717430327, 1.06301723479557, 1.1719181667393974], 'val_acc': [0.5404270213510676, 0.5434021701085054, 0.5993174658732937, 0.5378893944697235, 0.6198809940497025, 0.6254812740637031, 0.6472698634931746, 0.5829541477073854, 0.6144557227861394, 0.6567203360168008, 0.6316940847042352, 0.6245187259362969, 0.672033601680084, 0.5784914245712286, 0.5749912495624782, 0.6618830941547077, 0.6850717535876794, 0.6861218060903045, 0.642369618480924, 0.5899544977248863, 0.6616205810290514, 0.615680784039202, 0.6790339516975848, 0.6106930346517326, 0.6891844592229611, 0.6715085754287714, 0.6359817990899544, 0.670546027301365, 0.6065803290164509], 'final_state_dict_size_bytes': 2916, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.008379565847641665, 'batch_size': 64, 'epochs': 29, 'weight_decay': 0.0003216831509807614, 'dropout': 0.026395191928506593, 'channel_multiplier': 2, 'kernel_size1': 40, 'stride1': 4, 'kernel_size2': 22, 'stride2': 5, 'gcn_hidden': 12, 'label_smoothing': 0.11444285425239749, 'grad_clip_norm': 4.27526839593882, 'use_amp': False, 'calibrate_batches': 97, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 689, 'model_storage_size_kb': 2.9605468750000004, 'model_size_validation': 'PASS'}
2025-10-13 12:00:51,111 - INFO - _models.training_function_executor - BO Objective: base=0.6066, size_penalty=0.0000, final=0.6066
2025-10-13 12:00:51,111 - INFO - _models.training_function_executor - Model: 689 parameters, 3.0KB (PASS 256KB limit)
2025-10-13 12:00:51,111 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 46.413s
2025-10-13 12:00:51,218 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6066
2025-10-13 12:00:51,218 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-13 12:00:51,218 - INFO - bo.run_bo - Recorded observation #44: hparams={'lr': 0.008379565847641665, 'batch_size': np.int64(64), 'epochs': np.int64(29), 'weight_decay': 0.0003216831509807614, 'dropout': 0.026395191928506593, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(40), 'stride1': np.int64(4), 'kernel_size2': np.int64(22), 'stride2': np.int64(5), 'gcn_hidden': np.int64(12), 'label_smoothing': 0.11444285425239749, 'grad_clip_norm': 4.27526839593882, 'use_amp': np.False_, 'calibrate_batches': np.int64(97), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.6066
2025-10-13 12:00:51,218 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 44: {'lr': 0.008379565847641665, 'batch_size': np.int64(64), 'epochs': np.int64(29), 'weight_decay': 0.0003216831509807614, 'dropout': 0.026395191928506593, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(40), 'stride1': np.int64(4), 'kernel_size2': np.int64(22), 'stride2': np.int64(5), 'gcn_hidden': np.int64(12), 'label_smoothing': 0.11444285425239749, 'grad_clip_norm': 4.27526839593882, 'use_amp': np.False_, 'calibrate_batches': np.int64(97), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.6066
2025-10-13 12:00:51,219 - INFO - bo.run_bo - üîçBO Trial 45: Using RF surrogate + Expected Improvement
2025-10-13 12:00:51,219 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 12:00:51,219 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 45 (NaN monitoring active)
2025-10-13 12:00:51,219 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 12:00:51,219 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:00:51,219 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007778687626423507, 'batch_size': 32, 'epochs': 40, 'weight_decay': 6.290350973584067e-06, 'dropout': 0.011797813175034347, 'channel_multiplier': 8, 'kernel_size1': 40, 'stride1': 12, 'kernel_size2': 25, 'stride2': 4, 'gcn_hidden': 9, 'label_smoothing': 0.10022439985999618, 'grad_clip_norm': 0.35691383670475757, 'use_amp': False, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 12:00:51,220 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007778687626423507, 'batch_size': 32, 'epochs': 40, 'weight_decay': 6.290350973584067e-06, 'dropout': 0.011797813175034347, 'channel_multiplier': 8, 'kernel_size1': 40, 'stride1': 12, 'kernel_size2': 25, 'stride2': 4, 'gcn_hidden': 9, 'label_smoothing': 0.10022439985999618, 'grad_clip_norm': 0.35691383670475757, 'use_amp': False, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 12:00:56,106 - INFO - _models.training_function_executor - Epoch 001/040 - train_loss: 1.2358 - val_loss: 1.2249 - val_acc: 0.5519
2025-10-13 12:00:58,192 - INFO - _models.training_function_executor - Epoch 002/040 - train_loss: 1.1098 - val_loss: 1.0876 - val_acc: 0.6404
2025-10-13 12:01:00,275 - INFO - _models.training_function_executor - Epoch 003/040 - train_loss: 1.0827 - val_loss: 1.2497 - val_acc: 0.5363
2025-10-13 12:01:02,374 - INFO - _models.training_function_executor - Epoch 004/040 - train_loss: 1.0695 - val_loss: 1.1401 - val_acc: 0.6046
2025-10-13 12:01:04,483 - INFO - _models.training_function_executor - Epoch 005/040 - train_loss: 1.0580 - val_loss: 1.1067 - val_acc: 0.6137
2025-10-13 12:01:06,580 - INFO - _models.training_function_executor - Epoch 006/040 - train_loss: 1.0410 - val_loss: 1.0739 - val_acc: 0.6450
2025-10-13 12:01:08,693 - INFO - _models.training_function_executor - Epoch 007/040 - train_loss: 1.0343 - val_loss: 1.0607 - val_acc: 0.6488
2025-10-13 12:01:10,794 - INFO - _models.training_function_executor - Epoch 008/040 - train_loss: 1.0248 - val_loss: 1.1479 - val_acc: 0.6318
2025-10-13 12:01:12,893 - INFO - _models.training_function_executor - Epoch 009/040 - train_loss: 1.0183 - val_loss: 1.0050 - val_acc: 0.6775
2025-10-13 12:01:14,981 - INFO - _models.training_function_executor - Epoch 010/040 - train_loss: 1.0146 - val_loss: 0.9961 - val_acc: 0.6821
2025-10-13 12:01:17,092 - INFO - _models.training_function_executor - Epoch 011/040 - train_loss: 1.0118 - val_loss: 1.0358 - val_acc: 0.6520
2025-10-13 12:01:19,189 - INFO - _models.training_function_executor - Epoch 012/040 - train_loss: 1.0098 - val_loss: 1.2480 - val_acc: 0.5628
2025-10-13 12:01:21,307 - INFO - _models.training_function_executor - Epoch 013/040 - train_loss: 1.0071 - val_loss: 0.9954 - val_acc: 0.6936
2025-10-13 12:01:23,426 - INFO - _models.training_function_executor - Epoch 014/040 - train_loss: 1.0041 - val_loss: 1.0342 - val_acc: 0.6659
2025-10-13 12:01:25,526 - INFO - _models.training_function_executor - Epoch 015/040 - train_loss: 1.0030 - val_loss: 1.2338 - val_acc: 0.6324
2025-10-13 12:01:27,599 - INFO - _models.training_function_executor - Epoch 016/040 - train_loss: 0.9990 - val_loss: 1.0059 - val_acc: 0.6947
2025-10-13 12:01:29,723 - INFO - _models.training_function_executor - Epoch 017/040 - train_loss: 1.0029 - val_loss: 0.9836 - val_acc: 0.7001
2025-10-13 12:01:31,827 - INFO - _models.training_function_executor - Epoch 018/040 - train_loss: 0.9959 - val_loss: 1.0490 - val_acc: 0.6579
2025-10-13 12:01:33,934 - INFO - _models.training_function_executor - Epoch 019/040 - train_loss: 0.9951 - val_loss: 0.9900 - val_acc: 0.6952
2025-10-13 12:01:36,074 - INFO - _models.training_function_executor - Epoch 020/040 - train_loss: 0.9972 - val_loss: 1.2649 - val_acc: 0.5245
2025-10-13 12:01:38,158 - INFO - _models.training_function_executor - Epoch 021/040 - train_loss: 0.9923 - val_loss: 0.9834 - val_acc: 0.7055
2025-10-13 12:01:40,257 - INFO - _models.training_function_executor - Epoch 022/040 - train_loss: 0.9929 - val_loss: 1.0042 - val_acc: 0.6745
2025-10-13 12:01:42,376 - INFO - _models.training_function_executor - Epoch 023/040 - train_loss: 0.9905 - val_loss: 0.9757 - val_acc: 0.7020
2025-10-13 12:01:44,505 - INFO - _models.training_function_executor - Epoch 024/040 - train_loss: 0.9889 - val_loss: 1.0231 - val_acc: 0.6729
2025-10-13 12:01:46,604 - INFO - _models.training_function_executor - Epoch 025/040 - train_loss: 0.9854 - val_loss: 1.2088 - val_acc: 0.5912
2025-10-13 12:01:48,728 - INFO - _models.training_function_executor - Epoch 026/040 - train_loss: 0.9866 - val_loss: 0.9602 - val_acc: 0.7097
2025-10-13 12:01:50,829 - INFO - _models.training_function_executor - Epoch 027/040 - train_loss: 0.9860 - val_loss: 1.0078 - val_acc: 0.6773
2025-10-13 12:01:52,940 - INFO - _models.training_function_executor - Epoch 028/040 - train_loss: 0.9849 - val_loss: 1.0651 - val_acc: 0.6650
2025-10-13 12:01:55,061 - INFO - _models.training_function_executor - Epoch 029/040 - train_loss: 0.9808 - val_loss: 0.9842 - val_acc: 0.6888
2025-10-13 12:01:57,178 - INFO - _models.training_function_executor - Epoch 030/040 - train_loss: 0.9826 - val_loss: 1.0040 - val_acc: 0.6809
2025-10-13 12:01:59,298 - INFO - _models.training_function_executor - Epoch 031/040 - train_loss: 0.9820 - val_loss: 1.0283 - val_acc: 0.6724
2025-10-13 12:02:01,381 - INFO - _models.training_function_executor - Epoch 032/040 - train_loss: 0.9778 - val_loss: 1.0275 - val_acc: 0.6638
2025-10-13 12:02:03,466 - INFO - _models.training_function_executor - Epoch 033/040 - train_loss: 0.9795 - val_loss: 0.9831 - val_acc: 0.6888
2025-10-13 12:02:05,571 - INFO - _models.training_function_executor - Epoch 034/040 - train_loss: 0.9779 - val_loss: 1.0128 - val_acc: 0.6715
2025-10-13 12:02:07,646 - INFO - _models.training_function_executor - Epoch 035/040 - train_loss: 0.9773 - val_loss: 0.9909 - val_acc: 0.6893
2025-10-13 12:02:09,740 - INFO - _models.training_function_executor - Epoch 036/040 - train_loss: 0.9758 - val_loss: 0.9763 - val_acc: 0.7009
2025-10-13 12:02:11,842 - INFO - _models.training_function_executor - Epoch 037/040 - train_loss: 0.9744 - val_loss: 0.9394 - val_acc: 0.7165
2025-10-13 12:02:13,935 - INFO - _models.training_function_executor - Epoch 038/040 - train_loss: 0.9754 - val_loss: 0.9792 - val_acc: 0.7006
2025-10-13 12:02:16,035 - INFO - _models.training_function_executor - Epoch 039/040 - train_loss: 0.9752 - val_loss: 1.0478 - val_acc: 0.6557
2025-10-13 12:02:18,136 - INFO - _models.training_function_executor - Epoch 040/040 - train_loss: 0.9688 - val_loss: 1.1449 - val_acc: 0.6454
2025-10-13 12:02:19,266 - INFO - _models.training_function_executor - Model: 1,724 parameters, 7.4KB storage
2025-10-13 12:02:19,266 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2357944754566144, 1.1098206993329345, 1.082666970233964, 1.0695252688898254, 1.0580184156760328, 1.0409962294775161, 1.0342659019364067, 1.0247864306995325, 1.0183200397439716, 1.014609417758457, 1.0118254213263032, 1.0098344621267776, 1.007097520567881, 1.0040578770395505, 1.0029936993418351, 0.9990144703494196, 1.0028522899195078, 0.9958987073294132, 0.995053170797163, 0.9972402295492143, 0.9923278594459317, 0.9929440596072792, 0.99051509222285, 0.9888617822996252, 0.9854271550841126, 0.9865785382993162, 0.9859606658073, 0.9848682429767965, 0.9808416328607091, 0.982628066430444, 0.9820354324894265, 0.9778185943477338, 0.979517435167985, 0.9778955905722037, 0.9772743533698253, 0.9757692326938601, 0.9744401433311812, 0.9753737620928506, 0.9752417733546609, 0.9688411805026382], 'val_losses': [1.2248616308693623, 1.087646819679813, 1.2496718341418818, 1.1400970026125723, 1.1067103525955526, 1.0739239271095178, 1.0607329290731828, 1.1479012374490718, 1.004985831106798, 0.9961127177125972, 1.0358082248816591, 1.248034395452225, 0.9954092100778993, 1.0341538202107516, 1.233786785940545, 1.0058862708188205, 0.9836341771038003, 1.0489964662083888, 0.9899664526850267, 1.2648782488930088, 0.9834155432611318, 1.004219479188662, 0.9756762767363814, 1.0231127360295198, 1.2087860502560823, 0.9601727543613232, 1.007813866045828, 1.0651177648568346, 0.9841577576556154, 1.003991107486702, 1.028331247041974, 1.027534281097595, 0.9830734675523907, 1.0128446795283643, 0.9908522052451118, 0.9763127566427044, 0.9394025534944264, 0.979190985827668, 1.0478073912439623, 1.1448805323421516], 'val_acc': [0.5518900945047253, 0.6404445222261113, 0.5363143157157858, 0.6045677283864194, 0.6136681834091705, 0.6449947497374868, 0.6487574378718935, 0.6317815890794539, 0.6775463773188659, 0.6820966048302415, 0.6519950997549877, 0.5628281414070704, 0.6936471823591179, 0.6659082954147707, 0.6323941197059852, 0.6946972348617431, 0.7001225061253062, 0.6578578928946447, 0.6952222611130556, 0.5245012250612531, 0.7054602730136507, 0.6744837241862093, 0.702047602380119, 0.6729086454322716, 0.5911795589779489, 0.70974798739937, 0.6772838641932096, 0.6650332516625831, 0.6888344417220861, 0.6808715435771788, 0.672383619180959, 0.6638081904095204, 0.6888344417220861, 0.6715085754287714, 0.6892719635981799, 0.7009100455022751, 0.7164858242912145, 0.7005600280014, 0.6556702835141757, 0.6454322716135806], 'final_state_dict_size_bytes': 7344, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007778687626423507, 'batch_size': 32, 'epochs': 40, 'weight_decay': 6.290350973584067e-06, 'dropout': 0.011797813175034347, 'channel_multiplier': 8, 'kernel_size1': 40, 'stride1': 12, 'kernel_size2': 25, 'stride2': 4, 'gcn_hidden': 9, 'label_smoothing': 0.10022439985999618, 'grad_clip_norm': 0.35691383670475757, 'use_amp': False, 'calibrate_batches': 32, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1724, 'model_storage_size_kb': 7.4078125, 'model_size_validation': 'PASS'}
2025-10-13 12:02:19,266 - INFO - _models.training_function_executor - BO Objective: base=0.6454, size_penalty=0.0000, final=0.6454
2025-10-13 12:02:19,266 - INFO - _models.training_function_executor - Model: 1,724 parameters, 7.4KB (PASS 256KB limit)
2025-10-13 12:02:19,266 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 88.047s
2025-10-13 12:02:19,373 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6454
2025-10-13 12:02:19,373 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-13 12:02:19,373 - INFO - bo.run_bo - Recorded observation #45: hparams={'lr': 0.007778687626423507, 'batch_size': np.int64(32), 'epochs': np.int64(40), 'weight_decay': 6.290350973584067e-06, 'dropout': 0.011797813175034347, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(40), 'stride1': np.int64(12), 'kernel_size2': np.int64(25), 'stride2': np.int64(4), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.10022439985999618, 'grad_clip_norm': 0.35691383670475757, 'use_amp': np.False_, 'calibrate_batches': np.int64(32), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6454
2025-10-13 12:02:19,373 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 45: {'lr': 0.007778687626423507, 'batch_size': np.int64(32), 'epochs': np.int64(40), 'weight_decay': 6.290350973584067e-06, 'dropout': 0.011797813175034347, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(40), 'stride1': np.int64(12), 'kernel_size2': np.int64(25), 'stride2': np.int64(4), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.10022439985999618, 'grad_clip_norm': 0.35691383670475757, 'use_amp': np.False_, 'calibrate_batches': np.int64(32), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6454
2025-10-13 12:02:19,374 - INFO - bo.run_bo - üîçBO Trial 46: Using RF surrogate + Expected Improvement
2025-10-13 12:02:19,374 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 12:02:19,374 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 46 (NaN monitoring active)
2025-10-13 12:02:19,374 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 12:02:19,374 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:02:19,374 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002182029657017292, 'batch_size': 32, 'epochs': 30, 'weight_decay': 5.179208934599921e-05, 'dropout': 0.009390860697175764, 'channel_multiplier': 2, 'kernel_size1': 109, 'stride1': 4, 'kernel_size2': 26, 'stride2': 5, 'gcn_hidden': 12, 'label_smoothing': 0.1938902389087036, 'grad_clip_norm': 4.681432544092359, 'use_amp': True, 'calibrate_batches': 31, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 12:02:19,375 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002182029657017292, 'batch_size': 32, 'epochs': 30, 'weight_decay': 5.179208934599921e-05, 'dropout': 0.009390860697175764, 'channel_multiplier': 2, 'kernel_size1': 109, 'stride1': 4, 'kernel_size2': 26, 'stride2': 5, 'gcn_hidden': 12, 'label_smoothing': 0.1938902389087036, 'grad_clip_norm': 4.681432544092359, 'use_amp': True, 'calibrate_batches': 31, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 12:02:24,765 - INFO - _models.training_function_executor - Epoch 001/030 - train_loss: 1.4641 - val_loss: 1.4553 - val_acc: 0.4482
2025-10-13 12:02:27,383 - INFO - _models.training_function_executor - Epoch 002/030 - train_loss: 1.4083 - val_loss: 1.3709 - val_acc: 0.5005
2025-10-13 12:02:30,006 - INFO - _models.training_function_executor - Epoch 003/030 - train_loss: 1.3103 - val_loss: 1.2961 - val_acc: 0.5589
2025-10-13 12:02:32,650 - INFO - _models.training_function_executor - Epoch 004/030 - train_loss: 1.2835 - val_loss: 1.3250 - val_acc: 0.5425
2025-10-13 12:02:35,299 - INFO - _models.training_function_executor - Epoch 005/030 - train_loss: 1.2696 - val_loss: 1.2632 - val_acc: 0.5827
2025-10-13 12:02:37,915 - INFO - _models.training_function_executor - Epoch 006/030 - train_loss: 1.2576 - val_loss: 1.2430 - val_acc: 0.6207
2025-10-13 12:02:40,550 - INFO - _models.training_function_executor - Epoch 007/030 - train_loss: 1.2486 - val_loss: 1.2557 - val_acc: 0.6244
2025-10-13 12:02:43,191 - INFO - _models.training_function_executor - Epoch 008/030 - train_loss: 1.2429 - val_loss: 1.2606 - val_acc: 0.5878
2025-10-13 12:02:45,810 - INFO - _models.training_function_executor - Epoch 009/030 - train_loss: 1.2337 - val_loss: 1.2417 - val_acc: 0.6157
2025-10-13 12:02:48,459 - INFO - _models.training_function_executor - Epoch 010/030 - train_loss: 1.2245 - val_loss: 1.2341 - val_acc: 0.6435
2025-10-13 12:02:51,098 - INFO - _models.training_function_executor - Epoch 011/030 - train_loss: 1.2193 - val_loss: 1.2155 - val_acc: 0.6516
2025-10-13 12:02:53,744 - INFO - _models.training_function_executor - Epoch 012/030 - train_loss: 1.2131 - val_loss: 1.2158 - val_acc: 0.6206
2025-10-13 12:02:56,394 - INFO - _models.training_function_executor - Epoch 013/030 - train_loss: 1.2085 - val_loss: 1.2435 - val_acc: 0.6066
2025-10-13 12:02:59,045 - INFO - _models.training_function_executor - Epoch 014/030 - train_loss: 1.2071 - val_loss: 1.2039 - val_acc: 0.6582
2025-10-13 12:03:01,695 - INFO - _models.training_function_executor - Epoch 015/030 - train_loss: 1.2011 - val_loss: 1.1820 - val_acc: 0.6680
2025-10-13 12:03:04,312 - INFO - _models.training_function_executor - Epoch 016/030 - train_loss: 1.1956 - val_loss: 1.2551 - val_acc: 0.5819
2025-10-13 12:03:06,927 - INFO - _models.training_function_executor - Epoch 017/030 - train_loss: 1.1889 - val_loss: 1.2180 - val_acc: 0.6267
2025-10-13 12:03:09,592 - INFO - _models.training_function_executor - Epoch 018/030 - train_loss: 1.1834 - val_loss: 1.1985 - val_acc: 0.6316
2025-10-13 12:03:12,234 - INFO - _models.training_function_executor - Epoch 019/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:14,872 - INFO - _models.training_function_executor - Epoch 020/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:17,501 - INFO - _models.training_function_executor - Epoch 021/030 - train_loss: 1.1737 - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:20,131 - INFO - _models.training_function_executor - Epoch 022/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:22,700 - INFO - _models.training_function_executor - Epoch 023/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:25,327 - INFO - _models.training_function_executor - Epoch 024/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:27,965 - INFO - _models.training_function_executor - Epoch 025/030 - train_loss: 1.1598 - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:30,607 - INFO - _models.training_function_executor - Epoch 026/030 - train_loss: 1.1606 - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:33,244 - INFO - _models.training_function_executor - Epoch 027/030 - train_loss: 1.1563 - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:35,878 - INFO - _models.training_function_executor - Epoch 028/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:38,519 - INFO - _models.training_function_executor - Epoch 029/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:41,132 - INFO - _models.training_function_executor - Epoch 030/030 - train_loss: nan - val_loss: nan - val_acc: 0.2325
2025-10-13 12:03:42,240 - INFO - _models.training_function_executor - Model: 1,151 parameters, 4.9KB storage
2025-10-13 12:03:42,240 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4640876227506692, 1.4082627659875444, 1.3102564321016572, 1.2834700279649756, 1.2695601040723652, 1.2576051914153668, 1.2486042749393558, 1.2428655087801808, 1.2337448097502055, 1.2245234807221088, 1.219318275565153, 1.213144058149763, 1.208470142968351, 1.2071336140197018, 1.2010756592922458, 1.1955659958212201, 1.1888966105974843, 1.183367338679577, nan, nan, 1.1737041612334047, nan, nan, nan, 1.159835158505972, 1.160606421871873, 1.1562552918159423, nan, nan, nan], 'val_losses': [1.4553227970388998, 1.3708978449501354, 1.2961448658418104, 1.325049418647013, 1.2631916594663866, 1.242984605661672, 1.2557158965016313, 1.2605553725652858, 1.241700688983996, 1.2340521936363218, 1.215523990877116, 1.2158171692051418, 1.243545078213164, 1.2039478791523615, 1.1820070101407845, 1.2550776010215554, 1.2180425207181789, 1.1984761384220277, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.4481974098704935, 0.5005250262513126, 0.5588904445222261, 0.5425271263563178, 0.5826916345817291, 0.6206685334266714, 0.6244312215610781, 0.5877668883444173, 0.615680784039202, 0.6435071753587679, 0.6516450822541127, 0.6205810290514526, 0.6065803290164509, 0.6582079103955197, 0.668008400420021, 0.5819040952047603, 0.6267063353167658, 0.6316065803290164, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'final_state_dict_size_bytes': 4764, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002182029657017292, 'batch_size': 32, 'epochs': 30, 'weight_decay': 5.179208934599921e-05, 'dropout': 0.009390860697175764, 'channel_multiplier': 2, 'kernel_size1': 109, 'stride1': 4, 'kernel_size2': 26, 'stride2': 5, 'gcn_hidden': 12, 'label_smoothing': 0.1938902389087036, 'grad_clip_norm': 4.681432544092359, 'use_amp': True, 'calibrate_batches': 31, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 1151, 'model_storage_size_kb': 4.9457031250000005, 'model_size_validation': 'PASS'}
2025-10-13 12:03:42,241 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-13 12:03:42,241 - INFO - _models.training_function_executor - Model: 1,151 parameters, 4.9KB (PASS 256KB limit)
2025-10-13 12:03:42,241 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 82.867s
2025-10-13 12:03:42,347 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-13 12:03:42,347 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-13 12:03:42,347 - INFO - bo.run_bo - Recorded observation #46: hparams={'lr': 0.002182029657017292, 'batch_size': np.int64(32), 'epochs': np.int64(30), 'weight_decay': 5.179208934599921e-05, 'dropout': 0.009390860697175764, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(109), 'stride1': np.int64(4), 'kernel_size2': np.int64(26), 'stride2': np.int64(5), 'gcn_hidden': np.int64(12), 'label_smoothing': 0.1938902389087036, 'grad_clip_norm': 4.681432544092359, 'use_amp': np.True_, 'calibrate_batches': np.int64(31), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.2325
2025-10-13 12:03:42,347 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 46: {'lr': 0.002182029657017292, 'batch_size': np.int64(32), 'epochs': np.int64(30), 'weight_decay': 5.179208934599921e-05, 'dropout': 0.009390860697175764, 'channel_multiplier': np.int64(2), 'kernel_size1': np.int64(109), 'stride1': np.int64(4), 'kernel_size2': np.int64(26), 'stride2': np.int64(5), 'gcn_hidden': np.int64(12), 'label_smoothing': 0.1938902389087036, 'grad_clip_norm': 4.681432544092359, 'use_amp': np.True_, 'calibrate_batches': np.int64(31), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.2325
2025-10-13 12:03:42,348 - INFO - bo.run_bo - üîçBO Trial 47: Using RF surrogate + Expected Improvement
2025-10-13 12:03:42,348 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 12:03:42,348 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 47 (NaN monitoring active)
2025-10-13 12:03:42,348 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 12:03:42,348 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:03:42,348 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.567924988093146e-05, 'batch_size': 32, 'epochs': 28, 'weight_decay': 1.3271783153953103e-06, 'dropout': 0.006125306848167168, 'channel_multiplier': 6, 'kernel_size1': 118, 'stride1': 15, 'kernel_size2': 35, 'stride2': 6, 'gcn_hidden': 14, 'label_smoothing': 0.09206453264493301, 'grad_clip_norm': 0.886236294317252, 'use_amp': True, 'calibrate_batches': 21, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 12:03:42,349 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.567924988093146e-05, 'batch_size': 32, 'epochs': 28, 'weight_decay': 1.3271783153953103e-06, 'dropout': 0.006125306848167168, 'channel_multiplier': 6, 'kernel_size1': 118, 'stride1': 15, 'kernel_size2': 35, 'stride2': 6, 'gcn_hidden': 14, 'label_smoothing': 0.09206453264493301, 'grad_clip_norm': 0.886236294317252, 'use_amp': True, 'calibrate_batches': 21, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 12:03:47,660 - INFO - _models.training_function_executor - Epoch 001/028 - train_loss: 1.5593 - val_loss: 1.5162 - val_acc: 0.4289
2025-10-13 12:03:50,237 - INFO - _models.training_function_executor - Epoch 002/028 - train_loss: 1.4720 - val_loss: 1.4870 - val_acc: 0.4304
2025-10-13 12:03:52,799 - INFO - _models.training_function_executor - Epoch 003/028 - train_loss: 1.4397 - val_loss: 1.4509 - val_acc: 0.4569
2025-10-13 12:03:55,349 - INFO - _models.training_function_executor - Epoch 004/028 - train_loss: 1.4239 - val_loss: 1.6068 - val_acc: 0.2349
2025-10-13 12:03:57,902 - INFO - _models.training_function_executor - Epoch 005/028 - train_loss: 1.4144 - val_loss: 1.4468 - val_acc: 0.4382
2025-10-13 12:04:00,453 - INFO - _models.training_function_executor - Epoch 006/028 - train_loss: 1.4069 - val_loss: 1.4256 - val_acc: 0.4544
2025-10-13 12:04:03,018 - INFO - _models.training_function_executor - Epoch 007/028 - train_loss: 1.4018 - val_loss: 1.4133 - val_acc: 0.4639
2025-10-13 12:04:05,590 - INFO - _models.training_function_executor - Epoch 008/028 - train_loss: 1.3973 - val_loss: 1.4183 - val_acc: 0.4606
2025-10-13 12:04:08,158 - INFO - _models.training_function_executor - Epoch 009/028 - train_loss: 1.3940 - val_loss: 1.4704 - val_acc: 0.4086
2025-10-13 12:04:10,748 - INFO - _models.training_function_executor - Epoch 010/028 - train_loss: 1.3891 - val_loss: 1.4017 - val_acc: 0.4654
2025-10-13 12:04:13,329 - INFO - _models.training_function_executor - Epoch 011/028 - train_loss: 1.3830 - val_loss: 1.4032 - val_acc: 0.4627
2025-10-13 12:04:15,885 - INFO - _models.training_function_executor - Epoch 012/028 - train_loss: 1.3809 - val_loss: 1.3869 - val_acc: 0.4751
2025-10-13 12:04:18,466 - INFO - _models.training_function_executor - Epoch 013/028 - train_loss: 1.3780 - val_loss: 1.4006 - val_acc: 0.4654
2025-10-13 12:04:21,040 - INFO - _models.training_function_executor - Epoch 014/028 - train_loss: 1.3742 - val_loss: 1.3761 - val_acc: 0.4813
2025-10-13 12:04:23,587 - INFO - _models.training_function_executor - Epoch 015/028 - train_loss: 1.3715 - val_loss: 1.4322 - val_acc: 0.4288
2025-10-13 12:04:26,156 - INFO - _models.training_function_executor - Epoch 016/028 - train_loss: 1.3676 - val_loss: 1.3675 - val_acc: 0.4860
2025-10-13 12:04:28,720 - INFO - _models.training_function_executor - Epoch 017/028 - train_loss: 1.3647 - val_loss: 1.4065 - val_acc: 0.4465
2025-10-13 12:04:31,263 - INFO - _models.training_function_executor - Epoch 018/028 - train_loss: 1.3611 - val_loss: 1.3667 - val_acc: 0.4799
2025-10-13 12:04:33,825 - INFO - _models.training_function_executor - Epoch 019/028 - train_loss: 1.3576 - val_loss: 1.3942 - val_acc: 0.4581
2025-10-13 12:04:36,376 - INFO - _models.training_function_executor - Epoch 020/028 - train_loss: 1.3555 - val_loss: 1.5050 - val_acc: 0.3411
2025-10-13 12:04:38,954 - INFO - _models.training_function_executor - Epoch 021/028 - train_loss: 1.3529 - val_loss: 1.3515 - val_acc: 0.4918
2025-10-13 12:04:41,528 - INFO - _models.training_function_executor - Epoch 022/028 - train_loss: 1.3474 - val_loss: 1.3549 - val_acc: 0.4884
2025-10-13 12:04:44,109 - INFO - _models.training_function_executor - Epoch 023/028 - train_loss: 1.3441 - val_loss: 1.3581 - val_acc: 0.4807
2025-10-13 12:04:46,637 - INFO - _models.training_function_executor - Epoch 024/028 - train_loss: 1.3392 - val_loss: 1.3340 - val_acc: 0.5020
2025-10-13 12:04:49,217 - INFO - _models.training_function_executor - Epoch 025/028 - train_loss: 1.3387 - val_loss: 1.3414 - val_acc: 0.4863
2025-10-13 12:04:51,786 - INFO - _models.training_function_executor - Epoch 026/028 - train_loss: 1.3319 - val_loss: 1.3338 - val_acc: 0.4973
2025-10-13 12:04:54,336 - INFO - _models.training_function_executor - Epoch 027/028 - train_loss: 1.3275 - val_loss: 1.3375 - val_acc: 0.4905
2025-10-13 12:04:56,898 - INFO - _models.training_function_executor - Epoch 028/028 - train_loss: 1.3235 - val_loss: 1.3241 - val_acc: 0.4989
2025-10-13 12:04:58,002 - INFO - _models.training_function_executor - Model: 2,275 parameters, 9.8KB storage
2025-10-13 12:04:58,002 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5593043077980926, 1.4719911751147956, 1.4396603607739191, 1.4238753886251212, 1.4143874036043225, 1.4069159758186942, 1.4018321258019517, 1.3972735079927883, 1.3940414562065115, 1.3890966122743755, 1.3830417424680304, 1.380888211631174, 1.3779716165407079, 1.3741639524979903, 1.3714770638613087, 1.3676342182239536, 1.364747319890771, 1.3611110477627764, 1.357638218538887, 1.3554864942839733, 1.3528585292511066, 1.3473655576258636, 1.3440963080349109, 1.339220989822799, 1.3387126072245041, 1.3319346144101734, 1.3275069604605947, 1.3234661050638954], 'val_losses': [1.5161886352069067, 1.486975180965059, 1.4509276825104054, 1.6067595135135002, 1.446826727773328, 1.4256245424416167, 1.4132781996775392, 1.4182528221903459, 1.470432844118593, 1.4016916811528806, 1.4031660880581833, 1.3869012612999425, 1.400564620742691, 1.3761164411865918, 1.4322127859451406, 1.3675399375287312, 1.4064528414282633, 1.3666546293434916, 1.3942154467752608, 1.5049942768575597, 1.351474956653316, 1.3548635876091117, 1.3581255515388646, 1.3340046079500096, 1.341424075965494, 1.333816064543185, 1.337483452715822, 1.324118269837566], 'val_acc': [0.4288589429471474, 0.4304340217010851, 0.4569478473923696, 0.2349492474623731, 0.43822191109555475, 0.45441022051102553, 0.4639481974098705, 0.46062303115155756, 0.40855792789639483, 0.4654357717885894, 0.4627231361568078, 0.4750612530626531, 0.4654357717885894, 0.48127406370318515, 0.4287714385719286, 0.48599929996499824, 0.44653482674133704, 0.479873993699685, 0.4580854042702135, 0.3410920546027301, 0.49177458872943647, 0.4883619180959048, 0.4807490374518726, 0.5020126006300315, 0.4863493174658733, 0.4972873643682184, 0.49046202310115505, 0.4988624431221561], 'final_state_dict_size_bytes': 9452, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.567924988093146e-05, 'batch_size': 32, 'epochs': 28, 'weight_decay': 1.3271783153953103e-06, 'dropout': 0.006125306848167168, 'channel_multiplier': 6, 'kernel_size1': 118, 'stride1': 15, 'kernel_size2': 35, 'stride2': 6, 'gcn_hidden': 14, 'label_smoothing': 0.09206453264493301, 'grad_clip_norm': 0.886236294317252, 'use_amp': True, 'calibrate_batches': 21, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 2275, 'model_storage_size_kb': 9.775390625, 'model_size_validation': 'PASS'}
2025-10-13 12:04:58,003 - INFO - _models.training_function_executor - BO Objective: base=0.4989, size_penalty=0.0000, final=0.4989
2025-10-13 12:04:58,003 - INFO - _models.training_function_executor - Model: 2,275 parameters, 9.8KB (PASS 256KB limit)
2025-10-13 12:04:58,003 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 75.655s
2025-10-13 12:04:58,113 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.4989
2025-10-13 12:04:58,113 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-13 12:04:58,113 - INFO - bo.run_bo - Recorded observation #47: hparams={'lr': 8.567924988093146e-05, 'batch_size': np.int64(32), 'epochs': np.int64(28), 'weight_decay': 1.3271783153953103e-06, 'dropout': 0.006125306848167168, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(118), 'stride1': np.int64(15), 'kernel_size2': np.int64(35), 'stride2': np.int64(6), 'gcn_hidden': np.int64(14), 'label_smoothing': 0.09206453264493301, 'grad_clip_norm': 0.886236294317252, 'use_amp': np.True_, 'calibrate_batches': np.int64(21), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.4989
2025-10-13 12:04:58,113 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 47: {'lr': 8.567924988093146e-05, 'batch_size': np.int64(32), 'epochs': np.int64(28), 'weight_decay': 1.3271783153953103e-06, 'dropout': 0.006125306848167168, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(118), 'stride1': np.int64(15), 'kernel_size2': np.int64(35), 'stride2': np.int64(6), 'gcn_hidden': np.int64(14), 'label_smoothing': 0.09206453264493301, 'grad_clip_norm': 0.886236294317252, 'use_amp': np.True_, 'calibrate_batches': np.int64(21), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.4989
2025-10-13 12:04:58,113 - INFO - bo.run_bo - üîçBO Trial 48: Using RF surrogate + Expected Improvement
2025-10-13 12:04:58,113 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 12:04:58,113 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 48 (NaN monitoring active)
2025-10-13 12:04:58,114 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 12:04:58,114 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:04:58,114 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001898739872676943, 'batch_size': 16, 'epochs': 39, 'weight_decay': 2.260063028082725e-05, 'dropout': 0.01674993310704141, 'channel_multiplier': 7, 'kernel_size1': 41, 'stride1': 14, 'kernel_size2': 29, 'stride2': 5, 'gcn_hidden': 11, 'label_smoothing': 0.020948064946519733, 'grad_clip_norm': 4.719769415061444, 'use_amp': True, 'calibrate_batches': 88, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 12:04:58,115 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001898739872676943, 'batch_size': 16, 'epochs': 39, 'weight_decay': 2.260063028082725e-05, 'dropout': 0.01674993310704141, 'channel_multiplier': 7, 'kernel_size1': 41, 'stride1': 14, 'kernel_size2': 29, 'stride2': 5, 'gcn_hidden': 11, 'label_smoothing': 0.020948064946519733, 'grad_clip_norm': 4.719769415061444, 'use_amp': True, 'calibrate_batches': 88, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 12:05:05,426 - INFO - _models.training_function_executor - Epoch 001/039 - train_loss: 1.2600 - val_loss: 1.2468 - val_acc: 0.4942
2025-10-13 12:05:09,831 - INFO - _models.training_function_executor - Epoch 002/039 - train_loss: 1.1151 - val_loss: 1.1298 - val_acc: 0.5373
2025-10-13 12:05:14,261 - INFO - _models.training_function_executor - Epoch 003/039 - train_loss: 1.0730 - val_loss: 1.4280 - val_acc: 0.3669
2025-10-13 12:05:18,688 - INFO - _models.training_function_executor - Epoch 004/039 - train_loss: 1.0479 - val_loss: 0.9978 - val_acc: 0.6129
2025-10-13 12:05:23,157 - INFO - _models.training_function_executor - Epoch 005/039 - train_loss: 1.0284 - val_loss: 1.0804 - val_acc: 0.5725
2025-10-13 12:05:27,583 - INFO - _models.training_function_executor - Epoch 006/039 - train_loss: 1.0163 - val_loss: 1.0082 - val_acc: 0.6078
2025-10-13 12:05:31,934 - INFO - _models.training_function_executor - Epoch 007/039 - train_loss: 1.0076 - val_loss: 0.9755 - val_acc: 0.6489
2025-10-13 12:05:36,345 - INFO - _models.training_function_executor - Epoch 008/039 - train_loss: 0.9968 - val_loss: 1.0798 - val_acc: 0.5835
2025-10-13 12:05:40,858 - INFO - _models.training_function_executor - Epoch 009/039 - train_loss: 0.9886 - val_loss: 1.0684 - val_acc: 0.5923
2025-10-13 12:05:45,323 - INFO - _models.training_function_executor - Epoch 010/039 - train_loss: 0.9833 - val_loss: 1.0971 - val_acc: 0.5642
2025-10-13 12:05:49,646 - INFO - _models.training_function_executor - Epoch 011/039 - train_loss: 0.9716 - val_loss: 0.9997 - val_acc: 0.6355
2025-10-13 12:05:53,980 - INFO - _models.training_function_executor - Epoch 012/039 - train_loss: 0.9658 - val_loss: 1.0156 - val_acc: 0.6310
2025-10-13 12:05:58,365 - INFO - _models.training_function_executor - Epoch 013/039 - train_loss: 0.9564 - val_loss: 1.0244 - val_acc: 0.6020
2025-10-13 12:06:02,807 - INFO - _models.training_function_executor - Epoch 014/039 - train_loss: 0.9450 - val_loss: 1.2557 - val_acc: 0.4757
2025-10-13 12:06:07,223 - INFO - _models.training_function_executor - Epoch 015/039 - train_loss: 0.9410 - val_loss: 0.9930 - val_acc: 0.6607
2025-10-13 12:06:11,586 - INFO - _models.training_function_executor - Epoch 016/039 - train_loss: 0.9306 - val_loss: 0.9299 - val_acc: 0.6700
2025-10-13 12:06:15,959 - INFO - _models.training_function_executor - Epoch 017/039 - train_loss: 0.9238 - val_loss: 0.9658 - val_acc: 0.6483
2025-10-13 12:06:20,400 - INFO - _models.training_function_executor - Epoch 018/039 - train_loss: 0.9202 - val_loss: 1.1118 - val_acc: 0.5530
2025-10-13 12:06:24,851 - INFO - _models.training_function_executor - Epoch 019/039 - train_loss: 0.9134 - val_loss: 0.9174 - val_acc: 0.6976
2025-10-13 12:06:29,256 - INFO - _models.training_function_executor - Epoch 020/039 - train_loss: 0.9028 - val_loss: 1.0117 - val_acc: 0.6129
2025-10-13 12:06:33,673 - INFO - _models.training_function_executor - Epoch 021/039 - train_loss: 0.8978 - val_loss: 0.8830 - val_acc: 0.6991
2025-10-13 12:06:38,076 - INFO - _models.training_function_executor - Epoch 022/039 - train_loss: 0.8945 - val_loss: 1.0372 - val_acc: 0.6060
2025-10-13 12:06:42,327 - INFO - _models.training_function_executor - Epoch 023/039 - train_loss: 0.8920 - val_loss: 0.9809 - val_acc: 0.6407
2025-10-13 12:06:46,764 - INFO - _models.training_function_executor - Epoch 024/039 - train_loss: 0.8859 - val_loss: 1.0935 - val_acc: 0.6243
2025-10-13 12:06:51,135 - INFO - _models.training_function_executor - Epoch 025/039 - train_loss: 0.8836 - val_loss: 1.2006 - val_acc: 0.4993
2025-10-13 12:06:55,551 - INFO - _models.training_function_executor - Epoch 026/039 - train_loss: 0.8811 - val_loss: 0.8554 - val_acc: 0.6952
2025-10-13 12:06:59,923 - INFO - _models.training_function_executor - Epoch 027/039 - train_loss: 0.8774 - val_loss: 1.1642 - val_acc: 0.5775
2025-10-13 12:07:04,305 - INFO - _models.training_function_executor - Epoch 028/039 - train_loss: 0.8696 - val_loss: 0.8805 - val_acc: 0.6828
2025-10-13 12:07:08,722 - INFO - _models.training_function_executor - Epoch 029/039 - train_loss: 0.8708 - val_loss: 0.8459 - val_acc: 0.6950
2025-10-13 12:07:13,150 - INFO - _models.training_function_executor - Epoch 030/039 - train_loss: 0.8655 - val_loss: 0.9753 - val_acc: 0.6098
2025-10-13 12:07:17,360 - INFO - _models.training_function_executor - Epoch 031/039 - train_loss: 0.8609 - val_loss: 0.8747 - val_acc: 0.6726
2025-10-13 12:07:21,738 - INFO - _models.training_function_executor - Epoch 032/039 - train_loss: 0.8626 - val_loss: 0.8988 - val_acc: 0.6609
2025-10-13 12:07:26,183 - INFO - _models.training_function_executor - Epoch 033/039 - train_loss: 0.8595 - val_loss: 0.9660 - val_acc: 0.6537
2025-10-13 12:07:30,689 - INFO - _models.training_function_executor - Epoch 034/039 - train_loss: 0.8565 - val_loss: 1.1411 - val_acc: 0.5613
2025-10-13 12:07:35,120 - INFO - _models.training_function_executor - Epoch 035/039 - train_loss: 0.8569 - val_loss: 1.0039 - val_acc: 0.6449
2025-10-13 12:07:39,515 - INFO - _models.training_function_executor - Epoch 036/039 - train_loss: 0.8538 - val_loss: 1.0084 - val_acc: 0.6099
2025-10-13 12:07:43,970 - INFO - _models.training_function_executor - Epoch 037/039 - train_loss: 0.8549 - val_loss: 0.9686 - val_acc: 0.6290
2025-10-13 12:07:48,372 - INFO - _models.training_function_executor - Epoch 038/039 - train_loss: 0.8550 - val_loss: 0.9013 - val_acc: 0.6507
2025-10-13 12:07:52,788 - INFO - _models.training_function_executor - Epoch 039/039 - train_loss: 0.8521 - val_loss: 1.0498 - val_acc: 0.6075
2025-10-13 12:07:53,916 - INFO - _models.training_function_executor - Model: 1,755 parameters, 7.5KB storage
2025-10-13 12:07:53,916 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.259962678039078, 1.115055515126077, 1.0730154630100557, 1.04790011533374, 1.028406267634296, 1.016326442626877, 1.0076103323316257, 0.9968202353608663, 0.9885880790121454, 0.9832528595078187, 0.9715753704111268, 0.9657693743434534, 0.9563521410582739, 0.9449857918061199, 0.9409914206782546, 0.9306165263666988, 0.9238377491890404, 0.920170555842436, 0.91338226698811, 0.902830099627652, 0.8977846284199729, 0.8944628861950209, 0.8919554651722359, 0.8859416698508218, 0.8835883463831018, 0.8810552292284033, 0.8773574700170269, 0.8695804447634553, 0.8707872232774942, 0.8655036514377861, 0.8608609875119729, 0.8625790908656256, 0.8594935146044049, 0.8564822987572146, 0.8569432291109995, 0.8538129771657035, 0.8548734546604797, 0.8550118107164828, 0.8521437394397844], 'val_losses': [1.2468298629818155, 1.1298025914493623, 1.4279688509519508, 0.9978290275964947, 1.080379883517825, 1.0082128800876833, 0.975535911782705, 1.079813568334209, 1.068404684752737, 1.097059694461402, 0.9997402617344707, 1.0156444584860183, 1.0243515853578076, 1.2557136678261736, 0.9929970919480889, 0.9299163406321667, 0.9658198620749805, 1.111811520588494, 0.9173934260865045, 1.011673373278096, 0.8829587268629064, 1.0371928249241633, 0.9808799525554004, 1.0934932811259388, 1.2006484149926853, 0.8554097654146041, 1.1641882915867348, 0.8805124154239423, 0.8458948495361327, 0.975271427364336, 0.8747320674205936, 0.8987594546243616, 0.9659609510258523, 1.1410663894393622, 1.0038644952460274, 1.0083915912316401, 0.968638509710143, 0.9013418989933409, 1.049794627229025], 'val_acc': [0.4942247112355618, 0.5372768638431922, 0.3669058452922646, 0.6128806440322017, 0.5724536226811341, 0.6078053902695135, 0.6489324466223311, 0.583479173958698, 0.5923171158557928, 0.5642282114105706, 0.6355442772138606, 0.6309940497024851, 0.6020301015050753, 0.47567378368918445, 0.6607455372768638, 0.6700210010500525, 0.6483199159957997, 0.5530276513825692, 0.6975848792439622, 0.6128806440322017, 0.6990724536226811, 0.6059677983899195, 0.6407070353517675, 0.6243437171858593, 0.4992999649982499, 0.6952222611130556, 0.5775288764438222, 0.6827966398319916, 0.6950472523626181, 0.609817990899545, 0.6726461323066153, 0.6609205460273013, 0.6537451872593629, 0.5612530626531327, 0.6449072453622681, 0.6099054952747638, 0.6289814490724536, 0.6506825341267063, 0.6074553727686385], 'final_state_dict_size_bytes': 7420, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001898739872676943, 'batch_size': 16, 'epochs': 39, 'weight_decay': 2.260063028082725e-05, 'dropout': 0.01674993310704141, 'channel_multiplier': 7, 'kernel_size1': 41, 'stride1': 14, 'kernel_size2': 29, 'stride2': 5, 'gcn_hidden': 11, 'label_smoothing': 0.020948064946519733, 'grad_clip_norm': 4.719769415061444, 'use_amp': True, 'calibrate_batches': 88, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1755, 'model_storage_size_kb': 7.541015625000001, 'model_size_validation': 'PASS'}
2025-10-13 12:07:53,916 - INFO - _models.training_function_executor - BO Objective: base=0.6075, size_penalty=0.0000, final=0.6075
2025-10-13 12:07:53,916 - INFO - _models.training_function_executor - Model: 1,755 parameters, 7.5KB (PASS 256KB limit)
2025-10-13 12:07:53,916 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 175.803s
2025-10-13 12:07:54,024 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6075
2025-10-13 12:07:54,024 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-13 12:07:54,024 - INFO - bo.run_bo - Recorded observation #48: hparams={'lr': 0.001898739872676943, 'batch_size': np.int64(16), 'epochs': np.int64(39), 'weight_decay': 2.260063028082725e-05, 'dropout': 0.01674993310704141, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(41), 'stride1': np.int64(14), 'kernel_size2': np.int64(29), 'stride2': np.int64(5), 'gcn_hidden': np.int64(11), 'label_smoothing': 0.020948064946519733, 'grad_clip_norm': 4.719769415061444, 'use_amp': np.True_, 'calibrate_batches': np.int64(88), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6075
2025-10-13 12:07:54,024 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 48: {'lr': 0.001898739872676943, 'batch_size': np.int64(16), 'epochs': np.int64(39), 'weight_decay': 2.260063028082725e-05, 'dropout': 0.01674993310704141, 'channel_multiplier': np.int64(7), 'kernel_size1': np.int64(41), 'stride1': np.int64(14), 'kernel_size2': np.int64(29), 'stride2': np.int64(5), 'gcn_hidden': np.int64(11), 'label_smoothing': 0.020948064946519733, 'grad_clip_norm': 4.719769415061444, 'use_amp': np.True_, 'calibrate_batches': np.int64(88), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6075
2025-10-13 12:07:54,025 - INFO - bo.run_bo - üîçBO Trial 49: Using RF surrogate + Expected Improvement
2025-10-13 12:07:54,025 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 12:07:54,025 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 49 (NaN monitoring active)
2025-10-13 12:07:54,025 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 12:07:54,025 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:07:54,025 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.007461085498201085, 'batch_size': 64, 'epochs': 55, 'weight_decay': 1.0972492013164593e-06, 'dropout': 0.018957842905868376, 'channel_multiplier': 6, 'kernel_size1': 126, 'stride1': 9, 'kernel_size2': 26, 'stride2': 2, 'gcn_hidden': 9, 'label_smoothing': 0.04995703175899323, 'grad_clip_norm': 0.8430077150179284, 'use_amp': False, 'calibrate_batches': 8, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 12:07:54,026 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.007461085498201085, 'batch_size': 64, 'epochs': 55, 'weight_decay': 1.0972492013164593e-06, 'dropout': 0.018957842905868376, 'channel_multiplier': 6, 'kernel_size1': 126, 'stride1': 9, 'kernel_size2': 26, 'stride2': 2, 'gcn_hidden': 9, 'label_smoothing': 0.04995703175899323, 'grad_clip_norm': 0.8430077150179284, 'use_amp': False, 'calibrate_batches': 8, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 12:07:58,549 - INFO - _models.training_function_executor - Epoch 001/055 - train_loss: 1.2268 - val_loss: 1.2869 - val_acc: 0.5005
2025-10-13 12:08:00,260 - INFO - _models.training_function_executor - Epoch 002/055 - train_loss: 1.0888 - val_loss: 1.0544 - val_acc: 0.6204
2025-10-13 12:08:01,965 - INFO - _models.training_function_executor - Epoch 003/055 - train_loss: 1.0570 - val_loss: 1.2323 - val_acc: 0.4800
2025-10-13 12:08:03,679 - INFO - _models.training_function_executor - Epoch 004/055 - train_loss: 1.0374 - val_loss: 1.2176 - val_acc: 0.5389
2025-10-13 12:08:05,389 - INFO - _models.training_function_executor - Epoch 005/055 - train_loss: 1.0244 - val_loss: 1.0885 - val_acc: 0.6002
2025-10-13 12:08:07,099 - INFO - _models.training_function_executor - Epoch 006/055 - train_loss: 1.0150 - val_loss: 1.0030 - val_acc: 0.6523
2025-10-13 12:08:08,801 - INFO - _models.training_function_executor - Epoch 007/055 - train_loss: 1.0039 - val_loss: 0.9685 - val_acc: 0.6625
2025-10-13 12:08:10,500 - INFO - _models.training_function_executor - Epoch 008/055 - train_loss: 0.9956 - val_loss: 1.0954 - val_acc: 0.5751
2025-10-13 12:08:12,211 - INFO - _models.training_function_executor - Epoch 009/055 - train_loss: 0.9929 - val_loss: 1.0494 - val_acc: 0.6231
2025-10-13 12:08:13,929 - INFO - _models.training_function_executor - Epoch 010/055 - train_loss: 0.9913 - val_loss: 0.9779 - val_acc: 0.6635
2025-10-13 12:08:15,642 - INFO - _models.training_function_executor - Epoch 011/055 - train_loss: 0.9842 - val_loss: 0.9863 - val_acc: 0.6651
2025-10-13 12:08:17,354 - INFO - _models.training_function_executor - Epoch 012/055 - train_loss: 0.9810 - val_loss: 1.0717 - val_acc: 0.5893
2025-10-13 12:08:19,058 - INFO - _models.training_function_executor - Epoch 013/055 - train_loss: 0.9729 - val_loss: 1.0261 - val_acc: 0.6184
2025-10-13 12:08:20,767 - INFO - _models.training_function_executor - Epoch 014/055 - train_loss: 0.9756 - val_loss: 1.0111 - val_acc: 0.6396
2025-10-13 12:08:22,483 - INFO - _models.training_function_executor - Epoch 015/055 - train_loss: 0.9696 - val_loss: 0.9646 - val_acc: 0.6453
2025-10-13 12:08:24,195 - INFO - _models.training_function_executor - Epoch 016/055 - train_loss: 0.9633 - val_loss: 0.9342 - val_acc: 0.6966
2025-10-13 12:08:25,923 - INFO - _models.training_function_executor - Epoch 017/055 - train_loss: 0.9609 - val_loss: 0.9413 - val_acc: 0.6656
2025-10-13 12:08:27,622 - INFO - _models.training_function_executor - Epoch 018/055 - train_loss: 0.9585 - val_loss: 0.9617 - val_acc: 0.6834
2025-10-13 12:08:29,334 - INFO - _models.training_function_executor - Epoch 019/055 - train_loss: 0.9555 - val_loss: 0.9189 - val_acc: 0.6960
2025-10-13 12:08:31,046 - INFO - _models.training_function_executor - Epoch 020/055 - train_loss: 0.9543 - val_loss: 0.9905 - val_acc: 0.6484
2025-10-13 12:08:32,752 - INFO - _models.training_function_executor - Epoch 021/055 - train_loss: 0.9503 - val_loss: 0.9233 - val_acc: 0.6954
2025-10-13 12:08:34,468 - INFO - _models.training_function_executor - Epoch 022/055 - train_loss: 0.9455 - val_loss: 1.0164 - val_acc: 0.6373
2025-10-13 12:08:36,168 - INFO - _models.training_function_executor - Epoch 023/055 - train_loss: 0.9450 - val_loss: 0.9275 - val_acc: 0.6832
2025-10-13 12:08:37,881 - INFO - _models.training_function_executor - Epoch 024/055 - train_loss: 0.9381 - val_loss: 0.9926 - val_acc: 0.6484
2025-10-13 12:08:39,580 - INFO - _models.training_function_executor - Epoch 025/055 - train_loss: 0.9378 - val_loss: 0.9063 - val_acc: 0.6952
2025-10-13 12:08:41,291 - INFO - _models.training_function_executor - Epoch 026/055 - train_loss: 0.9358 - val_loss: 0.9890 - val_acc: 0.6645
2025-10-13 12:08:42,992 - INFO - _models.training_function_executor - Epoch 027/055 - train_loss: 0.9307 - val_loss: 0.9016 - val_acc: 0.6924
2025-10-13 12:08:44,709 - INFO - _models.training_function_executor - Epoch 028/055 - train_loss: 0.9302 - val_loss: 1.0079 - val_acc: 0.6156
2025-10-13 12:08:46,416 - INFO - _models.training_function_executor - Epoch 029/055 - train_loss: 0.9277 - val_loss: 0.9482 - val_acc: 0.6601
2025-10-13 12:08:48,124 - INFO - _models.training_function_executor - Epoch 030/055 - train_loss: 0.9185 - val_loss: 0.9624 - val_acc: 0.6737
2025-10-13 12:08:49,828 - INFO - _models.training_function_executor - Epoch 031/055 - train_loss: 0.9128 - val_loss: 0.9544 - val_acc: 0.6502
2025-10-13 12:08:51,542 - INFO - _models.training_function_executor - Epoch 032/055 - train_loss: 0.9122 - val_loss: 0.9138 - val_acc: 0.6908
2025-10-13 12:08:53,256 - INFO - _models.training_function_executor - Epoch 033/055 - train_loss: 0.9120 - val_loss: 0.9362 - val_acc: 0.6557
2025-10-13 12:08:54,969 - INFO - _models.training_function_executor - Epoch 034/055 - train_loss: 0.9070 - val_loss: 0.8880 - val_acc: 0.6864
2025-10-13 12:08:56,697 - INFO - _models.training_function_executor - Epoch 035/055 - train_loss: 0.9071 - val_loss: 0.9216 - val_acc: 0.6803
2025-10-13 12:08:58,403 - INFO - _models.training_function_executor - Epoch 036/055 - train_loss: 0.8989 - val_loss: 0.8836 - val_acc: 0.7002
2025-10-13 12:09:00,117 - INFO - _models.training_function_executor - Epoch 037/055 - train_loss: 0.8977 - val_loss: 1.1423 - val_acc: 0.5563
2025-10-13 12:09:01,832 - INFO - _models.training_function_executor - Epoch 038/055 - train_loss: 0.8933 - val_loss: 0.9558 - val_acc: 0.6629
2025-10-13 12:09:03,536 - INFO - _models.training_function_executor - Epoch 039/055 - train_loss: 0.8884 - val_loss: 0.8853 - val_acc: 0.7047
2025-10-13 12:09:05,247 - INFO - _models.training_function_executor - Epoch 040/055 - train_loss: 0.8835 - val_loss: 0.8782 - val_acc: 0.6942
2025-10-13 12:09:06,969 - INFO - _models.training_function_executor - Epoch 041/055 - train_loss: 0.8810 - val_loss: 0.8802 - val_acc: 0.7019
2025-10-13 12:09:08,677 - INFO - _models.training_function_executor - Epoch 042/055 - train_loss: 0.8770 - val_loss: 0.9238 - val_acc: 0.6677
2025-10-13 12:09:10,394 - INFO - _models.training_function_executor - Epoch 043/055 - train_loss: 0.8794 - val_loss: 1.2859 - val_acc: 0.4974
2025-10-13 12:09:12,103 - INFO - _models.training_function_executor - Epoch 044/055 - train_loss: 0.8723 - val_loss: 0.8497 - val_acc: 0.7227
2025-10-13 12:09:13,828 - INFO - _models.training_function_executor - Epoch 045/055 - train_loss: 0.8783 - val_loss: 0.8526 - val_acc: 0.7193
2025-10-13 12:09:15,548 - INFO - _models.training_function_executor - Epoch 046/055 - train_loss: 0.8719 - val_loss: 0.8883 - val_acc: 0.6973
2025-10-13 12:09:17,262 - INFO - _models.training_function_executor - Epoch 047/055 - train_loss: 0.8649 - val_loss: 1.0174 - val_acc: 0.6221
2025-10-13 12:09:18,982 - INFO - _models.training_function_executor - Epoch 048/055 - train_loss: 0.8686 - val_loss: 0.9046 - val_acc: 0.6899
2025-10-13 12:09:20,711 - INFO - _models.training_function_executor - Epoch 049/055 - train_loss: 0.8654 - val_loss: 0.8523 - val_acc: 0.7072
2025-10-13 12:09:22,415 - INFO - _models.training_function_executor - Epoch 050/055 - train_loss: 0.8593 - val_loss: 0.8518 - val_acc: 0.7153
2025-10-13 12:09:24,127 - INFO - _models.training_function_executor - Epoch 051/055 - train_loss: 0.8613 - val_loss: 1.0372 - val_acc: 0.6096
2025-10-13 12:09:25,839 - INFO - _models.training_function_executor - Epoch 052/055 - train_loss: 0.8626 - val_loss: 0.9153 - val_acc: 0.6826
2025-10-13 12:09:27,557 - INFO - _models.training_function_executor - Epoch 053/055 - train_loss: 0.8589 - val_loss: 0.9238 - val_acc: 0.6896
2025-10-13 12:09:29,283 - INFO - _models.training_function_executor - Epoch 054/055 - train_loss: 0.8562 - val_loss: 0.8703 - val_acc: 0.6992
2025-10-13 12:09:31,000 - INFO - _models.training_function_executor - Epoch 055/055 - train_loss: 0.8515 - val_loss: 0.8474 - val_acc: 0.7187
2025-10-13 12:09:32,105 - INFO - _models.training_function_executor - Model: 1,934 parameters, 8.3KB storage
2025-10-13 12:09:32,105 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2267751301924665, 1.0887990810673347, 1.056996940690235, 1.0373767180838367, 1.024419887628345, 1.0149741363058067, 1.0038769996203782, 0.9956245691908963, 0.9929178212963287, 0.9912852788664137, 0.9842002945093162, 0.9810149642525747, 0.9729170864555524, 0.9756082729897718, 0.9696103834713677, 0.9633252951996202, 0.9609427709115482, 0.9584972326013648, 0.9554952836595801, 0.9542508535465245, 0.9503391279721952, 0.945470961649851, 0.9450130286774187, 0.9381291292161845, 0.9377853991812578, 0.9357842464817543, 0.9306692162050748, 0.9302282889155521, 0.9277469801619038, 0.9185260799242393, 0.912821784422537, 0.9121887883732775, 0.911994388398066, 0.907012058631248, 0.907110252683297, 0.8988614783530724, 0.897701598252706, 0.8932506017097444, 0.8883823783280009, 0.8835013002251093, 0.8810124567099956, 0.876997745178945, 0.8793674802755116, 0.8722597165753635, 0.8782512352397319, 0.8718981113223542, 0.8648729034766978, 0.8685676464885943, 0.8653549769352815, 0.8593153116541974, 0.8612624635469426, 0.8625703422306382, 0.8589427335762169, 0.8561897667129431, 0.851511368644709], 'val_losses': [1.2869322705110304, 1.0543981657438775, 1.232296467995702, 1.2175774273022848, 1.0885147326135285, 1.0029512574132773, 0.9684652377142955, 1.095392555217456, 1.0494133071712484, 0.9778520050355927, 0.986319050740478, 1.0716976409280554, 1.0261437030868343, 1.0111159707934947, 0.9645771970688817, 0.934166909849723, 0.9413336475787565, 0.9616635907226231, 0.9189469475908049, 0.990508840765868, 0.9232617489808416, 1.0164149335768409, 0.9274567710297651, 0.9926348234499757, 0.9063150966171623, 0.9889891344974372, 0.901604556353058, 1.007884649784781, 0.9481785147182583, 0.9624378498425883, 0.9543745850698907, 0.9138490529923243, 0.9362427731014275, 0.8880467710688601, 0.9216279463622801, 0.8836455418590403, 1.142282740194396, 0.9558302333065376, 0.8852502759787266, 0.8782195555483665, 0.8801947243363031, 0.9237976942523025, 1.2859445606281092, 0.8497156880725544, 0.8525649927110576, 0.8882679017140058, 1.017412711366474, 0.9046054983789953, 0.852313561042289, 0.8517764221758203, 1.0371540663415082, 0.9152953983980499, 0.9238265421910431, 0.8702654788074353, 0.8473684824468541], 'val_acc': [0.5005250262513126, 0.6204060203010151, 0.4800490024501225, 0.5388519425971299, 0.6001925096254813, 0.6523451172558627, 0.662495624781239, 0.5750787539376969, 0.6231186559327967, 0.6635456772838642, 0.6651207560378019, 0.589341967098355, 0.6183934196709836, 0.6395694784739236, 0.6453447672383619, 0.6966223311165558, 0.6656457822891144, 0.6834091704585229, 0.6960098004900245, 0.6484074203710185, 0.6953972698634932, 0.6372943647182359, 0.6832341617080854, 0.6484074203710185, 0.6952222611130556, 0.6645082254112705, 0.6924221211060553, 0.6155932796639833, 0.6601330066503325, 0.6736961848092404, 0.6502450122506125, 0.6908470423521176, 0.6556702835141757, 0.6863843192159608, 0.6802590129506475, 0.700210010500525, 0.5562653132656633, 0.6629331466573328, 0.7046727336366818, 0.6941722086104305, 0.7018725936296815, 0.6677458872943647, 0.49737486874343717, 0.7226986349317466, 0.7192859642982149, 0.6973223661183059, 0.6220686034301716, 0.6898844942247112, 0.7072103605180259, 0.7152607630381519, 0.6095554777738887, 0.682621631081554, 0.6896219810990549, 0.6992474623731186, 0.7186734336716836], 'final_state_dict_size_bytes': 8088, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.007461085498201085, 'batch_size': 64, 'epochs': 55, 'weight_decay': 1.0972492013164593e-06, 'dropout': 0.018957842905868376, 'channel_multiplier': 6, 'kernel_size1': 126, 'stride1': 9, 'kernel_size2': 26, 'stride2': 2, 'gcn_hidden': 9, 'label_smoothing': 0.04995703175899323, 'grad_clip_norm': 0.8430077150179284, 'use_amp': False, 'calibrate_batches': 8, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 1934, 'model_storage_size_kb': 8.31015625, 'model_size_validation': 'PASS'}
2025-10-13 12:09:32,106 - INFO - _models.training_function_executor - BO Objective: base=0.7187, size_penalty=0.0000, final=0.7187
2025-10-13 12:09:32,106 - INFO - _models.training_function_executor - Model: 1,934 parameters, 8.3KB (PASS 256KB limit)
2025-10-13 12:09:32,106 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 98.080s
2025-10-13 12:09:32,215 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7187
2025-10-13 12:09:32,215 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-13 12:09:32,215 - INFO - bo.run_bo - Recorded observation #49: hparams={'lr': 0.007461085498201085, 'batch_size': np.int64(64), 'epochs': np.int64(55), 'weight_decay': 1.0972492013164593e-06, 'dropout': 0.018957842905868376, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(126), 'stride1': np.int64(9), 'kernel_size2': np.int64(26), 'stride2': np.int64(2), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.04995703175899323, 'grad_clip_norm': 0.8430077150179284, 'use_amp': np.False_, 'calibrate_batches': np.int64(8), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7187
2025-10-13 12:09:32,215 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 49: {'lr': 0.007461085498201085, 'batch_size': np.int64(64), 'epochs': np.int64(55), 'weight_decay': 1.0972492013164593e-06, 'dropout': 0.018957842905868376, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(126), 'stride1': np.int64(9), 'kernel_size2': np.int64(26), 'stride2': np.int64(2), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.04995703175899323, 'grad_clip_norm': 0.8430077150179284, 'use_amp': np.False_, 'calibrate_batches': np.int64(8), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7187
2025-10-13 12:09:32,216 - INFO - bo.run_bo - üîçBO Trial 50: Using RF surrogate + Expected Improvement
2025-10-13 12:09:32,216 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 12:09:32,216 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 50 (NaN monitoring active)
2025-10-13 12:09:32,216 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 12:09:32,216 - INFO - _models.training_function_executor - Executing training function: MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:09:32,216 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002011882452209812, 'batch_size': 96, 'epochs': 55, 'weight_decay': 1.5794668232071665e-05, 'dropout': 0.2664803591568869, 'channel_multiplier': 8, 'kernel_size1': 42, 'stride1': 16, 'kernel_size2': 51, 'stride2': 4, 'gcn_hidden': 5, 'label_smoothing': 0.0033950985809440455, 'grad_clip_norm': 4.998028403538681, 'use_amp': True, 'calibrate_batches': 79, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 12:09:32,217 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002011882452209812, 'batch_size': 96, 'epochs': 55, 'weight_decay': 1.5794668232071665e-05, 'dropout': 0.2664803591568869, 'channel_multiplier': 8, 'kernel_size1': 42, 'stride1': 16, 'kernel_size2': 51, 'stride2': 4, 'gcn_hidden': 5, 'label_smoothing': 0.0033950985809440455, 'grad_clip_norm': 4.998028403538681, 'use_amp': True, 'calibrate_batches': 79, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 12:09:36,545 - INFO - _models.training_function_executor - Epoch 001/055 - train_loss: 1.3592 - val_loss: 1.3509 - val_acc: 0.4149
2025-10-13 12:09:38,098 - INFO - _models.training_function_executor - Epoch 002/055 - train_loss: 1.1172 - val_loss: 1.1864 - val_acc: 0.5377
2025-10-13 12:09:39,628 - INFO - _models.training_function_executor - Epoch 003/055 - train_loss: 1.0861 - val_loss: 1.1854 - val_acc: 0.5016
2025-10-13 12:09:41,191 - INFO - _models.training_function_executor - Epoch 004/055 - train_loss: 1.0609 - val_loss: 1.1272 - val_acc: 0.5497
2025-10-13 12:09:42,723 - INFO - _models.training_function_executor - Epoch 005/055 - train_loss: 1.0320 - val_loss: 1.0855 - val_acc: 0.5992
2025-10-13 12:09:44,278 - INFO - _models.training_function_executor - Epoch 006/055 - train_loss: 1.0166 - val_loss: 1.0512 - val_acc: 0.5871
2025-10-13 12:09:45,843 - INFO - _models.training_function_executor - Epoch 007/055 - train_loss: 0.9992 - val_loss: 1.1540 - val_acc: 0.5414
2025-10-13 12:09:47,393 - INFO - _models.training_function_executor - Epoch 008/055 - train_loss: 0.9894 - val_loss: 1.4126 - val_acc: 0.3589
2025-10-13 12:09:48,948 - INFO - _models.training_function_executor - Epoch 009/055 - train_loss: 0.9823 - val_loss: 1.0856 - val_acc: 0.5637
2025-10-13 12:09:50,516 - INFO - _models.training_function_executor - Epoch 010/055 - train_loss: 0.9780 - val_loss: 1.0250 - val_acc: 0.6046
2025-10-13 12:09:52,078 - INFO - _models.training_function_executor - Epoch 011/055 - train_loss: 0.9702 - val_loss: 1.1474 - val_acc: 0.5362
2025-10-13 12:09:53,626 - INFO - _models.training_function_executor - Epoch 012/055 - train_loss: 0.9661 - val_loss: 1.0800 - val_acc: 0.5781
2025-10-13 12:09:55,177 - INFO - _models.training_function_executor - Epoch 013/055 - train_loss: 0.9632 - val_loss: 1.0322 - val_acc: 0.6075
2025-10-13 12:09:56,713 - INFO - _models.training_function_executor - Epoch 014/055 - train_loss: 0.9515 - val_loss: 1.0467 - val_acc: 0.5783
2025-10-13 12:09:58,260 - INFO - _models.training_function_executor - Epoch 015/055 - train_loss: 0.9512 - val_loss: 1.0057 - val_acc: 0.6130
2025-10-13 12:09:59,803 - INFO - _models.training_function_executor - Epoch 016/055 - train_loss: 0.9494 - val_loss: 1.0030 - val_acc: 0.6197
2025-10-13 12:10:01,365 - INFO - _models.training_function_executor - Epoch 017/055 - train_loss: 0.9448 - val_loss: 1.0519 - val_acc: 0.5707
2025-10-13 12:10:02,910 - INFO - _models.training_function_executor - Epoch 018/055 - train_loss: 0.9446 - val_loss: 1.0114 - val_acc: 0.5970
2025-10-13 12:10:04,468 - INFO - _models.training_function_executor - Epoch 019/055 - train_loss: 0.9367 - val_loss: 1.0067 - val_acc: 0.6198
2025-10-13 12:10:06,020 - INFO - _models.training_function_executor - Epoch 020/055 - train_loss: 0.9374 - val_loss: 1.0256 - val_acc: 0.6207
2025-10-13 12:10:07,590 - INFO - _models.training_function_executor - Epoch 021/055 - train_loss: 0.9309 - val_loss: 1.0639 - val_acc: 0.5854
2025-10-13 12:10:09,154 - INFO - _models.training_function_executor - Epoch 022/055 - train_loss: 0.9253 - val_loss: 0.9954 - val_acc: 0.6014
2025-10-13 12:10:10,681 - INFO - _models.training_function_executor - Epoch 023/055 - train_loss: 0.9269 - val_loss: 1.0347 - val_acc: 0.6229
2025-10-13 12:10:12,231 - INFO - _models.training_function_executor - Epoch 024/055 - train_loss: 0.9181 - val_loss: 1.0175 - val_acc: 0.5955
2025-10-13 12:10:13,778 - INFO - _models.training_function_executor - Epoch 025/055 - train_loss: 0.9158 - val_loss: 0.9878 - val_acc: 0.6547
2025-10-13 12:10:15,310 - INFO - _models.training_function_executor - Epoch 026/055 - train_loss: 0.9131 - val_loss: 1.0073 - val_acc: 0.6116
2025-10-13 12:10:16,866 - INFO - _models.training_function_executor - Epoch 027/055 - train_loss: 0.9160 - val_loss: 0.9534 - val_acc: 0.6506
2025-10-13 12:10:18,393 - INFO - _models.training_function_executor - Epoch 028/055 - train_loss: 0.9118 - val_loss: 1.0064 - val_acc: 0.6068
2025-10-13 12:10:19,949 - INFO - _models.training_function_executor - Epoch 029/055 - train_loss: 0.9057 - val_loss: 1.0966 - val_acc: 0.5841
2025-10-13 12:10:21,492 - INFO - _models.training_function_executor - Epoch 030/055 - train_loss: 0.9047 - val_loss: 0.9638 - val_acc: 0.6257
2025-10-13 12:10:23,039 - INFO - _models.training_function_executor - Epoch 031/055 - train_loss: 0.8989 - val_loss: 0.9857 - val_acc: 0.6087
2025-10-13 12:10:24,598 - INFO - _models.training_function_executor - Epoch 032/055 - train_loss: 0.8974 - val_loss: 0.9206 - val_acc: 0.6459
2025-10-13 12:10:26,153 - INFO - _models.training_function_executor - Epoch 033/055 - train_loss: 0.8951 - val_loss: 0.9560 - val_acc: 0.6251
2025-10-13 12:10:27,716 - INFO - _models.training_function_executor - Epoch 034/055 - train_loss: 0.8922 - val_loss: 0.9512 - val_acc: 0.6200
2025-10-13 12:10:29,277 - INFO - _models.training_function_executor - Epoch 035/055 - train_loss: 0.8895 - val_loss: 1.0393 - val_acc: 0.5912
2025-10-13 12:10:30,830 - INFO - _models.training_function_executor - Epoch 036/055 - train_loss: 0.8888 - val_loss: 0.9479 - val_acc: 0.6152
2025-10-13 12:10:32,392 - INFO - _models.training_function_executor - Epoch 037/055 - train_loss: 0.8853 - val_loss: 0.9081 - val_acc: 0.6619
2025-10-13 12:10:33,965 - INFO - _models.training_function_executor - Epoch 038/055 - train_loss: 0.8824 - val_loss: 0.9581 - val_acc: 0.6251
2025-10-13 12:10:35,517 - INFO - _models.training_function_executor - Epoch 039/055 - train_loss: 0.8758 - val_loss: 0.9169 - val_acc: 0.6541
2025-10-13 12:10:37,087 - INFO - _models.training_function_executor - Epoch 040/055 - train_loss: 0.8806 - val_loss: 0.9837 - val_acc: 0.6182
2025-10-13 12:10:38,640 - INFO - _models.training_function_executor - Epoch 041/055 - train_loss: 0.8791 - val_loss: 0.9141 - val_acc: 0.6510
2025-10-13 12:10:40,202 - INFO - _models.training_function_executor - Epoch 042/055 - train_loss: 0.8775 - val_loss: 0.9928 - val_acc: 0.6010
2025-10-13 12:10:41,760 - INFO - _models.training_function_executor - Epoch 043/055 - train_loss: 0.8711 - val_loss: 0.9429 - val_acc: 0.6220
2025-10-13 12:10:43,307 - INFO - _models.training_function_executor - Epoch 044/055 - train_loss: 0.8693 - val_loss: 0.9272 - val_acc: 0.6310
2025-10-13 12:10:44,830 - INFO - _models.training_function_executor - Epoch 045/055 - train_loss: 0.8742 - val_loss: 1.2020 - val_acc: 0.4987
2025-10-13 12:10:46,373 - INFO - _models.training_function_executor - Epoch 046/055 - train_loss: 0.8727 - val_loss: 0.9463 - val_acc: 0.6321
2025-10-13 12:10:47,935 - INFO - _models.training_function_executor - Epoch 047/055 - train_loss: 0.8677 - val_loss: 0.9715 - val_acc: 0.6330
2025-10-13 12:10:49,467 - INFO - _models.training_function_executor - Epoch 048/055 - train_loss: 0.8641 - val_loss: 0.8992 - val_acc: 0.6555
2025-10-13 12:10:51,033 - INFO - _models.training_function_executor - Epoch 049/055 - train_loss: 0.8660 - val_loss: 0.9151 - val_acc: 0.6637
2025-10-13 12:10:52,587 - INFO - _models.training_function_executor - Epoch 050/055 - train_loss: 0.8592 - val_loss: 1.2324 - val_acc: 0.4796
2025-10-13 12:10:54,144 - INFO - _models.training_function_executor - Epoch 051/055 - train_loss: 0.8592 - val_loss: 0.9246 - val_acc: 0.6417
2025-10-13 12:10:55,695 - INFO - _models.training_function_executor - Epoch 052/055 - train_loss: 0.8609 - val_loss: 0.9165 - val_acc: 0.6515
2025-10-13 12:10:57,256 - INFO - _models.training_function_executor - Epoch 053/055 - train_loss: 0.8580 - val_loss: 0.9589 - val_acc: 0.6211
2025-10-13 12:10:58,812 - INFO - _models.training_function_executor - Epoch 054/055 - train_loss: 0.8551 - val_loss: 0.9234 - val_acc: 0.6388
2025-10-13 12:11:00,330 - INFO - _models.training_function_executor - Epoch 055/055 - train_loss: 0.8531 - val_loss: 0.9296 - val_acc: 0.6460
2025-10-13 12:11:01,448 - INFO - _models.training_function_executor - Model: 2,924 parameters, 12.6KB storage
2025-10-13 12:11:01,449 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3592017698338035, 1.1172269791583729, 1.0861010728368068, 1.0608542022231078, 1.0319693245418764, 1.0166082711206434, 0.9991659906138313, 0.9893609316231364, 0.9823208277902279, 0.9779799039605034, 0.9701746150167997, 0.9660641606303834, 0.9632267979086802, 0.9515408720634682, 0.9511503599972669, 0.9494009138113308, 0.9447650534938923, 0.9446047911245088, 0.9366533592692781, 0.9374098008773024, 0.9309088622601582, 0.9252707589369451, 0.9269279901239478, 0.918139382471853, 0.9158101528935138, 0.9130866346886661, 0.9159912805603984, 0.9118470323014852, 0.905668887905946, 0.9047100974372687, 0.8988703822897663, 0.8974478982068209, 0.8950520293004119, 0.8921733756644517, 0.8895029171722353, 0.8888241214939127, 0.8852726393827492, 0.8823937021188065, 0.8757852364512728, 0.8806143777329563, 0.8791482745245032, 0.8774869275501987, 0.8710502620172283, 0.8692675592559679, 0.8742040630650345, 0.8726952782994097, 0.8677171709489939, 0.8640653183087211, 0.8659574639183848, 0.8592060202687697, 0.8592078519067774, 0.8608876262714198, 0.8580005109664816, 0.8550801118604362, 0.8530581560759098], 'val_losses': [1.350880988502903, 1.186444132195347, 1.185390280809359, 1.1271927493161824, 1.08551179538626, 1.0511592309667717, 1.1540147382394392, 1.4125852591932175, 1.0855657681118662, 1.025006398522107, 1.1473994254857292, 1.0799503968777588, 1.0321607829850998, 1.0467242381353248, 1.0057230889067017, 1.002952990975879, 1.0518767269165898, 1.0114175508311882, 1.0066783329720341, 1.0256220920961305, 1.0638615701179384, 0.9953674304347627, 1.0346974125265616, 1.01753556939076, 0.987833080214139, 1.0072731562206534, 0.9533934082482551, 1.006427627136376, 1.0965655075322926, 0.9638072889002212, 0.9857201500292796, 0.9205914682385635, 0.9560049883460598, 0.9511635824020901, 1.0393391691140457, 0.9479114503805396, 0.9080997488487839, 0.9580757826785754, 0.9169077813980001, 0.9836625022240606, 0.9140524957035654, 0.9928298778453822, 0.9428534959636871, 0.927245631141182, 1.2020342874493597, 0.9462602216337042, 0.9715026397157641, 0.899195560780613, 0.9150946570894791, 1.232386974759314, 0.9245528731472975, 0.9164754266625399, 0.9589249964648291, 0.9234089873285197, 0.9295890561592174], 'val_acc': [0.4149457472873644, 0.537714385719286, 0.5015750787539377, 0.5497024851242562, 0.599229961498075, 0.5870668533426672, 0.5413895694784739, 0.35894294714735736, 0.563703185159258, 0.6045677283864194, 0.536226811340567, 0.5780539026951348, 0.6074553727686385, 0.5783164158207911, 0.6129681484074204, 0.619705985299265, 0.5707035351767589, 0.5969548477423872, 0.6197934896744838, 0.6206685334266714, 0.5854042702135107, 0.601417570878544, 0.6228561428071404, 0.5954672733636682, 0.6547077353867693, 0.6115680784039202, 0.6505950297514875, 0.6068428421421072, 0.5840917045852293, 0.6257437871893594, 0.6086804340217011, 0.6458697934896744, 0.6251312565628281, 0.6199684984249213, 0.5911795589779489, 0.6151557577878894, 0.6618830941547077, 0.6251312565628281, 0.654095204760238, 0.6182184109205461, 0.6510325516275813, 0.6009800490024502, 0.6219810990549528, 0.6309940497024851, 0.4986874343717186, 0.632131606580329, 0.6330066503325166, 0.6554952747637381, 0.6637206860343017, 0.4796114805740287, 0.6416695834791739, 0.6514700735036751, 0.6211060553027652, 0.6387819390969548, 0.6459572978648932], 'final_state_dict_size_bytes': 12144, 'model_name': 'MixSleepTinyGCN (MixSleepNet-inspired)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002011882452209812, 'batch_size': 96, 'epochs': 55, 'weight_decay': 1.5794668232071665e-05, 'dropout': 0.2664803591568869, 'channel_multiplier': 8, 'kernel_size1': 42, 'stride1': 16, 'kernel_size2': 51, 'stride2': 4, 'gcn_hidden': 5, 'label_smoothing': 0.0033950985809440455, 'grad_clip_norm': 4.998028403538681, 'use_amp': True, 'calibrate_batches': 79, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 2924, 'model_storage_size_kb': 12.5640625, 'model_size_validation': 'PASS'}
2025-10-13 12:11:01,449 - INFO - _models.training_function_executor - BO Objective: base=0.6460, size_penalty=0.0000, final=0.6460
2025-10-13 12:11:01,449 - INFO - _models.training_function_executor - Model: 2,924 parameters, 12.6KB (PASS 256KB limit)
2025-10-13 12:11:01,449 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 89.232s
2025-10-13 12:11:01,561 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6460
2025-10-13 12:11:01,561 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 12:11:01,561 - INFO - bo.run_bo - Recorded observation #50: hparams={'lr': 0.002011882452209812, 'batch_size': np.int64(96), 'epochs': np.int64(55), 'weight_decay': 1.5794668232071665e-05, 'dropout': 0.2664803591568869, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(42), 'stride1': np.int64(16), 'kernel_size2': np.int64(51), 'stride2': np.int64(4), 'gcn_hidden': np.int64(5), 'label_smoothing': 0.0033950985809440455, 'grad_clip_norm': 4.998028403538681, 'use_amp': np.True_, 'calibrate_batches': np.int64(79), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.6460
2025-10-13 12:11:01,561 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 50: {'lr': 0.002011882452209812, 'batch_size': np.int64(96), 'epochs': np.int64(55), 'weight_decay': 1.5794668232071665e-05, 'dropout': 0.2664803591568869, 'channel_multiplier': np.int64(8), 'kernel_size1': np.int64(42), 'stride1': np.int64(16), 'kernel_size2': np.int64(51), 'stride2': np.int64(4), 'gcn_hidden': np.int64(5), 'label_smoothing': 0.0033950985809440455, 'grad_clip_norm': 4.998028403538681, 'use_amp': np.True_, 'calibrate_batches': np.int64(79), 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.6460
2025-10-13 12:11:01,561 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.7187
2025-10-13 12:11:01,561 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.007461085498201085, 'batch_size': np.int64(64), 'epochs': np.int64(55), 'weight_decay': 1.0972492013164593e-06, 'dropout': 0.018957842905868376, 'channel_multiplier': np.int64(6), 'kernel_size1': np.int64(126), 'stride1': np.int64(9), 'kernel_size2': np.int64(26), 'stride2': np.int64(2), 'gcn_hidden': np.int64(9), 'label_smoothing': 0.04995703175899323, 'grad_clip_norm': 0.8430077150179284, 'use_amp': np.False_, 'calibrate_batches': np.int64(8), 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}
2025-10-13 12:11:01,583 - INFO - visualization - Generating BO visualization charts with 50 trials...
2025-10-13 12:11:02,996 - INFO - visualization - BO summary saved to: charts/20251013_121101_BO_MixSleepTinyGCN (MixSleepNet-inspired)/bo_summary.txt
2025-10-13 12:11:03,005 - INFO - visualization - Raw data saved to: charts/20251013_121101_BO_MixSleepTinyGCN (MixSleepNet-inspired)/bo_raw_data.json
2025-10-13 12:11:03,005 - INFO - visualization - Numpy arrays saved to: charts/20251013_121101_BO_MixSleepTinyGCN (MixSleepNet-inspired)/bo_raw_data.npz
2025-10-13 12:11:03,005 - INFO - visualization - BO charts saved to: charts/20251013_121101_BO_MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:11:03,005 - INFO - evaluation.code_generation_pipeline_orchestrator - üìä BO charts saved to: charts/20251013_121101_BO_MixSleepTinyGCN (MixSleepNet-inspired)
2025-10-13 12:11:03,016 - INFO - evaluation.code_generation_pipeline_orchestrator - üöÄ STEP 4: Final Training Execution
2025-10-13 12:11:03,016 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (57140, 6, 6000), Val: (14286, 6, 6000), Test: (17857, 6, 6000)
