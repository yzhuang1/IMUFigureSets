2025-09-15 19:33:23,227 - INFO - __main__ - Logging system initialized successfully
2025-09-15 19:33:23,229 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'y.npy', 'X.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-09-15 19:33:23,229 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-09-15 19:33:23,229 - INFO - __main__ - Attempting to load: y.npy
2025-09-15 19:33:23,231 - INFO - __main__ - Attempting to load: X.npy
2025-09-15 19:33:23,541 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-09-15 19:33:23,855 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-09-15 19:33:23,856 - INFO - __main__ - Starting AI-enhanced training with new pipeline flow
2025-09-15 19:33:23,856 - INFO - __main__ - Flow: Template Selection â†’ BO â†’ Evaluation â†’ Feedback Loop
2025-09-15 19:33:23,868 - INFO - __main__ - Data profile: {'data_type': 'numpy_array', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-09-15 19:33:23,869 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized with max 4 attempts
2025-09-15 19:33:23,869 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution
2025-09-15 19:33:23,869 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation â†’ JSON Storage â†’ BO â†’ Training Execution â†’ Evaluation
2025-09-15 19:33:23,870 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-09-15 19:33:23,870 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-09-15 19:33:23,870 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-09-15 19:33:23,871 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-09-15 19:33:24,530 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-09-15 19:33:24,531 - INFO - class_balancing - Class imbalance analysis:
2025-09-15 19:33:24,531 - INFO - class_balancing -   Strategy: severe_imbalance
2025-09-15 19:33:24,531 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-09-15 19:33:24,531 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-09-15 19:33:24,531 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-09-15 19:33:24,532 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-09-15 19:33:24,532 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-09-15 19:33:24,533 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-09-15 19:33:24,533 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-09-15 19:33:25,860 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-09-15 19:33:25,862 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-09-15 19:33:25,865 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-15 19:33:25,865 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE ATTEMPT 1/4
2025-09-15 19:33:25,865 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-15 19:33:25,866 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ¤– STEP 1: AI Training Code Generation
2025-09-15 19:33:25,866 - INFO - models.ai_code_generator - Conducting literature review before code generation...
2025-09-15 19:33:25,866 - INFO - models.literature_review - Making GPT-5 literature review call with query: ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods
2025-09-15 19:36:20,090 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-15 19:36:20,301 - INFO - models.literature_review - Successfully completed GPT-5 literature review with web search
2025-09-15 19:36:20,302 - INFO - models.literature_review - Literature review completed with confidence: 0.78
2025-09-15 19:36:20,302 - INFO - models.literature_review - Found 5 recommended approaches
2025-09-15 19:36:20,303 - INFO - models.literature_review - Literature review saved to: literature_reviews/literature_review_numpy_array_1757964980.txt
2025-09-15 19:36:20,303 - INFO - models.ai_code_generator - Making API call to gpt-5
2025-09-15 19:36:20,303 - INFO - models.ai_code_generator - Prompt length: 4748 characters
2025-09-15 19:36:20,303 - INFO - models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-15 19:36:20,303 - INFO - models.ai_code_generator - Calling self.client.responses.create...
2025-09-15 19:36:20,303 - INFO - models.ai_code_generator - Model parameter: gpt-5
2025-09-15 19:36:20,303 - INFO - models.ai_code_generator - Input prompt preview: Generate PyTorch training function for 5-class classification.

Data: numpy_array, shape (1000, 2), 62352 samples

Dataset: MIT-BIH Arrhythmia Database
Source: https://physionet.org/content/mitdb/1.0....
2025-09-15 19:38:50,104 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-15 19:38:50,166 - INFO - models.ai_code_generator - API call completed successfully
2025-09-15 19:38:50,166 - INFO - models.ai_code_generator - Response type: <class 'openai.types.responses.response.Response'>
2025-09-15 19:38:50,167 - INFO - models.ai_code_generator - Response attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_request_id', '_setattr_handler', 'background', 'construct', 'conversation', 'copy', 'created_at', 'dict', 'error', 'from_orm', 'id', 'incomplete_details', 'instructions', 'json', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'object', 'output', 'output_text', 'parallel_tool_calls', 'parse_file', 'parse_obj', 'parse_raw', 'previous_response_id', 'prompt', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'schema', 'schema_json', 'service_tier', 'status', 'temperature', 'text', 'to_dict', 'to_json', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'update_forward_refs', 'usage', 'user', 'validate']
2025-09-15 19:38:50,167 - INFO - models.ai_code_generator - Using response.output_text
2025-09-15 19:38:50,167 - INFO - models.ai_code_generator - Extracted result length: 17948 characters
2025-09-15 19:38:50,167 - INFO - models.ai_code_generator - Result preview: {
    "model_name": "TinyECGTrans-1D",
    "training_code": "def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import math\n    import numpy as np\n    import torch\n    imp...
2025-09-15 19:38:50,167 - INFO - models.ai_code_generator - Successfully extracted response content
2025-09-15 19:38:50,168 - ERROR - models.ai_code_generator - Failed to parse code recommendation: Expecting ',' delimiter: line 45 column 24 (char 17821)
2025-09-15 19:38:50,168 - ERROR - models.ai_code_generator - Original response: {
    "model_name": "TinyECGTrans-1D",
    "training_code": "def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import math\n    import numpy as np\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n    from collections import defaultdict\n    import random\n\n    # -----------------------\n    # Defaults and hyperparams\n    # -----------------------\n    hp = {\n        'num_classes': 5,\n        'epochs': 20,\n        'batch_size': 64,\n        'lr': 1e-3,\n        'weight_decay': 1e-4,\n        'dropout': 0.1,\n        'hidden_size': 64,           # Transformer d_model\n        'nhead': 4,\n        'num_layers': 2,\n        'dim_feedforward': 128,\n        'warmup_epochs': 2,\n        'use_weighted_sampler': True,\n        'label_smoothing': 0.05,\n        'focal_gamma': 0.0,          # 0 disables focal loss\n        'grad_clip': 1.0,\n        'patience': 8,\n        'mixup_alpha': 0.0,          # 0 disables mixup\n        'seed': 42,\n    }\n    hp.update(hyperparams or {})\n\n    # -----------------------\n    # Reproducibility\n    # -----------------------\n    def set_all_seeds(seed: int):\n        random.seed(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    set_all_seeds(hp['seed'])\n\n    # -----------------------\n    # Data utilities\n    # -----------------------\n    def ensure_cl_shape(x):\n        # Ensure input is (N, C, L) from (N, 1000, 2) or (N, 2, 1000)\n        x = np.asarray(x)\n        if x.ndim != 3:\n            raise ValueError('Expected X to be 3D: (N, L, C) or (N, C, L)')\n        if x.shape[-1] == 2 and x.shape[1] != 2:  # (N, L, 2)\n            x = np.transpose(x, (0, 2, 1))\n        elif x.shape[1] == 2:  # already (N, 2, L)\n            pass\n        else:\n            raise ValueError('Expected 2 channels; got shape %s' % (x.shape,))\n        return x.astype(np.float32)\n\n    X_train = ensure_cl_shape(X_train)\n    X_val = ensure_cl_shape(X_val)\n    y_train = np.asarray(y_train).astype(np.int64)\n    y_val = np.asarray(y_val).astype(np.int64)\n\n    num_classes = hp['num_classes']\n    if num_classes != len(np.unique(y_train)) and num_classes < (np.max(y_train) + 1):\n        num_classes = int(np.max(y_train) + 1)\n\n    # Per-channel standardization (fit on train only)\n    def compute_mean_std(x):\n        # x: (N, C, L)\n        mean = x.mean(axis=(0, 2), keepdims=True)\n        std = x.std(axis=(0, 2), keepdims=True) + 1e-6\n        return mean, std\n\n    mean, std = compute_mean_std(X_train)\n\n    class ECGDataset(Dataset):\n        def __init__(self, X, y, mean, std):\n            self.X = (X - mean) / std\n            self.y = y\n        def __len__(self):\n            return self.X.shape[0]\n        def __getitem__(self, idx):\n            x = torch.from_numpy(self.X[idx])  # (C, L)\n            y = torch.tensor(int(self.y[idx]), dtype=torch.long)\n            return x, y\n\n    # Class weights for imbalanced 5-class setup\n    counts = np.bincount(y_train, minlength=num_classes).astype(np.float32)\n    counts[counts == 0] = 1.0\n    class_weights = (counts.sum() / (num_classes * counts))\n    class_weights_t = torch.tensor(class_weights, dtype=torch.float32, device=device)\n\n    # Sampler weights per sample (optional)\n    sample_weights = class_weights[y_train]\n    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True) if hp['use_weighted_sampler'] else None\n\n    train_ds = ECGDataset(X_train, y_train, mean, std)\n    val_ds = ECGDataset(X_val, y_val, mean, std)\n\n    train_loader = DataLoader(train_ds, batch_size=hp['batch_size'], shuffle=(sampler is None), sampler=sampler, num_workers=0, pin_memory=('cuda' in str(device)))\n    val_loader = DataLoader(val_ds, batch_size=hp['batch_size'], shuffle=False, num_workers=0, pin_memory=('cuda' in str(device)))\n\n    # -----------------------\n    # Model: Multi-scale 1D CNN + Tiny Transformer\n    # -----------------------\n    class PositionalEncoding(nn.Module):\n        def __init__(self, d_model, max_len=2000):\n            super().__init__()\n            pe = torch.zeros(max_len, d_model)\n            position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n            div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n            pe[:, 0::2] = torch.sin(position * div_term)\n            pe[:, 1::2] = torch.cos(position * div_term)\n            self.register_buffer('pe', pe.unsqueeze(0))  # (1, L, D)\n        def forward(self, x):  # x: (B, L, D)\n            L = x.size(1)\n            return x + self.pe[:, :L, :]\n\n    class DepthwiseSeparableConv1d(nn.Module):\n        def __init__(self, in_ch, out_ch, k=7, s=2, p=None, dropout=0.1):\n            super().__init__()\n            if p is None:\n                p = (k // 2)\n            self.depth = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=s, padding=p, groups=in_ch, bias=False)\n            self.point = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.act = nn.SiLU()\n            self.do = nn.Dropout(dropout)\n        def forward(self, x):  # (B, C, L)\n            x = self.depth(x)\n            x = self.point(x)\n            x = self.bn(x)\n            x = self.act(x)\n            x = self.do(x)\n            return x\n\n    class TinyECGTrans(nn.Module):\n        def __init__(self, in_ch=2, num_classes=5, d_model=64, nhead=4, num_layers=2, dim_ff=128, dropout=0.1):\n            super().__init__()\n            # Multi-scale conv stem\n            b1 = nn.Conv1d(in_ch, 32, kernel_size=5, padding=2, bias=False)\n            b2 = nn.Conv1d(in_ch, 32, kernel_size=9, padding=4, bias=False)\n            b3 = nn.Conv1d(in_ch, 32, kernel_size=15, padding=7, bias=False)\n            self.branches = nn.ModuleList([b1, b2, b3])\n            self.bn0 = nn.BatchNorm1d(96)\n            self.act0 = nn.SiLU()\n            self.conv1x1 = nn.Conv1d(96, d_model, kernel_size=1, bias=False)\n            self.bn1 = nn.BatchNorm1d(d_model)\n            self.act1 = nn.SiLU()\n            self.do1 = nn.Dropout(dropout)\n\n            # Downsample to reduce sequence length (1000 -> 500 -> 250)\n            self.ds1 = DepthwiseSeparableConv1d(d_model, d_model, k=7, s=2, dropout=dropout)\n            self.ds2 = DepthwiseSeparableConv1d(d_model, d_model, k=7, s=2, dropout=dropout)\n\n            # Transformer encoder (batch_first for convenience)\n            enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_ff, dropout=dropout, activation='gelu', batch_first=True, norm_first=True)\n            self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n            self.posenc = PositionalEncoding(d_model)\n\n            # Head: pooled sequence -> logits\n            self.head = nn.Sequential(\n                nn.LayerNorm(d_model),\n                nn.Linear(d_model, num_classes)\n            )\n\n        def forward(self, x):  # x: (B, C, L=1000)\n            bs = x.size(0)\n            feats = []\n            for b in self.branches:\n                feats.append(b(x))\n            x = torch.cat(feats, dim=1)  # (B, 96, L)\n            x = self.act0(self.bn0(x))\n            x = self.do1(self.act1(self.bn1(self.conv1x1(x))))  # (B, d_model, L)\n            x = self.ds1(x)  # (B, d_model, 500)\n            x = self.ds2(x)  # (B, d_model, 250)\n            x = x.transpose(1, 2)  # (B, 250, d_model)\n            x = self.posenc(x)\n            x = self.encoder(x)  # (B, 250, d_model)\n            # Pooling: mean + max\n            x_mean = x.mean(dim=1)\n            x_max, _ = x.max(dim=1)\n            x = 0.5 * (x_mean + x_max)\n            logits = self.head(x)\n            return logits\n\n    model = TinyECGTrans(\n        in_ch=2,\n        num_classes=num_classes,\n        d_model=hp['hidden_size'],\n        nhead=hp['nhead'],\n        num_layers=hp['num_layers'],\n        dim_ff=hp['dim_feedforward'],\n        dropout=hp['dropout']\n    ).to(device)\n\n    # Parameter budget check\n    n_params = sum(p.numel() for p in model.parameters())\n    if n_params >= 256_000:\n        raise RuntimeError(f'Model has {n_params} parameters; exceeds <256K constraint. Reduce hidden_size or layers.')\n\n    # -----------------------\n    # Losses\n    # -----------------------\n    class FocalLoss(nn.Module):\n        def __init__(self, gamma=2.0, weight=None, reduction='mean'):\n            super().__init__()\n            self.gamma = gamma\n            self.weight = weight\n            self.reduction = reduction\n        def forward(self, logits, target):\n            logpt = F.log_softmax(logits, dim=-1)\n            pt = torch.exp(logpt)\n            # Gather logpt for targets\n            logpt = logpt.gather(1, target.unsqueeze(1)).squeeze(1)\n            pt = pt.gather(1, target.unsqueeze(1)).squeeze(1)\n            loss = -(1 - pt) ** self.gamma * logpt\n            if self.weight is not None:\n                w = self.weight[target]\n                loss = loss * w\n            if self.reduction == 'mean':\n                return loss.mean()\n            elif self.reduction == 'sum':\n                return loss.sum()\n            else:\n                return loss\n\n    if hp['focal_gamma'] and hp['focal_gamma'] > 0.0:\n        criterion = FocalLoss(gamma=hp['focal_gamma'], weight=class_weights_t)\n    else:\n        criterion = nn.CrossEntropyLoss(weight=class_weights_t, label_smoothing=hp['label_smoothing'])\n\n    # -----------------------\n    # Optimizer and scheduler (warmup + cosine)\n    # -----------------------\n    optimizer = torch.optim.AdamW(model.parameters(), lr=hp['lr'], weight_decay=hp['weight_decay'])\n\n    def lr_lambda(epoch):\n        e = epoch\n        E = max(1, hp['epochs'])\n        W = max(0, min(hp['warmup_epochs'], E-1))\n        if e < W and W > 0:\n            return float(e + 1) / float(W)\n        # Cosine from 1 -> 0 over remaining epochs\n        denom = max(1, E - W)\n        progress = float(e - W + 1) / float(denom)\n        return 0.5 * (1.0 + math.cos(math.pi * min(1.0, progress)))\n\n    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n    use_amp = ('cuda' in str(device))\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    # -----------------------\n    # Metrics helpers\n    # -----------------------\n    def update_confmat(cm, preds, targets, num_classes):\n        with torch.no_grad():\n            for t, p in zip(targets.view(-1), preds.view(-1)):\n                if 0 <= t < num_classes and 0 <= p < num_classes:\n                    cm[t.long(), p.long()] += 1\n        return cm\n\n    def f1_from_confmat(cm):\n        cm = cm.astype(np.float64)\n        per_class_f1 = []\n        for c in range(cm.shape[0]):\n            tp = cm[c, c]\n            fp = cm[:, c].sum() - tp\n            fn = cm[c, :].sum() - tp\n            denom = (2 * tp + fp + fn)\n            f1 = 0.0 if denom == 0 else (2 * tp) / denom\n            per_class_f1.append(f1)\n        macro_f1 = float(np.mean(per_class_f1)) if len(per_class_f1) > 0 else 0.0\n        return macro_f1, per_class_f1\n\n    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_macro_f1': [], 'lr': []}\n\n    best_state = None\n    best_metric = -1.0\n    epochs_no_improve = 0\n\n    # Mixup helper\n    def mixup_batch(x, y, alpha):\n        if alpha <= 0.0:\n            return x, y, None, 1.0\n        lam = np.random.beta(alpha, alpha)\n        batch_size = x.size(0)\n        index = torch.randperm(batch_size, device=x.device)\n        mixed_x = lam * x + (1 - lam) * x[index, :]\n        y_a, y_b = y, y[index]\n        return mixed_x, y_a, y_b, lam\n\n    # -----------------------\n    # Training loop\n    # -----------------------\n    for epoch in range(hp['epochs']):\n        model.train()\n        train_loss = 0.0\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n\n            optimizer.zero_grad(set_to_none=True)\n            xmix, ya, yb2, lam = mixup_batch(xb, yb, hp['mixup_alpha'])\n\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                logits = model(xmix)\n                if yb2 is None:\n                    loss = criterion(logits, ya)\n                else:\n                    loss = lam * criterion(logits, ya) + (1 - lam) * criterion(logits, yb2)\n\n            scaler.scale(loss).backward()\n            if hp['grad_clip'] and hp['grad_clip'] > 0:\n                scaler.unscale_(optimizer)\n                nn.utils.clip_grad_norm_(model.parameters(), hp['grad_clip'])\n            scaler.step(optimizer)\n            scaler.update()\n\n            train_loss += float(loss.item()) * xb.size(0)\n\n        scheduler.step()\n        train_loss /= len(train_ds)\n\n        # Validation\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n        confmat = torch.zeros((num_classes, num_classes), dtype=torch.long)\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb = xb.to(device, non_blocking=True)\n                yb = yb.to(device, non_blocking=True)\n                with torch.cuda.amp.autocast(enabled=use_amp):\n                    logits = model(xb)\n                    loss = criterion(logits, yb)\n                val_loss += float(loss.item()) * xb.size(0)\n                preds = torch.argmax(logits, dim=1)\n                correct += int((preds == yb).sum().item())\n                total += int(yb.size(0))\n                confmat = update_confmat(confmat, preds.cpu(), yb.cpu(), num_classes)\n\n        val_loss /= len(val_ds)\n        val_acc = correct / max(1, total)\n        macro_f1, per_class_f1 = f1_from_confmat(confmat.numpy())\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        history['val_macro_f1'].append(macro_f1)\n        history['lr'].append(optimizer.param_groups[0]['lr'])\n\n        # Early stopping on macro-F1 (better for class imbalance)\n        metric = macro_f1\n        if metric > best_metric:\n            best_metric = metric\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= hp['patience']:\n                break\n\n    # Load best weights\n    if best_state is not None:\n        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n\n    # Final validation with best model\n    model.eval()\n    confmat = torch.zeros((num_classes, num_classes), dtype=torch.long)\n    correct = 0\n    total = 0\n    val_loss = 0.0\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                logits = model(xb)\n                loss = criterion(logits, yb)\n            val_loss += float(loss.item()) * xb.size(0)\n            preds = torch.argmax(logits, dim=1)\n            correct += int((preds == yb).sum().item())\n            total += int(yb.size(0))\n            confmat = update_confmat(confmat, preds.cpu(), yb.cpu(), num_classes)\n\n    val_loss /= len(val_ds)\n    final_acc = correct / max(1, total)\n    final_macro_f1, per_class_f1 = f1_from_confmat(confmat.numpy())\n\n    metrics = {\n        'param_count': int(n_params),\n        'val_loss': float(val_loss),\n        'val_acc': float(final_acc),\n        'val_macro_f1': float(final_macro_f1),\n        'val_per_class_f1': [float(x) for x in per_class_f1],\n        'confusion_matrix': confmat.tolist(),\n        'history': history,\n    }\n\n    return model, metrics\n",
    "hyperparameters": {
        "lr": 0.001,
        "epochs": 20,
        "batch_size": 64,
        "hidden_size": 64,
        "dropout": 0.1
    },
    "reasoning": "Implements a lightweight multi-scale 1D CNN front-end plus a tiny Transformer encoder, reflecting 2024â€“2025 findings that CNNâ€“Transformer hybrids capture local ECG morphology and global rhythm timing efficiently. The model reduces the 1000-sample sequence to ~250 tokens and uses a small d_model (64), 2 layers, and 4 heads to stay under 256K parameters while preserving temporal context. Class-weighted loss and optional focal loss address MIT-BIHâ€™s class imbalance; a weighted sampler and macro-F1 early stopping further stabilize minority-class performance. Cosine schedule with warmup and mixed precision improve training stability and speed.",
    "confidence": 0.9,
    "bo_parameters": [
        "lr",
        "batch_size",
        "epochs",
        "hidden_size",
        "dropout"
    ],
    "bo_search_space": {
        "lr": {
            "type": "Real",
            "low": 1e-05,
            "high": 1e-01,
            "prior": "log-uniform"
        },
        "batch_size": {
            "type": "Categorical",
            "categories": [
                8,
                16,
                32,
                64,
                128
            ]
        },
        "epochs": {
            "type": "Integer",
            "low": 5,
            "high": 50
        },
        "hidden_size": {
            "type": "Integer",
            "low": 32,
            "high": 512"
        },
        "dropout": {
            "type": "Real",
            "low": 0.0,
            "high": 0.7
        }
    }
}
2025-09-15 19:38:50,169 - ERROR - evaluation.code_generation_pipeline_orchestrator - Pipeline attempt 1 failed: Failed to parse AI code recommendation: Expecting ',' delimiter: line 45 column 24 (char 17821)
2025-09-15 19:38:50,169 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-15 19:38:50,169 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE ATTEMPT 2/4
2025-09-15 19:38:50,169 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-15 19:38:50,169 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ¤– STEP 1: AI Training Code Generation
2025-09-15 19:38:50,169 - INFO - models.ai_code_generator - Conducting literature review before code generation...
2025-09-15 19:38:50,169 - INFO - models.literature_review - Making GPT-5 literature review call with query: ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods
