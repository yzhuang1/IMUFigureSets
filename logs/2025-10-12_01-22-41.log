2025-10-12 01:22:41,839 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-12 01:22:41,978 - INFO - __main__ - Logging system initialized successfully
2025-10-12 01:22:41,978 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-10-12 01:22:41,978 - INFO - __main__ - Starting real data processing from data/dataset3/ directory
2025-10-12 01:22:41,979 - INFO - __main__ - Found 4 data files: ['sleep_sample.csv', 'X.npy', 'y.npy', 'sleep_metadata.json']
2025-10-12 01:22:41,979 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-10-12 01:22:41,979 - INFO - __main__ - Attempting to load: X.npy
2025-10-12 01:22:48,074 - INFO - __main__ - Successfully loaded NPY data: X(89283, 6, 6000), y(89283,)
2025-10-12 01:22:52,522 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (89283, 6, 6000), device: cuda
2025-10-12 01:22:52,523 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-10-12 01:22:52,523 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-10-12 01:22:52,523 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-10-12 01:22:52,527 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-12 01:22:52,527 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (89283, 6, 6000), 'dtype': 'float32', 'feature_count': 6000, 'sample_count': 89283, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-10-12 01:22:52,528 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-10-12 01:22:52,528 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-10-12 01:22:52,528 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-10-12 01:22:52,528 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-10-12 01:22:52,528 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-10-12 01:22:52,528 - INFO - data_splitting - Input data shape: X=(89283, 6, 6000), y=(89283,)
2025-10-12 01:22:52,528 - INFO - data_splitting - Class distribution: [20758 11387 28006 17266 11866]
2025-10-12 01:23:03,256 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.8602182913059842), np.int64(1): np.float64(1.5682722656786057), np.int64(2): np.float64(0.6375808971211783), np.int64(3): np.float64(1.03420814479638), np.int64(4): np.float64(1.5048722675796682)}
2025-10-12 01:23:03,270 - INFO - class_balancing - Class imbalance analysis:
2025-10-12 01:23:03,270 - INFO - class_balancing -   Strategy: mild_imbalance
2025-10-12 01:23:03,271 - INFO - class_balancing -   Imbalance ratio: 2.46
2025-10-12 01:23:03,271 - INFO - class_balancing -   Recommendations: Standard training should work, Consider class_weight='balanced'
2025-10-12 01:23:03,271 - INFO - data_splitting - Final splits - Train: 57140, Val: 14286, Test: 17857
2025-10-12 01:23:03,271 - INFO - data_splitting - Train class distribution: [13285  7287 17924 11050  7594]
2025-10-12 01:23:03,271 - INFO - data_splitting - Val class distribution: [3321 1822 4481 2763 1899]
2025-10-12 01:23:03,271 - INFO - data_splitting - Test class distribution: [4152 2278 5601 3453 2373]
2025-10-12 01:23:03,271 - INFO - data_splitting - Recommended balancing strategy: mild_imbalance
2025-10-12 01:23:10,695 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 6000]), std shape: torch.Size([1, 6000])
2025-10-12 01:23:10,705 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-10-12 01:23:10,705 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-10-12 01:23:10,705 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-10-12 01:23:10,705 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-10-12 01:23:10,705 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-10-12 01:23:10,706 - INFO - _models.ai_code_generator - Conducting literature review before code generation...
2025-10-12 01:27:11,872 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-12 01:27:11,910 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-10-12 01:27:11,910 - INFO - _models.ai_code_generator - Prompt length: 4936 characters
2025-10-12 01:27:11,910 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-10-12 01:27:11,910 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-10-12 01:27:11,910 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-10-12 01:29:05,312 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-12 01:29:05,465 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-10-12 01:29:05,465 - INFO - _models.ai_code_generator - AI generated training function: STMiniUSleepNet-Quant
2025-10-12 01:29:05,465 - INFO - _models.ai_code_generator - Confidence: 0.86
2025-10-12 01:29:05,465 - INFO - _models.ai_code_generator - Literature review informed code generation (confidence: 0.72)
2025-10-12 01:29:05,465 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: STMiniUSleepNet-Quant
2025-10-12 01:29:05,465 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'base_channels', 'temporal_kernel', 'spatial_segments', 'label_smoothing', 'grad_clip', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_samples']
2025-10-12 01:29:05,465 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.86
2025-10-12 01:29:05,467 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-10-12 01:29:05,468 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions/training_function_torch_tensor_STMiniUSleepNet-Quant_1760250545.json
2025-10-12 01:29:05,468 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_torch_tensor_STMiniUSleepNet-Quant_1760250545.json
2025-10-12 01:29:05,468 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-10-12 01:29:05,468 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: STMiniUSleepNet-Quant
2025-10-12 01:29:05,468 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-10-12 01:29:05,480 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-10-12 01:29:05,482 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-10-12 01:29:05,483 - INFO - package_installer - Available packages: {'torch'}
2025-10-12 01:29:05,483 - INFO - package_installer - Missing packages: set()
2025-10-12 01:29:05,483 - INFO - package_installer - ‚úÖ All required packages are already available
2025-10-12 01:29:05,483 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-10-12 01:29:05,483 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-12 01:29:05,483 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 57140 samples (using bo_sample_num=100000000000000)
2025-10-12 01:29:05,483 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'base_channels', 'temporal_kernel', 'spatial_segments', 'label_smoothing', 'grad_clip', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_samples']
2025-10-12 01:29:05,484 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-12 01:29:05,484 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-12 01:29:05,484 - INFO - _models.training_function_executor - Using BO subset for optimization: 57140 samples (bo_sample_num=100000000000000)
2025-10-12 01:29:06,069 - INFO - _models.training_function_executor - BO splits - Train: 45712, Val: 11428
2025-10-12 01:29:07,799 - INFO - bo.run_bo - Converted GPT search space: 15 parameters
2025-10-12 01:29:07,799 - INFO - bo.run_bo - Using GPT-generated search space
2025-10-12 01:29:07,801 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-10-12 01:29:07,803 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-10-12 01:29:07,803 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-10-12 01:29:07,803 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:29:07,804 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 01:29:07,804 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 5563}
2025-10-12 01:29:07,805 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 5563}
2025-10-12 01:29:28,102 - INFO - _models.training_function_executor - Epoch 001/12 - train_loss: 1.3148 - val_loss: 2.7426 - val_acc: 0.2322
2025-10-12 01:29:45,078 - INFO - _models.training_function_executor - Epoch 002/12 - train_loss: 1.1707 - val_loss: 1.1439 - val_acc: 0.6143
2025-10-12 01:30:02,057 - INFO - _models.training_function_executor - Epoch 003/12 - train_loss: 1.1100 - val_loss: 1.4480 - val_acc: 0.4899
2025-10-12 01:30:19,017 - INFO - _models.training_function_executor - Epoch 004/12 - train_loss: 1.0576 - val_loss: 1.0451 - val_acc: 0.6859
2025-10-12 01:30:35,988 - INFO - _models.training_function_executor - Epoch 005/12 - train_loss: 1.0129 - val_loss: 1.1212 - val_acc: 0.6527
2025-10-12 01:30:52,991 - INFO - _models.training_function_executor - Epoch 006/12 - train_loss: 1.0112 - val_loss: 0.8484 - val_acc: 0.7415
2025-10-12 01:31:10,025 - INFO - _models.training_function_executor - Epoch 007/12 - train_loss: 0.9999 - val_loss: 1.1752 - val_acc: 0.6847
2025-10-12 01:31:26,999 - INFO - _models.training_function_executor - Epoch 008/12 - train_loss: 0.9577 - val_loss: 1.0662 - val_acc: 0.6439
2025-10-12 01:31:44,005 - INFO - _models.training_function_executor - Epoch 009/12 - train_loss: 0.9764 - val_loss: 1.1600 - val_acc: 0.6058
2025-10-12 01:32:01,064 - INFO - _models.training_function_executor - Epoch 010/12 - train_loss: 0.9627 - val_loss: 0.9652 - val_acc: 0.7244
2025-10-12 01:32:18,123 - INFO - _models.training_function_executor - Epoch 011/12 - train_loss: 0.9602 - val_loss: 0.9095 - val_acc: 0.7383
2025-10-12 01:32:35,204 - INFO - _models.training_function_executor - Epoch 012/12 - train_loss: 0.9578 - val_loss: 1.2190 - val_acc: 0.7258
2025-10-12 01:32:35,209 - INFO - _models.training_function_executor - Model: 50,309 parameters, 216.2KB storage
2025-10-12 01:32:35,209 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3147894241904143, 1.170658552611692, 1.1099720675606473, 1.0576402557962292, 1.0129470589499312, 1.01122993348433, 0.9999169611721177, 0.957700840737651, 0.9763740054352908, 0.9627447605060038, 0.9602432950684396, 0.9578317358469187], 'val_losses': [2.742597902701541, 1.1439307228351416, 1.4480185631817772, 1.0450909195515423, 1.1211546494028641, 0.8483838132932381, 1.1752385160995606, 1.0662298081824109, 1.1600321187166054, 0.9652326172220986, 0.9094552139135187, 1.2190149389950595], 'val_acc': [0.23223661183059152, 0.6142807140357018, 0.4899369968498425, 0.685946797339867, 0.6526951347567378, 0.7415120756037802, 0.6847217360868043, 0.6439446972348617, 0.605792789639482, 0.7244487224361218, 0.738274413720686, 0.7257612880644032], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 5563}, 'model_parameter_count': 50309, 'model_storage_size_kb': 216.171484375, 'model_size_validation': 'PASS'}
2025-10-12 01:32:35,209 - INFO - _models.training_function_executor - BO Objective: base=0.7258, size_penalty=0.0000, final=0.7258
2025-10-12 01:32:35,209 - INFO - _models.training_function_executor - Model: 50,309 parameters, 216.2KB (PASS 256KB limit)
2025-10-12 01:32:35,209 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 207.406s
2025-10-12 01:32:35,211 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7258
2025-10-12 01:32:35,211 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-12 01:32:35,211 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': np.int64(12), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': np.int64(18), 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': np.int64(5563)}, value=0.7258
2025-10-12 01:32:35,211 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': np.int64(12), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': np.int64(18), 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': np.int64(5563)} -> 0.7258
2025-10-12 01:32:35,211 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-10-12 01:32:35,211 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 01:32:35,211 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:32:35,211 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 01:32:35,211 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4068}
2025-10-12 01:32:35,212 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4068}
2025-10-12 01:32:50,031 - INFO - _models.training_function_executor - Epoch 001/26 - train_loss: 1.6429 - val_loss: 1.5677 - val_acc: 0.3078
2025-10-12 01:33:04,620 - INFO - _models.training_function_executor - Epoch 002/26 - train_loss: 1.5069 - val_loss: 1.5065 - val_acc: 0.3648
2025-10-12 01:33:19,201 - INFO - _models.training_function_executor - Epoch 003/26 - train_loss: 1.4281 - val_loss: 1.4393 - val_acc: 0.4189
2025-10-12 01:33:33,804 - INFO - _models.training_function_executor - Epoch 004/26 - train_loss: 1.3599 - val_loss: 1.3730 - val_acc: 0.4708
2025-10-12 01:33:48,398 - INFO - _models.training_function_executor - Epoch 005/26 - train_loss: 1.3029 - val_loss: 1.3916 - val_acc: 0.4468
2025-10-12 01:34:02,965 - INFO - _models.training_function_executor - Epoch 006/26 - train_loss: 1.2521 - val_loss: 1.3071 - val_acc: 0.5078
2025-10-12 01:34:17,572 - INFO - _models.training_function_executor - Epoch 007/26 - train_loss: 1.2097 - val_loss: 1.3573 - val_acc: 0.4846
2025-10-12 01:34:32,185 - INFO - _models.training_function_executor - Epoch 008/26 - train_loss: 1.1727 - val_loss: 1.2328 - val_acc: 0.5647
2025-10-12 01:34:46,790 - INFO - _models.training_function_executor - Epoch 009/26 - train_loss: 1.1421 - val_loss: 1.2173 - val_acc: 0.5473
2025-10-12 01:35:01,381 - INFO - _models.training_function_executor - Epoch 010/26 - train_loss: 1.1138 - val_loss: 1.2036 - val_acc: 0.5664
2025-10-12 01:35:15,962 - INFO - _models.training_function_executor - Epoch 011/26 - train_loss: 1.0864 - val_loss: 1.2254 - val_acc: 0.5509
2025-10-12 01:35:30,524 - INFO - _models.training_function_executor - Epoch 012/26 - train_loss: 1.0671 - val_loss: 1.1955 - val_acc: 0.5594
2025-10-12 01:35:45,137 - INFO - _models.training_function_executor - Epoch 013/26 - train_loss: 1.0457 - val_loss: 1.1566 - val_acc: 0.5835
2025-10-12 01:35:59,758 - INFO - _models.training_function_executor - Epoch 014/26 - train_loss: 1.0305 - val_loss: 1.0906 - val_acc: 0.6084
2025-10-12 01:36:14,330 - INFO - _models.training_function_executor - Epoch 015/26 - train_loss: 1.0149 - val_loss: 1.1306 - val_acc: 0.5803
2025-10-12 01:36:28,958 - INFO - _models.training_function_executor - Epoch 016/26 - train_loss: 1.0033 - val_loss: 1.0466 - val_acc: 0.6254
2025-10-12 01:36:43,558 - INFO - _models.training_function_executor - Epoch 017/26 - train_loss: 0.9898 - val_loss: 1.0693 - val_acc: 0.6087
2025-10-12 01:36:58,150 - INFO - _models.training_function_executor - Epoch 018/26 - train_loss: 0.9781 - val_loss: 1.0483 - val_acc: 0.6183
2025-10-12 01:37:12,747 - INFO - _models.training_function_executor - Epoch 019/26 - train_loss: 0.9690 - val_loss: 1.1487 - val_acc: 0.5685
2025-10-12 01:37:27,324 - INFO - _models.training_function_executor - Epoch 020/26 - train_loss: 0.9595 - val_loss: 1.1233 - val_acc: 0.5788
2025-10-12 01:37:41,944 - INFO - _models.training_function_executor - Epoch 021/26 - train_loss: 0.9506 - val_loss: 1.2533 - val_acc: 0.5232
2025-10-12 01:37:56,497 - INFO - _models.training_function_executor - Epoch 022/26 - train_loss: 0.9447 - val_loss: 1.0309 - val_acc: 0.6279
2025-10-12 01:38:11,077 - INFO - _models.training_function_executor - Epoch 023/26 - train_loss: 0.9347 - val_loss: 1.1508 - val_acc: 0.5750
2025-10-12 01:38:25,690 - INFO - _models.training_function_executor - Epoch 024/26 - train_loss: 0.9249 - val_loss: 1.0175 - val_acc: 0.6390
2025-10-12 01:38:40,287 - INFO - _models.training_function_executor - Epoch 025/26 - train_loss: 0.9212 - val_loss: 1.0183 - val_acc: 0.6400
2025-10-12 01:38:54,900 - INFO - _models.training_function_executor - Epoch 026/26 - train_loss: 0.9160 - val_loss: 1.0280 - val_acc: 0.6375
2025-10-12 01:38:54,903 - INFO - _models.training_function_executor - Model: 137,361 parameters, 590.2KB storage
2025-10-12 01:38:54,903 - WARNING - _models.training_function_executor - Model storage 590.2KB exceeds 256KB limit!
2025-10-12 01:38:54,903 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6428515928209684, 1.5068713674438472, 1.428053319516781, 1.3598842250537237, 1.3028849069789277, 1.2521031242715424, 1.2096813867298255, 1.1727130272858286, 1.1421052270474699, 1.1138075858636214, 1.086440359811746, 1.0670556684536745, 1.0456616083850467, 1.0305151616020722, 1.0148749932944043, 1.0033159296246397, 0.9898014706375301, 0.9781162734627515, 0.9690047919145196, 0.9595318130984521, 0.9506434520767166, 0.9447433684395459, 0.9346778942105818, 0.9248667124229835, 0.9211785097534438, 0.9159927047087589], 'val_losses': [1.5677326244201366, 1.5065496320235465, 1.4392802290537576, 1.3730067210386048, 1.391610455838458, 1.307138704047739, 1.3573499906926794, 1.2328183847705425, 1.2172935349690066, 1.2035769890520511, 1.2253689432544728, 1.1955435522210986, 1.1565653618958434, 1.0905556789344117, 1.1306041289886313, 1.0466427819103805, 1.0693409425585596, 1.048286996502788, 1.1486641846005217, 1.1233011226492158, 1.2532684537218632, 1.0308864090590366, 1.1508245202349248, 1.0175032774217905, 1.0183363240375192, 1.0280305621588108], 'val_acc': [0.30775288764438224, 0.36480574028701435, 0.41888344417220863, 0.47077353867693383, 0.4467973398669933, 0.5077878893944697, 0.48459922996149807, 0.5646657332866644, 0.5472523626181309, 0.5664158207910396, 0.5509275463773189, 0.5594154707735387, 0.583479173958698, 0.6084179208960449, 0.5803290164508226, 0.6253937696884844, 0.6086804340217011, 0.6183059152957648, 0.5685159257962898, 0.5787539376968849, 0.5231886594329717, 0.6279313965698284, 0.5749912495624782, 0.6390444522226111, 0.6400070003500175, 0.6374693734686734], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4068}, 'model_parameter_count': 137361, 'model_storage_size_kb': 590.223046875, 'model_size_validation': 'FAIL'}
2025-10-12 01:38:54,903 - INFO - _models.training_function_executor - BO Objective: base=0.6375, size_penalty=0.6528, final=-0.0153
2025-10-12 01:38:54,903 - INFO - _models.training_function_executor - Model: 137,361 parameters, 590.2KB (FAIL 256KB limit)
2025-10-12 01:38:54,903 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 379.692s
2025-10-12 01:38:54,906 - INFO - bo.run_bo - Updated RF surrogate model with observation: -0.0153
2025-10-12 01:38:54,906 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-12 01:38:54,906 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': np.int64(26), 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': np.int64(17), 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': np.int64(4068)}, value=-0.0153
2025-10-12 01:38:54,906 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': np.int64(26), 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': np.int64(17), 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': np.int64(4068)} -> -0.0153
2025-10-12 01:38:54,907 - INFO - bo.run_bo - üîçBO Trial 3: Initial random exploration
2025-10-12 01:38:54,907 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 01:38:54,907 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:38:54,907 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 01:38:54,907 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0010907475835157708, 'batch_size': 8, 'epochs': 43, 'weight_decay': 1.1299516083106616e-06, 'dropout': 0.4711008778424265, 'base_channels': 21, 'temporal_kernel': 9, 'spatial_segments': 30, 'label_smoothing': 0.019534422801276777, 'grad_clip': 0.684233026512157, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6861}
2025-10-12 01:38:54,908 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0010907475835157708, 'batch_size': 8, 'epochs': 43, 'weight_decay': 1.1299516083106616e-06, 'dropout': 0.4711008778424265, 'base_channels': 21, 'temporal_kernel': 9, 'spatial_segments': 30, 'label_smoothing': 0.019534422801276777, 'grad_clip': 0.684233026512157, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6861}
2025-10-12 01:39:13,128 - INFO - _models.training_function_executor - Epoch 001/43 - train_loss: 1.1997 - val_loss: 0.9421 - val_acc: 0.6502
2025-10-12 01:39:31,298 - INFO - _models.training_function_executor - Epoch 002/43 - train_loss: 1.0599 - val_loss: 0.8543 - val_acc: 0.6985
2025-10-12 01:39:49,336 - INFO - _models.training_function_executor - Epoch 003/43 - train_loss: 0.9845 - val_loss: 0.8477 - val_acc: 0.6952
2025-10-12 01:40:07,458 - INFO - _models.training_function_executor - Epoch 004/43 - train_loss: 0.9435 - val_loss: 0.7967 - val_acc: 0.7207
2025-10-12 01:40:25,583 - INFO - _models.training_function_executor - Epoch 005/43 - train_loss: 0.9128 - val_loss: 0.7554 - val_acc: 0.7411
2025-10-12 01:40:43,637 - INFO - _models.training_function_executor - Epoch 006/43 - train_loss: 0.8868 - val_loss: 0.7396 - val_acc: 0.7373
2025-10-12 01:41:01,742 - INFO - _models.training_function_executor - Epoch 007/43 - train_loss: 0.8731 - val_loss: 0.7112 - val_acc: 0.7561
2025-10-12 01:41:19,906 - INFO - _models.training_function_executor - Epoch 008/43 - train_loss: 0.8609 - val_loss: 0.7104 - val_acc: 0.7553
2025-10-12 01:41:38,094 - INFO - _models.training_function_executor - Epoch 009/43 - train_loss: 0.8485 - val_loss: 0.6922 - val_acc: 0.7605
2025-10-12 01:41:56,255 - INFO - _models.training_function_executor - Epoch 010/43 - train_loss: 0.8433 - val_loss: 0.7027 - val_acc: 0.7669
2025-10-12 01:42:14,282 - INFO - _models.training_function_executor - Epoch 011/43 - train_loss: 0.8327 - val_loss: 0.7368 - val_acc: 0.7591
2025-10-12 01:42:32,508 - INFO - _models.training_function_executor - Epoch 012/43 - train_loss: 0.8242 - val_loss: 0.6967 - val_acc: 0.7609
2025-10-12 01:42:50,653 - INFO - _models.training_function_executor - Epoch 013/43 - train_loss: 0.8202 - val_loss: 0.7196 - val_acc: 0.7608
2025-10-12 01:43:08,795 - INFO - _models.training_function_executor - Epoch 014/43 - train_loss: 0.8166 - val_loss: 0.6860 - val_acc: 0.7684
2025-10-12 01:43:26,935 - INFO - _models.training_function_executor - Epoch 015/43 - train_loss: 0.8057 - val_loss: 0.6832 - val_acc: 0.7743
2025-10-12 01:43:45,084 - INFO - _models.training_function_executor - Epoch 016/43 - train_loss: 0.8088 - val_loss: 0.6724 - val_acc: 0.7777
2025-10-12 01:44:03,255 - INFO - _models.training_function_executor - Epoch 017/43 - train_loss: 0.8058 - val_loss: 0.8088 - val_acc: 0.7753
2025-10-12 01:44:21,424 - INFO - _models.training_function_executor - Epoch 018/43 - train_loss: 0.8013 - val_loss: 0.7292 - val_acc: 0.7592
2025-10-12 01:44:39,521 - INFO - _models.training_function_executor - Epoch 019/43 - train_loss: 0.7911 - val_loss: 0.6693 - val_acc: 0.7787
2025-10-12 01:44:57,663 - INFO - _models.training_function_executor - Epoch 020/43 - train_loss: 0.7890 - val_loss: 0.7115 - val_acc: 0.7567
2025-10-12 01:45:15,824 - INFO - _models.training_function_executor - Epoch 021/43 - train_loss: 0.7855 - val_loss: 0.7528 - val_acc: 0.7347
2025-10-12 01:45:33,999 - INFO - _models.training_function_executor - Epoch 022/43 - train_loss: 0.7815 - val_loss: 0.7037 - val_acc: 0.7675
2025-10-12 01:45:52,183 - INFO - _models.training_function_executor - Epoch 023/43 - train_loss: 0.7757 - val_loss: 0.6996 - val_acc: 0.7694
2025-10-12 01:46:10,317 - INFO - _models.training_function_executor - Epoch 024/43 - train_loss: 0.7801 - val_loss: 0.7096 - val_acc: 0.7807
2025-10-12 01:46:28,526 - INFO - _models.training_function_executor - Epoch 025/43 - train_loss: 0.7823 - val_loss: 0.6714 - val_acc: 0.7802
2025-10-12 01:46:46,701 - INFO - _models.training_function_executor - Epoch 026/43 - train_loss: 0.7741 - val_loss: 0.6887 - val_acc: 0.7812
2025-10-12 01:47:04,837 - INFO - _models.training_function_executor - Epoch 027/43 - train_loss: 0.7721 - val_loss: 0.6912 - val_acc: 0.7847
2025-10-12 01:47:22,997 - INFO - _models.training_function_executor - Epoch 028/43 - train_loss: 0.7663 - val_loss: 0.6797 - val_acc: 0.7842
2025-10-12 01:47:41,145 - INFO - _models.training_function_executor - Epoch 029/43 - train_loss: 0.7690 - val_loss: 0.7530 - val_acc: 0.7421
2025-10-12 01:47:59,238 - INFO - _models.training_function_executor - Epoch 030/43 - train_loss: 0.7653 - val_loss: 0.6694 - val_acc: 0.7832
2025-10-12 01:48:17,367 - INFO - _models.training_function_executor - Epoch 031/43 - train_loss: 0.7623 - val_loss: 0.6957 - val_acc: 0.7678
2025-10-12 01:48:35,472 - INFO - _models.training_function_executor - Epoch 032/43 - train_loss: 0.7629 - val_loss: 0.7438 - val_acc: 0.7829
2025-10-12 01:48:53,581 - INFO - _models.training_function_executor - Epoch 033/43 - train_loss: 0.7577 - val_loss: 0.7157 - val_acc: 0.7681
2025-10-12 01:49:11,672 - INFO - _models.training_function_executor - Epoch 034/43 - train_loss: 0.7585 - val_loss: 0.7285 - val_acc: 0.7609
2025-10-12 01:49:29,827 - INFO - _models.training_function_executor - Epoch 035/43 - train_loss: 0.7536 - val_loss: 0.6815 - val_acc: 0.7793
2025-10-12 01:49:48,019 - INFO - _models.training_function_executor - Epoch 036/43 - train_loss: 0.7500 - val_loss: 0.6879 - val_acc: 0.7890
2025-10-12 01:50:06,123 - INFO - _models.training_function_executor - Epoch 037/43 - train_loss: 0.7486 - val_loss: 0.6692 - val_acc: 0.7872
2025-10-12 01:50:24,262 - INFO - _models.training_function_executor - Epoch 038/43 - train_loss: 0.7482 - val_loss: 0.6666 - val_acc: 0.7880
2025-10-12 01:50:42,368 - INFO - _models.training_function_executor - Epoch 039/43 - train_loss: 0.7466 - val_loss: 0.7243 - val_acc: 0.7856
2025-10-12 01:51:00,575 - INFO - _models.training_function_executor - Epoch 040/43 - train_loss: 0.7441 - val_loss: 0.7780 - val_acc: 0.7827
2025-10-12 01:51:18,725 - INFO - _models.training_function_executor - Epoch 041/43 - train_loss: 0.7447 - val_loss: 0.6931 - val_acc: 0.7839
2025-10-12 01:51:36,937 - INFO - _models.training_function_executor - Epoch 042/43 - train_loss: 0.7391 - val_loss: 0.6513 - val_acc: 0.7918
2025-10-12 01:51:55,057 - INFO - _models.training_function_executor - Epoch 043/43 - train_loss: 0.7378 - val_loss: 0.6886 - val_acc: 0.7822
2025-10-12 01:51:55,064 - ERROR - _models.training_function_executor - Training execution failed: Per channel weight observer is not supported yet for ConvTranspose{n}d.
2025-10-12 01:51:55,064 - INFO - _models.ai_code_generator - Starting debug attempts (max: 4)
2025-10-12 01:51:55,064 - INFO - _models.ai_code_generator - Calling GPT to debug training error (attempt 1/4)
2025-10-12 01:51:55,064 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-10-12 01:51:55,065 - INFO - _models.ai_code_generator - Prompt length: 13856 characters
2025-10-12 01:51:55,065 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-10-12 01:51:55,065 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-10-12 01:51:55,065 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-10-12 01:53:45,566 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-12 01:53:45,569 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-10-12 01:53:45,570 - INFO - _models.ai_code_generator - Saved GPT debug response to: gpt_debug_responses/gpt_debug_training_error_20251012_015345_attempt1.txt
2025-10-12 01:53:45,570 - INFO - _models.ai_code_generator - GPT suggested correction: {"training_code":"def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import math\n    import copy\n    import torch\n    from torch import nn, optim\n    from torch.utils.data import TensorDataset, DataLoader\n    import torch.ao.quantization as tq\n\n    # Robust device handling\n    device = torch.device(device)\n    torch.backends.cudnn.benchmark = True\n\n    # ------------ Hyperparameters ------------\n    lr = float(hyperparams.get('lr', 1e-3))\n    batch_size = int(hyperparams.get('batch_size', 32))\n    epochs = int(hyperparams.get('epochs', 15))\n    weight_decay = float(hyperparams.get('weight_decay', 1e-4))\n    dropout = float(hyperparams.get('dropout', 0.1))\n    base_channels = int(hyperparams.get('base_channels', 12))\n    temporal_kernel = int(hyperparams.get('temporal_kernel', 7))\n    spatial_segments = int(hyperparams.get('spatial_segments', 10))  # must divide 6000\n    label_smoothing = float(hyperparams.get('label_smoothing', 0.0))\n    grad_clip = float(hyperparams.get('grad_clip', 0.0))\n    num_workers = int(hyperparams.get('num_workers', 4))\n\n    # Quantization params\n    quantization_bits = int(hyperparams.get('quantization_bits', 8))  # {8,16,32}\n    quantize_weights = bool(hyperparams.get('quantize_weights', True))\n    quantize_activations = bool(hyperparams.get('quantize_activations', True))\n    calibration_samples = int(hyperparams.get('calibration_samples', 2048))\n\n    # ------------ Sanity checks ------------\n    if X_train.dim() != 3:\n        raise ValueError(f\"X_train must be a 3D tensor of shape (N, 6, 6000). Got {tuple(X_train.shape)}\")\n    if X_train.shape[1] != 6 or X_train.shape[2] != 6000:\n        raise ValueError(f\"Expected input per-sample shape (6, 6000). Got {tuple(X_train.shape[1:])}\")\n    if spatial_segments <= 0 or (6000 % spatial_segments) != 0:\n        raise ValueError(\"spatial_segments must be a positive divisor of 6000\")\n    if temporal_kernel % 2 == 0:\n        temporal_kernel += 1  # ensure odd for same padding\n\n    # ------------ DataLoaders (spawn ctx + pin_memory) ------------\n    train_ds = TensorDataset(X_train, y_train)\n    val_ds = TensorDataset(X_val, y_val)\n    mp_ctx = torch.multiprocessing.get_context('spawn')\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n        multiprocessing_context=mp_ctx,\n        drop_last=False,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        multiprocessing_context=mp_ctx,\n        drop_last=False,\n    )\n\n    # ------------ Model Definition (ST-mini U-SleepNet) ------------\n    class TemporalBlock(nn.Module):\n        def __init__(self, in_ch, out_ch, ksize, stride=1):\n            super().__init__()\n            pad = ksize // 2\n            self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=ksize, stride=stride, padding=pad, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.relu = nn.ReLU(inplace=True)\n        def forward(self, x):\n            return self.relu(self.bn(self.conv(x)))\n\n    class UpBlock(nn.Module):\n        def __init__(self, in_ch, out_ch):\n            super().__init__()\n            self.deconv = nn.ConvTranspose1d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.relu = nn.ReLU(inplace=True)\n        def forward(self, x):\n            return self.relu(self.bn(self.deconv(x)))\n\n    class STMiniUSleepNet(nn.Module):\n        def __init__(self, in_channels=6, num_classes=5, base_channels=12, k=7, dropout=0.1, spatial_segments=10):\n            super().__init__()\n            C = base_channels\n            self.enc1 = TemporalBlock(in_channels, C, k)\n            self.down1 = TemporalBlock(C, 2*C, 5, stride=2)\n            self.down2 = TemporalBlock(2*C, 4*C, 5, stride=2)\n            self.bottleneck = TemporalBlock(4*C, 4*C, 3, stride=1)\n            self.up1 = UpBlock(4*C, 2*C)\n            self.up2 = UpBlock(2*C, C)\n            self.gap = nn.AdaptiveAvgPool1d(1)\n            self.temp_mlp = nn.Sequential(\n                nn.Linear(C, 16), nn.ReLU(inplace=True), nn.Dropout(dropout), nn.Linear(16, 8)\n            )\n            self.spatial_segments = spatial_segments\n            self.adjacency = nn.Parameter(torch.eye(6))  # learnable channel graph (6x6)\n            self.spat_mlp = nn.Sequential(\n                nn.Linear(6*spatial_segments, 16), nn.ReLU(inplace=True), nn.Dropout(dropout), nn.Linear(16, 8)\n            )\n            self.head = nn.Linear(16, num_classes)\n        def forward(self, x):\n            # Temporal U-Net branch\n            t = self.enc1(x)\n            t = self.down1(t)\n            t = self.down2(t)\n            t = self.bottleneck(t)\n            t = self.up1(t)\n            t = self.up2(t)\n            t = self.gap(t).squeeze(-1)  # (B, C)\n            tfeat = self.temp_mlp(t)     # (B, 8)\n            # Spatial graph branch over channel-time segments\n            B, C_in, T = x.shape  # C_in should be 6\n            K = self.spatial_segments\n            seg_len = T // K\n            xt = x[:, :, :seg_len*K]\n            xs = xt.view(B, C_in, K, seg_len).mean(-1)  # (B, 6, K)\n            A = torch.softmax(self.adjacency, dim=1)    # (6,6)\n            msg = torch.einsum('ij,bjk->bik', A, xs)    # (B, 6, K)\n            sfeat = self.spat_mlp(msg.reshape(B, -1))   # (B, 8)\n            fused = torch.cat([tfeat, sfeat], dim=1)     # (B, 16)\n            logits = self.head(fused)\n            return logits\n        def fuse_model(self):\n            # fuse Conv-BN-ReLU where applicable\n            try:\n                tq.fuse_modules(self, [['enc1.conv', 'enc1.bn', 'enc1.relu']], inplace=True)\n                tq.fuse_modules(self, [['down1.conv', 'down1.bn', 'down1.relu']], inplace=True)\n                tq.fuse_modules(self, [['down2.conv', 'down2.bn', 'down2.relu']], inplace=True)\n                tq.fuse_modules(self, [['bottleneck.conv', 'bottleneck.bn', 'bottleneck.relu']], inplace=True)\n            except Exception:\n                pass\n            # UpBlocks use ConvTranspose1d which is not fuse-supported; skip\n\n    model = STMiniUSleepNet(in_channels=6, num_classes=5, base_channels=base_channels, k=temporal_kernel, dropout=dropout, spatial_segments=spatial_segments)\n    model = model.to(device)\n\n    # ------------ Optimization ------------\n    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing).to(device)\n    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    train_losses, val_losses, val_accs = [], [], []\n\n    # ------------ Training Loop ------------\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        seen = 0\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=True).float()\n            yb = yb.to(device, non_blocking=True).long()\n            optimizer.zero_grad(set_to_none=True)\n            out = model(xb)\n            loss = criterion(out, yb)\n            loss.backward()\n            if grad_clip and grad_clip > 0.0:\n                nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n            optimizer.step()\n            bs = xb.size(0)\n            running_loss += loss.detach().item() * bs\n            seen += bs\n        epoch_train_loss = running_loss / max(1, seen)\n        train_losses.append(epoch_train_loss)\n\n        # Validation\n        model.eval()\n        val_loss, correct, total = 0.0, 0, 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb = xb.to(device, non_blocking=True).float()\n                yb = yb.to(device, non_blocking=True).long()\n                out = model(xb)\n                loss = criterion(out, yb)\n                val_loss += loss.detach().item() * xb.size(0)\n                preds = out.argmax(dim=1)\n                correct += (preds == yb).sum().item()\n                total += xb.size(0)\n        epoch_val_loss = val_loss / max(1, total)\n        epoch_val_acc = correct / max(1, total)\n        val_losses.append(epoch_val_loss)\n        val_accs.append(epoch_val_acc)\n\n        print(f\"Epoch {epoch:03d}/{epochs} - train_loss: {epoch_train_loss:.4f} - val_loss: {epoch_val_loss:.4f} - val_acc: {epoch_val_acc:.4f}\")\n\n    # ------------ Post-Training Quantization ------------\n    def quantize_post_training(trained_model):\n        # Always quantize/evaluate on CPU\n        mdl = copy.deepcopy(trained_model).to('cpu')\n        mdl.eval()\n\n        # If 32-bit requested or weights quantization disabled, just return CPU model\n        if quantization_bits == 32 or not quantize_weights:\n            return mdl\n\n        if quantization_bits == 8:\n            if quantize_weights and quantize_activations:\n                # Static int8 quantization (Conv/Linear) with calibration\n                torch.backends.quantized.engine = 'fbgemm'\n                try:\n                    mdl.fuse_model()\n                except Exception:\n                    pass\n                try:\n                    default_qconfig = tq.get_default_qconfig('fbgemm')\n                    # Set global qconfig\n                    mdl.qconfig = default_qconfig\n                    # Disable quantization for ConvTranspose1d (unsupported)\n                    for name, module in mdl.named_modules():\n                        if isinstance(module, nn.ConvTranspose1d):\n                            module.qconfig = None\n                    # Also disable at container level for safety\n                    if hasattr(mdl, 'up1'):\n                        try:\n                            mdl.up1.qconfig = None\n                            if hasattr(mdl.up1, 'deconv'):\n                                mdl.up1.deconv.qconfig = None\n                        except Exception:\n                            pass\n                    if hasattr(mdl, 'up2'):\n                        try:\n                            mdl.up2.qconfig = None\n                            if hasattr(mdl.up2, 'deconv'):\n                                mdl.up2.deconv.qconfig = None\n                        except Exception:\n                            pass\n\n                    tq.prepare(mdl, inplace=True)\n\n                    # Calibration with a small CPU loader\n                    calib_bs = min(256, batch_size)\n                    calib_loader = DataLoader(\n                        TensorDataset(X_train.cpu(), y_train.cpu()),\n                        batch_size=calib_bs,\n                        shuffle=False,\n                        num_workers=0,\n                        pin_memory=False,\n                    )\n                    seen = 0\n                    with torch.no_grad():\n                        for xb, _ in calib_loader:\n                            xb = xb.float()\n                            _ = mdl(xb)\n                            seen += xb.size(0)\n                            if seen >= calibration_samples:\n                                break\n                    tq.convert(mdl, inplace=True)\n                    return mdl\n                except Exception:\n                    # Fallback to dynamic quantization (Linear-only)\n                    qdtype = torch.qint8\n                    mdl = tq.quantize_dynamic(mdl, {nn.Linear}, dtype=qdtype)\n                    return mdl\n            else:\n                # Dynamic quantization for Linear layers only\n                qdtype = torch.qint8\n                mdl = tq.quantize_dynamic(mdl, {nn.Linear}, dtype=qdtype)\n                return mdl\n\n        if quantization_bits == 16:\n            # Float16 weight cast; activations stay fp32 on CPU\n            mdl = mdl.to(dtype=torch.float16)\n            return mdl\n\n        # Fallback\n        return mdl\n\n    quantized_model = quantize_post_training(model)\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs,\n    }\n\n    return quantized_model, metrics\n"}
2025-10-12 01:53:45,570 - INFO - _models.ai_code_generator - Debug successful on attempt 1
2025-10-12 01:53:45,570 - INFO - _models.training_function_executor - GPT suggested corrections: {"training_code":"def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import math\n    import copy\n    import torch\n    from torch import nn, optim\n    from torch.utils.data import TensorDataset, DataLoader\n    import torch.ao.quantization as tq\n\n    # Robust device handling\n    device = torch.device(device)\n    torch.backends.cudnn.benchmark = True\n\n    # ------------ Hyperparameters ------------\n    lr = float(hyperparams.get('lr', 1e-3))\n    batch_size = int(hyperparams.get('batch_size', 32))\n    epochs = int(hyperparams.get('epochs', 15))\n    weight_decay = float(hyperparams.get('weight_decay', 1e-4))\n    dropout = float(hyperparams.get('dropout', 0.1))\n    base_channels = int(hyperparams.get('base_channels', 12))\n    temporal_kernel = int(hyperparams.get('temporal_kernel', 7))\n    spatial_segments = int(hyperparams.get('spatial_segments', 10))  # must divide 6000\n    label_smoothing = float(hyperparams.get('label_smoothing', 0.0))\n    grad_clip = float(hyperparams.get('grad_clip', 0.0))\n    num_workers = int(hyperparams.get('num_workers', 4))\n\n    # Quantization params\n    quantization_bits = int(hyperparams.get('quantization_bits', 8))  # {8,16,32}\n    quantize_weights = bool(hyperparams.get('quantize_weights', True))\n    quantize_activations = bool(hyperparams.get('quantize_activations', True))\n    calibration_samples = int(hyperparams.get('calibration_samples', 2048))\n\n    # ------------ Sanity checks ------------\n    if X_train.dim() != 3:\n        raise ValueError(f\"X_train must be a 3D tensor of shape (N, 6, 6000). Got {tuple(X_train.shape)}\")\n    if X_train.shape[1] != 6 or X_train.shape[2] != 6000:\n        raise ValueError(f\"Expected input per-sample shape (6, 6000). Got {tuple(X_train.shape[1:])}\")\n    if spatial_segments <= 0 or (6000 % spatial_segments) != 0:\n        raise ValueError(\"spatial_segments must be a positive divisor of 6000\")\n    if temporal_kernel % 2 == 0:\n        temporal_kernel += 1  # ensure odd for same padding\n\n    # ------------ DataLoaders (spawn ctx + pin_memory) ------------\n    train_ds = TensorDataset(X_train, y_train)\n    val_ds = TensorDataset(X_val, y_val)\n    mp_ctx = torch.multiprocessing.get_context('spawn')\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n        multiprocessing_context=mp_ctx,\n        drop_last=False,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        multiprocessing_context=mp_ctx,\n        drop_last=False,\n    )\n\n    # ------------ Model Definition (ST-mini U-SleepNet) ------------\n    class TemporalBlock(nn.Module):\n        def __init__(self, in_ch, out_ch, ksize, stride=1):\n            super().__init__()\n            pad = ksize // 2\n            self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=ksize, stride=stride, padding=pad, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.relu = nn.ReLU(inplace=True)\n        def forward(self, x):\n            return self.relu(self.bn(self.conv(x)))\n\n    class UpBlock(nn.Module):\n        def __init__(self, in_ch, out_ch):\n            super().__init__()\n            self.deconv = nn.ConvTranspose1d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.relu = nn.ReLU(inplace=True)\n        def forward(self, x):\n            return self.relu(self.bn(self.deconv(x)))\n\n    class STMiniUSleepNet(nn.Module):\n        def __init__(self, in_channels=6, num_classes=5, base_channels=12, k=7, dropout=0.1, spatial_segments=10):\n            super().__init__()\n            C = base_channels\n            self.enc1 = TemporalBlock(in_channels, C, k)\n            self.down1 = TemporalBlock(C, 2*C, 5, stride=2)\n            self.down2 = TemporalBlock(2*C, 4*C, 5, stride=2)\n            self.bottleneck = TemporalBlock(4*C, 4*C, 3, stride=1)\n            self.up1 = UpBlock(4*C, 2*C)\n            self.up2 = UpBlock(2*C, C)\n            self.gap = nn.AdaptiveAvgPool1d(1)\n            self.temp_mlp = nn.Sequential(\n                nn.Linear(C, 16), nn.ReLU(inplace=True), nn.Dropout(dropout), nn.Linear(16, 8)\n            )\n            self.spatial_segments = spatial_segments\n            self.adjacency = nn.Parameter(torch.eye(6))  # learnable channel graph (6x6)\n            self.spat_mlp = nn.Sequential(\n                nn.Linear(6*spatial_segments, 16), nn.ReLU(inplace=True), nn.Dropout(dropout), nn.Linear(16, 8)\n            )\n            self.head = nn.Linear(16, num_classes)\n        def forward(self, x):\n            # Temporal U-Net branch\n            t = self.enc1(x)\n            t = self.down1(t)\n            t = self.down2(t)\n            t = self.bottleneck(t)\n            t = self.up1(t)\n            t = self.up2(t)\n            t = self.gap(t).squeeze(-1)  # (B, C)\n            tfeat = self.temp_mlp(t)     # (B, 8)\n            # Spatial graph branch over channel-time segments\n            B, C_in, T = x.shape  # C_in should be 6\n            K = self.spatial_segments\n            seg_len = T // K\n            xt = x[:, :, :seg_len*K]\n            xs = xt.view(B, C_in, K, seg_len).mean(-1)  # (B, 6, K)\n            A = torch.softmax(self.adjacency, dim=1)    # (6,6)\n            msg = torch.einsum('ij,bjk->bik', A, xs)    # (B, 6, K)\n            sfeat = self.spat_mlp(msg.reshape(B, -1))   # (B, 8)\n            fused = torch.cat([tfeat, sfeat], dim=1)     # (B, 16)\n            logits = self.head(fused)\n            return logits\n        def fuse_model(self):\n            # fuse Conv-BN-ReLU where applicable\n            try:\n                tq.fuse_modules(self, [['enc1.conv', 'enc1.bn', 'enc1.relu']], inplace=True)\n                tq.fuse_modules(self, [['down1.conv', 'down1.bn', 'down1.relu']], inplace=True)\n                tq.fuse_modules(self, [['down2.conv', 'down2.bn', 'down2.relu']], inplace=True)\n                tq.fuse_modules(self, [['bottleneck.conv', 'bottleneck.bn', 'bottleneck.relu']], inplace=True)\n            except Exception:\n                pass\n            # UpBlocks use ConvTranspose1d which is not fuse-supported; skip\n\n    model = STMiniUSleepNet(in_channels=6, num_classes=5, base_channels=base_channels, k=temporal_kernel, dropout=dropout, spatial_segments=spatial_segments)\n    model = model.to(device)\n\n    # ------------ Optimization ------------\n    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing).to(device)\n    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    train_losses, val_losses, val_accs = [], [], []\n\n    # ------------ Training Loop ------------\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        seen = 0\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=True).float()\n            yb = yb.to(device, non_blocking=True).long()\n            optimizer.zero_grad(set_to_none=True)\n            out = model(xb)\n            loss = criterion(out, yb)\n            loss.backward()\n            if grad_clip and grad_clip > 0.0:\n                nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n            optimizer.step()\n            bs = xb.size(0)\n            running_loss += loss.detach().item() * bs\n            seen += bs\n        epoch_train_loss = running_loss / max(1, seen)\n        train_losses.append(epoch_train_loss)\n\n        # Validation\n        model.eval()\n        val_loss, correct, total = 0.0, 0, 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb = xb.to(device, non_blocking=True).float()\n                yb = yb.to(device, non_blocking=True).long()\n                out = model(xb)\n                loss = criterion(out, yb)\n                val_loss += loss.detach().item() * xb.size(0)\n                preds = out.argmax(dim=1)\n                correct += (preds == yb).sum().item()\n                total += xb.size(0)\n        epoch_val_loss = val_loss / max(1, total)\n        epoch_val_acc = correct / max(1, total)\n        val_losses.append(epoch_val_loss)\n        val_accs.append(epoch_val_acc)\n\n        print(f\"Epoch {epoch:03d}/{epochs} - train_loss: {epoch_train_loss:.4f} - val_loss: {epoch_val_loss:.4f} - val_acc: {epoch_val_acc:.4f}\")\n\n    # ------------ Post-Training Quantization ------------\n    def quantize_post_training(trained_model):\n        # Always quantize/evaluate on CPU\n        mdl = copy.deepcopy(trained_model).to('cpu')\n        mdl.eval()\n\n        # If 32-bit requested or weights quantization disabled, just return CPU model\n        if quantization_bits == 32 or not quantize_weights:\n            return mdl\n\n        if quantization_bits == 8:\n            if quantize_weights and quantize_activations:\n                # Static int8 quantization (Conv/Linear) with calibration\n                torch.backends.quantized.engine = 'fbgemm'\n                try:\n                    mdl.fuse_model()\n                except Exception:\n                    pass\n                try:\n                    default_qconfig = tq.get_default_qconfig('fbgemm')\n                    # Set global qconfig\n                    mdl.qconfig = default_qconfig\n                    # Disable quantization for ConvTranspose1d (unsupported)\n                    for name, module in mdl.named_modules():\n                        if isinstance(module, nn.ConvTranspose1d):\n                            module.qconfig = None\n                    # Also disable at container level for safety\n                    if hasattr(mdl, 'up1'):\n                        try:\n                            mdl.up1.qconfig = None\n                            if hasattr(mdl.up1, 'deconv'):\n                                mdl.up1.deconv.qconfig = None\n                        except Exception:\n                            pass\n                    if hasattr(mdl, 'up2'):\n                        try:\n                            mdl.up2.qconfig = None\n                            if hasattr(mdl.up2, 'deconv'):\n                                mdl.up2.deconv.qconfig = None\n                        except Exception:\n                            pass\n\n                    tq.prepare(mdl, inplace=True)\n\n                    # Calibration with a small CPU loader\n                    calib_bs = min(256, batch_size)\n                    calib_loader = DataLoader(\n                        TensorDataset(X_train.cpu(), y_train.cpu()),\n                        batch_size=calib_bs,\n                        shuffle=False,\n                        num_workers=0,\n                        pin_memory=False,\n                    )\n                    seen = 0\n                    with torch.no_grad():\n                        for xb, _ in calib_loader:\n                            xb = xb.float()\n                            _ = mdl(xb)\n                            seen += xb.size(0)\n                            if seen >= calibration_samples:\n                                break\n                    tq.convert(mdl, inplace=True)\n                    return mdl\n                except Exception:\n                    # Fallback to dynamic quantization (Linear-only)\n                    qdtype = torch.qint8\n                    mdl = tq.quantize_dynamic(mdl, {nn.Linear}, dtype=qdtype)\n                    return mdl\n            else:\n                # Dynamic quantization for Linear layers only\n                qdtype = torch.qint8\n                mdl = tq.quantize_dynamic(mdl, {nn.Linear}, dtype=qdtype)\n                return mdl\n\n        if quantization_bits == 16:\n            # Float16 weight cast; activations stay fp32 on CPU\n            mdl = mdl.to(dtype=torch.float16)\n            return mdl\n\n        # Fallback\n        return mdl\n\n    quantized_model = quantize_post_training(model)\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs,\n    }\n\n    return quantized_model, metrics\n"}
2025-10-12 01:53:45,570 - INFO - _models.training_function_executor - Stored corrections for BO process
2025-10-12 01:53:45,570 - ERROR - _models.training_function_executor - BO training objective failed: Per channel weight observer is not supported yet for ConvTranspose{n}d.
2025-10-12 01:53:45,570 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 890.663s
2025-10-12 01:53:45,575 - ERROR - evaluation.code_generation_pipeline_orchestrator - BO Trial 3 FAILED with error: Per channel weight observer is not supported yet for ConvTranspose{n}d.
2025-10-12 01:53:45,575 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚è≥ Waiting for GPT to finish debugging...
2025-10-12 01:53:48,577 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ GPT provided fixes after 3s - requesting BO restart
2025-10-12 01:53:48,577 - INFO - evaluation.code_generation_pipeline_orchestrator - üîß Applying GPT fixes to original JSON file
2025-10-12 01:53:48,582 - INFO - evaluation.code_generation_pipeline_orchestrator - Applying fixes to: generated_training_functions/training_function_torch_tensor_STMiniUSleepNet-Quant_1760250545.json
2025-10-12 01:53:48,582 - INFO - _models.training_function_executor - Loaded training function: STMiniUSleepNet-Quant
2025-10-12 01:53:48,582 - INFO - _models.training_function_executor - Reasoning: No reasoning provided
2025-10-12 01:53:48,582 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Updated training_code with GPT fix
2025-10-12 01:53:48,582 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ Saved GPT fixes back to: generated_training_functions/training_function_torch_tensor_STMiniUSleepNet-Quant_1760250545.json
2025-10-12 01:53:48,582 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Reloaded fixed training function: STMiniUSleepNet-Quant
2025-10-12 01:53:48,582 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Applied GPT fixes, restarting BO from trial 0
2025-10-12 01:53:48,908 - INFO - evaluation.code_generation_pipeline_orchestrator - üîÑ BO Restart attempt 1/4
2025-10-12 01:53:48,908 - INFO - evaluation.code_generation_pipeline_orchestrator - Session 1: üì¶ Installing dependencies for GPT-generated training code...
2025-10-12 01:53:48,908 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-10-12 01:53:48,910 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-10-12 01:53:48,910 - INFO - package_installer - Available packages: {'torch'}
2025-10-12 01:53:48,910 - INFO - package_installer - Missing packages: set()
2025-10-12 01:53:48,910 - INFO - package_installer - ‚úÖ All required packages are already available
2025-10-12 01:53:48,910 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-10-12 01:53:48,911 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-12 01:53:48,911 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 57140 samples (using bo_sample_num=100000000000000)
2025-10-12 01:53:48,911 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'base_channels', 'temporal_kernel', 'spatial_segments', 'label_smoothing', 'grad_clip', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_samples']
2025-10-12 01:53:48,911 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-12 01:53:48,911 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-12 01:53:48,911 - INFO - _models.training_function_executor - Using BO subset for optimization: 57140 samples (bo_sample_num=100000000000000)
2025-10-12 01:54:00,098 - INFO - _models.training_function_executor - BO splits - Train: 45712, Val: 11428
2025-10-12 01:54:01,364 - INFO - bo.run_bo - Converted GPT search space: 15 parameters
2025-10-12 01:54:01,364 - INFO - bo.run_bo - Using GPT-generated search space
2025-10-12 01:54:01,368 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-10-12 01:54:01,370 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-10-12 01:54:01,370 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-10-12 01:54:01,370 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:54:01,370 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 01:54:01,370 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 5563}
2025-10-12 01:54:01,373 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 5563}
2025-10-12 01:54:20,435 - INFO - _models.training_function_executor - Epoch 001/12 - train_loss: 1.3047 - val_loss: 1.4547 - val_acc: 0.5110
2025-10-12 01:54:37,557 - INFO - _models.training_function_executor - Epoch 002/12 - train_loss: 1.1590 - val_loss: 1.1625 - val_acc: 0.6481
2025-10-12 01:54:54,624 - INFO - _models.training_function_executor - Epoch 003/12 - train_loss: 1.0957 - val_loss: 0.9864 - val_acc: 0.6643
2025-10-12 01:55:11,724 - INFO - _models.training_function_executor - Epoch 004/12 - train_loss: 1.0720 - val_loss: 1.0170 - val_acc: 0.6857
2025-10-12 01:55:28,772 - INFO - _models.training_function_executor - Epoch 005/12 - train_loss: 1.0534 - val_loss: 1.3634 - val_acc: 0.5678
2025-10-12 01:55:45,861 - INFO - _models.training_function_executor - Epoch 006/12 - train_loss: 1.0452 - val_loss: 0.9829 - val_acc: 0.7114
2025-10-12 01:56:02,988 - INFO - _models.training_function_executor - Epoch 007/12 - train_loss: 1.0312 - val_loss: 1.0765 - val_acc: 0.7102
2025-10-12 01:56:20,070 - INFO - _models.training_function_executor - Epoch 008/12 - train_loss: 1.0058 - val_loss: 0.9830 - val_acc: 0.7098
2025-10-12 01:56:37,225 - INFO - _models.training_function_executor - Epoch 009/12 - train_loss: 1.0146 - val_loss: 1.0022 - val_acc: 0.7104
2025-10-12 01:56:54,384 - INFO - _models.training_function_executor - Epoch 010/12 - train_loss: 1.0057 - val_loss: 1.2072 - val_acc: 0.6653
2025-10-12 01:57:11,484 - INFO - _models.training_function_executor - Epoch 011/12 - train_loss: 0.9825 - val_loss: 1.0978 - val_acc: 0.6718
2025-10-12 01:57:28,682 - INFO - _models.training_function_executor - Epoch 012/12 - train_loss: 0.9672 - val_loss: 0.8339 - val_acc: 0.7496
2025-10-12 01:57:28,687 - INFO - _models.training_function_executor - Model: 50,309 parameters, 216.2KB storage
2025-10-12 01:57:28,687 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3047152805733104, 1.159035725425831, 1.0957453009347462, 1.0719975323335125, 1.0533566782169506, 1.0452250833898564, 1.03117023037579, 1.0057507307302256, 1.014563343566241, 1.0057356869283571, 0.9825371164837666, 0.9671620493966631], 'val_losses': [1.4547337799127342, 1.1625165753027422, 0.9863816935113981, 1.0170136146249995, 1.363432553230068, 0.9828760169021391, 1.0765484946672008, 0.9830487857425718, 1.0022210611990794, 1.2071982814917666, 1.0978261309985227, 0.8339000520044413], 'val_acc': [0.5110255512775639, 0.6481449072453622, 0.664333216660833, 0.6856842842142107, 0.5678158907945398, 0.7114105705285264, 0.7101855092754638, 0.7098354917745887, 0.7103605180259013, 0.6652957647882394, 0.6717710885544277, 0.749649982499125], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 5563}, 'model_parameter_count': 50309, 'model_storage_size_kb': 216.171484375, 'model_size_validation': 'PASS'}
2025-10-12 01:57:28,687 - INFO - _models.training_function_executor - BO Objective: base=0.7496, size_penalty=0.0000, final=0.7496
2025-10-12 01:57:28,687 - INFO - _models.training_function_executor - Model: 50,309 parameters, 216.2KB (PASS 256KB limit)
2025-10-12 01:57:28,687 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 207.317s
2025-10-12 01:57:28,689 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7496
2025-10-12 01:57:28,689 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-12 01:57:28,689 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': np.int64(12), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': np.int64(18), 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': np.int64(5563)}, value=0.7496
2025-10-12 01:57:28,689 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.009609812947036413, 'batch_size': 8, 'epochs': np.int64(12), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'base_channels': np.int64(18), 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.02857336358438816, 'grad_clip': 0.650888472948853, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': np.int64(5563)} -> 0.7496
2025-10-12 01:57:28,690 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-10-12 01:57:28,690 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 01:57:28,690 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:57:28,690 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 01:57:28,690 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4068}
2025-10-12 01:57:28,691 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4068}
2025-10-12 01:57:43,321 - INFO - _models.training_function_executor - Epoch 001/26 - train_loss: 1.8232 - val_loss: 1.7253 - val_acc: 0.2311
2025-10-12 01:57:57,928 - INFO - _models.training_function_executor - Epoch 002/26 - train_loss: 1.5881 - val_loss: 1.5974 - val_acc: 0.3113
2025-10-12 01:58:12,543 - INFO - _models.training_function_executor - Epoch 003/26 - train_loss: 1.4629 - val_loss: 1.4887 - val_acc: 0.3946
2025-10-12 01:58:27,165 - INFO - _models.training_function_executor - Epoch 004/26 - train_loss: 1.3663 - val_loss: 1.5614 - val_acc: 0.3249
2025-10-12 01:58:41,783 - INFO - _models.training_function_executor - Epoch 005/26 - train_loss: 1.2939 - val_loss: 1.4307 - val_acc: 0.4181
2025-10-12 01:58:56,418 - INFO - _models.training_function_executor - Epoch 006/26 - train_loss: 1.2423 - val_loss: 1.2661 - val_acc: 0.5328
2025-10-12 01:59:11,070 - INFO - _models.training_function_executor - Epoch 007/26 - train_loss: 1.2041 - val_loss: 1.2694 - val_acc: 0.5238
2025-10-12 01:59:25,671 - INFO - _models.training_function_executor - Epoch 008/26 - train_loss: 1.1672 - val_loss: 1.2193 - val_acc: 0.5660
2025-10-12 01:59:40,285 - INFO - _models.training_function_executor - Epoch 009/26 - train_loss: 1.1410 - val_loss: 1.2060 - val_acc: 0.5720
2025-10-12 01:59:54,887 - INFO - _models.training_function_executor - Epoch 010/26 - train_loss: 1.1136 - val_loss: 1.1734 - val_acc: 0.5749
2025-10-12 02:00:09,524 - INFO - _models.training_function_executor - Epoch 011/26 - train_loss: 1.0905 - val_loss: 1.1874 - val_acc: 0.5774
2025-10-12 02:00:24,145 - INFO - _models.training_function_executor - Epoch 012/26 - train_loss: 1.0692 - val_loss: 1.1561 - val_acc: 0.5895
2025-10-12 02:00:38,731 - INFO - _models.training_function_executor - Epoch 013/26 - train_loss: 1.0476 - val_loss: 1.1125 - val_acc: 0.6033
2025-10-12 02:00:53,356 - INFO - _models.training_function_executor - Epoch 014/26 - train_loss: 1.0331 - val_loss: 1.1249 - val_acc: 0.5982
2025-10-12 02:01:07,941 - INFO - _models.training_function_executor - Epoch 015/26 - train_loss: 1.0159 - val_loss: 1.1194 - val_acc: 0.5984
2025-10-12 02:01:22,548 - INFO - _models.training_function_executor - Epoch 016/26 - train_loss: 1.0000 - val_loss: 1.1014 - val_acc: 0.6048
2025-10-12 02:01:37,164 - INFO - _models.training_function_executor - Epoch 017/26 - train_loss: 0.9856 - val_loss: 1.1075 - val_acc: 0.5996
2025-10-12 02:01:51,809 - INFO - _models.training_function_executor - Epoch 018/26 - train_loss: 0.9731 - val_loss: 1.0688 - val_acc: 0.6201
2025-10-12 02:02:06,463 - INFO - _models.training_function_executor - Epoch 019/26 - train_loss: 0.9634 - val_loss: 1.1226 - val_acc: 0.5985
2025-10-12 02:02:21,098 - INFO - _models.training_function_executor - Epoch 020/26 - train_loss: 0.9500 - val_loss: 1.4063 - val_acc: 0.4459
2025-10-12 02:02:35,736 - INFO - _models.training_function_executor - Epoch 021/26 - train_loss: 0.9412 - val_loss: 1.0387 - val_acc: 0.6355
2025-10-12 02:02:50,370 - INFO - _models.training_function_executor - Epoch 022/26 - train_loss: 0.9337 - val_loss: 1.1806 - val_acc: 0.5802
2025-10-12 02:03:04,992 - INFO - _models.training_function_executor - Epoch 023/26 - train_loss: 0.9225 - val_loss: 1.2757 - val_acc: 0.5230
2025-10-12 02:03:19,613 - INFO - _models.training_function_executor - Epoch 024/26 - train_loss: 0.9163 - val_loss: 1.1304 - val_acc: 0.5972
2025-10-12 02:03:34,209 - INFO - _models.training_function_executor - Epoch 025/26 - train_loss: 0.9082 - val_loss: 1.0819 - val_acc: 0.6227
2025-10-12 02:03:48,843 - INFO - _models.training_function_executor - Epoch 026/26 - train_loss: 0.9063 - val_loss: 1.5401 - val_acc: 0.4260
2025-10-12 02:03:48,846 - INFO - _models.training_function_executor - Model: 137,361 parameters, 590.2KB storage
2025-10-12 02:03:48,848 - WARNING - _models.training_function_executor - Model storage 590.2KB exceeds 256KB limit!
2025-10-12 02:03:48,848 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.8231849372073992, 1.5881249515752422, 1.462910887783626, 1.3663342766382913, 1.293877630601782, 1.242291516280483, 1.2041012412149004, 1.1672069261780893, 1.1410392571630534, 1.1136377284607772, 1.0905237694198868, 1.0692101382566659, 1.0475824080566698, 1.0330794539992358, 1.0158510387340207, 1.0000159782381963, 0.9855596217443194, 0.9730971480609238, 0.9634213452890781, 0.9499825434038845, 0.9411575361528219, 0.9337154560085773, 0.9224528663217667, 0.9163072221254943, 0.9081662119603215, 0.906313464947835], 'val_losses': [1.7252535565482765, 1.597393637901843, 1.4886507693812443, 1.5614170850804523, 1.4307258870996375, 1.2660736486884234, 1.2694311759085517, 1.219294005542691, 1.2060177562785057, 1.173444264745395, 1.1873936833390666, 1.1561274362227947, 1.112488245062783, 1.1248519836208142, 1.1193934536747971, 1.1013641090379713, 1.1075499554092667, 1.0687877334495253, 1.1226068828170184, 1.406277369234501, 1.0386835764787143, 1.180550989088246, 1.27565627622571, 1.1303866333088592, 1.0819307718403823, 1.5400662650417773], 'val_acc': [0.23109905495274763, 0.3112530626531327, 0.39464473223661184, 0.32490374518725934, 0.4180959047952398, 0.5328141407070354, 0.523801190059503, 0.5659782989149458, 0.5720161008050403, 0.5749037451872594, 0.5773538676933847, 0.5895169758487925, 0.603255162758138, 0.5981799089954498, 0.5984424221211061, 0.6048302415120757, 0.59957997899895, 0.6201435071753588, 0.5985299264963249, 0.4459222961148057, 0.6355442772138606, 0.5802415120756038, 0.5230136506825341, 0.5972173608680434, 0.6226811340567029, 0.42597129856492827], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4068}, 'model_parameter_count': 137361, 'model_storage_size_kb': 590.223046875, 'model_size_validation': 'FAIL'}
2025-10-12 02:03:48,848 - INFO - _models.training_function_executor - BO Objective: base=0.4260, size_penalty=0.6528, final=-0.2268
2025-10-12 02:03:48,848 - INFO - _models.training_function_executor - Model: 137,361 parameters, 590.2KB (FAIL 256KB limit)
2025-10-12 02:03:48,848 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 380.158s
2025-10-12 02:03:48,851 - INFO - bo.run_bo - Updated RF surrogate model with observation: -0.2268
2025-10-12 02:03:48,851 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-12 02:03:48,851 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': np.int64(26), 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': np.int64(17), 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': np.int64(4068)}, value=-0.2268
2025-10-12 02:03:48,851 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 8.260808399079598e-06, 'batch_size': 16, 'epochs': np.int64(26), 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'base_channels': np.int64(17), 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.046554268086060856, 'grad_clip': 0.09060643453282081, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': np.int64(4068)} -> -0.2268
2025-10-12 02:03:48,852 - INFO - bo.run_bo - üîçBO Trial 3: Initial random exploration
2025-10-12 02:03:48,852 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 02:03:48,852 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 02:03:48,852 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 02:03:48,852 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0010907475835157708, 'batch_size': 8, 'epochs': 43, 'weight_decay': 1.1299516083106616e-06, 'dropout': 0.4711008778424265, 'base_channels': 21, 'temporal_kernel': 9, 'spatial_segments': 30, 'label_smoothing': 0.019534422801276777, 'grad_clip': 0.684233026512157, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6861}
2025-10-12 02:03:48,853 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0010907475835157708, 'batch_size': 8, 'epochs': 43, 'weight_decay': 1.1299516083106616e-06, 'dropout': 0.4711008778424265, 'base_channels': 21, 'temporal_kernel': 9, 'spatial_segments': 30, 'label_smoothing': 0.019534422801276777, 'grad_clip': 0.684233026512157, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6861}
2025-10-12 02:04:07,067 - INFO - _models.training_function_executor - Epoch 001/43 - train_loss: 1.2171 - val_loss: 0.9568 - val_acc: 0.6272
2025-10-12 02:04:25,134 - INFO - _models.training_function_executor - Epoch 002/43 - train_loss: 1.0271 - val_loss: 0.8486 - val_acc: 0.7045
2025-10-12 02:04:43,344 - INFO - _models.training_function_executor - Epoch 003/43 - train_loss: 0.9589 - val_loss: 0.7583 - val_acc: 0.7310
2025-10-12 02:05:01,456 - INFO - _models.training_function_executor - Epoch 004/43 - train_loss: 0.9129 - val_loss: 0.7817 - val_acc: 0.7297
2025-10-12 02:05:19,633 - INFO - _models.training_function_executor - Epoch 005/43 - train_loss: 0.8890 - val_loss: 0.8024 - val_acc: 0.7183
2025-10-12 02:05:37,808 - INFO - _models.training_function_executor - Epoch 006/43 - train_loss: 0.8726 - val_loss: 0.7149 - val_acc: 0.7576
2025-10-12 02:05:55,938 - INFO - _models.training_function_executor - Epoch 007/43 - train_loss: 0.8653 - val_loss: 0.7512 - val_acc: 0.7453
2025-10-12 02:06:14,156 - INFO - _models.training_function_executor - Epoch 008/43 - train_loss: 0.8549 - val_loss: 0.7349 - val_acc: 0.7541
2025-10-12 02:06:32,355 - INFO - _models.training_function_executor - Epoch 009/43 - train_loss: 0.8405 - val_loss: 0.7745 - val_acc: 0.7363
2025-10-12 02:06:50,526 - INFO - _models.training_function_executor - Epoch 010/43 - train_loss: 0.8390 - val_loss: 0.6991 - val_acc: 0.7597
2025-10-12 02:07:08,739 - INFO - _models.training_function_executor - Epoch 011/43 - train_loss: 0.8301 - val_loss: 0.7151 - val_acc: 0.7679
2025-10-12 02:07:26,932 - INFO - _models.training_function_executor - Epoch 012/43 - train_loss: 0.8254 - val_loss: 0.6934 - val_acc: 0.7724
2025-10-12 02:07:45,115 - INFO - _models.training_function_executor - Epoch 013/43 - train_loss: 0.8202 - val_loss: 0.6786 - val_acc: 0.7764
2025-10-12 02:08:03,257 - INFO - _models.training_function_executor - Epoch 014/43 - train_loss: 0.8150 - val_loss: 0.7002 - val_acc: 0.7644
2025-10-12 02:08:21,343 - INFO - _models.training_function_executor - Epoch 015/43 - train_loss: 0.8075 - val_loss: 0.6855 - val_acc: 0.7794
2025-10-12 02:08:39,548 - INFO - _models.training_function_executor - Epoch 016/43 - train_loss: 0.8095 - val_loss: 0.6772 - val_acc: 0.7715
2025-10-12 02:08:57,655 - INFO - _models.training_function_executor - Epoch 017/43 - train_loss: 0.8029 - val_loss: 0.6766 - val_acc: 0.7685
2025-10-12 02:09:15,726 - INFO - _models.training_function_executor - Epoch 018/43 - train_loss: 0.8014 - val_loss: 0.6891 - val_acc: 0.7847
2025-10-12 02:09:33,874 - INFO - _models.training_function_executor - Epoch 019/43 - train_loss: 0.7980 - val_loss: 0.7159 - val_acc: 0.7567
2025-10-12 02:09:51,985 - INFO - _models.training_function_executor - Epoch 020/43 - train_loss: 0.7988 - val_loss: 0.6915 - val_acc: 0.7702
2025-10-12 02:10:10,214 - INFO - _models.training_function_executor - Epoch 021/43 - train_loss: 0.7928 - val_loss: 0.6910 - val_acc: 0.7674
2025-10-12 02:10:28,331 - INFO - _models.training_function_executor - Epoch 022/43 - train_loss: 0.7889 - val_loss: 0.6849 - val_acc: 0.7739
2025-10-12 02:10:46,497 - INFO - _models.training_function_executor - Epoch 023/43 - train_loss: 0.7868 - val_loss: 0.7344 - val_acc: 0.7789
2025-10-12 02:11:04,685 - INFO - _models.training_function_executor - Epoch 024/43 - train_loss: 0.7849 - val_loss: 0.7213 - val_acc: 0.7720
2025-10-12 02:11:22,868 - INFO - _models.training_function_executor - Epoch 025/43 - train_loss: 0.7859 - val_loss: 0.7825 - val_acc: 0.7692
2025-10-12 02:11:41,032 - INFO - _models.training_function_executor - Epoch 026/43 - train_loss: 0.7791 - val_loss: 0.7554 - val_acc: 0.7752
2025-10-12 02:11:59,114 - INFO - _models.training_function_executor - Epoch 027/43 - train_loss: 0.7745 - val_loss: 0.7872 - val_acc: 0.7759
2025-10-12 02:12:17,344 - INFO - _models.training_function_executor - Epoch 028/43 - train_loss: 0.7724 - val_loss: 0.7386 - val_acc: 0.7560
2025-10-12 02:12:35,467 - INFO - _models.training_function_executor - Epoch 029/43 - train_loss: 0.7740 - val_loss: 0.7433 - val_acc: 0.7686
2025-10-12 02:12:53,605 - INFO - _models.training_function_executor - Epoch 030/43 - train_loss: 0.7733 - val_loss: 0.7046 - val_acc: 0.7760
2025-10-12 02:13:11,792 - INFO - _models.training_function_executor - Epoch 031/43 - train_loss: 0.7695 - val_loss: 0.7159 - val_acc: 0.7608
2025-10-12 02:13:29,933 - INFO - _models.training_function_executor - Epoch 032/43 - train_loss: 0.7715 - val_loss: 0.6976 - val_acc: 0.7876
2025-10-12 02:13:48,133 - INFO - _models.training_function_executor - Epoch 033/43 - train_loss: 0.7668 - val_loss: 0.8020 - val_acc: 0.7806
2025-10-12 02:14:06,259 - INFO - _models.training_function_executor - Epoch 034/43 - train_loss: 0.7614 - val_loss: 0.8239 - val_acc: 0.7900
2025-10-12 02:14:24,403 - INFO - _models.training_function_executor - Epoch 035/43 - train_loss: 0.7601 - val_loss: 0.7071 - val_acc: 0.7835
2025-10-12 02:14:42,580 - INFO - _models.training_function_executor - Epoch 036/43 - train_loss: 0.7642 - val_loss: 0.8015 - val_acc: 0.7789
2025-10-12 02:15:00,731 - INFO - _models.training_function_executor - Epoch 037/43 - train_loss: 0.7617 - val_loss: 0.7318 - val_acc: 0.7915
2025-10-12 02:15:18,811 - INFO - _models.training_function_executor - Epoch 038/43 - train_loss: 0.7579 - val_loss: 0.7702 - val_acc: 0.7579
2025-10-12 02:15:36,982 - INFO - _models.training_function_executor - Epoch 039/43 - train_loss: 0.7548 - val_loss: 0.8619 - val_acc: 0.7876
2025-10-12 02:15:55,207 - INFO - _models.training_function_executor - Epoch 040/43 - train_loss: 0.7475 - val_loss: 0.8294 - val_acc: 0.7728
2025-10-12 02:16:13,383 - INFO - _models.training_function_executor - Epoch 041/43 - train_loss: 0.7462 - val_loss: 0.6621 - val_acc: 0.7960
2025-10-12 02:16:31,591 - INFO - _models.training_function_executor - Epoch 042/43 - train_loss: 0.7529 - val_loss: 0.7232 - val_acc: 0.7671
2025-10-12 02:16:49,762 - INFO - _models.training_function_executor - Epoch 043/43 - train_loss: 0.7457 - val_loss: 0.8335 - val_acc: 0.7895
2025-10-12 02:16:56,273 - INFO - _models.training_function_executor - Model: 17,802 parameters, 19.1KB storage
2025-10-12 02:16:56,274 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2171038862579888, 1.027077483393364, 0.9588738991887076, 0.9129280653952676, 0.8890362783750121, 0.8725771250990165, 0.8652543008802109, 0.8548728264959533, 0.840532725351567, 0.8389868281591302, 0.8300785095015939, 0.8253961835509003, 0.8201818116788978, 0.8149819392808718, 0.8074798390430965, 0.809529555628339, 0.8028796825598369, 0.8013837577623214, 0.7980255433337063, 0.7987756651464691, 0.7928147237039881, 0.7889229811683668, 0.7867902793931636, 0.784906754488602, 0.7858699167556057, 0.7791267917770208, 0.7744616206799264, 0.7723818717509414, 0.773970223801575, 0.7732972685621884, 0.7695266579023223, 0.7714827228878651, 0.7668269573703361, 0.7613812493180577, 0.7601062173364794, 0.7642058267965156, 0.7617254982753613, 0.7578694499823069, 0.7548165461599389, 0.747489588921267, 0.7461870420472497, 0.7529496925305686, 0.7456892412162386], 'val_losses': [0.956824652769785, 0.8485634113614026, 0.7583411222243585, 0.7817258531182723, 0.8024320206234912, 0.7149290175633202, 0.7512238672720957, 0.7349471562823341, 0.7744806592995194, 0.6990644530186838, 0.715128611592008, 0.6934435421931481, 0.6785811349608742, 0.7002305448117855, 0.6854737755569662, 0.67716724179114, 0.6765851987422159, 0.6890949862358826, 0.7158945831732605, 0.6915420060563346, 0.6909908199794317, 0.6849175966783215, 0.7343569686039787, 0.7212910800598533, 0.7824992474493214, 0.7554162954028186, 0.7871898457872146, 0.7386220350814608, 0.7433483185970913, 0.7046428550403769, 0.715928092395504, 0.6975781945319371, 0.8020468418690805, 0.8238758309491665, 0.7071392490578399, 0.8014896838428008, 0.7317999127468614, 0.7702087113854765, 0.8619108251082468, 0.8293971103160666, 0.6620848285263137, 0.7232230205322255, 0.8335022572604017], 'val_acc': [0.6272313615680783, 0.7044977248862443, 0.7310115505775289, 0.7296989849492475, 0.7183234161708085, 0.7576128806440322, 0.7452747637381869, 0.7541127056352818, 0.7363493174658733, 0.7597129856492825, 0.767938396919846, 0.7724011200560028, 0.7764263213160658, 0.7644382219110956, 0.7794014700735037, 0.7715260763038152, 0.7684634231711586, 0.7847392369618481, 0.7566503325166258, 0.7702135106755338, 0.7674133706685334, 0.7738886944347217, 0.7788764438221911, 0.771963598179909, 0.7691634581729087, 0.7752012600630032, 0.7759012950647532, 0.7560378018900945, 0.7685509275463773, 0.775988799439972, 0.7607630381519076, 0.7876268813440672, 0.7806265313265663, 0.7899894994749738, 0.7835141757087855, 0.7788764438221911, 0.7914770738536927, 0.7578753937696885, 0.7876268813440672, 0.7727511375568779, 0.7960273013650683, 0.7670633531676584, 0.7894644732236612], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0010907475835157708, 'batch_size': 8, 'epochs': 43, 'weight_decay': 1.1299516083106616e-06, 'dropout': 0.4711008778424265, 'base_channels': 21, 'temporal_kernel': 9, 'spatial_segments': 30, 'label_smoothing': 0.019534422801276777, 'grad_clip': 0.684233026512157, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6861}, 'model_parameter_count': 17802, 'model_storage_size_kb': 19.1232421875, 'model_size_validation': 'PASS'}
2025-10-12 02:16:56,274 - INFO - _models.training_function_executor - BO Objective: base=0.7895, size_penalty=0.0000, final=0.7895
2025-10-12 02:16:56,274 - INFO - _models.training_function_executor - Model: 17,802 parameters, 19.1KB (PASS 256KB limit)
2025-10-12 02:16:56,274 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 787.422s
2025-10-12 02:16:56,367 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7895
2025-10-12 02:16:56,367 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.091s
2025-10-12 02:16:56,367 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 0.0010907475835157708, 'batch_size': 8, 'epochs': np.int64(43), 'weight_decay': 1.1299516083106616e-06, 'dropout': 0.4711008778424265, 'base_channels': np.int64(21), 'temporal_kernel': 9, 'spatial_segments': 30, 'label_smoothing': 0.019534422801276777, 'grad_clip': 0.684233026512157, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': np.int64(6861)}, value=0.7895
2025-10-12 02:16:56,367 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 0.0010907475835157708, 'batch_size': 8, 'epochs': np.int64(43), 'weight_decay': 1.1299516083106616e-06, 'dropout': 0.4711008778424265, 'base_channels': np.int64(21), 'temporal_kernel': 9, 'spatial_segments': 30, 'label_smoothing': 0.019534422801276777, 'grad_clip': 0.684233026512157, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': np.int64(6861)} -> 0.7895
2025-10-12 02:16:56,367 - INFO - bo.run_bo - üîçBO Trial 4: Using RF surrogate + Expected Improvement
2025-10-12 02:16:56,367 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 02:16:56,367 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 02:16:56,367 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 02:16:56,367 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 9.022004468565623e-05, 'batch_size': 48, 'epochs': 37, 'weight_decay': 2.261956269416809e-05, 'dropout': 0.22280037778852874, 'base_channels': 10, 'temporal_kernel': 7, 'spatial_segments': 20, 'label_smoothing': 0.1310403062812608, 'grad_clip': 0.7272741575850397, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 6263}
2025-10-12 02:16:56,368 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 9.022004468565623e-05, 'batch_size': 48, 'epochs': 37, 'weight_decay': 2.261956269416809e-05, 'dropout': 0.22280037778852874, 'base_channels': 10, 'temporal_kernel': 7, 'spatial_segments': 20, 'label_smoothing': 0.1310403062812608, 'grad_clip': 0.7272741575850397, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 6263}
2025-10-12 02:17:06,636 - INFO - _models.training_function_executor - Epoch 001/37 - train_loss: 1.5915 - val_loss: 1.5003 - val_acc: 0.3931
2025-10-12 02:17:16,549 - INFO - _models.training_function_executor - Epoch 002/37 - train_loss: 1.3781 - val_loss: 1.3075 - val_acc: 0.5594
2025-10-12 02:17:26,448 - INFO - _models.training_function_executor - Epoch 003/37 - train_loss: 1.2702 - val_loss: 1.2756 - val_acc: 0.5452
2025-10-12 02:17:36,331 - INFO - _models.training_function_executor - Epoch 004/37 - train_loss: 1.2120 - val_loss: 1.1950 - val_acc: 0.6026
2025-10-12 02:17:46,235 - INFO - _models.training_function_executor - Epoch 005/37 - train_loss: 1.1683 - val_loss: 1.1535 - val_acc: 0.6156
2025-10-12 02:17:56,179 - INFO - _models.training_function_executor - Epoch 006/37 - train_loss: 1.1427 - val_loss: 1.1425 - val_acc: 0.6164
2025-10-12 02:18:06,112 - INFO - _models.training_function_executor - Epoch 007/37 - train_loss: 1.1246 - val_loss: 1.0752 - val_acc: 0.6577
2025-10-12 02:18:16,033 - INFO - _models.training_function_executor - Epoch 008/37 - train_loss: 1.1104 - val_loss: 1.2830 - val_acc: 0.5382
2025-10-12 02:18:25,964 - INFO - _models.training_function_executor - Epoch 009/37 - train_loss: 1.0975 - val_loss: 1.0453 - val_acc: 0.6872
2025-10-12 02:18:35,843 - INFO - _models.training_function_executor - Epoch 010/37 - train_loss: 1.0844 - val_loss: 1.0287 - val_acc: 0.7015
2025-10-12 02:18:45,765 - INFO - _models.training_function_executor - Epoch 011/37 - train_loss: 1.0758 - val_loss: 1.0345 - val_acc: 0.6979
2025-10-12 02:18:55,694 - INFO - _models.training_function_executor - Epoch 012/37 - train_loss: 1.0670 - val_loss: 1.0338 - val_acc: 0.6929
2025-10-12 02:19:05,649 - INFO - _models.training_function_executor - Epoch 013/37 - train_loss: 1.0570 - val_loss: 1.0749 - val_acc: 0.6650
2025-10-12 02:19:15,597 - INFO - _models.training_function_executor - Epoch 014/37 - train_loss: 1.0456 - val_loss: 1.1321 - val_acc: 0.6348
2025-10-12 02:19:25,522 - INFO - _models.training_function_executor - Epoch 015/37 - train_loss: 1.0400 - val_loss: 1.0351 - val_acc: 0.6932
2025-10-12 02:19:35,412 - INFO - _models.training_function_executor - Epoch 016/37 - train_loss: 1.0303 - val_loss: 0.9802 - val_acc: 0.7328
2025-10-12 02:19:45,362 - INFO - _models.training_function_executor - Epoch 017/37 - train_loss: 1.0276 - val_loss: 1.2180 - val_acc: 0.5741
2025-10-12 02:19:55,266 - INFO - _models.training_function_executor - Epoch 018/37 - train_loss: 1.0195 - val_loss: 0.9619 - val_acc: 0.7424
2025-10-12 02:20:05,196 - INFO - _models.training_function_executor - Epoch 019/37 - train_loss: 1.0171 - val_loss: 0.9703 - val_acc: 0.7330
2025-10-12 02:20:15,144 - INFO - _models.training_function_executor - Epoch 020/37 - train_loss: 1.0083 - val_loss: 0.9481 - val_acc: 0.7480
2025-10-12 02:20:25,043 - INFO - _models.training_function_executor - Epoch 021/37 - train_loss: 1.0067 - val_loss: 0.9821 - val_acc: 0.7256
2025-10-12 02:20:34,966 - INFO - _models.training_function_executor - Epoch 022/37 - train_loss: 0.9997 - val_loss: 0.9358 - val_acc: 0.7502
2025-10-12 02:20:44,916 - INFO - _models.training_function_executor - Epoch 023/37 - train_loss: 0.9978 - val_loss: 1.0511 - val_acc: 0.6774
2025-10-12 02:20:54,852 - INFO - _models.training_function_executor - Epoch 024/37 - train_loss: 0.9908 - val_loss: 0.9879 - val_acc: 0.7193
2025-10-12 02:21:04,787 - INFO - _models.training_function_executor - Epoch 025/37 - train_loss: 0.9892 - val_loss: 0.9248 - val_acc: 0.7590
2025-10-12 02:21:14,726 - INFO - _models.training_function_executor - Epoch 026/37 - train_loss: 0.9860 - val_loss: 0.9327 - val_acc: 0.7557
2025-10-12 02:21:24,674 - INFO - _models.training_function_executor - Epoch 027/37 - train_loss: 0.9812 - val_loss: 1.0032 - val_acc: 0.7006
2025-10-12 02:21:34,600 - INFO - _models.training_function_executor - Epoch 028/37 - train_loss: 0.9783 - val_loss: 0.9305 - val_acc: 0.7523
2025-10-12 02:21:44,544 - INFO - _models.training_function_executor - Epoch 029/37 - train_loss: 0.9748 - val_loss: 1.0040 - val_acc: 0.7059
2025-10-12 02:21:54,469 - INFO - _models.training_function_executor - Epoch 030/37 - train_loss: 0.9744 - val_loss: 0.9332 - val_acc: 0.7462
2025-10-12 02:22:04,395 - INFO - _models.training_function_executor - Epoch 031/37 - train_loss: 0.9700 - val_loss: 0.9269 - val_acc: 0.7532
2025-10-12 02:22:14,348 - INFO - _models.training_function_executor - Epoch 032/37 - train_loss: 0.9678 - val_loss: 0.9706 - val_acc: 0.7260
2025-10-12 02:22:24,274 - INFO - _models.training_function_executor - Epoch 033/37 - train_loss: 0.9655 - val_loss: 0.9526 - val_acc: 0.7362
2025-10-12 02:22:34,188 - INFO - _models.training_function_executor - Epoch 034/37 - train_loss: 0.9622 - val_loss: 0.9248 - val_acc: 0.7509
2025-10-12 02:22:44,081 - INFO - _models.training_function_executor - Epoch 035/37 - train_loss: 0.9627 - val_loss: 0.9380 - val_acc: 0.7439
2025-10-12 02:22:54,024 - INFO - _models.training_function_executor - Epoch 036/37 - train_loss: 0.9576 - val_loss: 1.0215 - val_acc: 0.6894
2025-10-12 02:23:03,978 - INFO - _models.training_function_executor - Epoch 037/37 - train_loss: 0.9579 - val_loss: 0.9756 - val_acc: 0.7191
2025-10-12 02:23:03,980 - INFO - _models.training_function_executor - Model: 17,005 parameters, 73.1KB storage
2025-10-12 02:23:03,980 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5915285509952015, 1.3781221949390736, 1.2702185496776555, 1.2119636258588289, 1.168265659261676, 1.1426972207340444, 1.124627342080586, 1.1103792704816544, 1.0974877352767947, 1.0843622009988678, 1.0758386048396067, 1.0669567005217888, 1.0569864292849098, 1.0456349521113895, 1.0400012688783653, 1.03029718570539, 1.0276424568518083, 1.0194610276754645, 1.0171347440311365, 1.0083053576015784, 1.0066924058018258, 0.9997240225877385, 0.9977861073286666, 0.9907786086759744, 0.9891665838254595, 0.9860303201665401, 0.9812498686611548, 0.978329121044227, 0.9747600497838956, 0.9743738358238588, 0.9700123333497026, 0.9678243904168847, 0.9655324143674101, 0.9621914974826176, 0.9626880917133549, 0.9576240108277692, 0.9578833097046306], 'val_losses': [1.5003465194989218, 1.3075017623647678, 1.275590902865246, 1.1949817170869816, 1.1534976547816687, 1.1425122968124934, 1.0752053779866422, 1.2830370556319306, 1.0452648118779841, 1.028684994746306, 1.0345427319433542, 1.0337912750945126, 1.0748914856154643, 1.1321461060516977, 1.035148680815131, 0.9801571406306693, 1.2179780175604935, 0.9619038713366409, 0.9702882891273765, 0.9480526037136073, 0.9821410856757666, 0.9357910628580822, 1.0510626348491143, 0.9879371048396894, 0.9247922521393576, 0.9327232654085517, 1.003234828816121, 0.9305447265323242, 1.0039790525985506, 0.9332145642349676, 0.9268680957801533, 0.9705891144371633, 0.9526368861103292, 0.9247628245939522, 0.9380442727308904, 1.0215156541072616, 0.9755973187117131], 'val_acc': [0.39306965348267414, 0.5594154707735387, 0.5451522576128807, 0.6026426321316066, 0.6155932796639833, 0.6163808190409521, 0.6576828841442072, 0.5382394119705985, 0.6871718585929296, 0.7015225761288064, 0.6979348967448372, 0.6928596429821491, 0.6650332516625831, 0.6348442422121106, 0.6932096604830241, 0.7327616380819041, 0.5741162058102905, 0.7423871193559678, 0.7330241512075604, 0.7479873993699685, 0.7255862793139657, 0.7501750087504375, 0.6773713685684284, 0.7192859642982149, 0.7590129506475324, 0.7556877843892195, 0.7006475323766188, 0.7522751137556878, 0.7058977948897445, 0.7462373118655933, 0.7532376618830942, 0.7260238011900595, 0.7361743087154358, 0.7508750437521876, 0.7438746937346867, 0.6894469723486174, 0.7191109555477774], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 9.022004468565623e-05, 'batch_size': 48, 'epochs': 37, 'weight_decay': 2.261956269416809e-05, 'dropout': 0.22280037778852874, 'base_channels': 10, 'temporal_kernel': 7, 'spatial_segments': 20, 'label_smoothing': 0.1310403062812608, 'grad_clip': 0.7272741575850397, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 6263}, 'model_parameter_count': 17005, 'model_storage_size_kb': 73.068359375, 'model_size_validation': 'PASS'}
2025-10-12 02:23:03,980 - INFO - _models.training_function_executor - BO Objective: base=0.7191, size_penalty=0.0000, final=0.7191
2025-10-12 02:23:03,980 - INFO - _models.training_function_executor - Model: 17,005 parameters, 73.1KB (PASS 256KB limit)
2025-10-12 02:23:03,980 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 367.613s
2025-10-12 02:23:04,067 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7191
2025-10-12 02:23:04,067 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.081s
2025-10-12 02:23:04,067 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 9.022004468565623e-05, 'batch_size': np.int64(48), 'epochs': np.int64(37), 'weight_decay': 2.261956269416809e-05, 'dropout': 0.22280037778852874, 'base_channels': np.int64(10), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(20), 'label_smoothing': 0.1310403062812608, 'grad_clip': 0.7272741575850397, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(6263)}, value=0.7191
2025-10-12 02:23:04,067 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 9.022004468565623e-05, 'batch_size': np.int64(48), 'epochs': np.int64(37), 'weight_decay': 2.261956269416809e-05, 'dropout': 0.22280037778852874, 'base_channels': np.int64(10), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(20), 'label_smoothing': 0.1310403062812608, 'grad_clip': 0.7272741575850397, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(6263)} -> 0.7191
2025-10-12 02:23:04,067 - INFO - bo.run_bo - üîçBO Trial 5: Using RF surrogate + Expected Improvement
2025-10-12 02:23:04,067 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 02:23:04,067 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 02:23:04,067 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 02:23:04,067 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00015610555179509047, 'batch_size': 16, 'epochs': 29, 'weight_decay': 6.961399983578005e-05, 'dropout': 0.05163342583765919, 'base_channels': 8, 'temporal_kernel': 9, 'spatial_segments': 20, 'label_smoothing': 0.0253014281337886, 'grad_clip': 0.28121785847794517, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 536}
2025-10-12 02:23:04,068 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00015610555179509047, 'batch_size': 16, 'epochs': 29, 'weight_decay': 6.961399983578005e-05, 'dropout': 0.05163342583765919, 'base_channels': 8, 'temporal_kernel': 9, 'spatial_segments': 20, 'label_smoothing': 0.0253014281337886, 'grad_clip': 0.28121785847794517, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 536}
2025-10-12 02:23:14,354 - INFO - _models.training_function_executor - Epoch 001/29 - train_loss: 1.2357 - val_loss: 1.0232 - val_acc: 0.6175
2025-10-12 02:23:24,556 - INFO - _models.training_function_executor - Epoch 002/29 - train_loss: 0.9783 - val_loss: 0.9495 - val_acc: 0.6327
2025-10-12 02:23:34,722 - INFO - _models.training_function_executor - Epoch 003/29 - train_loss: 0.9164 - val_loss: 0.8507 - val_acc: 0.6996
2025-10-12 02:23:44,900 - INFO - _models.training_function_executor - Epoch 004/29 - train_loss: 0.8680 - val_loss: 0.8932 - val_acc: 0.6705
2025-10-12 02:23:55,117 - INFO - _models.training_function_executor - Epoch 005/29 - train_loss: 0.8371 - val_loss: 0.7795 - val_acc: 0.7193
2025-10-12 02:24:05,323 - INFO - _models.training_function_executor - Epoch 006/29 - train_loss: 0.8135 - val_loss: 0.7510 - val_acc: 0.7370
2025-10-12 02:24:15,477 - INFO - _models.training_function_executor - Epoch 007/29 - train_loss: 0.7907 - val_loss: 0.7490 - val_acc: 0.7348
2025-10-12 02:24:25,622 - INFO - _models.training_function_executor - Epoch 008/29 - train_loss: 0.7747 - val_loss: 0.7793 - val_acc: 0.7204
2025-10-12 02:24:35,766 - INFO - _models.training_function_executor - Epoch 009/29 - train_loss: 0.7609 - val_loss: 0.8792 - val_acc: 0.6799
2025-10-12 02:24:45,915 - INFO - _models.training_function_executor - Epoch 010/29 - train_loss: 0.7521 - val_loss: 0.6928 - val_acc: 0.7576
2025-10-12 02:24:56,013 - INFO - _models.training_function_executor - Epoch 011/29 - train_loss: 0.7318 - val_loss: 0.6706 - val_acc: 0.7673
2025-10-12 02:25:06,198 - INFO - _models.training_function_executor - Epoch 012/29 - train_loss: 0.7308 - val_loss: 0.6624 - val_acc: 0.7747
2025-10-12 02:25:16,444 - INFO - _models.training_function_executor - Epoch 013/29 - train_loss: 0.7149 - val_loss: 0.6528 - val_acc: 0.7799
2025-10-12 02:25:26,610 - INFO - _models.training_function_executor - Epoch 014/29 - train_loss: 0.7103 - val_loss: 0.7079 - val_acc: 0.7519
2025-10-12 02:25:36,790 - INFO - _models.training_function_executor - Epoch 015/29 - train_loss: 0.6997 - val_loss: 0.7020 - val_acc: 0.7580
2025-10-12 02:25:46,932 - INFO - _models.training_function_executor - Epoch 016/29 - train_loss: 0.6936 - val_loss: 0.6600 - val_acc: 0.7770
2025-10-12 02:25:57,155 - INFO - _models.training_function_executor - Epoch 017/29 - train_loss: 0.6895 - val_loss: 0.7840 - val_acc: 0.7195
2025-10-12 02:26:07,344 - INFO - _models.training_function_executor - Epoch 018/29 - train_loss: 0.6789 - val_loss: 0.6496 - val_acc: 0.7810
2025-10-12 02:26:17,512 - INFO - _models.training_function_executor - Epoch 019/29 - train_loss: 0.6772 - val_loss: 0.6889 - val_acc: 0.7574
2025-10-12 02:26:27,738 - INFO - _models.training_function_executor - Epoch 020/29 - train_loss: 0.6714 - val_loss: 0.6322 - val_acc: 0.7867
2025-10-12 02:26:37,927 - INFO - _models.training_function_executor - Epoch 021/29 - train_loss: 0.6698 - val_loss: 0.7207 - val_acc: 0.7431
2025-10-12 02:26:48,105 - INFO - _models.training_function_executor - Epoch 022/29 - train_loss: 0.6621 - val_loss: 0.6386 - val_acc: 0.7846
2025-10-12 02:26:58,294 - INFO - _models.training_function_executor - Epoch 023/29 - train_loss: 0.6618 - val_loss: 0.6568 - val_acc: 0.7741
2025-10-12 02:27:08,467 - INFO - _models.training_function_executor - Epoch 024/29 - train_loss: 0.6551 - val_loss: 0.6334 - val_acc: 0.7905
2025-10-12 02:27:18,624 - INFO - _models.training_function_executor - Epoch 025/29 - train_loss: 0.6534 - val_loss: 0.7454 - val_acc: 0.7379
2025-10-12 02:27:28,817 - INFO - _models.training_function_executor - Epoch 026/29 - train_loss: 0.6484 - val_loss: 0.6785 - val_acc: 0.7711
2025-10-12 02:27:39,029 - INFO - _models.training_function_executor - Epoch 027/29 - train_loss: 0.6455 - val_loss: 0.7059 - val_acc: 0.7565
2025-10-12 02:27:49,216 - INFO - _models.training_function_executor - Epoch 028/29 - train_loss: 0.6444 - val_loss: 0.6364 - val_acc: 0.7905
2025-10-12 02:27:59,385 - INFO - _models.training_function_executor - Epoch 029/29 - train_loss: 0.6410 - val_loss: 0.8326 - val_acc: 0.7029
2025-10-12 02:27:59,387 - INFO - _models.training_function_executor - Model: 11,961 parameters, 51.4KB storage
2025-10-12 02:27:59,387 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2357267418607032, 0.9783451252981713, 0.9164199031938988, 0.8680346170880389, 0.8370599053750557, 0.8134663304875354, 0.7907185131409471, 0.7747444481878044, 0.7608790915872736, 0.7521258328275577, 0.7317922658694137, 0.7307735560947588, 0.7149142843466102, 0.7102914564898267, 0.6997260589897111, 0.6936208934249016, 0.6895423438224001, 0.6788756721058132, 0.6772299066869204, 0.6713549413274625, 0.669795921195584, 0.6621318079497291, 0.6618155362954873, 0.6551263255540165, 0.6533810309974473, 0.6483543176082702, 0.6455222069173999, 0.6443537661390452, 0.6409782197432039], 'val_losses': [1.0231711331012994, 0.9495473641342828, 0.8506891478764498, 0.8931859791550054, 0.7794530938295038, 0.7509660867802697, 0.7489644843963714, 0.779290903165368, 0.8792387493995256, 0.6928075748513034, 0.6706464214678782, 0.6624140471668564, 0.6527886115507434, 0.7079493077455553, 0.7019772629012667, 0.6599656766555007, 0.7839967327640321, 0.6495955531355965, 0.6888997709371428, 0.632152077646409, 0.720667331211209, 0.638636635156791, 0.6567697635596559, 0.6333586313443289, 0.7453700978938708, 0.6784608655452394, 0.7059019462478966, 0.6363505065169917, 0.8326397849977705], 'val_acc': [0.617518375918796, 0.6327441372068603, 0.6995974798739937, 0.6704585229261463, 0.7192859642982149, 0.7370493524676234, 0.7347742387119356, 0.7204235211760588, 0.6799089954497725, 0.7576128806440322, 0.7673258662933147, 0.7746762338116906, 0.7799264963248163, 0.7519250962548127, 0.7579628981449072, 0.7770388519425971, 0.7195484774238712, 0.7809765488274414, 0.7573503675183759, 0.7866643332166608, 0.7430871543577179, 0.7845642282114106, 0.7740637031851593, 0.7905145257262863, 0.737924396219811, 0.7710885544277214, 0.7564753237661883, 0.7905145257262863, 0.7029226461323066], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00015610555179509047, 'batch_size': 16, 'epochs': 29, 'weight_decay': 6.961399983578005e-05, 'dropout': 0.05163342583765919, 'base_channels': 8, 'temporal_kernel': 9, 'spatial_segments': 20, 'label_smoothing': 0.0253014281337886, 'grad_clip': 0.28121785847794517, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 536}, 'model_parameter_count': 11961, 'model_storage_size_kb': 51.394921875, 'model_size_validation': 'PASS'}
2025-10-12 02:27:59,387 - INFO - _models.training_function_executor - BO Objective: base=0.7029, size_penalty=0.0000, final=0.7029
2025-10-12 02:27:59,387 - INFO - _models.training_function_executor - Model: 11,961 parameters, 51.4KB (PASS 256KB limit)
2025-10-12 02:27:59,387 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 295.321s
2025-10-12 02:27:59,471 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7029
2025-10-12 02:27:59,471 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.082s
2025-10-12 02:27:59,471 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 0.00015610555179509047, 'batch_size': np.int64(16), 'epochs': np.int64(29), 'weight_decay': 6.961399983578005e-05, 'dropout': 0.05163342583765919, 'base_channels': np.int64(8), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(20), 'label_smoothing': 0.0253014281337886, 'grad_clip': 0.28121785847794517, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(536)}, value=0.7029
2025-10-12 02:27:59,472 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 0.00015610555179509047, 'batch_size': np.int64(16), 'epochs': np.int64(29), 'weight_decay': 6.961399983578005e-05, 'dropout': 0.05163342583765919, 'base_channels': np.int64(8), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(20), 'label_smoothing': 0.0253014281337886, 'grad_clip': 0.28121785847794517, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(536)} -> 0.7029
2025-10-12 02:27:59,472 - INFO - bo.run_bo - üîçBO Trial 6: Using RF surrogate + Expected Improvement
2025-10-12 02:27:59,472 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 02:27:59,472 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 02:27:59,472 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 02:27:59,472 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.000901604411334716, 'batch_size': 64, 'epochs': 7, 'weight_decay': 6.473030482714825e-05, 'dropout': 0.48962361351748773, 'base_channels': 24, 'temporal_kernel': 9, 'spatial_segments': 25, 'label_smoothing': 0.021600310451549625, 'grad_clip': 0.9656676398010107, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 6167}
2025-10-12 02:27:59,473 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.000901604411334716, 'batch_size': 64, 'epochs': 7, 'weight_decay': 6.473030482714825e-05, 'dropout': 0.48962361351748773, 'base_channels': 24, 'temporal_kernel': 9, 'spatial_segments': 25, 'label_smoothing': 0.021600310451549625, 'grad_clip': 0.9656676398010107, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 6167}
2025-10-12 02:28:16,228 - INFO - _models.training_function_executor - Epoch 001/7 - train_loss: 1.2089 - val_loss: 0.9353 - val_acc: 0.6488
2025-10-12 02:28:32,208 - INFO - _models.training_function_executor - Epoch 002/7 - train_loss: 0.9582 - val_loss: 0.9415 - val_acc: 0.6477
2025-10-12 02:28:48,170 - INFO - _models.training_function_executor - Epoch 003/7 - train_loss: 0.9010 - val_loss: 1.0143 - val_acc: 0.6330
2025-10-12 02:29:04,169 - INFO - _models.training_function_executor - Epoch 004/7 - train_loss: 0.8733 - val_loss: 0.7289 - val_acc: 0.7412
2025-10-12 02:29:20,150 - INFO - _models.training_function_executor - Epoch 005/7 - train_loss: 0.8527 - val_loss: 0.7966 - val_acc: 0.7117
2025-10-12 02:29:36,133 - INFO - _models.training_function_executor - Epoch 006/7 - train_loss: 0.8420 - val_loss: 0.7352 - val_acc: 0.7416
2025-10-12 02:29:52,079 - INFO - _models.training_function_executor - Epoch 007/7 - train_loss: 0.8237 - val_loss: 0.7054 - val_acc: 0.7560
2025-10-12 02:29:52,083 - INFO - _models.training_function_executor - Model: 84,665 parameters, 363.8KB storage
2025-10-12 02:29:52,083 - WARNING - _models.training_function_executor - Model storage 363.8KB exceeds 256KB limit!
2025-10-12 02:29:52,084 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2088888874411123, 0.9582121300038067, 0.900962789450069, 0.8733131573423039, 0.8526871825666498, 0.8419912611432622, 0.8237455844211545], 'val_losses': [0.9353222673824713, 0.94148535656687, 1.0142578847515946, 0.7289429855046258, 0.7965584607194427, 0.7352067713016474, 0.7054274303954007], 'val_acc': [0.6487574378718935, 0.6477073853692684, 0.6330066503325166, 0.7411620581029051, 0.7116730836541827, 0.741599579978999, 0.7560378018900945], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.000901604411334716, 'batch_size': 64, 'epochs': 7, 'weight_decay': 6.473030482714825e-05, 'dropout': 0.48962361351748773, 'base_channels': 24, 'temporal_kernel': 9, 'spatial_segments': 25, 'label_smoothing': 0.021600310451549625, 'grad_clip': 0.9656676398010107, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 6167}, 'model_parameter_count': 84665, 'model_storage_size_kb': 363.79492187500006, 'model_size_validation': 'FAIL'}
2025-10-12 02:29:52,084 - INFO - _models.training_function_executor - BO Objective: base=0.7560, size_penalty=0.2105, final=0.5455
2025-10-12 02:29:52,084 - INFO - _models.training_function_executor - Model: 84,665 parameters, 363.8KB (FAIL 256KB limit)
2025-10-12 02:29:52,084 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 112.612s
2025-10-12 02:29:52,181 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5455
2025-10-12 02:29:52,181 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.082s
2025-10-12 02:29:52,181 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.000901604411334716, 'batch_size': np.int64(64), 'epochs': np.int64(7), 'weight_decay': 6.473030482714825e-05, 'dropout': 0.48962361351748773, 'base_channels': np.int64(24), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(25), 'label_smoothing': 0.021600310451549625, 'grad_clip': 0.9656676398010107, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(6167)}, value=0.5455
2025-10-12 02:29:52,182 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.000901604411334716, 'batch_size': np.int64(64), 'epochs': np.int64(7), 'weight_decay': 6.473030482714825e-05, 'dropout': 0.48962361351748773, 'base_channels': np.int64(24), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(25), 'label_smoothing': 0.021600310451549625, 'grad_clip': 0.9656676398010107, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(6167)} -> 0.5455
2025-10-12 02:29:52,182 - INFO - bo.run_bo - üîçBO Trial 7: Using RF surrogate + Expected Improvement
2025-10-12 02:29:52,182 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 02:29:52,182 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 02:29:52,182 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 02:29:52,182 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0005981896351920309, 'batch_size': 48, 'epochs': 48, 'weight_decay': 7.334814477223572e-05, 'dropout': 0.20449548658650818, 'base_channels': 12, 'temporal_kernel': 3, 'spatial_segments': 25, 'label_smoothing': 0.12870760040175191, 'grad_clip': 0.39880679295899757, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 852}
2025-10-12 02:29:52,183 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0005981896351920309, 'batch_size': 48, 'epochs': 48, 'weight_decay': 7.334814477223572e-05, 'dropout': 0.20449548658650818, 'base_channels': 12, 'temporal_kernel': 3, 'spatial_segments': 25, 'label_smoothing': 0.12870760040175191, 'grad_clip': 0.39880679295899757, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 852}
2025-10-12 02:30:03,023 - INFO - _models.training_function_executor - Epoch 001/48 - train_loss: 1.2793 - val_loss: 1.0821 - val_acc: 0.6502
2025-10-12 02:30:13,533 - INFO - _models.training_function_executor - Epoch 002/48 - train_loss: 1.0944 - val_loss: 1.1359 - val_acc: 0.6320
2025-10-12 02:30:24,014 - INFO - _models.training_function_executor - Epoch 003/48 - train_loss: 1.0384 - val_loss: 1.0856 - val_acc: 0.6563
2025-10-12 02:30:34,543 - INFO - _models.training_function_executor - Epoch 004/48 - train_loss: 0.9967 - val_loss: 0.9477 - val_acc: 0.7395
2025-10-12 02:30:45,059 - INFO - _models.training_function_executor - Epoch 005/48 - train_loss: 0.9735 - val_loss: 1.0361 - val_acc: 0.6925
2025-10-12 02:30:55,532 - INFO - _models.training_function_executor - Epoch 006/48 - train_loss: 0.9584 - val_loss: 0.9506 - val_acc: 0.7376
2025-10-12 02:31:06,020 - INFO - _models.training_function_executor - Epoch 007/48 - train_loss: 0.9469 - val_loss: 0.9278 - val_acc: 0.7551
2025-10-12 02:31:16,508 - INFO - _models.training_function_executor - Epoch 008/48 - train_loss: 0.9383 - val_loss: 0.9139 - val_acc: 0.7535
2025-10-12 02:31:27,020 - INFO - _models.training_function_executor - Epoch 009/48 - train_loss: 0.9312 - val_loss: 0.9038 - val_acc: 0.7640
2025-10-12 02:31:37,511 - INFO - _models.training_function_executor - Epoch 010/48 - train_loss: 0.9254 - val_loss: 0.8942 - val_acc: 0.7699
2025-10-12 02:31:48,026 - INFO - _models.training_function_executor - Epoch 011/48 - train_loss: 0.9175 - val_loss: 0.8792 - val_acc: 0.7833
2025-10-12 02:31:58,504 - INFO - _models.training_function_executor - Epoch 012/48 - train_loss: 0.9137 - val_loss: 0.8640 - val_acc: 0.7898
2025-10-12 02:32:09,004 - INFO - _models.training_function_executor - Epoch 013/48 - train_loss: 0.9103 - val_loss: 0.9134 - val_acc: 0.7612
2025-10-12 02:32:19,492 - INFO - _models.training_function_executor - Epoch 014/48 - train_loss: 0.9052 - val_loss: 0.9387 - val_acc: 0.7458
2025-10-12 02:32:30,031 - INFO - _models.training_function_executor - Epoch 015/48 - train_loss: 0.9025 - val_loss: 0.9043 - val_acc: 0.7622
2025-10-12 02:32:40,541 - INFO - _models.training_function_executor - Epoch 016/48 - train_loss: 0.9005 - val_loss: 0.9154 - val_acc: 0.7580
2025-10-12 02:32:51,072 - INFO - _models.training_function_executor - Epoch 017/48 - train_loss: 0.8939 - val_loss: 0.9798 - val_acc: 0.7289
2025-10-12 02:33:01,557 - INFO - _models.training_function_executor - Epoch 018/48 - train_loss: 0.8921 - val_loss: 0.9004 - val_acc: 0.7672
2025-10-12 02:33:12,044 - INFO - _models.training_function_executor - Epoch 019/48 - train_loss: 0.8923 - val_loss: 0.8528 - val_acc: 0.7941
2025-10-12 02:33:22,591 - INFO - _models.training_function_executor - Epoch 020/48 - train_loss: 0.8879 - val_loss: 0.8640 - val_acc: 0.7855
2025-10-12 02:33:33,135 - INFO - _models.training_function_executor - Epoch 021/48 - train_loss: 0.8852 - val_loss: 0.9038 - val_acc: 0.7658
2025-10-12 02:33:43,676 - INFO - _models.training_function_executor - Epoch 022/48 - train_loss: 0.8862 - val_loss: 0.8528 - val_acc: 0.7980
2025-10-12 02:33:54,187 - INFO - _models.training_function_executor - Epoch 023/48 - train_loss: 0.8808 - val_loss: 0.8852 - val_acc: 0.7752
2025-10-12 02:34:04,733 - INFO - _models.training_function_executor - Epoch 024/48 - train_loss: 0.8793 - val_loss: 0.9723 - val_acc: 0.7407
2025-10-12 02:34:15,259 - INFO - _models.training_function_executor - Epoch 025/48 - train_loss: 0.8779 - val_loss: 0.8553 - val_acc: 0.7938
2025-10-12 02:34:25,760 - INFO - _models.training_function_executor - Epoch 026/48 - train_loss: 0.8783 - val_loss: 0.8612 - val_acc: 0.7931
2025-10-12 02:34:36,280 - INFO - _models.training_function_executor - Epoch 027/48 - train_loss: 0.8769 - val_loss: 0.8637 - val_acc: 0.7885
2025-10-12 02:34:46,808 - INFO - _models.training_function_executor - Epoch 028/48 - train_loss: 0.8742 - val_loss: 0.8947 - val_acc: 0.7629
2025-10-12 02:34:57,330 - INFO - _models.training_function_executor - Epoch 029/48 - train_loss: 0.8724 - val_loss: 0.8597 - val_acc: 0.7886
2025-10-12 02:35:07,879 - INFO - _models.training_function_executor - Epoch 030/48 - train_loss: 0.8716 - val_loss: 0.9391 - val_acc: 0.7543
2025-10-12 02:35:18,405 - INFO - _models.training_function_executor - Epoch 031/48 - train_loss: 0.8694 - val_loss: 0.9162 - val_acc: 0.7652
2025-10-12 02:35:28,907 - INFO - _models.training_function_executor - Epoch 032/48 - train_loss: 0.8678 - val_loss: 0.8875 - val_acc: 0.7784
2025-10-12 02:35:39,410 - INFO - _models.training_function_executor - Epoch 033/48 - train_loss: 0.8673 - val_loss: 0.9802 - val_acc: 0.7315
2025-10-12 02:35:49,893 - INFO - _models.training_function_executor - Epoch 034/48 - train_loss: 0.8654 - val_loss: 0.9975 - val_acc: 0.7080
2025-10-12 02:36:00,426 - INFO - _models.training_function_executor - Epoch 035/48 - train_loss: 0.8649 - val_loss: 1.0260 - val_acc: 0.7011
2025-10-12 02:36:10,952 - INFO - _models.training_function_executor - Epoch 036/48 - train_loss: 0.8644 - val_loss: 0.8849 - val_acc: 0.7682
2025-10-12 02:36:21,490 - INFO - _models.training_function_executor - Epoch 037/48 - train_loss: 0.8646 - val_loss: 0.9315 - val_acc: 0.7495
2025-10-12 02:36:31,997 - INFO - _models.training_function_executor - Epoch 038/48 - train_loss: 0.8599 - val_loss: 0.8630 - val_acc: 0.7939
2025-10-12 02:36:42,527 - INFO - _models.training_function_executor - Epoch 039/48 - train_loss: 0.8595 - val_loss: 0.8685 - val_acc: 0.7858
2025-10-12 02:36:53,069 - INFO - _models.training_function_executor - Epoch 040/48 - train_loss: 0.8589 - val_loss: 0.8443 - val_acc: 0.8030
2025-10-12 02:37:03,551 - INFO - _models.training_function_executor - Epoch 041/48 - train_loss: 0.8598 - val_loss: 0.8550 - val_acc: 0.7945
2025-10-12 02:37:14,034 - INFO - _models.training_function_executor - Epoch 042/48 - train_loss: 0.8577 - val_loss: 0.8616 - val_acc: 0.7929
2025-10-12 02:37:24,555 - INFO - _models.training_function_executor - Epoch 043/48 - train_loss: 0.8552 - val_loss: 1.0076 - val_acc: 0.7139
2025-10-12 02:37:35,037 - INFO - _models.training_function_executor - Epoch 044/48 - train_loss: 0.8516 - val_loss: 0.8692 - val_acc: 0.7861
2025-10-12 02:37:45,591 - INFO - _models.training_function_executor - Epoch 045/48 - train_loss: 0.8534 - val_loss: 1.0554 - val_acc: 0.7118
2025-10-12 02:37:56,101 - INFO - _models.training_function_executor - Epoch 046/48 - train_loss: 0.8507 - val_loss: 0.9059 - val_acc: 0.7686
2025-10-12 02:38:06,598 - INFO - _models.training_function_executor - Epoch 047/48 - train_loss: 0.8491 - val_loss: 0.8971 - val_acc: 0.7807
2025-10-12 02:38:17,110 - INFO - _models.training_function_executor - Epoch 048/48 - train_loss: 0.8490 - val_loss: 0.8483 - val_acc: 0.7939
2025-10-12 02:38:17,112 - INFO - _models.training_function_executor - Model: 23,441 parameters, 100.7KB storage
2025-10-12 02:38:17,112 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2793222763424033, 1.0943577437288994, 1.038446858937314, 0.9967055606975562, 0.9734529576854019, 0.9583993422054602, 0.9468684357323345, 0.9383105294329743, 0.9312440885252413, 0.9254394846234574, 0.9174778043368416, 0.9136768782268173, 0.9102744618453552, 0.9052341924416338, 0.9024537296657342, 0.9005486572126763, 0.8939007286387889, 0.8921404620088144, 0.8922974910817866, 0.8879279544147362, 0.8852046163798964, 0.8862423796857367, 0.8807949776994961, 0.8793075026270807, 0.8778507059213787, 0.8782766939336117, 0.8769040277549175, 0.8742207087834565, 0.8723916454794193, 0.8715904289331726, 0.8693910592662983, 0.8677851632419983, 0.8673039638875121, 0.8653706088740383, 0.8649141294454669, 0.8643569233620296, 0.8645939041485852, 0.8599341905822193, 0.8595302522829207, 0.858948480073163, 0.8598174472392586, 0.8577097985224579, 0.855244693073477, 0.8516330195758407, 0.8533621569342408, 0.8507427390029808, 0.8490939639563488, 0.8490337775351912], 'val_losses': [1.0821170647493976, 1.1359172645548152, 1.0856469198670218, 0.9477226259327035, 1.0360714252236258, 0.9505716287718396, 0.9277700428408595, 0.9138912196171046, 0.9037875674761464, 0.8942064365015441, 0.8791872197445932, 0.8639911551303616, 0.9134287038465292, 0.9387143075069765, 0.9042872310644436, 0.9153584985829835, 0.9797603595828442, 0.9004385233300943, 0.8528017014275492, 0.8639927025353695, 0.9038033179983126, 0.8527945148223006, 0.8852097228727518, 0.9723203606149889, 0.8552696822947208, 0.8611632792274561, 0.8636803292376952, 0.8947220514777827, 0.8597009317375038, 0.9390727357093296, 0.916170440856752, 0.8874837216231053, 0.980244393610729, 0.9974740130065995, 1.0259795989613036, 0.8849060602191449, 0.9314900497310346, 0.8630172952639293, 0.8684904419921018, 0.84425603997094, 0.8549965041101835, 0.8615668322141244, 1.0076010379918106, 0.8692394299735796, 1.055383277431751, 0.905876805388431, 0.8971087164423205, 0.8483097818417694], 'val_acc': [0.6501575078753937, 0.6319565978298914, 0.656282814140707, 0.7394994749737487, 0.692509625481274, 0.7375743787189359, 0.7550752537626881, 0.7535001750087504, 0.7640007000350018, 0.7698634931746587, 0.7832516625831292, 0.7898144907245362, 0.7612005600280014, 0.7457997899894995, 0.7621631081554078, 0.7579628981449072, 0.7289114455722786, 0.7672383619180959, 0.7941022051102555, 0.785526776338817, 0.765750787539377, 0.7980399019950998, 0.7752012600630032, 0.7407245362268113, 0.7937521876093805, 0.7931396569828492, 0.7885019250962548, 0.7628631431571579, 0.7885894294714736, 0.7542877143857193, 0.7652257612880644, 0.7783514175708786, 0.7315365768288414, 0.7079978998949947, 0.7010850542527126, 0.7682009100455023, 0.7494749737486874, 0.793927196359818, 0.7857892894644732, 0.8030276513825692, 0.7944522226111306, 0.7928771438571929, 0.7139481974098705, 0.7860518025901295, 0.7117605880294015, 0.7686384319215961, 0.7807140357017851, 0.793927196359818], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0005981896351920309, 'batch_size': 48, 'epochs': 48, 'weight_decay': 7.334814477223572e-05, 'dropout': 0.20449548658650818, 'base_channels': 12, 'temporal_kernel': 3, 'spatial_segments': 25, 'label_smoothing': 0.12870760040175191, 'grad_clip': 0.39880679295899757, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 852}, 'model_parameter_count': 23441, 'model_storage_size_kb': 100.72304687500001, 'model_size_validation': 'PASS'}
2025-10-12 02:38:17,112 - INFO - _models.training_function_executor - BO Objective: base=0.7939, size_penalty=0.0000, final=0.7939
2025-10-12 02:38:17,112 - INFO - _models.training_function_executor - Model: 23,441 parameters, 100.7KB (PASS 256KB limit)
2025-10-12 02:38:17,113 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 504.931s
2025-10-12 02:38:17,203 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7939
2025-10-12 02:38:17,203 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.085s
2025-10-12 02:38:17,203 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 0.0005981896351920309, 'batch_size': np.int64(48), 'epochs': np.int64(48), 'weight_decay': 7.334814477223572e-05, 'dropout': 0.20449548658650818, 'base_channels': np.int64(12), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(25), 'label_smoothing': 0.12870760040175191, 'grad_clip': 0.39880679295899757, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(852)}, value=0.7939
2025-10-12 02:38:17,203 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 0.0005981896351920309, 'batch_size': np.int64(48), 'epochs': np.int64(48), 'weight_decay': 7.334814477223572e-05, 'dropout': 0.20449548658650818, 'base_channels': np.int64(12), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(25), 'label_smoothing': 0.12870760040175191, 'grad_clip': 0.39880679295899757, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(852)} -> 0.7939
2025-10-12 02:38:17,203 - INFO - bo.run_bo - üîçBO Trial 8: Using RF surrogate + Expected Improvement
2025-10-12 02:38:17,203 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 02:38:17,203 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 02:38:17,203 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 02:38:17,203 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 4.801015947905565e-05, 'batch_size': 64, 'epochs': 39, 'weight_decay': 0.0006415073396746449, 'dropout': 0.27661569013751675, 'base_channels': 23, 'temporal_kernel': 7, 'spatial_segments': 60, 'label_smoothing': 0.04424296629487204, 'grad_clip': 0.2948750921538163, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4031}
2025-10-12 02:38:17,204 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 4.801015947905565e-05, 'batch_size': 64, 'epochs': 39, 'weight_decay': 0.0006415073396746449, 'dropout': 0.27661569013751675, 'base_channels': 23, 'temporal_kernel': 7, 'spatial_segments': 60, 'label_smoothing': 0.04424296629487204, 'grad_clip': 0.2948750921538163, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4031}
2025-10-12 02:38:33,590 - INFO - _models.training_function_executor - Epoch 001/39 - train_loss: 1.7775 - val_loss: 1.5638 - val_acc: 0.3616
2025-10-12 02:38:49,122 - INFO - _models.training_function_executor - Epoch 002/39 - train_loss: 1.4596 - val_loss: 1.3452 - val_acc: 0.5109
2025-10-12 02:39:04,650 - INFO - _models.training_function_executor - Epoch 003/39 - train_loss: 1.3071 - val_loss: 1.3745 - val_acc: 0.4838
2025-10-12 02:39:20,227 - INFO - _models.training_function_executor - Epoch 004/39 - train_loss: 1.2069 - val_loss: 1.2327 - val_acc: 0.5354
2025-10-12 02:39:35,840 - INFO - _models.training_function_executor - Epoch 005/39 - train_loss: 1.1365 - val_loss: 1.5353 - val_acc: 0.3666
2025-10-12 02:39:51,401 - INFO - _models.training_function_executor - Epoch 006/39 - train_loss: 1.0915 - val_loss: 1.0172 - val_acc: 0.6214
2025-10-12 02:40:06,987 - INFO - _models.training_function_executor - Epoch 007/39 - train_loss: 1.0494 - val_loss: 1.2081 - val_acc: 0.5460
2025-10-12 02:40:22,573 - INFO - _models.training_function_executor - Epoch 008/39 - train_loss: 1.0249 - val_loss: 1.0002 - val_acc: 0.6243
2025-10-12 02:40:38,146 - INFO - _models.training_function_executor - Epoch 009/39 - train_loss: 1.0003 - val_loss: 1.2701 - val_acc: 0.5257
2025-10-12 02:40:53,701 - INFO - _models.training_function_executor - Epoch 010/39 - train_loss: 0.9835 - val_loss: 1.4141 - val_acc: 0.4877
2025-10-12 02:41:09,268 - INFO - _models.training_function_executor - Epoch 011/39 - train_loss: 0.9644 - val_loss: 0.9898 - val_acc: 0.6453
2025-10-12 02:41:24,864 - INFO - _models.training_function_executor - Epoch 012/39 - train_loss: 0.9474 - val_loss: 0.9809 - val_acc: 0.6586
2025-10-12 02:41:40,429 - INFO - _models.training_function_executor - Epoch 013/39 - train_loss: 0.9348 - val_loss: 0.9958 - val_acc: 0.6452
2025-10-12 02:41:56,022 - INFO - _models.training_function_executor - Epoch 014/39 - train_loss: 0.9224 - val_loss: 1.4629 - val_acc: 0.4480
2025-10-12 02:42:11,634 - INFO - _models.training_function_executor - Epoch 015/39 - train_loss: 0.9065 - val_loss: 1.1856 - val_acc: 0.5631
2025-10-12 02:42:27,208 - INFO - _models.training_function_executor - Epoch 016/39 - train_loss: 0.9004 - val_loss: 1.2402 - val_acc: 0.5297
2025-10-12 02:42:42,800 - INFO - _models.training_function_executor - Epoch 017/39 - train_loss: 0.8872 - val_loss: 1.2119 - val_acc: 0.5507
2025-10-12 02:42:58,406 - INFO - _models.training_function_executor - Epoch 018/39 - train_loss: 0.8775 - val_loss: 0.8051 - val_acc: 0.7362
2025-10-12 02:43:13,947 - INFO - _models.training_function_executor - Epoch 019/39 - train_loss: 0.8646 - val_loss: 1.1228 - val_acc: 0.5671
2025-10-12 02:43:29,545 - INFO - _models.training_function_executor - Epoch 020/39 - train_loss: 0.8583 - val_loss: 1.3161 - val_acc: 0.5275
2025-10-12 02:43:45,135 - INFO - _models.training_function_executor - Epoch 021/39 - train_loss: 0.8500 - val_loss: 0.9962 - val_acc: 0.6490
2025-10-12 02:44:00,708 - INFO - _models.training_function_executor - Epoch 022/39 - train_loss: 0.8441 - val_loss: 1.1907 - val_acc: 0.5703
2025-10-12 02:44:16,260 - INFO - _models.training_function_executor - Epoch 023/39 - train_loss: 0.8354 - val_loss: 1.0976 - val_acc: 0.6184
2025-10-12 02:44:31,829 - INFO - _models.training_function_executor - Epoch 024/39 - train_loss: 0.8325 - val_loss: 1.1461 - val_acc: 0.5808
2025-10-12 02:44:47,368 - INFO - _models.training_function_executor - Epoch 025/39 - train_loss: 0.8220 - val_loss: 0.8420 - val_acc: 0.7097
2025-10-12 02:45:02,919 - INFO - _models.training_function_executor - Epoch 026/39 - train_loss: 0.8182 - val_loss: 1.0172 - val_acc: 0.6437
2025-10-12 02:45:18,491 - INFO - _models.training_function_executor - Epoch 027/39 - train_loss: 0.8152 - val_loss: 0.7611 - val_acc: 0.7506
2025-10-12 02:45:34,041 - INFO - _models.training_function_executor - Epoch 028/39 - train_loss: 0.8124 - val_loss: 0.7529 - val_acc: 0.7579
2025-10-12 02:45:49,643 - INFO - _models.training_function_executor - Epoch 029/39 - train_loss: 0.8087 - val_loss: 0.7611 - val_acc: 0.7529
2025-10-12 02:46:05,246 - INFO - _models.training_function_executor - Epoch 030/39 - train_loss: 0.8029 - val_loss: 0.8968 - val_acc: 0.6989
2025-10-12 02:46:20,852 - INFO - _models.training_function_executor - Epoch 031/39 - train_loss: 0.7936 - val_loss: 0.8703 - val_acc: 0.7069
2025-10-12 02:46:36,442 - INFO - _models.training_function_executor - Epoch 032/39 - train_loss: 0.7959 - val_loss: 0.8880 - val_acc: 0.6916
2025-10-12 02:46:52,063 - INFO - _models.training_function_executor - Epoch 033/39 - train_loss: 0.7911 - val_loss: 0.9008 - val_acc: 0.6858
2025-10-12 02:47:07,678 - INFO - _models.training_function_executor - Epoch 034/39 - train_loss: 0.7867 - val_loss: 0.9589 - val_acc: 0.6649
2025-10-12 02:47:23,232 - INFO - _models.training_function_executor - Epoch 035/39 - train_loss: 0.7838 - val_loss: 0.7519 - val_acc: 0.7501
2025-10-12 02:47:38,828 - INFO - _models.training_function_executor - Epoch 036/39 - train_loss: 0.7804 - val_loss: 0.8559 - val_acc: 0.7057
2025-10-12 02:47:54,443 - INFO - _models.training_function_executor - Epoch 037/39 - train_loss: 0.7752 - val_loss: 0.7991 - val_acc: 0.7342
2025-10-12 02:48:10,049 - INFO - _models.training_function_executor - Epoch 038/39 - train_loss: 0.7721 - val_loss: 0.7979 - val_acc: 0.7336
2025-10-12 02:48:25,670 - INFO - _models.training_function_executor - Epoch 039/39 - train_loss: 0.7724 - val_loss: 0.8511 - val_acc: 0.7134
2025-10-12 02:48:25,675 - INFO - _models.training_function_executor - Model: 81,165 parameters, 174.4KB storage
2025-10-12 02:48:25,675 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.777511614538132, 1.459614094921789, 1.3071463826155805, 1.2068817862523031, 1.13648839154609, 1.0915390295626861, 1.049356953931681, 1.024850053974161, 1.0003069528633788, 0.983512806400036, 0.9644179812126907, 0.9474433369681599, 0.9347549058525638, 0.9224359169263375, 0.9065137605046242, 0.9003735249135141, 0.8872254741830262, 0.877459568621856, 0.8646456891521525, 0.8582674215254685, 0.8500438668655272, 0.8441201405254828, 0.8354489503726285, 0.8325420376676173, 0.8220303083242216, 0.8181780288801103, 0.8151872106936998, 0.8124471406733026, 0.8087090374416182, 0.8029087990115562, 0.79359604025538, 0.7958580015587732, 0.7910708496943611, 0.7866751327354423, 0.7837966362788288, 0.7803555943976761, 0.7751946102124976, 0.7720680899414768, 0.7724420012900326], 'val_losses': [1.5638135911953546, 1.3451872918836962, 1.3744675388359548, 1.232657880269025, 1.5352655190206468, 1.0171829270532091, 1.208120239419373, 1.000237902895654, 1.27008514730589, 1.4141168228846395, 0.9898414527531224, 0.9808645195004654, 0.9957917623683461, 1.4628884690100803, 1.185580527694817, 1.2402207007723585, 1.2118567299667589, 0.8051030847172576, 1.1228175416124588, 1.3160869161023683, 0.9962064526821293, 1.1907332382879767, 1.0976102467304265, 1.1460690366917237, 0.8420201570870036, 1.0171577620848435, 0.761138558471207, 0.7528924727548366, 0.7610950929158043, 0.8968159623775275, 0.8702943988058339, 0.8880098835755196, 0.9008322252357678, 0.9588581300674721, 0.7518593919915589, 0.8559266353012341, 0.7990919289824259, 0.7978785828480905, 0.8511188284976106], 'val_acc': [0.3615680784039202, 0.5109380469023451, 0.4838116905845292, 0.5353517675883794, 0.3666433321666083, 0.6213685684284215, 0.5460273013650683, 0.6243437171858593, 0.5257262863143157, 0.4876618830941547, 0.6453447672383619, 0.6585579278963948, 0.6451697584879243, 0.448022401120056, 0.5630906545327267, 0.52966398319916, 0.5506650332516626, 0.7361743087154358, 0.5671158557927897, 0.527476373818691, 0.6490199509975498, 0.5702660133006651, 0.6183934196709836, 0.5807665383269164, 0.7096604830241512, 0.6436821841092054, 0.7506125306265313, 0.7578753937696885, 0.7528876443822191, 0.6988974448722436, 0.7068603430171508, 0.6916345817290864, 0.6857717885894294, 0.6648582429121456, 0.7500875043752188, 0.705722786139307, 0.7341617080854043, 0.7336366818340917, 0.7134231711585579], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 4.801015947905565e-05, 'batch_size': 64, 'epochs': 39, 'weight_decay': 0.0006415073396746449, 'dropout': 0.27661569013751675, 'base_channels': 23, 'temporal_kernel': 7, 'spatial_segments': 60, 'label_smoothing': 0.04424296629487204, 'grad_clip': 0.2948750921538163, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4031}, 'model_parameter_count': 81165, 'model_storage_size_kb': 174.3779296875, 'model_size_validation': 'PASS'}
2025-10-12 02:48:25,676 - INFO - _models.training_function_executor - BO Objective: base=0.7134, size_penalty=0.0000, final=0.7134
2025-10-12 02:48:25,676 - INFO - _models.training_function_executor - Model: 81,165 parameters, 174.4KB (PASS 256KB limit)
2025-10-12 02:48:25,676 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 608.473s
2025-10-12 02:48:25,775 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7134
2025-10-12 02:48:25,775 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.086s
2025-10-12 02:48:25,775 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 4.801015947905565e-05, 'batch_size': np.int64(64), 'epochs': np.int64(39), 'weight_decay': 0.0006415073396746449, 'dropout': 0.27661569013751675, 'base_channels': np.int64(23), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(60), 'label_smoothing': 0.04424296629487204, 'grad_clip': 0.2948750921538163, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4031)}, value=0.7134
2025-10-12 02:48:25,775 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 4.801015947905565e-05, 'batch_size': np.int64(64), 'epochs': np.int64(39), 'weight_decay': 0.0006415073396746449, 'dropout': 0.27661569013751675, 'base_channels': np.int64(23), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(60), 'label_smoothing': 0.04424296629487204, 'grad_clip': 0.2948750921538163, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4031)} -> 0.7134
2025-10-12 02:48:25,775 - INFO - bo.run_bo - üîçBO Trial 9: Using RF surrogate + Expected Improvement
2025-10-12 02:48:25,775 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 02:48:25,775 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 02:48:25,775 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 02:48:25,776 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.013557254114185268, 'batch_size': 32, 'epochs': 40, 'weight_decay': 2.5982240697154045e-05, 'dropout': 0.037036903703656095, 'base_channels': 11, 'temporal_kernel': 9, 'spatial_segments': 250, 'label_smoothing': 0.08615866105499609, 'grad_clip': 0.06908208265622741, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 6634}
2025-10-12 02:48:25,777 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.013557254114185268, 'batch_size': 32, 'epochs': 40, 'weight_decay': 2.5982240697154045e-05, 'dropout': 0.037036903703656095, 'base_channels': 11, 'temporal_kernel': 9, 'spatial_segments': 250, 'label_smoothing': 0.08615866105499609, 'grad_clip': 0.06908208265622741, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 6634}
2025-10-12 02:48:36,744 - INFO - _models.training_function_executor - Epoch 001/40 - train_loss: 1.4303 - val_loss: 1.3191 - val_acc: 0.5252
2025-10-12 02:48:47,412 - INFO - _models.training_function_executor - Epoch 002/40 - train_loss: 1.3104 - val_loss: 1.2785 - val_acc: 0.6019
2025-10-12 02:48:58,107 - INFO - _models.training_function_executor - Epoch 003/40 - train_loss: 1.2720 - val_loss: 1.4402 - val_acc: 0.5857
2025-10-12 02:49:08,817 - INFO - _models.training_function_executor - Epoch 004/40 - train_loss: 1.2540 - val_loss: 1.2173 - val_acc: 0.6243
2025-10-12 02:49:19,534 - INFO - _models.training_function_executor - Epoch 005/40 - train_loss: 1.1900 - val_loss: 1.1757 - val_acc: 0.6640
2025-10-12 02:49:30,224 - INFO - _models.training_function_executor - Epoch 006/40 - train_loss: 1.1867 - val_loss: 1.2697 - val_acc: 0.6683
2025-10-12 02:49:40,931 - INFO - _models.training_function_executor - Epoch 007/40 - train_loss: 1.1653 - val_loss: 1.1096 - val_acc: 0.6586
2025-10-12 02:49:51,596 - INFO - _models.training_function_executor - Epoch 008/40 - train_loss: 1.1550 - val_loss: 1.1838 - val_acc: 0.6801
2025-10-12 02:50:02,270 - INFO - _models.training_function_executor - Epoch 009/40 - train_loss: 1.1586 - val_loss: 1.1388 - val_acc: 0.7160
2025-10-12 02:50:12,956 - INFO - _models.training_function_executor - Epoch 010/40 - train_loss: 1.1612 - val_loss: 1.3727 - val_acc: 0.5964
2025-10-12 02:50:23,657 - INFO - _models.training_function_executor - Epoch 011/40 - train_loss: 1.1432 - val_loss: 1.3742 - val_acc: 0.6093
2025-10-12 02:50:34,345 - INFO - _models.training_function_executor - Epoch 012/40 - train_loss: 1.1281 - val_loss: 1.3265 - val_acc: 0.6719
2025-10-12 02:50:45,043 - INFO - _models.training_function_executor - Epoch 013/40 - train_loss: 1.1432 - val_loss: 1.2801 - val_acc: 0.7245
2025-10-12 02:50:55,742 - INFO - _models.training_function_executor - Epoch 014/40 - train_loss: 1.1383 - val_loss: 1.0829 - val_acc: 0.7123
2025-10-12 02:51:06,460 - INFO - _models.training_function_executor - Epoch 015/40 - train_loss: 1.1200 - val_loss: 1.0149 - val_acc: 0.7362
2025-10-12 02:51:17,116 - INFO - _models.training_function_executor - Epoch 016/40 - train_loss: 1.1096 - val_loss: 0.9863 - val_acc: 0.7442
2025-10-12 02:51:27,827 - INFO - _models.training_function_executor - Epoch 017/40 - train_loss: 1.1233 - val_loss: 1.1305 - val_acc: 0.6943
2025-10-12 02:51:38,570 - INFO - _models.training_function_executor - Epoch 018/40 - train_loss: 1.1373 - val_loss: 1.1687 - val_acc: 0.7288
2025-10-12 02:51:49,268 - INFO - _models.training_function_executor - Epoch 019/40 - train_loss: 1.1224 - val_loss: 1.5349 - val_acc: 0.7160
2025-10-12 02:51:59,957 - INFO - _models.training_function_executor - Epoch 020/40 - train_loss: 1.1080 - val_loss: 1.1837 - val_acc: 0.7212
2025-10-12 02:52:10,675 - INFO - _models.training_function_executor - Epoch 021/40 - train_loss: 1.1216 - val_loss: 0.9689 - val_acc: 0.7474
2025-10-12 02:52:21,351 - INFO - _models.training_function_executor - Epoch 022/40 - train_loss: 1.1494 - val_loss: 1.2405 - val_acc: 0.6663
2025-10-12 02:52:32,057 - INFO - _models.training_function_executor - Epoch 023/40 - train_loss: 1.0990 - val_loss: 1.0298 - val_acc: 0.7354
2025-10-12 02:52:42,712 - INFO - _models.training_function_executor - Epoch 024/40 - train_loss: 1.1476 - val_loss: 1.3561 - val_acc: 0.7132
2025-10-12 02:52:53,374 - INFO - _models.training_function_executor - Epoch 025/40 - train_loss: 1.1275 - val_loss: 1.3965 - val_acc: 0.6866
2025-10-12 02:53:04,082 - INFO - _models.training_function_executor - Epoch 026/40 - train_loss: 1.1336 - val_loss: 2.0208 - val_acc: 0.7005
2025-10-12 02:53:14,788 - INFO - _models.training_function_executor - Epoch 027/40 - train_loss: 1.1117 - val_loss: 1.1107 - val_acc: 0.6702
2025-10-12 02:53:25,488 - INFO - _models.training_function_executor - Epoch 028/40 - train_loss: 1.1227 - val_loss: 1.0873 - val_acc: 0.7340
2025-10-12 02:53:36,189 - INFO - _models.training_function_executor - Epoch 029/40 - train_loss: 1.1186 - val_loss: 1.3991 - val_acc: 0.6936
2025-10-12 02:53:46,890 - INFO - _models.training_function_executor - Epoch 030/40 - train_loss: 1.1334 - val_loss: 1.3881 - val_acc: 0.7321
2025-10-12 02:53:57,538 - INFO - _models.training_function_executor - Epoch 031/40 - train_loss: 1.1973 - val_loss: 2.4274 - val_acc: 0.7064
2025-10-12 02:54:08,230 - INFO - _models.training_function_executor - Epoch 032/40 - train_loss: 1.1589 - val_loss: 1.3334 - val_acc: 0.7467
2025-10-12 02:54:18,906 - INFO - _models.training_function_executor - Epoch 033/40 - train_loss: 1.1582 - val_loss: 1.2815 - val_acc: 0.7446
2025-10-12 02:54:29,595 - INFO - _models.training_function_executor - Epoch 034/40 - train_loss: 1.1577 - val_loss: 1.1235 - val_acc: 0.7568
2025-10-12 02:54:40,275 - INFO - _models.training_function_executor - Epoch 035/40 - train_loss: 1.1275 - val_loss: 1.4613 - val_acc: 0.7480
2025-10-12 02:54:50,961 - INFO - _models.training_function_executor - Epoch 036/40 - train_loss: 1.2581 - val_loss: 0.9721 - val_acc: 0.7612
2025-10-12 02:55:01,663 - INFO - _models.training_function_executor - Epoch 037/40 - train_loss: 1.1720 - val_loss: 0.9898 - val_acc: 0.7547
2025-10-12 02:55:12,387 - INFO - _models.training_function_executor - Epoch 038/40 - train_loss: 1.1935 - val_loss: 1.2777 - val_acc: 0.7428
2025-10-12 02:55:23,097 - INFO - _models.training_function_executor - Epoch 039/40 - train_loss: 1.2323 - val_loss: 1.0769 - val_acc: 0.7589
2025-10-12 02:55:33,795 - INFO - _models.training_function_executor - Epoch 040/40 - train_loss: 1.1133 - val_loss: 1.2020 - val_acc: 0.7229
2025-10-12 02:55:33,797 - INFO - _models.training_function_executor - Model: 42,201 parameters, 181.3KB storage
2025-10-12 02:55:33,797 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4302811710242838, 1.3104379328556481, 1.272016585603393, 1.2539699148539276, 1.1899733402364354, 1.1866662872809817, 1.1652824590787798, 1.1550244008656103, 1.158579545626909, 1.1612386269964954, 1.1432041276114613, 1.1281146284663515, 1.1432487061276568, 1.138314543548146, 1.1200021438595296, 1.109585393192804, 1.123279735764132, 1.1372981613901556, 1.1224248658371505, 1.108027204709492, 1.1216148980689458, 1.1493909879501858, 1.0990094139645223, 1.1475696447724264, 1.127529933480145, 1.1335657408991018, 1.1117228217420354, 1.1227081305170377, 1.118555553108819, 1.133369286702069, 1.1973008900453128, 1.1589068002245164, 1.1581868308592727, 1.157660583203015, 1.1274913537531497, 1.2580763692825794, 1.1720450300414287, 1.1935043905346303, 1.232252188733628, 1.1132750282931836], 'val_losses': [1.319112772035315, 1.2785453478439646, 1.4402053972036637, 1.217294075604206, 1.175694483203574, 1.2697268514145827, 1.1096277002024826, 1.1837787134145832, 1.1388020265924375, 1.3727425393584227, 1.374186179147219, 1.3264586564582421, 1.280106753622021, 1.0828845713328012, 1.0149024323145326, 0.9862715620488857, 1.1305325615435244, 1.1686627911987277, 1.534947651017576, 1.1837289674865394, 0.9688713835551683, 1.2404733557863006, 1.0297824789854375, 1.356146675412956, 1.3964868653767752, 2.020794540476791, 1.1106917280645108, 1.0872952881750628, 1.399091752375762, 1.3881220810889865, 2.42736278651142, 1.3333606695770008, 1.2814997253319498, 1.1234725544742241, 1.4613323206245628, 0.9721327476831929, 0.989755965109509, 1.2777196317858992, 1.0768756728761464, 1.202003898364412], 'val_acc': [0.5252012600630032, 0.6019425971298565, 0.585666783339167, 0.6242562128106406, 0.663983199159958, 0.6682709135456772, 0.6586454322716135, 0.68008400420021, 0.7160483024151207, 0.5964298214910746, 0.6092929646482325, 0.6719460973048652, 0.7245362268113406, 0.712285614280714, 0.7361743087154358, 0.7442247112355618, 0.694347217360868, 0.7288239411970598, 0.715960798039902, 0.7212110605530276, 0.7473748687434372, 0.6662583129156457, 0.7353867693384669, 0.7132481624081204, 0.686646832341617, 0.7004725236261813, 0.67019600980049, 0.7339866993349667, 0.6935596779838992, 0.7321491074553728, 0.706422821141057, 0.7466748337416871, 0.7445747287364368, 0.7568253412670634, 0.7479873993699685, 0.7612005600280014, 0.7547252362618131, 0.7428246412320616, 0.7589254462723136, 0.7228736436821841], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.013557254114185268, 'batch_size': 32, 'epochs': 40, 'weight_decay': 2.5982240697154045e-05, 'dropout': 0.037036903703656095, 'base_channels': 11, 'temporal_kernel': 9, 'spatial_segments': 250, 'label_smoothing': 0.08615866105499609, 'grad_clip': 0.06908208265622741, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 6634}, 'model_parameter_count': 42201, 'model_storage_size_kb': 181.33242187500002, 'model_size_validation': 'PASS'}
2025-10-12 02:55:33,797 - INFO - _models.training_function_executor - BO Objective: base=0.7229, size_penalty=0.0000, final=0.7229
2025-10-12 02:55:33,797 - INFO - _models.training_function_executor - Model: 42,201 parameters, 181.3KB (PASS 256KB limit)
2025-10-12 02:55:33,797 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 428.022s
2025-10-12 02:55:33,890 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7229
2025-10-12 02:55:33,890 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.089s
2025-10-12 02:55:33,890 - INFO - bo.run_bo - Recorded observation #9: hparams={'lr': 0.013557254114185268, 'batch_size': np.int64(32), 'epochs': np.int64(40), 'weight_decay': 2.5982240697154045e-05, 'dropout': 0.037036903703656095, 'base_channels': np.int64(11), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(250), 'label_smoothing': 0.08615866105499609, 'grad_clip': 0.06908208265622741, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(6634)}, value=0.7229
2025-10-12 02:55:33,890 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'lr': 0.013557254114185268, 'batch_size': np.int64(32), 'epochs': np.int64(40), 'weight_decay': 2.5982240697154045e-05, 'dropout': 0.037036903703656095, 'base_channels': np.int64(11), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(250), 'label_smoothing': 0.08615866105499609, 'grad_clip': 0.06908208265622741, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(6634)} -> 0.7229
2025-10-12 02:55:33,890 - INFO - bo.run_bo - üîçBO Trial 10: Using RF surrogate + Expected Improvement
2025-10-12 02:55:33,890 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 02:55:33,890 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 02:55:33,890 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 02:55:33,890 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003054307379632007, 'batch_size': 8, 'epochs': 49, 'weight_decay': 1.7353547103127357e-05, 'dropout': 0.14259926808052784, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.03176222985899649, 'grad_clip': 0.08646275170667207, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6468}
2025-10-12 02:55:33,891 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003054307379632007, 'batch_size': 8, 'epochs': 49, 'weight_decay': 1.7353547103127357e-05, 'dropout': 0.14259926808052784, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.03176222985899649, 'grad_clip': 0.08646275170667207, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6468}
2025-10-12 02:55:51,504 - INFO - _models.training_function_executor - Epoch 001/49 - train_loss: 1.2894 - val_loss: 1.2114 - val_acc: 0.5463
2025-10-12 02:56:09,103 - INFO - _models.training_function_executor - Epoch 002/49 - train_loss: 1.0916 - val_loss: 0.9429 - val_acc: 0.6949
2025-10-12 02:56:26,722 - INFO - _models.training_function_executor - Epoch 003/49 - train_loss: 1.0233 - val_loss: 1.1266 - val_acc: 0.6215
2025-10-12 02:56:44,279 - INFO - _models.training_function_executor - Epoch 004/49 - train_loss: 0.9778 - val_loss: 1.0851 - val_acc: 0.6663
2025-10-12 02:57:01,847 - INFO - _models.training_function_executor - Epoch 005/49 - train_loss: 0.9521 - val_loss: 0.8643 - val_acc: 0.7254
2025-10-12 02:57:19,460 - INFO - _models.training_function_executor - Epoch 006/49 - train_loss: 0.9434 - val_loss: 0.9541 - val_acc: 0.7057
2025-10-12 02:57:37,052 - INFO - _models.training_function_executor - Epoch 007/49 - train_loss: 0.9414 - val_loss: 0.8249 - val_acc: 0.7467
2025-10-12 02:57:54,640 - INFO - _models.training_function_executor - Epoch 008/49 - train_loss: 0.9373 - val_loss: 0.8372 - val_acc: 0.7341
2025-10-12 02:58:12,276 - INFO - _models.training_function_executor - Epoch 009/49 - train_loss: 0.9284 - val_loss: 1.0075 - val_acc: 0.6769
2025-10-12 02:58:29,896 - INFO - _models.training_function_executor - Epoch 010/49 - train_loss: 0.9302 - val_loss: 1.1003 - val_acc: 0.6157
2025-10-12 02:58:47,445 - INFO - _models.training_function_executor - Epoch 011/49 - train_loss: 0.8946 - val_loss: 1.0963 - val_acc: 0.7125
2025-10-12 02:59:05,044 - INFO - _models.training_function_executor - Epoch 012/49 - train_loss: 0.9041 - val_loss: 0.9126 - val_acc: 0.6925
2025-10-12 02:59:22,591 - INFO - _models.training_function_executor - Epoch 013/49 - train_loss: 0.8944 - val_loss: 0.8332 - val_acc: 0.7644
2025-10-12 02:59:40,158 - INFO - _models.training_function_executor - Epoch 014/49 - train_loss: 0.9124 - val_loss: 0.8887 - val_acc: 0.7412
2025-10-12 02:59:57,709 - INFO - _models.training_function_executor - Epoch 015/49 - train_loss: 0.8843 - val_loss: 0.9001 - val_acc: 0.7401
2025-10-12 03:00:15,268 - INFO - _models.training_function_executor - Epoch 016/49 - train_loss: 0.8726 - val_loss: 0.8915 - val_acc: 0.7320
2025-10-12 03:00:32,817 - INFO - _models.training_function_executor - Epoch 017/49 - train_loss: 0.8886 - val_loss: 0.7913 - val_acc: 0.7636
2025-10-12 03:00:50,450 - INFO - _models.training_function_executor - Epoch 018/49 - train_loss: 0.8791 - val_loss: 0.9816 - val_acc: 0.7189
2025-10-12 03:01:08,088 - INFO - _models.training_function_executor - Epoch 019/49 - train_loss: 0.8908 - val_loss: 0.7837 - val_acc: 0.7553
2025-10-12 03:01:25,599 - INFO - _models.training_function_executor - Epoch 020/49 - train_loss: 0.8716 - val_loss: 0.9111 - val_acc: 0.7284
2025-10-12 03:01:43,093 - INFO - _models.training_function_executor - Epoch 021/49 - train_loss: 0.9160 - val_loss: 1.0672 - val_acc: 0.6598
2025-10-12 03:02:00,737 - INFO - _models.training_function_executor - Epoch 022/49 - train_loss: 0.8731 - val_loss: 1.0621 - val_acc: 0.6636
2025-10-12 03:02:18,288 - INFO - _models.training_function_executor - Epoch 023/49 - train_loss: 0.8923 - val_loss: 0.7291 - val_acc: 0.7754
2025-10-12 03:02:35,834 - INFO - _models.training_function_executor - Epoch 024/49 - train_loss: 0.8649 - val_loss: 0.8205 - val_acc: 0.7328
2025-10-12 03:02:53,425 - INFO - _models.training_function_executor - Epoch 025/49 - train_loss: 0.8641 - val_loss: 0.8115 - val_acc: 0.7560
2025-10-12 03:03:10,933 - INFO - _models.training_function_executor - Epoch 026/49 - train_loss: 0.8895 - val_loss: 0.9376 - val_acc: 0.7708
2025-10-12 03:03:28,459 - INFO - _models.training_function_executor - Epoch 027/49 - train_loss: 0.8668 - val_loss: 0.7769 - val_acc: 0.7767
2025-10-12 03:03:45,988 - INFO - _models.training_function_executor - Epoch 028/49 - train_loss: 0.9357 - val_loss: 0.9057 - val_acc: 0.6959
2025-10-12 03:04:03,616 - INFO - _models.training_function_executor - Epoch 029/49 - train_loss: 0.9044 - val_loss: 0.9842 - val_acc: 0.6824
2025-10-12 03:04:21,154 - INFO - _models.training_function_executor - Epoch 030/49 - train_loss: 0.8701 - val_loss: 0.9598 - val_acc: 0.7648
2025-10-12 03:04:38,774 - INFO - _models.training_function_executor - Epoch 031/49 - train_loss: 0.9113 - val_loss: 0.9189 - val_acc: 0.7281
2025-10-12 03:04:56,301 - INFO - _models.training_function_executor - Epoch 032/49 - train_loss: 0.9040 - val_loss: 0.8468 - val_acc: 0.7700
2025-10-12 03:05:13,865 - INFO - _models.training_function_executor - Epoch 033/49 - train_loss: 0.8618 - val_loss: 0.9716 - val_acc: 0.7743
2025-10-12 03:05:31,477 - INFO - _models.training_function_executor - Epoch 034/49 - train_loss: 0.8555 - val_loss: 0.8629 - val_acc: 0.7665
2025-10-12 03:05:49,028 - INFO - _models.training_function_executor - Epoch 035/49 - train_loss: 0.8959 - val_loss: 1.6903 - val_acc: 0.6251
2025-10-12 03:06:06,511 - INFO - _models.training_function_executor - Epoch 036/49 - train_loss: 0.8655 - val_loss: 0.9074 - val_acc: 0.7756
2025-10-12 03:06:24,144 - INFO - _models.training_function_executor - Epoch 037/49 - train_loss: 0.8820 - val_loss: 0.9471 - val_acc: 0.7280
2025-10-12 03:06:41,638 - INFO - _models.training_function_executor - Epoch 038/49 - train_loss: 0.8746 - val_loss: 0.8822 - val_acc: 0.7344
2025-10-12 03:06:59,156 - INFO - _models.training_function_executor - Epoch 039/49 - train_loss: 0.8548 - val_loss: 0.7808 - val_acc: 0.7920
2025-10-12 03:07:16,731 - INFO - _models.training_function_executor - Epoch 040/49 - train_loss: 0.8886 - val_loss: 0.9554 - val_acc: 0.7477
2025-10-12 03:07:34,271 - INFO - _models.training_function_executor - Epoch 041/49 - train_loss: 0.8947 - val_loss: 1.0140 - val_acc: 0.7546
2025-10-12 03:07:51,863 - INFO - _models.training_function_executor - Epoch 042/49 - train_loss: 0.8758 - val_loss: 0.8496 - val_acc: 0.7875
2025-10-12 03:08:09,418 - INFO - _models.training_function_executor - Epoch 043/49 - train_loss: 0.8695 - val_loss: 0.9115 - val_acc: 0.7320
2025-10-12 03:08:27,091 - INFO - _models.training_function_executor - Epoch 044/49 - train_loss: 0.8909 - val_loss: 0.8614 - val_acc: 0.7311
2025-10-12 03:08:44,607 - INFO - _models.training_function_executor - Epoch 045/49 - train_loss: 0.8618 - val_loss: 0.8069 - val_acc: 0.7632
2025-10-12 03:09:02,234 - INFO - _models.training_function_executor - Epoch 046/49 - train_loss: 0.9055 - val_loss: 1.0727 - val_acc: 0.7398
2025-10-12 03:09:19,857 - INFO - _models.training_function_executor - Epoch 047/49 - train_loss: 0.8568 - val_loss: 1.0323 - val_acc: 0.7710
2025-10-12 03:09:37,395 - INFO - _models.training_function_executor - Epoch 048/49 - train_loss: 0.8873 - val_loss: 0.8692 - val_acc: 0.7784
2025-10-12 03:09:54,964 - INFO - _models.training_function_executor - Epoch 049/49 - train_loss: 0.8783 - val_loss: 0.9435 - val_acc: 0.7452
2025-10-12 03:09:54,967 - INFO - _models.training_function_executor - Model: 142,253 parameters, 305.6KB storage
2025-10-12 03:09:54,967 - WARNING - _models.training_function_executor - Model storage 305.6KB exceeds 256KB limit!
2025-10-12 03:09:54,967 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2894193781321392, 1.0915834365303716, 1.0233026107666916, 0.9777886320816958, 0.9521224737130849, 0.9434257150504779, 0.9414442205657524, 0.9373392653910689, 0.9283867561717029, 0.9301710878640653, 0.894589097882886, 0.9041429067230701, 0.8944417408605243, 0.9123532046356274, 0.8842902706768448, 0.8726097187160987, 0.8886098799236721, 0.8790688519273181, 0.8907634146566319, 0.8716463936081414, 0.9160452125672907, 0.8731220763125827, 0.8923315745672439, 0.864911460838912, 0.8641336929362097, 0.8895193888464507, 0.8668142184589057, 0.9357010017106447, 0.9043724371924199, 0.8701408539602379, 0.911250613050879, 0.9040393821157106, 0.8617808805908362, 0.8554635251167149, 0.8959385125963346, 0.8654756883917507, 0.8819639496022811, 0.8746426160394165, 0.8547978720435071, 0.8885692850662813, 0.8947310478517464, 0.8757535342569113, 0.869547208607468, 0.8909289605620861, 0.8618347556165644, 0.905531125932692, 0.8567737203755077, 0.8873027854337949, 0.8783235167905213], 'val_losses': [1.2114366809095918, 0.9428799945155683, 1.1266491738782716, 1.0850966666017665, 0.8642991818161665, 0.9540754969423786, 0.8249247754771767, 0.8372111047194644, 1.0075361063149078, 1.1003459517798058, 1.096276833923872, 0.9126114088586882, 0.8331533484434722, 0.888747575464973, 0.9001460499933728, 0.891504799001151, 0.7913032575090907, 0.9815685795056139, 0.7837239402154963, 0.9110977384002633, 1.0672016994578462, 1.0620906400772339, 0.729120327118689, 0.8205278913562516, 0.8115181893183294, 0.9376019468602076, 0.776859046822876, 0.9057391896025051, 0.9842073318734634, 0.9598412036395048, 0.9189315620036571, 0.8468367983024772, 0.9715924241720566, 0.8628699396993466, 1.690252400170601, 0.9074119289187564, 0.947065301779312, 0.8821933837904145, 0.7808038180196539, 0.9553950512726322, 1.014027371903504, 0.8495811614324298, 0.9114746431558334, 0.8614212675949139, 0.8069252111421918, 1.0727152423942927, 1.03234357842416, 0.8692192839061542, 0.9434709911439065], 'val_acc': [0.5462898144907246, 0.6948722436121806, 0.621543577178859, 0.6663458172908645, 0.7254112705635282, 0.705722786139307, 0.7466748337416871, 0.7340742037101855, 0.6769338466923346, 0.615680784039202, 0.7124606230311515, 0.692509625481274, 0.7643507175358768, 0.7412495624781239, 0.74011200560028, 0.7319740987049352, 0.763563178158908, 0.7189359467973399, 0.7552502625131257, 0.728386419320966, 0.6597829891494574, 0.6636331816590829, 0.7753762688134407, 0.7327616380819041, 0.7559502975148757, 0.7708260413020651, 0.7766888344417221, 0.6959222961148057, 0.6823591179558978, 0.7647882394119706, 0.7281239061953098, 0.7699509975498775, 0.7743262163108156, 0.7664508225411271, 0.6251312565628281, 0.775638781939097, 0.728036401820091, 0.7344242212110605, 0.7920021001050053, 0.7477248862443122, 0.7545502275113756, 0.7875393769688485, 0.7319740987049352, 0.7310990549527476, 0.7632131606580329, 0.739761988099405, 0.7710010500525026, 0.7783514175708786, 0.7451872593629681], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003054307379632007, 'batch_size': 8, 'epochs': 49, 'weight_decay': 1.7353547103127357e-05, 'dropout': 0.14259926808052784, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 1000, 'label_smoothing': 0.03176222985899649, 'grad_clip': 0.08646275170667207, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6468}, 'model_parameter_count': 142253, 'model_storage_size_kb': 305.62167968750003, 'model_size_validation': 'FAIL'}
2025-10-12 03:09:54,967 - INFO - _models.training_function_executor - BO Objective: base=0.7452, size_penalty=0.0969, final=0.6483
2025-10-12 03:09:54,967 - INFO - _models.training_function_executor - Model: 142,253 parameters, 305.6KB (FAIL 256KB limit)
2025-10-12 03:09:54,967 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 861.077s
2025-10-12 03:09:55,383 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6483
2025-10-12 03:09:55,383 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.415s
2025-10-12 03:09:55,383 - INFO - bo.run_bo - Recorded observation #10: hparams={'lr': 0.003054307379632007, 'batch_size': np.int64(8), 'epochs': np.int64(49), 'weight_decay': 1.7353547103127357e-05, 'dropout': 0.14259926808052784, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(1000), 'label_smoothing': 0.03176222985899649, 'grad_clip': 0.08646275170667207, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(6468)}, value=0.6483
2025-10-12 03:09:55,383 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'lr': 0.003054307379632007, 'batch_size': np.int64(8), 'epochs': np.int64(49), 'weight_decay': 1.7353547103127357e-05, 'dropout': 0.14259926808052784, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(1000), 'label_smoothing': 0.03176222985899649, 'grad_clip': 0.08646275170667207, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(6468)} -> 0.6483
2025-10-12 03:09:55,384 - INFO - bo.run_bo - üîçBO Trial 11: Using RF surrogate + Expected Improvement
2025-10-12 03:09:55,384 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 03:09:55,384 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 03:09:55,384 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 03:09:55,384 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00016002204230620398, 'batch_size': 64, 'epochs': 50, 'weight_decay': 3.6890627685419935e-06, 'dropout': 0.08282863374634182, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 120, 'label_smoothing': 0.0750940027188549, 'grad_clip': 0.7683275197380957, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 3354}
2025-10-12 03:09:55,387 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00016002204230620398, 'batch_size': 64, 'epochs': 50, 'weight_decay': 3.6890627685419935e-06, 'dropout': 0.08282863374634182, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 120, 'label_smoothing': 0.0750940027188549, 'grad_clip': 0.7683275197380957, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 3354}
2025-10-12 03:10:07,472 - INFO - _models.training_function_executor - Epoch 001/50 - train_loss: 1.4888 - val_loss: 1.3759 - val_acc: 0.4719
2025-10-12 03:10:18,973 - INFO - _models.training_function_executor - Epoch 002/50 - train_loss: 1.2222 - val_loss: 1.1510 - val_acc: 0.5695
2025-10-12 03:10:30,512 - INFO - _models.training_function_executor - Epoch 003/50 - train_loss: 1.1105 - val_loss: 1.1008 - val_acc: 0.6120
2025-10-12 03:10:42,072 - INFO - _models.training_function_executor - Epoch 004/50 - train_loss: 1.0352 - val_loss: 1.1298 - val_acc: 0.6012
2025-10-12 03:10:53,605 - INFO - _models.training_function_executor - Epoch 005/50 - train_loss: 0.9907 - val_loss: 1.2484 - val_acc: 0.5473
2025-10-12 03:11:05,148 - INFO - _models.training_function_executor - Epoch 006/50 - train_loss: 0.9586 - val_loss: 1.0842 - val_acc: 0.6333
2025-10-12 03:11:16,730 - INFO - _models.training_function_executor - Epoch 007/50 - train_loss: 0.9341 - val_loss: 0.9559 - val_acc: 0.7045
2025-10-12 03:11:28,227 - INFO - _models.training_function_executor - Epoch 008/50 - train_loss: 0.9140 - val_loss: 0.9465 - val_acc: 0.7051
2025-10-12 03:11:39,729 - INFO - _models.training_function_executor - Epoch 009/50 - train_loss: 0.8965 - val_loss: 1.0715 - val_acc: 0.6416
2025-10-12 03:11:51,266 - INFO - _models.training_function_executor - Epoch 010/50 - train_loss: 0.8824 - val_loss: 1.0554 - val_acc: 0.6612
2025-10-12 03:12:02,795 - INFO - _models.training_function_executor - Epoch 011/50 - train_loss: 0.8679 - val_loss: 0.9448 - val_acc: 0.6991
2025-10-12 03:12:14,326 - INFO - _models.training_function_executor - Epoch 012/50 - train_loss: 0.8572 - val_loss: 1.0208 - val_acc: 0.6530
2025-10-12 03:12:25,876 - INFO - _models.training_function_executor - Epoch 013/50 - train_loss: 0.8439 - val_loss: 0.9245 - val_acc: 0.7128
2025-10-12 03:12:37,420 - INFO - _models.training_function_executor - Epoch 014/50 - train_loss: 0.8336 - val_loss: 0.8954 - val_acc: 0.7292
2025-10-12 03:12:48,887 - INFO - _models.training_function_executor - Epoch 015/50 - train_loss: 0.8265 - val_loss: 0.9439 - val_acc: 0.7092
2025-10-12 03:13:00,430 - INFO - _models.training_function_executor - Epoch 016/50 - train_loss: 0.8160 - val_loss: 0.8792 - val_acc: 0.7261
2025-10-12 03:13:11,977 - INFO - _models.training_function_executor - Epoch 017/50 - train_loss: 0.8061 - val_loss: 0.8241 - val_acc: 0.7631
2025-10-12 03:13:23,498 - INFO - _models.training_function_executor - Epoch 018/50 - train_loss: 0.8021 - val_loss: 1.2336 - val_acc: 0.5905
2025-10-12 03:13:35,002 - INFO - _models.training_function_executor - Epoch 019/50 - train_loss: 0.7935 - val_loss: 0.9779 - val_acc: 0.6932
2025-10-12 03:13:46,521 - INFO - _models.training_function_executor - Epoch 020/50 - train_loss: 0.7874 - val_loss: 0.8795 - val_acc: 0.7367
2025-10-12 03:13:58,059 - INFO - _models.training_function_executor - Epoch 021/50 - train_loss: 0.7823 - val_loss: 0.8383 - val_acc: 0.7491
2025-10-12 03:14:09,557 - INFO - _models.training_function_executor - Epoch 022/50 - train_loss: 0.7784 - val_loss: 0.8272 - val_acc: 0.7558
2025-10-12 03:14:21,097 - INFO - _models.training_function_executor - Epoch 023/50 - train_loss: 0.7705 - val_loss: 0.7968 - val_acc: 0.7712
2025-10-12 03:14:32,637 - INFO - _models.training_function_executor - Epoch 024/50 - train_loss: 0.7659 - val_loss: 0.8519 - val_acc: 0.7386
2025-10-12 03:14:44,180 - INFO - _models.training_function_executor - Epoch 025/50 - train_loss: 0.7615 - val_loss: 0.9000 - val_acc: 0.7197
2025-10-12 03:14:55,731 - INFO - _models.training_function_executor - Epoch 026/50 - train_loss: 0.7573 - val_loss: 0.7950 - val_acc: 0.7666
2025-10-12 03:15:07,319 - INFO - _models.training_function_executor - Epoch 027/50 - train_loss: 0.7534 - val_loss: 0.8420 - val_acc: 0.7450
2025-10-12 03:15:18,842 - INFO - _models.training_function_executor - Epoch 028/50 - train_loss: 0.7486 - val_loss: 0.7609 - val_acc: 0.7867
2025-10-12 03:15:30,341 - INFO - _models.training_function_executor - Epoch 029/50 - train_loss: 0.7435 - val_loss: 0.7691 - val_acc: 0.7850
2025-10-12 03:15:41,857 - INFO - _models.training_function_executor - Epoch 030/50 - train_loss: 0.7418 - val_loss: 0.7993 - val_acc: 0.7694
2025-10-12 03:15:53,344 - INFO - _models.training_function_executor - Epoch 031/50 - train_loss: 0.7393 - val_loss: 0.8116 - val_acc: 0.7624
2025-10-12 03:16:04,892 - INFO - _models.training_function_executor - Epoch 032/50 - train_loss: 0.7334 - val_loss: 0.9627 - val_acc: 0.7019
2025-10-12 03:16:16,365 - INFO - _models.training_function_executor - Epoch 033/50 - train_loss: 0.7303 - val_loss: 0.7481 - val_acc: 0.7953
2025-10-12 03:16:27,923 - INFO - _models.training_function_executor - Epoch 034/50 - train_loss: 0.7302 - val_loss: 0.7771 - val_acc: 0.7819
2025-10-12 03:16:39,464 - INFO - _models.training_function_executor - Epoch 035/50 - train_loss: 0.7259 - val_loss: 0.7525 - val_acc: 0.7949
2025-10-12 03:16:50,969 - INFO - _models.training_function_executor - Epoch 036/50 - train_loss: 0.7234 - val_loss: 1.0117 - val_acc: 0.6778
2025-10-12 03:17:02,474 - INFO - _models.training_function_executor - Epoch 037/50 - train_loss: 0.7191 - val_loss: 0.8460 - val_acc: 0.7443
2025-10-12 03:17:13,989 - INFO - _models.training_function_executor - Epoch 038/50 - train_loss: 0.7180 - val_loss: 0.8695 - val_acc: 0.7418
2025-10-12 03:17:25,484 - INFO - _models.training_function_executor - Epoch 039/50 - train_loss: 0.7170 - val_loss: 0.7911 - val_acc: 0.7724
2025-10-12 03:17:37,031 - INFO - _models.training_function_executor - Epoch 040/50 - train_loss: 0.7161 - val_loss: 0.7502 - val_acc: 0.7944
2025-10-12 03:17:48,501 - INFO - _models.training_function_executor - Epoch 041/50 - train_loss: 0.7102 - val_loss: 0.8029 - val_acc: 0.7664
2025-10-12 03:18:00,025 - INFO - _models.training_function_executor - Epoch 042/50 - train_loss: 0.7092 - val_loss: 0.7326 - val_acc: 0.8029
2025-10-12 03:18:11,563 - INFO - _models.training_function_executor - Epoch 043/50 - train_loss: 0.7077 - val_loss: 0.9348 - val_acc: 0.7132
2025-10-12 03:18:23,076 - INFO - _models.training_function_executor - Epoch 044/50 - train_loss: 0.7030 - val_loss: 0.7691 - val_acc: 0.7824
2025-10-12 03:18:34,557 - INFO - _models.training_function_executor - Epoch 045/50 - train_loss: 0.7004 - val_loss: 0.7588 - val_acc: 0.7864
2025-10-12 03:18:46,074 - INFO - _models.training_function_executor - Epoch 046/50 - train_loss: 0.7018 - val_loss: 0.7973 - val_acc: 0.7691
2025-10-12 03:18:57,614 - INFO - _models.training_function_executor - Epoch 047/50 - train_loss: 0.6993 - val_loss: 0.7791 - val_acc: 0.7771
2025-10-12 03:19:09,118 - INFO - _models.training_function_executor - Epoch 048/50 - train_loss: 0.7000 - val_loss: 0.7835 - val_acc: 0.7823
2025-10-12 03:19:20,640 - INFO - _models.training_function_executor - Epoch 049/50 - train_loss: 0.6963 - val_loss: 0.8878 - val_acc: 0.7331
2025-10-12 03:19:32,157 - INFO - _models.training_function_executor - Epoch 050/50 - train_loss: 0.6955 - val_loss: 0.8788 - val_acc: 0.7351
2025-10-12 03:19:32,160 - INFO - _models.training_function_executor - Model: 44,105 parameters, 94.8KB storage
2025-10-12 03:19:32,160 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4887588382560055, 1.2222197992967734, 1.1105022325272071, 1.0351530030176779, 0.9906764370518044, 0.9586388837177102, 0.9340514365634511, 0.9139561338528162, 0.896497944246692, 0.8824451459342881, 0.8679278673598263, 0.8572138306307634, 0.8439295680154901, 0.8336415103277127, 0.8265498596803267, 0.8159931976769327, 0.8061314036806939, 0.8021196192446646, 0.7935147570445482, 0.7873929767580269, 0.7822608016027117, 0.7784249611696998, 0.7705119278909112, 0.7659177275274782, 0.7615026366598004, 0.7573475659540327, 0.7533837893979717, 0.7486139778745395, 0.7435136649589419, 0.7417696121692824, 0.7393131114237368, 0.7333833125449579, 0.7303478496451039, 0.7301877507973185, 0.7259466172850211, 0.723438170601281, 0.7190769475617107, 0.7180379350618503, 0.7170365530584173, 0.7161242999436349, 0.7102342455963759, 0.7091617447369408, 0.7076775770442737, 0.7029990223599849, 0.7004386449469359, 0.7018193079534844, 0.6992580241826518, 0.6999575755460137, 0.6963036761944804, 0.6954821842844185], 'val_losses': [1.3758537569870513, 1.1509833205276159, 1.1008453257733974, 1.1298337766746145, 1.248444469650183, 1.0842075382115168, 0.9559145936775675, 0.9465113761001923, 1.0715417480568892, 1.0554028426094575, 0.9447579307075477, 1.02082225138965, 0.9244644314332321, 0.8954345632734355, 0.9438601478146722, 0.8791880598008153, 0.8240805280596634, 1.2336281589331808, 0.9779310435901625, 0.8795479865060806, 0.8382757906109293, 0.827159970091238, 0.7968273205818894, 0.8519310071036913, 0.9000181091970858, 0.79501190200568, 0.8420202208850448, 0.7608685489922584, 0.7691304193829839, 0.7993312016791884, 0.8115777376860558, 0.9626940169616475, 0.7480630111477364, 0.7770695321869509, 0.7524902919476208, 1.0116641917844564, 0.8460275517045763, 0.8694541922890727, 0.7910680084074967, 0.7501595890684732, 0.8028545143473261, 0.7326460830348331, 0.9347505090033879, 0.7691371118141965, 0.7588489765172911, 0.7972974227698983, 0.7791466751130344, 0.7835213650679063, 0.8878302362193, 0.8788253247717022], 'val_acc': [0.4719110955547777, 0.5694784739236962, 0.612005600280014, 0.6012425621281065, 0.5472523626181309, 0.6332691634581729, 0.7044977248862443, 0.7051102555127756, 0.6415820791039551, 0.6611830591529576, 0.6990724536226811, 0.6530451522576128, 0.7128106405320266, 0.7291739586979349, 0.7092229611480574, 0.7261113055652783, 0.7631256562828141, 0.5904795239761989, 0.6932096604830241, 0.7366993349667483, 0.7491249562478124, 0.7557752887644382, 0.7711760588029402, 0.7386244312215611, 0.7197234861743087, 0.7666258312915646, 0.7450122506125306, 0.7866643332166608, 0.7850017500875044, 0.7694259712985649, 0.7624256212810641, 0.7018725936296815, 0.7953272663633182, 0.781851592579629, 0.7948897444872244, 0.6778088904445222, 0.7443122156107805, 0.7417745887294365, 0.7724011200560028, 0.7943647182359118, 0.7663633181659083, 0.8028526426321316, 0.7132481624081204, 0.7823766188309416, 0.7864018200910046, 0.7690759537976899, 0.7771263563178159, 0.7822891144557228, 0.7331116555827791, 0.7351242562128106], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00016002204230620398, 'batch_size': 64, 'epochs': 50, 'weight_decay': 3.6890627685419935e-06, 'dropout': 0.08282863374634182, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 120, 'label_smoothing': 0.0750940027188549, 'grad_clip': 0.7683275197380957, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 3354}, 'model_parameter_count': 44105, 'model_storage_size_kb': 94.75683593750001, 'model_size_validation': 'PASS'}
2025-10-12 03:19:32,160 - INFO - _models.training_function_executor - BO Objective: base=0.7351, size_penalty=0.0000, final=0.7351
2025-10-12 03:19:32,160 - INFO - _models.training_function_executor - Model: 44,105 parameters, 94.8KB (PASS 256KB limit)
2025-10-12 03:19:32,160 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 576.776s
2025-10-12 03:19:32,261 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7351
2025-10-12 03:19:32,261 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.090s
2025-10-12 03:19:32,261 - INFO - bo.run_bo - Recorded observation #11: hparams={'lr': 0.00016002204230620398, 'batch_size': np.int64(64), 'epochs': np.int64(50), 'weight_decay': 3.6890627685419935e-06, 'dropout': 0.08282863374634182, 'base_channels': np.int64(15), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(120), 'label_smoothing': 0.0750940027188549, 'grad_clip': 0.7683275197380957, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(3354)}, value=0.7351
2025-10-12 03:19:32,261 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 11: {'lr': 0.00016002204230620398, 'batch_size': np.int64(64), 'epochs': np.int64(50), 'weight_decay': 3.6890627685419935e-06, 'dropout': 0.08282863374634182, 'base_channels': np.int64(15), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(120), 'label_smoothing': 0.0750940027188549, 'grad_clip': 0.7683275197380957, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(3354)} -> 0.7351
2025-10-12 03:19:32,261 - INFO - bo.run_bo - üîçBO Trial 12: Using RF surrogate + Expected Improvement
2025-10-12 03:19:32,261 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 03:19:32,261 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 03:19:32,261 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 03:19:32,261 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 4.6111103886440106e-05, 'batch_size': 8, 'epochs': 47, 'weight_decay': 2.262602407263362e-05, 'dropout': 0.06339584026196511, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.029502787722633688, 'grad_clip': 0.39086024613616577, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 1949}
2025-10-12 03:19:32,262 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 4.6111103886440106e-05, 'batch_size': 8, 'epochs': 47, 'weight_decay': 2.262602407263362e-05, 'dropout': 0.06339584026196511, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.029502787722633688, 'grad_clip': 0.39086024613616577, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 1949}
2025-10-12 03:19:49,434 - INFO - _models.training_function_executor - Epoch 001/47 - train_loss: 1.4568 - val_loss: 1.2268 - val_acc: 0.5450
2025-10-12 03:20:06,532 - INFO - _models.training_function_executor - Epoch 002/47 - train_loss: 1.1565 - val_loss: 1.0726 - val_acc: 0.6026
2025-10-12 03:20:23,663 - INFO - _models.training_function_executor - Epoch 003/47 - train_loss: 1.0472 - val_loss: 1.0182 - val_acc: 0.6089
2025-10-12 03:20:40,702 - INFO - _models.training_function_executor - Epoch 004/47 - train_loss: 1.0012 - val_loss: 0.9754 - val_acc: 0.6460
2025-10-12 03:20:57,820 - INFO - _models.training_function_executor - Epoch 005/47 - train_loss: 0.9577 - val_loss: 0.9883 - val_acc: 0.6328
2025-10-12 03:21:14,927 - INFO - _models.training_function_executor - Epoch 006/47 - train_loss: 0.9249 - val_loss: 0.9368 - val_acc: 0.6695
2025-10-12 03:21:32,054 - INFO - _models.training_function_executor - Epoch 007/47 - train_loss: 0.8952 - val_loss: 1.0909 - val_acc: 0.5837
2025-10-12 03:21:49,180 - INFO - _models.training_function_executor - Epoch 008/47 - train_loss: 0.8751 - val_loss: 0.8591 - val_acc: 0.7050
2025-10-12 03:22:06,326 - INFO - _models.training_function_executor - Epoch 009/47 - train_loss: 0.8557 - val_loss: 0.8356 - val_acc: 0.7253
2025-10-12 03:22:23,379 - INFO - _models.training_function_executor - Epoch 010/47 - train_loss: 0.8385 - val_loss: 0.8546 - val_acc: 0.7101
2025-10-12 03:22:40,496 - INFO - _models.training_function_executor - Epoch 011/47 - train_loss: 0.8255 - val_loss: 1.0999 - val_acc: 0.5907
2025-10-12 03:22:57,568 - INFO - _models.training_function_executor - Epoch 012/47 - train_loss: 0.8079 - val_loss: 0.9078 - val_acc: 0.6698
2025-10-12 03:23:14,727 - INFO - _models.training_function_executor - Epoch 013/47 - train_loss: 0.7970 - val_loss: 0.7510 - val_acc: 0.7533
2025-10-12 03:23:31,892 - INFO - _models.training_function_executor - Epoch 014/47 - train_loss: 0.7833 - val_loss: 0.9081 - val_acc: 0.6843
2025-10-12 03:23:49,057 - INFO - _models.training_function_executor - Epoch 015/47 - train_loss: 0.7753 - val_loss: 0.7953 - val_acc: 0.7291
2025-10-12 03:24:06,192 - INFO - _models.training_function_executor - Epoch 016/47 - train_loss: 0.7675 - val_loss: 0.7742 - val_acc: 0.7511
2025-10-12 03:24:23,298 - INFO - _models.training_function_executor - Epoch 017/47 - train_loss: 0.7544 - val_loss: 0.8141 - val_acc: 0.7202
2025-10-12 03:24:40,435 - INFO - _models.training_function_executor - Epoch 018/47 - train_loss: 0.7483 - val_loss: 0.7318 - val_acc: 0.7669
2025-10-12 03:24:57,675 - INFO - _models.training_function_executor - Epoch 019/47 - train_loss: 0.7344 - val_loss: 0.8500 - val_acc: 0.7104
2025-10-12 03:25:14,804 - INFO - _models.training_function_executor - Epoch 020/47 - train_loss: 0.7297 - val_loss: 0.7389 - val_acc: 0.7602
2025-10-12 03:25:31,924 - INFO - _models.training_function_executor - Epoch 021/47 - train_loss: 0.7254 - val_loss: 0.7595 - val_acc: 0.7446
2025-10-12 03:25:49,129 - INFO - _models.training_function_executor - Epoch 022/47 - train_loss: 0.7147 - val_loss: 1.0261 - val_acc: 0.6256
2025-10-12 03:26:06,263 - INFO - _models.training_function_executor - Epoch 023/47 - train_loss: 0.7082 - val_loss: 0.7403 - val_acc: 0.7629
2025-10-12 03:26:23,370 - INFO - _models.training_function_executor - Epoch 024/47 - train_loss: 0.7010 - val_loss: 0.7373 - val_acc: 0.7547
2025-10-12 03:26:40,505 - INFO - _models.training_function_executor - Epoch 025/47 - train_loss: 0.6953 - val_loss: 0.7794 - val_acc: 0.7401
2025-10-12 03:26:57,547 - INFO - _models.training_function_executor - Epoch 026/47 - train_loss: 0.6876 - val_loss: 0.7036 - val_acc: 0.7751
2025-10-12 03:27:14,559 - INFO - _models.training_function_executor - Epoch 027/47 - train_loss: 0.6847 - val_loss: 0.6955 - val_acc: 0.7809
2025-10-12 03:27:31,704 - INFO - _models.training_function_executor - Epoch 028/47 - train_loss: 0.6792 - val_loss: 0.7168 - val_acc: 0.7669
2025-10-12 03:27:48,813 - INFO - _models.training_function_executor - Epoch 029/47 - train_loss: 0.6691 - val_loss: 0.6837 - val_acc: 0.7854
2025-10-12 03:28:05,969 - INFO - _models.training_function_executor - Epoch 030/47 - train_loss: 0.6658 - val_loss: 0.8477 - val_acc: 0.7012
2025-10-12 03:28:23,117 - INFO - _models.training_function_executor - Epoch 031/47 - train_loss: 0.6634 - val_loss: 0.7172 - val_acc: 0.7674
2025-10-12 03:28:40,219 - INFO - _models.training_function_executor - Epoch 032/47 - train_loss: 0.6581 - val_loss: 0.6789 - val_acc: 0.7860
2025-10-12 03:28:57,336 - INFO - _models.training_function_executor - Epoch 033/47 - train_loss: 0.6527 - val_loss: 0.7277 - val_acc: 0.7520
2025-10-12 03:29:14,446 - INFO - _models.training_function_executor - Epoch 034/47 - train_loss: 0.6478 - val_loss: 0.8390 - val_acc: 0.6950
2025-10-12 03:29:31,516 - INFO - _models.training_function_executor - Epoch 035/47 - train_loss: 0.6452 - val_loss: 0.8229 - val_acc: 0.7158
2025-10-12 03:29:48,648 - INFO - _models.training_function_executor - Epoch 036/47 - train_loss: 0.6427 - val_loss: 0.7466 - val_acc: 0.7620
2025-10-12 03:30:05,730 - INFO - _models.training_function_executor - Epoch 037/47 - train_loss: 0.6367 - val_loss: 1.0340 - val_acc: 0.6592
2025-10-12 03:30:22,879 - INFO - _models.training_function_executor - Epoch 038/47 - train_loss: 0.6356 - val_loss: 0.7170 - val_acc: 0.7746
2025-10-12 03:30:40,000 - INFO - _models.training_function_executor - Epoch 039/47 - train_loss: 0.6305 - val_loss: 0.7147 - val_acc: 0.7784
2025-10-12 03:30:57,163 - INFO - _models.training_function_executor - Epoch 040/47 - train_loss: 0.6278 - val_loss: 0.6608 - val_acc: 0.7939
2025-10-12 03:31:14,244 - INFO - _models.training_function_executor - Epoch 041/47 - train_loss: 0.6215 - val_loss: 0.6597 - val_acc: 0.7966
2025-10-12 03:31:31,336 - INFO - _models.training_function_executor - Epoch 042/47 - train_loss: 0.6238 - val_loss: 0.7047 - val_acc: 0.7860
2025-10-12 03:31:48,506 - INFO - _models.training_function_executor - Epoch 043/47 - train_loss: 0.6180 - val_loss: 0.7353 - val_acc: 0.7676
2025-10-12 03:32:05,693 - INFO - _models.training_function_executor - Epoch 044/47 - train_loss: 0.6156 - val_loss: 0.6714 - val_acc: 0.8010
2025-10-12 03:32:22,908 - INFO - _models.training_function_executor - Epoch 045/47 - train_loss: 0.6129 - val_loss: 0.8293 - val_acc: 0.7232
2025-10-12 03:32:40,014 - INFO - _models.training_function_executor - Epoch 046/47 - train_loss: 0.6119 - val_loss: 0.7884 - val_acc: 0.7284
2025-10-12 03:32:57,119 - INFO - _models.training_function_executor - Epoch 047/47 - train_loss: 0.6094 - val_loss: 0.7006 - val_acc: 0.7737
2025-10-12 03:32:57,122 - INFO - _models.training_function_executor - Model: 55,853 parameters, 120.0KB storage
2025-10-12 03:32:57,122 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4567502892785111, 1.1565444775037845, 1.0472250877350495, 1.0011746492478077, 0.9576628761594848, 0.9249071913778177, 0.8952408278003038, 0.8750874601933019, 0.8556827250000978, 0.8384902525144229, 0.8255419192987595, 0.8079247786958483, 0.7969725446310709, 0.7833007482807245, 0.775256826289684, 0.7675049870131856, 0.7543537199137342, 0.7482823260339733, 0.73439062082417, 0.7297067130528884, 0.7253670402165889, 0.7146698565913073, 0.7081838818302846, 0.7010307987231995, 0.695346645833543, 0.6875823720309089, 0.6847158517136956, 0.6791846272794776, 0.6690990679229436, 0.665806313106281, 0.6634144290739271, 0.658053943792819, 0.6526762624360858, 0.6478133796472044, 0.645150125636936, 0.6427448063066551, 0.6367319144900545, 0.6356481474921718, 0.6305388765977444, 0.6278425201351174, 0.6214898983769622, 0.6238089993486547, 0.6180034928939164, 0.6156231330164588, 0.6128891723547985, 0.6119217215732423, 0.6094340154908319], 'val_losses': [1.2268211241572897, 1.0725939436563046, 1.0182259035435932, 0.9753576181633388, 0.9883360690614916, 0.9368254033301651, 1.0909196385395956, 0.8591284370939758, 0.8356074757162073, 0.8545712775019111, 1.099874812612844, 0.9078129233807419, 0.7510479018639801, 0.9081148103395875, 0.7953317099553036, 0.7742256183368909, 0.8141044979125501, 0.7318298399114592, 0.8499613831541444, 0.7388735231211605, 0.7595096494628284, 1.0261215985885315, 0.7402773349590556, 0.7373439294081031, 0.77938464618789, 0.7035737934962076, 0.69553058868027, 0.7168022651208378, 0.6837118506473305, 0.8477130864815651, 0.7172499153845202, 0.6788915107831864, 0.7277290731157336, 0.838982512494422, 0.8229300205028262, 0.7465524733442087, 1.033987044130208, 0.7170057943704289, 0.7147068789122528, 0.6608159804849054, 0.6596723641492205, 0.7046699860649256, 0.7353074339185514, 0.6714076372681692, 0.8292696216659693, 0.7883846670086667, 0.7005912301254139], 'val_acc': [0.5449772488624431, 0.6025551277563879, 0.6089429471473574, 0.6459572978648932, 0.632831641582079, 0.6694959747987399, 0.5836541827091355, 0.7050227511375569, 0.7253237661883094, 0.710098004900245, 0.5906545327266364, 0.669845992299615, 0.7533251662583129, 0.6842842142107105, 0.7290864543227161, 0.7511375568778439, 0.7201610080504025, 0.7668883444172209, 0.7103605180259013, 0.760238011900595, 0.7445747287364368, 0.6255687784389219, 0.7628631431571579, 0.7547252362618131, 0.74011200560028, 0.7751137556877844, 0.7808890444522226, 0.7668883444172209, 0.7854392719635982, 0.7011725586279314, 0.7674133706685334, 0.7859642982149108, 0.7520126006300315, 0.6950472523626181, 0.7157857892894645, 0.7619880994049703, 0.6591704585229261, 0.7745887294364718, 0.7783514175708786, 0.793927196359818, 0.7965523276163808, 0.7859642982149108, 0.767588379418971, 0.8010150507525376, 0.7232236611830591, 0.728386419320966, 0.7737136856842842], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 4.6111103886440106e-05, 'batch_size': 8, 'epochs': 47, 'weight_decay': 2.262602407263362e-05, 'dropout': 0.06339584026196511, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.029502787722633688, 'grad_clip': 0.39086024613616577, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 1949}, 'model_parameter_count': 55853, 'model_storage_size_kb': 119.9966796875, 'model_size_validation': 'PASS'}
2025-10-12 03:32:57,122 - INFO - _models.training_function_executor - BO Objective: base=0.7737, size_penalty=0.0000, final=0.7737
2025-10-12 03:32:57,122 - INFO - _models.training_function_executor - Model: 55,853 parameters, 120.0KB (PASS 256KB limit)
2025-10-12 03:32:57,122 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 804.861s
2025-10-12 03:32:57,216 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7737
2025-10-12 03:32:57,216 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.092s
2025-10-12 03:32:57,216 - INFO - bo.run_bo - Recorded observation #12: hparams={'lr': 4.6111103886440106e-05, 'batch_size': np.int64(8), 'epochs': np.int64(47), 'weight_decay': 2.262602407263362e-05, 'dropout': 0.06339584026196511, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(100), 'label_smoothing': 0.029502787722633688, 'grad_clip': 0.39086024613616577, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(1949)}, value=0.7737
2025-10-12 03:32:57,216 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 12: {'lr': 4.6111103886440106e-05, 'batch_size': np.int64(8), 'epochs': np.int64(47), 'weight_decay': 2.262602407263362e-05, 'dropout': 0.06339584026196511, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(100), 'label_smoothing': 0.029502787722633688, 'grad_clip': 0.39086024613616577, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(1949)} -> 0.7737
2025-10-12 03:32:57,216 - INFO - bo.run_bo - üîçBO Trial 13: Using RF surrogate + Expected Improvement
2025-10-12 03:32:57,216 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 03:32:57,216 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 03:32:57,217 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 03:32:57,217 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.0674350435890964e-05, 'batch_size': 32, 'epochs': 34, 'weight_decay': 4.510733748760559e-06, 'dropout': 0.03014725524986895, 'base_channels': 24, 'temporal_kernel': 7, 'spatial_segments': 25, 'label_smoothing': 0.08908799751401124, 'grad_clip': 0.6921019101049516, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 3615}
2025-10-12 03:32:57,218 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.0674350435890964e-05, 'batch_size': 32, 'epochs': 34, 'weight_decay': 4.510733748760559e-06, 'dropout': 0.03014725524986895, 'base_channels': 24, 'temporal_kernel': 7, 'spatial_segments': 25, 'label_smoothing': 0.08908799751401124, 'grad_clip': 0.6921019101049516, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 3615}
2025-10-12 03:33:14,023 - INFO - _models.training_function_executor - Epoch 001/34 - train_loss: 1.6344 - val_loss: 1.5689 - val_acc: 0.3757
2025-10-12 03:33:30,465 - INFO - _models.training_function_executor - Epoch 002/34 - train_loss: 1.4833 - val_loss: 1.4537 - val_acc: 0.4694
2025-10-12 03:33:46,907 - INFO - _models.training_function_executor - Epoch 003/34 - train_loss: 1.3828 - val_loss: 1.4385 - val_acc: 0.4401
2025-10-12 03:34:03,369 - INFO - _models.training_function_executor - Epoch 004/34 - train_loss: 1.3112 - val_loss: 1.3070 - val_acc: 0.5084
2025-10-12 03:34:19,840 - INFO - _models.training_function_executor - Epoch 005/34 - train_loss: 1.2557 - val_loss: 1.2875 - val_acc: 0.5372
2025-10-12 03:34:36,332 - INFO - _models.training_function_executor - Epoch 006/34 - train_loss: 1.2069 - val_loss: 1.2691 - val_acc: 0.5168
2025-10-12 03:34:52,764 - INFO - _models.training_function_executor - Epoch 007/34 - train_loss: 1.1625 - val_loss: 1.1842 - val_acc: 0.5865
2025-10-12 03:35:09,243 - INFO - _models.training_function_executor - Epoch 008/34 - train_loss: 1.1200 - val_loss: 1.1791 - val_acc: 0.5971
2025-10-12 03:35:25,730 - INFO - _models.training_function_executor - Epoch 009/34 - train_loss: 1.0798 - val_loss: 1.2114 - val_acc: 0.5208
2025-10-12 03:35:42,210 - INFO - _models.training_function_executor - Epoch 010/34 - train_loss: 1.0496 - val_loss: 1.0042 - val_acc: 0.6992
2025-10-12 03:35:58,650 - INFO - _models.training_function_executor - Epoch 011/34 - train_loss: 1.0199 - val_loss: 1.0946 - val_acc: 0.6448
2025-10-12 03:36:15,081 - INFO - _models.training_function_executor - Epoch 012/34 - train_loss: 1.0004 - val_loss: 1.0597 - val_acc: 0.6523
2025-10-12 03:36:31,550 - INFO - _models.training_function_executor - Epoch 013/34 - train_loss: 0.9792 - val_loss: 1.0728 - val_acc: 0.6473
2025-10-12 03:36:48,038 - INFO - _models.training_function_executor - Epoch 014/34 - train_loss: 0.9675 - val_loss: 1.0340 - val_acc: 0.6693
2025-10-12 03:37:04,505 - INFO - _models.training_function_executor - Epoch 015/34 - train_loss: 0.9554 - val_loss: 1.0991 - val_acc: 0.6266
2025-10-12 03:37:20,986 - INFO - _models.training_function_executor - Epoch 016/34 - train_loss: 0.9455 - val_loss: 1.1052 - val_acc: 0.6313
2025-10-12 03:37:37,413 - INFO - _models.training_function_executor - Epoch 017/34 - train_loss: 0.9339 - val_loss: 1.0381 - val_acc: 0.6623
2025-10-12 03:37:53,865 - INFO - _models.training_function_executor - Epoch 018/34 - train_loss: 0.9254 - val_loss: 1.0595 - val_acc: 0.6324
2025-10-12 03:38:10,352 - INFO - _models.training_function_executor - Epoch 019/34 - train_loss: 0.9187 - val_loss: 0.9766 - val_acc: 0.6885
2025-10-12 03:38:26,814 - INFO - _models.training_function_executor - Epoch 020/34 - train_loss: 0.9104 - val_loss: 1.2161 - val_acc: 0.5508
2025-10-12 03:38:43,302 - INFO - _models.training_function_executor - Epoch 021/34 - train_loss: 0.9039 - val_loss: 1.0077 - val_acc: 0.6742
2025-10-12 03:38:59,759 - INFO - _models.training_function_executor - Epoch 022/34 - train_loss: 0.8985 - val_loss: 0.8830 - val_acc: 0.7397
2025-10-12 03:39:16,207 - INFO - _models.training_function_executor - Epoch 023/34 - train_loss: 0.8933 - val_loss: 0.9189 - val_acc: 0.7210
2025-10-12 03:39:32,659 - INFO - _models.training_function_executor - Epoch 024/34 - train_loss: 0.8887 - val_loss: 1.0862 - val_acc: 0.6327
2025-10-12 03:39:49,136 - INFO - _models.training_function_executor - Epoch 025/34 - train_loss: 0.8830 - val_loss: 1.1243 - val_acc: 0.6201
2025-10-12 03:40:05,604 - INFO - _models.training_function_executor - Epoch 026/34 - train_loss: 0.8811 - val_loss: 0.9203 - val_acc: 0.7243
2025-10-12 03:40:22,065 - INFO - _models.training_function_executor - Epoch 027/34 - train_loss: 0.8761 - val_loss: 0.9038 - val_acc: 0.7289
2025-10-12 03:40:38,527 - INFO - _models.training_function_executor - Epoch 028/34 - train_loss: 0.8716 - val_loss: 0.8362 - val_acc: 0.7677
2025-10-12 03:40:54,993 - INFO - _models.training_function_executor - Epoch 029/34 - train_loss: 0.8694 - val_loss: 0.9134 - val_acc: 0.7213
2025-10-12 03:41:11,435 - INFO - _models.training_function_executor - Epoch 030/34 - train_loss: 0.8650 - val_loss: 0.8446 - val_acc: 0.7604
2025-10-12 03:41:27,917 - INFO - _models.training_function_executor - Epoch 031/34 - train_loss: 0.8617 - val_loss: 0.9810 - val_acc: 0.6790
2025-10-12 03:41:44,345 - INFO - _models.training_function_executor - Epoch 032/34 - train_loss: 0.8585 - val_loss: 0.8375 - val_acc: 0.7646
2025-10-12 03:42:00,837 - INFO - _models.training_function_executor - Epoch 033/34 - train_loss: 0.8518 - val_loss: 0.8493 - val_acc: 0.7574
2025-10-12 03:42:17,317 - INFO - _models.training_function_executor - Epoch 034/34 - train_loss: 0.8491 - val_loss: 0.9110 - val_acc: 0.7224
2025-10-12 03:42:17,320 - INFO - _models.training_function_executor - Model: 84,377 parameters, 362.6KB storage
2025-10-12 03:42:17,320 - WARNING - _models.training_function_executor - Model storage 362.6KB exceeds 256KB limit!
2025-10-12 03:42:17,320 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6343587162113289, 1.4832939200356243, 1.3828350160353076, 1.3111934473266709, 1.2556981180028812, 1.2068891362122485, 1.162485827505067, 1.1200277704353052, 1.0798143375616704, 1.0496207216547886, 1.0199129266425118, 1.00042628207155, 0.9791598497965889, 0.9674794071405802, 0.9554072018474142, 0.9455171912793809, 0.9339371199452631, 0.9254194669553272, 0.9186844128514238, 0.9103596464169789, 0.9039323316156176, 0.8985010816953296, 0.8933349915179999, 0.888718719807045, 0.8830336593104527, 0.8810562047876592, 0.8760571576600147, 0.87156094825055, 0.8693603386526806, 0.8650165572214844, 0.861725110460254, 0.8584539758019987, 0.8517539789929521, 0.8491144743589909], 'val_losses': [1.5688977316621722, 1.45371399636781, 1.4385443267014464, 1.3070053377892532, 1.2874907400376905, 1.2691006490222048, 1.1842205219849615, 1.1791409326676183, 1.2113653531139617, 1.0041731775203366, 1.0946349016552752, 1.059737829257443, 1.072791596664012, 1.0340362092937085, 1.0990820016984468, 1.1052422511398188, 1.0381420688650849, 1.0594552780391038, 0.9765653829704768, 1.2161113078418126, 1.007733660266664, 0.8830050514593047, 0.9188922828713372, 1.0862229975487412, 1.124255827018169, 0.9202589898999021, 0.9037547757628084, 0.8362028766938511, 0.9133693872526221, 0.8445728579141646, 0.981028672444641, 0.8375007274019831, 0.8492642720971526, 0.9109570885772759], 'val_acc': [0.3756562828141407, 0.46937346867343366, 0.44005950297514873, 0.508400420021001, 0.5371893594679734, 0.5168008400420021, 0.5864543227161358, 0.5971298564928247, 0.5208260413020651, 0.6991599579978999, 0.6448197409870493, 0.6523451172558627, 0.6472698634931746, 0.6693209660483024, 0.626618830941547, 0.6313440672033601, 0.6623206160308015, 0.6323941197059852, 0.688484424221211, 0.5507525376268814, 0.674221211060553, 0.7396744837241862, 0.7210360518025901, 0.6326566328316415, 0.6201435071753588, 0.7242737136856843, 0.7289114455722786, 0.7676758837941897, 0.7212985649282464, 0.7604130206510326, 0.6790339516975848, 0.7646132306615331, 0.7573503675183759, 0.7224361218060903], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.0674350435890964e-05, 'batch_size': 32, 'epochs': 34, 'weight_decay': 4.510733748760559e-06, 'dropout': 0.03014725524986895, 'base_channels': 24, 'temporal_kernel': 7, 'spatial_segments': 25, 'label_smoothing': 0.08908799751401124, 'grad_clip': 0.6921019101049516, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 3615}, 'model_parameter_count': 84377, 'model_storage_size_kb': 362.55742187500005, 'model_size_validation': 'FAIL'}
2025-10-12 03:42:17,320 - INFO - _models.training_function_executor - BO Objective: base=0.7224, size_penalty=0.2081, final=0.5143
2025-10-12 03:42:17,320 - INFO - _models.training_function_executor - Model: 84,377 parameters, 362.6KB (FAIL 256KB limit)
2025-10-12 03:42:17,320 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 560.104s
2025-10-12 03:42:17,421 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5143
2025-10-12 03:42:17,422 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-12 03:42:17,422 - INFO - bo.run_bo - Recorded observation #13: hparams={'lr': 2.0674350435890964e-05, 'batch_size': np.int64(32), 'epochs': np.int64(34), 'weight_decay': 4.510733748760559e-06, 'dropout': 0.03014725524986895, 'base_channels': np.int64(24), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(25), 'label_smoothing': 0.08908799751401124, 'grad_clip': 0.6921019101049516, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(3615)}, value=0.5143
2025-10-12 03:42:17,422 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 13: {'lr': 2.0674350435890964e-05, 'batch_size': np.int64(32), 'epochs': np.int64(34), 'weight_decay': 4.510733748760559e-06, 'dropout': 0.03014725524986895, 'base_channels': np.int64(24), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(25), 'label_smoothing': 0.08908799751401124, 'grad_clip': 0.6921019101049516, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(3615)} -> 0.5143
2025-10-12 03:42:17,422 - INFO - bo.run_bo - üîçBO Trial 14: Using RF surrogate + Expected Improvement
2025-10-12 03:42:17,422 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 03:42:17,422 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 03:42:17,422 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 03:42:17,422 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 5.201290249443388e-05, 'batch_size': 16, 'epochs': 43, 'weight_decay': 2.7432136815929644e-06, 'dropout': 0.015527359777809783, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 100, 'label_smoothing': 0.011915454457737586, 'grad_clip': 0.5175408585263696, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 576}
2025-10-12 03:42:17,423 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 5.201290249443388e-05, 'batch_size': 16, 'epochs': 43, 'weight_decay': 2.7432136815929644e-06, 'dropout': 0.015527359777809783, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 100, 'label_smoothing': 0.011915454457737586, 'grad_clip': 0.5175408585263696, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 576}
2025-10-12 03:42:32,535 - INFO - _models.training_function_executor - Epoch 001/43 - train_loss: 1.4104 - val_loss: 1.2670 - val_acc: 0.5258
2025-10-12 03:42:47,589 - INFO - _models.training_function_executor - Epoch 002/43 - train_loss: 1.0457 - val_loss: 1.0223 - val_acc: 0.6047
2025-10-12 03:43:02,637 - INFO - _models.training_function_executor - Epoch 003/43 - train_loss: 0.9447 - val_loss: 0.9138 - val_acc: 0.6493
2025-10-12 03:43:17,616 - INFO - _models.training_function_executor - Epoch 004/43 - train_loss: 0.8939 - val_loss: 1.0498 - val_acc: 0.5836
2025-10-12 03:43:32,674 - INFO - _models.training_function_executor - Epoch 005/43 - train_loss: 0.8601 - val_loss: 0.9517 - val_acc: 0.6268
2025-10-12 03:43:47,682 - INFO - _models.training_function_executor - Epoch 006/43 - train_loss: 0.8261 - val_loss: 0.7706 - val_acc: 0.7205
2025-10-12 03:44:02,690 - INFO - _models.training_function_executor - Epoch 007/43 - train_loss: 0.8040 - val_loss: 0.7953 - val_acc: 0.7119
2025-10-12 03:44:17,732 - INFO - _models.training_function_executor - Epoch 008/43 - train_loss: 0.7835 - val_loss: 1.1071 - val_acc: 0.5637
2025-10-12 03:44:32,779 - INFO - _models.training_function_executor - Epoch 009/43 - train_loss: 0.7634 - val_loss: 0.7213 - val_acc: 0.7380
2025-10-12 03:44:47,823 - INFO - _models.training_function_executor - Epoch 010/43 - train_loss: 0.7473 - val_loss: 1.0546 - val_acc: 0.5972
2025-10-12 03:45:02,859 - INFO - _models.training_function_executor - Epoch 011/43 - train_loss: 0.7294 - val_loss: 0.7067 - val_acc: 0.7535
2025-10-12 03:45:17,881 - INFO - _models.training_function_executor - Epoch 012/43 - train_loss: 0.7187 - val_loss: 0.9198 - val_acc: 0.6565
2025-10-12 03:45:32,862 - INFO - _models.training_function_executor - Epoch 013/43 - train_loss: 0.7080 - val_loss: 0.7539 - val_acc: 0.7265
2025-10-12 03:45:47,896 - INFO - _models.training_function_executor - Epoch 014/43 - train_loss: 0.6978 - val_loss: 0.7394 - val_acc: 0.7468
2025-10-12 03:46:02,922 - INFO - _models.training_function_executor - Epoch 015/43 - train_loss: 0.6855 - val_loss: 0.7174 - val_acc: 0.7679
2025-10-12 03:46:17,946 - INFO - _models.training_function_executor - Epoch 016/43 - train_loss: 0.6748 - val_loss: 0.7193 - val_acc: 0.7679
2025-10-12 03:46:32,980 - INFO - _models.training_function_executor - Epoch 017/43 - train_loss: 0.6647 - val_loss: 1.2755 - val_acc: 0.5553
2025-10-12 03:46:48,019 - INFO - _models.training_function_executor - Epoch 018/43 - train_loss: 0.6568 - val_loss: 0.7520 - val_acc: 0.7342
2025-10-12 03:47:03,022 - INFO - _models.training_function_executor - Epoch 019/43 - train_loss: 0.6502 - val_loss: 0.7470 - val_acc: 0.7337
2025-10-12 03:47:18,078 - INFO - _models.training_function_executor - Epoch 020/43 - train_loss: 0.6404 - val_loss: 0.9624 - val_acc: 0.6419
2025-10-12 03:47:33,146 - INFO - _models.training_function_executor - Epoch 021/43 - train_loss: 0.6346 - val_loss: 0.6727 - val_acc: 0.7690
2025-10-12 03:47:48,130 - INFO - _models.training_function_executor - Epoch 022/43 - train_loss: 0.6314 - val_loss: 0.8492 - val_acc: 0.6882
2025-10-12 03:48:03,103 - INFO - _models.training_function_executor - Epoch 023/43 - train_loss: 0.6212 - val_loss: 0.7285 - val_acc: 0.7411
2025-10-12 03:48:18,132 - INFO - _models.training_function_executor - Epoch 024/43 - train_loss: 0.6160 - val_loss: 0.6605 - val_acc: 0.7743
2025-10-12 03:48:33,133 - INFO - _models.training_function_executor - Epoch 025/43 - train_loss: 0.6079 - val_loss: 0.7579 - val_acc: 0.7251
2025-10-12 03:48:48,179 - INFO - _models.training_function_executor - Epoch 026/43 - train_loss: 0.6050 - val_loss: 0.9247 - val_acc: 0.6543
2025-10-12 03:49:03,208 - INFO - _models.training_function_executor - Epoch 027/43 - train_loss: 0.5952 - val_loss: 0.6585 - val_acc: 0.7728
2025-10-12 03:49:18,251 - INFO - _models.training_function_executor - Epoch 028/43 - train_loss: 0.5955 - val_loss: 0.7522 - val_acc: 0.7337
2025-10-12 03:49:33,286 - INFO - _models.training_function_executor - Epoch 029/43 - train_loss: 0.5903 - val_loss: 0.8844 - val_acc: 0.6775
2025-10-12 03:49:48,330 - INFO - _models.training_function_executor - Epoch 030/43 - train_loss: 0.5855 - val_loss: 0.6436 - val_acc: 0.7756
2025-10-12 03:50:03,347 - INFO - _models.training_function_executor - Epoch 031/43 - train_loss: 0.5824 - val_loss: 0.9259 - val_acc: 0.6558
2025-10-12 03:50:18,367 - INFO - _models.training_function_executor - Epoch 032/43 - train_loss: 0.5799 - val_loss: 0.6742 - val_acc: 0.7617
2025-10-12 03:50:33,354 - INFO - _models.training_function_executor - Epoch 033/43 - train_loss: 0.5739 - val_loss: 0.7537 - val_acc: 0.7318
2025-10-12 03:50:48,360 - INFO - _models.training_function_executor - Epoch 034/43 - train_loss: 0.5696 - val_loss: 0.6589 - val_acc: 0.7746
2025-10-12 03:51:03,373 - INFO - _models.training_function_executor - Epoch 035/43 - train_loss: 0.5700 - val_loss: 0.6907 - val_acc: 0.7584
2025-10-12 03:51:18,376 - INFO - _models.training_function_executor - Epoch 036/43 - train_loss: 0.5626 - val_loss: 0.6309 - val_acc: 0.7887
2025-10-12 03:51:33,395 - INFO - _models.training_function_executor - Epoch 037/43 - train_loss: 0.5626 - val_loss: 0.7075 - val_acc: 0.7481
2025-10-12 03:51:48,427 - INFO - _models.training_function_executor - Epoch 038/43 - train_loss: 0.5590 - val_loss: 0.6718 - val_acc: 0.7749
2025-10-12 03:52:03,419 - INFO - _models.training_function_executor - Epoch 039/43 - train_loss: 0.5542 - val_loss: 0.6720 - val_acc: 0.7610
2025-10-12 03:52:18,441 - INFO - _models.training_function_executor - Epoch 040/43 - train_loss: 0.5476 - val_loss: 0.6756 - val_acc: 0.7644
2025-10-12 03:52:33,454 - INFO - _models.training_function_executor - Epoch 041/43 - train_loss: 0.5494 - val_loss: 0.6503 - val_acc: 0.7746
2025-10-12 03:52:48,454 - INFO - _models.training_function_executor - Epoch 042/43 - train_loss: 0.5458 - val_loss: 0.6517 - val_acc: 0.7819
2025-10-12 03:53:03,474 - INFO - _models.training_function_executor - Epoch 043/43 - train_loss: 0.5434 - val_loss: 0.7458 - val_acc: 0.7336
2025-10-12 03:53:03,477 - INFO - _models.training_function_executor - Model: 56,069 parameters, 240.9KB storage
2025-10-12 03:53:03,477 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4103752468948312, 1.0457187053683257, 0.9446964765245947, 0.8938813218191699, 0.8600542696155699, 0.8261490062395509, 0.8040454836003548, 0.7835103114939754, 0.7633613314835559, 0.7473127132410097, 0.7293838408544508, 0.7186865700701546, 0.7079785287557551, 0.6977957773237826, 0.6855329467119935, 0.6747791212903564, 0.6646961971183819, 0.6567707442824224, 0.6501670310004508, 0.6404470693389144, 0.6345948222105345, 0.6313801141032649, 0.6212264625893467, 0.6159602705210625, 0.6079493329726945, 0.60495025983506, 0.5952145012058409, 0.5954576661203306, 0.5903211380578356, 0.5854970597286178, 0.5823650874320051, 0.5799232699683716, 0.5738746500021518, 0.5696361495672843, 0.5700447238749626, 0.5626387176008378, 0.5625532052401775, 0.5589768969234488, 0.554210218346991, 0.5476426434946677, 0.5493750570431263, 0.5458419937581752, 0.5434343572947209], 'val_losses': [1.266961242420756, 1.0222940706772783, 0.9137992103658108, 1.0498006439288263, 0.95172418384315, 0.7706117781259232, 0.7952743794561726, 1.1071384462978109, 0.7213305552021624, 1.054622371045701, 0.7066739433329966, 0.9197804153820915, 0.753924473290849, 0.739426541670578, 0.7174213344624378, 0.719299816818224, 1.2755003100118314, 0.7519668169504786, 0.7470312640879344, 0.962386553088059, 0.6726789821068391, 0.8491556147699553, 0.7285095287299799, 0.6604729724756521, 0.757873984037432, 0.924718924583903, 0.6585030280337869, 0.752155812910315, 0.8844173215029746, 0.6435570042367827, 0.9259481501925605, 0.6741782821764427, 0.7536834266204954, 0.6589252069034399, 0.6907475541157033, 0.6308585146965578, 0.7075399208108487, 0.6717710860300448, 0.6719652331392791, 0.6755968090388005, 0.650291559983685, 0.6517087165442305, 0.745750823136097], 'val_acc': [0.5258137906895345, 0.6047427371368569, 0.6492824641232061, 0.5835666783339167, 0.6267938396919845, 0.7205110255512776, 0.711935596779839, 0.563703185159258, 0.7380119005950297, 0.5972173608680434, 0.7535001750087504, 0.6565453272663633, 0.7265488274413721, 0.7468498424921246, 0.7678508925446272, 0.7678508925446272, 0.5553027651382569, 0.734249212460623, 0.7337241862093105, 0.6419320966048302, 0.7689884494224711, 0.6882219110955548, 0.7410745537276864, 0.7743262163108156, 0.7250612530626531, 0.6542702135106755, 0.7727511375568779, 0.7337241862093105, 0.6775463773188659, 0.775638781939097, 0.6557577878893944, 0.761725586279314, 0.7317990899544977, 0.7745887294364718, 0.758400420021001, 0.7886769338466924, 0.7480749037451873, 0.7749387469373469, 0.7610255512775639, 0.7644382219110956, 0.7745887294364718, 0.781851592579629, 0.7336366818340917], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 5.201290249443388e-05, 'batch_size': 16, 'epochs': 43, 'weight_decay': 2.7432136815929644e-06, 'dropout': 0.015527359777809783, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 100, 'label_smoothing': 0.011915454457737586, 'grad_clip': 0.5175408585263696, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 576}, 'model_parameter_count': 56069, 'model_storage_size_kb': 240.921484375, 'model_size_validation': 'PASS'}
2025-10-12 03:53:03,477 - INFO - _models.training_function_executor - BO Objective: base=0.7336, size_penalty=0.0000, final=0.7336
2025-10-12 03:53:03,477 - INFO - _models.training_function_executor - Model: 56,069 parameters, 240.9KB (PASS 256KB limit)
2025-10-12 03:53:03,477 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 646.055s
2025-10-12 03:53:03,574 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7336
2025-10-12 03:53:03,574 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-12 03:53:03,574 - INFO - bo.run_bo - Recorded observation #14: hparams={'lr': 5.201290249443388e-05, 'batch_size': np.int64(16), 'epochs': np.int64(43), 'weight_decay': 2.7432136815929644e-06, 'dropout': 0.015527359777809783, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(100), 'label_smoothing': 0.011915454457737586, 'grad_clip': 0.5175408585263696, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(576)}, value=0.7336
2025-10-12 03:53:03,574 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 14: {'lr': 5.201290249443388e-05, 'batch_size': np.int64(16), 'epochs': np.int64(43), 'weight_decay': 2.7432136815929644e-06, 'dropout': 0.015527359777809783, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(100), 'label_smoothing': 0.011915454457737586, 'grad_clip': 0.5175408585263696, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(576)} -> 0.7336
2025-10-12 03:53:03,575 - INFO - bo.run_bo - üîçBO Trial 15: Using RF surrogate + Expected Improvement
2025-10-12 03:53:03,575 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 03:53:03,575 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 03:53:03,575 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 03:53:03,575 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 7.369793709761812e-06, 'batch_size': 8, 'epochs': 44, 'weight_decay': 0.00026244372847505166, 'dropout': 0.01386227286854164, 'base_channels': 16, 'temporal_kernel': 7, 'spatial_segments': 250, 'label_smoothing': 0.05168699022624795, 'grad_clip': 0.6617595775329063, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 720}
2025-10-12 03:53:03,576 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 7.369793709761812e-06, 'batch_size': 8, 'epochs': 44, 'weight_decay': 0.00026244372847505166, 'dropout': 0.01386227286854164, 'base_channels': 16, 'temporal_kernel': 7, 'spatial_segments': 250, 'label_smoothing': 0.05168699022624795, 'grad_clip': 0.6617595775329063, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 720}
2025-10-12 03:53:19,685 - INFO - _models.training_function_executor - Epoch 001/44 - train_loss: 1.6625 - val_loss: 1.5673 - val_acc: 0.3243
2025-10-12 03:53:35,632 - INFO - _models.training_function_executor - Epoch 002/44 - train_loss: 1.4828 - val_loss: 1.4672 - val_acc: 0.4220
2025-10-12 03:53:51,662 - INFO - _models.training_function_executor - Epoch 003/44 - train_loss: 1.3811 - val_loss: 1.3393 - val_acc: 0.5047
2025-10-12 03:54:07,629 - INFO - _models.training_function_executor - Epoch 004/44 - train_loss: 1.3114 - val_loss: 1.2922 - val_acc: 0.5058
2025-10-12 03:54:23,632 - INFO - _models.training_function_executor - Epoch 005/44 - train_loss: 1.2679 - val_loss: 1.2569 - val_acc: 0.5571
2025-10-12 03:54:39,656 - INFO - _models.training_function_executor - Epoch 006/44 - train_loss: 1.2341 - val_loss: 1.2029 - val_acc: 0.5861
2025-10-12 03:54:55,726 - INFO - _models.training_function_executor - Epoch 007/44 - train_loss: 1.2081 - val_loss: 1.7005 - val_acc: 0.2563
2025-10-12 03:55:11,670 - INFO - _models.training_function_executor - Epoch 008/44 - train_loss: 1.1829 - val_loss: 1.1696 - val_acc: 0.5900
2025-10-12 03:55:27,561 - INFO - _models.training_function_executor - Epoch 009/44 - train_loss: 1.1622 - val_loss: 1.1072 - val_acc: 0.6187
2025-10-12 03:55:43,547 - INFO - _models.training_function_executor - Epoch 010/44 - train_loss: 1.1405 - val_loss: 1.1572 - val_acc: 0.5722
2025-10-12 03:55:59,570 - INFO - _models.training_function_executor - Epoch 011/44 - train_loss: 1.1218 - val_loss: 1.0822 - val_acc: 0.6250
2025-10-12 03:56:15,607 - INFO - _models.training_function_executor - Epoch 012/44 - train_loss: 1.1057 - val_loss: 1.0780 - val_acc: 0.6138
2025-10-12 03:56:31,640 - INFO - _models.training_function_executor - Epoch 013/44 - train_loss: 1.0927 - val_loss: 1.0789 - val_acc: 0.6072
2025-10-12 03:56:47,632 - INFO - _models.training_function_executor - Epoch 014/44 - train_loss: 1.0781 - val_loss: 1.0470 - val_acc: 0.6275
2025-10-12 03:57:03,615 - INFO - _models.training_function_executor - Epoch 015/44 - train_loss: 1.0633 - val_loss: 1.0731 - val_acc: 0.6127
2025-10-12 03:57:19,664 - INFO - _models.training_function_executor - Epoch 016/44 - train_loss: 1.0523 - val_loss: 1.0380 - val_acc: 0.6231
2025-10-12 03:57:35,623 - INFO - _models.training_function_executor - Epoch 017/44 - train_loss: 1.0442 - val_loss: 1.0499 - val_acc: 0.6184
2025-10-12 03:57:51,610 - INFO - _models.training_function_executor - Epoch 018/44 - train_loss: 1.0356 - val_loss: 1.0100 - val_acc: 0.6412
2025-10-12 03:58:07,622 - INFO - _models.training_function_executor - Epoch 019/44 - train_loss: 1.0275 - val_loss: 1.1049 - val_acc: 0.6089
2025-10-12 03:58:23,600 - INFO - _models.training_function_executor - Epoch 020/44 - train_loss: 1.0204 - val_loss: 0.9991 - val_acc: 0.6467
2025-10-12 03:58:39,607 - INFO - _models.training_function_executor - Epoch 021/44 - train_loss: 1.0133 - val_loss: 0.9783 - val_acc: 0.6599
2025-10-12 03:58:55,569 - INFO - _models.training_function_executor - Epoch 022/44 - train_loss: 1.0043 - val_loss: 1.0084 - val_acc: 0.6404
2025-10-12 03:59:11,567 - INFO - _models.training_function_executor - Epoch 023/44 - train_loss: 1.0006 - val_loss: 1.0083 - val_acc: 0.6440
2025-10-12 03:59:27,532 - INFO - _models.training_function_executor - Epoch 024/44 - train_loss: 0.9928 - val_loss: 1.1037 - val_acc: 0.6065
2025-10-12 03:59:43,485 - INFO - _models.training_function_executor - Epoch 025/44 - train_loss: 0.9861 - val_loss: 0.9924 - val_acc: 0.6456
2025-10-12 03:59:59,461 - INFO - _models.training_function_executor - Epoch 026/44 - train_loss: 0.9791 - val_loss: 1.0521 - val_acc: 0.6191
2025-10-12 04:00:15,547 - INFO - _models.training_function_executor - Epoch 027/44 - train_loss: 0.9778 - val_loss: 0.9813 - val_acc: 0.6639
2025-10-12 04:00:31,532 - INFO - _models.training_function_executor - Epoch 028/44 - train_loss: 0.9689 - val_loss: 0.9663 - val_acc: 0.6626
2025-10-12 04:00:47,498 - INFO - _models.training_function_executor - Epoch 029/44 - train_loss: 0.9615 - val_loss: 0.9458 - val_acc: 0.6852
2025-10-12 04:01:03,473 - INFO - _models.training_function_executor - Epoch 030/44 - train_loss: 0.9592 - val_loss: 0.9377 - val_acc: 0.6903
2025-10-12 04:01:19,399 - INFO - _models.training_function_executor - Epoch 031/44 - train_loss: 0.9481 - val_loss: 0.9732 - val_acc: 0.6698
2025-10-12 04:01:35,437 - INFO - _models.training_function_executor - Epoch 032/44 - train_loss: 0.9448 - val_loss: 0.9723 - val_acc: 0.6580
2025-10-12 04:01:51,381 - INFO - _models.training_function_executor - Epoch 033/44 - train_loss: 0.9448 - val_loss: 1.4182 - val_acc: 0.5106
2025-10-12 04:02:07,393 - INFO - _models.training_function_executor - Epoch 034/44 - train_loss: 0.9367 - val_loss: 1.5769 - val_acc: 0.4835
2025-10-12 04:02:23,352 - INFO - _models.training_function_executor - Epoch 035/44 - train_loss: 0.9317 - val_loss: 0.9214 - val_acc: 0.6957
2025-10-12 04:02:39,322 - INFO - _models.training_function_executor - Epoch 036/44 - train_loss: 0.9260 - val_loss: 0.9297 - val_acc: 0.6883
2025-10-12 04:02:55,323 - INFO - _models.training_function_executor - Epoch 037/44 - train_loss: 0.9219 - val_loss: 0.9662 - val_acc: 0.6750
2025-10-12 04:03:11,282 - INFO - _models.training_function_executor - Epoch 038/44 - train_loss: 0.9158 - val_loss: 1.2519 - val_acc: 0.5751
2025-10-12 04:03:27,236 - INFO - _models.training_function_executor - Epoch 039/44 - train_loss: 0.9111 - val_loss: 0.9006 - val_acc: 0.7066
2025-10-12 04:03:43,221 - INFO - _models.training_function_executor - Epoch 040/44 - train_loss: 0.9103 - val_loss: 0.9221 - val_acc: 0.6863
2025-10-12 04:03:59,228 - INFO - _models.training_function_executor - Epoch 041/44 - train_loss: 0.9019 - val_loss: 0.8918 - val_acc: 0.7111
2025-10-12 04:04:15,225 - INFO - _models.training_function_executor - Epoch 042/44 - train_loss: 0.8981 - val_loss: 0.8955 - val_acc: 0.7118
2025-10-12 04:04:31,223 - INFO - _models.training_function_executor - Epoch 043/44 - train_loss: 0.8955 - val_loss: 0.9196 - val_acc: 0.6978
2025-10-12 04:04:47,219 - INFO - _models.training_function_executor - Epoch 044/44 - train_loss: 0.8889 - val_loss: 1.0532 - val_acc: 0.6431
2025-10-12 04:04:47,625 - INFO - _models.training_function_executor - Model: 10,372 parameters, 11.1KB storage
2025-10-12 04:04:47,625 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6624945331838192, 1.4828293732425155, 1.3810820456126123, 1.3114111696793394, 1.2678778453602588, 1.2341414246060107, 1.2081037014670668, 1.1829329953458203, 1.162211919523512, 1.1404806582565528, 1.1218439910559543, 1.1056631969788044, 1.092667655236328, 1.0781025861500442, 1.0632565407317796, 1.0522616859662353, 1.0441858631030303, 1.0356491463696327, 1.0274980126413633, 1.020421499117171, 1.0133315795914544, 1.0042920138583886, 1.0006462825337699, 0.9928194773929454, 0.9861455053393557, 0.9790523825073142, 0.9778369139458777, 0.9689436774279715, 0.9614680415742415, 0.9592380200466745, 0.9481296027649688, 0.9447732032764029, 0.94481331034895, 0.9367419410292235, 0.9317005507368953, 0.9259671554475303, 0.9219048699070033, 0.9157875835280089, 0.9111172059250329, 0.9102667906003103, 0.9019331206725033, 0.8981032725769112, 0.8955193346077469, 0.8888891195088865], 'val_losses': [1.5673106159828407, 1.4671760573435548, 1.3392762534051748, 1.2922463396607806, 1.2569203071131922, 1.2028773877643228, 1.700525433649164, 1.169637823797499, 1.1072101585715644, 1.1572441331648435, 1.0821712996144373, 1.0779506354887751, 1.0788911707049949, 1.0469561831534722, 1.0731044512634558, 1.0380319977374106, 1.0499056151875426, 1.0100329851703624, 1.1049227177324852, 0.9990936426336965, 0.9782501991537011, 1.008385631247004, 1.0083440618995692, 1.1037493751188405, 0.9924225585837025, 1.0520508979891496, 0.9813124822243385, 0.9663038487237443, 0.945831305754531, 0.937686263263163, 0.9731783964519615, 0.9723008394366509, 1.4181523389402368, 1.5768931913008672, 0.9213857400196184, 0.9297077673734131, 0.9662115223181594, 1.2519299027842161, 0.9005547389518476, 0.9220862604748089, 0.8917656486627727, 0.8954647423130339, 0.9196003921014427, 1.0532225693569843], 'val_acc': [0.324291214560728, 0.422033601680084, 0.5047252362618131, 0.5057752887644382, 0.5571403570178509, 0.5861043052152608, 0.2563003150157508, 0.5899544977248863, 0.6186559327966399, 0.5721911095554778, 0.6250437521876093, 0.613843192159608, 0.6071928596429822, 0.6274938746937346, 0.6127056352817641, 0.6231186559327967, 0.6183934196709836, 0.6412320616030801, 0.6088554427721387, 0.6466573328666433, 0.6598704935246762, 0.6403570178508925, 0.6440322016100805, 0.6064928246412321, 0.6456072803640182, 0.6190934546727337, 0.6638956947847392, 0.6625831291564578, 0.6851592579628981, 0.690322016100805, 0.669845992299615, 0.6580329016450822, 0.5105880294014701, 0.48354917745887294, 0.6956597829891494, 0.6883094154707735, 0.6750087504375218, 0.5750787539376969, 0.7065978298914946, 0.686296814840742, 0.7110605530276514, 0.7117605880294015, 0.6977598879943997, 0.6430696534826741], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 7.369793709761812e-06, 'batch_size': 8, 'epochs': 44, 'weight_decay': 0.00026244372847505166, 'dropout': 0.01386227286854164, 'base_channels': 16, 'temporal_kernel': 7, 'spatial_segments': 250, 'label_smoothing': 0.05168699022624795, 'grad_clip': 0.6617595775329063, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 720}, 'model_parameter_count': 10372, 'model_storage_size_kb': 11.141796875, 'model_size_validation': 'PASS'}
2025-10-12 04:04:47,625 - INFO - _models.training_function_executor - BO Objective: base=0.6431, size_penalty=0.0000, final=0.6431
2025-10-12 04:04:47,625 - INFO - _models.training_function_executor - Model: 10,372 parameters, 11.1KB (PASS 256KB limit)
2025-10-12 04:04:47,625 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 704.051s
2025-10-12 04:04:47,722 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6431
2025-10-12 04:04:47,722 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-12 04:04:47,722 - INFO - bo.run_bo - Recorded observation #15: hparams={'lr': 7.369793709761812e-06, 'batch_size': np.int64(8), 'epochs': np.int64(44), 'weight_decay': 0.00026244372847505166, 'dropout': 0.01386227286854164, 'base_channels': np.int64(16), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(250), 'label_smoothing': 0.05168699022624795, 'grad_clip': 0.6617595775329063, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(720)}, value=0.6431
2025-10-12 04:04:47,722 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 15: {'lr': 7.369793709761812e-06, 'batch_size': np.int64(8), 'epochs': np.int64(44), 'weight_decay': 0.00026244372847505166, 'dropout': 0.01386227286854164, 'base_channels': np.int64(16), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(250), 'label_smoothing': 0.05168699022624795, 'grad_clip': 0.6617595775329063, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(720)} -> 0.6431
2025-10-12 04:04:47,723 - INFO - bo.run_bo - üîçBO Trial 16: Using RF surrogate + Expected Improvement
2025-10-12 04:04:47,723 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 04:04:47,723 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 04:04:47,723 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 04:04:47,723 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 6.302733026208444e-06, 'batch_size': 48, 'epochs': 39, 'weight_decay': 3.897854077640694e-06, 'dropout': 0.27353407318800105, 'base_channels': 9, 'temporal_kernel': 5, 'spatial_segments': 60, 'label_smoothing': 0.024081194357260933, 'grad_clip': 0.006613940532034681, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 583}
2025-10-12 04:04:47,724 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 6.302733026208444e-06, 'batch_size': 48, 'epochs': 39, 'weight_decay': 3.897854077640694e-06, 'dropout': 0.27353407318800105, 'base_channels': 9, 'temporal_kernel': 5, 'spatial_segments': 60, 'label_smoothing': 0.024081194357260933, 'grad_clip': 0.006613940532034681, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 583}
2025-10-12 04:04:57,498 - INFO - _models.training_function_executor - Epoch 001/39 - train_loss: 2.0395 - val_loss: 1.9070 - val_acc: 0.2484
2025-10-12 04:05:07,029 - INFO - _models.training_function_executor - Epoch 002/39 - train_loss: 1.9169 - val_loss: 1.8053 - val_acc: 0.2582
2025-10-12 04:05:16,578 - INFO - _models.training_function_executor - Epoch 003/39 - train_loss: 1.8234 - val_loss: 1.7314 - val_acc: 0.2641
2025-10-12 04:05:26,097 - INFO - _models.training_function_executor - Epoch 004/39 - train_loss: 1.7538 - val_loss: 1.6758 - val_acc: 0.2726
2025-10-12 04:05:35,617 - INFO - _models.training_function_executor - Epoch 005/39 - train_loss: 1.7067 - val_loss: 1.6368 - val_acc: 0.2805
2025-10-12 04:05:45,132 - INFO - _models.training_function_executor - Epoch 006/39 - train_loss: 1.6678 - val_loss: 1.6100 - val_acc: 0.2865
2025-10-12 04:05:54,693 - INFO - _models.training_function_executor - Epoch 007/39 - train_loss: 1.6334 - val_loss: 1.5974 - val_acc: 0.2882
2025-10-12 04:06:04,243 - INFO - _models.training_function_executor - Epoch 008/39 - train_loss: 1.6077 - val_loss: 1.5607 - val_acc: 0.3052
2025-10-12 04:06:13,795 - INFO - _models.training_function_executor - Epoch 009/39 - train_loss: 1.5864 - val_loss: 1.5505 - val_acc: 0.3096
2025-10-12 04:06:23,346 - INFO - _models.training_function_executor - Epoch 010/39 - train_loss: 1.5648 - val_loss: 1.5315 - val_acc: 0.3253
2025-10-12 04:06:32,888 - INFO - _models.training_function_executor - Epoch 011/39 - train_loss: 1.5454 - val_loss: 1.5254 - val_acc: 0.3297
2025-10-12 04:06:42,457 - INFO - _models.training_function_executor - Epoch 012/39 - train_loss: 1.5323 - val_loss: 1.5386 - val_acc: 0.3267
2025-10-12 04:06:52,013 - INFO - _models.training_function_executor - Epoch 013/39 - train_loss: 1.5183 - val_loss: 1.4939 - val_acc: 0.3483
2025-10-12 04:07:01,527 - INFO - _models.training_function_executor - Epoch 014/39 - train_loss: 1.5031 - val_loss: 1.4728 - val_acc: 0.3645
2025-10-12 04:07:11,050 - INFO - _models.training_function_executor - Epoch 015/39 - train_loss: 1.4890 - val_loss: 1.4907 - val_acc: 0.3500
2025-10-12 04:07:20,586 - INFO - _models.training_function_executor - Epoch 016/39 - train_loss: 1.4772 - val_loss: 1.4735 - val_acc: 0.3623
2025-10-12 04:07:30,101 - INFO - _models.training_function_executor - Epoch 017/39 - train_loss: 1.4660 - val_loss: 1.4426 - val_acc: 0.3813
2025-10-12 04:07:39,688 - INFO - _models.training_function_executor - Epoch 018/39 - train_loss: 1.4542 - val_loss: 1.4816 - val_acc: 0.3582
2025-10-12 04:07:49,251 - INFO - _models.training_function_executor - Epoch 019/39 - train_loss: 1.4419 - val_loss: 1.4459 - val_acc: 0.3773
2025-10-12 04:07:58,790 - INFO - _models.training_function_executor - Epoch 020/39 - train_loss: 1.4337 - val_loss: 1.4210 - val_acc: 0.3919
2025-10-12 04:08:08,317 - INFO - _models.training_function_executor - Epoch 021/39 - train_loss: 1.4197 - val_loss: 1.4082 - val_acc: 0.3989
2025-10-12 04:08:17,822 - INFO - _models.training_function_executor - Epoch 022/39 - train_loss: 1.4122 - val_loss: 1.4028 - val_acc: 0.3979
2025-10-12 04:08:27,302 - INFO - _models.training_function_executor - Epoch 023/39 - train_loss: 1.4026 - val_loss: 1.4177 - val_acc: 0.3897
2025-10-12 04:08:36,847 - INFO - _models.training_function_executor - Epoch 024/39 - train_loss: 1.3939 - val_loss: 1.4313 - val_acc: 0.3880
2025-10-12 04:08:46,410 - INFO - _models.training_function_executor - Epoch 025/39 - train_loss: 1.3850 - val_loss: 1.4406 - val_acc: 0.3816
2025-10-12 04:08:55,938 - INFO - _models.training_function_executor - Epoch 026/39 - train_loss: 1.3768 - val_loss: 1.5001 - val_acc: 0.3639
2025-10-12 04:09:05,486 - INFO - _models.training_function_executor - Epoch 027/39 - train_loss: 1.3692 - val_loss: 1.3917 - val_acc: 0.4019
2025-10-12 04:09:15,036 - INFO - _models.training_function_executor - Epoch 028/39 - train_loss: 1.3603 - val_loss: 1.3988 - val_acc: 0.3991
2025-10-12 04:09:24,568 - INFO - _models.training_function_executor - Epoch 029/39 - train_loss: 1.3537 - val_loss: 1.3608 - val_acc: 0.4134
2025-10-12 04:09:34,094 - INFO - _models.training_function_executor - Epoch 030/39 - train_loss: 1.3434 - val_loss: 1.5092 - val_acc: 0.3628
2025-10-12 04:09:43,627 - INFO - _models.training_function_executor - Epoch 031/39 - train_loss: 1.3369 - val_loss: 1.3870 - val_acc: 0.4048
2025-10-12 04:09:53,159 - INFO - _models.training_function_executor - Epoch 032/39 - train_loss: 1.3329 - val_loss: 1.3697 - val_acc: 0.4128
2025-10-12 04:10:02,702 - INFO - _models.training_function_executor - Epoch 033/39 - train_loss: 1.3252 - val_loss: 1.3124 - val_acc: 0.4484
2025-10-12 04:10:12,217 - INFO - _models.training_function_executor - Epoch 034/39 - train_loss: 1.3168 - val_loss: 1.3013 - val_acc: 0.4554
2025-10-12 04:10:21,773 - INFO - _models.training_function_executor - Epoch 035/39 - train_loss: 1.3075 - val_loss: 1.4243 - val_acc: 0.3926
2025-10-12 04:10:31,315 - INFO - _models.training_function_executor - Epoch 036/39 - train_loss: 1.3018 - val_loss: 1.3681 - val_acc: 0.4126
2025-10-12 04:10:40,866 - INFO - _models.training_function_executor - Epoch 037/39 - train_loss: 1.2929 - val_loss: 1.3481 - val_acc: 0.4229
2025-10-12 04:10:50,334 - INFO - _models.training_function_executor - Epoch 038/39 - train_loss: 1.2868 - val_loss: 1.6369 - val_acc: 0.3405
2025-10-12 04:10:59,865 - INFO - _models.training_function_executor - Epoch 039/39 - train_loss: 1.2816 - val_loss: 1.2804 - val_acc: 0.4643
2025-10-12 04:10:59,868 - INFO - _models.training_function_executor - Model: 18,029 parameters, 77.5KB storage
2025-10-12 04:10:59,868 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [2.039461299010328, 1.9169322496366785, 1.8234201418506462, 1.7537706852543384, 1.7066559153167276, 1.6677606370760336, 1.6334048821286051, 1.6076500486317822, 1.5864349786827185, 1.564780602056245, 1.545433573928128, 1.53234584768794, 1.5183386440080155, 1.5030999067241093, 1.4889540335996025, 1.4772391569626928, 1.4659624638405553, 1.4542418033207969, 1.4418817400974038, 1.4336695532136168, 1.4197241615740035, 1.4121591625073426, 1.402595332756216, 1.3939015757674558, 1.385018336885577, 1.3767801193161198, 1.3692097053437706, 1.3603468383572759, 1.3536518686586299, 1.3434135665165865, 1.3368898593423915, 1.3329223231665104, 1.325179833901859, 1.3167998983512026, 1.3074970506561943, 1.301809557593282, 1.2928588216355683, 1.2868135844989386, 1.2815578679417579], 'val_losses': [1.907034512662704, 1.8052691782860226, 1.7313882560633178, 1.6758242859721892, 1.6367531542098728, 1.6099603574593917, 1.5973600898541727, 1.5606863109390343, 1.550452142526188, 1.5314851490233719, 1.5253609334583837, 1.5386436870559597, 1.4939423750278873, 1.4727836562738494, 1.4907248529221238, 1.4734596237253383, 1.442570846774255, 1.4815726602749262, 1.4458883167105954, 1.4209996724737912, 1.4082185783543117, 1.4027923275049976, 1.4177304827169726, 1.4312907147332425, 1.4406248782955353, 1.5001135161593113, 1.3916842866119155, 1.3987523874787546, 1.3607800934837964, 1.509237377928152, 1.3870267312677749, 1.369657039892686, 1.3123667608577554, 1.3012624905999823, 1.4242981575484204, 1.3680706610410915, 1.3481189766087063, 1.636890044778137, 1.2804228205091686], 'val_acc': [0.2484249212460623, 0.25822541127056353, 0.2640882044102205, 0.27257612880644033, 0.2804515225761288, 0.2864893244662233, 0.2881519075953798, 0.3052152607630382, 0.3095904795239762, 0.3252537626881344, 0.3297164858242912, 0.32665383269163456, 0.3482674133706685, 0.3644557227861393, 0.35001750087504374, 0.3622681134056703, 0.38134406720336017, 0.3581554077703885, 0.37731886594329717, 0.39193209660483025, 0.3989324466223311, 0.397882394119706, 0.3897444872243612, 0.387994399719986, 0.38160658032901645, 0.36393069653482674, 0.401907595379769, 0.39910745537276865, 0.4133706685334267, 0.36279313965698284, 0.4047952397619881, 0.4128456422821141, 0.448372418620931, 0.4553727686384319, 0.39263213160658034, 0.41258312915645784, 0.42290864543227163, 0.3404795239761988, 0.4642982149107455], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 6.302733026208444e-06, 'batch_size': 48, 'epochs': 39, 'weight_decay': 3.897854077640694e-06, 'dropout': 0.27353407318800105, 'base_channels': 9, 'temporal_kernel': 5, 'spatial_segments': 60, 'label_smoothing': 0.024081194357260933, 'grad_clip': 0.006613940532034681, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 583}, 'model_parameter_count': 18029, 'model_storage_size_kb': 77.468359375, 'model_size_validation': 'PASS'}
2025-10-12 04:10:59,868 - INFO - _models.training_function_executor - BO Objective: base=0.4643, size_penalty=0.0000, final=0.4643
2025-10-12 04:10:59,868 - INFO - _models.training_function_executor - Model: 18,029 parameters, 77.5KB (PASS 256KB limit)
2025-10-12 04:10:59,868 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 372.145s
2025-10-12 04:10:59,968 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.4643
2025-10-12 04:10:59,968 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.096s
2025-10-12 04:10:59,968 - INFO - bo.run_bo - Recorded observation #16: hparams={'lr': 6.302733026208444e-06, 'batch_size': np.int64(48), 'epochs': np.int64(39), 'weight_decay': 3.897854077640694e-06, 'dropout': 0.27353407318800105, 'base_channels': np.int64(9), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(60), 'label_smoothing': 0.024081194357260933, 'grad_clip': 0.006613940532034681, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(583)}, value=0.4643
2025-10-12 04:10:59,968 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 16: {'lr': 6.302733026208444e-06, 'batch_size': np.int64(48), 'epochs': np.int64(39), 'weight_decay': 3.897854077640694e-06, 'dropout': 0.27353407318800105, 'base_channels': np.int64(9), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(60), 'label_smoothing': 0.024081194357260933, 'grad_clip': 0.006613940532034681, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(583)} -> 0.4643
2025-10-12 04:10:59,968 - INFO - bo.run_bo - üîçBO Trial 17: Using RF surrogate + Expected Improvement
2025-10-12 04:10:59,968 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 04:10:59,968 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 04:10:59,968 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 04:10:59,969 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 3.339925178021054e-05, 'batch_size': 32, 'epochs': 45, 'weight_decay': 4.8447443211732205e-06, 'dropout': 0.13417022323125624, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 100, 'label_smoothing': 0.06299378889613541, 'grad_clip': 0.07575542541506698, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 555}
2025-10-12 04:10:59,970 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 3.339925178021054e-05, 'batch_size': 32, 'epochs': 45, 'weight_decay': 4.8447443211732205e-06, 'dropout': 0.13417022323125624, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 100, 'label_smoothing': 0.06299378889613541, 'grad_clip': 0.07575542541506698, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 555}
2025-10-12 04:11:12,093 - INFO - _models.training_function_executor - Epoch 001/45 - train_loss: 1.6114 - val_loss: 1.4914 - val_acc: 0.3893
2025-10-12 04:11:24,001 - INFO - _models.training_function_executor - Epoch 002/45 - train_loss: 1.3636 - val_loss: 1.3119 - val_acc: 0.5005
2025-10-12 04:11:35,978 - INFO - _models.training_function_executor - Epoch 003/45 - train_loss: 1.2328 - val_loss: 1.1817 - val_acc: 0.5743
2025-10-12 04:11:47,928 - INFO - _models.training_function_executor - Epoch 004/45 - train_loss: 1.1556 - val_loss: 1.1916 - val_acc: 0.5651
2025-10-12 04:11:59,869 - INFO - _models.training_function_executor - Epoch 005/45 - train_loss: 1.1048 - val_loss: 1.2201 - val_acc: 0.5483
2025-10-12 04:12:11,823 - INFO - _models.training_function_executor - Epoch 006/45 - train_loss: 1.0707 - val_loss: 1.1472 - val_acc: 0.5758
2025-10-12 04:12:23,771 - INFO - _models.training_function_executor - Epoch 007/45 - train_loss: 1.0490 - val_loss: 1.1247 - val_acc: 0.5820
2025-10-12 04:12:35,733 - INFO - _models.training_function_executor - Epoch 008/45 - train_loss: 1.0235 - val_loss: 1.1879 - val_acc: 0.5501
2025-10-12 04:12:47,654 - INFO - _models.training_function_executor - Epoch 009/45 - train_loss: 1.0104 - val_loss: 1.0666 - val_acc: 0.6214
2025-10-12 04:12:59,567 - INFO - _models.training_function_executor - Epoch 010/45 - train_loss: 1.0005 - val_loss: 1.0961 - val_acc: 0.6049
2025-10-12 04:13:11,458 - INFO - _models.training_function_executor - Epoch 011/45 - train_loss: 0.9887 - val_loss: 1.0236 - val_acc: 0.6461
2025-10-12 04:13:23,394 - INFO - _models.training_function_executor - Epoch 012/45 - train_loss: 0.9774 - val_loss: 0.9374 - val_acc: 0.6925
2025-10-12 04:13:35,364 - INFO - _models.training_function_executor - Epoch 013/45 - train_loss: 0.9666 - val_loss: 0.9962 - val_acc: 0.6681
2025-10-12 04:13:47,319 - INFO - _models.training_function_executor - Epoch 014/45 - train_loss: 0.9570 - val_loss: 1.1800 - val_acc: 0.5746
2025-10-12 04:13:59,306 - INFO - _models.training_function_executor - Epoch 015/45 - train_loss: 0.9491 - val_loss: 0.9394 - val_acc: 0.6881
2025-10-12 04:14:11,251 - INFO - _models.training_function_executor - Epoch 016/45 - train_loss: 0.9428 - val_loss: 0.8956 - val_acc: 0.7167
2025-10-12 04:14:23,214 - INFO - _models.training_function_executor - Epoch 017/45 - train_loss: 0.9319 - val_loss: 0.9884 - val_acc: 0.6740
2025-10-12 04:14:35,195 - INFO - _models.training_function_executor - Epoch 018/45 - train_loss: 0.9227 - val_loss: 0.9377 - val_acc: 0.7001
2025-10-12 04:14:47,143 - INFO - _models.training_function_executor - Epoch 019/45 - train_loss: 0.9160 - val_loss: 1.0897 - val_acc: 0.6322
2025-10-12 04:14:59,079 - INFO - _models.training_function_executor - Epoch 020/45 - train_loss: 0.9098 - val_loss: 1.2147 - val_acc: 0.5652
2025-10-12 04:15:11,013 - INFO - _models.training_function_executor - Epoch 021/45 - train_loss: 0.9045 - val_loss: 1.1969 - val_acc: 0.5574
2025-10-12 04:15:22,981 - INFO - _models.training_function_executor - Epoch 022/45 - train_loss: 0.8985 - val_loss: 0.9009 - val_acc: 0.7126
2025-10-12 04:15:34,928 - INFO - _models.training_function_executor - Epoch 023/45 - train_loss: 0.8898 - val_loss: 1.0557 - val_acc: 0.6419
2025-10-12 04:15:46,883 - INFO - _models.training_function_executor - Epoch 024/45 - train_loss: 0.8868 - val_loss: 0.8584 - val_acc: 0.7392
2025-10-12 04:15:58,821 - INFO - _models.training_function_executor - Epoch 025/45 - train_loss: 0.8828 - val_loss: 1.0726 - val_acc: 0.6389
2025-10-12 04:16:10,774 - INFO - _models.training_function_executor - Epoch 026/45 - train_loss: 0.8830 - val_loss: 0.9062 - val_acc: 0.7122
2025-10-12 04:16:22,744 - INFO - _models.training_function_executor - Epoch 027/45 - train_loss: 0.8734 - val_loss: 0.8510 - val_acc: 0.7367
2025-10-12 04:16:34,685 - INFO - _models.training_function_executor - Epoch 028/45 - train_loss: 0.8694 - val_loss: 1.1646 - val_acc: 0.5883
2025-10-12 04:16:46,601 - INFO - _models.training_function_executor - Epoch 029/45 - train_loss: 0.8658 - val_loss: 0.8831 - val_acc: 0.7244
2025-10-12 04:16:58,569 - INFO - _models.training_function_executor - Epoch 030/45 - train_loss: 0.8604 - val_loss: 0.8603 - val_acc: 0.7362
2025-10-12 04:17:10,509 - INFO - _models.training_function_executor - Epoch 031/45 - train_loss: 0.8566 - val_loss: 0.9257 - val_acc: 0.7064
2025-10-12 04:17:22,465 - INFO - _models.training_function_executor - Epoch 032/45 - train_loss: 0.8510 - val_loss: 0.9103 - val_acc: 0.7082
2025-10-12 04:17:34,412 - INFO - _models.training_function_executor - Epoch 033/45 - train_loss: 0.8450 - val_loss: 0.9836 - val_acc: 0.6798
2025-10-12 04:17:46,382 - INFO - _models.training_function_executor - Epoch 034/45 - train_loss: 0.8435 - val_loss: 0.9221 - val_acc: 0.7003
2025-10-12 04:17:58,300 - INFO - _models.training_function_executor - Epoch 035/45 - train_loss: 0.8391 - val_loss: 0.9199 - val_acc: 0.6966
2025-10-12 04:18:10,262 - INFO - _models.training_function_executor - Epoch 036/45 - train_loss: 0.8365 - val_loss: 0.8614 - val_acc: 0.7257
2025-10-12 04:18:22,172 - INFO - _models.training_function_executor - Epoch 037/45 - train_loss: 0.8316 - val_loss: 0.8967 - val_acc: 0.7139
2025-10-12 04:18:34,138 - INFO - _models.training_function_executor - Epoch 038/45 - train_loss: 0.8280 - val_loss: 0.8638 - val_acc: 0.7331
2025-10-12 04:18:46,124 - INFO - _models.training_function_executor - Epoch 039/45 - train_loss: 0.8275 - val_loss: 0.9584 - val_acc: 0.6858
2025-10-12 04:18:58,099 - INFO - _models.training_function_executor - Epoch 040/45 - train_loss: 0.8255 - val_loss: 0.9215 - val_acc: 0.7036
2025-10-12 04:19:10,033 - INFO - _models.training_function_executor - Epoch 041/45 - train_loss: 0.8182 - val_loss: 0.9208 - val_acc: 0.6995
2025-10-12 04:19:21,996 - INFO - _models.training_function_executor - Epoch 042/45 - train_loss: 0.8188 - val_loss: 0.8126 - val_acc: 0.7567
2025-10-12 04:19:33,930 - INFO - _models.training_function_executor - Epoch 043/45 - train_loss: 0.8132 - val_loss: 0.8146 - val_acc: 0.7625
2025-10-12 04:19:45,885 - INFO - _models.training_function_executor - Epoch 044/45 - train_loss: 0.8116 - val_loss: 0.8338 - val_acc: 0.7453
2025-10-12 04:19:57,786 - INFO - _models.training_function_executor - Epoch 045/45 - train_loss: 0.8069 - val_loss: 0.8595 - val_acc: 0.7336
2025-10-12 04:19:57,789 - INFO - _models.training_function_executor - Model: 42,185 parameters, 181.3KB storage
2025-10-12 04:19:57,789 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6114312595615112, 1.3635698207241695, 1.2328140659686107, 1.1555623146133236, 1.104818778310074, 1.0707352813574498, 1.0489747854726148, 1.023545481126376, 1.010411099679077, 1.0005137565714268, 0.988727555351738, 0.9774298423605863, 0.9666495302318484, 0.9570123342145854, 0.9490608816427245, 0.9428043899145584, 0.9319154852997977, 0.9227339112971435, 0.9159735394058254, 0.909848840327625, 0.9044803267890522, 0.8984822922751, 0.8897574965170225, 0.886759108832803, 0.8827996886940657, 0.8829800945751977, 0.8734036914360118, 0.8694062988617055, 0.8658160580844365, 0.8603874966945522, 0.8565713553775804, 0.8509871881242644, 0.8450123364791029, 0.8435439448445086, 0.8390822731034089, 0.836540670152056, 0.8315723453487681, 0.8279785016303217, 0.827501603594851, 0.8254936106729891, 0.8182103041380822, 0.818813668500722, 0.8131777539218186, 0.8115879176670244, 0.8069337655457326], 'val_losses': [1.4914366879328005, 1.3119410339626851, 1.1817306688001283, 1.1915821885578608, 1.2200859401624102, 1.1471705733790947, 1.1247071735417462, 1.1879449428525637, 1.06662528355054, 1.0960670647439232, 1.023643590705479, 0.9374495602421798, 0.9961777543913121, 1.179968801231538, 0.9394479077680986, 0.8955825184832764, 0.9883871751520906, 0.9377247831977494, 1.0896560499039738, 1.2146538814173156, 1.1968516352963605, 0.9008889775260328, 1.055690871488393, 0.8584075174341679, 1.07255215034812, 0.9062302704870513, 0.8509968678392978, 1.1645538401345001, 0.8830728061160801, 0.8603141230638935, 0.925651783287254, 0.9103392871643723, 0.9835991671254762, 0.9221321296600099, 0.9198936850281082, 0.8613551697782758, 0.8967053266434474, 0.8637922847233412, 0.9584421631565535, 0.9214836000186144, 0.9208107720232527, 0.8125625657459469, 0.8146098602431447, 0.8338129092105669, 0.859508382771288], 'val_acc': [0.3893069653482674, 0.5005250262513126, 0.5742912145607281, 0.5651032551627582, 0.5483024151207561, 0.575778788939447, 0.581991599579979, 0.5500525026251313, 0.6213685684284215, 0.6049177458872944, 0.6461323066153307, 0.692509625481274, 0.6680959047952397, 0.5746412320616031, 0.688134406720336, 0.7166608330416521, 0.6739586979348967, 0.7001225061253062, 0.6322191109555477, 0.5651907595379769, 0.5574028701435072, 0.7126356317815891, 0.6419320966048302, 0.7392369618480924, 0.6388694434721736, 0.7121981099054953, 0.7366993349667483, 0.5882919145957298, 0.724361218060903, 0.7361743087154358, 0.706422821141057, 0.7081729086454323, 0.6798214910745537, 0.7002975148757438, 0.6966223311165558, 0.7256737836891844, 0.7138606930346517, 0.7331116555827791, 0.6857717885894294, 0.7036226811340567, 0.6995099754987749, 0.7567378368918446, 0.7625131256562828, 0.7452747637381869, 0.7336366818340917], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 3.339925178021054e-05, 'batch_size': 32, 'epochs': 45, 'weight_decay': 4.8447443211732205e-06, 'dropout': 0.13417022323125624, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 100, 'label_smoothing': 0.06299378889613541, 'grad_clip': 0.07575542541506698, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 555}, 'model_parameter_count': 42185, 'model_storage_size_kb': 181.26367187500003, 'model_size_validation': 'PASS'}
2025-10-12 04:19:57,789 - INFO - _models.training_function_executor - BO Objective: base=0.7336, size_penalty=0.0000, final=0.7336
2025-10-12 04:19:57,789 - INFO - _models.training_function_executor - Model: 42,185 parameters, 181.3KB (PASS 256KB limit)
2025-10-12 04:19:57,789 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 537.821s
2025-10-12 04:19:57,892 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7336
2025-10-12 04:19:57,892 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-10-12 04:19:57,892 - INFO - bo.run_bo - Recorded observation #17: hparams={'lr': 3.339925178021054e-05, 'batch_size': np.int64(32), 'epochs': np.int64(45), 'weight_decay': 4.8447443211732205e-06, 'dropout': 0.13417022323125624, 'base_channels': np.int64(15), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(100), 'label_smoothing': 0.06299378889613541, 'grad_clip': 0.07575542541506698, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(555)}, value=0.7336
2025-10-12 04:19:57,892 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 17: {'lr': 3.339925178021054e-05, 'batch_size': np.int64(32), 'epochs': np.int64(45), 'weight_decay': 4.8447443211732205e-06, 'dropout': 0.13417022323125624, 'base_channels': np.int64(15), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(100), 'label_smoothing': 0.06299378889613541, 'grad_clip': 0.07575542541506698, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(555)} -> 0.7336
2025-10-12 04:19:57,892 - INFO - bo.run_bo - üîçBO Trial 18: Using RF surrogate + Expected Improvement
2025-10-12 04:19:57,892 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 04:19:57,892 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 04:19:57,892 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 04:19:57,892 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 5.3130202098356247e-05, 'batch_size': 32, 'epochs': 50, 'weight_decay': 2.844488796696464e-06, 'dropout': 0.009457081175505979, 'base_channels': 9, 'temporal_kernel': 9, 'spatial_segments': 1000, 'label_smoothing': 0.06208442594061386, 'grad_clip': 0.6422264182131826, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 826}
2025-10-12 04:19:57,893 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 5.3130202098356247e-05, 'batch_size': 32, 'epochs': 50, 'weight_decay': 2.844488796696464e-06, 'dropout': 0.009457081175505979, 'base_channels': 9, 'temporal_kernel': 9, 'spatial_segments': 1000, 'label_smoothing': 0.06208442594061386, 'grad_clip': 0.6422264182131826, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 826}
2025-10-12 04:20:08,196 - INFO - _models.training_function_executor - Epoch 001/50 - train_loss: 1.6268 - val_loss: 1.5195 - val_acc: 0.3736
2025-10-12 04:20:18,278 - INFO - _models.training_function_executor - Epoch 002/50 - train_loss: 1.3048 - val_loss: 1.2742 - val_acc: 0.5450
2025-10-12 04:20:28,321 - INFO - _models.training_function_executor - Epoch 003/50 - train_loss: 1.1833 - val_loss: 1.2184 - val_acc: 0.5634
2025-10-12 04:20:38,409 - INFO - _models.training_function_executor - Epoch 004/50 - train_loss: 1.1134 - val_loss: 1.1418 - val_acc: 0.6005
2025-10-12 04:20:48,490 - INFO - _models.training_function_executor - Epoch 005/50 - train_loss: 1.0673 - val_loss: 1.1262 - val_acc: 0.5974
2025-10-12 04:20:58,497 - INFO - _models.training_function_executor - Epoch 006/50 - train_loss: 1.0304 - val_loss: 1.0853 - val_acc: 0.6195
2025-10-12 04:21:08,574 - INFO - _models.training_function_executor - Epoch 007/50 - train_loss: 1.0052 - val_loss: 1.1624 - val_acc: 0.5959
2025-10-12 04:21:18,639 - INFO - _models.training_function_executor - Epoch 008/50 - train_loss: 0.9802 - val_loss: 1.1102 - val_acc: 0.6075
2025-10-12 04:21:28,704 - INFO - _models.training_function_executor - Epoch 009/50 - train_loss: 0.9576 - val_loss: 1.1482 - val_acc: 0.5752
2025-10-12 04:21:38,789 - INFO - _models.training_function_executor - Epoch 010/50 - train_loss: 0.9349 - val_loss: 1.1254 - val_acc: 0.6061
2025-10-12 04:21:48,888 - INFO - _models.training_function_executor - Epoch 011/50 - train_loss: 0.9166 - val_loss: 1.0216 - val_acc: 0.6576
2025-10-12 04:21:58,968 - INFO - _models.training_function_executor - Epoch 012/50 - train_loss: 0.9048 - val_loss: 1.0242 - val_acc: 0.6581
2025-10-12 04:22:09,042 - INFO - _models.training_function_executor - Epoch 013/50 - train_loss: 0.8854 - val_loss: 1.1545 - val_acc: 0.6044
2025-10-12 04:22:19,131 - INFO - _models.training_function_executor - Epoch 014/50 - train_loss: 0.8751 - val_loss: 1.0703 - val_acc: 0.6241
2025-10-12 04:22:29,205 - INFO - _models.training_function_executor - Epoch 015/50 - train_loss: 0.8603 - val_loss: 1.0933 - val_acc: 0.6306
2025-10-12 04:22:39,286 - INFO - _models.training_function_executor - Epoch 016/50 - train_loss: 0.8516 - val_loss: 1.0658 - val_acc: 0.6412
2025-10-12 04:22:49,307 - INFO - _models.training_function_executor - Epoch 017/50 - train_loss: 0.8372 - val_loss: 1.1459 - val_acc: 0.6160
2025-10-12 04:22:59,421 - INFO - _models.training_function_executor - Epoch 018/50 - train_loss: 0.8243 - val_loss: 1.0996 - val_acc: 0.6413
2025-10-12 04:23:09,483 - INFO - _models.training_function_executor - Epoch 019/50 - train_loss: 0.8138 - val_loss: 1.0984 - val_acc: 0.6241
2025-10-12 04:23:19,548 - INFO - _models.training_function_executor - Epoch 020/50 - train_loss: 0.8034 - val_loss: 1.0174 - val_acc: 0.6656
2025-10-12 04:23:29,622 - INFO - _models.training_function_executor - Epoch 021/50 - train_loss: 0.7908 - val_loss: 1.0190 - val_acc: 0.6749
2025-10-12 04:23:39,691 - INFO - _models.training_function_executor - Epoch 022/50 - train_loss: 0.7782 - val_loss: 1.0288 - val_acc: 0.6711
2025-10-12 04:23:49,782 - INFO - _models.training_function_executor - Epoch 023/50 - train_loss: 0.7749 - val_loss: 1.0313 - val_acc: 0.6704
2025-10-12 04:23:59,868 - INFO - _models.training_function_executor - Epoch 024/50 - train_loss: 0.7625 - val_loss: 1.0467 - val_acc: 0.6677
2025-10-12 04:24:09,923 - INFO - _models.training_function_executor - Epoch 025/50 - train_loss: 0.7559 - val_loss: 1.1562 - val_acc: 0.6241
2025-10-12 04:24:19,965 - INFO - _models.training_function_executor - Epoch 026/50 - train_loss: 0.7454 - val_loss: 1.0905 - val_acc: 0.6483
2025-10-12 04:24:30,036 - INFO - _models.training_function_executor - Epoch 027/50 - train_loss: 0.7359 - val_loss: 1.0897 - val_acc: 0.6559
2025-10-12 04:24:40,083 - INFO - _models.training_function_executor - Epoch 028/50 - train_loss: 0.7283 - val_loss: 1.0373 - val_acc: 0.6827
2025-10-12 04:24:50,120 - INFO - _models.training_function_executor - Epoch 029/50 - train_loss: 0.7228 - val_loss: 1.0853 - val_acc: 0.6635
2025-10-12 04:25:00,189 - INFO - _models.training_function_executor - Epoch 030/50 - train_loss: 0.7125 - val_loss: 1.0443 - val_acc: 0.6823
2025-10-12 04:25:10,257 - INFO - _models.training_function_executor - Epoch 031/50 - train_loss: 0.7045 - val_loss: 1.0634 - val_acc: 0.6789
2025-10-12 04:25:20,339 - INFO - _models.training_function_executor - Epoch 032/50 - train_loss: 0.7002 - val_loss: 1.1054 - val_acc: 0.6563
2025-10-12 04:25:30,403 - INFO - _models.training_function_executor - Epoch 033/50 - train_loss: 0.6901 - val_loss: 1.0791 - val_acc: 0.6741
2025-10-12 04:25:40,438 - INFO - _models.training_function_executor - Epoch 034/50 - train_loss: 0.6888 - val_loss: 1.0968 - val_acc: 0.6630
2025-10-12 04:25:50,522 - INFO - _models.training_function_executor - Epoch 035/50 - train_loss: 0.6779 - val_loss: 1.1244 - val_acc: 0.6607
2025-10-12 04:26:00,607 - INFO - _models.training_function_executor - Epoch 036/50 - train_loss: 0.6685 - val_loss: 1.0972 - val_acc: 0.6759
2025-10-12 04:26:10,724 - INFO - _models.training_function_executor - Epoch 037/50 - train_loss: 0.6648 - val_loss: 1.1314 - val_acc: 0.6621
2025-10-12 04:26:20,811 - INFO - _models.training_function_executor - Epoch 038/50 - train_loss: 0.6572 - val_loss: 1.2118 - val_acc: 0.6224
2025-10-12 04:26:30,885 - INFO - _models.training_function_executor - Epoch 039/50 - train_loss: 0.6486 - val_loss: 1.1337 - val_acc: 0.6590
2025-10-12 04:26:40,953 - INFO - _models.training_function_executor - Epoch 040/50 - train_loss: 0.6469 - val_loss: 1.1297 - val_acc: 0.6634
2025-10-12 04:26:51,053 - INFO - _models.training_function_executor - Epoch 041/50 - train_loss: 0.6373 - val_loss: 1.1174 - val_acc: 0.6810
2025-10-12 04:27:01,157 - INFO - _models.training_function_executor - Epoch 042/50 - train_loss: 0.6291 - val_loss: 1.1176 - val_acc: 0.6803
2025-10-12 04:27:11,238 - INFO - _models.training_function_executor - Epoch 043/50 - train_loss: 0.6221 - val_loss: 1.2701 - val_acc: 0.6221
2025-10-12 04:27:21,306 - INFO - _models.training_function_executor - Epoch 044/50 - train_loss: 0.6210 - val_loss: 1.1299 - val_acc: 0.6768
2025-10-12 04:27:31,386 - INFO - _models.training_function_executor - Epoch 045/50 - train_loss: 0.6146 - val_loss: 1.1728 - val_acc: 0.6696
2025-10-12 04:27:41,453 - INFO - _models.training_function_executor - Epoch 046/50 - train_loss: 0.6085 - val_loss: 1.1906 - val_acc: 0.6599
2025-10-12 04:27:51,533 - INFO - _models.training_function_executor - Epoch 047/50 - train_loss: 0.6062 - val_loss: 1.1367 - val_acc: 0.6854
2025-10-12 04:28:01,588 - INFO - _models.training_function_executor - Epoch 048/50 - train_loss: 0.5966 - val_loss: 1.2438 - val_acc: 0.6419
2025-10-12 04:28:11,688 - INFO - _models.training_function_executor - Epoch 049/50 - train_loss: 0.5964 - val_loss: 1.1309 - val_acc: 0.6896
2025-10-12 04:28:21,748 - INFO - _models.training_function_executor - Epoch 050/50 - train_loss: 0.5876 - val_loss: 1.1649 - val_acc: 0.6783
2025-10-12 04:28:21,751 - INFO - _models.training_function_executor - Model: 108,485 parameters, 466.1KB storage
2025-10-12 04:28:21,751 - WARNING - _models.training_function_executor - Model storage 466.1KB exceeds 256KB limit!
2025-10-12 04:28:21,751 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6268070545653843, 1.3048027457997313, 1.1833014434394529, 1.113368014334631, 1.0672586538969406, 1.0303555270112559, 1.0051934820895516, 0.9802258927629341, 0.9576257951075187, 0.9348909037280926, 0.9166024345220032, 0.9048328996747784, 0.8853572788128371, 0.87508249478946, 0.8602937301389396, 0.8515994611802867, 0.8371540410851614, 0.8243307422665311, 0.8137708308816082, 0.8034483524398617, 0.7907693990260769, 0.7782001811430761, 0.7748508491756452, 0.7624624529459029, 0.7559071806581195, 0.745367891019902, 0.7358757011073429, 0.7283025495355931, 0.722774608885445, 0.7124901656967633, 0.7044991524143572, 0.700203664932044, 0.69011027935213, 0.6887753807167344, 0.6778799210514354, 0.6684851986276215, 0.6648444716313688, 0.6571555475609512, 0.6486354829090895, 0.6468672738402383, 0.6373146793873192, 0.6291446090579075, 0.6220605367123768, 0.6209708424060129, 0.614586699090306, 0.6084501143723549, 0.606209422831023, 0.596588720526777, 0.5963673186877995, 0.5876162636726521], 'val_losses': [1.5194646795813254, 1.2742244474613296, 1.218444983713853, 1.1418075158456675, 1.1261898961399333, 1.0853004738881449, 1.1624375902609179, 1.1102318256770058, 1.1481926649819314, 1.125363325839031, 1.0216473758867415, 1.02424204061613, 1.1544602531255188, 1.0702624051020952, 1.0933271008101968, 1.0658386558513355, 1.1458609477806891, 1.0996297363388734, 1.0984243102994964, 1.0173847613152733, 1.018958658470238, 1.0287636913200087, 1.0312770118361216, 1.046690817746325, 1.1561761883367472, 1.0905043953233637, 1.089746339320302, 1.0372859184500802, 1.0852727055925149, 1.0442520446363428, 1.0634184545430847, 1.1054208370869, 1.079083110491713, 1.0967901033624137, 1.124374371414465, 1.0971537093244985, 1.1314297300933915, 1.211801814978716, 1.1336959663871122, 1.129727154438171, 1.1174309448549953, 1.117618491985934, 1.2700564184095378, 1.1298810827344041, 1.1728470629439056, 1.1906158948303478, 1.1366789345145434, 1.2438414095580514, 1.130903681800797, 1.1649438030118078], 'val_acc': [0.37355617780889044, 0.5449772488624431, 0.5634406720336017, 0.6004550227511376, 0.597392369618481, 0.6195309765488275, 0.595904795239762, 0.6074553727686385, 0.5751662583129157, 0.6061428071403571, 0.6575953797689884, 0.658120406020301, 0.6043927196359818, 0.6240812040602031, 0.6305565278263913, 0.6412320616030801, 0.616030801540077, 0.6413195659782989, 0.6240812040602031, 0.6656457822891144, 0.6749212460623031, 0.6710710535526776, 0.6703710185509275, 0.6677458872943647, 0.6240812040602031, 0.6483199159957997, 0.655932796639832, 0.6827091354567728, 0.6634581729086454, 0.682271613580679, 0.6789464473223661, 0.656282814140707, 0.6741337066853342, 0.6630206510325516, 0.6607455372768638, 0.6758837941897095, 0.6620581029051452, 0.6224186209310466, 0.6589954497724886, 0.6633706685334266, 0.6810465523276164, 0.6803465173258663, 0.6220686034301716, 0.6768463423171158, 0.6695834791739587, 0.6598704935246762, 0.6854217710885544, 0.6419320966048302, 0.6896219810990549, 0.6783339166958348], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 5.3130202098356247e-05, 'batch_size': 32, 'epochs': 50, 'weight_decay': 2.844488796696464e-06, 'dropout': 0.009457081175505979, 'base_channels': 9, 'temporal_kernel': 9, 'spatial_segments': 1000, 'label_smoothing': 0.06208442594061386, 'grad_clip': 0.6422264182131826, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 826}, 'model_parameter_count': 108485, 'model_storage_size_kb': 466.14648437500006, 'model_size_validation': 'FAIL'}
2025-10-12 04:28:21,751 - INFO - _models.training_function_executor - BO Objective: base=0.6783, size_penalty=0.4104, final=0.2679
2025-10-12 04:28:21,751 - INFO - _models.training_function_executor - Model: 108,485 parameters, 466.1KB (FAIL 256KB limit)
2025-10-12 04:28:21,751 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 503.859s
2025-10-12 04:28:21,852 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2679
2025-10-12 04:28:21,853 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-10-12 04:28:21,853 - INFO - bo.run_bo - Recorded observation #18: hparams={'lr': 5.3130202098356247e-05, 'batch_size': np.int64(32), 'epochs': np.int64(50), 'weight_decay': 2.844488796696464e-06, 'dropout': 0.009457081175505979, 'base_channels': np.int64(9), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(1000), 'label_smoothing': 0.06208442594061386, 'grad_clip': 0.6422264182131826, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(826)}, value=0.2679
2025-10-12 04:28:21,853 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 18: {'lr': 5.3130202098356247e-05, 'batch_size': np.int64(32), 'epochs': np.int64(50), 'weight_decay': 2.844488796696464e-06, 'dropout': 0.009457081175505979, 'base_channels': np.int64(9), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(1000), 'label_smoothing': 0.06208442594061386, 'grad_clip': 0.6422264182131826, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(826)} -> 0.2679
2025-10-12 04:28:21,853 - INFO - bo.run_bo - üîçBO Trial 19: Using RF surrogate + Expected Improvement
2025-10-12 04:28:21,853 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 04:28:21,853 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 04:28:21,853 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 04:28:21,853 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0028332998662204995, 'batch_size': 8, 'epochs': 47, 'weight_decay': 0.001514828422838729, 'dropout': 0.010800626049481512, 'base_channels': 20, 'temporal_kernel': 7, 'spatial_segments': 5, 'label_smoothing': 0.11217742536350714, 'grad_clip': 0.38659219937612577, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2993}
2025-10-12 04:28:21,854 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0028332998662204995, 'batch_size': 8, 'epochs': 47, 'weight_decay': 0.001514828422838729, 'dropout': 0.010800626049481512, 'base_channels': 20, 'temporal_kernel': 7, 'spatial_segments': 5, 'label_smoothing': 0.11217742536350714, 'grad_clip': 0.38659219937612577, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2993}
2025-10-12 04:28:39,596 - INFO - _models.training_function_executor - Epoch 001/47 - train_loss: 1.2092 - val_loss: 1.1584 - val_acc: 0.6087
2025-10-12 04:28:57,348 - INFO - _models.training_function_executor - Epoch 002/47 - train_loss: 1.0503 - val_loss: 0.9654 - val_acc: 0.7188
2025-10-12 04:29:15,121 - INFO - _models.training_function_executor - Epoch 003/47 - train_loss: 0.9697 - val_loss: 0.8776 - val_acc: 0.7643
2025-10-12 04:29:32,809 - INFO - _models.training_function_executor - Epoch 004/47 - train_loss: 0.9296 - val_loss: 0.9026 - val_acc: 0.7467
2025-10-12 04:29:50,512 - INFO - _models.training_function_executor - Epoch 005/47 - train_loss: 0.9126 - val_loss: 0.9335 - val_acc: 0.7288
2025-10-12 04:30:08,147 - INFO - _models.training_function_executor - Epoch 006/47 - train_loss: 0.8947 - val_loss: 0.8912 - val_acc: 0.7585
2025-10-12 04:30:25,884 - INFO - _models.training_function_executor - Epoch 007/47 - train_loss: 0.8832 - val_loss: 0.9448 - val_acc: 0.7367
2025-10-12 04:30:43,602 - INFO - _models.training_function_executor - Epoch 008/47 - train_loss: 0.8725 - val_loss: 0.8448 - val_acc: 0.7871
2025-10-12 04:31:01,238 - INFO - _models.training_function_executor - Epoch 009/47 - train_loss: 0.8670 - val_loss: 0.8714 - val_acc: 0.7602
2025-10-12 04:31:18,883 - INFO - _models.training_function_executor - Epoch 010/47 - train_loss: 0.8592 - val_loss: 0.9153 - val_acc: 0.7378
2025-10-12 04:31:36,623 - INFO - _models.training_function_executor - Epoch 011/47 - train_loss: 0.8563 - val_loss: 0.8958 - val_acc: 0.7569
2025-10-12 04:31:54,407 - INFO - _models.training_function_executor - Epoch 012/47 - train_loss: 0.8527 - val_loss: 0.9342 - val_acc: 0.7304
2025-10-12 04:32:12,120 - INFO - _models.training_function_executor - Epoch 013/47 - train_loss: 0.8481 - val_loss: 0.8735 - val_acc: 0.7686
2025-10-12 04:32:29,898 - INFO - _models.training_function_executor - Epoch 014/47 - train_loss: 0.8421 - val_loss: 0.8550 - val_acc: 0.7702
2025-10-12 04:32:47,686 - INFO - _models.training_function_executor - Epoch 015/47 - train_loss: 0.8411 - val_loss: 0.8324 - val_acc: 0.7869
2025-10-12 04:33:05,376 - INFO - _models.training_function_executor - Epoch 016/47 - train_loss: 0.8364 - val_loss: 0.8482 - val_acc: 0.7756
2025-10-12 04:33:23,224 - INFO - _models.training_function_executor - Epoch 017/47 - train_loss: 0.8309 - val_loss: 0.8684 - val_acc: 0.7769
2025-10-12 04:33:41,052 - INFO - _models.training_function_executor - Epoch 018/47 - train_loss: 0.8302 - val_loss: 0.8706 - val_acc: 0.7686
2025-10-12 04:33:58,870 - INFO - _models.training_function_executor - Epoch 019/47 - train_loss: 0.8258 - val_loss: 0.8455 - val_acc: 0.7851
2025-10-12 04:34:16,649 - INFO - _models.training_function_executor - Epoch 020/47 - train_loss: 0.8229 - val_loss: 0.9157 - val_acc: 0.7534
2025-10-12 04:34:34,437 - INFO - _models.training_function_executor - Epoch 021/47 - train_loss: 0.8218 - val_loss: 0.8944 - val_acc: 0.7595
2025-10-12 04:34:52,188 - INFO - _models.training_function_executor - Epoch 022/47 - train_loss: 0.8171 - val_loss: 0.9475 - val_acc: 0.7554
2025-10-12 04:35:09,939 - INFO - _models.training_function_executor - Epoch 023/47 - train_loss: 0.8148 - val_loss: 0.8933 - val_acc: 0.7663
2025-10-12 04:35:27,734 - INFO - _models.training_function_executor - Epoch 024/47 - train_loss: 0.8127 - val_loss: 0.8527 - val_acc: 0.7826
2025-10-12 04:35:45,553 - INFO - _models.training_function_executor - Epoch 025/47 - train_loss: 0.8100 - val_loss: 0.8658 - val_acc: 0.7881
2025-10-12 04:36:03,375 - INFO - _models.training_function_executor - Epoch 026/47 - train_loss: 0.8101 - val_loss: 0.8810 - val_acc: 0.7653
2025-10-12 04:36:21,093 - INFO - _models.training_function_executor - Epoch 027/47 - train_loss: 0.8063 - val_loss: 1.0974 - val_acc: 0.6674
2025-10-12 04:36:38,813 - INFO - _models.training_function_executor - Epoch 028/47 - train_loss: 0.8059 - val_loss: 0.8384 - val_acc: 0.7833
2025-10-12 04:36:56,582 - INFO - _models.training_function_executor - Epoch 029/47 - train_loss: 0.8048 - val_loss: 0.8331 - val_acc: 0.7945
2025-10-12 04:37:14,357 - INFO - _models.training_function_executor - Epoch 030/47 - train_loss: 0.8014 - val_loss: 0.8168 - val_acc: 0.7974
2025-10-12 04:37:32,038 - INFO - _models.training_function_executor - Epoch 031/47 - train_loss: 0.8013 - val_loss: 0.8904 - val_acc: 0.7584
2025-10-12 04:37:49,839 - INFO - _models.training_function_executor - Epoch 032/47 - train_loss: 0.7961 - val_loss: 0.8747 - val_acc: 0.7702
2025-10-12 04:38:07,642 - INFO - _models.training_function_executor - Epoch 033/47 - train_loss: 0.7961 - val_loss: 0.8531 - val_acc: 0.7986
2025-10-12 04:38:25,430 - INFO - _models.training_function_executor - Epoch 034/47 - train_loss: 0.7937 - val_loss: 0.8747 - val_acc: 0.7943
2025-10-12 04:38:43,218 - INFO - _models.training_function_executor - Epoch 035/47 - train_loss: 0.7960 - val_loss: 0.8362 - val_acc: 0.7958
2025-10-12 04:39:00,951 - INFO - _models.training_function_executor - Epoch 036/47 - train_loss: 0.7920 - val_loss: 0.8504 - val_acc: 0.7804
2025-10-12 04:39:18,767 - INFO - _models.training_function_executor - Epoch 037/47 - train_loss: 0.7906 - val_loss: 0.8425 - val_acc: 0.7893
2025-10-12 04:39:36,543 - INFO - _models.training_function_executor - Epoch 038/47 - train_loss: 0.7875 - val_loss: 0.8264 - val_acc: 0.7891
2025-10-12 04:39:54,338 - INFO - _models.training_function_executor - Epoch 039/47 - train_loss: 0.7889 - val_loss: 0.8592 - val_acc: 0.7879
2025-10-12 04:40:12,125 - INFO - _models.training_function_executor - Epoch 040/47 - train_loss: 0.7889 - val_loss: 0.9530 - val_acc: 0.7343
2025-10-12 04:40:29,941 - INFO - _models.training_function_executor - Epoch 041/47 - train_loss: 0.7864 - val_loss: 0.8149 - val_acc: 0.8027
2025-10-12 04:40:47,779 - INFO - _models.training_function_executor - Epoch 042/47 - train_loss: 0.7867 - val_loss: 0.8883 - val_acc: 0.7708
2025-10-12 04:41:05,565 - INFO - _models.training_function_executor - Epoch 043/47 - train_loss: 0.7837 - val_loss: 0.8415 - val_acc: 0.7924
2025-10-12 04:41:23,373 - INFO - _models.training_function_executor - Epoch 044/47 - train_loss: 0.7823 - val_loss: 0.8883 - val_acc: 0.7602
2025-10-12 04:41:41,088 - INFO - _models.training_function_executor - Epoch 045/47 - train_loss: 0.7797 - val_loss: 0.9256 - val_acc: 0.7299
2025-10-12 04:41:58,901 - INFO - _models.training_function_executor - Epoch 046/47 - train_loss: 0.7774 - val_loss: 0.8578 - val_acc: 0.7987
2025-10-12 04:42:16,733 - INFO - _models.training_function_executor - Epoch 047/47 - train_loss: 0.7801 - val_loss: 0.9256 - val_acc: 0.7520
2025-10-12 04:42:16,735 - INFO - _models.training_function_executor - Model: 57,825 parameters, 248.5KB storage
2025-10-12 04:42:16,736 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2092046308108548, 1.0502662963807938, 0.9696771534831948, 0.9296268123062833, 0.9126012727779903, 0.8947298166517782, 0.8831648249433388, 0.8725044677828758, 0.8670240884889954, 0.8591522940877521, 0.8562873634772156, 0.8527206500218304, 0.8480782388785438, 0.8420737880612321, 0.8411274974501379, 0.8364130566597485, 0.8308652560267367, 0.8302431042727616, 0.8258467253883026, 0.8228668257056895, 0.8217690606341731, 0.8171450843031188, 0.8147724355783836, 0.8127330003771116, 0.8099885757700898, 0.8100631960964637, 0.8062831719865906, 0.8058774807015456, 0.8047501988967148, 0.801379037354015, 0.8013291772185066, 0.7960806860137661, 0.7961457761947951, 0.7936897752457747, 0.7960184133778847, 0.792022828136577, 0.7905590870777209, 0.7875035570547804, 0.7889027780728362, 0.7888620067537769, 0.7864252832184565, 0.7867048342285516, 0.7836505538377472, 0.782256891949009, 0.7796705171210306, 0.7774133051363872, 0.7800874512930788], 'val_losses': [1.1584169777865838, 0.9653628420737977, 0.8775707844424423, 0.9025670595422758, 0.9335069218464652, 0.8911547844419122, 0.9448189716218942, 0.8447881138612643, 0.8714410943253957, 0.9153018285855156, 0.8958223370726308, 0.9342170339970894, 0.8735019394180596, 0.8550146306608372, 0.832449900632477, 0.848168349553957, 0.8684330310986765, 0.8706210151413833, 0.8455074363377364, 0.9156611242576375, 0.8943925169034149, 0.9475480296998162, 0.8933077708465635, 0.8527202940942693, 0.8658419537469145, 0.8810254241521432, 1.0973631749004595, 0.8384288617539831, 0.8330946493115423, 0.8168236245047517, 0.8904455508599968, 0.8746543181267993, 0.85312785710494, 0.8746951342171457, 0.8361707757747712, 0.8504245369468572, 0.8424642399386338, 0.8264081346997023, 0.8592268771481839, 0.9529513114601071, 0.8148770785473592, 0.8882993633904822, 0.841455424608031, 0.8882526733635772, 0.9256398802793314, 0.8577684126285811, 0.9256309771980069], 'val_acc': [0.6086804340217011, 0.7187609380469023, 0.764263213160658, 0.7466748337416871, 0.7288239411970598, 0.7584879243962198, 0.7366993349667483, 0.7871018550927547, 0.7601505075253763, 0.7378368918445922, 0.7569128456422821, 0.7303990199509975, 0.7685509275463773, 0.7702135106755338, 0.7869268463423171, 0.7755512775638782, 0.7768638431921596, 0.7686384319215961, 0.7850892544627232, 0.7534126706335317, 0.7594504725236262, 0.7554252712635632, 0.7662758137906895, 0.7825516275813791, 0.788064403220161, 0.7653132656632832, 0.6673958697934896, 0.7833391669583479, 0.7945397269863493, 0.7974273713685684, 0.758400420021001, 0.7702135106755338, 0.7985649282464123, 0.794277213860693, 0.795764788239412, 0.7803640182009101, 0.7892894644732237, 0.7891144557227862, 0.7878893944697235, 0.7343367168358418, 0.8026776338816941, 0.7708260413020651, 0.7923521176058803, 0.760238011900595, 0.729873993699685, 0.7987399369968499, 0.7520126006300315], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0028332998662204995, 'batch_size': 8, 'epochs': 47, 'weight_decay': 0.001514828422838729, 'dropout': 0.010800626049481512, 'base_channels': 20, 'temporal_kernel': 7, 'spatial_segments': 5, 'label_smoothing': 0.11217742536350714, 'grad_clip': 0.38659219937612577, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2993}, 'model_parameter_count': 57825, 'model_storage_size_kb': 248.46679687500003, 'model_size_validation': 'PASS'}
2025-10-12 04:42:16,736 - INFO - _models.training_function_executor - BO Objective: base=0.7520, size_penalty=0.0000, final=0.7520
2025-10-12 04:42:16,736 - INFO - _models.training_function_executor - Model: 57,825 parameters, 248.5KB (PASS 256KB limit)
2025-10-12 04:42:16,736 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 834.883s
2025-10-12 04:42:16,836 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7520
2025-10-12 04:42:16,836 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-10-12 04:42:16,836 - INFO - bo.run_bo - Recorded observation #19: hparams={'lr': 0.0028332998662204995, 'batch_size': np.int64(8), 'epochs': np.int64(47), 'weight_decay': 0.001514828422838729, 'dropout': 0.010800626049481512, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(5), 'label_smoothing': 0.11217742536350714, 'grad_clip': 0.38659219937612577, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2993)}, value=0.7520
2025-10-12 04:42:16,836 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 19: {'lr': 0.0028332998662204995, 'batch_size': np.int64(8), 'epochs': np.int64(47), 'weight_decay': 0.001514828422838729, 'dropout': 0.010800626049481512, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(5), 'label_smoothing': 0.11217742536350714, 'grad_clip': 0.38659219937612577, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2993)} -> 0.7520
2025-10-12 04:42:16,836 - INFO - bo.run_bo - üîçBO Trial 20: Using RF surrogate + Expected Improvement
2025-10-12 04:42:16,836 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 04:42:16,836 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 04:42:16,836 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 04:42:16,836 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 9.709841338456428e-05, 'batch_size': 16, 'epochs': 50, 'weight_decay': 1.624076854437134e-06, 'dropout': 0.45217419995207564, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 1000, 'label_smoothing': 0.09828946363290918, 'grad_clip': 0.46880754322844465, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4699}
2025-10-12 04:42:16,837 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 9.709841338456428e-05, 'batch_size': 16, 'epochs': 50, 'weight_decay': 1.624076854437134e-06, 'dropout': 0.45217419995207564, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 1000, 'label_smoothing': 0.09828946363290918, 'grad_clip': 0.46880754322844465, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4699}
2025-10-12 04:42:33,680 - INFO - _models.training_function_executor - Epoch 001/50 - train_loss: 1.5090 - val_loss: 1.1788 - val_acc: 0.6061
2025-10-12 04:42:50,339 - INFO - _models.training_function_executor - Epoch 002/50 - train_loss: 1.1753 - val_loss: 1.0661 - val_acc: 0.6475
2025-10-12 04:43:07,013 - INFO - _models.training_function_executor - Epoch 003/50 - train_loss: 1.1306 - val_loss: 1.0183 - val_acc: 0.6703
2025-10-12 04:43:23,671 - INFO - _models.training_function_executor - Epoch 004/50 - train_loss: 1.0981 - val_loss: 0.9793 - val_acc: 0.7215
2025-10-12 04:43:40,340 - INFO - _models.training_function_executor - Epoch 005/50 - train_loss: 1.0737 - val_loss: 0.9676 - val_acc: 0.7281
2025-10-12 04:43:57,025 - INFO - _models.training_function_executor - Epoch 006/50 - train_loss: 1.0582 - val_loss: 0.9724 - val_acc: 0.7047
2025-10-12 04:44:13,715 - INFO - _models.training_function_executor - Epoch 007/50 - train_loss: 1.0399 - val_loss: 0.9232 - val_acc: 0.7391
2025-10-12 04:44:30,381 - INFO - _models.training_function_executor - Epoch 008/50 - train_loss: 1.0213 - val_loss: 0.9270 - val_acc: 0.7377
2025-10-12 04:44:47,063 - INFO - _models.training_function_executor - Epoch 009/50 - train_loss: 1.0125 - val_loss: 0.9577 - val_acc: 0.7172
2025-10-12 04:45:03,731 - INFO - _models.training_function_executor - Epoch 010/50 - train_loss: 1.0021 - val_loss: 0.8957 - val_acc: 0.7530
2025-10-12 04:45:20,402 - INFO - _models.training_function_executor - Epoch 011/50 - train_loss: 0.9923 - val_loss: 0.8946 - val_acc: 0.7491
2025-10-12 04:45:37,080 - INFO - _models.training_function_executor - Epoch 012/50 - train_loss: 0.9850 - val_loss: 0.8819 - val_acc: 0.7566
2025-10-12 04:45:53,755 - INFO - _models.training_function_executor - Epoch 013/50 - train_loss: 0.9798 - val_loss: 0.9053 - val_acc: 0.7449
2025-10-12 04:46:10,404 - INFO - _models.training_function_executor - Epoch 014/50 - train_loss: 0.9770 - val_loss: 1.0919 - val_acc: 0.6488
2025-10-12 04:46:27,073 - INFO - _models.training_function_executor - Epoch 015/50 - train_loss: 0.9668 - val_loss: 0.8523 - val_acc: 0.7781
2025-10-12 04:46:43,741 - INFO - _models.training_function_executor - Epoch 016/50 - train_loss: 0.9579 - val_loss: 0.9070 - val_acc: 0.7489
2025-10-12 04:47:00,404 - INFO - _models.training_function_executor - Epoch 017/50 - train_loss: 0.9557 - val_loss: 0.9181 - val_acc: 0.7411
2025-10-12 04:47:17,024 - INFO - _models.training_function_executor - Epoch 018/50 - train_loss: 0.9532 - val_loss: 0.8508 - val_acc: 0.7762
2025-10-12 04:47:33,664 - INFO - _models.training_function_executor - Epoch 019/50 - train_loss: 0.9418 - val_loss: 0.8614 - val_acc: 0.7735
2025-10-12 04:47:50,302 - INFO - _models.training_function_executor - Epoch 020/50 - train_loss: 0.9375 - val_loss: 0.8307 - val_acc: 0.7863
2025-10-12 04:48:06,960 - INFO - _models.training_function_executor - Epoch 021/50 - train_loss: 0.9298 - val_loss: 0.8577 - val_acc: 0.7767
2025-10-12 04:48:23,606 - INFO - _models.training_function_executor - Epoch 022/50 - train_loss: 0.9232 - val_loss: 1.0248 - val_acc: 0.6858
2025-10-12 04:48:40,263 - INFO - _models.training_function_executor - Epoch 023/50 - train_loss: 0.9203 - val_loss: 0.8376 - val_acc: 0.7798
2025-10-12 04:48:56,942 - INFO - _models.training_function_executor - Epoch 024/50 - train_loss: 0.9119 - val_loss: 0.8911 - val_acc: 0.7496
2025-10-12 04:49:13,628 - INFO - _models.training_function_executor - Epoch 025/50 - train_loss: 0.9093 - val_loss: 0.8476 - val_acc: 0.7767
2025-10-12 04:49:30,259 - INFO - _models.training_function_executor - Epoch 026/50 - train_loss: 0.9063 - val_loss: 0.9107 - val_acc: 0.7457
2025-10-12 04:49:46,938 - INFO - _models.training_function_executor - Epoch 027/50 - train_loss: 0.9014 - val_loss: 0.8606 - val_acc: 0.7715
2025-10-12 04:50:03,566 - INFO - _models.training_function_executor - Epoch 028/50 - train_loss: 0.9020 - val_loss: 0.8305 - val_acc: 0.7909
2025-10-12 04:50:20,271 - INFO - _models.training_function_executor - Epoch 029/50 - train_loss: 0.8935 - val_loss: 0.8683 - val_acc: 0.7635
2025-10-12 04:50:36,944 - INFO - _models.training_function_executor - Epoch 030/50 - train_loss: 0.8911 - val_loss: 0.8332 - val_acc: 0.7835
2025-10-12 04:50:53,620 - INFO - _models.training_function_executor - Epoch 031/50 - train_loss: 0.8890 - val_loss: 0.8253 - val_acc: 0.7926
2025-10-12 04:51:10,308 - INFO - _models.training_function_executor - Epoch 032/50 - train_loss: 0.8809 - val_loss: 0.8764 - val_acc: 0.7568
2025-10-12 04:51:26,984 - INFO - _models.training_function_executor - Epoch 033/50 - train_loss: 0.8834 - val_loss: 0.8595 - val_acc: 0.7740
2025-10-12 04:51:43,649 - INFO - _models.training_function_executor - Epoch 034/50 - train_loss: 0.8811 - val_loss: 0.8333 - val_acc: 0.7854
2025-10-12 04:52:00,305 - INFO - _models.training_function_executor - Epoch 035/50 - train_loss: 0.8776 - val_loss: 0.8471 - val_acc: 0.7805
2025-10-12 04:52:16,981 - INFO - _models.training_function_executor - Epoch 036/50 - train_loss: 0.8742 - val_loss: 0.8212 - val_acc: 0.7924
2025-10-12 04:52:33,639 - INFO - _models.training_function_executor - Epoch 037/50 - train_loss: 0.8738 - val_loss: 0.8282 - val_acc: 0.7919
2025-10-12 04:52:50,301 - INFO - _models.training_function_executor - Epoch 038/50 - train_loss: 0.8670 - val_loss: 0.8284 - val_acc: 0.7956
2025-10-12 04:53:07,017 - INFO - _models.training_function_executor - Epoch 039/50 - train_loss: 0.8661 - val_loss: 0.8298 - val_acc: 0.7937
2025-10-12 04:53:23,644 - INFO - _models.training_function_executor - Epoch 040/50 - train_loss: 0.8615 - val_loss: 0.9349 - val_acc: 0.7332
2025-10-12 04:53:40,318 - INFO - _models.training_function_executor - Epoch 041/50 - train_loss: 0.8622 - val_loss: 0.8577 - val_acc: 0.7819
2025-10-12 04:53:56,975 - INFO - _models.training_function_executor - Epoch 042/50 - train_loss: 0.8553 - val_loss: 0.8392 - val_acc: 0.7862
2025-10-12 04:54:13,630 - INFO - _models.training_function_executor - Epoch 043/50 - train_loss: 0.8571 - val_loss: 0.8456 - val_acc: 0.7889
2025-10-12 04:54:30,264 - INFO - _models.training_function_executor - Epoch 044/50 - train_loss: 0.8545 - val_loss: 0.8529 - val_acc: 0.7847
2025-10-12 04:54:46,933 - INFO - _models.training_function_executor - Epoch 045/50 - train_loss: 0.8495 - val_loss: 0.9048 - val_acc: 0.7552
2025-10-12 04:55:03,610 - INFO - _models.training_function_executor - Epoch 046/50 - train_loss: 0.8503 - val_loss: 0.8301 - val_acc: 0.7954
2025-10-12 04:55:20,287 - INFO - _models.training_function_executor - Epoch 047/50 - train_loss: 0.8526 - val_loss: 0.8408 - val_acc: 0.7890
2025-10-12 04:55:36,951 - INFO - _models.training_function_executor - Epoch 048/50 - train_loss: 0.8497 - val_loss: 0.8453 - val_acc: 0.7913
2025-10-12 04:55:53,592 - INFO - _models.training_function_executor - Epoch 049/50 - train_loss: 0.8437 - val_loss: 0.8677 - val_acc: 0.7777
2025-10-12 04:56:10,260 - INFO - _models.training_function_executor - Epoch 050/50 - train_loss: 0.8455 - val_loss: 0.8401 - val_acc: 0.7961
2025-10-12 04:56:10,263 - INFO - _models.training_function_executor - Model: 158,837 parameters, 682.5KB storage
2025-10-12 04:56:10,263 - WARNING - _models.training_function_executor - Model storage 682.5KB exceeds 256KB limit!
2025-10-12 04:56:10,263 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.509001318937755, 1.1752508578285454, 1.1306434882909717, 1.0981322898287267, 1.0737318468753132, 1.0581974988848253, 1.0398660424000157, 1.021317740879486, 1.0124692865547953, 1.002062335229646, 0.9923386127747645, 0.9850149655575764, 0.9797761953081499, 0.9770489358426309, 0.9667751403759525, 0.9578696888019708, 0.9556511314882447, 0.9532282683538064, 0.9418252287813947, 0.937508528241754, 0.9298213515032995, 0.9231613316776288, 0.9202577634253283, 0.9118604384855579, 0.9093390968365814, 0.9062979681991722, 0.9013836955248079, 0.9020493593840153, 0.8934819227880558, 0.8910853113584014, 0.8890423778265892, 0.8808592440658906, 0.8834497497179394, 0.8811375211284092, 0.8776418021353634, 0.874182683773962, 0.8737714544934829, 0.8669954037224032, 0.8660878418081909, 0.8615376790336766, 0.8622387382255637, 0.8552909582529946, 0.8571253470766156, 0.8545417244675529, 0.8495328860095969, 0.8503224657138495, 0.8525523441130772, 0.8497396688341134, 0.8436650501959884, 0.845484665610968], 'val_losses': [1.1788000862290486, 1.0661277252350148, 1.0183182288017314, 0.9792809667059872, 0.9676139905897521, 0.9724261741518014, 0.9231736006793502, 0.9269654482738681, 0.9577405032136869, 0.8956745176996265, 0.8945746691985526, 0.8818513341913033, 0.9053143359874569, 1.0919077351955337, 0.8522734035759653, 0.9069722106834788, 0.9180914455875467, 0.8507912726639283, 0.8614302192653941, 0.8307355995940962, 0.8576826068501311, 1.0248166979256317, 0.8376179420117694, 0.8911191155161939, 0.8475735726830507, 0.9107299242814104, 0.8605889060675034, 0.8305418638236713, 0.8683178194302715, 0.8332059853636888, 0.8253248106110626, 0.8764124271917226, 0.8594642648715258, 0.8333377726832427, 0.8471443184844089, 0.8211669094878808, 0.8282303163794149, 0.8284031484233026, 0.8298388850784902, 0.9349221267356379, 0.8576930976222769, 0.8391705927082739, 0.8455867630474877, 0.8529108423931347, 0.9047568843086825, 0.8300958284348677, 0.8407945638358865, 0.8452584384035973, 0.8676861932238458, 0.8401376864148221], 'val_acc': [0.6060553027651383, 0.6475323766188309, 0.6702835141757088, 0.7214735736786839, 0.7281239061953098, 0.7046727336366818, 0.7390619530976549, 0.7376618830941547, 0.7171858592929646, 0.7529751487574379, 0.7491249562478124, 0.7565628281414071, 0.7449247462373119, 0.6487574378718935, 0.7780889044452223, 0.7488624431221561, 0.7410745537276864, 0.7761638081904095, 0.7735386769338467, 0.7863143157157858, 0.7766888344417221, 0.6857717885894294, 0.7797514875743787, 0.749649982499125, 0.7766888344417221, 0.7457122856142807, 0.7715260763038152, 0.7908645432271614, 0.7634756737836892, 0.7835141757087855, 0.7926146307315366, 0.7568253412670634, 0.7739761988099405, 0.7853517675883794, 0.7804515225761288, 0.7923521176058803, 0.7919145957297865, 0.7955897794889745, 0.7936646832341617, 0.7331991599579979, 0.7819390969548478, 0.786226811340567, 0.7889394469723486, 0.7847392369618481, 0.7551627581379069, 0.795414770738537, 0.7890269513475674, 0.7913020651032552, 0.7776513825691285, 0.796114805740287], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 9.709841338456428e-05, 'batch_size': 16, 'epochs': 50, 'weight_decay': 1.624076854437134e-06, 'dropout': 0.45217419995207564, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 1000, 'label_smoothing': 0.09828946363290918, 'grad_clip': 0.46880754322844465, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4699}, 'model_parameter_count': 158837, 'model_storage_size_kb': 682.502734375, 'model_size_validation': 'FAIL'}
2025-10-12 04:56:10,263 - INFO - _models.training_function_executor - BO Objective: base=0.7961, size_penalty=0.8000, final=-0.0039
2025-10-12 04:56:10,263 - INFO - _models.training_function_executor - Model: 158,837 parameters, 682.5KB (FAIL 256KB limit)
2025-10-12 04:56:10,263 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 833.426s
2025-10-12 04:56:10,364 - INFO - bo.run_bo - Updated RF surrogate model with observation: -0.0039
2025-10-12 04:56:10,364 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-10-12 04:56:10,364 - INFO - bo.run_bo - Recorded observation #20: hparams={'lr': 9.709841338456428e-05, 'batch_size': np.int64(16), 'epochs': np.int64(50), 'weight_decay': 1.624076854437134e-06, 'dropout': 0.45217419995207564, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(1000), 'label_smoothing': 0.09828946363290918, 'grad_clip': 0.46880754322844465, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4699)}, value=-0.0039
2025-10-12 04:56:10,364 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 20: {'lr': 9.709841338456428e-05, 'batch_size': np.int64(16), 'epochs': np.int64(50), 'weight_decay': 1.624076854437134e-06, 'dropout': 0.45217419995207564, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(1000), 'label_smoothing': 0.09828946363290918, 'grad_clip': 0.46880754322844465, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4699)} -> -0.0039
2025-10-12 04:56:10,365 - INFO - bo.run_bo - üîçBO Trial 21: Using RF surrogate + Expected Improvement
2025-10-12 04:56:10,365 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 04:56:10,365 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 04:56:10,365 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 04:56:10,365 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001969334085479426, 'batch_size': 64, 'epochs': 47, 'weight_decay': 1.406586018887598e-06, 'dropout': 0.07305425134828948, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 125, 'label_smoothing': 0.12659174442251048, 'grad_clip': 0.3963585428362486, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7687}
2025-10-12 04:56:10,366 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001969334085479426, 'batch_size': 64, 'epochs': 47, 'weight_decay': 1.406586018887598e-06, 'dropout': 0.07305425134828948, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 125, 'label_smoothing': 0.12659174442251048, 'grad_clip': 0.3963585428362486, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7687}
2025-10-12 04:56:22,077 - INFO - _models.training_function_executor - Epoch 001/47 - train_loss: 1.2260 - val_loss: 1.1361 - val_acc: 0.6496
2025-10-12 04:56:33,575 - INFO - _models.training_function_executor - Epoch 002/47 - train_loss: 1.0158 - val_loss: 0.9862 - val_acc: 0.7128
2025-10-12 04:56:45,127 - INFO - _models.training_function_executor - Epoch 003/47 - train_loss: 0.9626 - val_loss: 0.9268 - val_acc: 0.7532
2025-10-12 04:56:56,663 - INFO - _models.training_function_executor - Epoch 004/47 - train_loss: 0.9266 - val_loss: 1.0284 - val_acc: 0.6952
2025-10-12 04:57:08,199 - INFO - _models.training_function_executor - Epoch 005/47 - train_loss: 0.9137 - val_loss: 0.9410 - val_acc: 0.7458
2025-10-12 04:57:19,722 - INFO - _models.training_function_executor - Epoch 006/47 - train_loss: 0.9019 - val_loss: 0.9240 - val_acc: 0.7549
2025-10-12 04:57:31,226 - INFO - _models.training_function_executor - Epoch 007/47 - train_loss: 0.8894 - val_loss: 0.8759 - val_acc: 0.7811
2025-10-12 04:57:42,716 - INFO - _models.training_function_executor - Epoch 008/47 - train_loss: 0.8827 - val_loss: 0.8683 - val_acc: 0.7815
2025-10-12 04:57:54,233 - INFO - _models.training_function_executor - Epoch 009/47 - train_loss: 0.8721 - val_loss: 0.9381 - val_acc: 0.7408
2025-10-12 04:58:05,742 - INFO - _models.training_function_executor - Epoch 010/47 - train_loss: 0.8696 - val_loss: 0.8602 - val_acc: 0.7862
2025-10-12 04:58:17,249 - INFO - _models.training_function_executor - Epoch 011/47 - train_loss: 0.8632 - val_loss: 0.9473 - val_acc: 0.7413
2025-10-12 04:58:28,770 - INFO - _models.training_function_executor - Epoch 012/47 - train_loss: 0.8588 - val_loss: 0.8849 - val_acc: 0.7707
2025-10-12 04:58:40,322 - INFO - _models.training_function_executor - Epoch 013/47 - train_loss: 0.8537 - val_loss: 0.8513 - val_acc: 0.7924
2025-10-12 04:58:51,868 - INFO - _models.training_function_executor - Epoch 014/47 - train_loss: 0.8486 - val_loss: 0.8296 - val_acc: 0.8024
2025-10-12 04:59:03,426 - INFO - _models.training_function_executor - Epoch 015/47 - train_loss: 0.8457 - val_loss: 0.8327 - val_acc: 0.8000
2025-10-12 04:59:14,987 - INFO - _models.training_function_executor - Epoch 016/47 - train_loss: 0.8399 - val_loss: 0.9066 - val_acc: 0.7665
2025-10-12 04:59:26,578 - INFO - _models.training_function_executor - Epoch 017/47 - train_loss: 0.8378 - val_loss: 0.8992 - val_acc: 0.7712
2025-10-12 04:59:38,065 - INFO - _models.training_function_executor - Epoch 018/47 - train_loss: 0.8381 - val_loss: 0.9279 - val_acc: 0.7605
2025-10-12 04:59:49,588 - INFO - _models.training_function_executor - Epoch 019/47 - train_loss: 0.8326 - val_loss: 0.8430 - val_acc: 0.7984
2025-10-12 05:00:01,153 - INFO - _models.training_function_executor - Epoch 020/47 - train_loss: 0.8286 - val_loss: 0.9436 - val_acc: 0.7579
2025-10-12 05:00:12,724 - INFO - _models.training_function_executor - Epoch 021/47 - train_loss: 0.8257 - val_loss: 0.9144 - val_acc: 0.7528
2025-10-12 05:00:24,252 - INFO - _models.training_function_executor - Epoch 022/47 - train_loss: 0.8234 - val_loss: 0.8357 - val_acc: 0.8082
2025-10-12 05:00:35,809 - INFO - _models.training_function_executor - Epoch 023/47 - train_loss: 0.8204 - val_loss: 0.9077 - val_acc: 0.7684
2025-10-12 05:00:47,349 - INFO - _models.training_function_executor - Epoch 024/47 - train_loss: 0.8160 - val_loss: 0.8280 - val_acc: 0.8070
2025-10-12 05:00:58,895 - INFO - _models.training_function_executor - Epoch 025/47 - train_loss: 0.8118 - val_loss: 0.9880 - val_acc: 0.7309
2025-10-12 05:01:10,426 - INFO - _models.training_function_executor - Epoch 026/47 - train_loss: 0.8114 - val_loss: 0.8519 - val_acc: 0.7982
2025-10-12 05:01:21,956 - INFO - _models.training_function_executor - Epoch 027/47 - train_loss: 0.8091 - val_loss: 0.8845 - val_acc: 0.7767
2025-10-12 05:01:33,515 - INFO - _models.training_function_executor - Epoch 028/47 - train_loss: 0.8058 - val_loss: 0.8561 - val_acc: 0.7975
2025-10-12 05:01:45,077 - INFO - _models.training_function_executor - Epoch 029/47 - train_loss: 0.8055 - val_loss: 0.8697 - val_acc: 0.7945
2025-10-12 05:01:56,624 - INFO - _models.training_function_executor - Epoch 030/47 - train_loss: 0.7999 - val_loss: 0.8863 - val_acc: 0.7714
2025-10-12 05:02:08,176 - INFO - _models.training_function_executor - Epoch 031/47 - train_loss: 0.7979 - val_loss: 0.8960 - val_acc: 0.7810
2025-10-12 05:02:19,697 - INFO - _models.training_function_executor - Epoch 032/47 - train_loss: 0.7966 - val_loss: 0.8454 - val_acc: 0.7968
2025-10-12 05:02:31,232 - INFO - _models.training_function_executor - Epoch 033/47 - train_loss: 0.7952 - val_loss: 0.8696 - val_acc: 0.7837
2025-10-12 05:02:42,758 - INFO - _models.training_function_executor - Epoch 034/47 - train_loss: 0.7907 - val_loss: 0.8551 - val_acc: 0.7976
2025-10-12 05:02:54,320 - INFO - _models.training_function_executor - Epoch 035/47 - train_loss: 0.7891 - val_loss: 0.9183 - val_acc: 0.7742
2025-10-12 05:03:05,890 - INFO - _models.training_function_executor - Epoch 036/47 - train_loss: 0.7862 - val_loss: 0.8651 - val_acc: 0.7895
2025-10-12 05:03:17,404 - INFO - _models.training_function_executor - Epoch 037/47 - train_loss: 0.7846 - val_loss: 0.9322 - val_acc: 0.7602
2025-10-12 05:03:28,947 - INFO - _models.training_function_executor - Epoch 038/47 - train_loss: 0.7843 - val_loss: 0.8748 - val_acc: 0.7844
2025-10-12 05:03:40,500 - INFO - _models.training_function_executor - Epoch 039/47 - train_loss: 0.7799 - val_loss: 0.9365 - val_acc: 0.7513
2025-10-12 05:03:52,035 - INFO - _models.training_function_executor - Epoch 040/47 - train_loss: 0.7804 - val_loss: 0.8522 - val_acc: 0.7979
2025-10-12 05:04:03,557 - INFO - _models.training_function_executor - Epoch 041/47 - train_loss: 0.7772 - val_loss: 0.9108 - val_acc: 0.7722
2025-10-12 05:04:15,067 - INFO - _models.training_function_executor - Epoch 042/47 - train_loss: 0.7778 - val_loss: 0.8898 - val_acc: 0.7754
2025-10-12 05:04:26,573 - INFO - _models.training_function_executor - Epoch 043/47 - train_loss: 0.7748 - val_loss: 0.8573 - val_acc: 0.8030
2025-10-12 05:04:38,117 - INFO - _models.training_function_executor - Epoch 044/47 - train_loss: 0.7725 - val_loss: 0.8647 - val_acc: 0.7918
2025-10-12 05:04:49,656 - INFO - _models.training_function_executor - Epoch 045/47 - train_loss: 0.7695 - val_loss: 0.8561 - val_acc: 0.7983
2025-10-12 05:05:01,207 - INFO - _models.training_function_executor - Epoch 046/47 - train_loss: 0.7696 - val_loss: 0.8648 - val_acc: 0.7896
2025-10-12 05:05:12,750 - INFO - _models.training_function_executor - Epoch 047/47 - train_loss: 0.7671 - val_loss: 0.9394 - val_acc: 0.7584
2025-10-12 05:05:12,753 - INFO - _models.training_function_executor - Model: 44,585 parameters, 191.6KB storage
2025-10-12 05:05:12,753 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2260000505854627, 1.0158007915594964, 0.9625638103334896, 0.926595620584104, 0.913679936443712, 0.901868026595371, 0.8894417715898794, 0.8827127704763896, 0.8720928908312366, 0.8696294810582509, 0.8632111777823664, 0.8588162190145573, 0.8536704424423148, 0.8485794171696156, 0.8456708495125388, 0.8399140178260163, 0.8378460011283626, 0.8381411771612398, 0.832588707186519, 0.8285719025664952, 0.825702835305988, 0.8234052864621476, 0.8204273013831603, 0.8159781155738123, 0.8117663396335291, 0.8114298433117572, 0.8091293548761568, 0.8058247837020586, 0.8055457988735008, 0.7998776873550842, 0.7979220796557711, 0.7965731304301888, 0.7952001444476444, 0.7907190828169816, 0.7890827737365271, 0.78621586590828, 0.7845904684417265, 0.7842572202288608, 0.7799453828816318, 0.7804291614878625, 0.7772099337963362, 0.7778489010126223, 0.7747790054879408, 0.7724567017940779, 0.7694742640165503, 0.7696303384972486, 0.7670834125819889], 'val_losses': [1.1360536978551046, 0.986161226570335, 0.9267986019382871, 1.0283612680468561, 0.9409558475956368, 0.9239565784129222, 0.8758699273495646, 0.8683188635025318, 0.9381375636176542, 0.860177134441086, 0.9473402791812697, 0.8848898347374606, 0.8513257779939883, 0.8295715190665807, 0.8327342878908471, 0.9065539899888805, 0.8992188497152118, 0.9278936287636602, 0.8430438688012492, 0.943641571594695, 0.9143827146777833, 0.8357185386968818, 0.9076730950462013, 0.8279646997648726, 0.9880319045981119, 0.8519072471317563, 0.8845115170263518, 0.8561205044049752, 0.86966398678587, 0.8863434447330906, 0.895985028315642, 0.8453637743521956, 0.8695586982789806, 0.8551127361925824, 0.9182679270129125, 0.8651365299178121, 0.9322171785383321, 0.8747864631576725, 0.9364648490758221, 0.8522315584449114, 0.9107988416877375, 0.8897969899245981, 0.8573426289036009, 0.8646797292250038, 0.8560688616639466, 0.8647754524068729, 0.9393765065984623], 'val_acc': [0.6496324816240812, 0.7128106405320266, 0.7531501575078754, 0.6952222611130556, 0.7457997899894995, 0.7549002450122506, 0.7810640532026601, 0.781501575078754, 0.7408120406020301, 0.786226811340567, 0.7413370668533427, 0.7706510325516276, 0.7923521176058803, 0.8024151207560378, 0.7999649982499125, 0.7665383269163458, 0.7711760588029402, 0.7605005250262513, 0.7983899194959748, 0.7578753937696885, 0.7528001400070004, 0.808190409520476, 0.7683759187959398, 0.8069653482674134, 0.7309240462023101, 0.7982149107455373, 0.7766888344417221, 0.7975148757437872, 0.7944522226111306, 0.7713510675533777, 0.7809765488274414, 0.7968148407420371, 0.783689184459223, 0.797602380119006, 0.774151207560378, 0.7894644732236612, 0.7601505075253763, 0.7843892194609731, 0.7513125656282814, 0.7978648932446623, 0.7722261113055653, 0.7753762688134407, 0.8030276513825692, 0.7918270913545677, 0.7983024151207561, 0.7896394819740987, 0.758400420021001], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001969334085479426, 'batch_size': 64, 'epochs': 47, 'weight_decay': 1.406586018887598e-06, 'dropout': 0.07305425134828948, 'base_channels': 15, 'temporal_kernel': 5, 'spatial_segments': 125, 'label_smoothing': 0.12659174442251048, 'grad_clip': 0.3963585428362486, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7687}, 'model_parameter_count': 44585, 'model_storage_size_kb': 191.57617187500003, 'model_size_validation': 'PASS'}
2025-10-12 05:05:12,753 - INFO - _models.training_function_executor - BO Objective: base=0.7584, size_penalty=0.0000, final=0.7584
2025-10-12 05:05:12,753 - INFO - _models.training_function_executor - Model: 44,585 parameters, 191.6KB (PASS 256KB limit)
2025-10-12 05:05:12,753 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 542.389s
2025-10-12 05:05:12,863 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7584
2025-10-12 05:05:12,863 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-10-12 05:05:12,863 - INFO - bo.run_bo - Recorded observation #21: hparams={'lr': 0.001969334085479426, 'batch_size': np.int64(64), 'epochs': np.int64(47), 'weight_decay': 1.406586018887598e-06, 'dropout': 0.07305425134828948, 'base_channels': np.int64(15), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(125), 'label_smoothing': 0.12659174442251048, 'grad_clip': 0.3963585428362486, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(7687)}, value=0.7584
2025-10-12 05:05:12,863 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 21: {'lr': 0.001969334085479426, 'batch_size': np.int64(64), 'epochs': np.int64(47), 'weight_decay': 1.406586018887598e-06, 'dropout': 0.07305425134828948, 'base_channels': np.int64(15), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(125), 'label_smoothing': 0.12659174442251048, 'grad_clip': 0.3963585428362486, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(7687)} -> 0.7584
2025-10-12 05:05:12,863 - INFO - bo.run_bo - üîçBO Trial 22: Using RF surrogate + Expected Improvement
2025-10-12 05:05:12,863 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 05:05:12,863 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 05:05:12,863 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 05:05:12,864 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.02726207850660365, 'batch_size': 16, 'epochs': 49, 'weight_decay': 2.544707855386459e-06, 'dropout': 0.214560685546477, 'base_channels': 17, 'temporal_kernel': 7, 'spatial_segments': 75, 'label_smoothing': 0.1864928627351072, 'grad_clip': 0.42421568668878906, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 3426}
2025-10-12 05:05:12,865 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.02726207850660365, 'batch_size': 16, 'epochs': 49, 'weight_decay': 2.544707855386459e-06, 'dropout': 0.214560685546477, 'base_channels': 17, 'temporal_kernel': 7, 'spatial_segments': 75, 'label_smoothing': 0.1864928627351072, 'grad_clip': 0.42421568668878906, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 3426}
2025-10-12 05:05:27,394 - INFO - _models.training_function_executor - Epoch 001/49 - train_loss: 2.2414 - val_loss: 2.2343 - val_acc: 0.3307
2025-10-12 05:05:41,884 - INFO - _models.training_function_executor - Epoch 002/49 - train_loss: 2.4934 - val_loss: 3.0059 - val_acc: 0.2878
2025-10-12 05:05:56,417 - INFO - _models.training_function_executor - Epoch 003/49 - train_loss: 2.6326 - val_loss: 2.4853 - val_acc: 0.3603
2025-10-12 05:06:10,905 - INFO - _models.training_function_executor - Epoch 004/49 - train_loss: 2.6271 - val_loss: 2.6294 - val_acc: 0.3617
2025-10-12 05:06:25,375 - INFO - _models.training_function_executor - Epoch 005/49 - train_loss: 2.7322 - val_loss: 3.0632 - val_acc: 0.3715
2025-10-12 05:06:39,851 - INFO - _models.training_function_executor - Epoch 006/49 - train_loss: 2.9011 - val_loss: 2.5961 - val_acc: 0.3260
2025-10-12 05:06:54,325 - INFO - _models.training_function_executor - Epoch 007/49 - train_loss: 2.9237 - val_loss: 3.3929 - val_acc: 0.3180
2025-10-12 05:07:08,762 - INFO - _models.training_function_executor - Epoch 008/49 - train_loss: 3.0449 - val_loss: 2.8109 - val_acc: 0.4758
2025-10-12 05:07:23,203 - INFO - _models.training_function_executor - Epoch 009/49 - train_loss: 3.1736 - val_loss: 2.6627 - val_acc: 0.5300
2025-10-12 05:07:37,658 - INFO - _models.training_function_executor - Epoch 010/49 - train_loss: 3.4712 - val_loss: 3.3444 - val_acc: 0.4570
2025-10-12 05:07:52,125 - INFO - _models.training_function_executor - Epoch 011/49 - train_loss: 3.2034 - val_loss: 2.6783 - val_acc: 0.3911
2025-10-12 05:08:06,644 - INFO - _models.training_function_executor - Epoch 012/49 - train_loss: 3.0563 - val_loss: 3.6263 - val_acc: 0.2188
2025-10-12 05:08:21,081 - INFO - _models.training_function_executor - Epoch 013/49 - train_loss: 3.3997 - val_loss: 5.8748 - val_acc: 0.5366
2025-10-12 05:08:35,550 - INFO - _models.training_function_executor - Epoch 014/49 - train_loss: 3.3813 - val_loss: 3.7899 - val_acc: 0.4174
2025-10-12 05:08:50,059 - INFO - _models.training_function_executor - Epoch 015/49 - train_loss: 3.7581 - val_loss: 2.3705 - val_acc: 0.4728
2025-10-12 05:09:04,534 - INFO - _models.training_function_executor - Epoch 016/49 - train_loss: 3.5782 - val_loss: 3.0708 - val_acc: 0.4366
2025-10-12 05:09:19,040 - INFO - _models.training_function_executor - Epoch 017/49 - train_loss: 3.3407 - val_loss: 3.7245 - val_acc: 0.4550
2025-10-12 05:09:33,523 - INFO - _models.training_function_executor - Epoch 018/49 - train_loss: 3.6780 - val_loss: 2.5139 - val_acc: 0.4849
2025-10-12 05:09:48,059 - INFO - _models.training_function_executor - Epoch 019/49 - train_loss: 3.4331 - val_loss: 3.1655 - val_acc: 0.5409
2025-10-12 05:10:02,555 - INFO - _models.training_function_executor - Epoch 020/49 - train_loss: 3.8117 - val_loss: 5.7199 - val_acc: 0.5058
2025-10-12 05:10:17,044 - INFO - _models.training_function_executor - Epoch 021/49 - train_loss: 3.6950 - val_loss: 6.2671 - val_acc: 0.4728
2025-10-12 05:10:31,573 - INFO - _models.training_function_executor - Epoch 022/49 - train_loss: 3.9541 - val_loss: 3.7368 - val_acc: 0.5560
2025-10-12 05:10:46,051 - INFO - _models.training_function_executor - Epoch 023/49 - train_loss: 4.0310 - val_loss: 2.9711 - val_acc: 0.4282
2025-10-12 05:11:00,503 - INFO - _models.training_function_executor - Epoch 024/49 - train_loss: 3.7812 - val_loss: 4.2812 - val_acc: 0.4933
2025-10-12 05:11:15,018 - INFO - _models.training_function_executor - Epoch 025/49 - train_loss: 3.7316 - val_loss: 3.4672 - val_acc: 0.4105
2025-10-12 05:11:29,483 - INFO - _models.training_function_executor - Epoch 026/49 - train_loss: 4.0749 - val_loss: 3.6236 - val_acc: 0.2485
2025-10-12 05:11:43,985 - INFO - _models.training_function_executor - Epoch 027/49 - train_loss: 4.8546 - val_loss: 5.1579 - val_acc: 0.4954
2025-10-12 05:11:58,483 - INFO - _models.training_function_executor - Epoch 028/49 - train_loss: 4.0673 - val_loss: 5.3579 - val_acc: 0.4576
2025-10-12 05:12:12,929 - INFO - _models.training_function_executor - Epoch 029/49 - train_loss: 4.1179 - val_loss: 2.4359 - val_acc: 0.5053
2025-10-12 05:12:27,388 - INFO - _models.training_function_executor - Epoch 030/49 - train_loss: 3.8866 - val_loss: 4.6188 - val_acc: 0.5536
2025-10-12 05:12:41,891 - INFO - _models.training_function_executor - Epoch 031/49 - train_loss: 4.4501 - val_loss: 2.6177 - val_acc: 0.5868
2025-10-12 05:12:56,376 - INFO - _models.training_function_executor - Epoch 032/49 - train_loss: 4.1101 - val_loss: 5.5387 - val_acc: 0.4499
2025-10-12 05:13:10,875 - INFO - _models.training_function_executor - Epoch 033/49 - train_loss: 3.9293 - val_loss: 4.3410 - val_acc: 0.5758
2025-10-12 05:13:25,365 - INFO - _models.training_function_executor - Epoch 034/49 - train_loss: 4.5086 - val_loss: 6.5991 - val_acc: 0.2966
2025-10-12 05:13:39,830 - INFO - _models.training_function_executor - Epoch 035/49 - train_loss: 4.0367 - val_loss: 3.6991 - val_acc: 0.2637
2025-10-12 05:13:54,299 - INFO - _models.training_function_executor - Epoch 036/49 - train_loss: 5.2958 - val_loss: 3.6525 - val_acc: 0.2665
2025-10-12 05:14:08,788 - INFO - _models.training_function_executor - Epoch 037/49 - train_loss: 4.2840 - val_loss: 3.5830 - val_acc: 0.5867
2025-10-12 05:14:23,280 - INFO - _models.training_function_executor - Epoch 038/49 - train_loss: 4.6129 - val_loss: 3.5098 - val_acc: 0.4904
2025-10-12 05:14:37,781 - INFO - _models.training_function_executor - Epoch 039/49 - train_loss: 4.3159 - val_loss: 3.7642 - val_acc: 0.5716
2025-10-12 05:14:52,263 - INFO - _models.training_function_executor - Epoch 040/49 - train_loss: 4.0733 - val_loss: 3.6160 - val_acc: 0.3733
2025-10-12 05:15:06,723 - INFO - _models.training_function_executor - Epoch 041/49 - train_loss: 4.5572 - val_loss: 3.6406 - val_acc: 0.6086
2025-10-12 05:15:21,196 - INFO - _models.training_function_executor - Epoch 042/49 - train_loss: 4.5180 - val_loss: 4.4146 - val_acc: 0.4324
2025-10-12 05:15:35,643 - INFO - _models.training_function_executor - Epoch 043/49 - train_loss: 5.8673 - val_loss: 6.5271 - val_acc: 0.4744
2025-10-12 05:15:50,113 - INFO - _models.training_function_executor - Epoch 044/49 - train_loss: 5.7500 - val_loss: 3.7114 - val_acc: 0.5901
2025-10-12 05:16:04,575 - INFO - _models.training_function_executor - Epoch 045/49 - train_loss: 5.3561 - val_loss: 3.2716 - val_acc: 0.4871
2025-10-12 05:16:19,084 - INFO - _models.training_function_executor - Epoch 046/49 - train_loss: 5.4333 - val_loss: 9.2614 - val_acc: 0.6119
2025-10-12 05:16:33,570 - INFO - _models.training_function_executor - Epoch 047/49 - train_loss: 4.4981 - val_loss: 4.0097 - val_acc: 0.4740
2025-10-12 05:16:48,042 - INFO - _models.training_function_executor - Epoch 048/49 - train_loss: 5.6190 - val_loss: 7.6248 - val_acc: 0.3767
2025-10-12 05:17:02,505 - INFO - _models.training_function_executor - Epoch 049/49 - train_loss: 6.9242 - val_loss: 5.1087 - val_acc: 0.5604
2025-10-12 05:17:02,507 - INFO - _models.training_function_executor - Model: 48,969 parameters, 210.4KB storage
2025-10-12 05:17:02,507 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [2.241363005951897, 2.4933636008670876, 2.632582970711999, 2.6271061848459185, 2.732222328788549, 2.901068750026971, 2.9236895544027424, 3.044868063209021, 3.1736447578299325, 3.471187757536127, 3.2033594016391245, 3.0562806623900816, 3.3996647857559865, 3.3813112619918755, 3.758070047977382, 3.578202977938213, 3.3407230602096836, 3.6780036499252424, 3.433063446536613, 3.811700487412228, 3.6949670875577354, 3.954143187738525, 4.030989396350969, 3.781219351195688, 3.7316149632581097, 4.07494221528093, 4.854565510476099, 4.067309074982672, 4.117892778040773, 3.8865880094126966, 4.450083191719429, 4.110068321812182, 3.9292885684282743, 4.5086347334527614, 4.036749601572763, 5.295771678678214, 4.2840404350690005, 4.6129035551230055, 4.315866018868761, 4.073332889579917, 4.5571920140706705, 4.518020277428886, 5.8673280355685815, 5.750033461342419, 5.3560680083807926, 5.4332627787805325, 4.498115133062543, 5.618979572290134, 6.924236620853613], 'val_losses': [2.2342663318659404, 3.0058838702766972, 2.4852635452369314, 2.6294082331832658, 3.0631845410486847, 2.59613966382714, 3.392878438611109, 2.810935914871114, 2.662717235810197, 3.344429624301802, 2.6783244780906648, 3.6263250166359255, 5.8747594520517445, 3.789857948915417, 2.3705009240807042, 3.0708250974415483, 3.7244705995313345, 2.5139049098422404, 3.1655102408679165, 5.719943407911248, 6.267051762536476, 3.7368289697908796, 2.971083014170774, 4.2812227806846375, 3.4672473878096066, 3.623578138187877, 5.157910963685353, 5.357915505938986, 2.435932509499411, 4.6187529340256, 2.6177067098227003, 5.538712000154222, 4.340985787052519, 6.5990616736981185, 3.6990734445577242, 3.652497733603168, 3.5830449814307426, 3.509809850352938, 3.7641728541047415, 3.6160422796797493, 3.6406046861028356, 4.414581493226473, 6.527113378819862, 3.711368777345518, 3.271559427199265, 9.261401911486184, 4.0097009513943105, 7.624818309854701, 5.10866552076016], 'val_acc': [0.33067903395169757, 0.28780189009450474, 0.36034301715085754, 0.36165558277913895, 0.3714560728036402, 0.32604130206510323, 0.3179908995449772, 0.4757612880644032, 0.530014000700035, 0.45703535176758836, 0.39105705285264264, 0.2188484424221211, 0.5365768288414421, 0.4173958697934897, 0.47278613930696534, 0.4366468323416171, 0.45502275113755686, 0.4849492474623731, 0.5408645432271614, 0.5057752887644382, 0.47278613930696534, 0.556002800140007, 0.42824641232061605, 0.4932621631081554, 0.4104830241512076, 0.24851242562128106, 0.49544977248862443, 0.4575603780189009, 0.5052502625131257, 0.5536401820091005, 0.5868043402170109, 0.4499474973748687, 0.575778788939447, 0.29655232761638084, 0.2636506825341267, 0.2665383269163458, 0.5867168358417921, 0.4903745187259363, 0.5715785789289465, 0.37329366468323416, 0.6085929296464824, 0.4324466223311166, 0.47436121806090303, 0.5901295064753238, 0.48713685684284214, 0.6119180959047953, 0.474011200560028, 0.37670633531676584, 0.5603780189009451], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.02726207850660365, 'batch_size': 16, 'epochs': 49, 'weight_decay': 2.544707855386459e-06, 'dropout': 0.214560685546477, 'base_channels': 17, 'temporal_kernel': 7, 'spatial_segments': 75, 'label_smoothing': 0.1864928627351072, 'grad_clip': 0.42421568668878906, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 3426}, 'model_parameter_count': 48969, 'model_storage_size_kb': 210.413671875, 'model_size_validation': 'PASS'}
2025-10-12 05:17:02,507 - INFO - _models.training_function_executor - BO Objective: base=0.5604, size_penalty=0.0000, final=0.5604
2025-10-12 05:17:02,507 - INFO - _models.training_function_executor - Model: 48,969 parameters, 210.4KB (PASS 256KB limit)
2025-10-12 05:17:02,507 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 709.644s
2025-10-12 05:17:02,610 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5604
2025-10-12 05:17:02,610 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.100s
2025-10-12 05:17:02,610 - INFO - bo.run_bo - Recorded observation #22: hparams={'lr': 0.02726207850660365, 'batch_size': np.int64(16), 'epochs': np.int64(49), 'weight_decay': 2.544707855386459e-06, 'dropout': 0.214560685546477, 'base_channels': np.int64(17), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(75), 'label_smoothing': 0.1864928627351072, 'grad_clip': 0.42421568668878906, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(3426)}, value=0.5604
2025-10-12 05:17:02,610 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 22: {'lr': 0.02726207850660365, 'batch_size': np.int64(16), 'epochs': np.int64(49), 'weight_decay': 2.544707855386459e-06, 'dropout': 0.214560685546477, 'base_channels': np.int64(17), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(75), 'label_smoothing': 0.1864928627351072, 'grad_clip': 0.42421568668878906, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(3426)} -> 0.5604
2025-10-12 05:17:02,610 - INFO - bo.run_bo - üîçBO Trial 23: Using RF surrogate + Expected Improvement
2025-10-12 05:17:02,610 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 05:17:02,610 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 05:17:02,610 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 05:17:02,610 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0014632375231825496, 'batch_size': 16, 'epochs': 46, 'weight_decay': 1.6614795981792087e-06, 'dropout': 0.0032864092563727474, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 200, 'label_smoothing': 0.15706859081026722, 'grad_clip': 0.3483771143037428, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7916}
2025-10-12 05:17:02,611 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0014632375231825496, 'batch_size': 16, 'epochs': 46, 'weight_decay': 1.6614795981792087e-06, 'dropout': 0.0032864092563727474, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 200, 'label_smoothing': 0.15706859081026722, 'grad_clip': 0.3483771143037428, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7916}
2025-10-12 05:17:18,734 - INFO - _models.training_function_executor - Epoch 001/46 - train_loss: 1.2501 - val_loss: 1.7904 - val_acc: 0.3380
2025-10-12 05:17:34,654 - INFO - _models.training_function_executor - Epoch 002/46 - train_loss: 1.0824 - val_loss: 1.1409 - val_acc: 0.6694
2025-10-12 05:17:50,651 - INFO - _models.training_function_executor - Epoch 003/46 - train_loss: 1.0128 - val_loss: 0.9687 - val_acc: 0.7599
2025-10-12 05:18:06,614 - INFO - _models.training_function_executor - Epoch 004/46 - train_loss: 0.9798 - val_loss: 0.9858 - val_acc: 0.7417
2025-10-12 05:18:22,576 - INFO - _models.training_function_executor - Epoch 005/46 - train_loss: 0.9588 - val_loss: 0.9715 - val_acc: 0.7496
2025-10-12 05:18:38,548 - INFO - _models.training_function_executor - Epoch 006/46 - train_loss: 0.9462 - val_loss: 0.9353 - val_acc: 0.7715
2025-10-12 05:18:54,487 - INFO - _models.training_function_executor - Epoch 007/46 - train_loss: 0.9381 - val_loss: 0.9487 - val_acc: 0.7693
2025-10-12 05:19:10,446 - INFO - _models.training_function_executor - Epoch 008/46 - train_loss: 0.9332 - val_loss: 0.9259 - val_acc: 0.7743
2025-10-12 05:19:26,385 - INFO - _models.training_function_executor - Epoch 009/46 - train_loss: 0.9237 - val_loss: 1.1671 - val_acc: 0.6398
2025-10-12 05:19:42,323 - INFO - _models.training_function_executor - Epoch 010/46 - train_loss: 0.9185 - val_loss: 0.9217 - val_acc: 0.7806
2025-10-12 05:19:58,300 - INFO - _models.training_function_executor - Epoch 011/46 - train_loss: 0.9137 - val_loss: 0.8963 - val_acc: 0.8008
2025-10-12 05:20:14,279 - INFO - _models.training_function_executor - Epoch 012/46 - train_loss: 0.9094 - val_loss: 0.9095 - val_acc: 0.7906
2025-10-12 05:20:30,227 - INFO - _models.training_function_executor - Epoch 013/46 - train_loss: 0.9049 - val_loss: 0.9025 - val_acc: 0.7982
2025-10-12 05:20:46,183 - INFO - _models.training_function_executor - Epoch 014/46 - train_loss: 0.8995 - val_loss: 0.8917 - val_acc: 0.7994
2025-10-12 05:21:02,170 - INFO - _models.training_function_executor - Epoch 015/46 - train_loss: 0.8946 - val_loss: 0.9077 - val_acc: 0.7924
2025-10-12 05:21:18,130 - INFO - _models.training_function_executor - Epoch 016/46 - train_loss: 0.8917 - val_loss: 0.9005 - val_acc: 0.7906
2025-10-12 05:21:34,038 - INFO - _models.training_function_executor - Epoch 017/46 - train_loss: 0.8899 - val_loss: 0.9014 - val_acc: 0.7985
2025-10-12 05:21:50,014 - INFO - _models.training_function_executor - Epoch 018/46 - train_loss: 0.8853 - val_loss: 0.8892 - val_acc: 0.8009
2025-10-12 05:22:05,989 - INFO - _models.training_function_executor - Epoch 019/46 - train_loss: 0.8830 - val_loss: 0.9048 - val_acc: 0.7931
2025-10-12 05:22:21,947 - INFO - _models.training_function_executor - Epoch 020/46 - train_loss: 0.8795 - val_loss: 0.8956 - val_acc: 0.7966
2025-10-12 05:22:37,911 - INFO - _models.training_function_executor - Epoch 021/46 - train_loss: 0.8792 - val_loss: 0.9047 - val_acc: 0.7950
2025-10-12 05:22:53,806 - INFO - _models.training_function_executor - Epoch 022/46 - train_loss: 0.8748 - val_loss: 0.8760 - val_acc: 0.8076
2025-10-12 05:23:09,721 - INFO - _models.training_function_executor - Epoch 023/46 - train_loss: 0.8736 - val_loss: 0.8882 - val_acc: 0.8026
2025-10-12 05:23:25,656 - INFO - _models.training_function_executor - Epoch 024/46 - train_loss: 0.8691 - val_loss: 0.9157 - val_acc: 0.7879
2025-10-12 05:23:41,602 - INFO - _models.training_function_executor - Epoch 025/46 - train_loss: 0.8665 - val_loss: 0.8833 - val_acc: 0.8057
2025-10-12 05:23:57,565 - INFO - _models.training_function_executor - Epoch 026/46 - train_loss: 0.8647 - val_loss: 0.9075 - val_acc: 0.7868
2025-10-12 05:24:13,542 - INFO - _models.training_function_executor - Epoch 027/46 - train_loss: 0.8620 - val_loss: 1.0571 - val_acc: 0.7044
2025-10-12 05:24:29,505 - INFO - _models.training_function_executor - Epoch 028/46 - train_loss: 0.8581 - val_loss: 0.9031 - val_acc: 0.7957
2025-10-12 05:24:45,474 - INFO - _models.training_function_executor - Epoch 029/46 - train_loss: 0.8570 - val_loss: 0.9464 - val_acc: 0.7707
2025-10-12 05:25:01,401 - INFO - _models.training_function_executor - Epoch 030/46 - train_loss: 0.8539 - val_loss: 0.8933 - val_acc: 0.8015
2025-10-12 05:25:17,332 - INFO - _models.training_function_executor - Epoch 031/46 - train_loss: 0.8490 - val_loss: 0.8976 - val_acc: 0.7991
2025-10-12 05:25:33,264 - INFO - _models.training_function_executor - Epoch 032/46 - train_loss: 0.8455 - val_loss: 0.9144 - val_acc: 0.7861
2025-10-12 05:25:49,278 - INFO - _models.training_function_executor - Epoch 033/46 - train_loss: 0.8422 - val_loss: 1.0253 - val_acc: 0.7291
2025-10-12 05:26:05,265 - INFO - _models.training_function_executor - Epoch 034/46 - train_loss: 0.8400 - val_loss: 0.9000 - val_acc: 0.8016
2025-10-12 05:26:21,238 - INFO - _models.training_function_executor - Epoch 035/46 - train_loss: 0.8341 - val_loss: 0.9043 - val_acc: 0.8059
2025-10-12 05:26:37,193 - INFO - _models.training_function_executor - Epoch 036/46 - train_loss: 0.8304 - val_loss: 0.9650 - val_acc: 0.7736
2025-10-12 05:26:53,153 - INFO - _models.training_function_executor - Epoch 037/46 - train_loss: 0.8294 - val_loss: 0.9841 - val_acc: 0.7550
2025-10-12 05:27:09,136 - INFO - _models.training_function_executor - Epoch 038/46 - train_loss: 0.8254 - val_loss: 0.9436 - val_acc: 0.7782
2025-10-12 05:27:25,079 - INFO - _models.training_function_executor - Epoch 039/46 - train_loss: 0.8200 - val_loss: 0.9342 - val_acc: 0.7798
2025-10-12 05:27:41,051 - INFO - _models.training_function_executor - Epoch 040/46 - train_loss: 0.8162 - val_loss: 0.9284 - val_acc: 0.7904
2025-10-12 05:27:57,028 - INFO - _models.training_function_executor - Epoch 041/46 - train_loss: 0.8122 - val_loss: 0.9243 - val_acc: 0.7981
2025-10-12 05:28:12,991 - INFO - _models.training_function_executor - Epoch 042/46 - train_loss: 0.8074 - val_loss: 0.9215 - val_acc: 0.8039
2025-10-12 05:28:28,921 - INFO - _models.training_function_executor - Epoch 043/46 - train_loss: 0.8066 - val_loss: 0.9427 - val_acc: 0.7901
2025-10-12 05:28:44,882 - INFO - _models.training_function_executor - Epoch 044/46 - train_loss: 0.8014 - val_loss: 0.9005 - val_acc: 0.8086
2025-10-12 05:29:00,851 - INFO - _models.training_function_executor - Epoch 045/46 - train_loss: 0.8004 - val_loss: 0.9658 - val_acc: 0.7698
2025-10-12 05:29:16,828 - INFO - _models.training_function_executor - Epoch 046/46 - train_loss: 0.7960 - val_loss: 0.9644 - val_acc: 0.7809
2025-10-12 05:29:16,831 - INFO - _models.training_function_executor - Model: 76,785 parameters, 165.0KB storage
2025-10-12 05:29:16,831 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2501274348765685, 1.082449307944919, 1.012780134290676, 0.9798417670308688, 0.9588419614574231, 0.9461661975701705, 0.9380924603844757, 0.9331863050616034, 0.9236526698301754, 0.9184628421291422, 0.9136703452072571, 0.9094222259972118, 0.904919989008064, 0.8995492186502931, 0.8945640770755617, 0.8916589543249459, 0.8899387470233011, 0.8852674827151754, 0.8830327485715087, 0.8794703855771554, 0.8791738069261918, 0.8747816886107405, 0.8736083306004461, 0.8691426666416319, 0.86653375458709, 0.8647485216430821, 0.8620431177425018, 0.8580575214844297, 0.8570083920714485, 0.8538817442669333, 0.8489503392315345, 0.8455409884327644, 0.8421658180708813, 0.8400147342373118, 0.8341379381369409, 0.8304299820875596, 0.8293716919810196, 0.8253539832981057, 0.8199514771909784, 0.816217458556906, 0.8122172148694181, 0.8074437367528061, 0.8065542455607458, 0.8014237771177776, 0.8003595662692814, 0.7959637481264189], 'val_losses': [1.7904310737158562, 1.1408643552712057, 0.9687225439142088, 0.9857771951583953, 0.9715389131790364, 0.9353170759576912, 0.9486567301478134, 0.9259049126139712, 1.16708087416266, 0.9217406399482858, 0.8963011927566288, 0.9094913270784751, 0.902517293523482, 0.8916659880902829, 0.9077048529934374, 0.900537410440001, 0.9014123778348208, 0.8892126927477604, 0.9047965135530947, 0.8955603481423909, 0.9047436610067646, 0.8759948812375588, 0.8881515660901815, 0.9156786680722262, 0.8832965190067632, 0.9075045050296243, 1.0571198272129267, 0.9031212848927702, 0.9463552717232896, 0.8933400715569912, 0.8976314296704053, 0.9143589523483666, 1.0253431076639634, 0.90003191383727, 0.9043113491440887, 0.9650118430886687, 0.9841124861858757, 0.9435891122888092, 0.9341511089859369, 0.9283880666289498, 0.9243190240142309, 0.9214859254342674, 0.942733365941974, 0.9005196163359747, 0.9658430409590014, 0.9644177682465676], 'val_acc': [0.3380294014700735, 0.6694084704235211, 0.75988799439972, 0.7416870843542177, 0.749649982499125, 0.7715260763038152, 0.7692509625481274, 0.7743262163108156, 0.6398319915995799, 0.7806265313265663, 0.8008400420021001, 0.7906020301015051, 0.7982149107455373, 0.7994399719986, 0.7923521176058803, 0.7906020301015051, 0.7984774238711936, 0.8009275463773189, 0.7930521526076304, 0.7966398319915996, 0.7949772488624431, 0.8075778788939447, 0.8025901295064753, 0.7878893944697235, 0.8057402870143507, 0.7867518375918796, 0.7044102205110255, 0.7956772838641932, 0.7707385369268464, 0.8014525726286315, 0.7990899544977249, 0.7860518025901295, 0.7290864543227161, 0.801627581379069, 0.8059152957647883, 0.7736261813090655, 0.7549877493874694, 0.778176408820441, 0.7797514875743787, 0.7904270213510676, 0.7981274063703185, 0.8039026951347568, 0.7900770038501925, 0.8086279313965699, 0.76977598879944, 0.7808890444522226], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0014632375231825496, 'batch_size': 16, 'epochs': 46, 'weight_decay': 1.6614795981792087e-06, 'dropout': 0.0032864092563727474, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 200, 'label_smoothing': 0.15706859081026722, 'grad_clip': 0.3483771143037428, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7916}, 'model_parameter_count': 76785, 'model_storage_size_kb': 164.9677734375, 'model_size_validation': 'PASS'}
2025-10-12 05:29:16,831 - INFO - _models.training_function_executor - BO Objective: base=0.7809, size_penalty=0.0000, final=0.7809
2025-10-12 05:29:16,831 - INFO - _models.training_function_executor - Model: 76,785 parameters, 165.0KB (PASS 256KB limit)
2025-10-12 05:29:16,831 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 734.221s
2025-10-12 05:29:16,937 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7809
2025-10-12 05:29:16,937 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-12 05:29:16,937 - INFO - bo.run_bo - Recorded observation #23: hparams={'lr': 0.0014632375231825496, 'batch_size': np.int64(16), 'epochs': np.int64(46), 'weight_decay': 1.6614795981792087e-06, 'dropout': 0.0032864092563727474, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(200), 'label_smoothing': 0.15706859081026722, 'grad_clip': 0.3483771143037428, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(7916)}, value=0.7809
2025-10-12 05:29:16,937 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 23: {'lr': 0.0014632375231825496, 'batch_size': np.int64(16), 'epochs': np.int64(46), 'weight_decay': 1.6614795981792087e-06, 'dropout': 0.0032864092563727474, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(200), 'label_smoothing': 0.15706859081026722, 'grad_clip': 0.3483771143037428, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(7916)} -> 0.7809
2025-10-12 05:29:16,937 - INFO - bo.run_bo - üîçBO Trial 24: Using RF surrogate + Expected Improvement
2025-10-12 05:29:16,937 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 05:29:16,937 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 05:29:16,937 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 05:29:16,937 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00036789517124077175, 'batch_size': 16, 'epochs': 49, 'weight_decay': 1.3601526499853536e-06, 'dropout': 0.0035331523233703152, 'base_channels': 20, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.00551273456844752, 'grad_clip': 0.6126380958047585, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2157}
2025-10-12 05:29:16,938 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00036789517124077175, 'batch_size': 16, 'epochs': 49, 'weight_decay': 1.3601526499853536e-06, 'dropout': 0.0035331523233703152, 'base_channels': 20, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.00551273456844752, 'grad_clip': 0.6126380958047585, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2157}
2025-10-12 05:29:32,845 - INFO - _models.training_function_executor - Epoch 001/49 - train_loss: 1.0636 - val_loss: 0.8974 - val_acc: 0.6503
2025-10-12 05:29:48,684 - INFO - _models.training_function_executor - Epoch 002/49 - train_loss: 0.7618 - val_loss: 0.8086 - val_acc: 0.7074
2025-10-12 05:30:04,538 - INFO - _models.training_function_executor - Epoch 003/49 - train_loss: 0.6869 - val_loss: 0.6543 - val_acc: 0.7473
2025-10-12 05:30:20,363 - INFO - _models.training_function_executor - Epoch 004/49 - train_loss: 0.6461 - val_loss: 0.6690 - val_acc: 0.7448
2025-10-12 05:30:36,155 - INFO - _models.training_function_executor - Epoch 005/49 - train_loss: 0.6234 - val_loss: 0.6137 - val_acc: 0.7672
2025-10-12 05:30:51,979 - INFO - _models.training_function_executor - Epoch 006/49 - train_loss: 0.6004 - val_loss: 0.5820 - val_acc: 0.7827
2025-10-12 05:31:07,777 - INFO - _models.training_function_executor - Epoch 007/49 - train_loss: 0.5873 - val_loss: 0.8620 - val_acc: 0.6979
2025-10-12 05:31:23,592 - INFO - _models.training_function_executor - Epoch 008/49 - train_loss: 0.5741 - val_loss: 0.5980 - val_acc: 0.7812
2025-10-12 05:31:39,406 - INFO - _models.training_function_executor - Epoch 009/49 - train_loss: 0.5604 - val_loss: 0.6867 - val_acc: 0.7395
2025-10-12 05:31:55,239 - INFO - _models.training_function_executor - Epoch 010/49 - train_loss: 0.5533 - val_loss: 0.5654 - val_acc: 0.7924
2025-10-12 05:32:11,085 - INFO - _models.training_function_executor - Epoch 011/49 - train_loss: 0.5471 - val_loss: 0.6927 - val_acc: 0.7370
2025-10-12 05:32:26,889 - INFO - _models.training_function_executor - Epoch 012/49 - train_loss: 0.5405 - val_loss: 0.5729 - val_acc: 0.7897
2025-10-12 05:32:42,692 - INFO - _models.training_function_executor - Epoch 013/49 - train_loss: 0.5296 - val_loss: 0.5745 - val_acc: 0.7951
2025-10-12 05:32:58,548 - INFO - _models.training_function_executor - Epoch 014/49 - train_loss: 0.5225 - val_loss: 0.6180 - val_acc: 0.7709
2025-10-12 05:33:14,426 - INFO - _models.training_function_executor - Epoch 015/49 - train_loss: 0.5180 - val_loss: 0.5564 - val_acc: 0.7993
2025-10-12 05:33:30,256 - INFO - _models.training_function_executor - Epoch 016/49 - train_loss: 0.5114 - val_loss: 0.5873 - val_acc: 0.7875
2025-10-12 05:33:46,118 - INFO - _models.training_function_executor - Epoch 017/49 - train_loss: 0.5059 - val_loss: 0.5802 - val_acc: 0.7837
2025-10-12 05:34:01,955 - INFO - _models.training_function_executor - Epoch 018/49 - train_loss: 0.5004 - val_loss: 0.5985 - val_acc: 0.7897
2025-10-12 05:34:17,802 - INFO - _models.training_function_executor - Epoch 019/49 - train_loss: 0.4979 - val_loss: 0.6770 - val_acc: 0.7504
2025-10-12 05:34:33,625 - INFO - _models.training_function_executor - Epoch 020/49 - train_loss: 0.4910 - val_loss: 0.5542 - val_acc: 0.7938
2025-10-12 05:34:49,403 - INFO - _models.training_function_executor - Epoch 021/49 - train_loss: 0.4874 - val_loss: 0.5449 - val_acc: 0.8015
2025-10-12 05:35:05,222 - INFO - _models.training_function_executor - Epoch 022/49 - train_loss: 0.4848 - val_loss: 0.5642 - val_acc: 0.7914
2025-10-12 05:35:21,060 - INFO - _models.training_function_executor - Epoch 023/49 - train_loss: 0.4745 - val_loss: 0.5906 - val_acc: 0.7875
2025-10-12 05:35:36,891 - INFO - _models.training_function_executor - Epoch 024/49 - train_loss: 0.4707 - val_loss: 0.5924 - val_acc: 0.7941
2025-10-12 05:35:52,715 - INFO - _models.training_function_executor - Epoch 025/49 - train_loss: 0.4694 - val_loss: 0.6367 - val_acc: 0.7745
2025-10-12 05:36:08,534 - INFO - _models.training_function_executor - Epoch 026/49 - train_loss: 0.4656 - val_loss: 0.5742 - val_acc: 0.7937
2025-10-12 05:36:24,367 - INFO - _models.training_function_executor - Epoch 027/49 - train_loss: 0.4607 - val_loss: 0.5653 - val_acc: 0.7994
2025-10-12 05:36:40,200 - INFO - _models.training_function_executor - Epoch 028/49 - train_loss: 0.4567 - val_loss: 0.6402 - val_acc: 0.7706
2025-10-12 05:36:56,008 - INFO - _models.training_function_executor - Epoch 029/49 - train_loss: 0.4527 - val_loss: 0.5815 - val_acc: 0.7977
2025-10-12 05:37:11,834 - INFO - _models.training_function_executor - Epoch 030/49 - train_loss: 0.4498 - val_loss: 0.6239 - val_acc: 0.7788
2025-10-12 05:37:27,663 - INFO - _models.training_function_executor - Epoch 031/49 - train_loss: 0.4448 - val_loss: 0.5825 - val_acc: 0.7905
2025-10-12 05:37:43,492 - INFO - _models.training_function_executor - Epoch 032/49 - train_loss: 0.4383 - val_loss: 0.6416 - val_acc: 0.7697
2025-10-12 05:37:59,333 - INFO - _models.training_function_executor - Epoch 033/49 - train_loss: 0.4358 - val_loss: 0.6139 - val_acc: 0.7849
2025-10-12 05:38:15,148 - INFO - _models.training_function_executor - Epoch 034/49 - train_loss: 0.4335 - val_loss: 0.6146 - val_acc: 0.7763
2025-10-12 05:38:30,989 - INFO - _models.training_function_executor - Epoch 035/49 - train_loss: 0.4287 - val_loss: 0.5924 - val_acc: 0.7878
2025-10-12 05:38:46,781 - INFO - _models.training_function_executor - Epoch 036/49 - train_loss: 0.4290 - val_loss: 0.5816 - val_acc: 0.7941
2025-10-12 05:39:02,581 - INFO - _models.training_function_executor - Epoch 037/49 - train_loss: 0.4197 - val_loss: 0.5753 - val_acc: 0.7991
2025-10-12 05:39:18,417 - INFO - _models.training_function_executor - Epoch 038/49 - train_loss: 0.4185 - val_loss: 0.7094 - val_acc: 0.7603
2025-10-12 05:39:34,239 - INFO - _models.training_function_executor - Epoch 039/49 - train_loss: 0.4174 - val_loss: 0.5719 - val_acc: 0.8021
2025-10-12 05:39:50,039 - INFO - _models.training_function_executor - Epoch 040/49 - train_loss: 0.4098 - val_loss: 0.6222 - val_acc: 0.7838
2025-10-12 05:40:05,833 - INFO - _models.training_function_executor - Epoch 041/49 - train_loss: 0.4083 - val_loss: 0.6636 - val_acc: 0.7777
2025-10-12 05:40:21,663 - INFO - _models.training_function_executor - Epoch 042/49 - train_loss: 0.4038 - val_loss: 0.6320 - val_acc: 0.7866
2025-10-12 05:40:37,474 - INFO - _models.training_function_executor - Epoch 043/49 - train_loss: 0.4024 - val_loss: 0.5984 - val_acc: 0.8032
2025-10-12 05:40:53,298 - INFO - _models.training_function_executor - Epoch 044/49 - train_loss: 0.3967 - val_loss: 0.6471 - val_acc: 0.7849
2025-10-12 05:41:09,106 - INFO - _models.training_function_executor - Epoch 045/49 - train_loss: 0.3940 - val_loss: 0.5962 - val_acc: 0.7934
2025-10-12 05:41:24,923 - INFO - _models.training_function_executor - Epoch 046/49 - train_loss: 0.3920 - val_loss: 0.7772 - val_acc: 0.7439
2025-10-12 05:41:40,774 - INFO - _models.training_function_executor - Epoch 047/49 - train_loss: 0.3839 - val_loss: 0.6197 - val_acc: 0.7875
2025-10-12 05:41:56,577 - INFO - _models.training_function_executor - Epoch 048/49 - train_loss: 0.3831 - val_loss: 0.6948 - val_acc: 0.7672
2025-10-12 05:42:12,370 - INFO - _models.training_function_executor - Epoch 049/49 - train_loss: 0.3795 - val_loss: 0.6405 - val_acc: 0.7854
2025-10-12 05:42:14,728 - INFO - _models.training_function_executor - Model: 16,156 parameters, 17.4KB storage
2025-10-12 05:42:14,728 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0635876328347653, 0.7617705625214275, 0.686856938985665, 0.646096440464373, 0.623417182932753, 0.6003903373267461, 0.5872919571657342, 0.5741184137065302, 0.5603777038120581, 0.5532861244002547, 0.547102595568955, 0.5404684286164286, 0.52956378175155, 0.5224932564783021, 0.5180093956303463, 0.5114439611131176, 0.5059155944290176, 0.5004476883354453, 0.4979092340041467, 0.4910059631089877, 0.48739770818130096, 0.4847568367348086, 0.4745067846698906, 0.47067672085430307, 0.46938833434983573, 0.46563902141583063, 0.4606621954687876, 0.456697909701922, 0.45272679998818754, 0.4497850078399631, 0.44484364056727, 0.43826560600470693, 0.43584891714580754, 0.4335301964197244, 0.4286757835953395, 0.428959107900734, 0.41966529693330634, 0.4185295312381475, 0.4173630555171753, 0.40979738759074463, 0.4083023206348765, 0.40377605912993747, 0.40244829748836397, 0.3966855589987558, 0.39397122625927844, 0.39197192872174563, 0.38385039889232486, 0.38306873251831025, 0.379493453852522], 'val_losses': [0.8974023054728443, 0.808604937773048, 0.6543140628661649, 0.6689853957734577, 0.6137023221624452, 0.5820226208976736, 0.862016446698075, 0.597975873137672, 0.6866740721754149, 0.5654203338580487, 0.6927229350769816, 0.5728630142577845, 0.5744774965637832, 0.6180277718169146, 0.5564349393223732, 0.5872586204125658, 0.5801959922514389, 0.5984906209023173, 0.6770088189354216, 0.5541684070134605, 0.5449134623739408, 0.5642490077074024, 0.5905827189012345, 0.592362891020769, 0.6367175212513954, 0.5741740325645087, 0.5653474915760941, 0.6402204137270711, 0.581518351181554, 0.6238945416211664, 0.5825127218470191, 0.6415950191742814, 0.6139356922416951, 0.6145734382512313, 0.5923727412437867, 0.5815855943326312, 0.5752963276490658, 0.7093725656770433, 0.571905983539574, 0.6221510651653406, 0.6636303417804486, 0.6319734296902603, 0.5984138472642688, 0.6471351432996402, 0.5962434787933001, 0.7772440184944361, 0.6196654015773236, 0.6947793940856067, 0.6404842301019222], 'val_acc': [0.6503325166258312, 0.7073853692684634, 0.7472873643682184, 0.7448372418620931, 0.7672383619180959, 0.7827266363318166, 0.6979348967448372, 0.7811515575778789, 0.7394994749737487, 0.7923521176058803, 0.7370493524676234, 0.7897269863493175, 0.7950647532376619, 0.7709135456772839, 0.7992649632481624, 0.7875393769688485, 0.783689184459223, 0.7897269863493175, 0.750350017500875, 0.7937521876093805, 0.8014525726286315, 0.7913895694784739, 0.7874518725936297, 0.7941022051102555, 0.7745012250612531, 0.7936646832341617, 0.7993524676233812, 0.7705635281764088, 0.7976898844942247, 0.7787889394469724, 0.7905145257262863, 0.7696884844242212, 0.7849142457122856, 0.7762513125656283, 0.7878018900945047, 0.7941022051102555, 0.7990899544977249, 0.7603255162758138, 0.8020651032551628, 0.7837766888344417, 0.7777388869443472, 0.7865768288414421, 0.8032026601330067, 0.7849142457122856, 0.7934021701085054, 0.7438746937346867, 0.7875393769688485, 0.7672383619180959, 0.7853517675883794], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00036789517124077175, 'batch_size': 16, 'epochs': 49, 'weight_decay': 1.3601526499853536e-06, 'dropout': 0.0035331523233703152, 'base_channels': 20, 'temporal_kernel': 5, 'spatial_segments': 40, 'label_smoothing': 0.00551273456844752, 'grad_clip': 0.6126380958047585, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2157}, 'model_parameter_count': 16156, 'model_storage_size_kb': 17.355078125000002, 'model_size_validation': 'PASS'}
2025-10-12 05:42:14,728 - INFO - _models.training_function_executor - BO Objective: base=0.7854, size_penalty=0.0000, final=0.7854
2025-10-12 05:42:14,728 - INFO - _models.training_function_executor - Model: 16,156 parameters, 17.4KB (PASS 256KB limit)
2025-10-12 05:42:14,728 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 777.791s
2025-10-12 05:42:14,835 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7854
2025-10-12 05:42:14,835 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-12 05:42:14,835 - INFO - bo.run_bo - Recorded observation #24: hparams={'lr': 0.00036789517124077175, 'batch_size': np.int64(16), 'epochs': np.int64(49), 'weight_decay': 1.3601526499853536e-06, 'dropout': 0.0035331523233703152, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(40), 'label_smoothing': 0.00551273456844752, 'grad_clip': 0.6126380958047585, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2157)}, value=0.7854
2025-10-12 05:42:14,835 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 24: {'lr': 0.00036789517124077175, 'batch_size': np.int64(16), 'epochs': np.int64(49), 'weight_decay': 1.3601526499853536e-06, 'dropout': 0.0035331523233703152, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(40), 'label_smoothing': 0.00551273456844752, 'grad_clip': 0.6126380958047585, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2157)} -> 0.7854
2025-10-12 05:42:14,835 - INFO - bo.run_bo - üîçBO Trial 25: Using RF surrogate + Expected Improvement
2025-10-12 05:42:14,835 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 05:42:14,835 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 05:42:14,835 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 05:42:14,835 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0003681114241260694, 'batch_size': 16, 'epochs': 48, 'weight_decay': 1.2319767806564593e-06, 'dropout': 0.01918220705080637, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 500, 'label_smoothing': 0.017526695257107087, 'grad_clip': 0.49871281252176014, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2471}
2025-10-12 05:42:14,836 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0003681114241260694, 'batch_size': 16, 'epochs': 48, 'weight_decay': 1.2319767806564593e-06, 'dropout': 0.01918220705080637, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 500, 'label_smoothing': 0.017526695257107087, 'grad_clip': 0.49871281252176014, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2471}
2025-10-12 05:42:29,518 - INFO - _models.training_function_executor - Epoch 001/48 - train_loss: 1.1208 - val_loss: 1.1013 - val_acc: 0.5971
2025-10-12 05:42:44,242 - INFO - _models.training_function_executor - Epoch 002/48 - train_loss: 0.8369 - val_loss: 1.0077 - val_acc: 0.5944
2025-10-12 05:42:58,940 - INFO - _models.training_function_executor - Epoch 003/48 - train_loss: 0.7563 - val_loss: 0.7350 - val_acc: 0.7418
2025-10-12 05:43:13,622 - INFO - _models.training_function_executor - Epoch 004/48 - train_loss: 0.7089 - val_loss: 0.8141 - val_acc: 0.7101
2025-10-12 05:43:28,333 - INFO - _models.training_function_executor - Epoch 005/48 - train_loss: 0.6802 - val_loss: 0.7161 - val_acc: 0.7528
2025-10-12 05:43:43,038 - INFO - _models.training_function_executor - Epoch 006/48 - train_loss: 0.6570 - val_loss: 0.7222 - val_acc: 0.7556
2025-10-12 05:43:57,745 - INFO - _models.training_function_executor - Epoch 007/48 - train_loss: 0.6375 - val_loss: 0.7440 - val_acc: 0.7331
2025-10-12 05:44:12,429 - INFO - _models.training_function_executor - Epoch 008/48 - train_loss: 0.6205 - val_loss: 0.8102 - val_acc: 0.7132
2025-10-12 05:44:27,152 - INFO - _models.training_function_executor - Epoch 009/48 - train_loss: 0.6026 - val_loss: 0.6811 - val_acc: 0.7658
2025-10-12 05:44:41,880 - INFO - _models.training_function_executor - Epoch 010/48 - train_loss: 0.5845 - val_loss: 0.7115 - val_acc: 0.7710
2025-10-12 05:44:56,540 - INFO - _models.training_function_executor - Epoch 011/48 - train_loss: 0.5745 - val_loss: 0.7804 - val_acc: 0.7307
2025-10-12 05:45:11,233 - INFO - _models.training_function_executor - Epoch 012/48 - train_loss: 0.5548 - val_loss: 0.6800 - val_acc: 0.7778
2025-10-12 05:45:25,926 - INFO - _models.training_function_executor - Epoch 013/48 - train_loss: 0.5406 - val_loss: 0.7644 - val_acc: 0.7539
2025-10-12 05:45:40,650 - INFO - _models.training_function_executor - Epoch 014/48 - train_loss: 0.5313 - val_loss: 0.8044 - val_acc: 0.7258
2025-10-12 05:45:55,381 - INFO - _models.training_function_executor - Epoch 015/48 - train_loss: 0.5193 - val_loss: 0.9345 - val_acc: 0.6915
2025-10-12 05:46:10,012 - INFO - _models.training_function_executor - Epoch 016/48 - train_loss: 0.5057 - val_loss: 0.7714 - val_acc: 0.7472
2025-10-12 05:46:24,760 - INFO - _models.training_function_executor - Epoch 017/48 - train_loss: 0.4968 - val_loss: 0.7666 - val_acc: 0.7617
2025-10-12 05:46:39,443 - INFO - _models.training_function_executor - Epoch 018/48 - train_loss: 0.4868 - val_loss: 0.7477 - val_acc: 0.7703
2025-10-12 05:46:54,155 - INFO - _models.training_function_executor - Epoch 019/48 - train_loss: 0.4754 - val_loss: 0.7832 - val_acc: 0.7568
2025-10-12 05:47:08,883 - INFO - _models.training_function_executor - Epoch 020/48 - train_loss: 0.4677 - val_loss: 0.7823 - val_acc: 0.7684
2025-10-12 05:47:23,536 - INFO - _models.training_function_executor - Epoch 021/48 - train_loss: 0.4630 - val_loss: 0.8786 - val_acc: 0.7303
2025-10-12 05:47:38,244 - INFO - _models.training_function_executor - Epoch 022/48 - train_loss: 0.4553 - val_loss: 0.9391 - val_acc: 0.7148
2025-10-12 05:47:52,944 - INFO - _models.training_function_executor - Epoch 023/48 - train_loss: 0.4418 - val_loss: 0.9116 - val_acc: 0.7372
2025-10-12 05:48:07,672 - INFO - _models.training_function_executor - Epoch 024/48 - train_loss: 0.4324 - val_loss: 0.9968 - val_acc: 0.7038
2025-10-12 05:48:22,359 - INFO - _models.training_function_executor - Epoch 025/48 - train_loss: 0.4300 - val_loss: 0.8745 - val_acc: 0.7544
2025-10-12 05:48:37,058 - INFO - _models.training_function_executor - Epoch 026/48 - train_loss: 0.4244 - val_loss: 1.1924 - val_acc: 0.6498
2025-10-12 05:48:51,765 - INFO - _models.training_function_executor - Epoch 027/48 - train_loss: 0.4178 - val_loss: 1.5101 - val_acc: 0.5767
2025-10-12 05:49:06,496 - INFO - _models.training_function_executor - Epoch 028/48 - train_loss: 0.4114 - val_loss: 0.9703 - val_acc: 0.7153
2025-10-12 05:49:21,183 - INFO - _models.training_function_executor - Epoch 029/48 - train_loss: 0.4063 - val_loss: 0.8531 - val_acc: 0.7657
2025-10-12 05:49:35,901 - INFO - _models.training_function_executor - Epoch 030/48 - train_loss: 0.3994 - val_loss: 1.0451 - val_acc: 0.6908
2025-10-12 05:49:50,607 - INFO - _models.training_function_executor - Epoch 031/48 - train_loss: 0.3937 - val_loss: 0.9399 - val_acc: 0.7337
2025-10-12 05:50:05,291 - INFO - _models.training_function_executor - Epoch 032/48 - train_loss: 0.3891 - val_loss: 0.9430 - val_acc: 0.7546
2025-10-12 05:50:20,036 - INFO - _models.training_function_executor - Epoch 033/48 - train_loss: 0.3844 - val_loss: 1.1371 - val_acc: 0.6787
2025-10-12 05:50:34,736 - INFO - _models.training_function_executor - Epoch 034/48 - train_loss: 0.3800 - val_loss: 0.9502 - val_acc: 0.7649
2025-10-12 05:50:49,439 - INFO - _models.training_function_executor - Epoch 035/48 - train_loss: 0.3712 - val_loss: 0.9612 - val_acc: 0.7544
2025-10-12 05:51:04,145 - INFO - _models.training_function_executor - Epoch 036/48 - train_loss: 0.3704 - val_loss: 1.0115 - val_acc: 0.7321
2025-10-12 05:51:18,851 - INFO - _models.training_function_executor - Epoch 037/48 - train_loss: 0.3698 - val_loss: 0.9322 - val_acc: 0.7602
2025-10-12 05:51:33,550 - INFO - _models.training_function_executor - Epoch 038/48 - train_loss: 0.3619 - val_loss: 0.9531 - val_acc: 0.7486
2025-10-12 05:51:48,244 - INFO - _models.training_function_executor - Epoch 039/48 - train_loss: 0.3591 - val_loss: 1.0192 - val_acc: 0.7372
2025-10-12 05:52:02,931 - INFO - _models.training_function_executor - Epoch 040/48 - train_loss: 0.3533 - val_loss: 1.0341 - val_acc: 0.7459
2025-10-12 05:52:17,649 - INFO - _models.training_function_executor - Epoch 041/48 - train_loss: 0.3547 - val_loss: 0.9683 - val_acc: 0.7514
2025-10-12 05:52:32,327 - INFO - _models.training_function_executor - Epoch 042/48 - train_loss: 0.3474 - val_loss: 1.0006 - val_acc: 0.7510
2025-10-12 05:52:47,039 - INFO - _models.training_function_executor - Epoch 043/48 - train_loss: 0.3429 - val_loss: 1.1117 - val_acc: 0.7269
2025-10-12 05:53:01,762 - INFO - _models.training_function_executor - Epoch 044/48 - train_loss: 0.3456 - val_loss: 1.0292 - val_acc: 0.7390
2025-10-12 05:53:16,452 - INFO - _models.training_function_executor - Epoch 045/48 - train_loss: 0.3414 - val_loss: 1.2559 - val_acc: 0.6761
2025-10-12 05:53:31,114 - INFO - _models.training_function_executor - Epoch 046/48 - train_loss: 0.3348 - val_loss: 1.1011 - val_acc: 0.7236
2025-10-12 05:53:45,805 - INFO - _models.training_function_executor - Epoch 047/48 - train_loss: 0.3321 - val_loss: 1.0847 - val_acc: 0.7509
2025-10-12 05:54:00,533 - INFO - _models.training_function_executor - Epoch 048/48 - train_loss: 0.3330 - val_loss: 1.0559 - val_acc: 0.7537
2025-10-12 05:54:02,186 - INFO - _models.training_function_executor - Model: 11,698 parameters, 12.6KB storage
2025-10-12 05:54:02,186 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.120837185228042, 0.8369089252451395, 0.7562763580272028, 0.7088609370143838, 0.6802410893311732, 0.6569891145982899, 0.6375078915047571, 0.6204603510613119, 0.6026033927791804, 0.5844772714843773, 0.5745233857562837, 0.554764471976833, 0.5405592845272342, 0.5313378870330743, 0.5192560605342296, 0.50570626624677, 0.4967909527849308, 0.48677578747355943, 0.47535728671290384, 0.4677262372452352, 0.4629655399124732, 0.45526134826459375, 0.4417693948032224, 0.432446984194107, 0.43004121783420596, 0.4243918069966573, 0.4177963044422675, 0.411432075529696, 0.40625119159740714, 0.3993949664924209, 0.3936988406240585, 0.38909112854274286, 0.38437033101712903, 0.3799975470756792, 0.3712006270426489, 0.3704313912256473, 0.3698295710812426, 0.36188954944205026, 0.3590833332975052, 0.3532900045207634, 0.35471958971634837, 0.34743317582513805, 0.3429481575841206, 0.34558585403492953, 0.3413503791251548, 0.3348402663267364, 0.3320569324642576, 0.3330083140724599], 'val_losses': [1.1012793632917235, 1.007651559114039, 0.7350496288400703, 0.814095867787953, 0.7160644765224831, 0.7221957224521931, 0.7439945513942586, 0.8102076732073374, 0.6810660102294799, 0.7114661653474948, 0.7803540381990532, 0.6800428533787739, 0.7644083542468292, 0.8044264924184067, 0.934451553864958, 0.771360664443616, 0.7665673529805527, 0.7476898504797295, 0.7832357318283671, 0.7822748991547659, 0.8785548605491617, 0.9391429895782204, 0.9116322194566082, 0.9967542615727941, 0.8745144213418423, 1.1923533389315473, 1.5101004317794016, 0.9702986082623462, 0.8531065813761555, 1.045077822948612, 0.9399325736427707, 0.94295544239621, 1.1371137681523111, 0.9501944401900919, 0.9612496770425488, 1.0114603262703694, 0.93216573682998, 0.9530571371389929, 1.0191884787090182, 1.0341416697298516, 0.9683203163537522, 1.0006013843493315, 1.1116738570374878, 1.0292158391369695, 1.2558741290793787, 1.1011319213452604, 1.0847347082063623, 1.055861865405983], 'val_acc': [0.5971298564928247, 0.5944172208610431, 0.7417745887294365, 0.710098004900245, 0.7528001400070004, 0.7556002800140007, 0.7331116555827791, 0.7132481624081204, 0.7658382919145957, 0.7710010500525026, 0.7306615330766538, 0.777826391319566, 0.7539376968848442, 0.725848792439622, 0.6915470773538677, 0.7471998599929996, 0.761725586279314, 0.7703010150507525, 0.7568253412670634, 0.7683759187959398, 0.7303115155757788, 0.7148232411620581, 0.7372243612180609, 0.7037976898844942, 0.754375218760938, 0.6498074903745187, 0.5767413370668534, 0.7152607630381519, 0.7656632831641582, 0.6908470423521176, 0.7337241862093105, 0.7545502275113756, 0.6786839341967098, 0.7648757437871894, 0.754375218760938, 0.7321491074553728, 0.7601505075253763, 0.7485999299964998, 0.7372243612180609, 0.7458872943647182, 0.7514000700035002, 0.7509625481274064, 0.7268988449422471, 0.7389744487224361, 0.6761463073153657, 0.7235736786839342, 0.7508750437521876, 0.753675183759188], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0003681114241260694, 'batch_size': 16, 'epochs': 48, 'weight_decay': 1.2319767806564593e-06, 'dropout': 0.01918220705080637, 'base_channels': 17, 'temporal_kernel': 3, 'spatial_segments': 500, 'label_smoothing': 0.017526695257107087, 'grad_clip': 0.49871281252176014, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2471}, 'model_parameter_count': 11698, 'model_storage_size_kb': 12.566210937500001, 'model_size_validation': 'PASS'}
2025-10-12 05:54:02,186 - INFO - _models.training_function_executor - BO Objective: base=0.7537, size_penalty=0.0000, final=0.7537
2025-10-12 05:54:02,186 - INFO - _models.training_function_executor - Model: 11,698 parameters, 12.6KB (PASS 256KB limit)
2025-10-12 05:54:02,186 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 707.351s
2025-10-12 05:54:02,292 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7537
2025-10-12 05:54:02,292 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-12 05:54:02,292 - INFO - bo.run_bo - Recorded observation #25: hparams={'lr': 0.0003681114241260694, 'batch_size': np.int64(16), 'epochs': np.int64(48), 'weight_decay': 1.2319767806564593e-06, 'dropout': 0.01918220705080637, 'base_channels': np.int64(17), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(500), 'label_smoothing': 0.017526695257107087, 'grad_clip': 0.49871281252176014, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2471)}, value=0.7537
2025-10-12 05:54:02,292 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 25: {'lr': 0.0003681114241260694, 'batch_size': np.int64(16), 'epochs': np.int64(48), 'weight_decay': 1.2319767806564593e-06, 'dropout': 0.01918220705080637, 'base_channels': np.int64(17), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(500), 'label_smoothing': 0.017526695257107087, 'grad_clip': 0.49871281252176014, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2471)} -> 0.7537
2025-10-12 05:54:02,292 - INFO - bo.run_bo - üîçBO Trial 26: Using RF surrogate + Expected Improvement
2025-10-12 05:54:02,292 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 05:54:02,292 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 05:54:02,292 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 05:54:02,292 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.22999553276355e-06, 'batch_size': 64, 'epochs': 44, 'weight_decay': 1.6029477156416547e-06, 'dropout': 0.05765935845331584, 'base_channels': 22, 'temporal_kernel': 9, 'spatial_segments': 750, 'label_smoothing': 0.10756104790721326, 'grad_clip': 0.1398666038167974, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6460}
2025-10-12 05:54:02,293 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.22999553276355e-06, 'batch_size': 64, 'epochs': 44, 'weight_decay': 1.6029477156416547e-06, 'dropout': 0.05765935845331584, 'base_channels': 22, 'temporal_kernel': 9, 'spatial_segments': 750, 'label_smoothing': 0.10756104790721326, 'grad_clip': 0.1398666038167974, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6460}
2025-10-12 05:54:18,520 - INFO - _models.training_function_executor - Epoch 001/44 - train_loss: 1.8690 - val_loss: 1.7987 - val_acc: 0.2326
2025-10-12 05:54:33,949 - INFO - _models.training_function_executor - Epoch 002/44 - train_loss: 1.7719 - val_loss: 1.7382 - val_acc: 0.2433
2025-10-12 05:54:49,353 - INFO - _models.training_function_executor - Epoch 003/44 - train_loss: 1.7127 - val_loss: 1.6960 - val_acc: 0.2542
2025-10-12 05:55:04,793 - INFO - _models.training_function_executor - Epoch 004/44 - train_loss: 1.6763 - val_loss: 1.6672 - val_acc: 0.2660
2025-10-12 05:55:20,329 - INFO - _models.training_function_executor - Epoch 005/44 - train_loss: 1.6466 - val_loss: 1.6462 - val_acc: 0.2736
2025-10-12 05:55:35,848 - INFO - _models.training_function_executor - Epoch 006/44 - train_loss: 1.6239 - val_loss: 1.6326 - val_acc: 0.2784
2025-10-12 05:55:51,309 - INFO - _models.training_function_executor - Epoch 007/44 - train_loss: 1.6044 - val_loss: 1.6143 - val_acc: 0.2907
2025-10-12 05:56:06,752 - INFO - _models.training_function_executor - Epoch 008/44 - train_loss: 1.5877 - val_loss: 1.6063 - val_acc: 0.2958
2025-10-12 05:56:22,189 - INFO - _models.training_function_executor - Epoch 009/44 - train_loss: 1.5755 - val_loss: 1.5894 - val_acc: 0.3088
2025-10-12 05:56:37,649 - INFO - _models.training_function_executor - Epoch 010/44 - train_loss: 1.5598 - val_loss: 1.6016 - val_acc: 0.2973
2025-10-12 05:56:53,087 - INFO - _models.training_function_executor - Epoch 011/44 - train_loss: 1.5483 - val_loss: 1.5789 - val_acc: 0.3162
2025-10-12 05:57:08,510 - INFO - _models.training_function_executor - Epoch 012/44 - train_loss: 1.5356 - val_loss: 1.5607 - val_acc: 0.3322
2025-10-12 05:57:23,925 - INFO - _models.training_function_executor - Epoch 013/44 - train_loss: 1.5252 - val_loss: 1.5650 - val_acc: 0.3271
2025-10-12 05:57:39,390 - INFO - _models.training_function_executor - Epoch 014/44 - train_loss: 1.5138 - val_loss: 1.5618 - val_acc: 0.3309
2025-10-12 05:57:54,827 - INFO - _models.training_function_executor - Epoch 015/44 - train_loss: 1.5042 - val_loss: 1.5321 - val_acc: 0.3617
2025-10-12 05:58:10,282 - INFO - _models.training_function_executor - Epoch 016/44 - train_loss: 1.4946 - val_loss: 1.5377 - val_acc: 0.3536
2025-10-12 05:58:25,727 - INFO - _models.training_function_executor - Epoch 017/44 - train_loss: 1.4859 - val_loss: 1.5224 - val_acc: 0.3682
2025-10-12 05:58:41,156 - INFO - _models.training_function_executor - Epoch 018/44 - train_loss: 1.4776 - val_loss: 1.5136 - val_acc: 0.3766
2025-10-12 05:58:56,604 - INFO - _models.training_function_executor - Epoch 019/44 - train_loss: 1.4696 - val_loss: 1.5171 - val_acc: 0.3707
2025-10-12 05:59:12,079 - INFO - _models.training_function_executor - Epoch 020/44 - train_loss: 1.4626 - val_loss: 1.5143 - val_acc: 0.3731
2025-10-12 05:59:27,495 - INFO - _models.training_function_executor - Epoch 021/44 - train_loss: 1.4548 - val_loss: 1.4952 - val_acc: 0.3960
2025-10-12 05:59:42,927 - INFO - _models.training_function_executor - Epoch 022/44 - train_loss: 1.4465 - val_loss: 1.4970 - val_acc: 0.3890
2025-10-12 05:59:58,340 - INFO - _models.training_function_executor - Epoch 023/44 - train_loss: 1.4399 - val_loss: 1.4860 - val_acc: 0.4040
2025-10-12 06:00:13,715 - INFO - _models.training_function_executor - Epoch 024/44 - train_loss: 1.4350 - val_loss: 1.4906 - val_acc: 0.3927
2025-10-12 06:00:29,146 - INFO - _models.training_function_executor - Epoch 025/44 - train_loss: 1.4259 - val_loss: 1.4657 - val_acc: 0.4295
2025-10-12 06:00:44,598 - INFO - _models.training_function_executor - Epoch 026/44 - train_loss: 1.4196 - val_loss: 1.4861 - val_acc: 0.3975
2025-10-12 06:01:00,007 - INFO - _models.training_function_executor - Epoch 027/44 - train_loss: 1.4135 - val_loss: 1.4559 - val_acc: 0.4313
2025-10-12 06:01:15,408 - INFO - _models.training_function_executor - Epoch 028/44 - train_loss: 1.4066 - val_loss: 1.4632 - val_acc: 0.4196
2025-10-12 06:01:30,849 - INFO - _models.training_function_executor - Epoch 029/44 - train_loss: 1.3990 - val_loss: 1.4358 - val_acc: 0.4510
2025-10-12 06:01:46,287 - INFO - _models.training_function_executor - Epoch 030/44 - train_loss: 1.3946 - val_loss: 1.4450 - val_acc: 0.4335
2025-10-12 06:02:01,723 - INFO - _models.training_function_executor - Epoch 031/44 - train_loss: 1.3866 - val_loss: 1.4569 - val_acc: 0.4182
2025-10-12 06:02:17,138 - INFO - _models.training_function_executor - Epoch 032/44 - train_loss: 1.3797 - val_loss: 1.4409 - val_acc: 0.4336
2025-10-12 06:02:32,534 - INFO - _models.training_function_executor - Epoch 033/44 - train_loss: 1.3741 - val_loss: 1.4364 - val_acc: 0.4400
2025-10-12 06:02:47,980 - INFO - _models.training_function_executor - Epoch 034/44 - train_loss: 1.3669 - val_loss: 1.4290 - val_acc: 0.4380
2025-10-12 06:03:03,398 - INFO - _models.training_function_executor - Epoch 035/44 - train_loss: 1.3607 - val_loss: 1.4409 - val_acc: 0.4268
2025-10-12 06:03:18,832 - INFO - _models.training_function_executor - Epoch 036/44 - train_loss: 1.3563 - val_loss: 1.4094 - val_acc: 0.4551
2025-10-12 06:03:34,255 - INFO - _models.training_function_executor - Epoch 037/44 - train_loss: 1.3499 - val_loss: 1.4127 - val_acc: 0.4514
2025-10-12 06:03:49,713 - INFO - _models.training_function_executor - Epoch 038/44 - train_loss: 1.3426 - val_loss: 1.4132 - val_acc: 0.4494
2025-10-12 06:04:05,148 - INFO - _models.training_function_executor - Epoch 039/44 - train_loss: 1.3361 - val_loss: 1.4400 - val_acc: 0.4306
2025-10-12 06:04:20,590 - INFO - _models.training_function_executor - Epoch 040/44 - train_loss: 1.3306 - val_loss: 1.4095 - val_acc: 0.4471
2025-10-12 06:04:36,052 - INFO - _models.training_function_executor - Epoch 041/44 - train_loss: 1.3267 - val_loss: 1.3789 - val_acc: 0.4867
2025-10-12 06:04:51,475 - INFO - _models.training_function_executor - Epoch 042/44 - train_loss: 1.3193 - val_loss: 1.3928 - val_acc: 0.4712
2025-10-12 06:05:06,909 - INFO - _models.training_function_executor - Epoch 043/44 - train_loss: 1.3141 - val_loss: 1.3612 - val_acc: 0.4968
2025-10-12 06:05:22,384 - INFO - _models.training_function_executor - Epoch 044/44 - train_loss: 1.3084 - val_loss: 1.3841 - val_acc: 0.4758
2025-10-12 06:05:22,387 - INFO - _models.training_function_executor - Model: 141,373 parameters, 303.7KB storage
2025-10-12 06:05:22,387 - WARNING - _models.training_function_executor - Model storage 303.7KB exceeds 256KB limit!
2025-10-12 06:05:22,387 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.8689700811110388, 1.7719062898056384, 1.7127055300671528, 1.676312825001325, 1.6466201140323968, 1.623872974639094, 1.6044466161711215, 1.587708168026447, 1.5754952230026225, 1.5597659780464266, 1.5483410053416737, 1.5355753810997397, 1.5252271709969547, 1.5137826630732878, 1.5041956914485148, 1.494553076582519, 1.4858867300946186, 1.4775689737255189, 1.4695605179376439, 1.4626262994091286, 1.454837030741899, 1.4465163231813953, 1.4398897630499925, 1.43504244913202, 1.4258733188350758, 1.4195723821952455, 1.4134664860145587, 1.4065741421169111, 1.3989830212781678, 1.394646824136413, 1.3866272719539794, 1.379707179663688, 1.374052986257511, 1.3668951223394776, 1.360717736468851, 1.3562611472911255, 1.3498780007207147, 1.3426197589925006, 1.3360870813714236, 1.3305778776301678, 1.326663008468903, 1.319270658000683, 1.3141187040965208, 1.3083927663923938], 'val_losses': [1.798687290678001, 1.7382356336912075, 1.6960291948024735, 1.6671705529703975, 1.6462218926676428, 1.6325518497437665, 1.6142744974193766, 1.6062563780850365, 1.5894053938257806, 1.601645806180375, 1.5788618198090347, 1.5607058063519765, 1.5650009487657477, 1.5618386153871044, 1.5320537426607734, 1.5376542002160858, 1.5224265963371124, 1.513637143246227, 1.5171232165512523, 1.5143355848407845, 1.4952132797842055, 1.4969925436474536, 1.4859574087274463, 1.4905535893128141, 1.465719314484401, 1.486062630515521, 1.45590605204198, 1.463230295117852, 1.4358023912872433, 1.4450071060786849, 1.4568631703260273, 1.4408793672632412, 1.436423493341253, 1.4290376401757043, 1.4408608962490628, 1.4093847770477284, 1.4126694887970392, 1.4132256016766311, 1.4399695258312473, 1.4094802345643729, 1.3788845214887144, 1.392753285213413, 1.3611696190378404, 1.3841470551315538], 'val_acc': [0.23258662933146657, 0.24334966748337417, 0.2542002100105005, 0.26601330066503326, 0.27362618130906546, 0.27835141757087856, 0.29068953447672385, 0.295764788239412, 0.3088029401470074, 0.2972523626181309, 0.316240812040602, 0.3321666083304165, 0.32709135456772837, 0.3308540427021351, 0.36165558277913895, 0.35360518025901294, 0.368218410920546, 0.3766188309415471, 0.37066853342667133, 0.37311865593279664, 0.39595729786489325, 0.3889569478473924, 0.40400770038501926, 0.3927196359817991, 0.4294714735736787, 0.39753237661883095, 0.4313090654532727, 0.4195834791739587, 0.45099754987749385, 0.4334966748337417, 0.41818340917045854, 0.4335841792089605, 0.43997199859992997, 0.43804690234511723, 0.4267588379418971, 0.4551102555127756, 0.45143507175358766, 0.44942247112355616, 0.4306090304515226, 0.4470598529926496, 0.48669933496674833, 0.47121106055302764, 0.4968498424921246, 0.4757612880644032], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.22999553276355e-06, 'batch_size': 64, 'epochs': 44, 'weight_decay': 1.6029477156416547e-06, 'dropout': 0.05765935845331584, 'base_channels': 22, 'temporal_kernel': 9, 'spatial_segments': 750, 'label_smoothing': 0.10756104790721326, 'grad_clip': 0.1398666038167974, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6460}, 'model_parameter_count': 141373, 'model_storage_size_kb': 303.73105468750003, 'model_size_validation': 'FAIL'}
2025-10-12 06:05:22,387 - INFO - _models.training_function_executor - BO Objective: base=0.4758, size_penalty=0.0932, final=0.3825
2025-10-12 06:05:22,387 - INFO - _models.training_function_executor - Model: 141,373 parameters, 303.7KB (FAIL 256KB limit)
2025-10-12 06:05:22,387 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 680.095s
2025-10-12 06:05:22,503 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.3825
2025-10-12 06:05:22,503 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-12 06:05:22,503 - INFO - bo.run_bo - Recorded observation #26: hparams={'lr': 2.22999553276355e-06, 'batch_size': np.int64(64), 'epochs': np.int64(44), 'weight_decay': 1.6029477156416547e-06, 'dropout': 0.05765935845331584, 'base_channels': np.int64(22), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(750), 'label_smoothing': 0.10756104790721326, 'grad_clip': 0.1398666038167974, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(6460)}, value=0.3825
2025-10-12 06:05:22,503 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 26: {'lr': 2.22999553276355e-06, 'batch_size': np.int64(64), 'epochs': np.int64(44), 'weight_decay': 1.6029477156416547e-06, 'dropout': 0.05765935845331584, 'base_channels': np.int64(22), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(750), 'label_smoothing': 0.10756104790721326, 'grad_clip': 0.1398666038167974, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(6460)} -> 0.3825
2025-10-12 06:05:22,504 - INFO - bo.run_bo - üîçBO Trial 27: Using RF surrogate + Expected Improvement
2025-10-12 06:05:22,504 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 06:05:22,504 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 06:05:22,504 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 06:05:22,504 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009063530148893219, 'batch_size': 48, 'epochs': 43, 'weight_decay': 2.132895201152522e-06, 'dropout': 0.08018032673163857, 'base_channels': 20, 'temporal_kernel': 5, 'spatial_segments': 1000, 'label_smoothing': 0.19454642315341003, 'grad_clip': 0.609334513474725, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 2845}
2025-10-12 06:05:22,505 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009063530148893219, 'batch_size': 48, 'epochs': 43, 'weight_decay': 2.132895201152522e-06, 'dropout': 0.08018032673163857, 'base_channels': 20, 'temporal_kernel': 5, 'spatial_segments': 1000, 'label_smoothing': 0.19454642315341003, 'grad_clip': 0.609334513474725, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 2845}
2025-10-12 06:05:37,520 - INFO - _models.training_function_executor - Epoch 001/43 - train_loss: 1.6246 - val_loss: 1.2358 - val_acc: 0.6281
2025-10-12 06:05:52,188 - INFO - _models.training_function_executor - Epoch 002/43 - train_loss: 1.2958 - val_loss: 1.2087 - val_acc: 0.6739
2025-10-12 06:06:06,874 - INFO - _models.training_function_executor - Epoch 003/43 - train_loss: 1.2383 - val_loss: 1.1642 - val_acc: 0.6868
2025-10-12 06:06:21,553 - INFO - _models.training_function_executor - Epoch 004/43 - train_loss: 1.2233 - val_loss: 1.1687 - val_acc: 0.6966
2025-10-12 06:06:36,178 - INFO - _models.training_function_executor - Epoch 005/43 - train_loss: 1.2075 - val_loss: 1.1884 - val_acc: 0.6954
2025-10-12 06:06:50,880 - INFO - _models.training_function_executor - Epoch 006/43 - train_loss: 1.1945 - val_loss: 1.1343 - val_acc: 0.7288
2025-10-12 06:07:05,616 - INFO - _models.training_function_executor - Epoch 007/43 - train_loss: 1.1856 - val_loss: 1.2406 - val_acc: 0.6977
2025-10-12 06:07:20,280 - INFO - _models.training_function_executor - Epoch 008/43 - train_loss: 1.1749 - val_loss: 1.1412 - val_acc: 0.7098
2025-10-12 06:07:34,971 - INFO - _models.training_function_executor - Epoch 009/43 - train_loss: 1.1790 - val_loss: 1.1691 - val_acc: 0.7097
2025-10-12 06:07:49,636 - INFO - _models.training_function_executor - Epoch 010/43 - train_loss: 1.1660 - val_loss: 1.2014 - val_acc: 0.7259
2025-10-12 06:08:04,304 - INFO - _models.training_function_executor - Epoch 011/43 - train_loss: 1.1732 - val_loss: 1.2200 - val_acc: 0.7207
2025-10-12 06:08:18,993 - INFO - _models.training_function_executor - Epoch 012/43 - train_loss: 1.1496 - val_loss: 1.1717 - val_acc: 0.7276
2025-10-12 06:08:33,679 - INFO - _models.training_function_executor - Epoch 013/43 - train_loss: 1.1660 - val_loss: 1.1744 - val_acc: 0.6995
2025-10-12 06:08:48,335 - INFO - _models.training_function_executor - Epoch 014/43 - train_loss: 1.1429 - val_loss: 1.0830 - val_acc: 0.7580
2025-10-12 06:09:03,015 - INFO - _models.training_function_executor - Epoch 015/43 - train_loss: 1.1780 - val_loss: 1.1218 - val_acc: 0.7631
2025-10-12 06:09:17,708 - INFO - _models.training_function_executor - Epoch 016/43 - train_loss: 1.1416 - val_loss: 1.1288 - val_acc: 0.7412
2025-10-12 06:09:32,415 - INFO - _models.training_function_executor - Epoch 017/43 - train_loss: 1.1691 - val_loss: 1.2858 - val_acc: 0.7207
2025-10-12 06:09:47,079 - INFO - _models.training_function_executor - Epoch 018/43 - train_loss: 1.1658 - val_loss: 1.2331 - val_acc: 0.7098
2025-10-12 06:10:01,763 - INFO - _models.training_function_executor - Epoch 019/43 - train_loss: 1.1553 - val_loss: 1.0454 - val_acc: 0.7697
2025-10-12 06:10:16,461 - INFO - _models.training_function_executor - Epoch 020/43 - train_loss: 1.1420 - val_loss: 1.1276 - val_acc: 0.7418
2025-10-12 06:10:31,100 - INFO - _models.training_function_executor - Epoch 021/43 - train_loss: 1.1403 - val_loss: 1.1384 - val_acc: 0.7297
2025-10-12 06:10:45,751 - INFO - _models.training_function_executor - Epoch 022/43 - train_loss: 1.1351 - val_loss: 1.0756 - val_acc: 0.7524
2025-10-12 06:11:00,413 - INFO - _models.training_function_executor - Epoch 023/43 - train_loss: 1.1359 - val_loss: 1.0696 - val_acc: 0.7795
2025-10-12 06:11:15,117 - INFO - _models.training_function_executor - Epoch 024/43 - train_loss: 1.1474 - val_loss: 1.1936 - val_acc: 0.7271
2025-10-12 06:11:29,819 - INFO - _models.training_function_executor - Epoch 025/43 - train_loss: 1.1636 - val_loss: 1.2281 - val_acc: 0.7504
2025-10-12 06:11:44,495 - INFO - _models.training_function_executor - Epoch 026/43 - train_loss: 1.1700 - val_loss: 1.4328 - val_acc: 0.6562
2025-10-12 06:11:59,202 - INFO - _models.training_function_executor - Epoch 027/43 - train_loss: 1.1377 - val_loss: 1.1491 - val_acc: 0.7441
2025-10-12 06:12:13,860 - INFO - _models.training_function_executor - Epoch 028/43 - train_loss: 1.1368 - val_loss: 1.1203 - val_acc: 0.7541
2025-10-12 06:12:28,523 - INFO - _models.training_function_executor - Epoch 029/43 - train_loss: 1.1677 - val_loss: 1.1535 - val_acc: 0.7647
2025-10-12 06:12:43,183 - INFO - _models.training_function_executor - Epoch 030/43 - train_loss: 1.1399 - val_loss: 1.1146 - val_acc: 0.7792
2025-10-12 06:12:57,904 - INFO - _models.training_function_executor - Epoch 031/43 - train_loss: 1.1392 - val_loss: 1.1290 - val_acc: 0.7588
2025-10-12 06:13:12,595 - INFO - _models.training_function_executor - Epoch 032/43 - train_loss: 1.1343 - val_loss: 1.1478 - val_acc: 0.7550
2025-10-12 06:13:27,293 - INFO - _models.training_function_executor - Epoch 033/43 - train_loss: 1.1885 - val_loss: 1.1575 - val_acc: 0.7586
2025-10-12 06:13:41,977 - INFO - _models.training_function_executor - Epoch 034/43 - train_loss: 1.1272 - val_loss: 1.1081 - val_acc: 0.7819
2025-10-12 06:13:56,678 - INFO - _models.training_function_executor - Epoch 035/43 - train_loss: 1.1265 - val_loss: 1.1014 - val_acc: 0.7772
2025-10-12 06:14:11,338 - INFO - _models.training_function_executor - Epoch 036/43 - train_loss: 1.1514 - val_loss: 1.1997 - val_acc: 0.7432
2025-10-12 06:14:26,023 - INFO - _models.training_function_executor - Epoch 037/43 - train_loss: 1.1451 - val_loss: 1.1649 - val_acc: 0.7678
2025-10-12 06:14:40,710 - INFO - _models.training_function_executor - Epoch 038/43 - train_loss: 1.1519 - val_loss: 1.3192 - val_acc: 0.7458
2025-10-12 06:14:55,377 - INFO - _models.training_function_executor - Epoch 039/43 - train_loss: 1.1758 - val_loss: 1.1964 - val_acc: 0.7255
2025-10-12 06:15:10,064 - INFO - _models.training_function_executor - Epoch 040/43 - train_loss: 1.1423 - val_loss: 1.3165 - val_acc: 0.7395
2025-10-12 06:15:24,752 - INFO - _models.training_function_executor - Epoch 041/43 - train_loss: 1.1705 - val_loss: 1.1187 - val_acc: 0.7777
2025-10-12 06:15:39,424 - INFO - _models.training_function_executor - Epoch 042/43 - train_loss: 1.1455 - val_loss: 1.4322 - val_acc: 0.7375
2025-10-12 06:15:54,125 - INFO - _models.training_function_executor - Epoch 043/43 - train_loss: 1.1213 - val_loss: 1.1016 - val_acc: 0.7680
2025-10-12 06:15:54,128 - INFO - _models.training_function_executor - Model: 153,105 parameters, 657.9KB storage
2025-10-12 06:15:54,128 - WARNING - _models.training_function_executor - Model storage 657.9KB exceeds 256KB limit!
2025-10-12 06:15:54,128 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6246199802706447, 1.2957899132349042, 1.2383488993941798, 1.2232755524401986, 1.207534552726205, 1.194463554653706, 1.1856067079032349, 1.1748725519674326, 1.1789745679050214, 1.1659625921376235, 1.173244047110674, 1.1495617314114368, 1.1659751990728542, 1.142909675179389, 1.1779738304537413, 1.1415512840731978, 1.1691292915512808, 1.1657802767798664, 1.1553300059797216, 1.141981432393668, 1.1403115903075274, 1.135091060602377, 1.135867741523525, 1.1473748417930416, 1.1636252035659054, 1.1699526942731786, 1.1377064288184073, 1.136826162055359, 1.1676824114144913, 1.1399262118347884, 1.1391701795940512, 1.1342993831359134, 1.188499472339044, 1.1271693256504685, 1.126492463503428, 1.1514392207459132, 1.1451404808199317, 1.1518971289543576, 1.1757811222787415, 1.1422593555418727, 1.1704776967410486, 1.1454925041620991, 1.1213226002289942], 'val_losses': [1.235811616809459, 1.2087096652243576, 1.1641579756671663, 1.1686928811338677, 1.1884003653991961, 1.1342543598067565, 1.2405758824513682, 1.1411804996840305, 1.1690968486617652, 1.2013723329935284, 1.2200428134376118, 1.1717020960007676, 1.1744383077000586, 1.0830316898244472, 1.1218074692226099, 1.128802017916071, 1.2857904036561634, 1.233075551566103, 1.0453786326739853, 1.1276418718375398, 1.1383886360855089, 1.0756434363254017, 1.0695900701333227, 1.1935596521976406, 1.2280794206014412, 1.4327680821346995, 1.1490842865236914, 1.1203411511703933, 1.1534605207124455, 1.114576001496093, 1.1289725600734306, 1.147796017622088, 1.1575141336937071, 1.108088478284321, 1.1013756080403125, 1.199701662993239, 1.1648997658818678, 1.3192002057278118, 1.1964442887254474, 1.3164665970219822, 1.1186871836349852, 1.4322006274321133, 1.1015825193997317], 'val_acc': [0.628106405320266, 0.673871193559678, 0.6868218410920546, 0.6966223311165558, 0.6953972698634932, 0.7288239411970598, 0.6976723836191809, 0.7098354917745887, 0.7096604830241512, 0.7259362968148407, 0.7206860343017151, 0.7275988799439972, 0.6995099754987749, 0.7579628981449072, 0.7631256562828141, 0.7411620581029051, 0.7206860343017151, 0.7098354917745887, 0.7696884844242212, 0.7417745887294365, 0.7296989849492475, 0.7523626181309065, 0.7794889744487224, 0.7270738536926846, 0.750350017500875, 0.6561953097654882, 0.744137206860343, 0.7541127056352818, 0.7647007350367518, 0.7792264613230662, 0.7588379418970949, 0.7549877493874694, 0.7585754287714386, 0.7819390969548478, 0.7772138606930347, 0.7431746587329366, 0.7677633881694085, 0.7457997899894995, 0.7254987749387469, 0.7394994749737487, 0.7777388869443472, 0.7374868743437172, 0.7680259012950648], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009063530148893219, 'batch_size': 48, 'epochs': 43, 'weight_decay': 2.132895201152522e-06, 'dropout': 0.08018032673163857, 'base_channels': 20, 'temporal_kernel': 5, 'spatial_segments': 1000, 'label_smoothing': 0.19454642315341003, 'grad_clip': 0.609334513474725, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 2845}, 'model_parameter_count': 153105, 'model_storage_size_kb': 657.873046875, 'model_size_validation': 'FAIL'}
2025-10-12 06:15:54,128 - INFO - _models.training_function_executor - BO Objective: base=0.7680, size_penalty=0.7849, final=-0.0169
2025-10-12 06:15:54,128 - INFO - _models.training_function_executor - Model: 153,105 parameters, 657.9KB (FAIL 256KB limit)
2025-10-12 06:15:54,128 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 631.624s
2025-10-12 06:15:54,241 - INFO - bo.run_bo - Updated RF surrogate model with observation: -0.0169
2025-10-12 06:15:54,241 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-12 06:15:54,241 - INFO - bo.run_bo - Recorded observation #27: hparams={'lr': 0.009063530148893219, 'batch_size': np.int64(48), 'epochs': np.int64(43), 'weight_decay': 2.132895201152522e-06, 'dropout': 0.08018032673163857, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(1000), 'label_smoothing': 0.19454642315341003, 'grad_clip': 0.609334513474725, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(2845)}, value=-0.0169
2025-10-12 06:15:54,241 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 27: {'lr': 0.009063530148893219, 'batch_size': np.int64(48), 'epochs': np.int64(43), 'weight_decay': 2.132895201152522e-06, 'dropout': 0.08018032673163857, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(1000), 'label_smoothing': 0.19454642315341003, 'grad_clip': 0.609334513474725, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(2845)} -> -0.0169
2025-10-12 06:15:54,242 - INFO - bo.run_bo - üîçBO Trial 28: Using RF surrogate + Expected Improvement
2025-10-12 06:15:54,242 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 06:15:54,242 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 06:15:54,242 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 06:15:54,242 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.017437390359849335, 'batch_size': 48, 'epochs': 23, 'weight_decay': 1.5192856862538991e-06, 'dropout': 0.045563499550684235, 'base_channels': 20, 'temporal_kernel': 3, 'spatial_segments': 500, 'label_smoothing': 0.07451850466828004, 'grad_clip': 0.7358226091196197, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1349}
2025-10-12 06:15:54,243 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.017437390359849335, 'batch_size': 48, 'epochs': 23, 'weight_decay': 1.5192856862538991e-06, 'dropout': 0.045563499550684235, 'base_channels': 20, 'temporal_kernel': 3, 'spatial_segments': 500, 'label_smoothing': 0.07451850466828004, 'grad_clip': 0.7358226091196197, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1349}
2025-10-12 06:16:08,931 - INFO - _models.training_function_executor - Epoch 001/23 - train_loss: 1.7037 - val_loss: 1.5509 - val_acc: 0.4684
2025-10-12 06:16:23,564 - INFO - _models.training_function_executor - Epoch 002/23 - train_loss: 1.4473 - val_loss: 1.4741 - val_acc: 0.5378
2025-10-12 06:16:38,229 - INFO - _models.training_function_executor - Epoch 003/23 - train_loss: 1.4112 - val_loss: 1.6283 - val_acc: 0.5741
2025-10-12 06:16:52,895 - INFO - _models.training_function_executor - Epoch 004/23 - train_loss: 1.4412 - val_loss: 1.2230 - val_acc: 0.6155
2025-10-12 06:17:07,537 - INFO - _models.training_function_executor - Epoch 005/23 - train_loss: 1.4068 - val_loss: 1.2512 - val_acc: 0.5965
2025-10-12 06:17:22,139 - INFO - _models.training_function_executor - Epoch 006/23 - train_loss: 1.4068 - val_loss: 1.3737 - val_acc: 0.6055
2025-10-12 06:17:36,745 - INFO - _models.training_function_executor - Epoch 007/23 - train_loss: 1.3575 - val_loss: 1.3096 - val_acc: 0.6556
2025-10-12 06:17:51,357 - INFO - _models.training_function_executor - Epoch 008/23 - train_loss: 1.3903 - val_loss: 1.8423 - val_acc: 0.6029
2025-10-12 06:18:05,975 - INFO - _models.training_function_executor - Epoch 009/23 - train_loss: 1.3852 - val_loss: 1.1712 - val_acc: 0.6683
2025-10-12 06:18:20,610 - INFO - _models.training_function_executor - Epoch 010/23 - train_loss: 1.3746 - val_loss: 1.5744 - val_acc: 0.5878
2025-10-12 06:18:35,274 - INFO - _models.training_function_executor - Epoch 011/23 - train_loss: 1.3823 - val_loss: 1.3678 - val_acc: 0.6871
2025-10-12 06:18:49,907 - INFO - _models.training_function_executor - Epoch 012/23 - train_loss: 1.3679 - val_loss: 1.4800 - val_acc: 0.6246
2025-10-12 06:19:04,497 - INFO - _models.training_function_executor - Epoch 013/23 - train_loss: 1.5326 - val_loss: 2.5347 - val_acc: 0.6364
2025-10-12 06:19:19,107 - INFO - _models.training_function_executor - Epoch 014/23 - train_loss: 1.4374 - val_loss: 1.2466 - val_acc: 0.6934
2025-10-12 06:19:33,766 - INFO - _models.training_function_executor - Epoch 015/23 - train_loss: 1.4127 - val_loss: 1.2685 - val_acc: 0.7142
2025-10-12 06:19:48,401 - INFO - _models.training_function_executor - Epoch 016/23 - train_loss: 1.3111 - val_loss: 1.3560 - val_acc: 0.6772
2025-10-12 06:20:03,025 - INFO - _models.training_function_executor - Epoch 017/23 - train_loss: 1.3563 - val_loss: 1.7623 - val_acc: 0.5895
2025-10-12 06:20:17,685 - INFO - _models.training_function_executor - Epoch 018/23 - train_loss: 1.3656 - val_loss: 1.0497 - val_acc: 0.7493
2025-10-12 06:20:32,301 - INFO - _models.training_function_executor - Epoch 019/23 - train_loss: 1.4485 - val_loss: 1.5466 - val_acc: 0.6549
2025-10-12 06:20:46,944 - INFO - _models.training_function_executor - Epoch 020/23 - train_loss: 1.4565 - val_loss: 2.1384 - val_acc: 0.6200
2025-10-12 06:21:01,526 - INFO - _models.training_function_executor - Epoch 021/23 - train_loss: 1.4507 - val_loss: 1.3320 - val_acc: 0.6942
2025-10-12 06:21:16,137 - INFO - _models.training_function_executor - Epoch 022/23 - train_loss: 1.4700 - val_loss: 1.2348 - val_acc: 0.6968
2025-10-12 06:21:30,766 - INFO - _models.training_function_executor - Epoch 023/23 - train_loss: 1.4162 - val_loss: 1.5381 - val_acc: 0.6948
2025-10-12 06:21:30,769 - INFO - _models.training_function_executor - Model: 104,865 parameters, 450.6KB storage
2025-10-12 06:21:30,769 - WARNING - _models.training_function_executor - Model storage 450.6KB exceeds 256KB limit!
2025-10-12 06:21:30,769 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7036679731117998, 1.4472533811795198, 1.41123036617243, 1.4411954790677146, 1.406796684225915, 1.4067937299259734, 1.3575323836595643, 1.3902837184496095, 1.3851884174772522, 1.3745737006541603, 1.382296602647539, 1.3678838516141218, 1.5325947763162933, 1.4374309917784756, 1.4127453400991077, 1.3110720515042533, 1.3563456777972194, 1.3656444612148553, 1.4485111511542241, 1.4565380334144795, 1.450728534442126, 1.4699516044782932, 1.4162293307882194], 'val_losses': [1.5508968410977626, 1.4740798838454858, 1.628299511601385, 1.2229603974603047, 1.2511811338190353, 1.373720852132022, 1.3096283592875704, 1.8423009956888607, 1.1711623577709418, 1.5744286178499407, 1.3678415322328807, 1.4799553763837217, 2.5346735162170857, 1.2466196179348228, 1.2684582769766444, 1.3560038815856523, 1.7622671605074451, 1.049729803850236, 1.5465762422432798, 2.13837164963798, 1.3320138087254285, 1.2347651104598267, 1.538068028734746], 'val_acc': [0.4684109205460273, 0.5378018900945047, 0.5741162058102905, 0.6155057752887645, 0.5965173258662934, 0.6055302765138257, 0.6555827791389569, 0.6029051452572629, 0.6682709135456772, 0.5877668883444173, 0.6870843542177109, 0.6246062303115156, 0.6364193209660483, 0.6933846692334616, 0.7142107105355268, 0.6771963598179909, 0.5895169758487925, 0.7492999649982499, 0.6548827441372068, 0.6199684984249213, 0.6941722086104305, 0.6967973398669933, 0.6947847392369618], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.017437390359849335, 'batch_size': 48, 'epochs': 23, 'weight_decay': 1.5192856862538991e-06, 'dropout': 0.045563499550684235, 'base_channels': 20, 'temporal_kernel': 3, 'spatial_segments': 500, 'label_smoothing': 0.07451850466828004, 'grad_clip': 0.7358226091196197, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1349}, 'model_parameter_count': 104865, 'model_storage_size_kb': 450.59179687500006, 'model_size_validation': 'FAIL'}
2025-10-12 06:21:30,769 - INFO - _models.training_function_executor - BO Objective: base=0.6948, size_penalty=0.3801, final=0.3147
2025-10-12 06:21:30,769 - INFO - _models.training_function_executor - Model: 104,865 parameters, 450.6KB (FAIL 256KB limit)
2025-10-12 06:21:30,769 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 336.527s
2025-10-12 06:21:30,882 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.3147
2025-10-12 06:21:30,882 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-12 06:21:30,882 - INFO - bo.run_bo - Recorded observation #28: hparams={'lr': 0.017437390359849335, 'batch_size': np.int64(48), 'epochs': np.int64(23), 'weight_decay': 1.5192856862538991e-06, 'dropout': 0.045563499550684235, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(500), 'label_smoothing': 0.07451850466828004, 'grad_clip': 0.7358226091196197, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(1349)}, value=0.3147
2025-10-12 06:21:30,882 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 28: {'lr': 0.017437390359849335, 'batch_size': np.int64(48), 'epochs': np.int64(23), 'weight_decay': 1.5192856862538991e-06, 'dropout': 0.045563499550684235, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(500), 'label_smoothing': 0.07451850466828004, 'grad_clip': 0.7358226091196197, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(1349)} -> 0.3147
2025-10-12 06:21:30,882 - INFO - bo.run_bo - üîçBO Trial 29: Using RF surrogate + Expected Improvement
2025-10-12 06:21:30,882 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 06:21:30,883 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 06:21:30,883 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 06:21:30,883 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00024889901291209074, 'batch_size': 48, 'epochs': 49, 'weight_decay': 3.07693203077649e-06, 'dropout': 0.0713843443866299, 'base_channels': 23, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.19617926741082145, 'grad_clip': 0.47986863762426246, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 7978}
2025-10-12 06:21:30,884 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00024889901291209074, 'batch_size': 48, 'epochs': 49, 'weight_decay': 3.07693203077649e-06, 'dropout': 0.0713843443866299, 'base_channels': 23, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.19617926741082145, 'grad_clip': 0.47986863762426246, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 7978}
2025-10-12 06:21:47,107 - INFO - _models.training_function_executor - Epoch 001/49 - train_loss: 1.3675 - val_loss: 1.2669 - val_acc: 0.6025
2025-10-12 06:22:02,820 - INFO - _models.training_function_executor - Epoch 002/49 - train_loss: 1.1650 - val_loss: 1.5192 - val_acc: 0.3723
2025-10-12 06:22:18,560 - INFO - _models.training_function_executor - Epoch 003/49 - train_loss: 1.1064 - val_loss: 1.1438 - val_acc: 0.6764
2025-10-12 06:22:34,274 - INFO - _models.training_function_executor - Epoch 004/49 - train_loss: 1.0686 - val_loss: 1.1538 - val_acc: 0.6641
2025-10-12 06:22:50,017 - INFO - _models.training_function_executor - Epoch 005/49 - train_loss: 1.0495 - val_loss: 1.0626 - val_acc: 0.7350
2025-10-12 06:23:05,775 - INFO - _models.training_function_executor - Epoch 006/49 - train_loss: 1.0345 - val_loss: 1.0575 - val_acc: 0.7268
2025-10-12 06:23:21,558 - INFO - _models.training_function_executor - Epoch 007/49 - train_loss: 1.0235 - val_loss: 0.9959 - val_acc: 0.7821
2025-10-12 06:23:37,317 - INFO - _models.training_function_executor - Epoch 008/49 - train_loss: 1.0160 - val_loss: 1.2288 - val_acc: 0.6186
2025-10-12 06:23:53,070 - INFO - _models.training_function_executor - Epoch 009/49 - train_loss: 1.0051 - val_loss: 1.1443 - val_acc: 0.6829
2025-10-12 06:24:08,830 - INFO - _models.training_function_executor - Epoch 010/49 - train_loss: 1.0005 - val_loss: 1.0093 - val_acc: 0.7703
2025-10-12 06:24:24,589 - INFO - _models.training_function_executor - Epoch 011/49 - train_loss: 0.9959 - val_loss: 1.0730 - val_acc: 0.7327
2025-10-12 06:24:40,354 - INFO - _models.training_function_executor - Epoch 012/49 - train_loss: 0.9897 - val_loss: 1.0245 - val_acc: 0.7595
2025-10-12 06:24:56,082 - INFO - _models.training_function_executor - Epoch 013/49 - train_loss: 0.9839 - val_loss: 1.3120 - val_acc: 0.5805
2025-10-12 06:25:11,847 - INFO - _models.training_function_executor - Epoch 014/49 - train_loss: 0.9793 - val_loss: 0.9924 - val_acc: 0.7869
2025-10-12 06:25:27,597 - INFO - _models.training_function_executor - Epoch 015/49 - train_loss: 0.9746 - val_loss: 1.0933 - val_acc: 0.7170
2025-10-12 06:25:43,376 - INFO - _models.training_function_executor - Epoch 016/49 - train_loss: 0.9722 - val_loss: 1.0165 - val_acc: 0.7608
2025-10-12 06:25:59,145 - INFO - _models.training_function_executor - Epoch 017/49 - train_loss: 0.9699 - val_loss: 1.0503 - val_acc: 0.7437
2025-10-12 06:26:14,923 - INFO - _models.training_function_executor - Epoch 018/49 - train_loss: 0.9639 - val_loss: 1.0849 - val_acc: 0.7246
2025-10-12 06:26:30,656 - INFO - _models.training_function_executor - Epoch 019/49 - train_loss: 0.9607 - val_loss: 1.2603 - val_acc: 0.6180
2025-10-12 06:26:46,407 - INFO - _models.training_function_executor - Epoch 020/49 - train_loss: 0.9592 - val_loss: 1.0646 - val_acc: 0.7375
2025-10-12 06:27:02,143 - INFO - _models.training_function_executor - Epoch 021/49 - train_loss: 0.9578 - val_loss: 1.0036 - val_acc: 0.7763
2025-10-12 06:27:17,933 - INFO - _models.training_function_executor - Epoch 022/49 - train_loss: 0.9542 - val_loss: 1.0499 - val_acc: 0.7467
2025-10-12 06:27:33,661 - INFO - _models.training_function_executor - Epoch 023/49 - train_loss: 0.9512 - val_loss: 1.0903 - val_acc: 0.7173
2025-10-12 06:27:49,388 - INFO - _models.training_function_executor - Epoch 024/49 - train_loss: 0.9482 - val_loss: 1.0597 - val_acc: 0.7379
2025-10-12 06:28:05,156 - INFO - _models.training_function_executor - Epoch 025/49 - train_loss: 0.9476 - val_loss: 1.0066 - val_acc: 0.7807
2025-10-12 06:28:20,937 - INFO - _models.training_function_executor - Epoch 026/49 - train_loss: 0.9444 - val_loss: 1.3316 - val_acc: 0.6042
2025-10-12 06:28:36,734 - INFO - _models.training_function_executor - Epoch 027/49 - train_loss: 0.9423 - val_loss: 0.9607 - val_acc: 0.8087
2025-10-12 06:28:52,498 - INFO - _models.training_function_executor - Epoch 028/49 - train_loss: 0.9394 - val_loss: 1.0452 - val_acc: 0.7480
2025-10-12 06:29:08,294 - INFO - _models.training_function_executor - Epoch 029/49 - train_loss: 0.9395 - val_loss: 0.9659 - val_acc: 0.8047
2025-10-12 06:29:24,033 - INFO - _models.training_function_executor - Epoch 030/49 - train_loss: 0.9367 - val_loss: 1.0102 - val_acc: 0.7710
2025-10-12 06:29:39,833 - INFO - _models.training_function_executor - Epoch 031/49 - train_loss: 0.9360 - val_loss: 1.0891 - val_acc: 0.7283
2025-10-12 06:29:55,597 - INFO - _models.training_function_executor - Epoch 032/49 - train_loss: 0.9313 - val_loss: 1.2341 - val_acc: 0.6349
2025-10-12 06:30:11,318 - INFO - _models.training_function_executor - Epoch 033/49 - train_loss: 0.9308 - val_loss: 1.2434 - val_acc: 0.6318
2025-10-12 06:30:27,050 - INFO - _models.training_function_executor - Epoch 034/49 - train_loss: 0.9284 - val_loss: 1.0451 - val_acc: 0.7506
2025-10-12 06:30:42,849 - INFO - _models.training_function_executor - Epoch 035/49 - train_loss: 0.9272 - val_loss: 1.1100 - val_acc: 0.7059
2025-10-12 06:30:58,627 - INFO - _models.training_function_executor - Epoch 036/49 - train_loss: 0.9250 - val_loss: 1.0743 - val_acc: 0.7331
2025-10-12 06:31:14,420 - INFO - _models.training_function_executor - Epoch 037/49 - train_loss: 0.9236 - val_loss: 1.0948 - val_acc: 0.7144
2025-10-12 06:31:30,188 - INFO - _models.training_function_executor - Epoch 038/49 - train_loss: 0.9206 - val_loss: 1.1314 - val_acc: 0.6922
2025-10-12 06:31:45,989 - INFO - _models.training_function_executor - Epoch 039/49 - train_loss: 0.9217 - val_loss: 1.0723 - val_acc: 0.7314
2025-10-12 06:32:01,759 - INFO - _models.training_function_executor - Epoch 040/49 - train_loss: 0.9190 - val_loss: 0.9879 - val_acc: 0.7966
2025-10-12 06:32:17,522 - INFO - _models.training_function_executor - Epoch 041/49 - train_loss: 0.9181 - val_loss: 1.0332 - val_acc: 0.7556
2025-10-12 06:32:33,300 - INFO - _models.training_function_executor - Epoch 042/49 - train_loss: 0.9146 - val_loss: 1.0047 - val_acc: 0.7740
2025-10-12 06:32:49,092 - INFO - _models.training_function_executor - Epoch 043/49 - train_loss: 0.9141 - val_loss: 1.2386 - val_acc: 0.6295
2025-10-12 06:33:04,845 - INFO - _models.training_function_executor - Epoch 044/49 - train_loss: 0.9129 - val_loss: 1.0589 - val_acc: 0.7366
2025-10-12 06:33:20,592 - INFO - _models.training_function_executor - Epoch 045/49 - train_loss: 0.9112 - val_loss: 1.0633 - val_acc: 0.7300
2025-10-12 06:33:36,363 - INFO - _models.training_function_executor - Epoch 046/49 - train_loss: 0.9103 - val_loss: 1.0812 - val_acc: 0.7293
2025-10-12 06:33:52,138 - INFO - _models.training_function_executor - Epoch 047/49 - train_loss: 0.9054 - val_loss: 1.2596 - val_acc: 0.6202
2025-10-12 06:34:07,889 - INFO - _models.training_function_executor - Epoch 048/49 - train_loss: 0.9073 - val_loss: 1.0552 - val_acc: 0.7539
2025-10-12 06:34:23,666 - INFO - _models.training_function_executor - Epoch 049/49 - train_loss: 0.9053 - val_loss: 1.1142 - val_acc: 0.7113
2025-10-12 06:34:23,669 - INFO - _models.training_function_executor - Model: 84,453 parameters, 362.9KB storage
2025-10-12 06:34:23,669 - WARNING - _models.training_function_executor - Model storage 362.9KB exceeds 256KB limit!
2025-10-12 06:34:23,669 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.367539856080872, 1.1650297413933808, 1.1064259914155186, 1.0685684066533125, 1.0494818308155647, 1.0344609709982693, 1.0235361853470366, 1.0160356427474084, 1.0051232662324434, 1.0005112990324925, 0.9958641784859571, 0.9897385756786695, 0.9838546655334123, 0.9793461475457435, 0.974568463223023, 0.972202931495242, 0.9698702058760403, 0.9638938807423064, 0.9607420054648697, 0.9592308352825564, 0.9578039348229771, 0.954181002243691, 0.9512057382825959, 0.948240193550429, 0.9476220409979468, 0.9444012654841593, 0.9422568444150872, 0.9393908441129329, 0.9394885111531053, 0.9367103684311527, 0.9359991290913957, 0.9313351691374213, 0.9307838825233173, 0.9284430077370539, 0.9272231474847363, 0.9250082559088205, 0.923556485249523, 0.9205660850258194, 0.9217104634122077, 0.9189748046570906, 0.918102629626177, 0.9145661121195833, 0.9140524828521613, 0.9129418186220123, 0.911213268172211, 0.9103325263453315, 0.9054217857207958, 0.9073188982729232, 0.9052786721313671], 'val_losses': [1.2669476520610432, 1.519213867053979, 1.143812490085392, 1.1538011625508224, 1.0626141064059371, 1.0575361817418005, 0.9959239430639516, 1.2288461432074766, 1.1442754813370524, 1.0093290961660786, 1.0729936634196575, 1.024524765453599, 1.3119768334469848, 0.9923536874925001, 1.093335353393508, 1.0165260257026638, 1.050325179625776, 1.084893612144792, 1.2603174078326815, 1.064585051296222, 1.0036062504555072, 1.0499413201639525, 1.0902858639998498, 1.0596725809060905, 1.0065988310993157, 1.3316028227871184, 0.9607038891811992, 1.0451953507905078, 0.9659119568423538, 1.0102415707798158, 1.089115492146792, 1.2340997356946208, 1.2433876092925453, 1.0450851352723027, 1.1100302798622006, 1.074280676743264, 1.094817146601525, 1.1314269975010314, 1.0723306927432286, 0.9879219032143395, 1.033234563894442, 1.0047220015467402, 1.2386421683287763, 1.0588647643711169, 1.0633027556896377, 1.0811596397423937, 1.2596154139097813, 1.0551696056079565, 1.1142357979615252], 'val_acc': [0.6024676233811691, 0.3723311165558278, 0.676408820441022, 0.6640707035351767, 0.7350367518375919, 0.7268113405670283, 0.7821141057052853, 0.6185684284214211, 0.6828841442072103, 0.7703010150507525, 0.7326741337066853, 0.759537976898845, 0.5805040252012601, 0.7869268463423171, 0.7170108505425271, 0.7607630381519076, 0.7436996849842492, 0.7246237311865593, 0.6179558977948898, 0.7374868743437172, 0.776338816940847, 0.7466748337416871, 0.7172733636681834, 0.737924396219811, 0.7807140357017851, 0.6042177108855443, 0.8087154357717886, 0.7479873993699685, 0.8046902345117256, 0.7710010500525026, 0.7282989149457473, 0.6349317465873293, 0.6317815890794539, 0.7506125306265313, 0.7058977948897445, 0.7331116555827791, 0.7143857192859643, 0.692159607980399, 0.7313615680784039, 0.7965523276163808, 0.7556002800140007, 0.7739761988099405, 0.6295064753237661, 0.7366118305915296, 0.7300490024501225, 0.7292614630731536, 0.6202310115505776, 0.7539376968848442, 0.7113230661533076], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00024889901291209074, 'batch_size': 48, 'epochs': 49, 'weight_decay': 3.07693203077649e-06, 'dropout': 0.0713843443866299, 'base_channels': 23, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.19617926741082145, 'grad_clip': 0.47986863762426246, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 7978}, 'model_parameter_count': 84453, 'model_storage_size_kb': 362.883984375, 'model_size_validation': 'FAIL'}
2025-10-12 06:34:23,669 - INFO - _models.training_function_executor - BO Objective: base=0.7113, size_penalty=0.2088, final=0.5026
2025-10-12 06:34:23,669 - INFO - _models.training_function_executor - Model: 84,453 parameters, 362.9KB (FAIL 256KB limit)
2025-10-12 06:34:23,669 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 772.787s
2025-10-12 06:34:23,784 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5026
2025-10-12 06:34:23,784 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-12 06:34:23,784 - INFO - bo.run_bo - Recorded observation #29: hparams={'lr': 0.00024889901291209074, 'batch_size': np.int64(48), 'epochs': np.int64(49), 'weight_decay': 3.07693203077649e-06, 'dropout': 0.0713843443866299, 'base_channels': np.int64(23), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(100), 'label_smoothing': 0.19617926741082145, 'grad_clip': 0.47986863762426246, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(7978)}, value=0.5026
2025-10-12 06:34:23,784 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 29: {'lr': 0.00024889901291209074, 'batch_size': np.int64(48), 'epochs': np.int64(49), 'weight_decay': 3.07693203077649e-06, 'dropout': 0.0713843443866299, 'base_channels': np.int64(23), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(100), 'label_smoothing': 0.19617926741082145, 'grad_clip': 0.47986863762426246, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(7978)} -> 0.5026
2025-10-12 06:34:23,784 - INFO - bo.run_bo - üîçBO Trial 30: Using RF surrogate + Expected Improvement
2025-10-12 06:34:23,784 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 06:34:23,784 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 06:34:23,784 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 06:34:23,785 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0006191112684208738, 'batch_size': 8, 'epochs': 26, 'weight_decay': 1.4744120330312305e-06, 'dropout': 0.13184975993201495, 'base_channels': 16, 'temporal_kernel': 3, 'spatial_segments': 25, 'label_smoothing': 0.03283719581234395, 'grad_clip': 0.5083615276391641, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 830}
2025-10-12 06:34:23,786 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006191112684208738, 'batch_size': 8, 'epochs': 26, 'weight_decay': 1.4744120330312305e-06, 'dropout': 0.13184975993201495, 'base_channels': 16, 'temporal_kernel': 3, 'spatial_segments': 25, 'label_smoothing': 0.03283719581234395, 'grad_clip': 0.5083615276391641, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 830}
2025-10-12 06:34:39,848 - INFO - _models.training_function_executor - Epoch 001/26 - train_loss: 1.1126 - val_loss: 1.0475 - val_acc: 0.6033
2025-10-12 06:34:55,699 - INFO - _models.training_function_executor - Epoch 002/26 - train_loss: 0.8945 - val_loss: 1.0765 - val_acc: 0.6161
2025-10-12 06:35:11,668 - INFO - _models.training_function_executor - Epoch 003/26 - train_loss: 0.8237 - val_loss: 0.7587 - val_acc: 0.7625
2025-10-12 06:35:27,581 - INFO - _models.training_function_executor - Epoch 004/26 - train_loss: 0.7868 - val_loss: 0.7462 - val_acc: 0.7516
2025-10-12 06:35:43,439 - INFO - _models.training_function_executor - Epoch 005/26 - train_loss: 0.7625 - val_loss: 0.7147 - val_acc: 0.7609
2025-10-12 06:35:59,325 - INFO - _models.training_function_executor - Epoch 006/26 - train_loss: 0.7439 - val_loss: 0.8590 - val_acc: 0.7044
2025-10-12 06:36:15,265 - INFO - _models.training_function_executor - Epoch 007/26 - train_loss: 0.7277 - val_loss: 0.7984 - val_acc: 0.7419
2025-10-12 06:36:31,161 - INFO - _models.training_function_executor - Epoch 008/26 - train_loss: 0.7198 - val_loss: 0.7005 - val_acc: 0.7684
2025-10-12 06:36:47,075 - INFO - _models.training_function_executor - Epoch 009/26 - train_loss: 0.7053 - val_loss: 0.6912 - val_acc: 0.7845
2025-10-12 06:37:03,007 - INFO - _models.training_function_executor - Epoch 010/26 - train_loss: 0.6979 - val_loss: 0.7120 - val_acc: 0.7829
2025-10-12 06:37:18,980 - INFO - _models.training_function_executor - Epoch 011/26 - train_loss: 0.6941 - val_loss: 0.7488 - val_acc: 0.7607
2025-10-12 06:37:34,883 - INFO - _models.training_function_executor - Epoch 012/26 - train_loss: 0.6911 - val_loss: 0.8659 - val_acc: 0.7006
2025-10-12 06:37:50,788 - INFO - _models.training_function_executor - Epoch 013/26 - train_loss: 0.6789 - val_loss: 0.7196 - val_acc: 0.7843
2025-10-12 06:38:06,694 - INFO - _models.training_function_executor - Epoch 014/26 - train_loss: 0.6786 - val_loss: 0.6799 - val_acc: 0.7947
2025-10-12 06:38:22,555 - INFO - _models.training_function_executor - Epoch 015/26 - train_loss: 0.6726 - val_loss: 0.7416 - val_acc: 0.7566
2025-10-12 06:38:38,427 - INFO - _models.training_function_executor - Epoch 016/26 - train_loss: 0.6663 - val_loss: 0.7398 - val_acc: 0.7586
2025-10-12 06:38:54,295 - INFO - _models.training_function_executor - Epoch 017/26 - train_loss: 0.6688 - val_loss: 0.7023 - val_acc: 0.7783
2025-10-12 06:39:10,165 - INFO - _models.training_function_executor - Epoch 018/26 - train_loss: 0.6629 - val_loss: 0.7100 - val_acc: 0.7944
2025-10-12 06:39:26,066 - INFO - _models.training_function_executor - Epoch 019/26 - train_loss: 0.6593 - val_loss: 0.6696 - val_acc: 0.7822
2025-10-12 06:39:41,951 - INFO - _models.training_function_executor - Epoch 020/26 - train_loss: 0.6492 - val_loss: 0.6532 - val_acc: 0.7964
2025-10-12 06:39:57,916 - INFO - _models.training_function_executor - Epoch 021/26 - train_loss: 0.6528 - val_loss: 0.7489 - val_acc: 0.7699
2025-10-12 06:40:13,788 - INFO - _models.training_function_executor - Epoch 022/26 - train_loss: 0.6467 - val_loss: 0.6689 - val_acc: 0.8020
2025-10-12 06:40:29,720 - INFO - _models.training_function_executor - Epoch 023/26 - train_loss: 0.6479 - val_loss: 0.6907 - val_acc: 0.7814
2025-10-12 06:40:45,604 - INFO - _models.training_function_executor - Epoch 024/26 - train_loss: 0.6445 - val_loss: 0.7865 - val_acc: 0.7471
2025-10-12 06:41:01,445 - INFO - _models.training_function_executor - Epoch 025/26 - train_loss: 0.6405 - val_loss: 0.6634 - val_acc: 0.7924
2025-10-12 06:41:17,366 - INFO - _models.training_function_executor - Epoch 026/26 - train_loss: 0.6385 - val_loss: 0.7626 - val_acc: 0.7603
2025-10-12 06:41:17,849 - INFO - _models.training_function_executor - Model: 10,372 parameters, 11.1KB storage
2025-10-12 06:41:17,849 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1126447450584742, 0.8944836429179779, 0.8236672808271127, 0.7868410440192466, 0.7625050604536394, 0.7439006017843743, 0.7277465099700272, 0.7198161516060853, 0.7052841163339797, 0.6978573760719912, 0.6940510249848252, 0.6910963208656816, 0.6788936824696565, 0.6786285326442896, 0.6726000262727511, 0.6662761579897798, 0.668801180760177, 0.6629393398709592, 0.6592796187343237, 0.649228669603909, 0.652816821271759, 0.646733301424734, 0.6479166830972354, 0.6445437939560492, 0.6404525397914583, 0.6384834924834694], 'val_losses': [1.0474582725277222, 1.0764590630090691, 0.7586817498761205, 0.7462400871116797, 0.71471855701539, 0.8590142409159748, 0.7983995869124649, 0.7004780094962375, 0.6912013251943357, 0.7119607205131399, 0.7487500662106003, 0.8658850435134953, 0.7196096586396655, 0.6799108090102777, 0.7415662894705437, 0.7398159253271802, 0.7022983143494018, 0.7100094333682229, 0.6695884731961665, 0.6531504830739946, 0.7488792248860413, 0.6689131350566508, 0.6907260469469024, 0.7864916784950265, 0.6633805695805134, 0.7626013777495515], 'val_acc': [0.6033426671333567, 0.6161183059152958, 0.7625131256562828, 0.7515750787539377, 0.7608505425271264, 0.7044102205110255, 0.7418620931046552, 0.7683759187959398, 0.7844767238361918, 0.7829016450822541, 0.7606755337766888, 0.7006475323766188, 0.7843017150857543, 0.7947147357367869, 0.7565628281414071, 0.7585754287714386, 0.7782639131956598, 0.7943647182359118, 0.782201610080504, 0.7963773188659433, 0.7698634931746587, 0.801977598879944, 0.7814140707035352, 0.7471123556177809, 0.7924396219810991, 0.7603255162758138], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0006191112684208738, 'batch_size': 8, 'epochs': 26, 'weight_decay': 1.4744120330312305e-06, 'dropout': 0.13184975993201495, 'base_channels': 16, 'temporal_kernel': 3, 'spatial_segments': 25, 'label_smoothing': 0.03283719581234395, 'grad_clip': 0.5083615276391641, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 830}, 'model_parameter_count': 10372, 'model_storage_size_kb': 11.141796875, 'model_size_validation': 'PASS'}
2025-10-12 06:41:17,849 - INFO - _models.training_function_executor - BO Objective: base=0.7603, size_penalty=0.0000, final=0.7603
2025-10-12 06:41:17,849 - INFO - _models.training_function_executor - Model: 10,372 parameters, 11.1KB (PASS 256KB limit)
2025-10-12 06:41:17,849 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 414.065s
2025-10-12 06:41:17,957 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7603
2025-10-12 06:41:17,957 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.106s
2025-10-12 06:41:17,958 - INFO - bo.run_bo - Recorded observation #30: hparams={'lr': 0.0006191112684208738, 'batch_size': np.int64(8), 'epochs': np.int64(26), 'weight_decay': 1.4744120330312305e-06, 'dropout': 0.13184975993201495, 'base_channels': np.int64(16), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(25), 'label_smoothing': 0.03283719581234395, 'grad_clip': 0.5083615276391641, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(830)}, value=0.7603
2025-10-12 06:41:17,958 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 30: {'lr': 0.0006191112684208738, 'batch_size': np.int64(8), 'epochs': np.int64(26), 'weight_decay': 1.4744120330312305e-06, 'dropout': 0.13184975993201495, 'base_channels': np.int64(16), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(25), 'label_smoothing': 0.03283719581234395, 'grad_clip': 0.5083615276391641, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(830)} -> 0.7603
2025-10-12 06:41:17,958 - INFO - bo.run_bo - üîçBO Trial 31: Using RF surrogate + Expected Improvement
2025-10-12 06:41:17,958 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 06:41:17,958 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 06:41:17,958 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 06:41:17,958 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.03170584702419257, 'batch_size': 8, 'epochs': 12, 'weight_decay': 2.0739005498202302e-06, 'dropout': 0.0072051618163210835, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 125, 'label_smoothing': 0.025476937586611185, 'grad_clip': 0.43157193642027414, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2161}
2025-10-12 06:41:17,959 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.03170584702419257, 'batch_size': 8, 'epochs': 12, 'weight_decay': 2.0739005498202302e-06, 'dropout': 0.0072051618163210835, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 125, 'label_smoothing': 0.025476937586611185, 'grad_clip': 0.43157193642027414, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2161}
2025-10-12 06:41:35,647 - INFO - _models.training_function_executor - Epoch 001/12 - train_loss: 6.8081 - val_loss: 11.1924 - val_acc: 0.2174
2025-10-12 06:41:53,253 - INFO - _models.training_function_executor - Epoch 002/12 - train_loss: 7.7313 - val_loss: 9.1386 - val_acc: 0.2570
2025-10-12 06:42:10,935 - INFO - _models.training_function_executor - Epoch 003/12 - train_loss: 8.1908 - val_loss: 13.3158 - val_acc: 0.2598
2025-10-12 06:42:28,489 - INFO - _models.training_function_executor - Epoch 004/12 - train_loss: 8.6985 - val_loss: 15.1552 - val_acc: 0.2537
2025-10-12 06:42:46,119 - INFO - _models.training_function_executor - Epoch 005/12 - train_loss: 9.5638 - val_loss: 9.8865 - val_acc: 0.2558
2025-10-12 06:43:03,762 - INFO - _models.training_function_executor - Epoch 006/12 - train_loss: 11.3287 - val_loss: 14.2189 - val_acc: 0.3142
2025-10-12 06:43:21,341 - INFO - _models.training_function_executor - Epoch 007/12 - train_loss: 11.3308 - val_loss: 11.3098 - val_acc: 0.2868
2025-10-12 06:43:38,881 - INFO - _models.training_function_executor - Epoch 008/12 - train_loss: 11.9628 - val_loss: 5.5187 - val_acc: 0.2400
2025-10-12 06:43:56,471 - INFO - _models.training_function_executor - Epoch 009/12 - train_loss: 13.5196 - val_loss: 6.3478 - val_acc: 0.2782
2025-10-12 06:44:14,101 - INFO - _models.training_function_executor - Epoch 010/12 - train_loss: 13.6658 - val_loss: 12.0480 - val_acc: 0.2826
2025-10-12 06:44:31,619 - INFO - _models.training_function_executor - Epoch 011/12 - train_loss: 15.0116 - val_loss: 11.1194 - val_acc: 0.2714
2025-10-12 06:44:49,237 - INFO - _models.training_function_executor - Epoch 012/12 - train_loss: 13.4938 - val_loss: 9.7585 - val_acc: 0.1706
2025-10-12 06:44:49,240 - INFO - _models.training_function_executor - Model: 63,421 parameters, 272.5KB storage
2025-10-12 06:44:49,240 - WARNING - _models.training_function_executor - Model storage 272.5KB exceeds 256KB limit!
2025-10-12 06:44:49,240 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [6.80807647126765, 7.731274722488894, 8.190799818679007, 8.69845935765955, 9.56382940947947, 11.328693323945682, 11.33079251268338, 11.962820633072347, 13.51957250732536, 13.665816773254637, 15.011599906599935, 13.493820273504834], 'val_losses': [11.192353498948217, 9.13856565499581, 13.315772978083672, 15.155190154477188, 9.88648231358306, 14.218866256053605, 11.309776049624968, 5.5187331853231685, 6.34776220047937, 12.048002836584919, 11.119431821958644, 9.758533555183705], 'val_acc': [0.21736086804340218, 0.2570003500175009, 0.25980049002450123, 0.25367518375918796, 0.2557752887644382, 0.3142282114105705, 0.2867518375918796, 0.24002450122506125, 0.27817640882044103, 0.2825516275813791, 0.2713510675533777, 0.17063353167658382], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.03170584702419257, 'batch_size': 8, 'epochs': 12, 'weight_decay': 2.0739005498202302e-06, 'dropout': 0.0072051618163210835, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 125, 'label_smoothing': 0.025476937586611185, 'grad_clip': 0.43157193642027414, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2161}, 'model_parameter_count': 63421, 'model_storage_size_kb': 272.512109375, 'model_size_validation': 'FAIL'}
2025-10-12 06:44:49,240 - INFO - _models.training_function_executor - BO Objective: base=0.1706, size_penalty=0.0323, final=0.1384
2025-10-12 06:44:49,240 - INFO - _models.training_function_executor - Model: 63,421 parameters, 272.5KB (FAIL 256KB limit)
2025-10-12 06:44:49,240 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 211.282s
2025-10-12 06:44:49,349 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1384
2025-10-12 06:44:49,349 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-12 06:44:49,349 - INFO - bo.run_bo - Recorded observation #31: hparams={'lr': 0.03170584702419257, 'batch_size': np.int64(8), 'epochs': np.int64(12), 'weight_decay': 2.0739005498202302e-06, 'dropout': 0.0072051618163210835, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(125), 'label_smoothing': 0.025476937586611185, 'grad_clip': 0.43157193642027414, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2161)}, value=0.1384
2025-10-12 06:44:49,349 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 31: {'lr': 0.03170584702419257, 'batch_size': np.int64(8), 'epochs': np.int64(12), 'weight_decay': 2.0739005498202302e-06, 'dropout': 0.0072051618163210835, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(125), 'label_smoothing': 0.025476937586611185, 'grad_clip': 0.43157193642027414, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2161)} -> 0.1384
2025-10-12 06:44:49,349 - INFO - bo.run_bo - üîçBO Trial 32: Using RF surrogate + Expected Improvement
2025-10-12 06:44:49,349 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 06:44:49,349 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 06:44:49,349 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 06:44:49,349 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00034001125241967206, 'batch_size': 8, 'epochs': 27, 'weight_decay': 1.2463170135730093e-06, 'dropout': 0.15083996740317215, 'base_channels': 19, 'temporal_kernel': 5, 'spatial_segments': 400, 'label_smoothing': 0.06002707818319767, 'grad_clip': 0.3440105024638404, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 4239}
2025-10-12 06:44:49,350 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00034001125241967206, 'batch_size': 8, 'epochs': 27, 'weight_decay': 1.2463170135730093e-06, 'dropout': 0.15083996740317215, 'base_channels': 19, 'temporal_kernel': 5, 'spatial_segments': 400, 'label_smoothing': 0.06002707818319767, 'grad_clip': 0.3440105024638404, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 4239}
2025-10-12 06:45:07,136 - INFO - _models.training_function_executor - Epoch 001/27 - train_loss: 1.1856 - val_loss: 1.0487 - val_acc: 0.6299
2025-10-12 06:45:24,813 - INFO - _models.training_function_executor - Epoch 002/27 - train_loss: 0.9829 - val_loss: 0.9189 - val_acc: 0.6983
2025-10-12 06:45:42,568 - INFO - _models.training_function_executor - Epoch 003/27 - train_loss: 0.9152 - val_loss: 0.9038 - val_acc: 0.7072
2025-10-12 06:46:00,331 - INFO - _models.training_function_executor - Epoch 004/27 - train_loss: 0.8732 - val_loss: 0.8090 - val_acc: 0.7533
2025-10-12 06:46:17,992 - INFO - _models.training_function_executor - Epoch 005/27 - train_loss: 0.8437 - val_loss: 0.9630 - val_acc: 0.6684
2025-10-12 06:46:35,713 - INFO - _models.training_function_executor - Epoch 006/27 - train_loss: 0.8201 - val_loss: 0.8501 - val_acc: 0.7367
2025-10-12 06:46:53,429 - INFO - _models.training_function_executor - Epoch 007/27 - train_loss: 0.8005 - val_loss: 0.8089 - val_acc: 0.7725
2025-10-12 06:47:11,143 - INFO - _models.training_function_executor - Epoch 008/27 - train_loss: 0.7882 - val_loss: 0.8476 - val_acc: 0.7806
2025-10-12 06:47:28,856 - INFO - _models.training_function_executor - Epoch 009/27 - train_loss: 0.7812 - val_loss: 0.7770 - val_acc: 0.7771
2025-10-12 06:47:46,561 - INFO - _models.training_function_executor - Epoch 010/27 - train_loss: 0.7684 - val_loss: 0.8208 - val_acc: 0.7460
2025-10-12 06:48:04,311 - INFO - _models.training_function_executor - Epoch 011/27 - train_loss: 0.7558 - val_loss: 0.9553 - val_acc: 0.7037
2025-10-12 06:48:21,944 - INFO - _models.training_function_executor - Epoch 012/27 - train_loss: 0.7478 - val_loss: 0.8409 - val_acc: 0.7553
2025-10-12 06:48:39,670 - INFO - _models.training_function_executor - Epoch 013/27 - train_loss: 0.7367 - val_loss: 0.7968 - val_acc: 0.7761
2025-10-12 06:48:57,359 - INFO - _models.training_function_executor - Epoch 014/27 - train_loss: 0.7382 - val_loss: 0.7608 - val_acc: 0.7963
2025-10-12 06:49:15,061 - INFO - _models.training_function_executor - Epoch 015/27 - train_loss: 0.7288 - val_loss: 0.8657 - val_acc: 0.7372
2025-10-12 06:49:32,753 - INFO - _models.training_function_executor - Epoch 016/27 - train_loss: 0.7231 - val_loss: 0.7707 - val_acc: 0.7975
2025-10-12 06:49:50,502 - INFO - _models.training_function_executor - Epoch 017/27 - train_loss: 0.7123 - val_loss: 0.8235 - val_acc: 0.7578
2025-10-12 06:50:08,214 - INFO - _models.training_function_executor - Epoch 018/27 - train_loss: 0.7110 - val_loss: 0.7787 - val_acc: 0.7867
2025-10-12 06:50:25,910 - INFO - _models.training_function_executor - Epoch 019/27 - train_loss: 0.6989 - val_loss: 0.8041 - val_acc: 0.7910
2025-10-12 06:50:43,587 - INFO - _models.training_function_executor - Epoch 020/27 - train_loss: 0.6979 - val_loss: 0.8558 - val_acc: 0.7798
2025-10-12 06:51:01,307 - INFO - _models.training_function_executor - Epoch 021/27 - train_loss: 0.6942 - val_loss: 0.8148 - val_acc: 0.7886
2025-10-12 06:51:18,973 - INFO - _models.training_function_executor - Epoch 022/27 - train_loss: 0.6901 - val_loss: 0.7789 - val_acc: 0.7868
2025-10-12 06:51:36,604 - INFO - _models.training_function_executor - Epoch 023/27 - train_loss: 0.6819 - val_loss: 0.8443 - val_acc: 0.7611
2025-10-12 06:51:54,254 - INFO - _models.training_function_executor - Epoch 024/27 - train_loss: 0.6812 - val_loss: 0.8106 - val_acc: 0.7811
2025-10-12 06:52:11,997 - INFO - _models.training_function_executor - Epoch 025/27 - train_loss: 0.6739 - val_loss: 0.8352 - val_acc: 0.7670
2025-10-12 06:52:29,709 - INFO - _models.training_function_executor - Epoch 026/27 - train_loss: 0.6701 - val_loss: 0.9591 - val_acc: 0.7077
2025-10-12 06:52:47,412 - INFO - _models.training_function_executor - Epoch 027/27 - train_loss: 0.6660 - val_loss: 0.8117 - val_acc: 0.7683
2025-10-12 06:52:47,415 - INFO - _models.training_function_executor - Model: 90,049 parameters, 386.9KB storage
2025-10-12 06:52:47,415 - WARNING - _models.training_function_executor - Model storage 386.9KB exceeds 256KB limit!
2025-10-12 06:52:47,415 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1855998936131737, 0.9829255040600703, 0.9152295008526009, 0.8731693126884507, 0.8436689930943538, 0.8200787533182843, 0.8004682587239973, 0.7881754423548051, 0.7811529120084161, 0.7683873311973427, 0.7557719290976262, 0.7477921053407324, 0.7366952024475861, 0.7382135439688899, 0.7288184278769472, 0.7231096105169574, 0.7123082360010862, 0.7110469814912814, 0.6989273819205308, 0.6978703765840767, 0.6942406682063534, 0.6901359385936294, 0.6818638363260466, 0.6812236655841226, 0.6738955303218175, 0.6700907411965866, 0.665954658299382], 'val_losses': [1.0487261558688934, 0.9188662692513297, 0.9038019757776524, 0.8089811585564525, 0.9629898007970863, 0.850093723376147, 0.8088796131670121, 0.8475596114372431, 0.7769618106547627, 0.8208436867261959, 0.955311753572932, 0.8409053631958779, 0.7967547891145825, 0.7607578387784507, 0.8656773269280796, 0.7706815087382177, 0.8234886816635305, 0.7787373914433227, 0.8040650610870359, 0.8557581078100756, 0.8148343356539413, 0.7788504697578038, 0.8442793257970013, 0.8106104558921169, 0.8352151959352156, 0.9591165908074771, 0.8117401029290041], 'val_acc': [0.6299439971998599, 0.6982849142457123, 0.7072103605180259, 0.7533251662583129, 0.668358417920896, 0.7366993349667483, 0.7724886244312216, 0.7806265313265663, 0.7771263563178159, 0.745974798739937, 0.7037101855092754, 0.7553377668883444, 0.7760763038151908, 0.7962898144907246, 0.7372243612180609, 0.7975148757437872, 0.7577878893944697, 0.7866643332166608, 0.7909520476023801, 0.7798389919495975, 0.7885894294714736, 0.7868393419670984, 0.7611130556527826, 0.7810640532026601, 0.7669758487924396, 0.7077353867693384, 0.768288414420721], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00034001125241967206, 'batch_size': 8, 'epochs': 27, 'weight_decay': 1.2463170135730093e-06, 'dropout': 0.15083996740317215, 'base_channels': 19, 'temporal_kernel': 5, 'spatial_segments': 400, 'label_smoothing': 0.06002707818319767, 'grad_clip': 0.3440105024638404, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 4239}, 'model_parameter_count': 90049, 'model_storage_size_kb': 386.92929687500003, 'model_size_validation': 'FAIL'}
2025-10-12 06:52:47,415 - INFO - _models.training_function_executor - BO Objective: base=0.7683, size_penalty=0.2557, final=0.5126
2025-10-12 06:52:47,415 - INFO - _models.training_function_executor - Model: 90,049 parameters, 386.9KB (FAIL 256KB limit)
2025-10-12 06:52:47,415 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 478.065s
2025-10-12 06:52:47,524 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5126
2025-10-12 06:52:47,524 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-12 06:52:47,524 - INFO - bo.run_bo - Recorded observation #32: hparams={'lr': 0.00034001125241967206, 'batch_size': np.int64(8), 'epochs': np.int64(27), 'weight_decay': 1.2463170135730093e-06, 'dropout': 0.15083996740317215, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(400), 'label_smoothing': 0.06002707818319767, 'grad_clip': 0.3440105024638404, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(4239)}, value=0.5126
2025-10-12 06:52:47,524 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 32: {'lr': 0.00034001125241967206, 'batch_size': np.int64(8), 'epochs': np.int64(27), 'weight_decay': 1.2463170135730093e-06, 'dropout': 0.15083996740317215, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(400), 'label_smoothing': 0.06002707818319767, 'grad_clip': 0.3440105024638404, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(4239)} -> 0.5126
2025-10-12 06:52:47,525 - INFO - bo.run_bo - üîçBO Trial 33: Using RF surrogate + Expected Improvement
2025-10-12 06:52:47,525 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 06:52:47,525 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 06:52:47,525 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 06:52:47,525 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0005156929966807829, 'batch_size': 48, 'epochs': 26, 'weight_decay': 1.0675431149125032e-06, 'dropout': 0.03209278903021318, 'base_channels': 13, 'temporal_kernel': 9, 'spatial_segments': 200, 'label_smoothing': 0.015272798148069125, 'grad_clip': 0.5573455292479311, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1139}
2025-10-12 06:52:47,526 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0005156929966807829, 'batch_size': 48, 'epochs': 26, 'weight_decay': 1.0675431149125032e-06, 'dropout': 0.03209278903021318, 'base_channels': 13, 'temporal_kernel': 9, 'spatial_segments': 200, 'label_smoothing': 0.015272798148069125, 'grad_clip': 0.5573455292479311, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1139}
2025-10-12 06:52:58,979 - INFO - _models.training_function_executor - Epoch 001/26 - train_loss: 1.1404 - val_loss: 0.9038 - val_acc: 0.6546
2025-10-12 06:53:10,061 - INFO - _models.training_function_executor - Epoch 002/26 - train_loss: 0.8368 - val_loss: 0.8457 - val_acc: 0.6871
2025-10-12 06:53:21,184 - INFO - _models.training_function_executor - Epoch 003/26 - train_loss: 0.7447 - val_loss: 0.6992 - val_acc: 0.7444
2025-10-12 06:53:32,330 - INFO - _models.training_function_executor - Epoch 004/26 - train_loss: 0.7018 - val_loss: 0.7924 - val_acc: 0.7069
2025-10-12 06:53:43,452 - INFO - _models.training_function_executor - Epoch 005/26 - train_loss: 0.6683 - val_loss: 0.6983 - val_acc: 0.7434
2025-10-12 06:53:54,581 - INFO - _models.training_function_executor - Epoch 006/26 - train_loss: 0.6476 - val_loss: 0.6956 - val_acc: 0.7500
2025-10-12 06:54:05,729 - INFO - _models.training_function_executor - Epoch 007/26 - train_loss: 0.6247 - val_loss: 0.6076 - val_acc: 0.7787
2025-10-12 06:54:16,859 - INFO - _models.training_function_executor - Epoch 008/26 - train_loss: 0.6109 - val_loss: 0.6950 - val_acc: 0.7498
2025-10-12 06:54:28,009 - INFO - _models.training_function_executor - Epoch 009/26 - train_loss: 0.6010 - val_loss: 0.7016 - val_acc: 0.7451
2025-10-12 06:54:39,122 - INFO - _models.training_function_executor - Epoch 010/26 - train_loss: 0.5882 - val_loss: 0.6386 - val_acc: 0.7765
2025-10-12 06:54:50,234 - INFO - _models.training_function_executor - Epoch 011/26 - train_loss: 0.5803 - val_loss: 0.6620 - val_acc: 0.7633
2025-10-12 06:55:01,342 - INFO - _models.training_function_executor - Epoch 012/26 - train_loss: 0.5678 - val_loss: 0.9161 - val_acc: 0.6702
2025-10-12 06:55:12,471 - INFO - _models.training_function_executor - Epoch 013/26 - train_loss: 0.5596 - val_loss: 0.6469 - val_acc: 0.7775
2025-10-12 06:55:23,603 - INFO - _models.training_function_executor - Epoch 014/26 - train_loss: 0.5486 - val_loss: 0.6235 - val_acc: 0.7812
2025-10-12 06:55:34,716 - INFO - _models.training_function_executor - Epoch 015/26 - train_loss: 0.5436 - val_loss: 0.6274 - val_acc: 0.7780
2025-10-12 06:55:45,837 - INFO - _models.training_function_executor - Epoch 016/26 - train_loss: 0.5374 - val_loss: 0.6944 - val_acc: 0.7575
2025-10-12 06:55:56,992 - INFO - _models.training_function_executor - Epoch 017/26 - train_loss: 0.5327 - val_loss: 0.6233 - val_acc: 0.7834
2025-10-12 06:56:08,082 - INFO - _models.training_function_executor - Epoch 018/26 - train_loss: 0.5195 - val_loss: 0.6057 - val_acc: 0.7955
2025-10-12 06:56:19,202 - INFO - _models.training_function_executor - Epoch 019/26 - train_loss: 0.5168 - val_loss: 0.6083 - val_acc: 0.7942
2025-10-12 06:56:30,336 - INFO - _models.training_function_executor - Epoch 020/26 - train_loss: 0.5094 - val_loss: 0.8089 - val_acc: 0.7118
2025-10-12 06:56:41,458 - INFO - _models.training_function_executor - Epoch 021/26 - train_loss: 0.5055 - val_loss: 0.6276 - val_acc: 0.7900
2025-10-12 06:56:52,559 - INFO - _models.training_function_executor - Epoch 022/26 - train_loss: 0.4967 - val_loss: 0.6753 - val_acc: 0.7735
2025-10-12 06:57:03,690 - INFO - _models.training_function_executor - Epoch 023/26 - train_loss: 0.4932 - val_loss: 0.6647 - val_acc: 0.7777
2025-10-12 06:57:14,758 - INFO - _models.training_function_executor - Epoch 024/26 - train_loss: 0.4900 - val_loss: 0.6554 - val_acc: 0.7867
2025-10-12 06:57:25,887 - INFO - _models.training_function_executor - Epoch 025/26 - train_loss: 0.4860 - val_loss: 0.6650 - val_acc: 0.7792
2025-10-12 06:57:36,980 - INFO - _models.training_function_executor - Epoch 026/26 - train_loss: 0.4795 - val_loss: 0.7908 - val_acc: 0.7286
2025-10-12 06:57:36,983 - INFO - _models.training_function_executor - Model: 44,221 parameters, 95.0KB storage
2025-10-12 06:57:36,983 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1403802058518997, 0.8367947436397126, 0.7447176792006581, 0.7018475210412132, 0.6682634191743385, 0.647636731104038, 0.6247475657443881, 0.6108938682880442, 0.6010254951866097, 0.5881769909468989, 0.5803031665297459, 0.5678263600364114, 0.5596304892408793, 0.5486363854949025, 0.5436084543048063, 0.5374151618488193, 0.5326898848004887, 0.5195001008254396, 0.5167940043051176, 0.5093528427546117, 0.5054616395789592, 0.4967190005018196, 0.49321491838461207, 0.4899955933165792, 0.4860069289005508, 0.47949823389259466], 'val_losses': [0.9038176436836501, 0.8457239676406427, 0.6992076828027464, 0.7923558528163778, 0.6983343521155884, 0.6956081779678259, 0.6076157867261736, 0.6949603688082663, 0.7015632218441681, 0.63855859907432, 0.6619837631660197, 0.9161446932357719, 0.646892041145274, 0.6234952742700023, 0.6274381348687867, 0.6944320681402222, 0.6233135290733367, 0.6056649366124427, 0.6082905992203173, 0.808853703964662, 0.6275546667268738, 0.6752582074338254, 0.6647040772196042, 0.6553833069273922, 0.66504920371813, 0.7907518242199938], 'val_acc': [0.6546202310115505, 0.6870843542177109, 0.7443997199859993, 0.7069478473923696, 0.7434371718585929, 0.75, 0.7787014350717536, 0.7498249912495625, 0.7450997549877494, 0.7765138256912846, 0.7633006650332517, 0.67019600980049, 0.777476373818691, 0.7811515575778789, 0.7780014000700035, 0.7575253762688134, 0.7834266713335667, 0.7955022751137557, 0.7941897094854743, 0.7117605880294015, 0.7899894994749738, 0.7735386769338467, 0.7776513825691285, 0.7866643332166608, 0.7792264613230662, 0.7286489324466223], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0005156929966807829, 'batch_size': 48, 'epochs': 26, 'weight_decay': 1.0675431149125032e-06, 'dropout': 0.03209278903021318, 'base_channels': 13, 'temporal_kernel': 9, 'spatial_segments': 200, 'label_smoothing': 0.015272798148069125, 'grad_clip': 0.5573455292479311, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1139}, 'model_parameter_count': 44221, 'model_storage_size_kb': 95.00605468750001, 'model_size_validation': 'PASS'}
2025-10-12 06:57:36,983 - INFO - _models.training_function_executor - BO Objective: base=0.7286, size_penalty=0.0000, final=0.7286
2025-10-12 06:57:36,983 - INFO - _models.training_function_executor - Model: 44,221 parameters, 95.0KB (PASS 256KB limit)
2025-10-12 06:57:36,983 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 289.459s
2025-10-12 06:57:37,220 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7286
2025-10-12 06:57:37,220 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.231s
2025-10-12 06:57:37,220 - INFO - bo.run_bo - Recorded observation #33: hparams={'lr': 0.0005156929966807829, 'batch_size': np.int64(48), 'epochs': np.int64(26), 'weight_decay': 1.0675431149125032e-06, 'dropout': 0.03209278903021318, 'base_channels': np.int64(13), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(200), 'label_smoothing': 0.015272798148069125, 'grad_clip': 0.5573455292479311, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(1139)}, value=0.7286
2025-10-12 06:57:37,220 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 33: {'lr': 0.0005156929966807829, 'batch_size': np.int64(48), 'epochs': np.int64(26), 'weight_decay': 1.0675431149125032e-06, 'dropout': 0.03209278903021318, 'base_channels': np.int64(13), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(200), 'label_smoothing': 0.015272798148069125, 'grad_clip': 0.5573455292479311, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(1139)} -> 0.7286
2025-10-12 06:57:37,221 - INFO - bo.run_bo - üîçBO Trial 34: Using RF surrogate + Expected Improvement
2025-10-12 06:57:37,221 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 06:57:37,221 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 06:57:37,221 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 06:57:37,221 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009429570956379954, 'batch_size': 32, 'epochs': 46, 'weight_decay': 0.00037742268221044285, 'dropout': 0.01245578898238692, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 20, 'label_smoothing': 0.020939372146776686, 'grad_clip': 0.40373190201063136, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 3219}
2025-10-12 06:57:37,222 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009429570956379954, 'batch_size': 32, 'epochs': 46, 'weight_decay': 0.00037742268221044285, 'dropout': 0.01245578898238692, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 20, 'label_smoothing': 0.020939372146776686, 'grad_clip': 0.40373190201063136, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 3219}
2025-10-12 06:57:52,177 - INFO - _models.training_function_executor - Epoch 001/46 - train_loss: 1.0904 - val_loss: 1.1705 - val_acc: 0.5223
2025-10-12 06:58:06,648 - INFO - _models.training_function_executor - Epoch 002/46 - train_loss: 0.9119 - val_loss: 1.0091 - val_acc: 0.6104
2025-10-12 06:58:21,165 - INFO - _models.training_function_executor - Epoch 003/46 - train_loss: 0.7931 - val_loss: 0.8309 - val_acc: 0.6981
2025-10-12 06:58:35,680 - INFO - _models.training_function_executor - Epoch 004/46 - train_loss: 0.7438 - val_loss: 0.7820 - val_acc: 0.7142
2025-10-12 06:58:50,213 - INFO - _models.training_function_executor - Epoch 005/46 - train_loss: 0.7231 - val_loss: 0.6661 - val_acc: 0.7681
2025-10-12 06:59:04,743 - INFO - _models.training_function_executor - Epoch 006/46 - train_loss: 0.6982 - val_loss: 0.7266 - val_acc: 0.7587
2025-10-12 06:59:19,279 - INFO - _models.training_function_executor - Epoch 007/46 - train_loss: 0.6919 - val_loss: 0.6950 - val_acc: 0.7620
2025-10-12 06:59:33,792 - INFO - _models.training_function_executor - Epoch 008/46 - train_loss: 0.6844 - val_loss: 0.6588 - val_acc: 0.7704
2025-10-12 06:59:48,329 - INFO - _models.training_function_executor - Epoch 009/46 - train_loss: 0.6755 - val_loss: 0.6749 - val_acc: 0.7617
2025-10-12 07:00:02,836 - INFO - _models.training_function_executor - Epoch 010/46 - train_loss: 0.6581 - val_loss: 0.9146 - val_acc: 0.6847
2025-10-12 07:00:17,396 - INFO - _models.training_function_executor - Epoch 011/46 - train_loss: 0.6629 - val_loss: 0.7130 - val_acc: 0.7504
2025-10-12 07:00:31,897 - INFO - _models.training_function_executor - Epoch 012/46 - train_loss: 0.6557 - val_loss: 0.8352 - val_acc: 0.7099
2025-10-12 07:00:46,433 - INFO - _models.training_function_executor - Epoch 013/46 - train_loss: 0.6474 - val_loss: 0.6573 - val_acc: 0.7740
2025-10-12 07:01:00,938 - INFO - _models.training_function_executor - Epoch 014/46 - train_loss: 0.6404 - val_loss: 0.6605 - val_acc: 0.7773
2025-10-12 07:01:15,470 - INFO - _models.training_function_executor - Epoch 015/46 - train_loss: 0.6404 - val_loss: 0.6715 - val_acc: 0.7633
2025-10-12 07:01:29,969 - INFO - _models.training_function_executor - Epoch 016/46 - train_loss: 0.6370 - val_loss: 0.6870 - val_acc: 0.7623
2025-10-12 07:01:44,499 - INFO - _models.training_function_executor - Epoch 017/46 - train_loss: 0.6267 - val_loss: 0.6912 - val_acc: 0.7568
2025-10-12 07:01:59,055 - INFO - _models.training_function_executor - Epoch 018/46 - train_loss: 0.6257 - val_loss: 0.7598 - val_acc: 0.7276
2025-10-12 07:02:13,608 - INFO - _models.training_function_executor - Epoch 019/46 - train_loss: 0.6214 - val_loss: 0.7307 - val_acc: 0.7461
2025-10-12 07:02:28,116 - INFO - _models.training_function_executor - Epoch 020/46 - train_loss: 0.6238 - val_loss: 0.6582 - val_acc: 0.7857
2025-10-12 07:02:42,626 - INFO - _models.training_function_executor - Epoch 021/46 - train_loss: 0.6182 - val_loss: 0.7735 - val_acc: 0.7329
2025-10-12 07:02:57,141 - INFO - _models.training_function_executor - Epoch 022/46 - train_loss: 0.6162 - val_loss: 0.6645 - val_acc: 0.7801
2025-10-12 07:03:11,677 - INFO - _models.training_function_executor - Epoch 023/46 - train_loss: 0.6135 - val_loss: 0.7137 - val_acc: 0.7630
2025-10-12 07:03:26,211 - INFO - _models.training_function_executor - Epoch 024/46 - train_loss: 0.6080 - val_loss: 0.7530 - val_acc: 0.7404
2025-10-12 07:03:40,704 - INFO - _models.training_function_executor - Epoch 025/46 - train_loss: 0.6085 - val_loss: 0.5903 - val_acc: 0.8033
2025-10-12 07:03:55,240 - INFO - _models.training_function_executor - Epoch 026/46 - train_loss: 0.6018 - val_loss: 0.8196 - val_acc: 0.7302
2025-10-12 07:04:09,732 - INFO - _models.training_function_executor - Epoch 027/46 - train_loss: 0.6021 - val_loss: 0.7260 - val_acc: 0.7384
2025-10-12 07:04:24,267 - INFO - _models.training_function_executor - Epoch 028/46 - train_loss: 0.5979 - val_loss: 0.7787 - val_acc: 0.7377
2025-10-12 07:04:38,791 - INFO - _models.training_function_executor - Epoch 029/46 - train_loss: 0.5926 - val_loss: 0.7749 - val_acc: 0.7620
2025-10-12 07:04:53,387 - INFO - _models.training_function_executor - Epoch 030/46 - train_loss: 0.5937 - val_loss: 0.6109 - val_acc: 0.7856
2025-10-12 07:05:07,902 - INFO - _models.training_function_executor - Epoch 031/46 - train_loss: 0.5854 - val_loss: 0.6748 - val_acc: 0.7669
2025-10-12 07:05:22,412 - INFO - _models.training_function_executor - Epoch 032/46 - train_loss: 0.5838 - val_loss: 0.7421 - val_acc: 0.7446
2025-10-12 07:05:36,916 - INFO - _models.training_function_executor - Epoch 033/46 - train_loss: 0.5872 - val_loss: 0.6086 - val_acc: 0.7865
2025-10-12 07:05:51,445 - INFO - _models.training_function_executor - Epoch 034/46 - train_loss: 0.5788 - val_loss: 0.7061 - val_acc: 0.7560
2025-10-12 07:06:06,002 - INFO - _models.training_function_executor - Epoch 035/46 - train_loss: 0.5748 - val_loss: 0.6424 - val_acc: 0.7907
2025-10-12 07:06:20,526 - INFO - _models.training_function_executor - Epoch 036/46 - train_loss: 0.5743 - val_loss: 0.6727 - val_acc: 0.7753
2025-10-12 07:06:35,053 - INFO - _models.training_function_executor - Epoch 037/46 - train_loss: 0.5729 - val_loss: 0.7973 - val_acc: 0.7218
2025-10-12 07:06:49,560 - INFO - _models.training_function_executor - Epoch 038/46 - train_loss: 0.5661 - val_loss: 0.8119 - val_acc: 0.7205
2025-10-12 07:07:04,076 - INFO - _models.training_function_executor - Epoch 039/46 - train_loss: 0.5721 - val_loss: 0.6241 - val_acc: 0.7967
2025-10-12 07:07:18,610 - INFO - _models.training_function_executor - Epoch 040/46 - train_loss: 0.5672 - val_loss: 0.6286 - val_acc: 0.7839
2025-10-12 07:07:33,134 - INFO - _models.training_function_executor - Epoch 041/46 - train_loss: 0.5615 - val_loss: 0.6596 - val_acc: 0.7813
2025-10-12 07:07:47,678 - INFO - _models.training_function_executor - Epoch 042/46 - train_loss: 0.5626 - val_loss: 0.6944 - val_acc: 0.7670
2025-10-12 07:08:02,221 - INFO - _models.training_function_executor - Epoch 043/46 - train_loss: 0.5609 - val_loss: 0.6418 - val_acc: 0.7950
2025-10-12 07:08:16,748 - INFO - _models.training_function_executor - Epoch 044/46 - train_loss: 0.5529 - val_loss: 0.7138 - val_acc: 0.7563
2025-10-12 07:08:31,242 - INFO - _models.training_function_executor - Epoch 045/46 - train_loss: 0.5620 - val_loss: 0.8511 - val_acc: 0.7149
2025-10-12 07:08:45,743 - INFO - _models.training_function_executor - Epoch 046/46 - train_loss: 0.5509 - val_loss: 0.6639 - val_acc: 0.7735
2025-10-12 07:08:45,746 - INFO - _models.training_function_executor - Model: 53,341 parameters, 114.6KB storage
2025-10-12 07:08:45,746 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0904171800004214, 0.9118866073029585, 0.7930759250345788, 0.7438474888980159, 0.7230755004550679, 0.6981773157824075, 0.6918980751915499, 0.6843875655562134, 0.6754739327075225, 0.6580976113431889, 0.6629320294614184, 0.6556674413302164, 0.647417700182194, 0.6404053691929773, 0.6404420569471266, 0.6369848484170157, 0.626690930906275, 0.6256549792207118, 0.6213715206212334, 0.6237682034429404, 0.6181798450880882, 0.616192929011189, 0.6134674557239224, 0.608026885844462, 0.6084950362254908, 0.6017686699836204, 0.6021310170818385, 0.5979162770257281, 0.5925959865551208, 0.5936779759023671, 0.5853871855132431, 0.5837636642995147, 0.5872394672673525, 0.5788319126517363, 0.5748458292399163, 0.5742541371753761, 0.5729145420089985, 0.5661022029725831, 0.5721495109794438, 0.5672461444112359, 0.5614623430103199, 0.5625817035414515, 0.5609225306137067, 0.5529364476284866, 0.5620189245280411, 0.5509226112086998], 'val_losses': [1.1704824487458672, 1.0090741987490428, 0.8309005078920585, 0.7820062854926737, 0.6660928162486978, 0.7265935983948245, 0.6950138300229588, 0.6587886694514923, 0.6748857115964852, 0.9145942460334839, 0.7129551847581059, 0.8351890546774005, 0.6573204213207653, 0.6605448251551668, 0.67147162695385, 0.6870206637027008, 0.6912483621569918, 0.7597765949250603, 0.7306961369005416, 0.6581789217589408, 0.7735002158215549, 0.6644621107350457, 0.713749061848761, 0.7530026593573826, 0.5902550662152201, 0.8196025644727299, 0.7260232223344508, 0.7786764642513837, 0.7748661203154076, 0.610869704477429, 0.6748056657296776, 0.7420749604430781, 0.6085800778565392, 0.706064744307772, 0.6423823927973465, 0.6726732203749288, 0.7973018973533783, 0.8118856906014636, 0.6241106262856277, 0.6285658483222352, 0.6596212208083263, 0.6943838442794752, 0.6418167957067907, 0.7137956376421231, 0.8510659593237335, 0.66394906218001], 'val_acc': [0.522313615680784, 0.6104305215260764, 0.6981099054952747, 0.7142107105355268, 0.7681134056702835, 0.7586629331466573, 0.7619880994049703, 0.7703885194259713, 0.761725586279314, 0.6847217360868043, 0.7504375218760938, 0.7099229961498075, 0.7739761988099405, 0.7773013650682534, 0.7633006650332517, 0.7623381169058453, 0.7568253412670634, 0.7275988799439972, 0.7461498074903745, 0.7857017850892545, 0.7329366468323416, 0.7801015050752538, 0.7629506475323766, 0.7403745187259363, 0.8032901645082254, 0.73022401120056, 0.7384494224711236, 0.7376618830941547, 0.7619880994049703, 0.7856142807140357, 0.7668883444172209, 0.7445747287364368, 0.7864893244662233, 0.7560378018900945, 0.7906895344767239, 0.7752887644382219, 0.721823591179559, 0.7205110255512776, 0.7967273363668184, 0.7838641932096605, 0.7813265663283164, 0.7669758487924396, 0.7949772488624431, 0.7563003150157508, 0.7149107455372768, 0.7734511725586279], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009429570956379954, 'batch_size': 32, 'epochs': 46, 'weight_decay': 0.00037742268221044285, 'dropout': 0.01245578898238692, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 20, 'label_smoothing': 0.020939372146776686, 'grad_clip': 0.40373190201063136, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 3219}, 'model_parameter_count': 53341, 'model_storage_size_kb': 114.59980468750001, 'model_size_validation': 'PASS'}
2025-10-12 07:08:45,746 - INFO - _models.training_function_executor - BO Objective: base=0.7735, size_penalty=0.0000, final=0.7735
2025-10-12 07:08:45,746 - INFO - _models.training_function_executor - Model: 53,341 parameters, 114.6KB (PASS 256KB limit)
2025-10-12 07:08:45,746 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 668.525s
2025-10-12 07:08:45,863 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7735
2025-10-12 07:08:45,863 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-12 07:08:45,863 - INFO - bo.run_bo - Recorded observation #34: hparams={'lr': 0.009429570956379954, 'batch_size': np.int64(32), 'epochs': np.int64(46), 'weight_decay': 0.00037742268221044285, 'dropout': 0.01245578898238692, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(20), 'label_smoothing': 0.020939372146776686, 'grad_clip': 0.40373190201063136, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(3219)}, value=0.7735
2025-10-12 07:08:45,863 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 34: {'lr': 0.009429570956379954, 'batch_size': np.int64(32), 'epochs': np.int64(46), 'weight_decay': 0.00037742268221044285, 'dropout': 0.01245578898238692, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(20), 'label_smoothing': 0.020939372146776686, 'grad_clip': 0.40373190201063136, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(3219)} -> 0.7735
2025-10-12 07:08:45,864 - INFO - bo.run_bo - üîçBO Trial 35: Using RF surrogate + Expected Improvement
2025-10-12 07:08:45,864 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 07:08:45,864 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 07:08:45,864 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 07:08:45,864 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00140043502204734, 'batch_size': 48, 'epochs': 49, 'weight_decay': 1.2475316127241304e-06, 'dropout': 0.14391569226545495, 'base_channels': 19, 'temporal_kernel': 7, 'spatial_segments': 150, 'label_smoothing': 0.11010033359921143, 'grad_clip': 0.4716983294410113, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2047}
2025-10-12 07:08:45,865 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00140043502204734, 'batch_size': 48, 'epochs': 49, 'weight_decay': 1.2475316127241304e-06, 'dropout': 0.14391569226545495, 'base_channels': 19, 'temporal_kernel': 7, 'spatial_segments': 150, 'label_smoothing': 0.11010033359921143, 'grad_clip': 0.4716983294410113, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2047}
2025-10-12 07:09:00,550 - INFO - _models.training_function_executor - Epoch 001/49 - train_loss: 1.1678 - val_loss: 1.0325 - val_acc: 0.6787
2025-10-12 07:09:14,885 - INFO - _models.training_function_executor - Epoch 002/49 - train_loss: 0.9946 - val_loss: 1.0106 - val_acc: 0.6899
2025-10-12 07:09:29,174 - INFO - _models.training_function_executor - Epoch 003/49 - train_loss: 0.9409 - val_loss: 1.1018 - val_acc: 0.6454
2025-10-12 07:09:43,505 - INFO - _models.training_function_executor - Epoch 004/49 - train_loss: 0.9142 - val_loss: 0.9231 - val_acc: 0.7387
2025-10-12 07:09:57,825 - INFO - _models.training_function_executor - Epoch 005/49 - train_loss: 0.8915 - val_loss: 0.8990 - val_acc: 0.7481
2025-10-12 07:10:12,122 - INFO - _models.training_function_executor - Epoch 006/49 - train_loss: 0.8796 - val_loss: 0.8291 - val_acc: 0.7861
2025-10-12 07:10:26,453 - INFO - _models.training_function_executor - Epoch 007/49 - train_loss: 0.8688 - val_loss: 0.9604 - val_acc: 0.7226
2025-10-12 07:10:40,738 - INFO - _models.training_function_executor - Epoch 008/49 - train_loss: 0.8562 - val_loss: 0.9091 - val_acc: 0.7533
2025-10-12 07:10:55,061 - INFO - _models.training_function_executor - Epoch 009/49 - train_loss: 0.8535 - val_loss: 0.8390 - val_acc: 0.7796
2025-10-12 07:11:09,352 - INFO - _models.training_function_executor - Epoch 010/49 - train_loss: 0.8457 - val_loss: 0.8460 - val_acc: 0.7828
2025-10-12 07:11:23,642 - INFO - _models.training_function_executor - Epoch 011/49 - train_loss: 0.8368 - val_loss: 0.8127 - val_acc: 0.7983
2025-10-12 07:11:37,966 - INFO - _models.training_function_executor - Epoch 012/49 - train_loss: 0.8355 - val_loss: 0.8829 - val_acc: 0.7634
2025-10-12 07:11:52,283 - INFO - _models.training_function_executor - Epoch 013/49 - train_loss: 0.8259 - val_loss: 0.9154 - val_acc: 0.7432
2025-10-12 07:12:06,578 - INFO - _models.training_function_executor - Epoch 014/49 - train_loss: 0.8244 - val_loss: 0.7970 - val_acc: 0.8076
2025-10-12 07:12:20,874 - INFO - _models.training_function_executor - Epoch 015/49 - train_loss: 0.8185 - val_loss: 0.8703 - val_acc: 0.7707
2025-10-12 07:12:35,184 - INFO - _models.training_function_executor - Epoch 016/49 - train_loss: 0.8169 - val_loss: 0.9061 - val_acc: 0.7408
2025-10-12 07:12:49,517 - INFO - _models.training_function_executor - Epoch 017/49 - train_loss: 0.8125 - val_loss: 0.8782 - val_acc: 0.7651
2025-10-12 07:13:03,843 - INFO - _models.training_function_executor - Epoch 018/49 - train_loss: 0.8063 - val_loss: 0.8226 - val_acc: 0.7914
2025-10-12 07:13:18,119 - INFO - _models.training_function_executor - Epoch 019/49 - train_loss: 0.8038 - val_loss: 0.8356 - val_acc: 0.7864
2025-10-12 07:13:32,418 - INFO - _models.training_function_executor - Epoch 020/49 - train_loss: 0.7979 - val_loss: 0.8932 - val_acc: 0.7714
2025-10-12 07:13:46,763 - INFO - _models.training_function_executor - Epoch 021/49 - train_loss: 0.7963 - val_loss: 0.9016 - val_acc: 0.7525
2025-10-12 07:14:01,084 - INFO - _models.training_function_executor - Epoch 022/49 - train_loss: 0.7916 - val_loss: 0.8088 - val_acc: 0.7975
2025-10-12 07:14:15,371 - INFO - _models.training_function_executor - Epoch 023/49 - train_loss: 0.7897 - val_loss: 1.0344 - val_acc: 0.6750
2025-10-12 07:14:29,692 - INFO - _models.training_function_executor - Epoch 024/49 - train_loss: 0.7868 - val_loss: 0.8286 - val_acc: 0.7889
2025-10-12 07:14:43,986 - INFO - _models.training_function_executor - Epoch 025/49 - train_loss: 0.7854 - val_loss: 0.8165 - val_acc: 0.7909
2025-10-12 07:14:58,286 - INFO - _models.training_function_executor - Epoch 026/49 - train_loss: 0.7794 - val_loss: 0.8093 - val_acc: 0.7974
2025-10-12 07:15:12,638 - INFO - _models.training_function_executor - Epoch 027/49 - train_loss: 0.7802 - val_loss: 0.8037 - val_acc: 0.8029
2025-10-12 07:15:26,965 - INFO - _models.training_function_executor - Epoch 028/49 - train_loss: 0.7736 - val_loss: 0.8545 - val_acc: 0.7766
2025-10-12 07:15:41,293 - INFO - _models.training_function_executor - Epoch 029/49 - train_loss: 0.7737 - val_loss: 0.8013 - val_acc: 0.8100
2025-10-12 07:15:55,618 - INFO - _models.training_function_executor - Epoch 030/49 - train_loss: 0.7717 - val_loss: 0.9321 - val_acc: 0.7376
2025-10-12 07:16:09,930 - INFO - _models.training_function_executor - Epoch 031/49 - train_loss: 0.7656 - val_loss: 0.8182 - val_acc: 0.7974
2025-10-12 07:16:24,242 - INFO - _models.training_function_executor - Epoch 032/49 - train_loss: 0.7679 - val_loss: 0.8047 - val_acc: 0.8035
2025-10-12 07:16:38,538 - INFO - _models.training_function_executor - Epoch 033/49 - train_loss: 0.7640 - val_loss: 0.8121 - val_acc: 0.8042
2025-10-12 07:16:52,834 - INFO - _models.training_function_executor - Epoch 034/49 - train_loss: 0.7605 - val_loss: 0.8378 - val_acc: 0.7873
2025-10-12 07:17:07,141 - INFO - _models.training_function_executor - Epoch 035/49 - train_loss: 0.7587 - val_loss: 0.8460 - val_acc: 0.7857
2025-10-12 07:17:21,450 - INFO - _models.training_function_executor - Epoch 036/49 - train_loss: 0.7561 - val_loss: 0.8520 - val_acc: 0.7881
2025-10-12 07:17:35,783 - INFO - _models.training_function_executor - Epoch 037/49 - train_loss: 0.7544 - val_loss: 0.8375 - val_acc: 0.7874
2025-10-12 07:17:50,100 - INFO - _models.training_function_executor - Epoch 038/49 - train_loss: 0.7517 - val_loss: 0.8178 - val_acc: 0.7976
2025-10-12 07:18:04,432 - INFO - _models.training_function_executor - Epoch 039/49 - train_loss: 0.7494 - val_loss: 0.8142 - val_acc: 0.8028
2025-10-12 07:18:18,788 - INFO - _models.training_function_executor - Epoch 040/49 - train_loss: 0.7456 - val_loss: 0.8190 - val_acc: 0.8050
2025-10-12 07:18:33,113 - INFO - _models.training_function_executor - Epoch 041/49 - train_loss: 0.7474 - val_loss: 0.9744 - val_acc: 0.7267
2025-10-12 07:18:47,404 - INFO - _models.training_function_executor - Epoch 042/49 - train_loss: 0.7420 - val_loss: 1.0525 - val_acc: 0.6886
2025-10-12 07:19:01,731 - INFO - _models.training_function_executor - Epoch 043/49 - train_loss: 0.7415 - val_loss: 0.8837 - val_acc: 0.7686
2025-10-12 07:19:16,054 - INFO - _models.training_function_executor - Epoch 044/49 - train_loss: 0.7392 - val_loss: 0.8315 - val_acc: 0.7931
2025-10-12 07:19:30,358 - INFO - _models.training_function_executor - Epoch 045/49 - train_loss: 0.7340 - val_loss: 0.8475 - val_acc: 0.7884
2025-10-12 07:19:44,639 - INFO - _models.training_function_executor - Epoch 046/49 - train_loss: 0.7361 - val_loss: 0.8303 - val_acc: 0.7952
2025-10-12 07:19:58,982 - INFO - _models.training_function_executor - Epoch 047/49 - train_loss: 0.7306 - val_loss: 0.8076 - val_acc: 0.8103
2025-10-12 07:20:13,272 - INFO - _models.training_function_executor - Epoch 048/49 - train_loss: 0.7264 - val_loss: 0.8848 - val_acc: 0.7714
2025-10-12 07:20:27,580 - INFO - _models.training_function_executor - Epoch 049/49 - train_loss: 0.7279 - val_loss: 1.0609 - val_acc: 0.6941
2025-10-12 07:20:27,583 - INFO - _models.training_function_executor - Model: 66,277 parameters, 284.8KB storage
2025-10-12 07:20:27,583 - WARNING - _models.training_function_executor - Model storage 284.8KB exceeds 256KB limit!
2025-10-12 07:20:27,583 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1677814491528666, 0.9945785071326587, 0.9408787852573696, 0.9141528746403302, 0.8915191573991532, 0.8795854166374367, 0.8687827442132138, 0.8561642840269942, 0.853508609009657, 0.8456869139761453, 0.8368454779575536, 0.8354642911937047, 0.8258751989829611, 0.8243579784389304, 0.8184771253422586, 0.8169056252662144, 0.8124588291504018, 0.8063467973631331, 0.8037882620402887, 0.7978991561934045, 0.7962730808570162, 0.7915756880173034, 0.7896932265455588, 0.7867639345183087, 0.7854290215502596, 0.7793766735398691, 0.7802024386669315, 0.7735658144466853, 0.7736833381786353, 0.7716923560718995, 0.7656374865784944, 0.7678607049670969, 0.7640448088907971, 0.7604501722657602, 0.7587077885939184, 0.7561353757993132, 0.7544415160038274, 0.7517471962931442, 0.7493741349152514, 0.7456061417379704, 0.7473963954918528, 0.7419646024328451, 0.7414741459992702, 0.7391935362447005, 0.7339922067040032, 0.7360790894921944, 0.7305720587439332, 0.7264247664547401, 0.7278510172925381], 'val_losses': [1.032536902626286, 1.0106269254065243, 1.1017680945077641, 0.9230542300170562, 0.8990084929277649, 0.8290696469144384, 0.9603935922197749, 0.9090912483520428, 0.8390084027326061, 0.8460159576519161, 0.8127109354552916, 0.8828586849834187, 0.9154468938358855, 0.7969577655034504, 0.8702588437902873, 0.9061153787476723, 0.8782032457815002, 0.8226253254078968, 0.8356122227452791, 0.8931892519444488, 0.9015639674884688, 0.8087570133599777, 1.0343993744901898, 0.8286259615383742, 0.816534161379924, 0.8092702390390716, 0.8036803409566736, 0.8544826713065647, 0.8012665169698857, 0.9320796407266309, 0.8182464793799096, 0.8047444391050329, 0.8120889422523838, 0.837800741112228, 0.8459618336510983, 0.8519999701784005, 0.8374774821538128, 0.8178362643589371, 0.8141746354511997, 0.8189654567461144, 0.9744389415162821, 1.052499547929333, 0.8837135205287219, 0.8315024075075843, 0.8474875043479136, 0.8302838271174099, 0.8075510054607679, 0.8847927130265881, 1.0609336492895955], 'val_acc': [0.6786839341967098, 0.6898844942247112, 0.6454322716135806, 0.7387119355967798, 0.7480749037451873, 0.7860518025901295, 0.7226111305565278, 0.7533251662583129, 0.7795764788239412, 0.7828141407070354, 0.7983024151207561, 0.7633881694084704, 0.7431746587329366, 0.8075778788939447, 0.7707385369268464, 0.7408120406020301, 0.7650507525376269, 0.7913895694784739, 0.7864018200910046, 0.7713510675533777, 0.7524501225061253, 0.7975148757437872, 0.6750087504375218, 0.7888519425971299, 0.7908645432271614, 0.7974273713685684, 0.8028526426321316, 0.7766013300665033, 0.81002800140007, 0.7375743787189359, 0.7974273713685684, 0.803465173258663, 0.804165208260413, 0.7872768638431922, 0.7857017850892545, 0.788064403220161, 0.7873643682184109, 0.797602380119006, 0.8027651382569129, 0.8049527476373819, 0.7267238361918096, 0.6885719285964298, 0.7685509275463773, 0.7931396569828492, 0.7884144207210361, 0.7952397619880994, 0.8102905145257263, 0.7713510675533777, 0.6940847042352117], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00140043502204734, 'batch_size': 48, 'epochs': 49, 'weight_decay': 1.2475316127241304e-06, 'dropout': 0.14391569226545495, 'base_channels': 19, 'temporal_kernel': 7, 'spatial_segments': 150, 'label_smoothing': 0.11010033359921143, 'grad_clip': 0.4716983294410113, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2047}, 'model_parameter_count': 66277, 'model_storage_size_kb': 284.78398437500005, 'model_size_validation': 'FAIL'}
2025-10-12 07:20:27,583 - INFO - _models.training_function_executor - BO Objective: base=0.6941, size_penalty=0.0562, final=0.6379
2025-10-12 07:20:27,583 - INFO - _models.training_function_executor - Model: 66,277 parameters, 284.8KB (FAIL 256KB limit)
2025-10-12 07:20:27,583 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 701.720s
2025-10-12 07:20:27,704 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6379
2025-10-12 07:20:27,704 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-12 07:20:27,704 - INFO - bo.run_bo - Recorded observation #35: hparams={'lr': 0.00140043502204734, 'batch_size': np.int64(48), 'epochs': np.int64(49), 'weight_decay': 1.2475316127241304e-06, 'dropout': 0.14391569226545495, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(150), 'label_smoothing': 0.11010033359921143, 'grad_clip': 0.4716983294410113, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2047)}, value=0.6379
2025-10-12 07:20:27,704 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 35: {'lr': 0.00140043502204734, 'batch_size': np.int64(48), 'epochs': np.int64(49), 'weight_decay': 1.2475316127241304e-06, 'dropout': 0.14391569226545495, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(7), 'spatial_segments': np.int64(150), 'label_smoothing': 0.11010033359921143, 'grad_clip': 0.4716983294410113, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2047)} -> 0.6379
2025-10-12 07:20:27,704 - INFO - bo.run_bo - üîçBO Trial 36: Using RF surrogate + Expected Improvement
2025-10-12 07:20:27,704 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 07:20:27,704 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 07:20:27,704 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 07:20:27,704 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0008643411519974061, 'batch_size': 8, 'epochs': 50, 'weight_decay': 2.138224137190933e-06, 'dropout': 0.010341415363256614, 'base_channels': 16, 'temporal_kernel': 5, 'spatial_segments': 20, 'label_smoothing': 0.17377032905201595, 'grad_clip': 0.7201096028246935, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1356}
2025-10-12 07:20:27,706 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0008643411519974061, 'batch_size': 8, 'epochs': 50, 'weight_decay': 2.138224137190933e-06, 'dropout': 0.010341415363256614, 'base_channels': 16, 'temporal_kernel': 5, 'spatial_segments': 20, 'label_smoothing': 0.17377032905201595, 'grad_clip': 0.7201096028246935, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1356}
2025-10-12 07:20:43,690 - INFO - _models.training_function_executor - Epoch 001/50 - train_loss: 1.2589 - val_loss: 1.2338 - val_acc: 0.5929
2025-10-12 07:20:59,677 - INFO - _models.training_function_executor - Epoch 002/50 - train_loss: 1.1033 - val_loss: 1.0198 - val_acc: 0.7464
2025-10-12 07:21:15,528 - INFO - _models.training_function_executor - Epoch 003/50 - train_loss: 1.0480 - val_loss: 1.0217 - val_acc: 0.7385
2025-10-12 07:21:31,449 - INFO - _models.training_function_executor - Epoch 004/50 - train_loss: 1.0223 - val_loss: 0.9739 - val_acc: 0.7770
2025-10-12 07:21:47,370 - INFO - _models.training_function_executor - Epoch 005/50 - train_loss: 1.0017 - val_loss: 1.0269 - val_acc: 0.7381
2025-10-12 07:22:03,271 - INFO - _models.training_function_executor - Epoch 006/50 - train_loss: 0.9886 - val_loss: 1.0035 - val_acc: 0.7498
2025-10-12 07:22:19,158 - INFO - _models.training_function_executor - Epoch 007/50 - train_loss: 0.9776 - val_loss: 1.0198 - val_acc: 0.7377
2025-10-12 07:22:35,076 - INFO - _models.training_function_executor - Epoch 008/50 - train_loss: 0.9693 - val_loss: 0.9470 - val_acc: 0.7910
2025-10-12 07:22:50,975 - INFO - _models.training_function_executor - Epoch 009/50 - train_loss: 0.9631 - val_loss: 0.9420 - val_acc: 0.7850
2025-10-12 07:23:06,952 - INFO - _models.training_function_executor - Epoch 010/50 - train_loss: 0.9547 - val_loss: 0.9357 - val_acc: 0.7903
2025-10-12 07:23:22,849 - INFO - _models.training_function_executor - Epoch 011/50 - train_loss: 0.9501 - val_loss: 0.9476 - val_acc: 0.7868
2025-10-12 07:23:38,739 - INFO - _models.training_function_executor - Epoch 012/50 - train_loss: 0.9439 - val_loss: 0.9585 - val_acc: 0.7722
2025-10-12 07:23:54,649 - INFO - _models.training_function_executor - Epoch 013/50 - train_loss: 0.9412 - val_loss: 0.9789 - val_acc: 0.7628
2025-10-12 07:24:10,645 - INFO - _models.training_function_executor - Epoch 014/50 - train_loss: 0.9388 - val_loss: 0.9538 - val_acc: 0.7840
2025-10-12 07:24:26,618 - INFO - _models.training_function_executor - Epoch 015/50 - train_loss: 0.9345 - val_loss: 0.9905 - val_acc: 0.7508
2025-10-12 07:24:42,471 - INFO - _models.training_function_executor - Epoch 016/50 - train_loss: 0.9335 - val_loss: 1.0645 - val_acc: 0.7124
2025-10-12 07:24:58,365 - INFO - _models.training_function_executor - Epoch 017/50 - train_loss: 0.9287 - val_loss: 1.0222 - val_acc: 0.7287
2025-10-12 07:25:14,343 - INFO - _models.training_function_executor - Epoch 018/50 - train_loss: 0.9265 - val_loss: 0.9413 - val_acc: 0.7916
2025-10-12 07:25:30,283 - INFO - _models.training_function_executor - Epoch 019/50 - train_loss: 0.9221 - val_loss: 0.9721 - val_acc: 0.7763
2025-10-12 07:25:46,193 - INFO - _models.training_function_executor - Epoch 020/50 - train_loss: 0.9219 - val_loss: 0.9868 - val_acc: 0.7516
2025-10-12 07:26:02,069 - INFO - _models.training_function_executor - Epoch 021/50 - train_loss: 0.9176 - val_loss: 0.9374 - val_acc: 0.7908
2025-10-12 07:26:17,969 - INFO - _models.training_function_executor - Epoch 022/50 - train_loss: 0.9172 - val_loss: 0.9467 - val_acc: 0.7771
2025-10-12 07:26:33,892 - INFO - _models.training_function_executor - Epoch 023/50 - train_loss: 0.9160 - val_loss: 0.9602 - val_acc: 0.7816
2025-10-12 07:26:49,848 - INFO - _models.training_function_executor - Epoch 024/50 - train_loss: 0.9099 - val_loss: 1.0740 - val_acc: 0.6978
2025-10-12 07:27:05,818 - INFO - _models.training_function_executor - Epoch 025/50 - train_loss: 0.9121 - val_loss: 0.9309 - val_acc: 0.7984
2025-10-12 07:27:21,725 - INFO - _models.training_function_executor - Epoch 026/50 - train_loss: 0.9092 - val_loss: 0.9036 - val_acc: 0.8071
2025-10-12 07:27:37,664 - INFO - _models.training_function_executor - Epoch 027/50 - train_loss: 0.9050 - val_loss: 0.9337 - val_acc: 0.7903
2025-10-12 07:27:53,577 - INFO - _models.training_function_executor - Epoch 028/50 - train_loss: 0.9059 - val_loss: 0.9236 - val_acc: 0.7983
2025-10-12 07:28:09,525 - INFO - _models.training_function_executor - Epoch 029/50 - train_loss: 0.9025 - val_loss: 1.0362 - val_acc: 0.7374
2025-10-12 07:28:25,464 - INFO - _models.training_function_executor - Epoch 030/50 - train_loss: 0.8986 - val_loss: 0.9089 - val_acc: 0.8052
2025-10-12 07:28:41,420 - INFO - _models.training_function_executor - Epoch 031/50 - train_loss: 0.8976 - val_loss: 0.9643 - val_acc: 0.7786
2025-10-12 07:28:57,384 - INFO - _models.training_function_executor - Epoch 032/50 - train_loss: 0.8961 - val_loss: 0.9863 - val_acc: 0.7585
2025-10-12 07:29:13,328 - INFO - _models.training_function_executor - Epoch 033/50 - train_loss: 0.8964 - val_loss: 0.9325 - val_acc: 0.7950
2025-10-12 07:29:29,211 - INFO - _models.training_function_executor - Epoch 034/50 - train_loss: 0.8931 - val_loss: 1.0126 - val_acc: 0.7508
2025-10-12 07:29:45,135 - INFO - _models.training_function_executor - Epoch 035/50 - train_loss: 0.8908 - val_loss: 0.9176 - val_acc: 0.8007
2025-10-12 07:30:01,098 - INFO - _models.training_function_executor - Epoch 036/50 - train_loss: 0.8897 - val_loss: 1.0782 - val_acc: 0.6959
2025-10-12 07:30:16,997 - INFO - _models.training_function_executor - Epoch 037/50 - train_loss: 0.8903 - val_loss: 0.9201 - val_acc: 0.8059
2025-10-12 07:30:32,907 - INFO - _models.training_function_executor - Epoch 038/50 - train_loss: 0.8859 - val_loss: 0.9756 - val_acc: 0.7772
2025-10-12 07:30:48,860 - INFO - _models.training_function_executor - Epoch 039/50 - train_loss: 0.8860 - val_loss: 0.9544 - val_acc: 0.7837
2025-10-12 07:31:04,786 - INFO - _models.training_function_executor - Epoch 040/50 - train_loss: 0.8836 - val_loss: 0.9435 - val_acc: 0.7880
2025-10-12 07:31:20,742 - INFO - _models.training_function_executor - Epoch 041/50 - train_loss: 0.8846 - val_loss: 0.9145 - val_acc: 0.8034
2025-10-12 07:31:36,640 - INFO - _models.training_function_executor - Epoch 042/50 - train_loss: 0.8809 - val_loss: 0.9578 - val_acc: 0.7858
2025-10-12 07:31:52,542 - INFO - _models.training_function_executor - Epoch 043/50 - train_loss: 0.8805 - val_loss: 0.9203 - val_acc: 0.8058
2025-10-12 07:32:08,426 - INFO - _models.training_function_executor - Epoch 044/50 - train_loss: 0.8757 - val_loss: 0.9161 - val_acc: 0.8025
2025-10-12 07:32:24,421 - INFO - _models.training_function_executor - Epoch 045/50 - train_loss: 0.8772 - val_loss: 0.9104 - val_acc: 0.8063
2025-10-12 07:32:40,403 - INFO - _models.training_function_executor - Epoch 046/50 - train_loss: 0.8728 - val_loss: 1.0216 - val_acc: 0.7474
2025-10-12 07:32:56,353 - INFO - _models.training_function_executor - Epoch 047/50 - train_loss: 0.8726 - val_loss: 0.9875 - val_acc: 0.7689
2025-10-12 07:33:12,277 - INFO - _models.training_function_executor - Epoch 048/50 - train_loss: 0.8724 - val_loss: 0.9771 - val_acc: 0.7673
2025-10-12 07:33:28,136 - INFO - _models.training_function_executor - Epoch 049/50 - train_loss: 0.8690 - val_loss: 0.9980 - val_acc: 0.7569
2025-10-12 07:33:44,006 - INFO - _models.training_function_executor - Epoch 050/50 - train_loss: 0.8678 - val_loss: 0.9385 - val_acc: 0.7921
2025-10-12 07:33:44,008 - INFO - _models.training_function_executor - Model: 38,857 parameters, 83.5KB storage
2025-10-12 07:33:44,008 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2588677261732741, 1.1032682889339012, 1.0480441566130312, 1.0222526778384526, 1.0017224481713325, 0.9886387363988952, 0.9776418763918605, 0.9692895084588228, 0.9631218355061668, 0.9546917826823934, 0.9500555625986628, 0.9438792067492888, 0.9412407840116065, 0.9388488173630841, 0.9345139380118044, 0.9334796456490357, 0.9286834723285164, 0.9265092100699047, 0.9220551344160856, 0.9218666135096492, 0.9175829183379378, 0.9172352464164851, 0.9159950971874609, 0.9099312495592803, 0.9120631643554986, 0.9091846820959312, 0.9050041429116921, 0.9059066261847118, 0.9025372600780737, 0.8986112692888525, 0.8975588648854164, 0.8960907873174382, 0.8963847177863997, 0.8931042264089494, 0.8907771515479069, 0.8897036753587052, 0.8903313484649205, 0.8859268672761693, 0.8859609165181637, 0.8835710303054057, 0.8846147892397519, 0.8808621799858208, 0.8805080742363668, 0.8756744561180353, 0.877185569293106, 0.872799261210054, 0.8725993027939928, 0.8724187316909552, 0.8689529637294005, 0.8678198954964752], 'val_losses': [1.233761778401878, 1.019769380048392, 1.0216705262306316, 0.9738867007897457, 1.0269280357672945, 1.0035074095981373, 1.0198260285364484, 0.9470164592256903, 0.9420385507173709, 0.935663210957627, 0.9476497326024061, 0.9584818492830322, 0.9789327305849507, 0.9537926796728554, 0.990530850130401, 1.064516413637421, 1.02217469763664, 0.9412653280130666, 0.9721470757260121, 0.986795613450273, 0.9373697528356767, 0.9467014276693448, 0.9602278551522944, 1.0739577907676416, 0.9309324444195671, 0.9036033327945847, 0.9337310020557266, 0.9236384410936598, 1.0362403269284748, 0.9088561104067481, 0.9643402804558954, 0.9863163252414253, 0.9324541276344938, 1.012611897333043, 0.9176186627343604, 1.0782185118015637, 0.9201136794714482, 0.9756124363439584, 0.9544008347718583, 0.9435277094488842, 0.9145374432242663, 0.9578225056024378, 0.9202865559319579, 0.9161130720224671, 0.9104141695415136, 1.02162599855676, 0.987512606484597, 0.977097150534235, 0.9980203506618602, 0.938546714746831], 'val_acc': [0.5929296464823242, 0.7464123206160308, 0.7385369268463423, 0.7769513475673784, 0.7380994049702485, 0.7498249912495625, 0.7377493874693735, 0.7909520476023801, 0.7850017500875044, 0.79025201260063, 0.7868393419670984, 0.7722261113055653, 0.7627756387819391, 0.784039201960098, 0.7507875393769688, 0.7123731186559328, 0.7287364368218411, 0.7915645782289115, 0.776338816940847, 0.7515750787539377, 0.7907770388519426, 0.7771263563178159, 0.7815890794539727, 0.6978473923696185, 0.7983899194959748, 0.8071403570178509, 0.7903395169758488, 0.7983024151207561, 0.7373993699684984, 0.8052152607630382, 0.7786139306965348, 0.7584879243962198, 0.7949772488624431, 0.7507875393769688, 0.8006650332516626, 0.6959222961148057, 0.8059152957647883, 0.7772138606930347, 0.783689184459223, 0.7879768988449423, 0.8033776688834442, 0.7857892894644732, 0.8058277913895695, 0.8025026251312566, 0.8062653132656633, 0.7473748687434372, 0.7689009450472524, 0.7673258662933147, 0.7569128456422821, 0.792089604480224], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0008643411519974061, 'batch_size': 8, 'epochs': 50, 'weight_decay': 2.138224137190933e-06, 'dropout': 0.010341415363256614, 'base_channels': 16, 'temporal_kernel': 5, 'spatial_segments': 20, 'label_smoothing': 0.17377032905201595, 'grad_clip': 0.7201096028246935, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 1356}, 'model_parameter_count': 38857, 'model_storage_size_kb': 83.48183593750001, 'model_size_validation': 'PASS'}
2025-10-12 07:33:44,008 - INFO - _models.training_function_executor - BO Objective: base=0.7921, size_penalty=0.0000, final=0.7921
2025-10-12 07:33:44,008 - INFO - _models.training_function_executor - Model: 38,857 parameters, 83.5KB (PASS 256KB limit)
2025-10-12 07:33:44,008 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 796.304s
2025-10-12 07:33:44,120 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7921
2025-10-12 07:33:44,120 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-12 07:33:44,120 - INFO - bo.run_bo - Recorded observation #36: hparams={'lr': 0.0008643411519974061, 'batch_size': np.int64(8), 'epochs': np.int64(50), 'weight_decay': 2.138224137190933e-06, 'dropout': 0.010341415363256614, 'base_channels': np.int64(16), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(20), 'label_smoothing': 0.17377032905201595, 'grad_clip': 0.7201096028246935, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(1356)}, value=0.7921
2025-10-12 07:33:44,120 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 36: {'lr': 0.0008643411519974061, 'batch_size': np.int64(8), 'epochs': np.int64(50), 'weight_decay': 2.138224137190933e-06, 'dropout': 0.010341415363256614, 'base_channels': np.int64(16), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(20), 'label_smoothing': 0.17377032905201595, 'grad_clip': 0.7201096028246935, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(1356)} -> 0.7921
2025-10-12 07:33:44,120 - INFO - bo.run_bo - üîçBO Trial 37: Using RF surrogate + Expected Improvement
2025-10-12 07:33:44,120 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 07:33:44,120 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 07:33:44,120 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 07:33:44,120 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.012666468048047785, 'batch_size': 16, 'epochs': 47, 'weight_decay': 1.291414475557863e-06, 'dropout': 0.0007863162042012208, 'base_channels': 10, 'temporal_kernel': 3, 'spatial_segments': 50, 'label_smoothing': 0.14842457574922582, 'grad_clip': 0.150062331391033, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 5162}
2025-10-12 07:33:44,121 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.012666468048047785, 'batch_size': 16, 'epochs': 47, 'weight_decay': 1.291414475557863e-06, 'dropout': 0.0007863162042012208, 'base_channels': 10, 'temporal_kernel': 3, 'spatial_segments': 50, 'label_smoothing': 0.14842457574922582, 'grad_clip': 0.150062331391033, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 5162}
2025-10-12 07:33:54,989 - INFO - _models.training_function_executor - Epoch 001/47 - train_loss: 1.3248 - val_loss: 1.2513 - val_acc: 0.6017
2025-10-12 07:34:05,842 - INFO - _models.training_function_executor - Epoch 002/47 - train_loss: 1.2406 - val_loss: 1.4870 - val_acc: 0.5239
2025-10-12 07:34:16,660 - INFO - _models.training_function_executor - Epoch 003/47 - train_loss: 1.1981 - val_loss: 1.2619 - val_acc: 0.6605
2025-10-12 07:34:27,525 - INFO - _models.training_function_executor - Epoch 004/47 - train_loss: 1.1673 - val_loss: 1.2240 - val_acc: 0.6260
2025-10-12 07:34:38,396 - INFO - _models.training_function_executor - Epoch 005/47 - train_loss: 1.1376 - val_loss: 1.3343 - val_acc: 0.5719
2025-10-12 07:34:49,227 - INFO - _models.training_function_executor - Epoch 006/47 - train_loss: 1.1190 - val_loss: 1.0865 - val_acc: 0.7253
2025-10-12 07:35:00,081 - INFO - _models.training_function_executor - Epoch 007/47 - train_loss: 1.1025 - val_loss: 1.1815 - val_acc: 0.6973
2025-10-12 07:35:10,900 - INFO - _models.training_function_executor - Epoch 008/47 - train_loss: 1.0993 - val_loss: 1.2144 - val_acc: 0.6722
2025-10-12 07:35:21,755 - INFO - _models.training_function_executor - Epoch 009/47 - train_loss: 1.0989 - val_loss: 1.0270 - val_acc: 0.7383
2025-10-12 07:35:32,559 - INFO - _models.training_function_executor - Epoch 010/47 - train_loss: 1.0853 - val_loss: 1.1777 - val_acc: 0.7245
2025-10-12 07:35:43,373 - INFO - _models.training_function_executor - Epoch 011/47 - train_loss: 1.0934 - val_loss: 1.1149 - val_acc: 0.7207
2025-10-12 07:35:54,219 - INFO - _models.training_function_executor - Epoch 012/47 - train_loss: 1.0782 - val_loss: 1.0608 - val_acc: 0.7542
2025-10-12 07:36:05,006 - INFO - _models.training_function_executor - Epoch 013/47 - train_loss: 1.0607 - val_loss: 1.1677 - val_acc: 0.6684
2025-10-12 07:36:15,839 - INFO - _models.training_function_executor - Epoch 014/47 - train_loss: 1.0592 - val_loss: 1.1086 - val_acc: 0.7134
2025-10-12 07:36:26,642 - INFO - _models.training_function_executor - Epoch 015/47 - train_loss: 1.1273 - val_loss: 1.1653 - val_acc: 0.7381
2025-10-12 07:36:37,442 - INFO - _models.training_function_executor - Epoch 016/47 - train_loss: 1.0467 - val_loss: 0.9970 - val_acc: 0.7648
2025-10-12 07:36:48,193 - INFO - _models.training_function_executor - Epoch 017/47 - train_loss: 1.0582 - val_loss: 1.1606 - val_acc: 0.6975
2025-10-12 07:36:59,052 - INFO - _models.training_function_executor - Epoch 018/47 - train_loss: 1.0710 - val_loss: 1.1277 - val_acc: 0.6755
2025-10-12 07:37:09,864 - INFO - _models.training_function_executor - Epoch 019/47 - train_loss: 1.0708 - val_loss: 1.0924 - val_acc: 0.7301
2025-10-12 07:37:20,692 - INFO - _models.training_function_executor - Epoch 020/47 - train_loss: 1.0357 - val_loss: 1.1984 - val_acc: 0.6483
2025-10-12 07:37:31,503 - INFO - _models.training_function_executor - Epoch 021/47 - train_loss: 1.0574 - val_loss: 1.1287 - val_acc: 0.6960
2025-10-12 07:37:42,323 - INFO - _models.training_function_executor - Epoch 022/47 - train_loss: 1.0303 - val_loss: 1.2348 - val_acc: 0.6522
2025-10-12 07:37:53,219 - INFO - _models.training_function_executor - Epoch 023/47 - train_loss: 1.0414 - val_loss: 1.2932 - val_acc: 0.6619
2025-10-12 07:38:04,070 - INFO - _models.training_function_executor - Epoch 024/47 - train_loss: 1.0406 - val_loss: 1.1177 - val_acc: 0.7605
2025-10-12 07:38:14,923 - INFO - _models.training_function_executor - Epoch 025/47 - train_loss: 1.0519 - val_loss: 1.2255 - val_acc: 0.6365
2025-10-12 07:38:25,721 - INFO - _models.training_function_executor - Epoch 026/47 - train_loss: 1.0474 - val_loss: 1.2448 - val_acc: 0.7689
2025-10-12 07:38:36,526 - INFO - _models.training_function_executor - Epoch 027/47 - train_loss: 1.0556 - val_loss: 1.0124 - val_acc: 0.7693
2025-10-12 07:38:47,348 - INFO - _models.training_function_executor - Epoch 028/47 - train_loss: 1.0535 - val_loss: 1.2186 - val_acc: 0.7202
2025-10-12 07:38:58,182 - INFO - _models.training_function_executor - Epoch 029/47 - train_loss: 1.0224 - val_loss: 1.0290 - val_acc: 0.7412
2025-10-12 07:39:09,050 - INFO - _models.training_function_executor - Epoch 030/47 - train_loss: 1.0494 - val_loss: 1.0488 - val_acc: 0.7602
2025-10-12 07:39:19,874 - INFO - _models.training_function_executor - Epoch 031/47 - train_loss: 1.0510 - val_loss: 1.2534 - val_acc: 0.6820
2025-10-12 07:39:30,662 - INFO - _models.training_function_executor - Epoch 032/47 - train_loss: 1.0827 - val_loss: 1.1864 - val_acc: 0.7525
2025-10-12 07:39:41,463 - INFO - _models.training_function_executor - Epoch 033/47 - train_loss: 1.0868 - val_loss: 1.2426 - val_acc: 0.7455
2025-10-12 07:39:52,330 - INFO - _models.training_function_executor - Epoch 034/47 - train_loss: 1.0551 - val_loss: 1.0655 - val_acc: 0.7684
2025-10-12 07:40:03,162 - INFO - _models.training_function_executor - Epoch 035/47 - train_loss: 1.0658 - val_loss: 1.2314 - val_acc: 0.6745
2025-10-12 07:40:14,030 - INFO - _models.training_function_executor - Epoch 036/47 - train_loss: 1.0401 - val_loss: 1.3662 - val_acc: 0.6171
2025-10-12 07:40:24,853 - INFO - _models.training_function_executor - Epoch 037/47 - train_loss: 1.0402 - val_loss: 1.2137 - val_acc: 0.7264
2025-10-12 07:40:35,699 - INFO - _models.training_function_executor - Epoch 038/47 - train_loss: 1.0791 - val_loss: 1.0273 - val_acc: 0.7735
2025-10-12 07:40:46,494 - INFO - _models.training_function_executor - Epoch 039/47 - train_loss: 1.0736 - val_loss: 1.1683 - val_acc: 0.7623
2025-10-12 07:40:57,274 - INFO - _models.training_function_executor - Epoch 040/47 - train_loss: 1.0950 - val_loss: 1.0761 - val_acc: 0.7357
2025-10-12 07:41:08,078 - INFO - _models.training_function_executor - Epoch 041/47 - train_loss: 1.0471 - val_loss: 1.0798 - val_acc: 0.7379
2025-10-12 07:41:18,870 - INFO - _models.training_function_executor - Epoch 042/47 - train_loss: 1.0692 - val_loss: 1.2196 - val_acc: 0.6852
2025-10-12 07:41:29,744 - INFO - _models.training_function_executor - Epoch 043/47 - train_loss: 1.0640 - val_loss: 1.6527 - val_acc: 0.7506
2025-10-12 07:41:40,568 - INFO - _models.training_function_executor - Epoch 044/47 - train_loss: 1.0449 - val_loss: 1.2129 - val_acc: 0.7242
2025-10-12 07:41:51,350 - INFO - _models.training_function_executor - Epoch 045/47 - train_loss: 1.0764 - val_loss: 1.2832 - val_acc: 0.6924
2025-10-12 07:42:02,101 - INFO - _models.training_function_executor - Epoch 046/47 - train_loss: 1.0707 - val_loss: 0.9987 - val_acc: 0.7754
2025-10-12 07:42:12,914 - INFO - _models.training_function_executor - Epoch 047/47 - train_loss: 1.0476 - val_loss: 1.2501 - val_acc: 0.7015
2025-10-12 07:42:12,916 - INFO - _models.training_function_executor - Model: 19,645 parameters, 42.2KB storage
2025-10-12 07:42:12,917 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3247568930075808, 1.2406476866877658, 1.1981261819861841, 1.167303011911417, 1.137633706436818, 1.1189962704990308, 1.1024753347868514, 1.0993084424143702, 1.0989375743450382, 1.085312004956408, 1.0934399303790778, 1.078228470763419, 1.0606616366397763, 1.059247245144335, 1.1272524906323012, 1.0467079812135986, 1.0582113013761545, 1.0709614732860475, 1.0707622746049335, 1.0356683457360887, 1.0574441493120819, 1.0303134967448788, 1.0414108400541793, 1.0405627082685178, 1.0519469531633072, 1.0474240197808249, 1.055555353057856, 1.053543151634992, 1.0223553795308804, 1.0494237950852088, 1.0509978180003408, 1.0826930877083367, 1.0867821992716258, 1.0550967967088798, 1.0657591245831164, 1.0401404089430308, 1.0402435037820206, 1.0791313963876057, 1.073625134866806, 1.094956214126691, 1.0470764947847173, 1.0692217129279067, 1.064014235075262, 1.0448756009955735, 1.0763571155751381, 1.0707417429849573, 1.0476103519325204], 'val_losses': [1.2512636275236366, 1.486957529019258, 1.2618640526884037, 1.2239593186076387, 1.33425225859386, 1.0864973054885196, 1.1815254036095912, 1.2143718635322416, 1.026963859952994, 1.1776685059216625, 1.1149436404415474, 1.0607569999614712, 1.1676761540742366, 1.1086278034750299, 1.165348967097212, 0.9970357005396714, 1.1606426827758185, 1.1277399508319703, 1.0923832584019928, 1.1983637535200697, 1.128710020014069, 1.2348102553140294, 1.293178567946437, 1.1177410758538893, 1.2255429829130817, 1.2447549350035536, 1.0123719731577219, 1.218558818508705, 1.0289724458544915, 1.04878992874972, 1.2533646773574316, 1.1864473116243475, 1.2426106686728962, 1.0655363402585278, 1.2313910547486127, 1.366231331676714, 1.213671027925576, 1.027324096656655, 1.1683097063013836, 1.0761121239827403, 1.0797935767652773, 1.219645467470441, 1.652742403055097, 1.2129080350222936, 1.2831677226157383, 0.9987366290454645, 1.2501105256209142], 'val_acc': [0.6016800840042003, 0.5238886944347217, 0.6604830241512075, 0.6260063003150157, 0.5719285964298215, 0.7253237661883094, 0.6973223661183059, 0.6722086104305215, 0.738274413720686, 0.7245362268113406, 0.7206860343017151, 0.7542002100105005, 0.668358417920896, 0.7134231711585579, 0.7380994049702485, 0.7647882394119706, 0.6974973748687434, 0.6755337766888344, 0.7301365068253413, 0.6483199159957997, 0.6960098004900245, 0.6521701085054252, 0.6618830941547077, 0.7605005250262513, 0.636506825341267, 0.7689009450472524, 0.7693384669233462, 0.7202485124256213, 0.7411620581029051, 0.760238011900595, 0.6820091004550227, 0.7525376268813441, 0.7455372768638432, 0.7683759187959398, 0.6744837241862093, 0.6170808540427022, 0.7263738186909345, 0.7734511725586279, 0.7622506125306265, 0.735736786839342, 0.737924396219811, 0.6852467623381169, 0.7506125306265313, 0.7241862093104655, 0.6924221211060553, 0.7753762688134407, 0.7015225761288064], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.012666468048047785, 'batch_size': 16, 'epochs': 47, 'weight_decay': 1.291414475557863e-06, 'dropout': 0.0007863162042012208, 'base_channels': 10, 'temporal_kernel': 3, 'spatial_segments': 50, 'label_smoothing': 0.14842457574922582, 'grad_clip': 0.150062331391033, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 5162}, 'model_parameter_count': 19645, 'model_storage_size_kb': 42.2060546875, 'model_size_validation': 'PASS'}
2025-10-12 07:42:12,917 - INFO - _models.training_function_executor - BO Objective: base=0.7015, size_penalty=0.0000, final=0.7015
2025-10-12 07:42:12,917 - INFO - _models.training_function_executor - Model: 19,645 parameters, 42.2KB (PASS 256KB limit)
2025-10-12 07:42:12,917 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 508.796s
2025-10-12 07:42:13,028 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7015
2025-10-12 07:42:13,028 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-12 07:42:13,028 - INFO - bo.run_bo - Recorded observation #37: hparams={'lr': 0.012666468048047785, 'batch_size': np.int64(16), 'epochs': np.int64(47), 'weight_decay': 1.291414475557863e-06, 'dropout': 0.0007863162042012208, 'base_channels': np.int64(10), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(50), 'label_smoothing': 0.14842457574922582, 'grad_clip': 0.150062331391033, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(5162)}, value=0.7015
2025-10-12 07:42:13,028 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 37: {'lr': 0.012666468048047785, 'batch_size': np.int64(16), 'epochs': np.int64(47), 'weight_decay': 1.291414475557863e-06, 'dropout': 0.0007863162042012208, 'base_channels': np.int64(10), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(50), 'label_smoothing': 0.14842457574922582, 'grad_clip': 0.150062331391033, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(5162)} -> 0.7015
2025-10-12 07:42:13,028 - INFO - bo.run_bo - üîçBO Trial 38: Using RF surrogate + Expected Improvement
2025-10-12 07:42:13,028 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 07:42:13,029 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 07:42:13,029 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 07:42:13,029 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.014058974140761118, 'batch_size': 8, 'epochs': 47, 'weight_decay': 4.1021465402640175e-06, 'dropout': 0.004280976836186002, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 50, 'label_smoothing': 0.0957395628132924, 'grad_clip': 0.5447215478021078, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7889}
2025-10-12 07:42:13,030 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.014058974140761118, 'batch_size': 8, 'epochs': 47, 'weight_decay': 4.1021465402640175e-06, 'dropout': 0.004280976836186002, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 50, 'label_smoothing': 0.0957395628132924, 'grad_clip': 0.5447215478021078, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7889}
2025-10-12 07:42:31,356 - INFO - _models.training_function_executor - Epoch 001/47 - train_loss: 1.5355 - val_loss: 1.2589 - val_acc: 0.5753
2025-10-12 07:42:49,705 - INFO - _models.training_function_executor - Epoch 002/47 - train_loss: 1.4363 - val_loss: 1.4089 - val_acc: 0.5778
2025-10-12 07:43:08,052 - INFO - _models.training_function_executor - Epoch 003/47 - train_loss: 1.3734 - val_loss: 2.0413 - val_acc: 0.4047
2025-10-12 07:43:26,380 - INFO - _models.training_function_executor - Epoch 004/47 - train_loss: 1.3671 - val_loss: 1.4901 - val_acc: 0.5725
2025-10-12 07:43:44,696 - INFO - _models.training_function_executor - Epoch 005/47 - train_loss: 1.3892 - val_loss: 1.5306 - val_acc: 0.6483
2025-10-12 07:44:03,050 - INFO - _models.training_function_executor - Epoch 006/47 - train_loss: 1.3835 - val_loss: 1.2691 - val_acc: 0.5867
2025-10-12 07:44:21,409 - INFO - _models.training_function_executor - Epoch 007/47 - train_loss: 1.3578 - val_loss: 1.6321 - val_acc: 0.5122
2025-10-12 07:44:39,766 - INFO - _models.training_function_executor - Epoch 008/47 - train_loss: 1.3338 - val_loss: 1.8045 - val_acc: 0.4990
2025-10-12 07:44:58,082 - INFO - _models.training_function_executor - Epoch 009/47 - train_loss: 1.3508 - val_loss: 1.7996 - val_acc: 0.6228
2025-10-12 07:45:16,414 - INFO - _models.training_function_executor - Epoch 010/47 - train_loss: 1.3241 - val_loss: 1.4789 - val_acc: 0.6452
2025-10-12 07:45:34,801 - INFO - _models.training_function_executor - Epoch 011/47 - train_loss: 1.2787 - val_loss: 1.2828 - val_acc: 0.6793
2025-10-12 07:45:53,139 - INFO - _models.training_function_executor - Epoch 012/47 - train_loss: 1.3547 - val_loss: 1.3203 - val_acc: 0.6931
2025-10-12 07:46:11,512 - INFO - _models.training_function_executor - Epoch 013/47 - train_loss: 1.3598 - val_loss: 1.2173 - val_acc: 0.6827
2025-10-12 07:46:29,888 - INFO - _models.training_function_executor - Epoch 014/47 - train_loss: 1.3602 - val_loss: 1.4515 - val_acc: 0.6551
2025-10-12 07:46:48,273 - INFO - _models.training_function_executor - Epoch 015/47 - train_loss: 1.4261 - val_loss: 1.8269 - val_acc: 0.6577
2025-10-12 07:47:06,625 - INFO - _models.training_function_executor - Epoch 016/47 - train_loss: 1.3133 - val_loss: 1.8422 - val_acc: 0.6986
2025-10-12 07:47:24,914 - INFO - _models.training_function_executor - Epoch 017/47 - train_loss: 1.3906 - val_loss: 1.4320 - val_acc: 0.6994
2025-10-12 07:47:43,262 - INFO - _models.training_function_executor - Epoch 018/47 - train_loss: 1.3336 - val_loss: 3.1503 - val_acc: 0.6333
2025-10-12 07:48:01,535 - INFO - _models.training_function_executor - Epoch 019/47 - train_loss: 1.3956 - val_loss: 1.5239 - val_acc: 0.7295
2025-10-12 07:48:19,913 - INFO - _models.training_function_executor - Epoch 020/47 - train_loss: 1.3463 - val_loss: 1.6317 - val_acc: 0.6715
2025-10-12 07:48:38,265 - INFO - _models.training_function_executor - Epoch 021/47 - train_loss: 1.3422 - val_loss: 1.7629 - val_acc: 0.7210
2025-10-12 07:48:56,597 - INFO - _models.training_function_executor - Epoch 022/47 - train_loss: 1.3737 - val_loss: 1.3787 - val_acc: 0.6760
2025-10-12 07:49:14,981 - INFO - _models.training_function_executor - Epoch 023/47 - train_loss: 1.3504 - val_loss: 1.9400 - val_acc: 0.7069
2025-10-12 07:49:33,371 - INFO - _models.training_function_executor - Epoch 024/47 - train_loss: 1.5352 - val_loss: 1.4816 - val_acc: 0.7069
2025-10-12 07:49:51,714 - INFO - _models.training_function_executor - Epoch 025/47 - train_loss: 1.4221 - val_loss: 1.7723 - val_acc: 0.7327
2025-10-12 07:50:10,003 - INFO - _models.training_function_executor - Epoch 026/47 - train_loss: 1.4469 - val_loss: 1.4593 - val_acc: 0.7197
2025-10-12 07:50:28,403 - INFO - _models.training_function_executor - Epoch 027/47 - train_loss: 1.3441 - val_loss: 2.0213 - val_acc: 0.7377
2025-10-12 07:50:46,723 - INFO - _models.training_function_executor - Epoch 028/47 - train_loss: 1.4417 - val_loss: 1.2273 - val_acc: 0.7351
2025-10-12 07:51:05,030 - INFO - _models.training_function_executor - Epoch 029/47 - train_loss: 1.5284 - val_loss: 1.6245 - val_acc: 0.7320
2025-10-12 07:51:23,402 - INFO - _models.training_function_executor - Epoch 030/47 - train_loss: 1.4513 - val_loss: 1.2276 - val_acc: 0.6905
2025-10-12 07:51:41,808 - INFO - _models.training_function_executor - Epoch 031/47 - train_loss: 1.4482 - val_loss: 1.5909 - val_acc: 0.6964
2025-10-12 07:52:00,129 - INFO - _models.training_function_executor - Epoch 032/47 - train_loss: 1.4696 - val_loss: 1.4391 - val_acc: 0.7331
2025-10-12 07:52:18,532 - INFO - _models.training_function_executor - Epoch 033/47 - train_loss: 1.4984 - val_loss: 1.7815 - val_acc: 0.7468
2025-10-12 07:52:36,802 - INFO - _models.training_function_executor - Epoch 034/47 - train_loss: 1.4606 - val_loss: 1.7360 - val_acc: 0.7246
2025-10-12 07:52:55,154 - INFO - _models.training_function_executor - Epoch 035/47 - train_loss: 1.5127 - val_loss: 1.8447 - val_acc: 0.7466
2025-10-12 07:53:13,520 - INFO - _models.training_function_executor - Epoch 036/47 - train_loss: 1.6579 - val_loss: 1.2881 - val_acc: 0.7645
2025-10-12 07:53:31,875 - INFO - _models.training_function_executor - Epoch 037/47 - train_loss: 1.4839 - val_loss: 1.3215 - val_acc: 0.7528
2025-10-12 07:53:50,163 - INFO - _models.training_function_executor - Epoch 038/47 - train_loss: 1.4169 - val_loss: 2.0752 - val_acc: 0.7361
2025-10-12 07:54:08,575 - INFO - _models.training_function_executor - Epoch 039/47 - train_loss: 1.8017 - val_loss: 1.5933 - val_acc: 0.7069
2025-10-12 07:54:26,900 - INFO - _models.training_function_executor - Epoch 040/47 - train_loss: 1.7242 - val_loss: 1.4223 - val_acc: 0.7525
2025-10-12 07:54:45,262 - INFO - _models.training_function_executor - Epoch 041/47 - train_loss: 1.5582 - val_loss: 1.9391 - val_acc: 0.7511
2025-10-12 07:55:03,574 - INFO - _models.training_function_executor - Epoch 042/47 - train_loss: 1.4759 - val_loss: 1.6294 - val_acc: 0.7434
2025-10-12 07:55:21,866 - INFO - _models.training_function_executor - Epoch 043/47 - train_loss: 1.4953 - val_loss: 1.3036 - val_acc: 0.7465
2025-10-12 07:55:40,249 - INFO - _models.training_function_executor - Epoch 044/47 - train_loss: 1.5939 - val_loss: 1.1967 - val_acc: 0.7403
2025-10-12 07:55:58,551 - INFO - _models.training_function_executor - Epoch 045/47 - train_loss: 1.8814 - val_loss: 1.4084 - val_acc: 0.7468
2025-10-12 07:56:16,901 - INFO - _models.training_function_executor - Epoch 046/47 - train_loss: 1.5930 - val_loss: 2.1452 - val_acc: 0.7353
2025-10-12 07:56:35,257 - INFO - _models.training_function_executor - Epoch 047/47 - train_loss: 1.5449 - val_loss: 1.5470 - val_acc: 0.7435
2025-10-12 07:56:41,496 - INFO - _models.training_function_executor - Model: 17,802 parameters, 19.1KB storage
2025-10-12 07:56:41,496 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.535460596271107, 1.4363493653269217, 1.373401919903353, 1.367139506223196, 1.3892319526420343, 1.3834947285626709, 1.3577568918821232, 1.3338168040152651, 1.3507657423589376, 1.3241307595767549, 1.2786895980107271, 1.3547000619010738, 1.3598336363520955, 1.3602014783330425, 1.4260893123870468, 1.313326683647782, 1.3905685774285683, 1.3336321978582384, 1.395616088671454, 1.346336220308622, 1.3421533413969389, 1.373677476541663, 1.3503947337586686, 1.5351847790737105, 1.4220848279865963, 1.4469132868505918, 1.3441133799359313, 1.4417482856419856, 1.5284462926591824, 1.4512952420160325, 1.4482076175518708, 1.4695906529309326, 1.4983812573649142, 1.460610148823883, 1.5126693250365637, 1.6579323522185878, 1.4839087603004153, 1.4169364593685778, 1.8017345030156724, 1.7242331121365924, 1.5582065693108318, 1.4759494172846641, 1.4953199674094688, 1.593939375467429, 1.881372094436004, 1.5930269379423012, 1.544912505085167], 'val_losses': [1.258909007782781, 1.4088754960611896, 2.0412863646723567, 1.490069526890837, 1.5306271751068004, 1.2691193855972944, 1.6321008437406694, 1.8045284513163742, 1.7995855142113042, 1.478910340476712, 1.2827976159503671, 1.320273250018044, 1.2173118384768173, 1.451538480325391, 1.8269467551390275, 1.8422395024822857, 1.4319836601202915, 3.150269343338106, 1.5239065547777215, 1.6316654505869872, 1.7629011838971045, 1.3787138940656274, 1.939952480509267, 1.4815822668037175, 1.7723357561254651, 1.4593137285698532, 2.0212715400195767, 1.2272782320737587, 1.6244529478817833, 1.2276046082695589, 1.5908882434984835, 1.4390752691883786, 1.7814641524579586, 1.735953961880757, 1.844695033207614, 1.288115706170903, 1.3214661423710206, 2.0751732227307413, 1.5932988912691217, 1.4223073026622388, 1.9390839897630763, 1.6293557046133194, 1.3035735962980897, 1.1966976192726053, 1.4084101433223222, 2.145195648809559, 1.5469750007591674], 'val_acc': [0.5752537626881344, 0.5777913895694785, 0.40470773538676935, 0.5724536226811341, 0.6483199159957997, 0.5867168358417921, 0.5121631081554078, 0.49903745187259363, 0.6227686384319217, 0.6451697584879243, 0.6792964648232411, 0.6931221561078054, 0.6827091354567728, 0.6551452572628631, 0.6576828841442072, 0.6986349317465873, 0.6994224711235562, 0.6332691634581729, 0.7295239761988099, 0.6715085754287714, 0.7210360518025901, 0.6759712985649282, 0.7069478473923696, 0.7068603430171508, 0.7326741337066853, 0.7197234861743087, 0.7377493874693735, 0.7351242562128106, 0.7319740987049352, 0.6904970248512425, 0.6963598179908995, 0.7331116555827791, 0.7468498424921246, 0.7246237311865593, 0.7465873293664683, 0.7645257262863143, 0.7528001400070004, 0.736086804340217, 0.7069478473923696, 0.7525376268813441, 0.7511375568778439, 0.7434371718585929, 0.7464998249912496, 0.7402870143507175, 0.7467623381169058, 0.7352992649632482, 0.7435246762338117], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.014058974140761118, 'batch_size': 8, 'epochs': 47, 'weight_decay': 4.1021465402640175e-06, 'dropout': 0.004280976836186002, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 50, 'label_smoothing': 0.0957395628132924, 'grad_clip': 0.5447215478021078, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 7889}, 'model_parameter_count': 17802, 'model_storage_size_kb': 19.1232421875, 'model_size_validation': 'PASS'}
2025-10-12 07:56:41,496 - INFO - _models.training_function_executor - BO Objective: base=0.7435, size_penalty=0.0000, final=0.7435
2025-10-12 07:56:41,496 - INFO - _models.training_function_executor - Model: 17,802 parameters, 19.1KB (PASS 256KB limit)
2025-10-12 07:56:41,496 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 868.468s
2025-10-12 07:56:41,610 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7435
2025-10-12 07:56:41,610 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.112s
2025-10-12 07:56:41,610 - INFO - bo.run_bo - Recorded observation #38: hparams={'lr': 0.014058974140761118, 'batch_size': np.int64(8), 'epochs': np.int64(47), 'weight_decay': 4.1021465402640175e-06, 'dropout': 0.004280976836186002, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(50), 'label_smoothing': 0.0957395628132924, 'grad_clip': 0.5447215478021078, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(7889)}, value=0.7435
2025-10-12 07:56:41,610 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 38: {'lr': 0.014058974140761118, 'batch_size': np.int64(8), 'epochs': np.int64(47), 'weight_decay': 4.1021465402640175e-06, 'dropout': 0.004280976836186002, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(50), 'label_smoothing': 0.0957395628132924, 'grad_clip': 0.5447215478021078, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(7889)} -> 0.7435
2025-10-12 07:56:41,610 - INFO - bo.run_bo - üîçBO Trial 39: Using RF surrogate + Expected Improvement
2025-10-12 07:56:41,610 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 07:56:41,610 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 07:56:41,610 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 07:56:41,610 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0009328280838946776, 'batch_size': 8, 'epochs': 21, 'weight_decay': 4.356660449157678e-05, 'dropout': 0.004639038458441603, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 750, 'label_smoothing': 0.053002285933778925, 'grad_clip': 0.4788444997844956, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6929}
2025-10-12 07:56:41,611 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0009328280838946776, 'batch_size': 8, 'epochs': 21, 'weight_decay': 4.356660449157678e-05, 'dropout': 0.004639038458441603, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 750, 'label_smoothing': 0.053002285933778925, 'grad_clip': 0.4788444997844956, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6929}
2025-10-12 07:56:59,228 - INFO - _models.training_function_executor - Epoch 001/21 - train_loss: 1.2009 - val_loss: 1.1243 - val_acc: 0.5811
2025-10-12 07:57:16,828 - INFO - _models.training_function_executor - Epoch 002/21 - train_loss: 0.9577 - val_loss: 0.9217 - val_acc: 0.7003
2025-10-12 07:57:34,413 - INFO - _models.training_function_executor - Epoch 003/21 - train_loss: 0.8348 - val_loss: 0.7661 - val_acc: 0.7643
2025-10-12 07:57:52,047 - INFO - _models.training_function_executor - Epoch 004/21 - train_loss: 0.7984 - val_loss: 0.7396 - val_acc: 0.7737
2025-10-12 07:58:09,673 - INFO - _models.training_function_executor - Epoch 005/21 - train_loss: 0.7772 - val_loss: 0.7547 - val_acc: 0.7751
2025-10-12 07:58:27,422 - INFO - _models.training_function_executor - Epoch 006/21 - train_loss: 0.7665 - val_loss: 0.7267 - val_acc: 0.7804
2025-10-12 07:58:45,166 - INFO - _models.training_function_executor - Epoch 007/21 - train_loss: 0.7544 - val_loss: 0.7832 - val_acc: 0.7624
2025-10-12 07:59:02,776 - INFO - _models.training_function_executor - Epoch 008/21 - train_loss: 0.7472 - val_loss: 0.7577 - val_acc: 0.7631
2025-10-12 07:59:20,392 - INFO - _models.training_function_executor - Epoch 009/21 - train_loss: 0.7374 - val_loss: 0.7308 - val_acc: 0.7800
2025-10-12 07:59:38,113 - INFO - _models.training_function_executor - Epoch 010/21 - train_loss: 0.7300 - val_loss: 0.7361 - val_acc: 0.7723
2025-10-12 07:59:55,751 - INFO - _models.training_function_executor - Epoch 011/21 - train_loss: 0.7202 - val_loss: 0.7555 - val_acc: 0.7778
2025-10-12 08:00:13,466 - INFO - _models.training_function_executor - Epoch 012/21 - train_loss: 0.7128 - val_loss: 0.7693 - val_acc: 0.7643
2025-10-12 08:00:31,084 - INFO - _models.training_function_executor - Epoch 013/21 - train_loss: 0.6982 - val_loss: 0.7405 - val_acc: 0.7833
2025-10-12 08:00:48,685 - INFO - _models.training_function_executor - Epoch 014/21 - train_loss: 0.6940 - val_loss: 0.8132 - val_acc: 0.7717
2025-10-12 08:01:06,355 - INFO - _models.training_function_executor - Epoch 015/21 - train_loss: 0.6776 - val_loss: 0.7764 - val_acc: 0.7745
2025-10-12 08:01:24,020 - INFO - _models.training_function_executor - Epoch 016/21 - train_loss: 0.6651 - val_loss: 0.7823 - val_acc: 0.7678
2025-10-12 08:01:41,756 - INFO - _models.training_function_executor - Epoch 017/21 - train_loss: 0.6600 - val_loss: 1.0428 - val_acc: 0.6755
2025-10-12 08:01:59,483 - INFO - _models.training_function_executor - Epoch 018/21 - train_loss: 0.6453 - val_loss: 0.8396 - val_acc: 0.7734
2025-10-12 08:02:17,147 - INFO - _models.training_function_executor - Epoch 019/21 - train_loss: 0.6367 - val_loss: 0.8331 - val_acc: 0.7634
2025-10-12 08:02:34,713 - INFO - _models.training_function_executor - Epoch 020/21 - train_loss: 0.6256 - val_loss: 0.9051 - val_acc: 0.7369
2025-10-12 08:02:52,381 - INFO - _models.training_function_executor - Epoch 021/21 - train_loss: 0.6102 - val_loss: 0.8560 - val_acc: 0.7704
2025-10-12 08:02:52,384 - INFO - _models.training_function_executor - Model: 118,469 parameters, 254.5KB storage
2025-10-12 08:02:52,384 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2008793209977695, 0.957702138393043, 0.8348374336509384, 0.7984032396215386, 0.7772381818864076, 0.7665026868854238, 0.7543679548386389, 0.7471693613216682, 0.7374376139212706, 0.7300237355102474, 0.7201938861351894, 0.7127851209087225, 0.6982396633882894, 0.6940332355566445, 0.6776370415330392, 0.6651239192460774, 0.6599874116707232, 0.6453081138554594, 0.6367206694072554, 0.625638501989203, 0.6101809087743032], 'val_losses': [1.1242832386247503, 0.9217033473645051, 0.76611051684207, 0.7395743804250016, 0.7546555488769684, 0.7267314087355683, 0.7832293217107889, 0.7577171259548934, 0.7307942363403875, 0.7360767962259139, 0.7555041281981697, 0.7692600484907439, 0.7404967267737758, 0.8132213032408365, 0.7763953273597614, 0.7823125680489351, 1.0427540756102245, 0.839577138309175, 0.8331201806283723, 0.9050953233204482, 0.8560405055834858], 'val_acc': [0.5811165558277914, 0.7002975148757438, 0.764263213160658, 0.7737136856842842, 0.7751137556877844, 0.7803640182009101, 0.7624256212810641, 0.7631256562828141, 0.780014000700035, 0.772313615680784, 0.777826391319566, 0.764263213160658, 0.7833391669583479, 0.7717010850542527, 0.7745012250612531, 0.7677633881694085, 0.6755337766888344, 0.7733636681834092, 0.7633881694084704, 0.7368743437171859, 0.7703885194259713], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0009328280838946776, 'batch_size': 8, 'epochs': 21, 'weight_decay': 4.356660449157678e-05, 'dropout': 0.004639038458441603, 'base_channels': 18, 'temporal_kernel': 5, 'spatial_segments': 750, 'label_smoothing': 0.053002285933778925, 'grad_clip': 0.4788444997844956, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 6929}, 'model_parameter_count': 118469, 'model_storage_size_kb': 254.52324218750002, 'model_size_validation': 'PASS'}
2025-10-12 08:02:52,384 - INFO - _models.training_function_executor - BO Objective: base=0.7704, size_penalty=0.0000, final=0.7704
2025-10-12 08:02:52,384 - INFO - _models.training_function_executor - Model: 118,469 parameters, 254.5KB (PASS 256KB limit)
2025-10-12 08:02:52,384 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 370.774s
2025-10-12 08:02:52,499 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7704
2025-10-12 08:02:52,499 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.113s
2025-10-12 08:02:52,499 - INFO - bo.run_bo - Recorded observation #39: hparams={'lr': 0.0009328280838946776, 'batch_size': np.int64(8), 'epochs': np.int64(21), 'weight_decay': 4.356660449157678e-05, 'dropout': 0.004639038458441603, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(750), 'label_smoothing': 0.053002285933778925, 'grad_clip': 0.4788444997844956, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(6929)}, value=0.7704
2025-10-12 08:02:52,499 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 39: {'lr': 0.0009328280838946776, 'batch_size': np.int64(8), 'epochs': np.int64(21), 'weight_decay': 4.356660449157678e-05, 'dropout': 0.004639038458441603, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(750), 'label_smoothing': 0.053002285933778925, 'grad_clip': 0.4788444997844956, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(6929)} -> 0.7704
2025-10-12 08:02:52,499 - INFO - bo.run_bo - üîçBO Trial 40: Using RF surrogate + Expected Improvement
2025-10-12 08:02:52,499 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 08:02:52,500 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 08:02:52,500 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 08:02:52,500 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 5.8859420198068066e-05, 'batch_size': 8, 'epochs': 27, 'weight_decay': 1.6667818945140607e-06, 'dropout': 0.1477048875562196, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 200, 'label_smoothing': 0.05448408611310255, 'grad_clip': 0.41499961431333565, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 8011}
2025-10-12 08:02:52,501 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 5.8859420198068066e-05, 'batch_size': 8, 'epochs': 27, 'weight_decay': 1.6667818945140607e-06, 'dropout': 0.1477048875562196, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 200, 'label_smoothing': 0.05448408611310255, 'grad_clip': 0.41499961431333565, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 8011}
2025-10-12 08:03:09,790 - INFO - _models.training_function_executor - Epoch 001/27 - train_loss: 1.4592 - val_loss: 1.3774 - val_acc: 0.4034
2025-10-12 08:03:27,073 - INFO - _models.training_function_executor - Epoch 002/27 - train_loss: 1.1969 - val_loss: 1.1186 - val_acc: 0.6004
2025-10-12 08:03:44,308 - INFO - _models.training_function_executor - Epoch 003/27 - train_loss: 1.1064 - val_loss: 0.9978 - val_acc: 0.6901
2025-10-12 08:04:01,529 - INFO - _models.training_function_executor - Epoch 004/27 - train_loss: 1.0318 - val_loss: 1.0279 - val_acc: 0.6406
2025-10-12 08:04:18,664 - INFO - _models.training_function_executor - Epoch 005/27 - train_loss: 0.9850 - val_loss: 1.0146 - val_acc: 0.6740
2025-10-12 08:04:35,907 - INFO - _models.training_function_executor - Epoch 006/27 - train_loss: 0.9456 - val_loss: 0.9375 - val_acc: 0.7079
2025-10-12 08:04:53,086 - INFO - _models.training_function_executor - Epoch 007/27 - train_loss: 0.9185 - val_loss: 0.9985 - val_acc: 0.6459
2025-10-12 08:05:10,408 - INFO - _models.training_function_executor - Epoch 008/27 - train_loss: 0.8925 - val_loss: 0.9412 - val_acc: 0.7068
2025-10-12 08:05:27,679 - INFO - _models.training_function_executor - Epoch 009/27 - train_loss: 0.8770 - val_loss: 0.9930 - val_acc: 0.6562
2025-10-12 08:05:44,882 - INFO - _models.training_function_executor - Epoch 010/27 - train_loss: 0.8612 - val_loss: 0.8929 - val_acc: 0.7096
2025-10-12 08:06:02,067 - INFO - _models.training_function_executor - Epoch 011/27 - train_loss: 0.8419 - val_loss: 0.8992 - val_acc: 0.7163
2025-10-12 08:06:19,308 - INFO - _models.training_function_executor - Epoch 012/27 - train_loss: 0.8303 - val_loss: 0.8158 - val_acc: 0.7575
2025-10-12 08:06:36,559 - INFO - _models.training_function_executor - Epoch 013/27 - train_loss: 0.8192 - val_loss: 0.9916 - val_acc: 0.6341
2025-10-12 08:06:53,798 - INFO - _models.training_function_executor - Epoch 014/27 - train_loss: 0.8105 - val_loss: 0.7904 - val_acc: 0.7622
2025-10-12 08:07:11,111 - INFO - _models.training_function_executor - Epoch 015/27 - train_loss: 0.7994 - val_loss: 0.9561 - val_acc: 0.6719
2025-10-12 08:07:28,469 - INFO - _models.training_function_executor - Epoch 016/27 - train_loss: 0.7904 - val_loss: 0.7492 - val_acc: 0.7722
2025-10-12 08:07:45,779 - INFO - _models.training_function_executor - Epoch 017/27 - train_loss: 0.7820 - val_loss: 0.7997 - val_acc: 0.7596
2025-10-12 08:08:03,069 - INFO - _models.training_function_executor - Epoch 018/27 - train_loss: 0.7761 - val_loss: 0.7959 - val_acc: 0.7594
2025-10-12 08:08:20,294 - INFO - _models.training_function_executor - Epoch 019/27 - train_loss: 0.7690 - val_loss: 0.7594 - val_acc: 0.7688
2025-10-12 08:08:37,602 - INFO - _models.training_function_executor - Epoch 020/27 - train_loss: 0.7584 - val_loss: 1.2696 - val_acc: 0.5319
2025-10-12 08:08:54,835 - INFO - _models.training_function_executor - Epoch 021/27 - train_loss: 0.7549 - val_loss: 0.7722 - val_acc: 0.7734
2025-10-12 08:09:12,072 - INFO - _models.training_function_executor - Epoch 022/27 - train_loss: 0.7500 - val_loss: 0.9727 - val_acc: 0.6634
2025-10-12 08:09:29,280 - INFO - _models.training_function_executor - Epoch 023/27 - train_loss: 0.7467 - val_loss: 0.7482 - val_acc: 0.7819
2025-10-12 08:09:46,584 - INFO - _models.training_function_executor - Epoch 024/27 - train_loss: 0.7401 - val_loss: 0.7353 - val_acc: 0.7824
2025-10-12 08:10:03,882 - INFO - _models.training_function_executor - Epoch 025/27 - train_loss: 0.7368 - val_loss: 0.9767 - val_acc: 0.6708
2025-10-12 08:10:21,148 - INFO - _models.training_function_executor - Epoch 026/27 - train_loss: 0.7294 - val_loss: 1.0223 - val_acc: 0.6559
2025-10-12 08:10:38,437 - INFO - _models.training_function_executor - Epoch 027/27 - train_loss: 0.7272 - val_loss: 0.8523 - val_acc: 0.7267
2025-10-12 08:10:38,443 - INFO - _models.training_function_executor - Model: 45,576 parameters, 49.0KB storage
2025-10-12 08:10:38,443 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4591701744234473, 1.1968584546351875, 1.1064309434516053, 1.031767624124264, 0.9849574190776667, 0.9456249771259613, 0.9184506771904127, 0.8924550261370653, 0.8769536616973707, 0.8612073812142176, 0.8419076292601172, 0.8303189798433296, 0.8192276659704899, 0.8105419577784917, 0.7993916108771392, 0.7903829450671139, 0.782017697591568, 0.7761368520784762, 0.7690250074368988, 0.7584481085560979, 0.7548884978536797, 0.7500392311846914, 0.746735003091966, 0.7400621202626677, 0.7368466709099911, 0.7293629506364918, 0.7272344896029375], 'val_losses': [1.3773672646227775, 1.11858576554955, 0.9977593716934172, 1.0279001879199718, 1.014620128235368, 0.9374515538996736, 0.9984840158611734, 0.9412222590152726, 0.9930152704885133, 0.8929058849331712, 0.8991766557811981, 0.8158303126197284, 0.9915943286157715, 0.7903910310046424, 0.9561183915131568, 0.7491666890229635, 0.7996954243104692, 0.7958920045795247, 0.7593606814538677, 1.269556259812698, 0.7722022812559257, 0.972675302331582, 0.7481703953722952, 0.7352548240885102, 0.9766855232774857, 1.0223192886994108, 0.8522624610435892], 'val_acc': [0.40339516975848794, 0.6003675183759188, 0.6901470073503675, 0.6406195309765488, 0.6739586979348967, 0.707910395519776, 0.6458697934896744, 0.7067728386419321, 0.6561953097654882, 0.7095729786489324, 0.716310815540777, 0.7575253762688134, 0.6340567028351417, 0.7621631081554078, 0.6718585929296464, 0.7722261113055653, 0.7596254812740637, 0.7593629681484074, 0.7688134406720336, 0.5319390969548478, 0.7733636681834092, 0.6633706685334266, 0.7819390969548478, 0.7823766188309416, 0.6708085404270213, 0.655932796639832, 0.7267238361918096], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 5.8859420198068066e-05, 'batch_size': 8, 'epochs': 27, 'weight_decay': 1.6667818945140607e-06, 'dropout': 0.1477048875562196, 'base_channels': 18, 'temporal_kernel': 3, 'spatial_segments': 200, 'label_smoothing': 0.05448408611310255, 'grad_clip': 0.41499961431333565, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 8011}, 'model_parameter_count': 45576, 'model_storage_size_kb': 48.958593750000006, 'model_size_validation': 'PASS'}
2025-10-12 08:10:38,443 - INFO - _models.training_function_executor - BO Objective: base=0.7267, size_penalty=0.0000, final=0.7267
2025-10-12 08:10:38,443 - INFO - _models.training_function_executor - Model: 45,576 parameters, 49.0KB (PASS 256KB limit)
2025-10-12 08:10:38,443 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 465.944s
2025-10-12 08:10:38,559 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7267
2025-10-12 08:10:38,559 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.114s
2025-10-12 08:10:38,559 - INFO - bo.run_bo - Recorded observation #40: hparams={'lr': 5.8859420198068066e-05, 'batch_size': np.int64(8), 'epochs': np.int64(27), 'weight_decay': 1.6667818945140607e-06, 'dropout': 0.1477048875562196, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(200), 'label_smoothing': 0.05448408611310255, 'grad_clip': 0.41499961431333565, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(8011)}, value=0.7267
2025-10-12 08:10:38,559 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 40: {'lr': 5.8859420198068066e-05, 'batch_size': np.int64(8), 'epochs': np.int64(27), 'weight_decay': 1.6667818945140607e-06, 'dropout': 0.1477048875562196, 'base_channels': np.int64(18), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(200), 'label_smoothing': 0.05448408611310255, 'grad_clip': 0.41499961431333565, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(8011)} -> 0.7267
2025-10-12 08:10:38,560 - INFO - bo.run_bo - üîçBO Trial 41: Using RF surrogate + Expected Improvement
2025-10-12 08:10:38,560 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 08:10:38,560 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 08:10:38,560 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 08:10:38,560 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0017603597552497813, 'batch_size': 32, 'epochs': 48, 'weight_decay': 1.981883098673564e-06, 'dropout': 0.14199476217447485, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 125, 'label_smoothing': 0.15113228200837586, 'grad_clip': 0.6246269681701558, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 1564}
2025-10-12 08:10:38,561 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0017603597552497813, 'batch_size': 32, 'epochs': 48, 'weight_decay': 1.981883098673564e-06, 'dropout': 0.14199476217447485, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 125, 'label_smoothing': 0.15113228200837586, 'grad_clip': 0.6246269681701558, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 1564}
2025-10-12 08:10:53,137 - INFO - _models.training_function_executor - Epoch 001/48 - train_loss: 1.1838 - val_loss: 1.2202 - val_acc: 0.5972
2025-10-12 08:11:07,730 - INFO - _models.training_function_executor - Epoch 002/48 - train_loss: 1.0460 - val_loss: 2.4802 - val_acc: 0.3211
2025-10-12 08:11:22,273 - INFO - _models.training_function_executor - Epoch 003/48 - train_loss: 1.0051 - val_loss: 0.9841 - val_acc: 0.7398
2025-10-12 08:11:36,866 - INFO - _models.training_function_executor - Epoch 004/48 - train_loss: 0.9724 - val_loss: 0.9423 - val_acc: 0.7602
2025-10-12 08:11:51,460 - INFO - _models.training_function_executor - Epoch 005/48 - train_loss: 0.9623 - val_loss: 0.9561 - val_acc: 0.7653
2025-10-12 08:12:06,005 - INFO - _models.training_function_executor - Epoch 006/48 - train_loss: 0.9530 - val_loss: 1.2305 - val_acc: 0.6054
2025-10-12 08:12:20,565 - INFO - _models.training_function_executor - Epoch 007/48 - train_loss: 0.9442 - val_loss: 0.9100 - val_acc: 0.7852
2025-10-12 08:12:35,163 - INFO - _models.training_function_executor - Epoch 008/48 - train_loss: 0.9377 - val_loss: 1.2222 - val_acc: 0.6261
2025-10-12 08:12:49,728 - INFO - _models.training_function_executor - Epoch 009/48 - train_loss: 0.9310 - val_loss: 1.2255 - val_acc: 0.6082
2025-10-12 08:13:04,317 - INFO - _models.training_function_executor - Epoch 010/48 - train_loss: 0.9297 - val_loss: 1.1651 - val_acc: 0.6251
2025-10-12 08:13:18,893 - INFO - _models.training_function_executor - Epoch 011/48 - train_loss: 0.9249 - val_loss: 1.0015 - val_acc: 0.7216
2025-10-12 08:13:33,474 - INFO - _models.training_function_executor - Epoch 012/48 - train_loss: 0.9199 - val_loss: 0.8868 - val_acc: 0.7924
2025-10-12 08:13:48,079 - INFO - _models.training_function_executor - Epoch 013/48 - train_loss: 0.9154 - val_loss: 0.9497 - val_acc: 0.7651
2025-10-12 08:14:02,636 - INFO - _models.training_function_executor - Epoch 014/48 - train_loss: 0.9122 - val_loss: 0.8753 - val_acc: 0.8005
2025-10-12 08:14:17,198 - INFO - _models.training_function_executor - Epoch 015/48 - train_loss: 0.9114 - val_loss: 0.8714 - val_acc: 0.8043
2025-10-12 08:14:31,777 - INFO - _models.training_function_executor - Epoch 016/48 - train_loss: 0.9043 - val_loss: 1.1701 - val_acc: 0.6652
2025-10-12 08:14:46,292 - INFO - _models.training_function_executor - Epoch 017/48 - train_loss: 0.9022 - val_loss: 0.8713 - val_acc: 0.8046
2025-10-12 08:15:00,896 - INFO - _models.training_function_executor - Epoch 018/48 - train_loss: 0.8978 - val_loss: 0.8720 - val_acc: 0.8039
2025-10-12 08:15:15,460 - INFO - _models.training_function_executor - Epoch 019/48 - train_loss: 0.8967 - val_loss: 0.9485 - val_acc: 0.7625
2025-10-12 08:15:29,995 - INFO - _models.training_function_executor - Epoch 020/48 - train_loss: 0.8943 - val_loss: 0.9327 - val_acc: 0.7706
2025-10-12 08:15:44,568 - INFO - _models.training_function_executor - Epoch 021/48 - train_loss: 0.8932 - val_loss: 1.0693 - val_acc: 0.6741
2025-10-12 08:15:59,156 - INFO - _models.training_function_executor - Epoch 022/48 - train_loss: 0.8885 - val_loss: 0.8634 - val_acc: 0.8074
2025-10-12 08:16:13,726 - INFO - _models.training_function_executor - Epoch 023/48 - train_loss: 0.8874 - val_loss: 1.3613 - val_acc: 0.5810
2025-10-12 08:16:28,324 - INFO - _models.training_function_executor - Epoch 024/48 - train_loss: 0.8862 - val_loss: 0.8740 - val_acc: 0.7987
2025-10-12 08:16:42,905 - INFO - _models.training_function_executor - Epoch 025/48 - train_loss: 0.8844 - val_loss: 0.8707 - val_acc: 0.8057
2025-10-12 08:16:57,470 - INFO - _models.training_function_executor - Epoch 026/48 - train_loss: 0.8797 - val_loss: 0.9461 - val_acc: 0.7672
2025-10-12 08:17:12,009 - INFO - _models.training_function_executor - Epoch 027/48 - train_loss: 0.8780 - val_loss: 0.8581 - val_acc: 0.8111
2025-10-12 08:17:26,585 - INFO - _models.training_function_executor - Epoch 028/48 - train_loss: 0.8764 - val_loss: 1.0671 - val_acc: 0.7079
2025-10-12 08:17:41,138 - INFO - _models.training_function_executor - Epoch 029/48 - train_loss: 0.8722 - val_loss: 0.9160 - val_acc: 0.7888
2025-10-12 08:17:55,718 - INFO - _models.training_function_executor - Epoch 030/48 - train_loss: 0.8718 - val_loss: 0.8710 - val_acc: 0.8005
2025-10-12 08:18:10,288 - INFO - _models.training_function_executor - Epoch 031/48 - train_loss: 0.8684 - val_loss: 0.9920 - val_acc: 0.7370
2025-10-12 08:18:24,904 - INFO - _models.training_function_executor - Epoch 032/48 - train_loss: 0.8662 - val_loss: 1.0270 - val_acc: 0.7293
2025-10-12 08:18:39,487 - INFO - _models.training_function_executor - Epoch 033/48 - train_loss: 0.8631 - val_loss: 0.8600 - val_acc: 0.8134
2025-10-12 08:18:54,067 - INFO - _models.training_function_executor - Epoch 034/48 - train_loss: 0.8599 - val_loss: 0.8914 - val_acc: 0.7968
2025-10-12 08:19:08,650 - INFO - _models.training_function_executor - Epoch 035/48 - train_loss: 0.8582 - val_loss: 0.9084 - val_acc: 0.7847
2025-10-12 08:19:23,218 - INFO - _models.training_function_executor - Epoch 036/48 - train_loss: 0.8569 - val_loss: 0.9871 - val_acc: 0.7451
2025-10-12 08:19:37,801 - INFO - _models.training_function_executor - Epoch 037/48 - train_loss: 0.8518 - val_loss: 0.8976 - val_acc: 0.7937
2025-10-12 08:19:52,359 - INFO - _models.training_function_executor - Epoch 038/48 - train_loss: 0.8513 - val_loss: 0.9304 - val_acc: 0.7887
2025-10-12 08:20:06,925 - INFO - _models.training_function_executor - Epoch 039/48 - train_loss: 0.8505 - val_loss: 0.9437 - val_acc: 0.7679
2025-10-12 08:20:21,469 - INFO - _models.training_function_executor - Epoch 040/48 - train_loss: 0.8471 - val_loss: 0.9147 - val_acc: 0.7947
2025-10-12 08:20:36,013 - INFO - _models.training_function_executor - Epoch 041/48 - train_loss: 0.8448 - val_loss: 0.8936 - val_acc: 0.7959
2025-10-12 08:20:50,585 - INFO - _models.training_function_executor - Epoch 042/48 - train_loss: 0.8435 - val_loss: 0.9837 - val_acc: 0.7551
2025-10-12 08:21:05,165 - INFO - _models.training_function_executor - Epoch 043/48 - train_loss: 0.8397 - val_loss: 0.9596 - val_acc: 0.7671
2025-10-12 08:21:19,713 - INFO - _models.training_function_executor - Epoch 044/48 - train_loss: 0.8360 - val_loss: 1.0544 - val_acc: 0.7181
2025-10-12 08:21:34,274 - INFO - _models.training_function_executor - Epoch 045/48 - train_loss: 0.8379 - val_loss: 0.8785 - val_acc: 0.8100
2025-10-12 08:21:48,837 - INFO - _models.training_function_executor - Epoch 046/48 - train_loss: 0.8346 - val_loss: 0.9123 - val_acc: 0.7864
2025-10-12 08:22:03,406 - INFO - _models.training_function_executor - Epoch 047/48 - train_loss: 0.8309 - val_loss: 0.9428 - val_acc: 0.7664
2025-10-12 08:22:17,996 - INFO - _models.training_function_executor - Epoch 048/48 - train_loss: 0.8297 - val_loss: 0.9352 - val_acc: 0.7864
2025-10-12 08:22:17,999 - INFO - _models.training_function_executor - Model: 63,421 parameters, 136.3KB storage
2025-10-12 08:22:17,999 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1838154183595715, 1.0460450278740476, 1.00513140730479, 0.9724078866039325, 0.9623410856761339, 0.9530263037626502, 0.9441568474273895, 0.9377181807472275, 0.9310286642581298, 0.9297381886703217, 0.9249425599071835, 0.9198606324479595, 0.9154327584180876, 0.9121822581910403, 0.9113649406089289, 0.9042535767423385, 0.9022465694772642, 0.8978105072671398, 0.8967266630408728, 0.8942720386003088, 0.8931970306113753, 0.8885345021702837, 0.8874125176474145, 0.8861715313559609, 0.8844151774986582, 0.8797287789516028, 0.8779502839194255, 0.8764094398453138, 0.8721887915126919, 0.871819292451687, 0.8683640279259179, 0.8661974341584787, 0.863117591501075, 0.8599352169629365, 0.8582030169230305, 0.8568864737017654, 0.8517732849728614, 0.851277193741069, 0.8505488223114922, 0.8471131556343691, 0.8448229771124386, 0.8435350679041081, 0.8396960675486911, 0.8359512104035092, 0.8379018312156472, 0.8346492488733905, 0.8309074637353274, 0.8296552217837018], 'val_losses': [1.2202044699965635, 2.4801899299448005, 0.9840678556590469, 0.9423439341239008, 0.956135652909798, 1.2305279620719365, 0.909951870346303, 1.2221747232893776, 1.2255418201530985, 1.165141663477894, 1.001543618224908, 0.8867997358343507, 0.94965458316823, 0.8752837843481043, 0.8714305193515186, 1.170061651250888, 0.8713015546988974, 0.8719844823539529, 0.9485079134140643, 0.9327314991111475, 1.0693036263582378, 0.8633882929112973, 1.3613144082542394, 0.8740399374926804, 0.8706616142391116, 0.9461373436855695, 0.8580652605331482, 1.0670937397991564, 0.9159848250247901, 0.8710426898072723, 0.9919980271195548, 1.0270418702700692, 0.8599959287895453, 0.8914449549989764, 0.9083551345774458, 0.9870768949665888, 0.8975819119799584, 0.9303805159445947, 0.9436596390414079, 0.9147340396212497, 0.8935777176331923, 0.9837118543692306, 0.9596034179294615, 1.054445297016228, 0.8784618032199751, 0.9122933515268979, 0.9428489202588515, 0.9352234409203427], 'val_acc': [0.5972173608680434, 0.32105355267763386, 0.739761988099405, 0.7601505075253763, 0.7653132656632832, 0.605442772138607, 0.7851767588379419, 0.6260938046902345, 0.6081554077703886, 0.6251312565628281, 0.7215610780539027, 0.7923521176058803, 0.7650507525376269, 0.8004900245012251, 0.8043402170108506, 0.6652082604130206, 0.8046027301365068, 0.8039026951347568, 0.7625131256562828, 0.7705635281764088, 0.6741337066853342, 0.8074028701435072, 0.5810290514525727, 0.7987399369968499, 0.805652782639132, 0.7671508575428772, 0.8110780539026952, 0.707910395519776, 0.7887644382219111, 0.8004900245012251, 0.7369618480924046, 0.7293489674483724, 0.8134406720336017, 0.7968148407420371, 0.7846517325866293, 0.7450997549877494, 0.7936646832341617, 0.7886769338466924, 0.767938396919846, 0.7947147357367869, 0.7958522926146308, 0.7550752537626881, 0.7670633531676584, 0.718148407420371, 0.81002800140007, 0.7864018200910046, 0.7663633181659083, 0.7864018200910046], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0017603597552497813, 'batch_size': 32, 'epochs': 48, 'weight_decay': 1.981883098673564e-06, 'dropout': 0.14199476217447485, 'base_channels': 19, 'temporal_kernel': 3, 'spatial_segments': 125, 'label_smoothing': 0.15113228200837586, 'grad_clip': 0.6246269681701558, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 1564}, 'model_parameter_count': 63421, 'model_storage_size_kb': 136.2560546875, 'model_size_validation': 'PASS'}
2025-10-12 08:22:17,999 - INFO - _models.training_function_executor - BO Objective: base=0.7864, size_penalty=0.0000, final=0.7864
2025-10-12 08:22:17,999 - INFO - _models.training_function_executor - Model: 63,421 parameters, 136.3KB (PASS 256KB limit)
2025-10-12 08:22:17,999 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 699.440s
2025-10-12 08:22:18,120 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7864
2025-10-12 08:22:18,120 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.114s
2025-10-12 08:22:18,120 - INFO - bo.run_bo - Recorded observation #41: hparams={'lr': 0.0017603597552497813, 'batch_size': np.int64(32), 'epochs': np.int64(48), 'weight_decay': 1.981883098673564e-06, 'dropout': 0.14199476217447485, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(125), 'label_smoothing': 0.15113228200837586, 'grad_clip': 0.6246269681701558, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(1564)}, value=0.7864
2025-10-12 08:22:18,120 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 41: {'lr': 0.0017603597552497813, 'batch_size': np.int64(32), 'epochs': np.int64(48), 'weight_decay': 1.981883098673564e-06, 'dropout': 0.14199476217447485, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(125), 'label_smoothing': 0.15113228200837586, 'grad_clip': 0.6246269681701558, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(1564)} -> 0.7864
2025-10-12 08:22:18,120 - INFO - bo.run_bo - üîçBO Trial 42: Using RF surrogate + Expected Improvement
2025-10-12 08:22:18,120 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 08:22:18,121 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 08:22:18,121 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 08:22:18,121 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0008792080535367704, 'batch_size': 16, 'epochs': 50, 'weight_decay': 1.5692845820813259e-06, 'dropout': 0.005775923415135776, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 5, 'label_smoothing': 0.16900487166059386, 'grad_clip': 0.9725853766779118, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4706}
2025-10-12 08:22:18,122 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0008792080535367704, 'batch_size': 16, 'epochs': 50, 'weight_decay': 1.5692845820813259e-06, 'dropout': 0.005775923415135776, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 5, 'label_smoothing': 0.16900487166059386, 'grad_clip': 0.9725853766779118, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4706}
2025-10-12 08:22:34,067 - INFO - _models.training_function_executor - Epoch 001/50 - train_loss: 1.1737 - val_loss: 1.1723 - val_acc: 0.6560
2025-10-12 08:22:49,973 - INFO - _models.training_function_executor - Epoch 002/50 - train_loss: 1.0469 - val_loss: 0.9857 - val_acc: 0.7555
2025-10-12 08:23:05,902 - INFO - _models.training_function_executor - Epoch 003/50 - train_loss: 1.0019 - val_loss: 1.0822 - val_acc: 0.7024
2025-10-12 08:23:21,804 - INFO - _models.training_function_executor - Epoch 004/50 - train_loss: 0.9768 - val_loss: 0.9746 - val_acc: 0.7637
2025-10-12 08:23:37,723 - INFO - _models.training_function_executor - Epoch 005/50 - train_loss: 0.9596 - val_loss: 0.9532 - val_acc: 0.7814
2025-10-12 08:23:53,606 - INFO - _models.training_function_executor - Epoch 006/50 - train_loss: 0.9507 - val_loss: 0.9488 - val_acc: 0.7740
2025-10-12 08:24:09,527 - INFO - _models.training_function_executor - Epoch 007/50 - train_loss: 0.9400 - val_loss: 0.9976 - val_acc: 0.7469
2025-10-12 08:24:25,427 - INFO - _models.training_function_executor - Epoch 008/50 - train_loss: 0.9326 - val_loss: 1.0416 - val_acc: 0.7250
2025-10-12 08:24:41,309 - INFO - _models.training_function_executor - Epoch 009/50 - train_loss: 0.9265 - val_loss: 0.9440 - val_acc: 0.7767
2025-10-12 08:24:57,241 - INFO - _models.training_function_executor - Epoch 010/50 - train_loss: 0.9214 - val_loss: 0.9159 - val_acc: 0.7980
2025-10-12 08:25:13,135 - INFO - _models.training_function_executor - Epoch 011/50 - train_loss: 0.9186 - val_loss: 0.9481 - val_acc: 0.7728
2025-10-12 08:25:29,039 - INFO - _models.training_function_executor - Epoch 012/50 - train_loss: 0.9123 - val_loss: 0.9723 - val_acc: 0.7660
2025-10-12 08:25:44,988 - INFO - _models.training_function_executor - Epoch 013/50 - train_loss: 0.9067 - val_loss: 0.9672 - val_acc: 0.7653
2025-10-12 08:26:00,908 - INFO - _models.training_function_executor - Epoch 014/50 - train_loss: 0.9037 - val_loss: 0.9110 - val_acc: 0.7959
2025-10-12 08:26:16,852 - INFO - _models.training_function_executor - Epoch 015/50 - train_loss: 0.8987 - val_loss: 0.9112 - val_acc: 0.7953
2025-10-12 08:26:32,805 - INFO - _models.training_function_executor - Epoch 016/50 - train_loss: 0.8959 - val_loss: 0.8982 - val_acc: 0.8051
2025-10-12 08:26:48,703 - INFO - _models.training_function_executor - Epoch 017/50 - train_loss: 0.8933 - val_loss: 0.9130 - val_acc: 0.7933
2025-10-12 08:27:04,631 - INFO - _models.training_function_executor - Epoch 018/50 - train_loss: 0.8907 - val_loss: 0.9707 - val_acc: 0.7602
2025-10-12 08:27:20,576 - INFO - _models.training_function_executor - Epoch 019/50 - train_loss: 0.8906 - val_loss: 0.9117 - val_acc: 0.7982
2025-10-12 08:27:36,501 - INFO - _models.training_function_executor - Epoch 020/50 - train_loss: 0.8856 - val_loss: 1.0753 - val_acc: 0.6997
2025-10-12 08:27:52,424 - INFO - _models.training_function_executor - Epoch 021/50 - train_loss: 0.8832 - val_loss: 0.9027 - val_acc: 0.8044
2025-10-12 08:28:08,298 - INFO - _models.training_function_executor - Epoch 022/50 - train_loss: 0.8804 - val_loss: 0.9440 - val_acc: 0.7829
2025-10-12 08:28:24,186 - INFO - _models.training_function_executor - Epoch 023/50 - train_loss: 0.8762 - val_loss: 0.9008 - val_acc: 0.8031
2025-10-12 08:28:40,116 - INFO - _models.training_function_executor - Epoch 024/50 - train_loss: 0.8717 - val_loss: 0.8935 - val_acc: 0.8078
2025-10-12 08:28:55,966 - INFO - _models.training_function_executor - Epoch 025/50 - train_loss: 0.8717 - val_loss: 0.9019 - val_acc: 0.8018
2025-10-12 08:29:11,850 - INFO - _models.training_function_executor - Epoch 026/50 - train_loss: 0.8721 - val_loss: 0.9555 - val_acc: 0.7672
2025-10-12 08:29:27,770 - INFO - _models.training_function_executor - Epoch 027/50 - train_loss: 0.8680 - val_loss: 0.9261 - val_acc: 0.7877
2025-10-12 08:29:43,656 - INFO - _models.training_function_executor - Epoch 028/50 - train_loss: 0.8661 - val_loss: 0.9018 - val_acc: 0.7976
2025-10-12 08:29:59,592 - INFO - _models.training_function_executor - Epoch 029/50 - train_loss: 0.8624 - val_loss: 0.9057 - val_acc: 0.8070
2025-10-12 08:30:15,472 - INFO - _models.training_function_executor - Epoch 030/50 - train_loss: 0.8587 - val_loss: 0.8770 - val_acc: 0.8181
2025-10-12 08:30:31,392 - INFO - _models.training_function_executor - Epoch 031/50 - train_loss: 0.8578 - val_loss: 0.8944 - val_acc: 0.8097
2025-10-12 08:30:47,317 - INFO - _models.training_function_executor - Epoch 032/50 - train_loss: 0.8584 - val_loss: 0.8947 - val_acc: 0.8031
2025-10-12 08:31:03,201 - INFO - _models.training_function_executor - Epoch 033/50 - train_loss: 0.8566 - val_loss: 0.9038 - val_acc: 0.8021
2025-10-12 08:31:19,127 - INFO - _models.training_function_executor - Epoch 034/50 - train_loss: 0.8523 - val_loss: 0.9663 - val_acc: 0.7658
2025-10-12 08:31:35,100 - INFO - _models.training_function_executor - Epoch 035/50 - train_loss: 0.8507 - val_loss: 0.8943 - val_acc: 0.8122
2025-10-12 08:31:50,980 - INFO - _models.training_function_executor - Epoch 036/50 - train_loss: 0.8464 - val_loss: 0.9247 - val_acc: 0.7833
2025-10-12 08:32:06,896 - INFO - _models.training_function_executor - Epoch 037/50 - train_loss: 0.8443 - val_loss: 0.8959 - val_acc: 0.8057
2025-10-12 08:32:22,756 - INFO - _models.training_function_executor - Epoch 038/50 - train_loss: 0.8426 - val_loss: 0.9058 - val_acc: 0.8056
2025-10-12 08:32:38,677 - INFO - _models.training_function_executor - Epoch 039/50 - train_loss: 0.8392 - val_loss: 0.9005 - val_acc: 0.8085
2025-10-12 08:32:54,593 - INFO - _models.training_function_executor - Epoch 040/50 - train_loss: 0.8386 - val_loss: 0.8891 - val_acc: 0.8129
2025-10-12 08:33:10,482 - INFO - _models.training_function_executor - Epoch 041/50 - train_loss: 0.8343 - val_loss: 0.9051 - val_acc: 0.7970
2025-10-12 08:33:26,386 - INFO - _models.training_function_executor - Epoch 042/50 - train_loss: 0.8327 - val_loss: 0.9147 - val_acc: 0.7950
2025-10-12 08:33:42,257 - INFO - _models.training_function_executor - Epoch 043/50 - train_loss: 0.8302 - val_loss: 0.9050 - val_acc: 0.8069
2025-10-12 08:33:58,171 - INFO - _models.training_function_executor - Epoch 044/50 - train_loss: 0.8260 - val_loss: 0.9427 - val_acc: 0.7840
2025-10-12 08:34:14,054 - INFO - _models.training_function_executor - Epoch 045/50 - train_loss: 0.8272 - val_loss: 0.9093 - val_acc: 0.8039
2025-10-12 08:34:29,945 - INFO - _models.training_function_executor - Epoch 046/50 - train_loss: 0.8225 - val_loss: 0.9336 - val_acc: 0.7968
2025-10-12 08:34:45,831 - INFO - _models.training_function_executor - Epoch 047/50 - train_loss: 0.8203 - val_loss: 0.9046 - val_acc: 0.8094
2025-10-12 08:35:01,759 - INFO - _models.training_function_executor - Epoch 048/50 - train_loss: 0.8180 - val_loss: 0.9446 - val_acc: 0.7907
2025-10-12 08:35:17,619 - INFO - _models.training_function_executor - Epoch 049/50 - train_loss: 0.8134 - val_loss: 0.9436 - val_acc: 0.7858
2025-10-12 08:35:33,534 - INFO - _models.training_function_executor - Epoch 050/50 - train_loss: 0.8141 - val_loss: 0.9149 - val_acc: 0.7952
2025-10-12 08:35:33,537 - INFO - _models.training_function_executor - Model: 58,065 parameters, 249.5KB storage
2025-10-12 08:35:33,537 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1736662307735253, 1.046895212525457, 1.0018853137323729, 0.9768468534817093, 0.959601149802697, 0.9506987662927897, 0.9399649000351438, 0.9325781845320427, 0.9265107899059313, 0.9213768333499148, 0.9185803684063378, 0.9122546981964071, 0.9066733528068109, 0.9036773763881265, 0.8986899094603301, 0.8959350291565243, 0.8932700044507116, 0.8906987059103846, 0.8906245340531549, 0.8856443767369023, 0.8831996728291577, 0.8804426041982956, 0.8761526247943495, 0.8717495671802357, 0.8717482496401127, 0.8720515163202657, 0.8679901234203174, 0.8660923108630636, 0.8623554906855107, 0.8586918638851578, 0.8578303765282582, 0.8583713143615402, 0.8565721236662219, 0.8522737427820974, 0.8507101848945778, 0.8464099169611973, 0.8443456372890933, 0.8425739409417008, 0.8391997041216588, 0.8386037111240623, 0.8343025327229525, 0.8326547209266019, 0.830218492937038, 0.8260051516498517, 0.8271513242048946, 0.8225297975840583, 0.8202793389965615, 0.8180300649705365, 0.8133925470097482, 0.8140843283850536], 'val_losses': [1.1723250614666296, 0.9857103401729181, 1.0822275933328107, 0.9746202106111985, 0.9531649521568, 0.9487942015327772, 0.9976333571682037, 1.041643977874553, 0.9439661686846874, 0.9158866368560137, 0.948129536140036, 0.9722756779940762, 0.9671894131651448, 0.9110413015326879, 0.9111921188920622, 0.8982417174140014, 0.9130094552273762, 0.9707244224468227, 0.911694182125388, 1.075342338131907, 0.902717135108598, 0.9440456431229964, 0.9007938987189839, 0.8934542149941656, 0.9019143289313017, 0.9555247419356966, 0.9260571347194241, 0.9018436218209311, 0.9056957614851615, 0.87697807111897, 0.8943657186592965, 0.8947060631837801, 0.9037542810046176, 0.9662835046800233, 0.8943052181923853, 0.9247361546343843, 0.8958973125181375, 0.9058325605080351, 0.9004812979973569, 0.8891025641017082, 0.9050682364204441, 0.9147472809276508, 0.9050060285318553, 0.9427138690895078, 0.9093185967192351, 0.9335695897986266, 0.9045871985638771, 0.9445841823543834, 0.9435912205449426, 0.9148553135430934], 'val_acc': [0.6560203010150507, 0.7555127756387819, 0.702397619880994, 0.7637381869093455, 0.7814140707035352, 0.7739761988099405, 0.7469373468673434, 0.7249737486874344, 0.7766888344417221, 0.7980399019950998, 0.7728386419320966, 0.7660133006650333, 0.7653132656632832, 0.7958522926146308, 0.7953272663633182, 0.8051277563878194, 0.7933146657332867, 0.7601505075253763, 0.7982149107455373, 0.6996849842492124, 0.8044277213860693, 0.7829016450822541, 0.8031151557577879, 0.807840392019601, 0.8018025901295065, 0.7671508575428772, 0.787714385719286, 0.797602380119006, 0.8069653482674134, 0.818078403920196, 0.809677983899195, 0.8031151557577879, 0.8020651032551628, 0.7658382919145957, 0.812215610780539, 0.7833391669583479, 0.8057402870143507, 0.8055652782639132, 0.8085404270213511, 0.8129156457822891, 0.7969898494924746, 0.7949772488624431, 0.8068778438921946, 0.784039201960098, 0.8039026951347568, 0.7968148407420371, 0.8094154707735387, 0.7906895344767239, 0.7857892894644732, 0.7952397619880994], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0008792080535367704, 'batch_size': 16, 'epochs': 50, 'weight_decay': 1.5692845820813259e-06, 'dropout': 0.005775923415135776, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 5, 'label_smoothing': 0.16900487166059386, 'grad_clip': 0.9725853766779118, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 4706}, 'model_parameter_count': 58065, 'model_storage_size_kb': 249.49804687500003, 'model_size_validation': 'PASS'}
2025-10-12 08:35:33,537 - INFO - _models.training_function_executor - BO Objective: base=0.7952, size_penalty=0.0000, final=0.7952
2025-10-12 08:35:33,537 - INFO - _models.training_function_executor - Model: 58,065 parameters, 249.5KB (PASS 256KB limit)
2025-10-12 08:35:33,537 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 795.416s
2025-10-12 08:35:33,655 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7952
2025-10-12 08:35:33,656 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.115s
2025-10-12 08:35:33,656 - INFO - bo.run_bo - Recorded observation #42: hparams={'lr': 0.0008792080535367704, 'batch_size': np.int64(16), 'epochs': np.int64(50), 'weight_decay': 1.5692845820813259e-06, 'dropout': 0.005775923415135776, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(5), 'label_smoothing': 0.16900487166059386, 'grad_clip': 0.9725853766779118, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4706)}, value=0.7952
2025-10-12 08:35:33,656 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 42: {'lr': 0.0008792080535367704, 'batch_size': np.int64(16), 'epochs': np.int64(50), 'weight_decay': 1.5692845820813259e-06, 'dropout': 0.005775923415135776, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(5), 'label_smoothing': 0.16900487166059386, 'grad_clip': 0.9725853766779118, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4706)} -> 0.7952
2025-10-12 08:35:33,656 - INFO - bo.run_bo - üîçBO Trial 43: Using RF surrogate + Expected Improvement
2025-10-12 08:35:33,656 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 08:35:33,656 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 08:35:33,656 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 08:35:33,656 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.015561164236794812, 'batch_size': 16, 'epochs': 48, 'weight_decay': 4.758750410451636e-06, 'dropout': 0.14552473431678883, 'base_channels': 19, 'temporal_kernel': 5, 'spatial_segments': 25, 'label_smoothing': 0.16592337000554525, 'grad_clip': 0.6274732829218416, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 3460}
2025-10-12 08:35:33,657 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.015561164236794812, 'batch_size': 16, 'epochs': 48, 'weight_decay': 4.758750410451636e-06, 'dropout': 0.14552473431678883, 'base_channels': 19, 'temporal_kernel': 5, 'spatial_segments': 25, 'label_smoothing': 0.16592337000554525, 'grad_clip': 0.6274732829218416, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 3460}
2025-10-12 08:35:49,252 - INFO - _models.training_function_executor - Epoch 001/48 - train_loss: 1.4043 - val_loss: 1.3692 - val_acc: 0.5583
2025-10-12 08:36:04,824 - INFO - _models.training_function_executor - Epoch 002/48 - train_loss: 1.3176 - val_loss: 2.1372 - val_acc: 0.2412
2025-10-12 08:36:20,385 - INFO - _models.training_function_executor - Epoch 003/48 - train_loss: 1.2839 - val_loss: 1.2271 - val_acc: 0.6239
2025-10-12 08:36:35,914 - INFO - _models.training_function_executor - Epoch 004/48 - train_loss: 1.2526 - val_loss: 1.2503 - val_acc: 0.6220
2025-10-12 08:36:51,459 - INFO - _models.training_function_executor - Epoch 005/48 - train_loss: 1.2292 - val_loss: 1.1207 - val_acc: 0.6995
2025-10-12 08:37:06,983 - INFO - _models.training_function_executor - Epoch 006/48 - train_loss: 1.2320 - val_loss: 1.1338 - val_acc: 0.6996
2025-10-12 08:37:22,475 - INFO - _models.training_function_executor - Epoch 007/48 - train_loss: 1.2021 - val_loss: 1.1823 - val_acc: 0.7140
2025-10-12 08:37:37,999 - INFO - _models.training_function_executor - Epoch 008/48 - train_loss: 1.1932 - val_loss: 1.1128 - val_acc: 0.7164
2025-10-12 08:37:53,534 - INFO - _models.training_function_executor - Epoch 009/48 - train_loss: 1.2015 - val_loss: 1.1988 - val_acc: 0.6973
2025-10-12 08:38:09,076 - INFO - _models.training_function_executor - Epoch 010/48 - train_loss: 1.2022 - val_loss: 1.1584 - val_acc: 0.7244
2025-10-12 08:38:24,600 - INFO - _models.training_function_executor - Epoch 011/48 - train_loss: 1.1906 - val_loss: 1.1428 - val_acc: 0.7384
2025-10-12 08:38:40,134 - INFO - _models.training_function_executor - Epoch 012/48 - train_loss: 1.2197 - val_loss: 1.0918 - val_acc: 0.7454
2025-10-12 08:38:55,643 - INFO - _models.training_function_executor - Epoch 013/48 - train_loss: 1.1820 - val_loss: 1.1073 - val_acc: 0.7393
2025-10-12 08:39:11,186 - INFO - _models.training_function_executor - Epoch 014/48 - train_loss: 1.1664 - val_loss: 1.2100 - val_acc: 0.7440
2025-10-12 08:39:26,742 - INFO - _models.training_function_executor - Epoch 015/48 - train_loss: 1.1900 - val_loss: 1.2632 - val_acc: 0.7378
2025-10-12 08:39:42,285 - INFO - _models.training_function_executor - Epoch 016/48 - train_loss: 1.1608 - val_loss: 1.0907 - val_acc: 0.7390
2025-10-12 08:39:57,811 - INFO - _models.training_function_executor - Epoch 017/48 - train_loss: 1.1692 - val_loss: 1.0211 - val_acc: 0.7546
2025-10-12 08:40:13,334 - INFO - _models.training_function_executor - Epoch 018/48 - train_loss: 1.2270 - val_loss: 1.2036 - val_acc: 0.6613
2025-10-12 08:40:28,913 - INFO - _models.training_function_executor - Epoch 019/48 - train_loss: 1.1738 - val_loss: 1.1693 - val_acc: 0.7239
2025-10-12 08:40:44,438 - INFO - _models.training_function_executor - Epoch 020/48 - train_loss: 1.1851 - val_loss: 1.0970 - val_acc: 0.7289
2025-10-12 08:40:59,984 - INFO - _models.training_function_executor - Epoch 021/48 - train_loss: 1.1715 - val_loss: 1.1358 - val_acc: 0.7217
2025-10-12 08:41:15,506 - INFO - _models.training_function_executor - Epoch 022/48 - train_loss: 1.1632 - val_loss: 1.2046 - val_acc: 0.7075
2025-10-12 08:41:31,042 - INFO - _models.training_function_executor - Epoch 023/48 - train_loss: 1.1723 - val_loss: 1.1060 - val_acc: 0.7391
2025-10-12 08:41:46,611 - INFO - _models.training_function_executor - Epoch 024/48 - train_loss: 1.2124 - val_loss: 1.0384 - val_acc: 0.7526
2025-10-12 08:42:02,165 - INFO - _models.training_function_executor - Epoch 025/48 - train_loss: 1.2429 - val_loss: 1.1268 - val_acc: 0.7366
2025-10-12 08:42:17,702 - INFO - _models.training_function_executor - Epoch 026/48 - train_loss: 1.1897 - val_loss: 1.0671 - val_acc: 0.7613
2025-10-12 08:42:33,245 - INFO - _models.training_function_executor - Epoch 027/48 - train_loss: 1.1509 - val_loss: 1.1514 - val_acc: 0.7519
2025-10-12 08:42:48,779 - INFO - _models.training_function_executor - Epoch 028/48 - train_loss: 1.1957 - val_loss: 1.0451 - val_acc: 0.7541
2025-10-12 08:43:04,331 - INFO - _models.training_function_executor - Epoch 029/48 - train_loss: 1.1859 - val_loss: 1.2430 - val_acc: 0.7651
2025-10-12 08:43:19,866 - INFO - _models.training_function_executor - Epoch 030/48 - train_loss: 1.1882 - val_loss: 1.0635 - val_acc: 0.7673
2025-10-12 08:43:35,386 - INFO - _models.training_function_executor - Epoch 031/48 - train_loss: 1.1578 - val_loss: 1.1713 - val_acc: 0.7610
2025-10-12 08:43:50,914 - INFO - _models.training_function_executor - Epoch 032/48 - train_loss: 1.1743 - val_loss: 1.4746 - val_acc: 0.5617
2025-10-12 08:44:06,416 - INFO - _models.training_function_executor - Epoch 033/48 - train_loss: 1.1726 - val_loss: 1.2526 - val_acc: 0.7543
2025-10-12 08:44:21,963 - INFO - _models.training_function_executor - Epoch 034/48 - train_loss: 1.1993 - val_loss: 1.2114 - val_acc: 0.6919
2025-10-12 08:44:37,514 - INFO - _models.training_function_executor - Epoch 035/48 - train_loss: 1.2068 - val_loss: 1.1060 - val_acc: 0.7659
2025-10-12 08:44:53,065 - INFO - _models.training_function_executor - Epoch 036/48 - train_loss: 1.1903 - val_loss: 1.1191 - val_acc: 0.7440
2025-10-12 08:45:08,610 - INFO - _models.training_function_executor - Epoch 037/48 - train_loss: 1.1653 - val_loss: 1.1023 - val_acc: 0.7665
2025-10-12 08:45:24,158 - INFO - _models.training_function_executor - Epoch 038/48 - train_loss: 1.1823 - val_loss: 1.0819 - val_acc: 0.7761
2025-10-12 08:45:39,699 - INFO - _models.training_function_executor - Epoch 039/48 - train_loss: 1.2167 - val_loss: 1.2135 - val_acc: 0.7494
2025-10-12 08:45:55,268 - INFO - _models.training_function_executor - Epoch 040/48 - train_loss: 1.2011 - val_loss: 1.1613 - val_acc: 0.7430
2025-10-12 08:46:10,782 - INFO - _models.training_function_executor - Epoch 041/48 - train_loss: 1.1583 - val_loss: 1.1551 - val_acc: 0.7631
2025-10-12 08:46:26,324 - INFO - _models.training_function_executor - Epoch 042/48 - train_loss: 1.1933 - val_loss: 1.3745 - val_acc: 0.7074
2025-10-12 08:46:41,858 - INFO - _models.training_function_executor - Epoch 043/48 - train_loss: 1.2316 - val_loss: 1.0746 - val_acc: 0.7793
2025-10-12 08:46:57,411 - INFO - _models.training_function_executor - Epoch 044/48 - train_loss: 1.1690 - val_loss: 1.1759 - val_acc: 0.7691
2025-10-12 08:47:12,972 - INFO - _models.training_function_executor - Epoch 045/48 - train_loss: 1.1714 - val_loss: 1.2536 - val_acc: 0.7472
2025-10-12 08:47:28,486 - INFO - _models.training_function_executor - Epoch 046/48 - train_loss: 1.2511 - val_loss: 1.3649 - val_acc: 0.7327
2025-10-12 08:47:44,020 - INFO - _models.training_function_executor - Epoch 047/48 - train_loss: 1.1752 - val_loss: 1.1372 - val_acc: 0.7686
2025-10-12 08:47:59,588 - INFO - _models.training_function_executor - Epoch 048/48 - train_loss: 1.2243 - val_loss: 1.1527 - val_acc: 0.7511
2025-10-12 08:47:59,593 - INFO - _models.training_function_executor - Model: 50,956 parameters, 54.7KB storage
2025-10-12 08:47:59,593 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4043153528571337, 1.3176308560922174, 1.2838888781697424, 1.2525670666314106, 1.229157229007271, 1.2320343261003746, 1.2021083725596124, 1.1931779274249519, 1.2015185063228266, 1.2022146720922948, 1.1905619223133683, 1.2196629630088138, 1.1819652856585443, 1.1664211911507574, 1.1900249450282696, 1.1608447893791614, 1.1691646182040547, 1.2269764656489823, 1.1738062105814726, 1.1851479159730025, 1.171479974357991, 1.1631804446594924, 1.1722796630266876, 1.212370240400419, 1.24286357666756, 1.1896852318290068, 1.1509277638247433, 1.1957220583476091, 1.1858539158203905, 1.1881622716518478, 1.1577985515367497, 1.1742550638492266, 1.1726236789427649, 1.1993284852387065, 1.2068125062319295, 1.1903121825444518, 1.1652755225960676, 1.1823243693450884, 1.2166650387261937, 1.2011082795770343, 1.158335489412267, 1.1933212390011076, 1.2315530829968717, 1.1690037130975706, 1.1714260602982094, 1.2511104565631437, 1.1752464035861676, 1.2243027870038359], 'val_losses': [1.3692356746931946, 2.137197333363582, 1.2271265046221833, 1.250255842913186, 1.1207058249881812, 1.1337552633701107, 1.1823201231243814, 1.1128372231020476, 1.1987582807737838, 1.1583685001627648, 1.1428242232526646, 1.0918344176645915, 1.1072885701612112, 1.2100460315276411, 1.2632008648269195, 1.0906541533598668, 1.0211295379305536, 1.2036240897814543, 1.169286339400655, 1.0969677140423164, 1.1357978959579254, 1.2045689039727712, 1.1060070154088588, 1.0384188285439757, 1.1268023725652512, 1.0671384619548265, 1.1514007116390519, 1.045104089445028, 1.2430305026150852, 1.063499677878057, 1.1712988221983331, 1.4745909013362626, 1.2525697256620005, 1.2114362189266537, 1.1060196507590443, 1.1191039092898745, 1.1022994533301151, 1.0818835730564356, 1.2135291641560475, 1.1612619584700759, 1.155109231731547, 1.3745464550101094, 1.074558735770031, 1.1758787394571355, 1.253630313749784, 1.3649260478291763, 1.1371576319134733, 1.152741263077148], 'val_acc': [0.5582779138956948, 0.24116205810290514, 0.6239061953097655, 0.6219810990549528, 0.6995099754987749, 0.6995974798739937, 0.7140357017850892, 0.7163983199159958, 0.6973223661183059, 0.724361218060903, 0.7384494224711236, 0.7454497724886244, 0.7393244662233112, 0.7440497024851243, 0.7378368918445922, 0.7389744487224361, 0.7546377318865943, 0.6612705635281764, 0.7239236961848092, 0.7289114455722786, 0.7217360868043402, 0.7074728736436822, 0.7391494574728736, 0.7526251312565628, 0.7366118305915296, 0.7612880644032202, 0.7519250962548127, 0.7541127056352818, 0.7651382569128456, 0.7673258662933147, 0.7610255512775639, 0.5616905845292265, 0.7542877143857193, 0.6918970948547427, 0.7659257962898145, 0.7439621981099055, 0.7664508225411271, 0.7760763038151908, 0.7493874693734687, 0.7429996499824991, 0.7631256562828141, 0.7073853692684634, 0.7793139656982849, 0.7690759537976899, 0.7471998599929996, 0.7326741337066853, 0.7686384319215961, 0.7511375568778439], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.015561164236794812, 'batch_size': 16, 'epochs': 48, 'weight_decay': 4.758750410451636e-06, 'dropout': 0.14552473431678883, 'base_channels': 19, 'temporal_kernel': 5, 'spatial_segments': 25, 'label_smoothing': 0.16592337000554525, 'grad_clip': 0.6274732829218416, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 3460}, 'model_parameter_count': 50956, 'model_storage_size_kb': 54.737890625000006, 'model_size_validation': 'PASS'}
2025-10-12 08:47:59,594 - INFO - _models.training_function_executor - BO Objective: base=0.7511, size_penalty=0.0000, final=0.7511
2025-10-12 08:47:59,594 - INFO - _models.training_function_executor - Model: 50,956 parameters, 54.7KB (PASS 256KB limit)
2025-10-12 08:47:59,594 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 745.937s
2025-10-12 08:47:59,713 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7511
2025-10-12 08:47:59,713 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.116s
2025-10-12 08:47:59,713 - INFO - bo.run_bo - Recorded observation #43: hparams={'lr': 0.015561164236794812, 'batch_size': np.int64(16), 'epochs': np.int64(48), 'weight_decay': 4.758750410451636e-06, 'dropout': 0.14552473431678883, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(25), 'label_smoothing': 0.16592337000554525, 'grad_clip': 0.6274732829218416, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(3460)}, value=0.7511
2025-10-12 08:47:59,713 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 43: {'lr': 0.015561164236794812, 'batch_size': np.int64(16), 'epochs': np.int64(48), 'weight_decay': 4.758750410451636e-06, 'dropout': 0.14552473431678883, 'base_channels': np.int64(19), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(25), 'label_smoothing': 0.16592337000554525, 'grad_clip': 0.6274732829218416, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(3460)} -> 0.7511
2025-10-12 08:47:59,714 - INFO - bo.run_bo - üîçBO Trial 44: Using RF surrogate + Expected Improvement
2025-10-12 08:47:59,714 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 08:47:59,714 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 08:47:59,714 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 08:47:59,714 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.06515455979659397, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.0399760746584102e-06, 'dropout': 0.04374324781857231, 'base_channels': 21, 'temporal_kernel': 3, 'spatial_segments': 24, 'label_smoothing': 0.10769652635384803, 'grad_clip': 0.6173229005201537, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 1698}
2025-10-12 08:47:59,715 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.06515455979659397, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.0399760746584102e-06, 'dropout': 0.04374324781857231, 'base_channels': 21, 'temporal_kernel': 3, 'spatial_segments': 24, 'label_smoothing': 0.10769652635384803, 'grad_clip': 0.6173229005201537, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 1698}
2025-10-12 08:48:15,379 - INFO - _models.training_function_executor - Epoch 001/46 - train_loss: 1.9852 - val_loss: 2.2015 - val_acc: 0.4625
2025-10-12 08:48:30,369 - INFO - _models.training_function_executor - Epoch 002/46 - train_loss: 2.0628 - val_loss: 2.8171 - val_acc: 0.5008
2025-10-12 08:48:45,331 - INFO - _models.training_function_executor - Epoch 003/46 - train_loss: 2.3116 - val_loss: 3.7841 - val_acc: 0.2177
2025-10-12 08:49:00,357 - INFO - _models.training_function_executor - Epoch 004/46 - train_loss: 2.3605 - val_loss: 3.2857 - val_acc: 0.2080
2025-10-12 08:49:15,365 - INFO - _models.training_function_executor - Epoch 005/46 - train_loss: 2.3939 - val_loss: 1.7720 - val_acc: 0.5045
2025-10-12 08:49:30,320 - INFO - _models.training_function_executor - Epoch 006/46 - train_loss: 2.6109 - val_loss: 6.9671 - val_acc: 0.2802
2025-10-12 08:49:45,328 - INFO - _models.training_function_executor - Epoch 007/46 - train_loss: 2.6350 - val_loss: 2.9768 - val_acc: 0.2243
2025-10-12 08:50:00,323 - INFO - _models.training_function_executor - Epoch 008/46 - train_loss: 2.7220 - val_loss: 3.9429 - val_acc: 0.2228
2025-10-12 08:50:15,351 - INFO - _models.training_function_executor - Epoch 009/46 - train_loss: 2.7340 - val_loss: 9.3638 - val_acc: 0.2554
2025-10-12 08:50:30,351 - INFO - _models.training_function_executor - Epoch 010/46 - train_loss: 2.6113 - val_loss: 6.5861 - val_acc: 0.2935
2025-10-12 08:50:45,365 - INFO - _models.training_function_executor - Epoch 011/46 - train_loss: 2.6453 - val_loss: 3.3599 - val_acc: 0.2279
2025-10-12 08:51:00,311 - INFO - _models.training_function_executor - Epoch 012/46 - train_loss: 2.9001 - val_loss: 5.6808 - val_acc: 0.2154
2025-10-12 08:51:15,314 - INFO - _models.training_function_executor - Epoch 013/46 - train_loss: 2.8521 - val_loss: 3.6639 - val_acc: 0.2242
2025-10-12 08:51:30,274 - INFO - _models.training_function_executor - Epoch 014/46 - train_loss: 2.9276 - val_loss: 4.5588 - val_acc: 0.2214
2025-10-12 08:51:45,277 - INFO - _models.training_function_executor - Epoch 015/46 - train_loss: 2.8865 - val_loss: 4.5129 - val_acc: 0.2825
2025-10-12 08:52:00,273 - INFO - _models.training_function_executor - Epoch 016/46 - train_loss: 2.9374 - val_loss: 3.9384 - val_acc: 0.3078
2025-10-12 08:52:15,268 - INFO - _models.training_function_executor - Epoch 017/46 - train_loss: 2.8311 - val_loss: 3.3191 - val_acc: 0.2277
2025-10-12 08:52:30,241 - INFO - _models.training_function_executor - Epoch 018/46 - train_loss: 2.8116 - val_loss: 3.4411 - val_acc: 0.5889
2025-10-12 08:52:45,191 - INFO - _models.training_function_executor - Epoch 019/46 - train_loss: 2.6927 - val_loss: 4.2852 - val_acc: 0.2223
2025-10-12 08:53:00,189 - INFO - _models.training_function_executor - Epoch 020/46 - train_loss: 3.4191 - val_loss: 9.3192 - val_acc: 0.2173
2025-10-12 08:53:15,181 - INFO - _models.training_function_executor - Epoch 021/46 - train_loss: 3.0357 - val_loss: 3.1093 - val_acc: 0.2493
2025-10-12 08:53:30,171 - INFO - _models.training_function_executor - Epoch 022/46 - train_loss: 2.9089 - val_loss: 3.4610 - val_acc: 0.2325
2025-10-12 08:53:45,122 - INFO - _models.training_function_executor - Epoch 023/46 - train_loss: 3.0728 - val_loss: 5.4789 - val_acc: 0.2475
2025-10-12 08:54:00,082 - INFO - _models.training_function_executor - Epoch 024/46 - train_loss: 3.0339 - val_loss: 6.2121 - val_acc: 0.2882
2025-10-12 08:54:15,053 - INFO - _models.training_function_executor - Epoch 025/46 - train_loss: 3.2266 - val_loss: 5.1544 - val_acc: 0.4211
2025-10-12 08:54:30,061 - INFO - _models.training_function_executor - Epoch 026/46 - train_loss: 3.0604 - val_loss: 6.0281 - val_acc: 0.2244
2025-10-12 08:54:45,068 - INFO - _models.training_function_executor - Epoch 027/46 - train_loss: 3.1714 - val_loss: 3.0161 - val_acc: 0.4415
2025-10-12 08:55:00,051 - INFO - _models.training_function_executor - Epoch 028/46 - train_loss: 2.9269 - val_loss: 6.9556 - val_acc: 0.2274
2025-10-12 08:55:15,036 - INFO - _models.training_function_executor - Epoch 029/46 - train_loss: 3.3797 - val_loss: 3.3517 - val_acc: 0.2902
2025-10-12 08:55:30,018 - INFO - _models.training_function_executor - Epoch 030/46 - train_loss: 2.8438 - val_loss: 3.6444 - val_acc: 0.2385
2025-10-12 08:55:44,986 - INFO - _models.training_function_executor - Epoch 031/46 - train_loss: 3.0685 - val_loss: 3.5389 - val_acc: 0.2931
2025-10-12 08:55:59,995 - INFO - _models.training_function_executor - Epoch 032/46 - train_loss: 3.5876 - val_loss: 6.2897 - val_acc: 0.2282
2025-10-12 08:56:15,014 - INFO - _models.training_function_executor - Epoch 033/46 - train_loss: 3.4997 - val_loss: 3.8515 - val_acc: 0.2307
2025-10-12 08:56:29,981 - INFO - _models.training_function_executor - Epoch 034/46 - train_loss: 3.5137 - val_loss: 5.2266 - val_acc: 0.5899
2025-10-12 08:56:44,971 - INFO - _models.training_function_executor - Epoch 035/46 - train_loss: 3.2980 - val_loss: 3.4127 - val_acc: 0.2279
2025-10-12 08:56:59,982 - INFO - _models.training_function_executor - Epoch 036/46 - train_loss: 3.3162 - val_loss: 5.2264 - val_acc: 0.2867
2025-10-12 08:57:14,988 - INFO - _models.training_function_executor - Epoch 037/46 - train_loss: 3.3199 - val_loss: 2.8282 - val_acc: 0.3505
2025-10-12 08:57:30,001 - INFO - _models.training_function_executor - Epoch 038/46 - train_loss: 3.3697 - val_loss: 2.7485 - val_acc: 0.5933
2025-10-12 08:57:44,975 - INFO - _models.training_function_executor - Epoch 039/46 - train_loss: 3.2519 - val_loss: 3.6867 - val_acc: 0.4028
2025-10-12 08:57:59,946 - INFO - _models.training_function_executor - Epoch 040/46 - train_loss: 3.8045 - val_loss: 4.0078 - val_acc: 0.2685
2025-10-12 08:58:14,931 - INFO - _models.training_function_executor - Epoch 041/46 - train_loss: 3.4113 - val_loss: 5.8474 - val_acc: 0.5129
2025-10-12 08:58:29,937 - INFO - _models.training_function_executor - Epoch 042/46 - train_loss: 3.1584 - val_loss: 4.5109 - val_acc: 0.2274
2025-10-12 08:58:44,940 - INFO - _models.training_function_executor - Epoch 043/46 - train_loss: 3.5176 - val_loss: 4.1511 - val_acc: 0.2435
2025-10-12 08:58:59,918 - INFO - _models.training_function_executor - Epoch 044/46 - train_loss: 3.5923 - val_loss: 4.4387 - val_acc: 0.6040
2025-10-12 08:59:14,937 - INFO - _models.training_function_executor - Epoch 045/46 - train_loss: 3.4539 - val_loss: 4.5692 - val_acc: 0.5159
2025-10-12 08:59:29,925 - INFO - _models.training_function_executor - Epoch 046/46 - train_loss: 3.5730 - val_loss: 2.9390 - val_acc: 0.6333
2025-10-12 08:59:29,927 - INFO - _models.training_function_executor - Model: 64,889 parameters, 278.8KB storage
2025-10-12 08:59:29,927 - WARNING - _models.training_function_executor - Model storage 278.8KB exceeds 256KB limit!
2025-10-12 08:59:29,927 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.9852063618717721, 2.0628203592978034, 2.311600167892344, 2.360498413073253, 2.393863496473297, 2.610874231937343, 2.634971254306696, 2.7219866537989374, 2.733989134592571, 2.611347061209967, 2.64530206769757, 2.9000726759245983, 2.852124032583694, 2.9275922617129524, 2.8864967043182004, 2.9373734944927388, 2.83113147609919, 2.8116388877956107, 2.692681272504711, 3.419111522044341, 3.0356805737635284, 2.908877279151767, 3.0727618467486484, 3.03394642533812, 3.226562654091672, 3.060446859699552, 3.171391697083481, 2.9268926968723066, 3.3796899575305894, 2.843776870324639, 3.068474596181782, 3.5875788260724604, 3.4996651320095284, 3.513691802520538, 3.2980097353687894, 3.3162004291740046, 3.3198830359959293, 3.369677757482492, 3.251878737235011, 3.8045273503098906, 3.411324077775773, 3.158391209428111, 3.517635417226565, 3.5922600976812453, 3.4539450987427642, 3.5730428311805604], 'val_losses': [2.201474874721443, 2.8171364106955044, 3.7841245513885307, 3.2856998333448626, 1.7719810759224255, 6.967074600015439, 2.9767834080404696, 3.942925813192248, 9.363834652485112, 6.586074635495996, 3.3599020656189134, 5.680768178900431, 3.6638599319144234, 4.558757936032368, 4.512925145172931, 3.938435240396053, 3.3191140764528195, 3.44112000333541, 4.285195169058303, 9.319163825823203, 3.109308281685866, 3.4610381139755915, 5.478863028158122, 6.212060202991458, 5.154427466127144, 6.028140354540367, 3.016144509327174, 6.955642235375051, 3.3517220254790585, 3.644401844456599, 3.538933804329768, 6.289709158739845, 3.851479988311778, 5.226568597073233, 3.412738046739583, 5.226395708971354, 2.828204907776803, 2.74846042170573, 3.686671864957212, 4.007782348686889, 5.847446623906666, 4.51085299873085, 4.151093335430398, 4.4387498704712, 4.569156016425565, 2.9390275566820754], 'val_acc': [0.46246062303115154, 0.5007875393769688, 0.21771088554427723, 0.20799789989499476, 0.5044627231361568, 0.28018900945047254, 0.22427371368568427, 0.22278613930696534, 0.2554252712635632, 0.2934896744837242, 0.22794889744487223, 0.21543577178858944, 0.2241862093104655, 0.22138606930346516, 0.2824641232061603, 0.307840392019601, 0.22768638431921595, 0.5889044452222612, 0.22226111305565277, 0.21727336366818342, 0.2492999649982499, 0.2324991249562478, 0.24746237311865593, 0.28823941197059855, 0.42107105355267765, 0.2244487224361218, 0.4414595729786489, 0.22742387119355967, 0.2901645082254113, 0.2385369268463423, 0.29313965698284916, 0.22821141057052852, 0.23074903745187259, 0.5898669933496675, 0.22786139306965347, 0.28666433321666085, 0.3505425271263563, 0.5932796639831992, 0.4027826391319566, 0.26846342317115857, 0.5128631431571579, 0.22742387119355967, 0.2435246762338117, 0.603955197759888, 0.5159257962898145, 0.6332691634581729], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.06515455979659397, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.0399760746584102e-06, 'dropout': 0.04374324781857231, 'base_channels': 21, 'temporal_kernel': 3, 'spatial_segments': 24, 'label_smoothing': 0.10769652635384803, 'grad_clip': 0.6173229005201537, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 1698}, 'model_parameter_count': 64889, 'model_storage_size_kb': 278.81992187500003, 'model_size_validation': 'FAIL'}
2025-10-12 08:59:29,927 - INFO - _models.training_function_executor - BO Objective: base=0.6333, size_penalty=0.0446, final=0.5887
2025-10-12 08:59:29,927 - INFO - _models.training_function_executor - Model: 64,889 parameters, 278.8KB (FAIL 256KB limit)
2025-10-12 08:59:29,927 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 690.214s
2025-10-12 08:59:30,057 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5887
2025-10-12 08:59:30,057 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.115s
2025-10-12 08:59:30,057 - INFO - bo.run_bo - Recorded observation #44: hparams={'lr': 0.06515455979659397, 'batch_size': np.int64(64), 'epochs': np.int64(46), 'weight_decay': 1.0399760746584102e-06, 'dropout': 0.04374324781857231, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(24), 'label_smoothing': 0.10769652635384803, 'grad_clip': 0.6173229005201537, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(1698)}, value=0.5887
2025-10-12 08:59:30,057 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 44: {'lr': 0.06515455979659397, 'batch_size': np.int64(64), 'epochs': np.int64(46), 'weight_decay': 1.0399760746584102e-06, 'dropout': 0.04374324781857231, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(24), 'label_smoothing': 0.10769652635384803, 'grad_clip': 0.6173229005201537, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(1698)} -> 0.5887
2025-10-12 08:59:30,058 - INFO - bo.run_bo - üîçBO Trial 45: Using RF surrogate + Expected Improvement
2025-10-12 08:59:30,058 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 08:59:30,058 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 08:59:30,058 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 08:59:30,058 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.006905952458401957, 'batch_size': 16, 'epochs': 24, 'weight_decay': 2.1225910842245345e-06, 'dropout': 0.018438556990498903, 'base_channels': 20, 'temporal_kernel': 3, 'spatial_segments': 5, 'label_smoothing': 0.03282719425688948, 'grad_clip': 0.5763443227944065, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2615}
2025-10-12 08:59:30,059 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.006905952458401957, 'batch_size': 16, 'epochs': 24, 'weight_decay': 2.1225910842245345e-06, 'dropout': 0.018438556990498903, 'base_channels': 20, 'temporal_kernel': 3, 'spatial_segments': 5, 'label_smoothing': 0.03282719425688948, 'grad_clip': 0.5763443227944065, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2615}
2025-10-12 08:59:45,928 - INFO - _models.training_function_executor - Epoch 001/24 - train_loss: 1.0835 - val_loss: 0.8948 - val_acc: 0.6824
2025-10-12 09:00:01,737 - INFO - _models.training_function_executor - Epoch 002/24 - train_loss: 0.9095 - val_loss: 0.9424 - val_acc: 0.6628
2025-10-12 09:00:17,607 - INFO - _models.training_function_executor - Epoch 003/24 - train_loss: 0.8267 - val_loss: 0.8638 - val_acc: 0.6845
2025-10-12 09:00:33,578 - INFO - _models.training_function_executor - Epoch 004/24 - train_loss: 0.7821 - val_loss: 0.8241 - val_acc: 0.7073
2025-10-12 09:00:49,400 - INFO - _models.training_function_executor - Epoch 005/24 - train_loss: 0.7560 - val_loss: 0.7092 - val_acc: 0.7687
2025-10-12 09:01:05,239 - INFO - _models.training_function_executor - Epoch 006/24 - train_loss: 0.7404 - val_loss: 0.6969 - val_acc: 0.7716
2025-10-12 09:01:21,088 - INFO - _models.training_function_executor - Epoch 007/24 - train_loss: 0.7230 - val_loss: 0.7722 - val_acc: 0.7382
2025-10-12 09:01:36,930 - INFO - _models.training_function_executor - Epoch 008/24 - train_loss: 0.7125 - val_loss: 0.8186 - val_acc: 0.7217
2025-10-12 09:01:52,766 - INFO - _models.training_function_executor - Epoch 009/24 - train_loss: 0.6970 - val_loss: 0.6851 - val_acc: 0.7770
2025-10-12 09:02:08,540 - INFO - _models.training_function_executor - Epoch 010/24 - train_loss: 0.6883 - val_loss: 0.7180 - val_acc: 0.7586
2025-10-12 09:02:24,379 - INFO - _models.training_function_executor - Epoch 011/24 - train_loss: 0.6795 - val_loss: 0.7390 - val_acc: 0.7488
2025-10-12 09:02:40,234 - INFO - _models.training_function_executor - Epoch 012/24 - train_loss: 0.6682 - val_loss: 0.7965 - val_acc: 0.7143
2025-10-12 09:02:56,046 - INFO - _models.training_function_executor - Epoch 013/24 - train_loss: 0.6625 - val_loss: 0.6488 - val_acc: 0.7966
2025-10-12 09:03:11,874 - INFO - _models.training_function_executor - Epoch 014/24 - train_loss: 0.6647 - val_loss: 0.6668 - val_acc: 0.7789
2025-10-12 09:03:27,734 - INFO - _models.training_function_executor - Epoch 015/24 - train_loss: 0.6526 - val_loss: 0.6892 - val_acc: 0.7858
2025-10-12 09:03:43,573 - INFO - _models.training_function_executor - Epoch 016/24 - train_loss: 0.6516 - val_loss: 0.6504 - val_acc: 0.7875
2025-10-12 09:03:59,398 - INFO - _models.training_function_executor - Epoch 017/24 - train_loss: 0.6467 - val_loss: 0.6538 - val_acc: 0.7873
2025-10-12 09:04:15,225 - INFO - _models.training_function_executor - Epoch 018/24 - train_loss: 0.6418 - val_loss: 0.6581 - val_acc: 0.7889
2025-10-12 09:04:31,068 - INFO - _models.training_function_executor - Epoch 019/24 - train_loss: 0.6343 - val_loss: 0.7556 - val_acc: 0.7454
2025-10-12 09:04:46,930 - INFO - _models.training_function_executor - Epoch 020/24 - train_loss: 0.6342 - val_loss: 0.7073 - val_acc: 0.7681
2025-10-12 09:05:02,762 - INFO - _models.training_function_executor - Epoch 021/24 - train_loss: 0.6286 - val_loss: 0.7221 - val_acc: 0.7564
2025-10-12 09:05:18,576 - INFO - _models.training_function_executor - Epoch 022/24 - train_loss: 0.6237 - val_loss: 0.8082 - val_acc: 0.7212
2025-10-12 09:05:34,402 - INFO - _models.training_function_executor - Epoch 023/24 - train_loss: 0.6220 - val_loss: 0.6514 - val_acc: 0.7795
2025-10-12 09:05:50,264 - INFO - _models.training_function_executor - Epoch 024/24 - train_loss: 0.6209 - val_loss: 0.6357 - val_acc: 0.8036
2025-10-12 09:05:50,266 - INFO - _models.training_function_executor - Model: 57,345 parameters, 123.2KB storage
2025-10-12 09:05:50,266 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0834653076171707, 0.9094508549509492, 0.8266676828645934, 0.7821213054122899, 0.7559995911715537, 0.7403997449470977, 0.7230369055087558, 0.7125297965893264, 0.6970340372028991, 0.688348712195539, 0.6794894939646422, 0.6681509068014742, 0.662528923207077, 0.6646962138033014, 0.6525894651932027, 0.6515900634429986, 0.6466958887789022, 0.6417739179049249, 0.6343406672385092, 0.6342306227159533, 0.6286069177636159, 0.6236546178996083, 0.6219736542272367, 0.6209107979031597], 'val_losses': [0.8948153379625234, 0.942373351217109, 0.8637955249670214, 0.8240827675002582, 0.7091551405652486, 0.6968526479598731, 0.7722337179806502, 0.8186440006039298, 0.6850899397847032, 0.7180387341959475, 0.738984051777593, 0.7965161400655787, 0.6488416688422202, 0.666842676519221, 0.6892119710120781, 0.6503770673842458, 0.6537534174465991, 0.6580729244011534, 0.7556400218855304, 0.707309242495716, 0.7221358166234995, 0.8081808727355866, 0.6513756095924952, 0.6356553594299159], 'val_acc': [0.6823591179558978, 0.6628456422821141, 0.6845467273363668, 0.7072978648932446, 0.7687259362968148, 0.771613580679034, 0.7381869093454673, 0.7217360868043402, 0.7770388519425971, 0.7585754287714386, 0.7487749387469373, 0.7142982149107455, 0.7966398319915996, 0.7788764438221911, 0.7857892894644732, 0.7875393769688485, 0.7872768638431922, 0.7888519425971299, 0.7454497724886244, 0.7681134056702835, 0.7563878193909696, 0.7212110605530276, 0.7794889744487224, 0.8035526776338817], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.006905952458401957, 'batch_size': 16, 'epochs': 24, 'weight_decay': 2.1225910842245345e-06, 'dropout': 0.018438556990498903, 'base_channels': 20, 'temporal_kernel': 3, 'spatial_segments': 5, 'label_smoothing': 0.03282719425688948, 'grad_clip': 0.5763443227944065, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 2615}, 'model_parameter_count': 57345, 'model_storage_size_kb': 123.20214843750001, 'model_size_validation': 'PASS'}
2025-10-12 09:05:50,267 - INFO - _models.training_function_executor - BO Objective: base=0.8036, size_penalty=0.0000, final=0.8036
2025-10-12 09:05:50,267 - INFO - _models.training_function_executor - Model: 57,345 parameters, 123.2KB (PASS 256KB limit)
2025-10-12 09:05:50,267 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 380.209s
2025-10-12 09:05:50,387 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8036
2025-10-12 09:05:50,387 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.117s
2025-10-12 09:05:50,387 - INFO - bo.run_bo - Recorded observation #45: hparams={'lr': 0.006905952458401957, 'batch_size': np.int64(16), 'epochs': np.int64(24), 'weight_decay': 2.1225910842245345e-06, 'dropout': 0.018438556990498903, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(5), 'label_smoothing': 0.03282719425688948, 'grad_clip': 0.5763443227944065, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2615)}, value=0.8036
2025-10-12 09:05:50,387 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 45: {'lr': 0.006905952458401957, 'batch_size': np.int64(16), 'epochs': np.int64(24), 'weight_decay': 2.1225910842245345e-06, 'dropout': 0.018438556990498903, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(5), 'label_smoothing': 0.03282719425688948, 'grad_clip': 0.5763443227944065, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2615)} -> 0.8036
2025-10-12 09:05:50,388 - INFO - bo.run_bo - üîçBO Trial 46: Using RF surrogate + Expected Improvement
2025-10-12 09:05:50,388 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 09:05:50,388 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 09:05:50,388 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 09:05:50,388 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0015653565124801392, 'batch_size': 48, 'epochs': 17, 'weight_decay': 2.9048343008909173e-06, 'dropout': 0.019524631582602595, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 15, 'label_smoothing': 0.013778807326461575, 'grad_clip': 0.7218785917486631, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4491}
2025-10-12 09:05:50,389 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0015653565124801392, 'batch_size': 48, 'epochs': 17, 'weight_decay': 2.9048343008909173e-06, 'dropout': 0.019524631582602595, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 15, 'label_smoothing': 0.013778807326461575, 'grad_clip': 0.7218785917486631, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4491}
2025-10-12 09:06:05,116 - INFO - _models.training_function_executor - Epoch 001/17 - train_loss: 1.0417 - val_loss: 0.9081 - val_acc: 0.6457
2025-10-12 09:06:19,744 - INFO - _models.training_function_executor - Epoch 002/17 - train_loss: 0.7995 - val_loss: 0.9126 - val_acc: 0.6589
2025-10-12 09:06:34,381 - INFO - _models.training_function_executor - Epoch 003/17 - train_loss: 0.7343 - val_loss: 0.8927 - val_acc: 0.6712
2025-10-12 09:06:49,033 - INFO - _models.training_function_executor - Epoch 004/17 - train_loss: 0.6979 - val_loss: 0.6831 - val_acc: 0.7446
2025-10-12 09:07:03,670 - INFO - _models.training_function_executor - Epoch 005/17 - train_loss: 0.6725 - val_loss: 0.6928 - val_acc: 0.7447
2025-10-12 09:07:18,307 - INFO - _models.training_function_executor - Epoch 006/17 - train_loss: 0.6563 - val_loss: 0.7709 - val_acc: 0.7143
2025-10-12 09:07:32,962 - INFO - _models.training_function_executor - Epoch 007/17 - train_loss: 0.6325 - val_loss: 0.6795 - val_acc: 0.7472
2025-10-12 09:07:47,593 - INFO - _models.training_function_executor - Epoch 008/17 - train_loss: 0.6154 - val_loss: 0.7547 - val_acc: 0.7349
2025-10-12 09:08:02,184 - INFO - _models.training_function_executor - Epoch 009/17 - train_loss: 0.6070 - val_loss: 0.7481 - val_acc: 0.7251
2025-10-12 09:08:16,852 - INFO - _models.training_function_executor - Epoch 010/17 - train_loss: 0.6017 - val_loss: 0.6828 - val_acc: 0.7482
2025-10-12 09:08:31,466 - INFO - _models.training_function_executor - Epoch 011/17 - train_loss: 0.5932 - val_loss: 0.6472 - val_acc: 0.7550
2025-10-12 09:08:46,097 - INFO - _models.training_function_executor - Epoch 012/17 - train_loss: 0.5867 - val_loss: 0.5642 - val_acc: 0.7973
2025-10-12 09:09:00,734 - INFO - _models.training_function_executor - Epoch 013/17 - train_loss: 0.5779 - val_loss: 0.6758 - val_acc: 0.7667
2025-10-12 09:09:15,340 - INFO - _models.training_function_executor - Epoch 014/17 - train_loss: 0.5697 - val_loss: 0.9299 - val_acc: 0.7160
2025-10-12 09:09:29,948 - INFO - _models.training_function_executor - Epoch 015/17 - train_loss: 0.5684 - val_loss: 0.7298 - val_acc: 0.7453
2025-10-12 09:09:44,561 - INFO - _models.training_function_executor - Epoch 016/17 - train_loss: 0.5613 - val_loss: 0.9096 - val_acc: 0.6775
2025-10-12 09:09:59,176 - INFO - _models.training_function_executor - Epoch 017/17 - train_loss: 0.5573 - val_loss: 0.5936 - val_acc: 0.7831
2025-10-12 09:09:59,178 - INFO - _models.training_function_executor - Model: 59,025 parameters, 126.8KB storage
2025-10-12 09:09:59,179 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0417166855062352, 0.799511812494316, 0.7342651856083281, 0.6978618801161673, 0.6724800771668861, 0.6562845939036888, 0.6325326429345535, 0.6154199014249948, 0.6069786157230835, 0.601651739669422, 0.5932463032405695, 0.5866612491384018, 0.577899678472376, 0.5697381905337752, 0.5683862392536025, 0.5613075392956411, 0.5573323280672782], 'val_losses': [0.9081225304450028, 0.9125840116682109, 0.8927183456257335, 0.6831407065382361, 0.692810054567255, 0.7708849945517324, 0.6795048551476832, 0.754663426464239, 0.7481490116374744, 0.6827830902796589, 0.6472239178567238, 0.564223051790929, 0.6758323704545466, 0.9299096246261384, 0.7297502288273426, 0.9095925603519589, 0.5935713292878951], 'val_acc': [0.6456947847392369, 0.6589079453972698, 0.6712460623031151, 0.7445747287364368, 0.7447497374868743, 0.7142982149107455, 0.7471998599929996, 0.7348617430871544, 0.7250612530626531, 0.7482499124956248, 0.7549877493874694, 0.7972523626181309, 0.7667133356667833, 0.7160483024151207, 0.7452747637381869, 0.6774588729436472, 0.7830766538326916], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0015653565124801392, 'batch_size': 48, 'epochs': 17, 'weight_decay': 2.9048343008909173e-06, 'dropout': 0.019524631582602595, 'base_channels': 20, 'temporal_kernel': 9, 'spatial_segments': 15, 'label_smoothing': 0.013778807326461575, 'grad_clip': 0.7218785917486631, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4491}, 'model_parameter_count': 59025, 'model_storage_size_kb': 126.81152343750001, 'model_size_validation': 'PASS'}
2025-10-12 09:09:59,179 - INFO - _models.training_function_executor - BO Objective: base=0.7831, size_penalty=0.0000, final=0.7831
2025-10-12 09:09:59,179 - INFO - _models.training_function_executor - Model: 59,025 parameters, 126.8KB (PASS 256KB limit)
2025-10-12 09:09:59,179 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 248.791s
2025-10-12 09:09:59,306 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7831
2025-10-12 09:09:59,306 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.117s
2025-10-12 09:09:59,306 - INFO - bo.run_bo - Recorded observation #46: hparams={'lr': 0.0015653565124801392, 'batch_size': np.int64(48), 'epochs': np.int64(17), 'weight_decay': 2.9048343008909173e-06, 'dropout': 0.019524631582602595, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(15), 'label_smoothing': 0.013778807326461575, 'grad_clip': 0.7218785917486631, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4491)}, value=0.7831
2025-10-12 09:09:59,306 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 46: {'lr': 0.0015653565124801392, 'batch_size': np.int64(48), 'epochs': np.int64(17), 'weight_decay': 2.9048343008909173e-06, 'dropout': 0.019524631582602595, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(15), 'label_smoothing': 0.013778807326461575, 'grad_clip': 0.7218785917486631, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4491)} -> 0.7831
2025-10-12 09:09:59,307 - INFO - bo.run_bo - üîçBO Trial 47: Using RF surrogate + Expected Improvement
2025-10-12 09:09:59,307 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 09:09:59,307 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 09:09:59,307 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 09:09:59,307 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0003610856832441494, 'batch_size': 64, 'epochs': 12, 'weight_decay': 2.5461026536206006e-06, 'dropout': 0.0036593212243026816, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 12, 'label_smoothing': 0.16631886258835804, 'grad_clip': 0.893892630235284, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 3053}
2025-10-12 09:09:59,308 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0003610856832441494, 'batch_size': 64, 'epochs': 12, 'weight_decay': 2.5461026536206006e-06, 'dropout': 0.0036593212243026816, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 12, 'label_smoothing': 0.16631886258835804, 'grad_clip': 0.893892630235284, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 3053}
2025-10-12 09:10:14,407 - INFO - _models.training_function_executor - Epoch 001/12 - train_loss: 1.3075 - val_loss: 1.2267 - val_acc: 0.5959
2025-10-12 09:10:29,430 - INFO - _models.training_function_executor - Epoch 002/12 - train_loss: 1.0858 - val_loss: 1.0843 - val_acc: 0.6922
2025-10-12 09:10:44,472 - INFO - _models.training_function_executor - Epoch 003/12 - train_loss: 1.0296 - val_loss: 1.3867 - val_acc: 0.5095
2025-10-12 09:10:59,470 - INFO - _models.training_function_executor - Epoch 004/12 - train_loss: 0.9963 - val_loss: 1.0216 - val_acc: 0.7309
2025-10-12 09:11:14,485 - INFO - _models.training_function_executor - Epoch 005/12 - train_loss: 0.9747 - val_loss: 0.9683 - val_acc: 0.7707
2025-10-12 09:11:29,519 - INFO - _models.training_function_executor - Epoch 006/12 - train_loss: 0.9565 - val_loss: 1.0350 - val_acc: 0.7226
2025-10-12 09:11:44,533 - INFO - _models.training_function_executor - Epoch 007/12 - train_loss: 0.9404 - val_loss: 1.0001 - val_acc: 0.7479
2025-10-12 09:11:59,547 - INFO - _models.training_function_executor - Epoch 008/12 - train_loss: 0.9308 - val_loss: 1.0401 - val_acc: 0.7250
2025-10-12 09:12:14,576 - INFO - _models.training_function_executor - Epoch 009/12 - train_loss: 0.9213 - val_loss: 0.9510 - val_acc: 0.7771
2025-10-12 09:12:29,621 - INFO - _models.training_function_executor - Epoch 010/12 - train_loss: 0.9175 - val_loss: 1.2385 - val_acc: 0.6168
2025-10-12 09:12:44,625 - INFO - _models.training_function_executor - Epoch 011/12 - train_loss: 0.9120 - val_loss: 0.9490 - val_acc: 0.7776
2025-10-12 09:12:59,606 - INFO - _models.training_function_executor - Epoch 012/12 - train_loss: 0.9074 - val_loss: 0.9347 - val_acc: 0.7867
2025-10-12 09:12:59,608 - INFO - _models.training_function_executor - Model: 63,989 parameters, 275.0KB storage
2025-10-12 09:12:59,608 - WARNING - _models.training_function_executor - Model storage 275.0KB exceeds 256KB limit!
2025-10-12 09:12:59,608 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3075403618904358, 1.085767880994872, 1.0295630882868703, 0.9963481481733713, 0.9747168268404685, 0.9564836156464224, 0.9403849516375564, 0.9308172194825046, 0.9212922697347655, 0.9175147371021735, 0.9119761310176162, 0.9074368952953777], 'val_losses': [1.2267334820884568, 1.0842930474479924, 1.3866853446947096, 1.0215825782107606, 0.968321244992866, 1.0350198338905496, 1.0000730175883528, 1.0401316418445816, 0.9510493242202375, 1.2384562358432272, 0.9490368024928193, 0.9346859679590959], 'val_acc': [0.595904795239762, 0.6922471123556178, 0.509537976898845, 0.7309240462023101, 0.7706510325516276, 0.7226111305565278, 0.7478998949947497, 0.7249737486874344, 0.7771263563178159, 0.6168183409170459, 0.7775638781939097, 0.7866643332166608], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0003610856832441494, 'batch_size': 64, 'epochs': 12, 'weight_decay': 2.5461026536206006e-06, 'dropout': 0.0036593212243026816, 'base_channels': 21, 'temporal_kernel': 5, 'spatial_segments': 12, 'label_smoothing': 0.16631886258835804, 'grad_clip': 0.893892630235284, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_samples': 3053}, 'model_parameter_count': 63989, 'model_storage_size_kb': 274.95273437500003, 'model_size_validation': 'FAIL'}
2025-10-12 09:12:59,608 - INFO - _models.training_function_executor - BO Objective: base=0.7867, size_penalty=0.0370, final=0.7496
2025-10-12 09:12:59,608 - INFO - _models.training_function_executor - Model: 63,989 parameters, 275.0KB (FAIL 256KB limit)
2025-10-12 09:12:59,608 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 180.302s
2025-10-12 09:12:59,740 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7496
2025-10-12 09:12:59,740 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.117s
2025-10-12 09:12:59,740 - INFO - bo.run_bo - Recorded observation #47: hparams={'lr': 0.0003610856832441494, 'batch_size': np.int64(64), 'epochs': np.int64(12), 'weight_decay': 2.5461026536206006e-06, 'dropout': 0.0036593212243026816, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(12), 'label_smoothing': 0.16631886258835804, 'grad_clip': 0.893892630235284, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(3053)}, value=0.7496
2025-10-12 09:12:59,740 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 47: {'lr': 0.0003610856832441494, 'batch_size': np.int64(64), 'epochs': np.int64(12), 'weight_decay': 2.5461026536206006e-06, 'dropout': 0.0036593212243026816, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(5), 'spatial_segments': np.int64(12), 'label_smoothing': 0.16631886258835804, 'grad_clip': 0.893892630235284, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(3053)} -> 0.7496
2025-10-12 09:12:59,740 - INFO - bo.run_bo - üîçBO Trial 48: Using RF surrogate + Expected Improvement
2025-10-12 09:12:59,740 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 09:12:59,740 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 09:12:59,740 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 09:12:59,741 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.839220748459567e-05, 'batch_size': 48, 'epochs': 19, 'weight_decay': 1.0182824384306812e-06, 'dropout': 0.004928643010700396, 'base_channels': 21, 'temporal_kernel': 9, 'spatial_segments': 25, 'label_smoothing': 0.05851809685629431, 'grad_clip': 0.24869990544736015, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4996}
2025-10-12 09:12:59,742 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.839220748459567e-05, 'batch_size': 48, 'epochs': 19, 'weight_decay': 1.0182824384306812e-06, 'dropout': 0.004928643010700396, 'base_channels': 21, 'temporal_kernel': 9, 'spatial_segments': 25, 'label_smoothing': 0.05851809685629431, 'grad_clip': 0.24869990544736015, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4996}
2025-10-12 09:13:15,430 - INFO - _models.training_function_executor - Epoch 001/19 - train_loss: 1.4531 - val_loss: 1.3613 - val_acc: 0.4678
2025-10-12 09:13:30,706 - INFO - _models.training_function_executor - Epoch 002/19 - train_loss: 1.1975 - val_loss: 1.1235 - val_acc: 0.6182
2025-10-12 09:13:45,966 - INFO - _models.training_function_executor - Epoch 003/19 - train_loss: 1.0958 - val_loss: 1.2460 - val_acc: 0.5437
2025-10-12 09:14:01,240 - INFO - _models.training_function_executor - Epoch 004/19 - train_loss: 1.0259 - val_loss: 1.0095 - val_acc: 0.6385
2025-10-12 09:14:16,530 - INFO - _models.training_function_executor - Epoch 005/19 - train_loss: 0.9770 - val_loss: 1.0747 - val_acc: 0.5915
2025-10-12 09:14:31,815 - INFO - _models.training_function_executor - Epoch 006/19 - train_loss: 0.9405 - val_loss: 1.0512 - val_acc: 0.6315
2025-10-12 09:14:47,059 - INFO - _models.training_function_executor - Epoch 007/19 - train_loss: 0.9097 - val_loss: 0.8980 - val_acc: 0.7088
2025-10-12 09:15:02,363 - INFO - _models.training_function_executor - Epoch 008/19 - train_loss: 0.8833 - val_loss: 0.9286 - val_acc: 0.6859
2025-10-12 09:15:17,650 - INFO - _models.training_function_executor - Epoch 009/19 - train_loss: 0.8600 - val_loss: 0.8681 - val_acc: 0.7283
2025-10-12 09:15:32,943 - INFO - _models.training_function_executor - Epoch 010/19 - train_loss: 0.8434 - val_loss: 0.8842 - val_acc: 0.7106
2025-10-12 09:15:48,240 - INFO - _models.training_function_executor - Epoch 011/19 - train_loss: 0.8282 - val_loss: 0.8087 - val_acc: 0.7473
2025-10-12 09:16:03,519 - INFO - _models.training_function_executor - Epoch 012/19 - train_loss: 0.8106 - val_loss: 0.9667 - val_acc: 0.6664
2025-10-12 09:16:18,806 - INFO - _models.training_function_executor - Epoch 013/19 - train_loss: 0.8011 - val_loss: 0.8428 - val_acc: 0.7296
2025-10-12 09:16:34,044 - INFO - _models.training_function_executor - Epoch 014/19 - train_loss: 0.7962 - val_loss: 0.8109 - val_acc: 0.7459
2025-10-12 09:16:49,326 - INFO - _models.training_function_executor - Epoch 015/19 - train_loss: 0.7835 - val_loss: 0.7856 - val_acc: 0.7581
2025-10-12 09:17:04,584 - INFO - _models.training_function_executor - Epoch 016/19 - train_loss: 0.7750 - val_loss: 0.8638 - val_acc: 0.7129
2025-10-12 09:17:19,822 - INFO - _models.training_function_executor - Epoch 017/19 - train_loss: 0.7703 - val_loss: 0.7836 - val_acc: 0.7600
2025-10-12 09:17:35,087 - INFO - _models.training_function_executor - Epoch 018/19 - train_loss: 0.7656 - val_loss: 0.7901 - val_acc: 0.7490
2025-10-12 09:17:50,345 - INFO - _models.training_function_executor - Epoch 019/19 - train_loss: 0.7584 - val_loss: 0.8888 - val_acc: 0.6986
2025-10-12 09:17:50,348 - INFO - _models.training_function_executor - Model: 65,741 parameters, 141.2KB storage
2025-10-12 09:17:50,348 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4530891946532905, 1.197492702528026, 1.0957781899254933, 1.0258809818560568, 0.9769748085689244, 0.9405000268641076, 0.9096835899653449, 0.8832520013469727, 0.8600442331697626, 0.8433671807925686, 0.8281569152100335, 0.8106074566018302, 0.8011129166973944, 0.7962142315243023, 0.7834679750575024, 0.7749592380420203, 0.7702933851555173, 0.765615229928748, 0.7584412445294344], 'val_losses': [1.3613426273921423, 1.1235256305014625, 1.245967802902932, 1.0094750576349751, 1.0747466123433727, 1.0511684958276357, 0.897999349406519, 0.9285581698148953, 0.8681196100360495, 0.8842101862558253, 0.8086720534584344, 0.9666860889086658, 0.842803089225213, 0.8109383015604256, 0.7856299037652955, 0.8637922692015156, 0.7836404513720244, 0.7901190860646148, 0.888763193968171], 'val_acc': [0.46779838991949596, 0.6182184109205461, 0.5436646832341617, 0.6385194259712985, 0.591529576478824, 0.6315190759537976, 0.7087854392719636, 0.685946797339867, 0.7282989149457473, 0.7106230311515576, 0.7472873643682184, 0.6664333216660833, 0.7296114805740287, 0.7458872943647182, 0.7581379068953448, 0.7128981449072453, 0.7599754987749388, 0.7490374518725936, 0.6986349317465873], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.839220748459567e-05, 'batch_size': 48, 'epochs': 19, 'weight_decay': 1.0182824384306812e-06, 'dropout': 0.004928643010700396, 'base_channels': 21, 'temporal_kernel': 9, 'spatial_segments': 25, 'label_smoothing': 0.05851809685629431, 'grad_clip': 0.24869990544736015, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_samples': 4996}, 'model_parameter_count': 65741, 'model_storage_size_kb': 141.2404296875, 'model_size_validation': 'PASS'}
2025-10-12 09:17:50,348 - INFO - _models.training_function_executor - BO Objective: base=0.6986, size_penalty=0.0000, final=0.6986
2025-10-12 09:17:50,348 - INFO - _models.training_function_executor - Model: 65,741 parameters, 141.2KB (PASS 256KB limit)
2025-10-12 09:17:50,348 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 290.607s
2025-10-12 09:17:50,477 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6986
2025-10-12 09:17:50,477 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.118s
2025-10-12 09:17:50,477 - INFO - bo.run_bo - Recorded observation #48: hparams={'lr': 8.839220748459567e-05, 'batch_size': np.int64(48), 'epochs': np.int64(19), 'weight_decay': 1.0182824384306812e-06, 'dropout': 0.004928643010700396, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(25), 'label_smoothing': 0.05851809685629431, 'grad_clip': 0.24869990544736015, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4996)}, value=0.6986
2025-10-12 09:17:50,477 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 48: {'lr': 8.839220748459567e-05, 'batch_size': np.int64(48), 'epochs': np.int64(19), 'weight_decay': 1.0182824384306812e-06, 'dropout': 0.004928643010700396, 'base_channels': np.int64(21), 'temporal_kernel': np.int64(9), 'spatial_segments': np.int64(25), 'label_smoothing': 0.05851809685629431, 'grad_clip': 0.24869990544736015, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(4996)} -> 0.6986
2025-10-12 09:17:50,478 - INFO - bo.run_bo - üîçBO Trial 49: Using RF surrogate + Expected Improvement
2025-10-12 09:17:50,478 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 09:17:50,478 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 09:17:50,478 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 09:17:50,478 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.005341231339628704, 'batch_size': 48, 'epochs': 7, 'weight_decay': 2.782270024902906e-06, 'dropout': 0.05251975779331554, 'base_channels': 16, 'temporal_kernel': 3, 'spatial_segments': 40, 'label_smoothing': 0.06270069797652073, 'grad_clip': 0.7572105634771514, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 810}
2025-10-12 09:17:50,479 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.005341231339628704, 'batch_size': 48, 'epochs': 7, 'weight_decay': 2.782270024902906e-06, 'dropout': 0.05251975779331554, 'base_channels': 16, 'temporal_kernel': 3, 'spatial_segments': 40, 'label_smoothing': 0.06270069797652073, 'grad_clip': 0.7572105634771514, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 810}
2025-10-12 09:18:02,791 - INFO - _models.training_function_executor - Epoch 001/7 - train_loss: 1.1132 - val_loss: 0.9970 - val_acc: 0.6479
2025-10-12 09:18:14,752 - INFO - _models.training_function_executor - Epoch 002/7 - train_loss: 0.9472 - val_loss: 0.9878 - val_acc: 0.6570
2025-10-12 09:18:26,714 - INFO - _models.training_function_executor - Epoch 003/7 - train_loss: 0.8769 - val_loss: 0.9033 - val_acc: 0.7044
2025-10-12 09:18:38,655 - INFO - _models.training_function_executor - Epoch 004/7 - train_loss: 0.8332 - val_loss: 0.7943 - val_acc: 0.7499
2025-10-12 09:18:50,602 - INFO - _models.training_function_executor - Epoch 005/7 - train_loss: 0.8059 - val_loss: 0.8917 - val_acc: 0.7096
2025-10-12 09:19:02,509 - INFO - _models.training_function_executor - Epoch 006/7 - train_loss: 0.7919 - val_loss: 0.8591 - val_acc: 0.7236
2025-10-12 09:19:14,462 - INFO - _models.training_function_executor - Epoch 007/7 - train_loss: 0.7777 - val_loss: 0.7661 - val_acc: 0.7704
2025-10-12 09:19:14,464 - INFO - _models.training_function_executor - Model: 40,585 parameters, 174.4KB storage
2025-10-12 09:19:14,464 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.113208077276842, 0.9471671686624789, 0.8768628547564644, 0.8331551250770537, 0.8058612855072409, 0.7919422485088192, 0.7776720871614917], 'val_losses': [0.9970419398963055, 0.9877783266405648, 0.9032689846600942, 0.7942571663589464, 0.8917285743442331, 0.8590930358780235, 0.7661472498056227], 'val_acc': [0.6478823941197059, 0.6569828491424571, 0.7044102205110255, 0.7499124956247812, 0.7095729786489324, 0.7235736786839342, 0.7703885194259713], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.005341231339628704, 'batch_size': 48, 'epochs': 7, 'weight_decay': 2.782270024902906e-06, 'dropout': 0.05251975779331554, 'base_channels': 16, 'temporal_kernel': 3, 'spatial_segments': 40, 'label_smoothing': 0.06270069797652073, 'grad_clip': 0.7572105634771514, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_samples': 810}, 'model_parameter_count': 40585, 'model_storage_size_kb': 174.388671875, 'model_size_validation': 'PASS'}
2025-10-12 09:19:14,464 - INFO - _models.training_function_executor - BO Objective: base=0.7704, size_penalty=0.0000, final=0.7704
2025-10-12 09:19:14,464 - INFO - _models.training_function_executor - Model: 40,585 parameters, 174.4KB (PASS 256KB limit)
2025-10-12 09:19:14,464 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 83.987s
2025-10-12 09:19:14,592 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7704
2025-10-12 09:19:14,592 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.119s
2025-10-12 09:19:14,592 - INFO - bo.run_bo - Recorded observation #49: hparams={'lr': 0.005341231339628704, 'batch_size': np.int64(48), 'epochs': np.int64(7), 'weight_decay': 2.782270024902906e-06, 'dropout': 0.05251975779331554, 'base_channels': np.int64(16), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(40), 'label_smoothing': 0.06270069797652073, 'grad_clip': 0.7572105634771514, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(810)}, value=0.7704
2025-10-12 09:19:14,592 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 49: {'lr': 0.005341231339628704, 'batch_size': np.int64(48), 'epochs': np.int64(7), 'weight_decay': 2.782270024902906e-06, 'dropout': 0.05251975779331554, 'base_channels': np.int64(16), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(40), 'label_smoothing': 0.06270069797652073, 'grad_clip': 0.7572105634771514, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(810)} -> 0.7704
2025-10-12 09:19:14,592 - INFO - bo.run_bo - üîçBO Trial 50: Using RF surrogate + Expected Improvement
2025-10-12 09:19:14,592 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 09:19:14,592 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 09:19:14,593 - INFO - _models.training_function_executor - Executing training function: STMiniUSleepNet-Quant
2025-10-12 09:19:14,593 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.014618599834497904, 'batch_size': 16, 'epochs': 8, 'weight_decay': 1.613945808302857e-06, 'dropout': 0.4616644573898143, 'base_channels': 13, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.16567005269564028, 'grad_clip': 0.7848608899403368, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 2555}
2025-10-12 09:19:14,594 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.014618599834497904, 'batch_size': 16, 'epochs': 8, 'weight_decay': 1.613945808302857e-06, 'dropout': 0.4616644573898143, 'base_channels': 13, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.16567005269564028, 'grad_clip': 0.7848608899403368, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 2555}
2025-10-12 09:19:26,684 - INFO - _models.training_function_executor - Epoch 001/8 - train_loss: 1.6689 - val_loss: 1.4763 - val_acc: 0.4816
2025-10-12 09:19:38,703 - INFO - _models.training_function_executor - Epoch 002/8 - train_loss: 1.6749 - val_loss: 1.9110 - val_acc: 0.2394
2025-10-12 09:19:50,774 - INFO - _models.training_function_executor - Epoch 003/8 - train_loss: 1.6807 - val_loss: 1.5443 - val_acc: 0.4317
2025-10-12 09:20:02,810 - INFO - _models.training_function_executor - Epoch 004/8 - train_loss: 1.6907 - val_loss: 1.9091 - val_acc: 0.2487
2025-10-12 09:20:14,887 - INFO - _models.training_function_executor - Epoch 005/8 - train_loss: 1.6858 - val_loss: 1.4586 - val_acc: 0.5527
2025-10-12 09:20:26,919 - INFO - _models.training_function_executor - Epoch 006/8 - train_loss: 1.6868 - val_loss: 1.4779 - val_acc: 0.5806
2025-10-12 09:20:38,982 - INFO - _models.training_function_executor - Epoch 007/8 - train_loss: 1.7162 - val_loss: 1.5054 - val_acc: 0.6047
2025-10-12 09:20:51,050 - INFO - _models.training_function_executor - Epoch 008/8 - train_loss: 1.7110 - val_loss: 1.4741 - val_acc: 0.5644
2025-10-12 09:20:51,053 - INFO - _models.training_function_executor - Model: 34,153 parameters, 73.4KB storage
2025-10-12 09:20:51,053 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6688502251288253, 1.6748818519610311, 1.6807137184056278, 1.690748968656805, 1.6857948159270242, 1.6867821748789933, 1.7161795223013772, 1.7109869749845639], 'val_losses': [1.4762915019434901, 1.9110219410177625, 1.544345189859953, 1.9090832869490002, 1.4586033728475707, 1.4778617040068693, 1.505391478413337, 1.4740735519003276], 'val_acc': [0.4816240812040602, 0.23941197059852992, 0.4317465873293665, 0.24868743437171859, 0.5526776338816941, 0.5805915295764789, 0.6047427371368569, 0.5644032201610081], 'model_name': 'STMiniUSleepNet-Quant', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.014618599834497904, 'batch_size': 16, 'epochs': 8, 'weight_decay': 1.613945808302857e-06, 'dropout': 0.4616644573898143, 'base_channels': 13, 'temporal_kernel': 3, 'spatial_segments': 100, 'label_smoothing': 0.16567005269564028, 'grad_clip': 0.7848608899403368, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibration_samples': 2555}, 'model_parameter_count': 34153, 'model_storage_size_kb': 73.3755859375, 'model_size_validation': 'PASS'}
2025-10-12 09:20:51,053 - INFO - _models.training_function_executor - BO Objective: base=0.5644, size_penalty=0.0000, final=0.5644
2025-10-12 09:20:51,053 - INFO - _models.training_function_executor - Model: 34,153 parameters, 73.4KB (PASS 256KB limit)
2025-10-12 09:20:51,053 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 96.461s
2025-10-12 09:20:51,174 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5644
2025-10-12 09:20:51,174 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.119s
2025-10-12 09:20:51,174 - INFO - bo.run_bo - Recorded observation #50: hparams={'lr': 0.014618599834497904, 'batch_size': np.int64(16), 'epochs': np.int64(8), 'weight_decay': 1.613945808302857e-06, 'dropout': 0.4616644573898143, 'base_channels': np.int64(13), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(100), 'label_smoothing': 0.16567005269564028, 'grad_clip': 0.7848608899403368, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(2555)}, value=0.5644
2025-10-12 09:20:51,174 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 50: {'lr': 0.014618599834497904, 'batch_size': np.int64(16), 'epochs': np.int64(8), 'weight_decay': 1.613945808302857e-06, 'dropout': 0.4616644573898143, 'base_channels': np.int64(13), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(100), 'label_smoothing': 0.16567005269564028, 'grad_clip': 0.7848608899403368, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibration_samples': np.int64(2555)} -> 0.5644
2025-10-12 09:20:51,174 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.8036
2025-10-12 09:20:51,174 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.006905952458401957, 'batch_size': np.int64(16), 'epochs': np.int64(24), 'weight_decay': 2.1225910842245345e-06, 'dropout': 0.018438556990498903, 'base_channels': np.int64(20), 'temporal_kernel': np.int64(3), 'spatial_segments': np.int64(5), 'label_smoothing': 0.03282719425688948, 'grad_clip': 0.5763443227944065, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibration_samples': np.int64(2615)}
2025-10-12 09:20:51,187 - INFO - visualization - Generating BO visualization charts with 50 trials...
2025-10-12 09:20:52,513 - INFO - visualization - BO summary saved to: charts/20251012_092051_BO_STMiniUSleepNet-Quant/bo_summary.txt
2025-10-12 09:20:52,517 - ERROR - evaluation.code_generation_pipeline_orchestrator - Failed to generate BO charts: Object of type int64 is not JSON serializable
2025-10-12 09:20:52,547 - INFO - evaluation.code_generation_pipeline_orchestrator - üöÄ STEP 4: Final Training Execution
2025-10-12 09:20:52,547 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (57140, 6, 6000), Val: (14286, 6, 6000), Test: (17857, 6, 6000)
