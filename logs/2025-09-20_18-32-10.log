2025-09-20 18:32:12,397 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti Laptop GPU
2025-09-20 18:32:12,745 - INFO - __main__ - Logging system initialized successfully
2025-09-20 18:32:12,745 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-09-20 18:32:12,746 - INFO - __main__ - Starting real data processing from data/ directory
2025-09-20 18:32:12,747 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'X.npy', 'y.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-09-20 18:32:12,747 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-09-20 18:32:12,748 - INFO - __main__ - Attempting to load: X.npy
2025-09-20 18:32:12,874 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-09-20 18:32:12,964 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (62352, 1000, 2), device: cuda
2025-09-20 18:32:12,965 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-09-20 18:32:12,965 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-09-20 18:32:12,965 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-09-20 18:32:12,967 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-20 18:32:12,968 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-09-20 18:32:12,968 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-09-20 18:32:12,968 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-09-20 18:32:12,968 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-09-20 18:32:12,968 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-09-20 18:32:12,968 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-09-20 18:32:12,968 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-09-20 18:32:12,968 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-09-20 18:32:13,178 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-09-20 18:32:13,178 - INFO - class_balancing - Class imbalance analysis:
2025-09-20 18:32:13,178 - INFO - class_balancing -   Strategy: severe_imbalance
2025-09-20 18:32:13,178 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-09-20 18:32:13,178 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-09-20 18:32:13,178 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-09-20 18:32:13,178 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-09-20 18:32:13,178 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-09-20 18:32:13,179 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-09-20 18:32:13,179 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-09-20 18:32:13,895 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-09-20 18:32:13,905 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-09-20 18:32:13,905 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-20 18:32:13,905 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-09-20 18:32:13,905 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-20 18:32:13,905 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-09-20 18:32:13,905 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-20 18:32:13,905 - INFO - _models.ai_code_generator - Prompt length: 2552 characters
2025-09-20 18:32:13,905 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-20 18:32:13,905 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-20 18:32:13,905 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-09-20 18:33:23,701 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-20 18:33:23,796 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-09-20 18:33:23,796 - INFO - _models.ai_code_generator - AI generated training function: ECG1DSeparableCNN
2025-09-20 18:33:23,796 - INFO - _models.ai_code_generator - Confidence: 0.90
2025-09-20 18:33:23,796 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: ECG1DSeparableCNN
2025-09-20 18:33:23,796 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'channels1', 'channels2', 'channels3', 'kernel_size1', 'kernel_size2', 'kernel_size3', 'pool_size', 'lr_scheduler', 'step_size', 'gamma', 'label_smoothing', 'early_stopping_patience', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_batches', 'per_channel']
2025-09-20 18:33:23,796 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.90
2025-09-20 18:33:23,798 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-09-20 18:33:23,801 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions\training_function_torch_tensor_ECG1DSeparableCNN_1758411203.json
2025-09-20 18:33:23,801 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions\training_function_torch_tensor_ECG1DSeparableCNN_1758411203.json
2025-09-20 18:33:23,801 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-09-20 18:33:23,801 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: ECG1DSeparableCNN
2025-09-20 18:33:23,801 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-09-20 18:33:23,803 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-09-20 18:33:23,807 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-09-20 18:33:23,807 - INFO - package_installer - Available packages: {'torch'}
2025-09-20 18:33:23,807 - INFO - package_installer - Missing packages: set()
2025-09-20 18:33:23,807 - INFO - package_installer - ‚úÖ All required packages are already available
2025-09-20 18:33:23,807 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-09-20 18:33:23,887 - INFO - data_splitting - Created BO subset: 5000 samples
2025-09-20 18:33:23,887 - INFO - data_splitting - BO subset class distribution: [3600  766   96  100  438]
2025-09-20 18:33:23,887 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 5000 samples (using bo_sample_num=5000)
2025-09-20 18:33:23,887 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'channels1', 'channels2', 'channels3', 'kernel_size1', 'kernel_size2', 'kernel_size3', 'pool_size', 'lr_scheduler', 'step_size', 'gamma', 'label_smoothing', 'early_stopping_patience', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_batches', 'per_channel']
2025-09-20 18:33:23,888 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti Laptop GPU
2025-09-20 18:33:23,971 - INFO - data_splitting - Created BO subset: 5000 samples
2025-09-20 18:33:23,972 - INFO - data_splitting - BO subset class distribution: [3600  766   96  100  438]
2025-09-20 18:33:23,972 - INFO - _models.training_function_executor - Using BO subset for optimization: 5000 samples (bo_sample_num=5000)
2025-09-20 18:33:23,982 - INFO - _models.training_function_executor - BO splits - Train: 4000, Val: 1000
2025-09-20 18:33:24,268 - INFO - bo.run_bo - Converted GPT search space: 22 parameters
2025-09-20 18:33:24,268 - INFO - bo.run_bo - Using GPT-generated search space
2025-09-20 18:33:24,269 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-20 18:33:24,269 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-09-20 18:33:24,271 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-20 18:33:24,271 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 18:33:24,271 - INFO - _models.training_function_executor - Executing training function: ECG1DSeparableCNN
2025-09-20 18:33:24,271 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}
2025-09-20 18:33:24,272 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}
2025-09-20 18:33:42,942 - INFO - _models.training_function_executor - Model parameter count: 42,305
2025-09-20 18:33:42,943 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7294407515525818, 0.3975371010303497, 0.3297265713214874, 0.3025114538669586, 0.2828053605556488, 0.2699089117050171, 0.2587050893306732, 0.23716789436340333, 0.23046363401412964, 0.22621991539001465, 0.222009361743927, 0.21868928360939027, 0.20926043486595153, 0.20941941237449646, 0.20898129796981813, 0.20451701581478118, 0.19859168648719788, 0.19793727040290832, 0.19311613464355468, 0.19270472371578218, 0.2016008630990982, 0.18913375651836395, 0.17835696732997894, 0.1801470000743866, 0.18134458589553834, 0.18566534066200258, 0.17869638860225678, 0.17674406063556672, 0.17420056676864623, 0.1800490894317627, 0.17823657298088075, 0.1671427857875824, 0.17671991395950318, 0.16716329956054687, 0.1697591781616211, 0.1730183438062668, 0.16282733774185182, 0.16731502270698548, 0.17066380763053893, 0.16673202800750733, 0.15907520246505738, 0.16371745800971985, 0.1667735002040863, 0.16418384432792663, 0.16055571866035462, 0.1618524079322815, 0.1575638760328293, 0.16004826521873475, 0.15964822554588318, 0.16508187580108644, 0.16247943329811096, 0.15808202242851258], 'val_losses': [0.46938941240310667, 0.38977412486076357, 0.3344648666381836, 0.36320503044128416, 0.27056779742240905, 0.32704579138755796, 0.281433287858963, 0.2979718611240387, 0.245976726770401, 0.27826257777214053, 0.2619783155918121, 0.23600386357307435, 0.25621847581863405, 0.2535340738296509, 0.24077868247032166, 0.22602010679244994, 0.2867005081176758, 0.23107102131843568, 0.23567164826393128, 0.26737774419784544, 0.3063420009613037, 0.22826414823532104, 0.2663455047607422, 0.23243853497505187, 0.28306065845489503, 0.21856758666038514, 0.2311334648132324, 0.2266848406791687, 0.27194203209877016, 0.260072847366333, 0.22266903972625732, 0.249609393119812, 0.23604427909851075, 0.2370098156929016, 0.23288969945907592, 0.317620174407959, 0.214923889875412, 0.24889965343475343, 0.24107992935180664, 0.23046343994140625, 0.2613815197944641, 0.23757709407806396, 0.23543303537368773, 0.22637631154060364, 0.3432301149368286, 0.23886893463134765, 0.35465020704269407, 0.23354149198532104, 0.23853668117523194, 0.32924824047088624, 0.24146623969078063, 0.2719887568950653], 'val_acc': [0.9, 0.924, 0.928, 0.948, 0.95, 0.933, 0.947, 0.945, 0.958, 0.951, 0.958, 0.96, 0.954, 0.957, 0.957, 0.964, 0.952, 0.96, 0.96, 0.962, 0.942, 0.959, 0.958, 0.965, 0.953, 0.966, 0.964, 0.956, 0.947, 0.958, 0.964, 0.953, 0.954, 0.957, 0.963, 0.925, 0.968, 0.955, 0.958, 0.96, 0.946, 0.959, 0.965, 0.965, 0.922, 0.956, 0.925, 0.959, 0.953, 0.931, 0.959, 0.953], 'param_count': 42305, 'model_name': 'ECG1DSeparableCNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}, 'model_parameter_count': 42305, 'model_size_validation': 'PASS'}
2025-09-20 18:33:42,943 - INFO - _models.training_function_executor - BO Objective: base=0.9530, size_penalty=0.0000, final=0.9530
2025-09-20 18:33:42,943 - INFO - _models.training_function_executor - Model size: 42,305 parameters (PASS 256K limit)
2025-09-20 18:33:42,943 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 18.673s
2025-09-20 18:33:42,943 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9530
2025-09-20 18:33:42,943 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-09-20 18:33:42,943 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': np.int64(76), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': np.int64(34), 'channels2': np.int64(118), 'channels3': np.int64(138), 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': np.int64(8), 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': np.int64(15), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(93), 'per_channel': True}, value=0.9530
2025-09-20 18:33:42,943 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': np.int64(76), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': np.int64(34), 'channels2': np.int64(118), 'channels3': np.int64(138), 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': np.int64(8), 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': np.int64(15), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(93), 'per_channel': True} -> 0.9530
2025-09-20 18:33:42,945 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-09-20 18:33:42,945 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-20 18:33:42,946 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 18:33:42,946 - INFO - _models.training_function_executor - Executing training function: ECG1DSeparableCNN
2025-09-20 18:33:42,946 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0006847920095574785, 'batch_size': 64, 'epochs': 96, 'weight_decay': 0.007852755494724264, 'dropout': 0.11638567021515214, 'channels1': 62, 'channels2': 93, 'channels3': 114, 'kernel_size1': 7, 'kernel_size2': 7, 'kernel_size3': 5, 'pool_size': 4, 'lr_scheduler': 'step', 'step_size': 9, 'gamma': 0.15204127438822362, 'label_smoothing': 0.09488855372533335, 'early_stopping_patience': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 134, 'per_channel': False}
2025-09-20 18:33:42,947 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006847920095574785, 'batch_size': 64, 'epochs': 96, 'weight_decay': 0.007852755494724264, 'dropout': 0.11638567021515214, 'channels1': 62, 'channels2': 93, 'channels3': 114, 'kernel_size1': 7, 'kernel_size2': 7, 'kernel_size3': 5, 'pool_size': 4, 'lr_scheduler': 'step', 'step_size': 9, 'gamma': 0.15204127438822362, 'label_smoothing': 0.09488855372533335, 'early_stopping_patience': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 134, 'per_channel': False}
2025-09-20 18:34:01,675 - ERROR - _models.training_function_executor - Training execution failed: 'str' object has no attribute 'type'
2025-09-20 18:34:01,675 - INFO - _models.ai_code_generator - Starting debug attempts (max: 4)
2025-09-20 18:34:01,675 - INFO - _models.ai_code_generator - Calling GPT to debug training error (attempt 1/4)
2025-09-20 18:34:01,676 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-20 18:34:01,676 - INFO - _models.ai_code_generator - Prompt length: 14304 characters
2025-09-20 18:34:01,676 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-20 18:34:01,676 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-20 18:34:01,676 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-09-20 18:34:22,602 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-20 18:34:22,602 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-09-20 18:34:22,604 - INFO - _models.ai_code_generator - Saved GPT debug response to: gpt_debug_responses\gpt_debug_training_error_20250920_183422_attempt1.txt
2025-09-20 18:34:22,604 - INFO - _models.ai_code_generator - GPT suggested correction: {"quantization_bits": 8}
2025-09-20 18:34:22,604 - INFO - _models.ai_code_generator - Debug successful on attempt 1
2025-09-20 18:34:22,604 - INFO - _models.training_function_executor - GPT suggested corrections: {"quantization_bits": 8}
2025-09-20 18:34:22,604 - INFO - _models.training_function_executor - Stored corrections for BO process
2025-09-20 18:34:22,604 - ERROR - _models.training_function_executor - BO training objective failed: 'str' object has no attribute 'type'
2025-09-20 18:34:22,604 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 39.660s
2025-09-20 18:34:22,605 - ERROR - evaluation.code_generation_pipeline_orchestrator - BO Trial 2 FAILED with error: 'str' object has no attribute 'type'
2025-09-20 18:34:22,605 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚è≥ Waiting for GPT to finish debugging...
2025-09-20 18:34:25,605 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ GPT provided fixes after 3s - requesting BO restart
2025-09-20 18:34:25,605 - INFO - evaluation.code_generation_pipeline_orchestrator - üîß GPT has fixed the training function, reloading from JSON file
2025-09-20 18:34:25,618 - INFO - evaluation.code_generation_pipeline_orchestrator - Reloading fixed training function from: generated_training_functions\training_function_torch_tensor_ECG1DSeparableCNN_1758411203.json
2025-09-20 18:34:25,618 - INFO - _models.training_function_executor - Loaded training function: ECG1DSeparableCNN
2025-09-20 18:34:25,618 - INFO - _models.training_function_executor - Reasoning: No reasoning provided
2025-09-20 18:34:25,618 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Reloaded fixed training function: ECG1DSeparableCNN
2025-09-20 18:34:25,618 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Applied GPT fixes, restarting BO from trial 0
2025-09-20 18:34:25,619 - INFO - evaluation.code_generation_pipeline_orchestrator - üîÑ BO Restart attempt 1/2
2025-09-20 18:34:25,619 - INFO - evaluation.code_generation_pipeline_orchestrator - Session 1: üì¶ Installing dependencies for GPT-generated training code...
2025-09-20 18:34:25,619 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-09-20 18:34:25,702 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-09-20 18:34:25,702 - INFO - package_installer - Available packages: {'torch'}
2025-09-20 18:34:25,702 - INFO - package_installer - Missing packages: set()
2025-09-20 18:34:25,702 - INFO - package_installer - ‚úÖ All required packages are already available
2025-09-20 18:34:25,702 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-09-20 18:34:25,784 - INFO - data_splitting - Created BO subset: 5000 samples
2025-09-20 18:34:25,785 - INFO - data_splitting - BO subset class distribution: [3600  766   96  100  438]
2025-09-20 18:34:25,785 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 5000 samples (using bo_sample_num=5000)
2025-09-20 18:34:25,785 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'channels1', 'channels2', 'channels3', 'kernel_size1', 'kernel_size2', 'kernel_size3', 'pool_size', 'lr_scheduler', 'step_size', 'gamma', 'label_smoothing', 'early_stopping_patience', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_batches', 'per_channel']
2025-09-20 18:34:25,785 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti Laptop GPU
2025-09-20 18:34:25,872 - INFO - data_splitting - Created BO subset: 5000 samples
2025-09-20 18:34:25,872 - INFO - data_splitting - BO subset class distribution: [3600  766   96  100  438]
2025-09-20 18:34:25,872 - INFO - _models.training_function_executor - Using BO subset for optimization: 5000 samples (bo_sample_num=5000)
2025-09-20 18:34:25,883 - INFO - _models.training_function_executor - BO splits - Train: 4000, Val: 1000
2025-09-20 18:34:25,910 - INFO - bo.run_bo - Converted GPT search space: 22 parameters
2025-09-20 18:34:25,910 - INFO - bo.run_bo - Using GPT-generated search space
2025-09-20 18:34:25,911 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-20 18:34:25,911 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-09-20 18:34:25,911 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-20 18:34:25,911 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 18:34:25,911 - INFO - _models.training_function_executor - Executing training function: ECG1DSeparableCNN
2025-09-20 18:34:25,912 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}
2025-09-20 18:34:25,913 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}
2025-09-20 18:34:42,137 - INFO - _models.training_function_executor - Model parameter count: 42,305
2025-09-20 18:34:42,137 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7492680988311767, 0.435858154296875, 0.330596830368042, 0.3083405997753143, 0.28319308161735535, 0.26503694236278535, 0.251543292760849, 0.24520114827156067, 0.23363413786888124, 0.2213124966621399, 0.21419236147403717, 0.21128659391403198, 0.2123405327796936, 0.20132652831077574, 0.21314868581295013, 0.2081586230993271, 0.19030741190910339, 0.19724594974517823, 0.19533771467208863, 0.18811242628097535, 0.19944976878166198, 0.1919514765739441, 0.18331417560577393, 0.18406390488147736, 0.1784921967983246, 0.18404423320293425, 0.17697681188583375, 0.18085165858268737, 0.18361418533325197, 0.17669250798225403, 0.17763243865966796, 0.16604307675361632, 0.17396935629844665, 0.17084171915054322, 0.17532454109191895, 0.18044008946418763, 0.16973708999156953, 0.18735224509239196, 0.17466758441925048, 0.1712798788547516, 0.17036341881752015, 0.1651471483707428, 0.16481194639205932, 0.16721114814281463, 0.1637630407810211, 0.15932970666885377, 0.15771542608737946, 0.1644821608066559, 0.15732056093215943], 'val_losses': [0.5111799240112305, 0.3524444808959961, 0.34319209384918214, 0.35394442796707154, 0.27279996252059935, 0.2821180453300476, 0.3719746265411377, 0.2870149352550507, 0.25260220050811766, 0.24913201332092286, 0.291232780456543, 0.2988600301742554, 0.22930080699920655, 0.3247404329776764, 0.23167286610603333, 0.26062758708000183, 0.24669854950904846, 0.23505396270751952, 0.24941196489334105, 0.2327214572429657, 0.23342790484428405, 0.24516553592681883, 0.2621009860038757, 0.2323287992477417, 0.218642728805542, 0.24976989078521727, 0.21509904503822327, 0.42420482444763186, 0.3588494725227356, 0.23359456849098206, 0.2428290274143219, 0.2512539584636688, 0.22179372549057008, 0.21107181215286255, 0.23317876386642455, 0.28028517866134645, 0.22816218400001526, 0.26410344219207765, 0.3476752443313599, 0.2233960590362549, 0.24785452580451967, 0.2275650854110718, 0.22873516917228698, 0.28153285694122315, 0.2270216028690338, 0.24257386636734007, 0.21217184543609618, 0.2176498839855194, 0.27675881624221804], 'val_acc': [0.882, 0.932, 0.927, 0.931, 0.952, 0.952, 0.922, 0.95, 0.952, 0.956, 0.945, 0.951, 0.962, 0.934, 0.953, 0.952, 0.959, 0.963, 0.957, 0.962, 0.96, 0.957, 0.958, 0.961, 0.967, 0.954, 0.961, 0.902, 0.91, 0.962, 0.959, 0.952, 0.957, 0.969, 0.961, 0.95, 0.96, 0.95, 0.917, 0.963, 0.96, 0.961, 0.966, 0.952, 0.962, 0.951, 0.956, 0.967, 0.956], 'param_count': 42305, 'model_name': 'ECG1DSeparableCNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}, 'model_parameter_count': 42305, 'model_size_validation': 'PASS'}
2025-09-20 18:34:42,137 - INFO - _models.training_function_executor - BO Objective: base=0.9560, size_penalty=0.0000, final=0.9560
2025-09-20 18:34:42,137 - INFO - _models.training_function_executor - Model size: 42,305 parameters (PASS 256K limit)
2025-09-20 18:34:42,139 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 16.228s
2025-09-20 18:34:42,139 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9560
2025-09-20 18:34:42,139 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-09-20 18:34:42,139 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': np.int64(76), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': np.int64(34), 'channels2': np.int64(118), 'channels3': np.int64(138), 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': np.int64(8), 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': np.int64(15), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(93), 'per_channel': True}, value=0.9560
2025-09-20 18:34:42,139 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': np.int64(76), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': np.int64(34), 'channels2': np.int64(118), 'channels3': np.int64(138), 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': np.int64(8), 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': np.int64(15), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(93), 'per_channel': True} -> 0.9560
2025-09-20 18:34:42,140 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-09-20 18:34:42,140 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-20 18:34:42,140 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 18:34:42,140 - INFO - _models.training_function_executor - Executing training function: ECG1DSeparableCNN
2025-09-20 18:34:42,140 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0006847920095574785, 'batch_size': 64, 'epochs': 96, 'weight_decay': 0.007852755494724264, 'dropout': 0.11638567021515214, 'channels1': 62, 'channels2': 93, 'channels3': 114, 'kernel_size1': 7, 'kernel_size2': 7, 'kernel_size3': 5, 'pool_size': 4, 'lr_scheduler': 'step', 'step_size': 9, 'gamma': 0.15204127438822362, 'label_smoothing': 0.09488855372533335, 'early_stopping_patience': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 134, 'per_channel': False}
2025-09-20 18:34:42,141 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006847920095574785, 'batch_size': 64, 'epochs': 96, 'weight_decay': 0.007852755494724264, 'dropout': 0.11638567021515214, 'channels1': 62, 'channels2': 93, 'channels3': 114, 'kernel_size1': 7, 'kernel_size2': 7, 'kernel_size3': 5, 'pool_size': 4, 'lr_scheduler': 'step', 'step_size': 9, 'gamma': 0.15204127438822362, 'label_smoothing': 0.09488855372533335, 'early_stopping_patience': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 134, 'per_channel': False}
2025-09-20 18:35:02,310 - ERROR - _models.training_function_executor - Training execution failed: 'str' object has no attribute 'type'
2025-09-20 18:35:02,311 - INFO - _models.ai_code_generator - Starting debug attempts (max: 4)
2025-09-20 18:35:02,311 - INFO - _models.ai_code_generator - Calling GPT to debug training error (attempt 1/4)
2025-09-20 18:35:02,311 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-20 18:35:02,311 - INFO - _models.ai_code_generator - Prompt length: 14304 characters
2025-09-20 18:35:02,311 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-20 18:35:02,311 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-20 18:35:02,311 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-09-20 18:35:25,327 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-20 18:35:25,328 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-09-20 18:35:25,331 - INFO - _models.ai_code_generator - Saved GPT debug response to: gpt_debug_responses\gpt_debug_training_error_20250920_183525_attempt1.txt
2025-09-20 18:35:25,331 - INFO - _models.ai_code_generator - GPT suggested correction: {"quantization_bits": 8}
2025-09-20 18:35:25,331 - INFO - _models.ai_code_generator - Debug successful on attempt 1
2025-09-20 18:35:25,331 - INFO - _models.training_function_executor - GPT suggested corrections: {"quantization_bits": 8}
2025-09-20 18:35:25,331 - INFO - _models.training_function_executor - Stored corrections for BO process
2025-09-20 18:35:25,331 - ERROR - _models.training_function_executor - BO training objective failed: 'str' object has no attribute 'type'
2025-09-20 18:35:25,331 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 43.191s
2025-09-20 18:35:25,331 - ERROR - evaluation.code_generation_pipeline_orchestrator - BO Trial 2 FAILED with error: 'str' object has no attribute 'type'
2025-09-20 18:35:25,331 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚è≥ Waiting for GPT to finish debugging...
2025-09-20 18:35:28,331 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ GPT provided fixes after 3s - requesting BO restart
2025-09-20 18:35:28,331 - INFO - evaluation.code_generation_pipeline_orchestrator - üîß GPT has fixed the training function, reloading from JSON file
2025-09-20 18:35:28,334 - INFO - evaluation.code_generation_pipeline_orchestrator - Reloading fixed training function from: generated_training_functions\training_function_torch_tensor_ECG1DSeparableCNN_1758411203.json
2025-09-20 18:35:28,335 - INFO - _models.training_function_executor - Loaded training function: ECG1DSeparableCNN
2025-09-20 18:35:28,335 - INFO - _models.training_function_executor - Reasoning: No reasoning provided
2025-09-20 18:35:28,335 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Reloaded fixed training function: ECG1DSeparableCNN
2025-09-20 18:35:28,335 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Applied GPT fixes, restarting BO from trial 0
2025-09-20 18:35:28,336 - INFO - evaluation.code_generation_pipeline_orchestrator - üîÑ BO Restart attempt 2/2
2025-09-20 18:35:28,336 - INFO - evaluation.code_generation_pipeline_orchestrator - Session 2: üì¶ Installing dependencies for GPT-generated training code...
2025-09-20 18:35:28,336 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-09-20 18:35:28,339 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-09-20 18:35:28,339 - INFO - package_installer - Available packages: {'torch'}
2025-09-20 18:35:28,339 - INFO - package_installer - Missing packages: set()
2025-09-20 18:35:28,339 - INFO - package_installer - ‚úÖ All required packages are already available
2025-09-20 18:35:28,339 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-09-20 18:35:28,428 - INFO - data_splitting - Created BO subset: 5000 samples
2025-09-20 18:35:28,429 - INFO - data_splitting - BO subset class distribution: [3600  766   96  100  438]
2025-09-20 18:35:28,429 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 5000 samples (using bo_sample_num=5000)
2025-09-20 18:35:28,429 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'channels1', 'channels2', 'channels3', 'kernel_size1', 'kernel_size2', 'kernel_size3', 'pool_size', 'lr_scheduler', 'step_size', 'gamma', 'label_smoothing', 'early_stopping_patience', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_batches', 'per_channel']
2025-09-20 18:35:28,429 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti Laptop GPU
2025-09-20 18:35:28,514 - INFO - data_splitting - Created BO subset: 5000 samples
2025-09-20 18:35:28,514 - INFO - data_splitting - BO subset class distribution: [3600  766   96  100  438]
2025-09-20 18:35:28,514 - INFO - _models.training_function_executor - Using BO subset for optimization: 5000 samples (bo_sample_num=5000)
2025-09-20 18:35:28,523 - INFO - _models.training_function_executor - BO splits - Train: 4000, Val: 1000
2025-09-20 18:35:28,549 - INFO - bo.run_bo - Converted GPT search space: 22 parameters
2025-09-20 18:35:28,549 - INFO - bo.run_bo - Using GPT-generated search space
2025-09-20 18:35:28,550 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-20 18:35:28,550 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-09-20 18:35:28,550 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-20 18:35:28,551 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 18:35:28,551 - INFO - _models.training_function_executor - Executing training function: ECG1DSeparableCNN
2025-09-20 18:35:28,551 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}
2025-09-20 18:35:28,553 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}
2025-09-20 18:35:47,993 - INFO - _models.training_function_executor - Model parameter count: 42,305
2025-09-20 18:35:47,993 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7032960152626038, 0.41437202072143553, 0.3290926809310913, 0.3045768220424652, 0.2926718965768814, 0.27188394117355347, 0.2611063961982727, 0.24106998896598816, 0.23873089516162874, 0.22373140490055085, 0.2183356499671936, 0.216573299407959, 0.2096417233943939, 0.21299949264526366, 0.19671971750259398, 0.19978254175186158, 0.19210768890380858, 0.19923781967163087, 0.1894368624687195, 0.18970342254638672, 0.18821574234962463, 0.18109166955947875, 0.18348615193367004, 0.18441688227653502, 0.17511367893218993, 0.17797522509098054, 0.1911271493434906, 0.1793625054359436, 0.17516533732414247, 0.17582639217376708, 0.16950780749320984, 0.1724022629261017, 0.17360323929786683, 0.16913900125026704, 0.17060364985466003, 0.16563378500938417, 0.17049409008026123, 0.17647080075740815, 0.16732098841667176, 0.1657111647129059, 0.16273452305793762, 0.15852394962310792, 0.1547547528743744, 0.1621060538291931, 0.17044360375404358, 0.16818019008636476, 0.1743076696395874, 0.15921038341522217, 0.15139162516593932, 0.15913359236717223, 0.16774514067173005, 0.17831071078777314, 0.16825128877162934, 0.1594989800453186, 0.15267617189884186, 0.15158558750152587, 0.1466237864494324, 0.14921255457401275], 'val_losses': [0.47436434555053714, 0.34612972688674926, 0.32415826463699343, 0.3054208812713623, 0.2896670069694519, 0.27000050711631773, 0.255884019613266, 0.632137004852295, 0.24448484063148498, 0.23793370842933656, 0.24664114809036256, 0.2594762334823608, 0.2777341117858887, 0.2537612633705139, 0.28611815404891966, 0.23925914406776427, 0.28951349925994874, 0.2274149980545044, 0.39381070947647095, 0.22392507362365724, 0.2262237639427185, 0.2557688319683075, 0.2960690188407898, 0.21896293830871583, 0.21925373888015748, 0.3850071120262146, 0.23024991607666015, 0.32366281747817993, 0.25366915011405944, 0.2416024739742279, 0.22889240026474, 0.2287160394191742, 0.22430412817001344, 0.2286207368373871, 0.22075343799591066, 0.22481726002693175, 0.25613466143608093, 0.2169176571369171, 0.22129524278640747, 0.2187960171699524, 0.22843299794197083, 0.2192781240940094, 0.21676543140411378, 0.23952118396759034, 0.31822001886367796, 0.23962310886383056, 0.23216094255447386, 0.22775303554534912, 0.2656786298751831, 0.24319237995147705, 0.21759761595726013, 0.32570975494384763, 0.26194524693489074, 0.22431781506538392, 0.23265477895736694, 0.22087955689430236, 0.22006040382385253, 0.2286025905609131], 'val_acc': [0.886, 0.934, 0.937, 0.942, 0.944, 0.953, 0.954, 0.789, 0.952, 0.959, 0.953, 0.951, 0.952, 0.956, 0.944, 0.961, 0.949, 0.958, 0.926, 0.964, 0.959, 0.953, 0.938, 0.963, 0.968, 0.908, 0.96, 0.928, 0.956, 0.965, 0.962, 0.96, 0.968, 0.961, 0.964, 0.956, 0.964, 0.959, 0.964, 0.964, 0.965, 0.967, 0.963, 0.955, 0.954, 0.962, 0.959, 0.964, 0.945, 0.957, 0.962, 0.936, 0.952, 0.964, 0.962, 0.965, 0.965, 0.955], 'param_count': 42305, 'model_name': 'ECG1DSeparableCNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': 34, 'channels2': 118, 'channels3': 138, 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': 8, 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 93, 'per_channel': True}, 'model_parameter_count': 42305, 'model_size_validation': 'PASS'}
2025-09-20 18:35:47,993 - INFO - _models.training_function_executor - BO Objective: base=0.9550, size_penalty=0.0000, final=0.9550
2025-09-20 18:35:47,993 - INFO - _models.training_function_executor - Model size: 42,305 parameters (PASS 256K limit)
2025-09-20 18:35:47,993 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 19.442s
2025-09-20 18:35:47,993 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9550
2025-09-20 18:35:47,993 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-09-20 18:35:47,993 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': np.int64(76), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': np.int64(34), 'channels2': np.int64(118), 'channels3': np.int64(138), 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': np.int64(8), 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': np.int64(15), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(93), 'per_channel': True}, value=0.9550
2025-09-20 18:35:47,993 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.002452612631133679, 'batch_size': 64, 'epochs': np.int64(76), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'channels1': np.int64(34), 'channels2': np.int64(118), 'channels3': np.int64(138), 'kernel_size1': 7, 'kernel_size2': 5, 'kernel_size3': 3, 'pool_size': 4, 'lr_scheduler': 'none', 'step_size': np.int64(8), 'gamma': 0.7659541126403375, 'label_smoothing': 0.02123391106782762, 'early_stopping_patience': np.int64(15), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(93), 'per_channel': True} -> 0.9550
2025-09-20 18:35:47,994 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-09-20 18:35:47,994 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-20 18:35:47,994 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 18:35:47,994 - INFO - _models.training_function_executor - Executing training function: ECG1DSeparableCNN
2025-09-20 18:35:47,994 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0006847920095574785, 'batch_size': 64, 'epochs': 96, 'weight_decay': 0.007852755494724264, 'dropout': 0.11638567021515214, 'channels1': 62, 'channels2': 93, 'channels3': 114, 'kernel_size1': 7, 'kernel_size2': 7, 'kernel_size3': 5, 'pool_size': 4, 'lr_scheduler': 'step', 'step_size': 9, 'gamma': 0.15204127438822362, 'label_smoothing': 0.09488855372533335, 'early_stopping_patience': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 134, 'per_channel': False}
2025-09-20 18:35:47,997 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006847920095574785, 'batch_size': 64, 'epochs': 96, 'weight_decay': 0.007852755494724264, 'dropout': 0.11638567021515214, 'channels1': 62, 'channels2': 93, 'channels3': 114, 'kernel_size1': 7, 'kernel_size2': 7, 'kernel_size3': 5, 'pool_size': 4, 'lr_scheduler': 'step', 'step_size': 9, 'gamma': 0.15204127438822362, 'label_smoothing': 0.09488855372533335, 'early_stopping_patience': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 134, 'per_channel': False}
2025-09-20 18:36:03,168 - ERROR - _models.training_function_executor - Training execution failed: 'str' object has no attribute 'type'
2025-09-20 18:36:03,168 - INFO - _models.ai_code_generator - Starting debug attempts (max: 4)
2025-09-20 18:36:03,168 - INFO - _models.ai_code_generator - Calling GPT to debug training error (attempt 1/4)
2025-09-20 18:36:03,168 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-20 18:36:03,168 - INFO - _models.ai_code_generator - Prompt length: 14304 characters
2025-09-20 18:36:03,168 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-20 18:36:03,168 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-20 18:36:03,168 - INFO - _models.ai_code_generator - Model parameter: gpt-5
