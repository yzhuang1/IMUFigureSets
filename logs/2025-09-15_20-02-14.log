2025-09-15 20:02:14,512 - INFO - __main__ - Logging system initialized successfully
2025-09-15 20:02:14,515 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'y.npy', 'X.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-09-15 20:02:14,515 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-09-15 20:02:14,515 - INFO - __main__ - Attempting to load: y.npy
2025-09-15 20:02:14,516 - INFO - __main__ - Attempting to load: X.npy
2025-09-15 20:02:14,831 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-09-15 20:02:15,146 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-09-15 20:02:15,146 - INFO - __main__ - Starting AI-enhanced training with new pipeline flow
2025-09-15 20:02:15,147 - INFO - __main__ - Flow: Template Selection → BO → Evaluation → Feedback Loop
2025-09-15 20:02:15,159 - INFO - __main__ - Data profile: {'data_type': 'numpy_array', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-09-15 20:02:15,160 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized with max 4 attempts
2025-09-15 20:02:15,160 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution
2025-09-15 20:02:15,160 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation → JSON Storage → BO → Training Execution → Evaluation
2025-09-15 20:02:15,160 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-09-15 20:02:15,161 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-09-15 20:02:15,161 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-09-15 20:02:15,162 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-09-15 20:02:15,817 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-09-15 20:02:15,818 - INFO - class_balancing - Class imbalance analysis:
2025-09-15 20:02:15,818 - INFO - class_balancing -   Strategy: severe_imbalance
2025-09-15 20:02:15,819 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-09-15 20:02:15,819 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-09-15 20:02:15,819 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-09-15 20:02:15,819 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-09-15 20:02:15,820 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-09-15 20:02:15,820 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-09-15 20:02:15,820 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-09-15 20:02:17,130 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-09-15 20:02:17,132 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-09-15 20:02:17,135 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-15 20:02:17,135 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE ATTEMPT 1/4
2025-09-15 20:02:17,135 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-15 20:02:17,135 - INFO - evaluation.code_generation_pipeline_orchestrator - 🤖 STEP 1: AI Training Code Generation
2025-09-15 20:02:17,136 - INFO - models.ai_code_generator - Making API call to gpt-5
2025-09-15 20:02:17,136 - INFO - models.ai_code_generator - Prompt length: 1568 characters
2025-09-15 20:02:17,136 - INFO - models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-15 20:02:17,136 - INFO - models.ai_code_generator - Calling self.client.responses.create...
2025-09-15 20:02:17,136 - INFO - models.ai_code_generator - Model parameter: gpt-5
2025-09-15 20:02:17,136 - INFO - models.ai_code_generator - Input prompt preview: Generate PyTorch training function for 5-class classification.

Data: numpy_array, shape (1000, 2), 62352 samples

Dataset: MIT-BIH Arrhythmia Database
Source: https://physionet.org/content/mitdb/1.0....
2025-09-15 20:04:48,115 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-15 20:04:48,275 - INFO - models.ai_code_generator - API call completed successfully
2025-09-15 20:04:48,275 - INFO - models.ai_code_generator - Response type: <class 'openai.types.responses.response.Response'>
2025-09-15 20:04:48,275 - INFO - models.ai_code_generator - Response attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_request_id', '_setattr_handler', 'background', 'construct', 'conversation', 'copy', 'created_at', 'dict', 'error', 'from_orm', 'id', 'incomplete_details', 'instructions', 'json', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'object', 'output', 'output_text', 'parallel_tool_calls', 'parse_file', 'parse_obj', 'parse_raw', 'previous_response_id', 'prompt', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'schema', 'schema_json', 'service_tier', 'status', 'temperature', 'text', 'to_dict', 'to_json', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'update_forward_refs', 'usage', 'user', 'validate']
2025-09-15 20:04:48,276 - INFO - models.ai_code_generator - Using response.output_text
2025-09-15 20:04:48,276 - INFO - models.ai_code_generator - Extracted result length: 8953 characters
2025-09-15 20:04:48,276 - INFO - models.ai_code_generator - Result preview: {
    "model_name": "TinyECGNet-1D-CNN",
    "training_code": "def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import torch\n    import torch.nn as nn\n    from torch.util...
2025-09-15 20:04:48,276 - INFO - models.ai_code_generator - Successfully extracted response content
2025-09-15 20:04:48,276 - INFO - models.ai_code_generator - AI generated training function: TinyECGNet-1D-CNN
2025-09-15 20:04:48,276 - INFO - models.ai_code_generator - Confidence: 0.90
2025-09-15 20:04:48,276 - INFO - models.ai_code_generator - Reasoning: For MIT-BIH Arrhythmia (two-lead ECG, long 1D signals) lightweight 1D CNNs with small kernels and global average pooling are effective. The dataset is highly imbalanced across the 5 AAMI classes, so using class-weighted cross-entropy and macro-F1 for validation is standard in literature. The proposed TinyECGNet keeps parameters well under 256K by using three compact Conv1d blocks and a small MLP head with dropout. Bayesian Optimization can tune learning rate, batch size, epochs, hidden size of the MLP, and dropout while the core loop remains simple.
2025-09-15 20:04:48,276 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: TinyECGNet-1D-CNN
2025-09-15 20:04:48,277 - INFO - evaluation.code_generation_pipeline_orchestrator - Reasoning: For MIT-BIH Arrhythmia (two-lead ECG, long 1D signals) lightweight 1D CNNs with small kernels and global average pooling are effective. The dataset is highly imbalanced across the 5 AAMI classes, so using class-weighted cross-entropy and macro-F1 for validation is standard in literature. The proposed TinyECGNet keeps parameters well under 256K by using three compact Conv1d blocks and a small MLP head with dropout. Bayesian Optimization can tune learning rate, batch size, epochs, hidden size of the MLP, and dropout while the core loop remains simple.
2025-09-15 20:04:48,277 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'hidden_size', 'dropout']
2025-09-15 20:04:48,277 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.90
2025-09-15 20:04:48,277 - INFO - evaluation.code_generation_pipeline_orchestrator - 💾 STEP 2: Save Training Function to JSON
2025-09-15 20:04:48,278 - INFO - models.ai_code_generator - Training function saved to: generated_training_functions/training_function_numpy_array_TinyECGNet-1D-CNN_1757966688.json
2025-09-15 20:04:48,278 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_numpy_array_TinyECGNet-1D-CNN_1757966688.json
2025-09-15 20:04:48,283 - INFO - models.training_function_executor - Training function validation passed
2025-09-15 20:04:48,284 - INFO - evaluation.code_generation_pipeline_orchestrator - 🔍 STEP 3: Bayesian Optimization
2025-09-15 20:04:48,284 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: TinyECGNet-1D-CNN
2025-09-15 20:04:48,329 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 5000 samples
2025-09-15 20:04:48,330 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'hidden_size', 'dropout']
2025-09-15 20:04:48,330 - INFO - models.training_function_executor - GPU available: NVIDIA H100 NVL
2025-09-15 20:04:48,330 - WARNING - models.training_function_executor - Using provided subset instead of centralized splits - this may cause data leakage
2025-09-15 20:04:48,909 - INFO - bo.run_bo - Using default search space
2025-09-15 20:04:48,911 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-15 20:04:48,920 - INFO - bo.run_bo - Using explicitly provided search space
2025-09-15 20:04:48,921 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-15 20:04:48,923 - INFO - bo.run_bo - BO Trial 1: Initial random exploration
2025-09-15 20:04:48,924 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-09-15 20:04:48,924 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:48,924 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:48,924 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': 10, 'hidden_size': 204, 'dropout': 0.41779511056254093}
2025-09-15 20:04:48,929 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.01535224694197351, 'epochs': 10, 'batch_size': 16, 'hidden_size': 204, 'dropout': 0.41779511056254093}
2025-09-15 20:04:51,663 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:51,664 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:51,664 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:51,664 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 2.740s
2025-09-15 20:04:51,665 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:51,665 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.001s
2025-09-15 20:04:51,666 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}, value=0.0000
2025-09-15 20:04:51,666 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093} -> 0.0000
2025-09-15 20:04:51,668 - INFO - bo.run_bo - BO Trial 2: Initial random exploration
2025-09-15 20:04:51,668 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-09-15 20:04:51,668 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:51,669 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:51,669 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': 13, 'hidden_size': 103, 'dropout': 0.2335960277973153}
2025-09-15 20:04:51,679 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006071989493441302, 'epochs': 13, 'batch_size': 8, 'hidden_size': 103, 'dropout': 0.2335960277973153}
2025-09-15 20:04:51,694 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:51,694 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:51,694 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:51,694 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.026s
2025-09-15 20:04:51,695 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:51,695 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.001s
2025-09-15 20:04:51,695 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': np.int64(13), 'hidden_size': np.int64(103), 'dropout': 0.2335960277973153}, value=0.0000
2025-09-15 20:04:51,696 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': np.int64(13), 'hidden_size': np.int64(103), 'dropout': 0.2335960277973153} -> 0.0000
2025-09-15 20:04:51,698 - INFO - bo.run_bo - BO Trial 3: Initial random exploration
2025-09-15 20:04:51,698 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-09-15 20:04:51,698 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:51,698 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:51,698 - INFO - models.training_function_executor - Hyperparameters: {'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': 23, 'hidden_size': 273, 'dropout': 0.5053991405867774}
2025-09-15 20:04:51,703 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 3.727925903376984e-05, 'epochs': 23, 'batch_size': 64, 'hidden_size': 273, 'dropout': 0.5053991405867774}
2025-09-15 20:04:51,719 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:51,719 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:51,719 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:51,720 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.022s
2025-09-15 20:04:52,117 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:52,118 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.398s
2025-09-15 20:04:52,118 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': np.int64(23), 'hidden_size': np.int64(273), 'dropout': 0.5053991405867774}, value=0.0000
2025-09-15 20:04:52,118 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': np.int64(23), 'hidden_size': np.int64(273), 'dropout': 0.5053991405867774} -> 0.0000
2025-09-15 20:04:52,118 - INFO - bo.run_bo - BO Trial 4: Using RF surrogate + Expected Improvement
2025-09-15 20:04:52,118 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:04:52,119 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:52,119 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:52,119 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.05678201970293135, 'batch_size': 32, 'epochs': 5, 'hidden_size': 183, 'dropout': 0.08439771317838103}
2025-09-15 20:04:52,123 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.05678201970293135, 'epochs': 5, 'batch_size': 32, 'hidden_size': 183, 'dropout': 0.08439771317838103}
2025-09-15 20:04:52,133 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:52,133 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:52,133 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:52,134 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.015s
2025-09-15 20:04:52,529 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:52,530 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.396s
2025-09-15 20:04:52,530 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 0.05678201970293135, 'batch_size': np.int64(32), 'epochs': np.int64(5), 'hidden_size': np.int64(183), 'dropout': 0.08439771317838103}, value=0.0000
2025-09-15 20:04:52,530 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 0.05678201970293135, 'batch_size': np.int64(32), 'epochs': np.int64(5), 'hidden_size': np.int64(183), 'dropout': 0.08439771317838103} -> 0.0000
2025-09-15 20:04:52,530 - INFO - bo.run_bo - BO Trial 5: Using RF surrogate + Expected Improvement
2025-09-15 20:04:52,531 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:04:52,531 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:52,531 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:52,531 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006550049531232524, 'batch_size': 256, 'epochs': 6, 'hidden_size': 373, 'dropout': 0.4568590869235105}
2025-09-15 20:04:52,536 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006550049531232524, 'epochs': 6, 'batch_size': 256, 'hidden_size': 373, 'dropout': 0.4568590869235105}
2025-09-15 20:04:52,551 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:52,551 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:52,551 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:52,551 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.021s
2025-09-15 20:04:52,938 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:52,939 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.387s
2025-09-15 20:04:52,939 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 0.0006550049531232524, 'batch_size': np.int64(256), 'epochs': np.int64(6), 'hidden_size': np.int64(373), 'dropout': 0.4568590869235105}, value=0.0000
2025-09-15 20:04:52,939 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 0.0006550049531232524, 'batch_size': np.int64(256), 'epochs': np.int64(6), 'hidden_size': np.int64(373), 'dropout': 0.4568590869235105} -> 0.0000
2025-09-15 20:04:52,939 - INFO - bo.run_bo - BO Trial 6: Using RF surrogate + Expected Improvement
2025-09-15 20:04:52,939 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:04:52,939 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:52,940 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:52,940 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006302883671688219, 'batch_size': 128, 'epochs': 24, 'hidden_size': 432, 'dropout': 0.24572406269266053}
2025-09-15 20:04:52,944 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006302883671688219, 'epochs': 24, 'batch_size': 128, 'hidden_size': 432, 'dropout': 0.24572406269266053}
2025-09-15 20:04:52,956 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:52,956 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:52,959 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:52,960 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.020s
2025-09-15 20:04:53,349 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:53,350 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.389s
2025-09-15 20:04:53,350 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.0006302883671688219, 'batch_size': np.int64(128), 'epochs': np.int64(24), 'hidden_size': np.int64(432), 'dropout': 0.24572406269266053}, value=0.0000
2025-09-15 20:04:53,350 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.0006302883671688219, 'batch_size': np.int64(128), 'epochs': np.int64(24), 'hidden_size': np.int64(432), 'dropout': 0.24572406269266053} -> 0.0000
2025-09-15 20:04:53,350 - INFO - bo.run_bo - BO Trial 7: Using RF surrogate + Expected Improvement
2025-09-15 20:04:53,351 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:04:53,351 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:53,351 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:53,351 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.04222247265603969, 'batch_size': 16, 'epochs': 18, 'hidden_size': 51, 'dropout': 0.25007875594551915}
2025-09-15 20:04:53,355 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.04222247265603969, 'epochs': 18, 'batch_size': 16, 'hidden_size': 51, 'dropout': 0.25007875594551915}
2025-09-15 20:04:53,366 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:53,366 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:53,366 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:53,366 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.016s
2025-09-15 20:04:53,752 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:53,753 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.386s
2025-09-15 20:04:53,753 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 0.04222247265603969, 'batch_size': np.int64(16), 'epochs': np.int64(18), 'hidden_size': np.int64(51), 'dropout': 0.25007875594551915}, value=0.0000
2025-09-15 20:04:53,753 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 0.04222247265603969, 'batch_size': np.int64(16), 'epochs': np.int64(18), 'hidden_size': np.int64(51), 'dropout': 0.25007875594551915} -> 0.0000
2025-09-15 20:04:53,753 - INFO - bo.run_bo - BO Trial 8: Using RF surrogate + Expected Improvement
2025-09-15 20:04:53,753 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:04:53,754 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:53,754 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:53,754 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.015831723490615644, 'batch_size': 32, 'epochs': 12, 'hidden_size': 319, 'dropout': 0.2621266723153076}
2025-09-15 20:04:53,758 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.015831723490615644, 'epochs': 12, 'batch_size': 32, 'hidden_size': 319, 'dropout': 0.2621266723153076}
2025-09-15 20:04:53,768 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:53,768 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:53,768 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:53,769 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.015s
2025-09-15 20:04:54,165 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:54,165 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.396s
2025-09-15 20:04:54,165 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 0.015831723490615644, 'batch_size': np.int64(32), 'epochs': np.int64(12), 'hidden_size': np.int64(319), 'dropout': 0.2621266723153076}, value=0.0000
2025-09-15 20:04:54,165 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 0.015831723490615644, 'batch_size': np.int64(32), 'epochs': np.int64(12), 'hidden_size': np.int64(319), 'dropout': 0.2621266723153076} -> 0.0000
2025-09-15 20:04:54,166 - INFO - bo.run_bo - BO Trial 9: Using RF surrogate + Expected Improvement
2025-09-15 20:04:54,166 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:04:54,166 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:54,167 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:54,167 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0004582655140915009, 'batch_size': 8, 'epochs': 22, 'hidden_size': 288, 'dropout': 0.2979985056070939}
2025-09-15 20:04:54,171 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0004582655140915009, 'epochs': 22, 'batch_size': 8, 'hidden_size': 288, 'dropout': 0.2979985056070939}
2025-09-15 20:04:54,182 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:54,182 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:54,182 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:54,183 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.016s
2025-09-15 20:04:54,567 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:54,568 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.385s
2025-09-15 20:04:54,568 - INFO - bo.run_bo - Recorded observation #9: hparams={'lr': 0.0004582655140915009, 'batch_size': np.int64(8), 'epochs': np.int64(22), 'hidden_size': np.int64(288), 'dropout': 0.2979985056070939}, value=0.0000
2025-09-15 20:04:54,568 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'lr': 0.0004582655140915009, 'batch_size': np.int64(8), 'epochs': np.int64(22), 'hidden_size': np.int64(288), 'dropout': 0.2979985056070939} -> 0.0000
2025-09-15 20:04:54,568 - INFO - bo.run_bo - BO Trial 10: Using RF surrogate + Expected Improvement
2025-09-15 20:04:54,568 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:04:54,568 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:04:54,569 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:04:54,569 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0019299580918507716, 'batch_size': 16, 'epochs': 25, 'hidden_size': 367, 'dropout': 0.5945242340829255}
2025-09-15 20:04:54,573 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0019299580918507716, 'epochs': 25, 'batch_size': 16, 'hidden_size': 367, 'dropout': 0.5945242340829255}
2025-09-15 20:04:54,583 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:54,583 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:04:54,583 - ERROR - models.training_function_executor - BO training objective failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:04:54,583 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.015s
2025-09-15 20:04:54,973 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:04:54,974 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.390s
2025-09-15 20:04:54,974 - INFO - bo.run_bo - Recorded observation #10: hparams={'lr': 0.0019299580918507716, 'batch_size': np.int64(16), 'epochs': np.int64(25), 'hidden_size': np.int64(367), 'dropout': 0.5945242340829255}, value=0.0000
2025-09-15 20:04:54,974 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'lr': 0.0019299580918507716, 'batch_size': np.int64(16), 'epochs': np.int64(25), 'hidden_size': np.int64(367), 'dropout': 0.5945242340829255} -> 0.0000
2025-09-15 20:04:54,975 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.0000
2025-09-15 20:04:54,975 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}
2025-09-15 20:04:54,976 - INFO - visualization - Generating BO visualization charts with 10 trials...
2025-09-15 20:05:04,305 - INFO - visualization - BO summary saved to: charts/BO_TinyECGNet-1D-CNN_20250915_200454/bo_summary.txt
2025-09-15 20:05:04,306 - INFO - visualization - BO charts saved to: charts/BO_TinyECGNet-1D-CNN_20250915_200454
2025-09-15 20:05:04,306 - INFO - evaluation.code_generation_pipeline_orchestrator - 📊 BO charts saved to: charts/BO_TinyECGNet-1D-CNN_20250915_200454
2025-09-15 20:05:04,307 - INFO - evaluation.code_generation_pipeline_orchestrator - 🚀 STEP 4: Final Training Execution
2025-09-15 20:05:04,307 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (39904, 1000, 2), Val: (9977, 1000, 2), Test: (12471, 1000, 2)
2025-09-15 20:05:04,614 - INFO - models.training_function_executor - Loaded training function: TinyECGNet-1D-CNN
2025-09-15 20:05:04,614 - INFO - models.training_function_executor - Reasoning: For MIT-BIH Arrhythmia (two-lead ECG, long 1D signals) lightweight 1D CNNs with small kernels and global average pooling are effective. The dataset is highly imbalanced across the 5 AAMI classes, so using class-weighted cross-entropy and macro-F1 for validation is standard in literature. The proposed TinyECGNet keeps parameters well under 256K by using three compact Conv1d blocks and a small MLP head with dropout. Bayesian Optimization can tune learning rate, batch size, epochs, hidden size of the MLP, and dropout while the core loop remains simple.
2025-09-15 20:05:04,614 - INFO - evaluation.code_generation_pipeline_orchestrator - Executing final training with optimized params: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}
2025-09-15 20:05:04,614 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:05:04,703 - INFO - models.training_function_executor - Executing training function: TinyECGNet-1D-CNN
2025-09-15 20:05:04,703 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}
2025-09-15 20:05:04,708 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.01535224694197351, 'epochs': 10, 'batch_size': 16, 'hidden_size': 204, 'dropout': 0.41779511056254093}
2025-09-15 20:05:04,727 - ERROR - models.training_function_executor - Training execution failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:05:04,727 - ERROR - models.training_function_executor - Training code: def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
    import numpy as np

  ...
2025-09-15 20:05:04,727 - ERROR - evaluation.code_generation_pipeline_orchestrator - Pipeline attempt 1 failed: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
2025-09-15 20:05:04,780 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-15 20:05:04,780 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE ATTEMPT 2/4
2025-09-15 20:05:04,781 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-15 20:05:04,781 - INFO - evaluation.code_generation_pipeline_orchestrator - 🤖 STEP 1: AI Training Code Generation
2025-09-15 20:05:04,781 - INFO - models.ai_code_generator - Making API call to gpt-5
2025-09-15 20:05:04,781 - INFO - models.ai_code_generator - Prompt length: 1568 characters
2025-09-15 20:05:04,781 - INFO - models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-15 20:05:04,781 - INFO - models.ai_code_generator - Calling self.client.responses.create...
2025-09-15 20:05:04,781 - INFO - models.ai_code_generator - Model parameter: gpt-5
2025-09-15 20:05:04,781 - INFO - models.ai_code_generator - Input prompt preview: Generate PyTorch training function for 5-class classification.

Data: numpy_array, shape (1000, 2), 62352 samples

Dataset: MIT-BIH Arrhythmia Database
Source: https://physionet.org/content/mitdb/1.0....
