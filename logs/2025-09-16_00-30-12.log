2025-09-16 00:30:12,662 - INFO - __main__ - Logging system initialized successfully
2025-09-16 00:30:12,664 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'y.npy', 'X.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-09-16 00:30:12,664 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-09-16 00:30:12,664 - INFO - __main__ - Attempting to load: y.npy
2025-09-16 00:30:12,666 - INFO - __main__ - Attempting to load: X.npy
2025-09-16 00:30:12,964 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-09-16 00:30:13,288 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-09-16 00:30:13,288 - INFO - __main__ - Starting AI-enhanced training with new pipeline flow
2025-09-16 00:30:13,288 - INFO - __main__ - Flow: Template Selection â†’ BO â†’ Evaluation â†’ Feedback Loop
2025-09-16 00:30:13,301 - INFO - __main__ - Data profile: {'data_type': 'numpy_array', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-09-16 00:30:13,302 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized with max 4 attempts
2025-09-16 00:30:13,302 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution
2025-09-16 00:30:13,302 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation â†’ JSON Storage â†’ BO â†’ Training Execution â†’ Evaluation
2025-09-16 00:30:13,302 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-09-16 00:30:13,302 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-09-16 00:30:13,302 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-09-16 00:30:13,304 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-09-16 00:30:13,937 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-09-16 00:30:13,937 - INFO - class_balancing - Class imbalance analysis:
2025-09-16 00:30:13,938 - INFO - class_balancing -   Strategy: severe_imbalance
2025-09-16 00:30:13,938 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-09-16 00:30:13,938 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-09-16 00:30:13,938 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-09-16 00:30:13,938 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-09-16 00:30:13,939 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-09-16 00:30:13,939 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-09-16 00:30:13,939 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-09-16 00:30:15,269 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-09-16 00:30:15,272 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-09-16 00:30:15,275 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-16 00:30:15,275 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE ATTEMPT 1/4
2025-09-16 00:30:15,275 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-16 00:30:15,275 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ¤– STEP 1: AI Training Code Generation
2025-09-16 00:30:15,275 - INFO - models.ai_code_generator - Conducting literature review before code generation...
2025-09-16 00:30:15,276 - INFO - models.literature_review - Making GPT-5 literature review call with query: ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods
2025-09-16 00:33:10,881 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-16 00:33:11,120 - INFO - models.literature_review - Successfully completed GPT-5 literature review with web search
2025-09-16 00:33:11,120 - INFO - models.literature_review - Literature review completed with confidence: 0.78
2025-09-16 00:33:11,121 - INFO - models.literature_review - Found 5 recommended approaches
2025-09-16 00:33:11,121 - INFO - models.literature_review - Literature review saved to: literature_reviews/literature_review_numpy_array_1757982791.txt
2025-09-16 00:33:11,122 - INFO - models.ai_code_generator - Making API call to gpt-5
2025-09-16 00:33:11,122 - INFO - models.ai_code_generator - Prompt length: 4700 characters
2025-09-16 00:33:11,122 - INFO - models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-16 00:33:11,122 - INFO - models.ai_code_generator - Calling self.client.responses.create...
2025-09-16 00:33:11,122 - INFO - models.ai_code_generator - Model parameter: gpt-5
2025-09-16 00:33:11,122 - INFO - models.ai_code_generator - Input prompt preview: Generate PyTorch training function for 5-class classification.

Data: numpy_array, shape (1000, 2), 62352 samples

Dataset: MIT-BIH Arrhythmia Database
Source: https://physionet.org/content/mitdb/1.0....
2025-09-16 00:34:54,505 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-16 00:34:54,540 - INFO - models.ai_code_generator - API call completed successfully
2025-09-16 00:34:54,540 - INFO - models.ai_code_generator - Response type: <class 'openai.types.responses.response.Response'>
2025-09-16 00:34:54,540 - INFO - models.ai_code_generator - Response attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_request_id', '_setattr_handler', 'background', 'construct', 'conversation', 'copy', 'created_at', 'dict', 'error', 'from_orm', 'id', 'incomplete_details', 'instructions', 'json', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'object', 'output', 'output_text', 'parallel_tool_calls', 'parse_file', 'parse_obj', 'parse_raw', 'previous_response_id', 'prompt', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'schema', 'schema_json', 'service_tier', 'status', 'temperature', 'text', 'to_dict', 'to_json', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'update_forward_refs', 'usage', 'user', 'validate']
2025-09-16 00:34:54,541 - INFO - models.ai_code_generator - Using response.output_text
2025-09-16 00:34:54,541 - INFO - models.ai_code_generator - Extracted result length: 13520 characters
2025-09-16 00:34:54,541 - INFO - models.ai_code_generator - Result preview: {
    "model_name": "TinyCAT-ECG-1D",
    "training_code": "import math\nfrom typing import Dict, Any, Tuple\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.d...
2025-09-16 00:34:54,541 - INFO - models.ai_code_generator - Successfully extracted response content
2025-09-16 00:34:54,541 - INFO - models.ai_code_generator - AI generated training function: TinyCAT-ECG-1D
2025-09-16 00:34:54,541 - INFO - models.ai_code_generator - Confidence: 0.90
2025-09-16 00:34:54,541 - INFO - models.ai_code_generator - Reasoning: We use a compact CNN + tiny Transformer (TinyCAT) tailored to ECG: a 1D CNN stem (local morphology) followed by patch embedding and 2 lightweight Transformer encoder layers (global rhythm context). This aligns with recent results showing CNN+attention/Transformer hybrids outperform plain CNN/LSTM on MIT-BIH, especially on minority classes, while staying efficient. We include class-weighted loss (and optional focal gamma) to mitigate class imbalance, which is a key failure mode in arrhythmia classification. Metrics report per-class and macro-F1 per AAMI guidance rather than accuracy alone. The model has under 200k parameters with d_model=64, meeting the <256k constraint. The DataLoader only enables pin_memory when tensors are on CPU, as required. The loop is simple (no schedulers/early stopping) to support Bayesian optimization over core hyperparameters.
2025-09-16 00:34:54,541 - INFO - models.ai_code_generator - Literature review informed code generation (confidence: 0.78)
2025-09-16 00:34:54,542 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: TinyCAT-ECG-1D
2025-09-16 00:34:54,542 - INFO - evaluation.code_generation_pipeline_orchestrator - Reasoning: We use a compact CNN + tiny Transformer (TinyCAT) tailored to ECG: a 1D CNN stem (local morphology) followed by patch embedding and 2 lightweight Transformer encoder layers (global rhythm context). This aligns with recent results showing CNN+attention/Transformer hybrids outperform plain CNN/LSTM on MIT-BIH, especially on minority classes, while staying efficient. We include class-weighted loss (and optional focal gamma) to mitigate class imbalance, which is a key failure mode in arrhythmia classification. Metrics report per-class and macro-F1 per AAMI guidance rather than accuracy alone. The model has under 200k parameters with d_model=64, meeting the <256k constraint. The DataLoader only enables pin_memory when tensors are on CPU, as required. The loop is simple (no schedulers/early stopping) to support Bayesian optimization over core hyperparameters.
2025-09-16 00:34:54,542 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'hidden_size', 'dropout']
2025-09-16 00:34:54,542 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.90
2025-09-16 00:34:54,542 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ’¾ STEP 2: Save Training Function to JSON
2025-09-16 00:34:54,543 - INFO - models.ai_code_generator - Training function saved to: generated_training_functions/training_function_numpy_array_TinyCAT-ECG-1D_1757982894.json
2025-09-16 00:34:54,543 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_numpy_array_TinyCAT-ECG-1D_1757982894.json
2025-09-16 00:34:54,550 - INFO - models.training_function_executor - Training function validation passed
2025-09-16 00:34:54,550 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ” STEP 3: Bayesian Optimization
2025-09-16 00:34:54,551 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: TinyCAT-ECG-1D
2025-09-16 00:34:54,594 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 5000 samples
2025-09-16 00:34:54,594 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'hidden_size', 'dropout']
2025-09-16 00:34:54,595 - INFO - models.training_function_executor - GPU available: NVIDIA H100 NVL
2025-09-16 00:34:54,595 - WARNING - models.training_function_executor - Using provided subset instead of centralized splits - this may cause data leakage
2025-09-16 00:34:55,174 - INFO - bo.run_bo - Using default search space
2025-09-16 00:34:55,176 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-16 00:34:55,185 - INFO - bo.run_bo - Using explicitly provided search space
2025-09-16 00:34:55,187 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-16 00:34:55,189 - INFO - bo.run_bo - BO Trial 1: Initial random exploration
2025-09-16 00:34:55,189 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-09-16 00:34:55,189 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:34:55,190 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:34:55,190 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': 10, 'hidden_size': 204, 'dropout': 0.41779511056254093}
2025-09-16 00:34:55,197 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.01535224694197351, 'epochs': 10, 'batch_size': 16, 'hidden_size': 204, 'dropout': 0.41779511056254093}
2025-09-16 00:35:46,355 - INFO - models.training_function_executor - Training completed successfully: {'history': {'train_loss': [0.46839449819922446, 0.3451910338699818, 0.3328751083314419, 0.33169745323061944, 0.3250054413378239, 0.323138738155365, 0.32557979092001915, 0.3222063549757004, 0.31432617622613906, 0.314997460603714], 'val_loss': [0.29264264726638795, 0.31917399156093595, 0.304728040933609, 0.3237352395057678, 0.27404974222183226, 0.3075318967103958, 0.2913482426404953, 0.28606047892570496, 0.2823434978723526, 0.2817533737421036], 'val_accuracy': [0.26, 0.267, 0.151, 0.101, 0.407, 0.041, 0.422, 0.148, 0.128, 0.564], 'val_macro_f1': [0.23142948746681213, 0.1337684690952301, 0.10717197507619858, 0.0639861673116684, 0.22207868099212646, 0.04222548380494118, 0.1713368445634842, 0.08350418508052826, 0.12058510631322861, 0.22689738869667053], 'val_class_f1': [[0.3333333432674408, 0.17034700512886047, 0.08941176533699036, 0.05714285746216774, 0.5069124698638916], [0.48893359303474426, 0.0, 0.0, 0.04657534137368202, 0.13333334028720856], [0.1658291518688202, 0.0, 0.05666666850447655, 0.0, 0.31336405873298645], [0.04891304299235344, 0.013071895577013493, 0.0, 0.0044247787445783615, 0.2535211145877838], [0.565517246723175, 0.04597701132297516, 0.12179487198591232, 0.0, 0.37710437178611755], [0.0, 0.0, 0.07335907220840454, 0.07407407462596893, 0.06369426846504211], [0.6392092108726501, 0.13709677755832672, 0.0, 0.08037824928760529, 0.0], [0.2588774263858795, 0.0, 0.08172042667865753, 0.07692307978868484, 0.0], [0.0, 0.1944444477558136, 0.07786884903907776, 0.0, 0.3306122422218323], [0.7188665270805359, 0.0, 0.0, 0.028985507786273956, 0.38663485646247864]]}, 'best_val_macro_f1': 0.23142948746681213, 'best_epoch': 0, 'final_val_accuracy': 0.564, 'final_val_macro_f1': 0.22689738869667053, 'model_name': 'TinyCAT-ECG-1D', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.01535224694197351, 'epochs': 10, 'batch_size': 16, 'hidden_size': 204, 'dropout': 0.41779511056254093}}
2025-09-16 00:35:46,356 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 51.167s
2025-09-16 00:35:46,358 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-16 00:35:46,359 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.001s
2025-09-16 00:35:46,359 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}, value=0.0000
2025-09-16 00:35:46,359 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093} -> 0.0000
2025-09-16 00:35:46,362 - INFO - bo.run_bo - BO Trial 2: Initial random exploration
2025-09-16 00:35:46,362 - INFO - bo.run_bo - [PROFILE] suggest() took 0.003s
2025-09-16 00:35:46,362 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:35:46,362 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:35:46,363 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': 13, 'hidden_size': 103, 'dropout': 0.2335960277973153}
2025-09-16 00:35:46,370 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006071989493441302, 'epochs': 13, 'batch_size': 8, 'hidden_size': 103, 'dropout': 0.2335960277973153}
2025-09-16 00:35:46,377 - ERROR - models.training_function_executor - Training execution failed: embed_dim must be divisible by num_heads
2025-09-16 00:35:46,377 - ERROR - models.training_function_executor - Training code: import math
from typing import Dict, Any, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader


class SinusoidalPositionalE...
2025-09-16 00:35:46,378 - ERROR - models.training_function_executor - BO training objective failed: embed_dim must be divisible by num_heads
2025-09-16 00:35:46,378 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.015s
2025-09-16 00:35:46,378 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-16 00:35:46,378 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-09-16 00:35:46,378 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': np.int64(13), 'hidden_size': np.int64(103), 'dropout': 0.2335960277973153}, value=0.0000
2025-09-16 00:35:46,378 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': np.int64(13), 'hidden_size': np.int64(103), 'dropout': 0.2335960277973153} -> 0.0000
2025-09-16 00:35:46,380 - INFO - bo.run_bo - BO Trial 3: Initial random exploration
2025-09-16 00:35:46,380 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-09-16 00:35:46,380 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:35:46,380 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:35:46,381 - INFO - models.training_function_executor - Hyperparameters: {'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': 23, 'hidden_size': 273, 'dropout': 0.5053991405867774}
2025-09-16 00:35:46,386 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 3.727925903376984e-05, 'epochs': 23, 'batch_size': 64, 'hidden_size': 273, 'dropout': 0.5053991405867774}
2025-09-16 00:35:46,392 - ERROR - models.training_function_executor - Training execution failed: embed_dim must be divisible by num_heads
2025-09-16 00:35:46,392 - ERROR - models.training_function_executor - Training code: import math
from typing import Dict, Any, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader


class SinusoidalPositionalE...
2025-09-16 00:35:46,392 - ERROR - models.training_function_executor - BO training objective failed: embed_dim must be divisible by num_heads
2025-09-16 00:35:46,392 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.012s
2025-09-16 00:35:46,786 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-16 00:35:46,786 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.393s
2025-09-16 00:35:46,786 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': np.int64(23), 'hidden_size': np.int64(273), 'dropout': 0.5053991405867774}, value=0.0000
2025-09-16 00:35:46,786 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': np.int64(23), 'hidden_size': np.int64(273), 'dropout': 0.5053991405867774} -> 0.0000
2025-09-16 00:35:46,786 - INFO - bo.run_bo - BO Trial 4: Using RF surrogate + Expected Improvement
2025-09-16 00:35:46,786 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-16 00:35:46,787 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:35:46,787 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:35:46,787 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.05678201970293135, 'batch_size': 32, 'epochs': 5, 'hidden_size': 183, 'dropout': 0.08439771317838103}
2025-09-16 00:35:46,793 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.05678201970293135, 'epochs': 5, 'batch_size': 32, 'hidden_size': 183, 'dropout': 0.08439771317838103}
2025-09-16 00:35:46,798 - ERROR - models.training_function_executor - Training execution failed: embed_dim must be divisible by num_heads
2025-09-16 00:35:46,798 - ERROR - models.training_function_executor - Training code: import math
from typing import Dict, Any, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader


class SinusoidalPositionalE...
2025-09-16 00:35:46,798 - ERROR - models.training_function_executor - BO training objective failed: embed_dim must be divisible by num_heads
2025-09-16 00:35:46,798 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.011s
2025-09-16 00:35:47,181 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-16 00:35:47,181 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.383s
2025-09-16 00:35:47,182 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 0.05678201970293135, 'batch_size': np.int64(32), 'epochs': np.int64(5), 'hidden_size': np.int64(183), 'dropout': 0.08439771317838103}, value=0.0000
2025-09-16 00:35:47,182 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 0.05678201970293135, 'batch_size': np.int64(32), 'epochs': np.int64(5), 'hidden_size': np.int64(183), 'dropout': 0.08439771317838103} -> 0.0000
2025-09-16 00:35:47,182 - INFO - bo.run_bo - BO Trial 5: Using RF surrogate + Expected Improvement
2025-09-16 00:35:47,182 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-16 00:35:47,182 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:35:47,182 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:35:47,182 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006550049531232524, 'batch_size': 256, 'epochs': 6, 'hidden_size': 373, 'dropout': 0.4568590869235105}
2025-09-16 00:35:47,188 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006550049531232524, 'epochs': 6, 'batch_size': 256, 'hidden_size': 373, 'dropout': 0.4568590869235105}
2025-09-16 00:35:47,195 - ERROR - models.training_function_executor - Training execution failed: embed_dim must be divisible by num_heads
2025-09-16 00:35:47,195 - ERROR - models.training_function_executor - Training code: import math
from typing import Dict, Any, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader


class SinusoidalPositionalE...
2025-09-16 00:35:47,195 - ERROR - models.training_function_executor - BO training objective failed: embed_dim must be divisible by num_heads
2025-09-16 00:35:47,195 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.013s
2025-09-16 00:35:47,577 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-16 00:35:47,578 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.382s
2025-09-16 00:35:47,578 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 0.0006550049531232524, 'batch_size': np.int64(256), 'epochs': np.int64(6), 'hidden_size': np.int64(373), 'dropout': 0.4568590869235105}, value=0.0000
2025-09-16 00:35:47,578 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 0.0006550049531232524, 'batch_size': np.int64(256), 'epochs': np.int64(6), 'hidden_size': np.int64(373), 'dropout': 0.4568590869235105} -> 0.0000
2025-09-16 00:35:47,578 - INFO - bo.run_bo - BO Trial 6: Using RF surrogate + Expected Improvement
2025-09-16 00:35:47,578 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-16 00:35:47,578 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:35:47,579 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:35:47,579 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006302883671688219, 'batch_size': 128, 'epochs': 24, 'hidden_size': 432, 'dropout': 0.24572406269266053}
2025-09-16 00:35:47,584 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006302883671688219, 'epochs': 24, 'batch_size': 128, 'hidden_size': 432, 'dropout': 0.24572406269266053}
2025-09-16 00:36:03,254 - INFO - models.training_function_executor - Training completed successfully: {'history': {'train_loss': [0.3564159607887268, 0.2454930658340454, 0.21713835644721985, 0.1795501675605774, 0.1712417161464691, 0.14840132427215577, 0.14276776432991028, 0.11984603399038316, 0.09955584418773651, 0.10924188774824142, 0.11061973458528519, 0.08777864724397659, 0.07609419929981232, 0.08884473526477814, 0.06301270884275437, 0.07690256506204605, 0.0678030464053154, 0.08528114706277848, 0.06042706632614136, 0.05763784441351891, 0.05418579548597336, 0.05539968241751194, 0.05669070062041283, 0.05649884566664696], 'val_loss': [0.25770498418807986, 0.20910800898075105, 0.19437251150608062, 0.18631232166290282, 0.1432176648378372, 0.13077350568771362, 0.14374406731128692, 0.13880709922313691, 0.12866751319169997, 0.11407483613491058, 0.14019062197208404, 0.14835548937320708, 0.10821669602394104, 0.11115724611282349, 0.13849396920204163, 0.08955340337753295, 0.1479599540233612, 0.1318773913383484, 0.13535721206665038, 0.11971984624862671, 0.13951647400856018, 0.1688203001022339, 0.12225916528701783, 0.11430186867713928], 'val_accuracy': [0.404, 0.587, 0.521, 0.787, 0.646, 0.82, 0.714, 0.663, 0.687, 0.723, 0.835, 0.767, 0.853, 0.792, 0.84, 0.88, 0.827, 0.843, 0.827, 0.792, 0.804, 0.822, 0.859, 0.898], 'val_macro_f1': [0.2954772412776947, 0.42596063017845154, 0.4216330945491791, 0.599696159362793, 0.5428168773651123, 0.6543916463851929, 0.6190558671951294, 0.5259891152381897, 0.5644658803939819, 0.59211266040802, 0.6817083954811096, 0.628450870513916, 0.6750680804252625, 0.6207793354988098, 0.6507610082626343, 0.7334960699081421, 0.6419299244880676, 0.6936460733413696, 0.6493030190467834, 0.6522759199142456, 0.6409978270530701, 0.6689704656600952, 0.7201848030090332, 0.736630916595459], 'val_class_f1': [[0.536121666431427, 0.27796611189842224, 0.09625668078660965, 0.07692307978868484, 0.4901185631752014], [0.7134302854537964, 0.5112359523773193, 0.19178082048892975, 0.1492537260055542, 0.5641025900840759], [0.6757493019104004, 0.6279069781303406, 0.22368420660495758, 0.10256410390138626, 0.47826087474823], [0.857798159122467, 0.7106017470359802, 0.5245901346206665, 0.14492753148078918, 0.7605633735656738], [0.7279090285301208, 0.7631579041481018, 0.4266666769981384, 0.14035087823867798, 0.656000018119812], [0.8790874481201172, 0.8300653696060181, 0.5161290168762207, 0.29885056614875793, 0.747826099395752], [0.8087876439094543, 0.7938931584358215, 0.6842105388641357, 0.15740740299224854, 0.6509804129600525], [0.7421602606773376, 0.6997389197349548, 0.19780220091342926, 0.26829269528388977, 0.7219512462615967], [0.7570815682411194, 0.8401253819465637, 0.3636363744735718, 0.15458936989307404, 0.7068965435028076], [0.7943143844604492, 0.8385093212127686, 0.3720930218696594, 0.17894737422466278, 0.7766990065574646], [0.8938381671905518, 0.8275862336158752, 0.6666666865348816, 0.27586206793785095, 0.7445887327194214], [0.8370606899261475, 0.8438538312911987, 0.5769230723381042, 0.3333333432674408, 0.5510835647583008], [0.9084084033966064, 0.8636363744735718, 0.395061731338501, 0.3181818127632141, 0.8900523781776428], [0.8503184914588928, 0.8427299857139587, 0.35555556416511536, 0.2921348214149475, 0.7631579041481018], [0.8952959179878235, 0.8852459192276001, 0.41025641560554504, 0.2857142984867096, 0.7772925496101379], [0.9295154213905334, 0.8712871074676514, 0.695652186870575, 0.2947368323802948, 0.876288652420044], [0.8900845646858215, 0.8543689250946045, 0.3035714328289032, 0.3235294222831726, 0.8380952477455139], [0.8953399658203125, 0.7658402323722839, 0.5454545617103577, 0.3636363744735718, 0.8979591727256775], [0.8861348032951355, 0.882539689540863, 0.43589743971824646, 0.24742268025875092, 0.7945205569267273], [0.8532910346984863, 0.9054054021835327, 0.49275362491607666, 0.1875, 0.822429895401001], [0.8672427535057068, 0.8681672215461731, 0.5230769515037537, 0.2222222238779068, 0.7242798209190369], [0.8811728358268738, 0.8741722106933594, 0.6181818246841431, 0.3142857253551483, 0.6570397019386292], [0.9070294499397278, 0.8917197585105896, 0.6545454263687134, 0.24137930572032928, 0.90625], [0.9371345043182373, 0.9090909361839294, 0.5660377144813538, 0.3589743673801422, 0.9119170904159546]]}, 'best_val_macro_f1': 0.736630916595459, 'best_epoch': 23, 'final_val_accuracy': 0.898, 'final_val_macro_f1': 0.736630916595459, 'model_name': 'TinyCAT-ECG-1D', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0006302883671688219, 'epochs': 24, 'batch_size': 128, 'hidden_size': 432, 'dropout': 0.24572406269266053}}
2025-09-16 00:36:03,255 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 15.676s
2025-09-16 00:36:03,652 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-16 00:36:03,653 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.397s
2025-09-16 00:36:03,653 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.0006302883671688219, 'batch_size': np.int64(128), 'epochs': np.int64(24), 'hidden_size': np.int64(432), 'dropout': 0.24572406269266053}, value=0.0000
2025-09-16 00:36:03,653 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.0006302883671688219, 'batch_size': np.int64(128), 'epochs': np.int64(24), 'hidden_size': np.int64(432), 'dropout': 0.24572406269266053} -> 0.0000
2025-09-16 00:36:03,653 - INFO - bo.run_bo - BO Trial 7: Using RF surrogate + Expected Improvement
2025-09-16 00:36:03,654 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-16 00:36:03,654 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:36:03,654 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:36:03,654 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.04222247265603969, 'batch_size': 16, 'epochs': 18, 'hidden_size': 51, 'dropout': 0.25007875594551915}
2025-09-16 00:36:03,661 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.04222247265603969, 'epochs': 18, 'batch_size': 16, 'hidden_size': 51, 'dropout': 0.25007875594551915}
2025-09-16 00:36:03,666 - ERROR - models.training_function_executor - Training execution failed: embed_dim must be divisible by num_heads
2025-09-16 00:36:03,666 - ERROR - models.training_function_executor - Training code: import math
from typing import Dict, Any, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader


class SinusoidalPositionalE...
2025-09-16 00:36:03,666 - ERROR - models.training_function_executor - BO training objective failed: embed_dim must be divisible by num_heads
2025-09-16 00:36:03,666 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.013s
2025-09-16 00:36:04,048 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-16 00:36:04,049 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.382s
2025-09-16 00:36:04,049 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 0.04222247265603969, 'batch_size': np.int64(16), 'epochs': np.int64(18), 'hidden_size': np.int64(51), 'dropout': 0.25007875594551915}, value=0.0000
2025-09-16 00:36:04,049 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 0.04222247265603969, 'batch_size': np.int64(16), 'epochs': np.int64(18), 'hidden_size': np.int64(51), 'dropout': 0.25007875594551915} -> 0.0000
2025-09-16 00:36:04,049 - INFO - bo.run_bo - BO Trial 8: Using RF surrogate + Expected Improvement
2025-09-16 00:36:04,049 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-16 00:36:04,050 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:36:04,050 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:36:04,050 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.015831723490615644, 'batch_size': 32, 'epochs': 12, 'hidden_size': 319, 'dropout': 0.2621266723153076}
2025-09-16 00:36:04,055 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.015831723490615644, 'epochs': 12, 'batch_size': 32, 'hidden_size': 319, 'dropout': 0.2621266723153076}
2025-09-16 00:36:04,062 - ERROR - models.training_function_executor - Training execution failed: embed_dim must be divisible by num_heads
2025-09-16 00:36:04,062 - ERROR - models.training_function_executor - Training code: import math
from typing import Dict, Any, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader


class SinusoidalPositionalE...
2025-09-16 00:36:04,062 - ERROR - models.training_function_executor - BO training objective failed: embed_dim must be divisible by num_heads
2025-09-16 00:36:04,062 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 0.013s
2025-09-16 00:36:04,442 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-16 00:36:04,442 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.380s
2025-09-16 00:36:04,442 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 0.015831723490615644, 'batch_size': np.int64(32), 'epochs': np.int64(12), 'hidden_size': np.int64(319), 'dropout': 0.2621266723153076}, value=0.0000
2025-09-16 00:36:04,442 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 0.015831723490615644, 'batch_size': np.int64(32), 'epochs': np.int64(12), 'hidden_size': np.int64(319), 'dropout': 0.2621266723153076} -> 0.0000
2025-09-16 00:36:04,443 - INFO - bo.run_bo - BO Trial 9: Using RF surrogate + Expected Improvement
2025-09-16 00:36:04,443 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-16 00:36:04,443 - INFO - models.training_function_executor - Using device: cuda
2025-09-16 00:36:04,443 - INFO - models.training_function_executor - Executing training function: TinyCAT-ECG-1D
2025-09-16 00:36:04,443 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0004582655140915009, 'batch_size': 8, 'epochs': 22, 'hidden_size': 288, 'dropout': 0.2979985056070939}
2025-09-16 00:36:04,449 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0004582655140915009, 'epochs': 22, 'batch_size': 8, 'hidden_size': 288, 'dropout': 0.2979985056070939}
