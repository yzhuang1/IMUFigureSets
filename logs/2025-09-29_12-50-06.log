2025-09-29 12:50:06,940 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-09-29 12:50:07,046 - INFO - __main__ - Logging system initialized successfully
2025-09-29 12:50:07,047 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-09-29 12:50:07,047 - INFO - __main__ - Starting real data processing from data/dataset1/ directory
2025-09-29 12:50:07,047 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'X.npy', 'y.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-09-29 12:50:07,047 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-09-29 12:50:07,047 - INFO - __main__ - Attempting to load: X.npy
2025-09-29 12:50:07,088 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-09-29 12:50:07,126 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (62352, 1000, 2), device: cuda
2025-09-29 12:50:07,126 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-09-29 12:50:07,126 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-09-29 12:50:07,126 - INFO - __main__ - Flow: Code Generation â†’ BO â†’ Evaluation
2025-09-29 12:50:07,128 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-29 12:50:07,128 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-09-29 12:50:07,128 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-09-29 12:50:07,128 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-09-29 12:50:07,128 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation â†’ JSON Storage â†’ BO â†’ Training Execution â†’ Evaluation
2025-09-29 12:50:07,128 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-09-29 12:50:07,129 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-09-29 12:50:07,129 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-09-29 12:50:07,129 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-09-29 12:50:07,227 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-09-29 12:50:07,227 - INFO - class_balancing - Class imbalance analysis:
2025-09-29 12:50:07,227 - INFO - class_balancing -   Strategy: severe_imbalance
2025-09-29 12:50:07,227 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-09-29 12:50:07,227 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-09-29 12:50:07,227 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-09-29 12:50:07,228 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-09-29 12:50:07,228 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-09-29 12:50:07,228 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-09-29 12:50:07,228 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-09-29 12:50:07,398 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-09-29 12:50:07,399 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-09-29 12:50:07,399 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-29 12:50:07,399 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-09-29 12:50:07,399 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-29 12:50:07,399 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ¤– STEP 1: AI Training Code Generation
2025-09-29 12:50:07,399 - INFO - _models.ai_code_generator - Conducting literature review before code generation...
2025-09-29 12:53:37,831 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-29 12:53:37,859 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-29 12:53:37,859 - INFO - _models.ai_code_generator - Prompt length: 4123 characters
2025-09-29 12:53:37,859 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-29 12:53:37,859 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-29 12:53:37,859 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-09-29 12:55:27,748 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-29 12:55:27,879 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-09-29 12:55:27,879 - INFO - _models.ai_code_generator - AI generated training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:55:27,879 - INFO - _models.ai_code_generator - Confidence: 0.86
2025-09-29 12:55:27,879 - INFO - _models.ai_code_generator - Literature review informed code generation (confidence: 0.72)
2025-09-29 12:55:27,879 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:55:27,879 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'stem_channels', 'embed_channels', 'se_reduction', 'd_model', 'num_heads', 'num_layers', 'patch_size', 'class_weighting', 'label_smoothing', 'grad_clip', 'scheduler', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibrate_batches']
2025-09-29 12:55:27,879 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.86
2025-09-29 12:55:27,880 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ’¾ STEP 2: Save Training Function to JSON
2025-09-29 12:55:27,880 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions/training_function_torch_tensor_CAT-Net_Tiny__1D_CNN_+_Channel_Attention_+_Transformer_1759168527.json
2025-09-29 12:55:27,880 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_torch_tensor_CAT-Net_Tiny__1D_CNN_+_Channel_Attention_+_Transformer_1759168527.json
2025-09-29 12:55:27,880 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ” STEP 3: Bayesian Optimization
2025-09-29 12:55:27,880 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:55:27,880 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ“¦ Installing dependencies for GPT-generated training code...
2025-09-29 12:55:27,881 - INFO - package_installer - ðŸ” Analyzing GPT-generated code for package dependencies...
2025-09-29 12:55:27,883 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-09-29 12:55:27,883 - INFO - package_installer - Available packages: {'torch'}
2025-09-29 12:55:27,883 - INFO - package_installer - Missing packages: set()
2025-09-29 12:55:27,884 - INFO - package_installer - âœ… All required packages are already available
2025-09-29 12:55:27,884 - INFO - evaluation.code_generation_pipeline_orchestrator - âœ… All dependencies installed successfully
2025-09-29 12:55:27,884 - INFO - data_splitting - Using all 39904 training samples for BO
2025-09-29 12:55:27,884 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 39904 samples (using bo_sample_num=70000)
2025-09-29 12:55:27,884 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'stem_channels', 'embed_channels', 'se_reduction', 'd_model', 'num_heads', 'num_layers', 'patch_size', 'class_weighting', 'label_smoothing', 'grad_clip', 'scheduler', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibrate_batches']
2025-09-29 12:55:27,884 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-09-29 12:55:27,884 - INFO - data_splitting - Using all 39904 training samples for BO
2025-09-29 12:55:27,884 - INFO - _models.training_function_executor - Using BO subset for optimization: 39904 samples (bo_sample_num=70000)
2025-09-29 12:55:27,918 - INFO - _models.training_function_executor - BO splits - Train: 31923, Val: 7981
2025-09-29 12:55:28,045 - INFO - bo.run_bo - Converted GPT search space: 20 parameters
2025-09-29 12:55:28,045 - INFO - bo.run_bo - Using GPT-generated search space
2025-09-29 12:55:28,046 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-29 12:55:28,046 - INFO - bo.run_bo - ðŸ”BO Trial 1: Initial random exploration
2025-09-29 12:55:28,046 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-29 12:55:28,047 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 12:55:28,047 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:55:28,047 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0015352246941973508, 'batch_size': 64, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'stem_channels': 26, 'embed_channels': 42, 'se_reduction': 8, 'd_model': 51, 'num_heads': 2, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.09385527090157504, 'grad_clip': 0.0007787658410143285, 'scheduler': 'cosine', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 25}
2025-09-29 12:55:28,048 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0015352246941973508, 'batch_size': 64, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'stem_channels': 26, 'embed_channels': 42, 'se_reduction': 8, 'd_model': 51, 'num_heads': 2, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.09385527090157504, 'grad_clip': 0.0007787658410143285, 'scheduler': 'cosine', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 25}
2025-09-29 12:56:00,019 - INFO - _models.training_function_executor - Model: 66,792 parameters, 287.0KB storage
2025-09-29 12:56:00,019 - WARNING - _models.training_function_executor - Model storage 287.0KB exceeds 256KB limit!
2025-09-29 12:56:00,019 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7909141645163955, 1.536008431223447, 1.4534202800962872, 1.4183884007419518, 1.396048801934313, 1.3749598576453979, 1.3607799245981511, 1.3329969650518918, 1.317775950283708, 1.2986724610796911, 1.282148654331903, 1.284224412484255], 'val_losses': [1.6046439361572267, 1.4851708068847655, 1.4332925610542298, 1.407410322189331, 1.3980266160964965, 1.3726754679679871, 1.344984435081482, 1.3391389327049255, 1.3265949516296387, 1.3190755014419555, 1.3168915519714355, 1.3160627155303954], 'val_acc': [0.4585891366004944, 0.27352461218833923, 0.4909159243106842, 0.5939105153083801, 0.6887608170509338, 0.7571732997894287, 0.7757173180580139, 0.843879222869873, 0.8205738663673401, 0.8232051134109497, 0.8417491316795349, 0.8497682213783264], 'val_macro_f1': [0.4546042665839195, 0.4068940535187721, 0.5150491967797279, 0.5782665565609932, 0.604300606250763, 0.6332468569278717, 0.6426542460918426, 0.6877830564975739, 0.6714311361312866, 0.6733167052268982, 0.6867720425128937, 0.6949099361896515], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0015352246941973508, 'batch_size': 64, 'epochs': 12, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'stem_channels': 26, 'embed_channels': 42, 'se_reduction': 8, 'd_model': 51, 'num_heads': 2, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.09385527090157504, 'grad_clip': 0.0007787658410143285, 'scheduler': 'cosine', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 25}, 'model_parameter_count': 66792, 'model_storage_size_kb': 286.99687500000005, 'model_size_validation': 'FAIL'}
2025-09-29 12:56:00,019 - INFO - _models.training_function_executor - BO Objective: base=0.8498, size_penalty=0.0605, final=0.7892
2025-09-29 12:56:00,019 - INFO - _models.training_function_executor - Model: 66,792 parameters, 287.0KB (FAIL 256KB limit)
2025-09-29 12:56:00,020 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 31.973s
2025-09-29 12:56:00,020 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7892
2025-09-29 12:56:00,020 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-09-29 12:56:00,020 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.0015352246941973508, 'batch_size': 64, 'epochs': np.int64(12), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'stem_channels': np.int64(26), 'embed_channels': np.int64(42), 'se_reduction': 8, 'd_model': np.int64(51), 'num_heads': 2, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.09385527090157504, 'grad_clip': 0.0007787658410143285, 'scheduler': 'cosine', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': np.int64(25)}, value=0.7892
2025-09-29 12:56:00,020 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.0015352246941973508, 'batch_size': 64, 'epochs': np.int64(12), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'stem_channels': np.int64(26), 'embed_channels': np.int64(42), 'se_reduction': 8, 'd_model': np.int64(51), 'num_heads': 2, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.09385527090157504, 'grad_clip': 0.0007787658410143285, 'scheduler': 'cosine', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': np.int64(25)} -> 0.7892
2025-09-29 12:56:00,020 - INFO - bo.run_bo - ðŸ”BO Trial 2: Initial random exploration
2025-09-29 12:56:00,020 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-29 12:56:00,020 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 12:56:00,021 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:56:00,021 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.461896279370497e-05, 'batch_size': 256, 'epochs': 46, 'weight_decay': 1.536960311060885e-06, 'dropout': 0.4868777594207297, 'stem_channels': 30, 'embed_channels': 46, 'se_reduction': 4, 'd_model': 59, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.017052412368729158, 'grad_clip': 0.06505159298527953, 'scheduler': 'cosine', 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 21}
2025-09-29 12:56:00,022 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.461896279370497e-05, 'batch_size': 256, 'epochs': 46, 'weight_decay': 1.536960311060885e-06, 'dropout': 0.4868777594207297, 'stem_channels': 30, 'embed_channels': 46, 'se_reduction': 4, 'd_model': 59, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.017052412368729158, 'grad_clip': 0.06505159298527953, 'scheduler': 'cosine', 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 21}
2025-09-29 12:57:43,934 - INFO - _models.training_function_executor - Model: 87,758 parameters, 377.1KB storage
2025-09-29 12:57:43,934 - WARNING - _models.training_function_executor - Model storage 377.1KB exceeds 256KB limit!
2025-09-29 12:57:43,934 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7056134586334228, 1.6164115209579468, 1.5605883083343506, 1.5281367921829223, 1.4971872520446778, 1.4757187881469727, 1.4529165534973145, 1.434800287246704, 1.4141136121749878, 1.3890073976516724, 1.344252760887146, 1.301025050163269, 1.2677182006835936, 1.2443250303268432, 1.2225665130615235, 1.2028582134246826, 1.1906126799583434, 1.173751543521881, 1.1630166969299316, 1.151725422859192, 1.1432781500816345, 1.1336602458953857, 1.1264673552513123, 1.119385712146759, 1.1081266212463379, 1.1029894366264343, 1.0990241694450378, 1.0928965649604798, 1.08809423494339, 1.0847985272407532, 1.0782746658325195, 1.0755815615653992, 1.0696004629135132, 1.0677013840675353, 1.0658669271469117, 1.0603351178169251, 1.0624530391693114, 1.0610944910049438, 1.0595200238227844, 1.0544026703834535, 1.055243649482727, 1.0525848331451415, 1.054713001728058, 1.0542218136787413, 1.0546275010108948, 1.054668463230133], 'val_losses': [1.6349763795733452, 1.6237385757267475, 1.608341135084629, 1.631884541362524, 1.5854827389121056, 1.5804935619235039, 1.5375561192631721, 1.523690976202488, 1.515224665403366, 1.4479498267173767, 1.3736896812915802, 1.3722466640174389, 1.3335256353020668, 1.3054100722074509, 1.296833723783493, 1.281781166791916, 1.2617122568190098, 1.2366310488432646, 1.2366392612457275, 1.2307813987135887, 1.2142419945448637, 1.2112039290368557, 1.2043502423912287, 1.2021038718521595, 1.1864719409495592, 1.1750299856066704, 1.1699282489717007, 1.1698218192905188, 1.1755846850574017, 1.1606441531330347, 1.1490681152790785, 1.1465291734784842, 1.1504932697862387, 1.148910578340292, 1.1492127887904644, 1.1413877438753843, 1.143253332003951, 1.1424915120005608, 1.1425429452210665, 1.1362773049622774, 1.1376785822212696, 1.1381899751722813, 1.1371555030345917, 1.1368276253342628, 1.1370550636202097, 1.137017773464322], 'val_acc': [0.11865680664777756, 0.23480767011642456, 0.23067285120487213, 0.20749279856681824, 0.22365617752075195, 0.26763564348220825, 0.2875579595565796, 0.2844254970550537, 0.29269516468048096, 0.30935972929000854, 0.35722339153289795, 0.38153114914894104, 0.3990727961063385, 0.41548678278923035, 0.4241323173046112, 0.43277785181999207, 0.4419245719909668, 0.4595915377140045, 0.44443053007125854, 0.44092220067977905, 0.45144718885421753, 0.43791505694389343, 0.46335044503211975, 0.4628492593765259, 0.46297457814216614, 0.47149479389190674, 0.469364732503891, 0.4696153402328491, 0.46673348546028137, 0.47525373101234436, 0.47876206040382385, 0.47337427735328674, 0.47826087474823, 0.47801026701927185, 0.47562962770462036, 0.4793885350227356, 0.47838616371154785, 0.4728730618953705, 0.4751284420490265, 0.47838616371154785, 0.47876206040382385, 0.4785114526748657, 0.4792632460594177, 0.47951385378837585, 0.4793885350227356, 0.4793885350227356], 'val_macro_f1': [0.1212493672966957, 0.19570709615945817, 0.20946891009807586, 0.19847072958946227, 0.2059928923845291, 0.24117290526628493, 0.25927530974149704, 0.2594935581088066, 0.2613656744360924, 0.2706092894077301, 0.30409105122089386, 0.31557556986808777, 0.32940870672464373, 0.3419950842857361, 0.3554673880338669, 0.3613949790596962, 0.37240450233221056, 0.38760830760002135, 0.38172866106033326, 0.3805425614118576, 0.38969290256500244, 0.3856759324669838, 0.3948152184486389, 0.3916215807199478, 0.39601866602897645, 0.4006680458784103, 0.40152031779289243, 0.4012133777141571, 0.39797349870204923, 0.4050004482269287, 0.40902122259140017, 0.4084200918674469, 0.40775317549705503, 0.4070689707994461, 0.4061360865831375, 0.41000889241695404, 0.4082328200340271, 0.40737714767456057, 0.4081581711769104, 0.4107146501541138, 0.41036997437477113, 0.40985158681869505, 0.41020581126213074, 0.41049819588661196, 0.4103993594646454, 0.4103993594646454], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.461896279370497e-05, 'batch_size': 256, 'epochs': 46, 'weight_decay': 1.536960311060885e-06, 'dropout': 0.4868777594207297, 'stem_channels': 30, 'embed_channels': 46, 'se_reduction': 4, 'd_model': 59, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.017052412368729158, 'grad_clip': 0.06505159298527953, 'scheduler': 'cosine', 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 21}, 'model_parameter_count': 87758, 'model_storage_size_kb': 377.08515625, 'model_size_validation': 'FAIL'}
2025-09-29 12:57:43,934 - INFO - _models.training_function_executor - BO Objective: base=0.4794, size_penalty=0.2365, final=0.2429
2025-09-29 12:57:43,934 - INFO - _models.training_function_executor - Model: 87,758 parameters, 377.1KB (FAIL 256KB limit)
2025-09-29 12:57:43,934 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 103.914s
2025-09-29 12:57:43,934 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2429
2025-09-29 12:57:43,934 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-09-29 12:57:43,934 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 1.461896279370497e-05, 'batch_size': 256, 'epochs': np.int64(46), 'weight_decay': 1.536960311060885e-06, 'dropout': 0.4868777594207297, 'stem_channels': np.int64(30), 'embed_channels': np.int64(46), 'se_reduction': 4, 'd_model': np.int64(59), 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.017052412368729158, 'grad_clip': 0.06505159298527953, 'scheduler': 'cosine', 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': np.int64(21)}, value=0.2429
2025-09-29 12:57:43,934 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 1.461896279370497e-05, 'batch_size': 256, 'epochs': np.int64(46), 'weight_decay': 1.536960311060885e-06, 'dropout': 0.4868777594207297, 'stem_channels': np.int64(30), 'embed_channels': np.int64(46), 'se_reduction': 4, 'd_model': np.int64(59), 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': 'balanced', 'label_smoothing': 0.017052412368729158, 'grad_clip': 0.06505159298527953, 'scheduler': 'cosine', 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': np.int64(21)} -> 0.2429
2025-09-29 12:57:43,935 - INFO - bo.run_bo - ðŸ”BO Trial 3: Initial random exploration
2025-09-29 12:57:43,935 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-29 12:57:43,935 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 12:57:43,935 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:57:43,935 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.386394780402564e-06, 'batch_size': 64, 'epochs': 11, 'weight_decay': 0.0002754143921332031, 'dropout': 0.4165974558680823, 'stem_channels': 18, 'embed_channels': 45, 'se_reduction': 4, 'd_model': 55, 'num_heads': 4, 'num_layers': 1, 'patch_size': 25, 'class_weighting': 'balanced', 'label_smoothing': 0.003131329245555859, 'grad_clip': 0.8422847745949987, 'scheduler': 'none', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 15}
2025-09-29 12:57:43,936 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.386394780402564e-06, 'batch_size': 64, 'epochs': 11, 'weight_decay': 0.0002754143921332031, 'dropout': 0.4165974558680823, 'stem_channels': 18, 'embed_channels': 45, 'se_reduction': 4, 'd_model': 55, 'num_heads': 4, 'num_layers': 1, 'patch_size': 25, 'class_weighting': 'balanced', 'label_smoothing': 0.003131329245555859, 'grad_clip': 0.8422847745949987, 'scheduler': 'none', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 15}
2025-09-29 12:58:02,817 - INFO - _models.training_function_executor - Model: 89,263 parameters, 383.6KB storage
2025-09-29 12:58:02,818 - WARNING - _models.training_function_executor - Model storage 383.6KB exceeds 256KB limit!
2025-09-29 12:58:02,818 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6004545069887548, 1.541987683825598, 1.477304157369839, 1.3940273759838098, 1.3089457093355412, 1.2227627903760554, 1.163405371452859, 1.1152876021866809, 1.0685872015112148, 1.035706921307023, 1.0046554604369795], 'val_losses': [1.5469373207092285, 1.485417773246765, 1.3850812873840332, 1.3172688369750976, 1.2754389576911926, 1.1864237141609193, 1.0957079181671143, 1.0628218955993651, 1.049303771495819, 0.9856678185462951, 0.9796934809684753], 'val_acc': [0.3820323348045349, 0.396692156791687, 0.4565843939781189, 0.3492043614387512, 0.3781481087207794, 0.401829332113266, 0.45984211564064026, 0.4740007519721985, 0.5244956612586975, 0.5516852736473083, 0.5575742125511169], 'val_macro_f1': [0.1566435992717743, 0.22895896509289743, 0.28164215236902235, 0.29220998138189314, 0.29123819917440413, 0.30399249494075775, 0.35976741313934324, 0.3754800230264664, 0.4077337712049484, 0.42065533995628357, 0.4265743106603622], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.386394780402564e-06, 'batch_size': 64, 'epochs': 11, 'weight_decay': 0.0002754143921332031, 'dropout': 0.4165974558680823, 'stem_channels': 18, 'embed_channels': 45, 'se_reduction': 4, 'd_model': 55, 'num_heads': 4, 'num_layers': 1, 'patch_size': 25, 'class_weighting': 'balanced', 'label_smoothing': 0.003131329245555859, 'grad_clip': 0.8422847745949987, 'scheduler': 'none', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 15}, 'model_parameter_count': 89263, 'model_storage_size_kb': 383.551953125, 'model_size_validation': 'FAIL'}
2025-09-29 12:58:02,818 - INFO - _models.training_function_executor - BO Objective: base=0.5576, size_penalty=0.2491, final=0.3084
2025-09-29 12:58:02,818 - INFO - _models.training_function_executor - Model: 89,263 parameters, 383.6KB (FAIL 256KB limit)
2025-09-29 12:58:02,818 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 18.883s
2025-09-29 12:58:02,906 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.3084
2025-09-29 12:58:02,906 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.088s
2025-09-29 12:58:02,906 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 8.386394780402564e-06, 'batch_size': 64, 'epochs': np.int64(11), 'weight_decay': 0.0002754143921332031, 'dropout': 0.4165974558680823, 'stem_channels': np.int64(18), 'embed_channels': np.int64(45), 'se_reduction': 4, 'd_model': np.int64(55), 'num_heads': 4, 'num_layers': 1, 'patch_size': 25, 'class_weighting': 'balanced', 'label_smoothing': 0.003131329245555859, 'grad_clip': 0.8422847745949987, 'scheduler': 'none', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': np.int64(15)}, value=0.3084
2025-09-29 12:58:02,906 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 8.386394780402564e-06, 'batch_size': 64, 'epochs': np.int64(11), 'weight_decay': 0.0002754143921332031, 'dropout': 0.4165974558680823, 'stem_channels': np.int64(18), 'embed_channels': np.int64(45), 'se_reduction': 4, 'd_model': np.int64(55), 'num_heads': 4, 'num_layers': 1, 'patch_size': 25, 'class_weighting': 'balanced', 'label_smoothing': 0.003131329245555859, 'grad_clip': 0.8422847745949987, 'scheduler': 'none', 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': np.int64(15)} -> 0.3084
2025-09-29 12:58:02,906 - INFO - bo.run_bo - ðŸ”BO Trial 4: Using RF surrogate + Expected Improvement
2025-09-29 12:58:02,906 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 12:58:02,906 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 12:58:02,906 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:58:02,906 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.259279742015697e-06, 'batch_size': 128, 'epochs': 35, 'weight_decay': 0.0028238287471414178, 'dropout': 0.2233341537386907, 'stem_channels': 22, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 49, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.00021251514098165062, 'grad_clip': 0.6852692178617716, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 13}
2025-09-29 12:58:02,907 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.259279742015697e-06, 'batch_size': 128, 'epochs': 35, 'weight_decay': 0.0028238287471414178, 'dropout': 0.2233341537386907, 'stem_channels': 22, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 49, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.00021251514098165062, 'grad_clip': 0.6852692178617716, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 13}
2025-09-29 12:58:51,706 - INFO - _models.training_function_executor - Model: 41,115 parameters, 44.2KB storage
2025-09-29 12:58:51,706 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.135721310853958, 0.930156263589859, 0.8772592108249664, 0.8537835009098053, 0.8387294266223907, 0.82806232047081, 0.8212283403873444, 0.8165746464729309, 0.8129623894691467, 0.8105600039958953, 0.8068417513370514, 0.804095920085907, 0.8022909097671509, 0.8005067279338837, 0.7994789290428161, 0.7975712399482727, 0.7959601004123688, 0.7948212349414825, 0.7936970572471619, 0.7925590784549713, 0.7910838482379914, 0.7912683246135712, 0.7897006726264953, 0.7888149271011352, 0.7888758983612061, 0.7881338531970978, 0.7885435936450959, 0.7875038785934448, 0.7866160745620727, 0.7866252751350403, 0.7875365190505982, 0.7865455927848816, 0.7861569271087646, 0.7865006833076477, 0.7862606134414672], 'val_losses': [0.9383559425671896, 0.87942483879271, 0.856587825313447, 0.8414833119937352, 0.8336266544130113, 0.8287137434596107, 0.8243135270618257, 0.8244689816520328, 0.8182231083748832, 0.8183134737468901, 0.8161431286070082, 0.815278254804157, 0.8140680912941222, 0.8130830128987631, 0.8098054736379593, 0.8108195227289957, 0.806767191205706, 0.8059614641325814, 0.805330094837007, 0.803277609840272, 0.8030796684916057, 0.8027033313872323, 0.8018431445908925, 0.8022133348480104, 0.801644177663894, 0.8006173031670707, 0.7995608108384269, 0.7991733305037968, 0.7991223817779904, 0.7989660813694909, 0.7986823992123679, 0.7985380216250344, 0.7985201440160237, 0.7985123017477611, 0.7985037574692379], 'val_acc': [0.7200852036476135, 0.7200852036476135, 0.7177045345306396, 0.7168274521827698, 0.7283548712730408, 0.7269765734672546, 0.7247211933135986, 0.7249718308448792, 0.7257235646247864, 0.7263500690460205, 0.7262247800827026, 0.7260994911193848, 0.7259742021560669, 0.7260994911193848, 0.7262247800827026, 0.7263500690460205, 0.7264753580093384, 0.7264753580093384, 0.7266006469726562, 0.7273524403572083, 0.7274777889251709, 0.7272271513938904, 0.7272271513938904, 0.7274777889251709, 0.7271018624305725, 0.7278536558151245, 0.7277283668518066, 0.7279789447784424, 0.7279789447784424, 0.7279789447784424, 0.7279789447784424, 0.7279789447784424, 0.7279789447784424, 0.7279789447784424, 0.7279789447784424], 'val_macro_f1': [0.16745338439941407, 0.16745338439941407, 0.1671432614326477, 0.17589111998677254, 0.22770820260047914, 0.23016756176948547, 0.23353814482688903, 0.2343113124370575, 0.24129679799079895, 0.24188202619552612, 0.24280317425727843, 0.2427190661430359, 0.2426350772380829, 0.24326177835464477, 0.24398952722549438, 0.24391456842422485, 0.24634990692138672, 0.24575287699699402, 0.2456757605075836, 0.2481166124343872, 0.24839768409729004, 0.24720227122306823, 0.24720227122306823, 0.24757145047187806, 0.24677006006240845, 0.24851035475730895, 0.24883070588111877, 0.2493103474844247, 0.2493103474844247, 0.2493103474844247, 0.2493779286276549, 0.249255344318226, 0.249255344318226, 0.2493228122126311, 0.2493228122126311], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.259279742015697e-06, 'batch_size': 128, 'epochs': 35, 'weight_decay': 0.0028238287471414178, 'dropout': 0.2233341537386907, 'stem_channels': 22, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 49, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.00021251514098165062, 'grad_clip': 0.6852692178617716, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 13}, 'model_parameter_count': 41115, 'model_storage_size_kb': 44.16650390625001, 'model_size_validation': 'PASS'}
2025-09-29 12:58:51,706 - INFO - _models.training_function_executor - BO Objective: base=0.7280, size_penalty=0.0000, final=0.7280
2025-09-29 12:58:51,706 - INFO - _models.training_function_executor - Model: 41,115 parameters, 44.2KB (PASS 256KB limit)
2025-09-29 12:58:51,706 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 48.800s
2025-09-29 12:58:51,910 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7280
2025-09-29 12:58:51,910 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.204s
2025-09-29 12:58:51,910 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 2.259279742015697e-06, 'batch_size': np.int64(128), 'epochs': np.int64(35), 'weight_decay': 0.0028238287471414178, 'dropout': 0.2233341537386907, 'stem_channels': np.int64(22), 'embed_channels': np.int64(32), 'se_reduction': np.int64(8), 'd_model': np.int64(49), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(25), 'class_weighting': np.str_('none'), 'label_smoothing': 0.00021251514098165062, 'grad_clip': 0.6852692178617716, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(13)}, value=0.7280
2025-09-29 12:58:51,910 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 2.259279742015697e-06, 'batch_size': np.int64(128), 'epochs': np.int64(35), 'weight_decay': 0.0028238287471414178, 'dropout': 0.2233341537386907, 'stem_channels': np.int64(22), 'embed_channels': np.int64(32), 'se_reduction': np.int64(8), 'd_model': np.int64(49), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(25), 'class_weighting': np.str_('none'), 'label_smoothing': 0.00021251514098165062, 'grad_clip': 0.6852692178617716, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(13)} -> 0.7280
2025-09-29 12:58:51,910 - INFO - bo.run_bo - ðŸ”BO Trial 5: Using RF surrogate + Expected Improvement
2025-09-29 12:58:51,910 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 12:58:51,910 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 12:58:51,910 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:58:51,910 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004114396905371647, 'batch_size': 128, 'epochs': 19, 'weight_decay': 2.7394033519098686e-05, 'dropout': 0.2691931281833186, 'stem_channels': 28, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 26, 'num_heads': 4, 'num_layers': 2, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.026317122857012147, 'grad_clip': 0.8667014663244306, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 15}
2025-09-29 12:58:51,912 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004114396905371647, 'batch_size': 128, 'epochs': 19, 'weight_decay': 2.7394033519098686e-05, 'dropout': 0.2691931281833186, 'stem_channels': 28, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 26, 'num_heads': 4, 'num_layers': 2, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.026317122857012147, 'grad_clip': 0.8667014663244306, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 15}
2025-09-29 12:59:20,651 - INFO - _models.training_function_executor - Model: 30,095 parameters, 129.3KB storage
2025-09-29 12:59:20,652 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2187168271541595, 0.958499594449997, 0.8901836414337159, 0.8581137609481811, 0.8291011095046997, 0.8081241688728332, 0.789693149805069, 0.7646547150611878, 0.7496328701972962, 0.7310971871614457, 0.718260528922081, 0.7138575830459595, 0.7018677216768264, 0.6883867834806442, 0.687293558716774, 0.6724433101415634, 0.6638046195507049, 0.6553955851793289, 0.6466352763175964], 'val_losses': [1.0039432767837766, 0.9432490515330482, 0.8946823704810369, 0.870498017659263, 0.8594729266469441, 0.8517906684724111, 0.8306309647030301, 0.8414983276336913, 0.8036248466325184, 0.8531047172016568, 0.8005314545025901, 0.7952347927623324, 0.8039168072125268, 0.8190454197308373, 0.7592277545777578, 0.7682361782543243, 0.774249255657196, 0.7667470914976937, 0.7626698050234053], 'val_acc': [0.6897631883621216, 0.7992732524871826, 0.7735872864723206, 0.8099235892295837, 0.8064152598381042, 0.8247087001800537, 0.8203232884407043, 0.822954535484314, 0.8457586765289307, 0.8204485774040222, 0.8670592904090881, 0.8535271286964417, 0.8709434866905212, 0.7952637672424316, 0.874953031539917, 0.8643026947975159, 0.8779601454734802, 0.9283297657966614, 0.8906152248382568], 'val_macro_f1': [0.5659620821475982, 0.623370373249054, 0.642418384552002, 0.6486151903867722, 0.6574789881706238, 0.6756997913122177, 0.6813154369592667, 0.6484237730503082, 0.6772973656654357, 0.6916568517684937, 0.7166146874427796, 0.7046829879283905, 0.7207226991653443, 0.6460488498210907, 0.7176396310329437, 0.7048113584518433, 0.7137596547603607, 0.7870634377002717, 0.7383447825908661], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004114396905371647, 'batch_size': 128, 'epochs': 19, 'weight_decay': 2.7394033519098686e-05, 'dropout': 0.2691931281833186, 'stem_channels': 28, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 26, 'num_heads': 4, 'num_layers': 2, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.026317122857012147, 'grad_clip': 0.8667014663244306, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 15}, 'model_parameter_count': 30095, 'model_storage_size_kb': 129.314453125, 'model_size_validation': 'PASS'}
2025-09-29 12:59:20,652 - INFO - _models.training_function_executor - BO Objective: base=0.8906, size_penalty=0.0000, final=0.8906
2025-09-29 12:59:20,652 - INFO - _models.training_function_executor - Model: 30,095 parameters, 129.3KB (PASS 256KB limit)
2025-09-29 12:59:20,652 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 28.741s
2025-09-29 12:59:20,739 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8906
2025-09-29 12:59:20,739 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.087s
2025-09-29 12:59:20,739 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 0.004114396905371647, 'batch_size': np.int64(128), 'epochs': np.int64(19), 'weight_decay': 2.7394033519098686e-05, 'dropout': 0.2691931281833186, 'stem_channels': np.int64(28), 'embed_channels': np.int64(32), 'se_reduction': np.int64(8), 'd_model': np.int64(26), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(20), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.026317122857012147, 'grad_clip': 0.8667014663244306, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(15)}, value=0.8906
2025-09-29 12:59:20,739 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 0.004114396905371647, 'batch_size': np.int64(128), 'epochs': np.int64(19), 'weight_decay': 2.7394033519098686e-05, 'dropout': 0.2691931281833186, 'stem_channels': np.int64(28), 'embed_channels': np.int64(32), 'se_reduction': np.int64(8), 'd_model': np.int64(26), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(20), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.026317122857012147, 'grad_clip': 0.8667014663244306, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(15)} -> 0.8906
2025-09-29 12:59:20,739 - INFO - bo.run_bo - ðŸ”BO Trial 6: Using RF surrogate + Expected Improvement
2025-09-29 12:59:20,739 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 12:59:20,739 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 12:59:20,739 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:59:20,740 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001525284724709613, 'batch_size': 512, 'epochs': 37, 'weight_decay': 0.0003707774145451266, 'dropout': 0.20114806367636723, 'stem_channels': 29, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 46, 'num_heads': 2, 'num_layers': 1, 'patch_size': 125, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.004758663833694899, 'grad_clip': 0.19435695121154645, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 17}
2025-09-29 12:59:20,741 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001525284724709613, 'batch_size': 512, 'epochs': 37, 'weight_decay': 0.0003707774145451266, 'dropout': 0.20114806367636723, 'stem_channels': 29, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 46, 'num_heads': 2, 'num_layers': 1, 'patch_size': 125, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.004758663833694899, 'grad_clip': 0.19435695121154645, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 17}
2025-09-29 12:59:56,291 - INFO - _models.training_function_executor - Model: 256,920 parameters, 276.0KB storage
2025-09-29 12:59:56,291 - WARNING - _models.training_function_executor - Model storage 276.0KB exceeds 256KB limit!
2025-09-29 12:59:56,291 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5238565925567868, 1.11064085411647, 0.9055097689704289, 0.7975431586068774, 0.7139281280457027, 0.6376804108657534, 0.5807490944862366, 0.5293773696536109, 0.5093401504887475, 0.4741714364952511, 0.43231061148265054, 0.40398055362322977, 0.3914158013131883, 0.36624649450892494, 0.3398683520536574, 0.322915708971402, 0.31162049160117195, 0.29309118740142337, 0.28014668207319954, 0.2641308130252929, 0.2594394175306199, 0.24818884403932662, 0.24669398745847126, 0.23294449562118166, 0.23141609865521628, 0.22764467175990816, 0.22312791716484798, 0.2110860234215146, 0.20047515275932493, 0.19916514366392105, 0.19503598908583322, 0.19373049078479646, 0.18928650447300502, 0.1809910372609184, 0.17899174751743438, 0.17536456646427276, 0.16778448389636147], 'val_losses': [1.307528130710125, 0.9929763935506344, 0.8294550478458405, 0.7769039496779442, 0.7020235545933247, 0.6672527194023132, 0.6664402484893799, 0.621803306043148, 0.6163569781929255, 0.581072149798274, 0.6670334674417973, 0.5879625491797924, 0.557583175599575, 0.7038682289421558, 0.5617374442517757, 0.5715695507824421, 0.5446213465183973, 0.5259537920355797, 0.6186264995485544, 0.5534487888216972, 0.6873152032494545, 0.6226473692804575, 0.5918767340481281, 0.6043238639831543, 0.5899220816791058, 0.6437475271522999, 0.660425927489996, 0.6244082842022181, 0.6380517967045307, 0.6449506916105747, 0.6563262790441513, 0.6758369188755751, 0.6214206926524639, 0.7357905153185129, 0.6901353821158409, 0.7719486188143492, 0.7180709317326546], 'val_acc': [0.24796392023563385, 0.4534519612789154, 0.6695902943611145, 0.7140709161758423, 0.710312008857727, 0.7747149467468262, 0.7474000453948975, 0.8351083993911743, 0.7316125631332397, 0.848640501499176, 0.7645658254623413, 0.8308482766151428, 0.8472622632980347, 0.8918681740760803, 0.8755794763565063, 0.8872321844100952, 0.8648039102554321, 0.8772083520889282, 0.9042726755142212, 0.8927452564239502, 0.9200601577758789, 0.9131687879562378, 0.9050244092941284, 0.9205613136291504, 0.9149229526519775, 0.9012655019760132, 0.9011402130126953, 0.9288309812545776, 0.9190577864646912, 0.9122917056083679, 0.9112893342971802, 0.9201854467391968, 0.9258238077163696, 0.9377270936965942, 0.9305851459503174, 0.9304598569869995, 0.9368500113487244], 'val_macro_f1': [0.2548134535551071, 0.3926247537136078, 0.5213333994150162, 0.5610732764005661, 0.5545567810535431, 0.6060222923755646, 0.592067974805832, 0.6658771991729736, 0.586941933631897, 0.6841493546962738, 0.6299966454505921, 0.6671104848384857, 0.6805871367454529, 0.7407083153724671, 0.7121179103851318, 0.7236207664012909, 0.696774697303772, 0.7143243074417114, 0.7530204117298126, 0.7347336351871491, 0.7814156532287597, 0.774333256483078, 0.7471753299236298, 0.7692701339721679, 0.7648096442222595, 0.7475820064544678, 0.7482103407382965, 0.7868525624275208, 0.7782692074775696, 0.7696533560752868, 0.7589639663696289, 0.773024833202362, 0.776255977153778, 0.7997086882591248, 0.7859913468360901, 0.7822974443435669, 0.7934454202651977], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001525284724709613, 'batch_size': 512, 'epochs': 37, 'weight_decay': 0.0003707774145451266, 'dropout': 0.20114806367636723, 'stem_channels': 29, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 46, 'num_heads': 2, 'num_layers': 1, 'patch_size': 125, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.004758663833694899, 'grad_clip': 0.19435695121154645, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 17}, 'model_parameter_count': 256920, 'model_storage_size_kb': 275.98828125, 'model_size_validation': 'FAIL'}
2025-09-29 12:59:56,291 - INFO - _models.training_function_executor - BO Objective: base=0.9369, size_penalty=0.0390, final=0.8978
2025-09-29 12:59:56,291 - INFO - _models.training_function_executor - Model: 256,920 parameters, 276.0KB (FAIL 256KB limit)
2025-09-29 12:59:56,291 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 35.551s
2025-09-29 12:59:56,377 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8978
2025-09-29 12:59:56,377 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.087s
2025-09-29 12:59:56,378 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.001525284724709613, 'batch_size': np.int64(512), 'epochs': np.int64(37), 'weight_decay': 0.0003707774145451266, 'dropout': 0.20114806367636723, 'stem_channels': np.int64(29), 'embed_channels': np.int64(44), 'se_reduction': np.int64(2), 'd_model': np.int64(46), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(125), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.004758663833694899, 'grad_clip': 0.19435695121154645, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(17)}, value=0.8978
2025-09-29 12:59:56,378 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.001525284724709613, 'batch_size': np.int64(512), 'epochs': np.int64(37), 'weight_decay': 0.0003707774145451266, 'dropout': 0.20114806367636723, 'stem_channels': np.int64(29), 'embed_channels': np.int64(44), 'se_reduction': np.int64(2), 'd_model': np.int64(46), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(125), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.004758663833694899, 'grad_clip': 0.19435695121154645, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(17)} -> 0.8978
2025-09-29 12:59:56,378 - INFO - bo.run_bo - ðŸ”BO Trial 7: Using RF surrogate + Expected Improvement
2025-09-29 12:59:56,378 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 12:59:56,378 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 12:59:56,378 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 12:59:56,378 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0015747679021134676, 'batch_size': 128, 'epochs': 25, 'weight_decay': 0.00483905539473624, 'dropout': 0.21700260527193338, 'stem_channels': 28, 'embed_channels': 35, 'se_reduction': 4, 'd_model': 61, 'num_heads': 4, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.03274827181605465, 'grad_clip': 0.887958072223406, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}
2025-09-29 12:59:56,379 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0015747679021134676, 'batch_size': 128, 'epochs': 25, 'weight_decay': 0.00483905539473624, 'dropout': 0.21700260527193338, 'stem_channels': 28, 'embed_channels': 35, 'se_reduction': 4, 'd_model': 61, 'num_heads': 4, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.03274827181605465, 'grad_clip': 0.887958072223406, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}
2025-09-29 13:00:29,437 - INFO - _models.training_function_executor - Model: 45,082 parameters, 48.4KB storage
2025-09-29 13:00:29,437 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.338646354198456, 1.0460534422397614, 0.9811883039474487, 0.9326304368972779, 0.9112435464859009, 0.8862020065784454, 0.8683715319633484, 0.8534526197910309, 0.8244919555187226, 0.8185243999958038, 0.8007339870929718, 0.7892248376607894, 0.7784997165203095, 0.7650322303771973, 0.7487600252628327, 0.741463565826416, 0.7326484144926071, 0.722850499033928, 0.7218248934745789, 0.7110269467830658, 0.7065480800867081, 0.6995783129930496, 0.6963043931722641, 0.6959571743011475, 0.6935337175130845], 'val_losses': [1.137508093364655, 1.1020332281551664, 0.9860000950949532, 0.9948176505073668, 0.9498781457779899, 0.9500580657096136, 0.9131013022528754, 0.9133124597488887, 0.8807765567113482, 0.8682338898144071, 0.8597260306751917, 0.8885664939880371, 0.8286928695345682, 0.841570844725957, 0.8354913914014422, 0.8255749070455157, 0.823644705235012, 0.8203947534636845, 0.8098548187149895, 0.8158256298019773, 0.810607786216433, 0.8138606292860848, 0.808752629492018, 0.8078927227428981, 0.8079252328191485], 'val_acc': [0.6372634768486023, 0.7309861183166504, 0.7054253816604614, 0.7050495147705078, 0.7317378520965576, 0.6342563629150391, 0.7608069181442261, 0.8012780547142029, 0.7876206040382385, 0.805162250995636, 0.7547926306724548, 0.7991479635238647, 0.8326024413108826, 0.7828592658042908, 0.8097983002662659, 0.8278411030769348, 0.8175666928291321, 0.843127429485321, 0.8534018397331238, 0.840120255947113, 0.8435032963752747, 0.8422503471374512, 0.8495175838470459, 0.8507705926895142, 0.8521488308906555], 'val_macro_f1': [0.5136646747589111, 0.5579179972410202, 0.5904563516378403, 0.6229715168476104, 0.6076787680387497, 0.5549976766109467, 0.6175264835357666, 0.6850977182388306, 0.6377113878726959, 0.647341001033783, 0.6203508019447327, 0.6448305368423461, 0.6766888320446014, 0.6375833243131638, 0.6563795745372772, 0.6690634846687317, 0.6634264588356018, 0.6842456579208374, 0.691557115316391, 0.6781083345413208, 0.6828621566295624, 0.6831474006175995, 0.6892816007137299, 0.6899840772151947, 0.6915232062339782], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0015747679021134676, 'batch_size': 128, 'epochs': 25, 'weight_decay': 0.00483905539473624, 'dropout': 0.21700260527193338, 'stem_channels': 28, 'embed_channels': 35, 'se_reduction': 4, 'd_model': 61, 'num_heads': 4, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.03274827181605465, 'grad_clip': 0.887958072223406, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}, 'model_parameter_count': 45082, 'model_storage_size_kb': 48.427929687500004, 'model_size_validation': 'PASS'}
2025-09-29 13:00:29,437 - INFO - _models.training_function_executor - BO Objective: base=0.8521, size_penalty=0.0000, final=0.8521
2025-09-29 13:00:29,437 - INFO - _models.training_function_executor - Model: 45,082 parameters, 48.4KB (PASS 256KB limit)
2025-09-29 13:00:29,437 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 33.059s
2025-09-29 13:00:29,524 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8521
2025-09-29 13:00:29,525 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.088s
2025-09-29 13:00:29,525 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 0.0015747679021134676, 'batch_size': np.int64(128), 'epochs': np.int64(25), 'weight_decay': 0.00483905539473624, 'dropout': 0.21700260527193338, 'stem_channels': np.int64(28), 'embed_channels': np.int64(35), 'se_reduction': np.int64(4), 'd_model': np.int64(61), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(20), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.03274827181605465, 'grad_clip': 0.887958072223406, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(11)}, value=0.8521
2025-09-29 13:00:29,525 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 0.0015747679021134676, 'batch_size': np.int64(128), 'epochs': np.int64(25), 'weight_decay': 0.00483905539473624, 'dropout': 0.21700260527193338, 'stem_channels': np.int64(28), 'embed_channels': np.int64(35), 'se_reduction': np.int64(4), 'd_model': np.int64(61), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(20), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.03274827181605465, 'grad_clip': 0.887958072223406, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(11)} -> 0.8521
2025-09-29 13:00:29,525 - INFO - bo.run_bo - ðŸ”BO Trial 8: Using RF surrogate + Expected Improvement
2025-09-29 13:00:29,525 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:00:29,525 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:00:29,525 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:00:29,525 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0009735305170052863, 'batch_size': 128, 'epochs': 35, 'weight_decay': 1.211501114111258e-06, 'dropout': 0.19917905667112973, 'stem_channels': 29, 'embed_channels': 45, 'se_reduction': 2, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07736252316235052, 'grad_clip': 0.9138324226542895, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 1}
2025-09-29 13:00:29,526 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0009735305170052863, 'batch_size': 128, 'epochs': 35, 'weight_decay': 1.211501114111258e-06, 'dropout': 0.19917905667112973, 'stem_channels': 29, 'embed_channels': 45, 'se_reduction': 2, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07736252316235052, 'grad_clip': 0.9138324226542895, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 1}
2025-09-29 13:01:13,477 - INFO - _models.training_function_executor - Model: 80,281 parameters, 86.2KB storage
2025-09-29 13:01:13,477 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7117821502685546, 1.464139786720276, 1.376227954864502, 1.3239351811408997, 1.2955097653865815, 1.270069287776947, 1.243768800497055, 1.2276703979969024, 1.208001944065094, 1.196307141304016, 1.186269965171814, 1.1677496347427367, 1.1554543874263763, 1.152204722881317, 1.1401927776336669, 1.1337801282405853, 1.128954797267914, 1.116311054468155, 1.105423766374588, 1.1039251782894135, 1.1023788921833038, 1.0936932790279388, 1.0903097779750823, 1.0822848143577575, 1.0864478013515473, 1.0799514775276184, 1.0758422043323517, 1.0701250455379485, 1.0742485773563386, 1.0564768507480622, 1.0560461242198944, 1.0542186744213105, 1.0532768852710723, 1.053641159772873, 1.0474209942817687], 'val_losses': [1.51069314328451, 1.4322814695418826, 1.4012390015617249, 1.3592140163694109, 1.3255079066942608, 1.2992365057506259, 1.3042503245293149, 1.3175003812426613, 1.3041967342770289, 1.280736015902625, 1.2761811680263944, 1.2756379312939115, 1.2659219493941656, 1.2721962086738101, 1.2821683675523787, 1.2576887238593328, 1.2742616818064736, 1.2891500563848586, 1.2659724969712516, 1.2719500386525715, 1.284806017837827, 1.2929815924356853, 1.2860950392390054, 1.2870440502015372, 1.295118030101534, 1.2761683322134472, 1.2746366934170799, 1.2787198556794062, 1.2951483773806738, 1.3143482227174064, 1.2802189966988942, 1.3129582755149356, 1.3044532036024428, 1.2981448542504084, 1.2921502798322648], 'val_acc': [0.4230046272277832, 0.5682245492935181, 0.603307843208313, 0.6634507179260254, 0.6687132120132446, 0.7666959166526794, 0.7560455799102783, 0.6743515729904175, 0.8326024413108826, 0.8615461587905884, 0.8511464595794678, 0.8730735778808594, 0.8507705926895142, 0.8650544881820679, 0.872697651386261, 0.8828467726707458, 0.8526500463485718, 0.8452574610710144, 0.8744518160820007, 0.8778348565101624, 0.8803408145904541, 0.8898634314537048, 0.9059014916419983, 0.911414623260498, 0.9089086651802063, 0.9265756011009216, 0.9193083643913269, 0.92695152759552, 0.896003007888794, 0.9256985187530518, 0.9165518283843994, 0.9305851459503174, 0.9126675724983215, 0.9188071489334106, 0.933216392993927], 'val_macro_f1': [0.41149700433015823, 0.5102004319429397, 0.5235091865062713, 0.5636695981025696, 0.5626125693321228, 0.6184213817119598, 0.6106272727251053, 0.5694856882095337, 0.667520159482956, 0.6957990765571594, 0.6917954027652741, 0.6960796296596528, 0.709746241569519, 0.7063262104988098, 0.6977761030197144, 0.7176803886890412, 0.6777058959007263, 0.7090640783309936, 0.7101504504680634, 0.7134380459785461, 0.7077258944511413, 0.7190035462379456, 0.7417199909687042, 0.747976815700531, 0.7415287017822265, 0.7850656747817993, 0.7589210271835327, 0.78163743019104, 0.7272058844566345, 0.7755744218826294, 0.771457064151764, 0.7829149067401886, 0.7587974488735199, 0.7671306371688843, 0.7962985873222351], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0009735305170052863, 'batch_size': 128, 'epochs': 35, 'weight_decay': 1.211501114111258e-06, 'dropout': 0.19917905667112973, 'stem_channels': 29, 'embed_channels': 45, 'se_reduction': 2, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07736252316235052, 'grad_clip': 0.9138324226542895, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 1}, 'model_parameter_count': 80281, 'model_storage_size_kb': 86.23935546875, 'model_size_validation': 'PASS'}
2025-09-29 13:01:13,477 - INFO - _models.training_function_executor - BO Objective: base=0.9332, size_penalty=0.0000, final=0.9332
2025-09-29 13:01:13,477 - INFO - _models.training_function_executor - Model: 80,281 parameters, 86.2KB (PASS 256KB limit)
2025-09-29 13:01:13,477 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 43.952s
2025-09-29 13:01:13,568 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9332
2025-09-29 13:01:13,568 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.091s
2025-09-29 13:01:13,568 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 0.0009735305170052863, 'batch_size': np.int64(128), 'epochs': np.int64(35), 'weight_decay': 1.211501114111258e-06, 'dropout': 0.19917905667112973, 'stem_channels': np.int64(29), 'embed_channels': np.int64(45), 'se_reduction': np.int64(2), 'd_model': np.int64(17), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07736252316235052, 'grad_clip': 0.9138324226542895, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(1)}, value=0.9332
2025-09-29 13:01:13,568 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 0.0009735305170052863, 'batch_size': np.int64(128), 'epochs': np.int64(35), 'weight_decay': 1.211501114111258e-06, 'dropout': 0.19917905667112973, 'stem_channels': np.int64(29), 'embed_channels': np.int64(45), 'se_reduction': np.int64(2), 'd_model': np.int64(17), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07736252316235052, 'grad_clip': 0.9138324226542895, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(1)} -> 0.9332
2025-09-29 13:01:13,568 - INFO - bo.run_bo - ðŸ”BO Trial 9: Using RF surrogate + Expected Improvement
2025-09-29 13:01:13,568 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:01:13,568 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:01:13,568 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:01:13,568 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00027129956571442476, 'batch_size': 64, 'epochs': 41, 'weight_decay': 0.0020620354974222425, 'dropout': 0.05138598342167423, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 20, 'num_heads': 2, 'num_layers': 1, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08957547427984913, 'grad_clip': 0.9683658308573806, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}
2025-09-29 13:01:13,570 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00027129956571442476, 'batch_size': 64, 'epochs': 41, 'weight_decay': 0.0020620354974222425, 'dropout': 0.05138598342167423, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 20, 'num_heads': 2, 'num_layers': 1, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08957547427984913, 'grad_clip': 0.9683658308573806, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}
2025-09-29 13:02:16,133 - INFO - _models.training_function_executor - Model: 41,489 parameters, 178.3KB storage
2025-09-29 13:02:16,133 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7952727197047943, 0.5702380596516367, 0.527987825607728, 0.5020178643639437, 0.48616366431803887, 0.47588774908281756, 0.4693642238337912, 0.4630071228754544, 0.458049794834458, 0.45433635696141655, 0.4493446884031047, 0.4459231322060128, 0.443101482484527, 0.4418324411273719, 0.4387857286867971, 0.43438748379269676, 0.4327119446708588, 0.43113953920308956, 0.42938407294019193, 0.4265627101332487, 0.42389279239641164, 0.4230417947253149, 0.4205749236749026, 0.41936363599343385, 0.4163753745073307, 0.41554905256193003, 0.41376228251294767, 0.4123721490642112, 0.4115238749312017, 0.4085928814444609, 0.40758795585326535, 0.40696231832724056, 0.4054844395550554, 0.40378834125035273, 0.40278358252827295, 0.4012251628305248, 0.39963713073300455, 0.3987108752698841, 0.39728743333615857, 0.3964700096833682, 0.39563241224728507], 'val_losses': [0.6370445308685303, 0.563761034488678, 0.5171693046092987, 0.5029107444286346, 0.4919340159893036, 0.48917769122123717, 0.4815074133872986, 0.48421501994133, 0.4759874670505524, 0.4776214573383331, 0.46967927980422974, 0.4729878735542297, 0.47499722242355347, 0.46921294236183164, 0.4706340382099152, 0.4668372416496277, 0.4701520483493805, 0.471115275144577, 0.4698699676990509, 0.4756380743980408, 0.4705055062770844, 0.4714924051761627, 0.4678046178817749, 0.47304018640518186, 0.4736130509376526, 0.4762017743587494, 0.4729803690910339, 0.47329499149322507, 0.4753282573223114, 0.4759116225242615, 0.4830564739704132, 0.4786794230937958, 0.4772520580291748, 0.49497965002059935, 0.49204613304138184, 0.4816386649608612, 0.4934188232421875, 0.4907443449497223, 0.484678959608078, 0.4890226838588715, 0.4888104212284088], 'val_acc': [0.881217896938324, 0.9152988195419312, 0.933216392993927, 0.9373512268066406, 0.9447437524795532, 0.9466232061386108, 0.9476256370544434, 0.948753297328949, 0.9518857002258301, 0.9503821730613708, 0.9548928737640381, 0.9530134201049805, 0.9505074620246887, 0.9551434516906738, 0.9530134201049805, 0.9553940892219543, 0.9541410803794861, 0.954266369342804, 0.9546422958374023, 0.9523869156837463, 0.9552687406539917, 0.9545170068740845, 0.9552687406539917, 0.9571482539176941, 0.9560205340385437, 0.955769956111908, 0.9555193781852722, 0.957273542881012, 0.9576494097709656, 0.9561458230018616, 0.9555193781852722, 0.955769956111908, 0.9575241208076477, 0.9486280083656311, 0.9501315355300903, 0.9555193781852722, 0.9490038752555847, 0.9526374936103821, 0.953514575958252, 0.9527627825737, 0.9518857002258301], 'val_macro_f1': [0.611955440044403, 0.6580212593078614, 0.684686329588294, 0.7352200806140899, 0.7506949126720428, 0.7824359178543091, 0.7896293342113495, 0.7861606359481812, 0.8113747715950013, 0.8003247082233429, 0.8064913034439087, 0.8149552822113038, 0.8086694121360779, 0.8053671598434449, 0.8117671728134155, 0.8253561615943908, 0.8205249428749084, 0.8173973560333252, 0.822818398475647, 0.8138524651527405, 0.8171028852462768, 0.8236652135848999, 0.8072116851806641, 0.8183224201202393, 0.8169846892356872, 0.812349283695221, 0.8205720067024231, 0.8088233828544616, 0.8155507683753968, 0.8108223795890808, 0.8126768946647644, 0.8305517911911011, 0.83116375207901, 0.808477246761322, 0.8100207805633545, 0.8095832228660583, 0.8022539615631104, 0.8047486543655396, 0.8170656204223633, 0.803071391582489, 0.8025483012199401], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00027129956571442476, 'batch_size': 64, 'epochs': 41, 'weight_decay': 0.0020620354974222425, 'dropout': 0.05138598342167423, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 20, 'num_heads': 2, 'num_layers': 1, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08957547427984913, 'grad_clip': 0.9683658308573806, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}, 'model_parameter_count': 41489, 'model_storage_size_kb': 178.273046875, 'model_size_validation': 'PASS'}
2025-09-29 13:02:16,133 - INFO - _models.training_function_executor - BO Objective: base=0.9519, size_penalty=0.0000, final=0.9519
2025-09-29 13:02:16,133 - INFO - _models.training_function_executor - Model: 41,489 parameters, 178.3KB (PASS 256KB limit)
2025-09-29 13:02:16,133 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 62.565s
2025-09-29 13:02:16,225 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9519
2025-09-29 13:02:16,225 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.092s
2025-09-29 13:02:16,225 - INFO - bo.run_bo - Recorded observation #9: hparams={'lr': 0.00027129956571442476, 'batch_size': np.int64(64), 'epochs': np.int64(41), 'weight_decay': 0.0020620354974222425, 'dropout': 0.05138598342167423, 'stem_channels': np.int64(29), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(20), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(40), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08957547427984913, 'grad_clip': 0.9683658308573806, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(11)}, value=0.9519
2025-09-29 13:02:16,225 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'lr': 0.00027129956571442476, 'batch_size': np.int64(64), 'epochs': np.int64(41), 'weight_decay': 0.0020620354974222425, 'dropout': 0.05138598342167423, 'stem_channels': np.int64(29), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(20), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(40), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08957547427984913, 'grad_clip': 0.9683658308573806, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(11)} -> 0.9519
2025-09-29 13:02:16,226 - INFO - bo.run_bo - ðŸ”BO Trial 10: Using RF surrogate + Expected Improvement
2025-09-29 13:02:16,226 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:02:16,226 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:02:16,226 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:02:16,226 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0002962847821812754, 'batch_size': 256, 'epochs': 21, 'weight_decay': 5.312896886170548e-05, 'dropout': 0.04705187656390543, 'stem_channels': 30, 'embed_channels': 40, 'se_reduction': 2, 'd_model': 35, 'num_heads': 4, 'num_layers': 1, 'patch_size': 50, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.012461542960095731, 'grad_clip': 0.727044076002421, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 19}
2025-09-29 13:02:16,227 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0002962847821812754, 'batch_size': 256, 'epochs': 21, 'weight_decay': 5.312896886170548e-05, 'dropout': 0.04705187656390543, 'stem_channels': 30, 'embed_channels': 40, 'se_reduction': 2, 'd_model': 35, 'num_heads': 4, 'num_layers': 1, 'patch_size': 50, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.012461542960095731, 'grad_clip': 0.727044076002421, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 19}
2025-09-29 13:02:38,379 - INFO - _models.training_function_executor - Model: 83,663 parameters, 359.5KB storage
2025-09-29 13:02:38,380 - WARNING - _models.training_function_executor - Model storage 359.5KB exceeds 256KB limit!
2025-09-29 13:02:38,380 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4120992031097412, 1.0899748253822326, 0.9176075615882874, 0.8181919937133789, 0.7645361318588256, 0.7063900418281556, 0.671877026796341, 0.6375887818336486, 0.6156147983074188, 0.593525225162506, 0.5765155727863311, 0.5593811669349671, 0.5458769733905793, 0.5327456576824188, 0.5187805531024933, 0.5079325020313263, 0.4990824348926544, 0.4835416989326477, 0.47784566807746887, 0.46192168760299684, 0.4555501418113708], 'val_losses': [1.1866358369588852, 0.9503695629537106, 0.8402239233255386, 0.8029220849275589, 0.7408905103802681, 0.7133612688630819, 0.7038589864969254, 0.6729498915374279, 0.6740115629509091, 0.6835847534239292, 0.6477603586390615, 0.6730413231998682, 0.6776160979643464, 0.6584212435409427, 0.6238724226132035, 0.6192479794844985, 0.625164931640029, 0.64708321262151, 0.604641055688262, 0.6022494146600366, 0.6244746567681432], 'val_acc': [0.5263751149177551, 0.6408971548080444, 0.6860042810440063, 0.7522866725921631, 0.7079313397407532, 0.7575491666793823, 0.7504072189331055, 0.8145595788955688, 0.8160631656646729, 0.7897506356239319, 0.784864068031311, 0.812930703163147, 0.7951384782791138, 0.8689387440681458, 0.8230798244476318, 0.8085452914237976, 0.7977697253227234, 0.8599172830581665, 0.8483899235725403, 0.8646786212921143, 0.881969690322876], 'val_macro_f1': [0.3709261864423752, 0.4990076184272766, 0.5457488536834717, 0.5710549354553223, 0.5757207214832306, 0.6108816027641296, 0.6033688902854919, 0.6422189056873322, 0.640756094455719, 0.6289270222187042, 0.6214316487312317, 0.638527375459671, 0.6344574451446533, 0.6924997329711914, 0.6716148316860199, 0.6550976902246475, 0.6480534881353378, 0.6843106389045716, 0.6782492280006409, 0.6961366951465606, 0.7245613515377045], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0002962847821812754, 'batch_size': 256, 'epochs': 21, 'weight_decay': 5.312896886170548e-05, 'dropout': 0.04705187656390543, 'stem_channels': 30, 'embed_channels': 40, 'se_reduction': 2, 'd_model': 35, 'num_heads': 4, 'num_layers': 1, 'patch_size': 50, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.012461542960095731, 'grad_clip': 0.727044076002421, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 19}, 'model_parameter_count': 83663, 'model_storage_size_kb': 359.489453125, 'model_size_validation': 'FAIL'}
2025-09-29 13:02:38,380 - INFO - _models.training_function_executor - BO Objective: base=0.8820, size_penalty=0.2021, final=0.6798
2025-09-29 13:02:38,380 - INFO - _models.training_function_executor - Model: 83,663 parameters, 359.5KB (FAIL 256KB limit)
2025-09-29 13:02:38,380 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 22.154s
2025-09-29 13:02:38,476 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6798
2025-09-29 13:02:38,476 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.096s
2025-09-29 13:02:38,476 - INFO - bo.run_bo - Recorded observation #10: hparams={'lr': 0.0002962847821812754, 'batch_size': np.int64(256), 'epochs': np.int64(21), 'weight_decay': 5.312896886170548e-05, 'dropout': 0.04705187656390543, 'stem_channels': np.int64(30), 'embed_channels': np.int64(40), 'se_reduction': np.int64(2), 'd_model': np.int64(35), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(50), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.012461542960095731, 'grad_clip': 0.727044076002421, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(19)}, value=0.6798
2025-09-29 13:02:38,476 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'lr': 0.0002962847821812754, 'batch_size': np.int64(256), 'epochs': np.int64(21), 'weight_decay': 5.312896886170548e-05, 'dropout': 0.04705187656390543, 'stem_channels': np.int64(30), 'embed_channels': np.int64(40), 'se_reduction': np.int64(2), 'd_model': np.int64(35), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(50), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.012461542960095731, 'grad_clip': 0.727044076002421, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(19)} -> 0.6798
2025-09-29 13:02:38,476 - INFO - bo.run_bo - ðŸ”BO Trial 11: Using RF surrogate + Expected Improvement
2025-09-29 13:02:38,476 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:02:38,477 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:02:38,477 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:02:38,477 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0015929297094468453, 'batch_size': 512, 'epochs': 34, 'weight_decay': 0.0003133210652195563, 'dropout': 0.33136238573111804, 'stem_channels': 22, 'embed_channels': 44, 'se_reduction': 4, 'd_model': 21, 'num_heads': 2, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.024734943675345792, 'grad_clip': 0.9066668505226394, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 17}
2025-09-29 13:02:38,478 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0015929297094468453, 'batch_size': 512, 'epochs': 34, 'weight_decay': 0.0003133210652195563, 'dropout': 0.33136238573111804, 'stem_channels': 22, 'embed_channels': 44, 'se_reduction': 4, 'd_model': 21, 'num_heads': 2, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.024734943675345792, 'grad_clip': 0.9066668505226394, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 17}
2025-09-29 13:03:13,837 - INFO - _models.training_function_executor - Model: 468,160 parameters, 2011.6KB storage
2025-09-29 13:03:13,837 - WARNING - _models.training_function_executor - Model storage 2011.6KB exceeds 256KB limit!
2025-09-29 13:03:13,837 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9557894260164291, 0.7736930714713203, 0.5904255022132208, 0.49474198714135187, 0.4376404384771983, 0.3916590303655655, 0.3512366589099642, 0.3360621739947607, 0.3137847823756082, 0.299584584576743, 0.28865891221969847, 0.27977803869852946, 0.26558410766578855, 0.25558474849140833, 0.2471150907259139, 0.24101260257145715, 0.23433844035580045, 0.2264279593077917, 0.22002185550000933, 0.21336962306310261, 0.20734082801001413, 0.20043629668061697, 0.1986665011398376, 0.193754491588426, 0.18989318065227023, 0.18509171146249015, 0.18284979864718423, 0.18130058215724099, 0.17901410328017342, 0.176715777506904, 0.17423154390047466, 0.1722404725021786, 0.17037421701446412, 0.1684247153618979], 'val_losses': [0.8368242681026459, 0.6484106183052063, 0.5059001035988331, 0.45324702374637127, 0.39746724627912045, 0.38233274035155773, 0.37297063134610653, 0.35628181137144566, 0.36136570014059544, 0.34522008523344994, 0.3286927081644535, 0.33280655555427074, 0.33999435417354107, 0.3323272243142128, 0.3434364851564169, 0.3367860149592161, 0.331899905577302, 0.32182746566832066, 0.3328824955970049, 0.3288587313145399, 0.3245519269257784, 0.3322124741971493, 0.3339997064322233, 0.336170706897974, 0.3319264966994524, 0.3248261883854866, 0.3475815672427416, 0.3405586779117584, 0.33603106811642647, 0.3392524402588606, 0.3465499598532915, 0.3393101245164871, 0.3332080915570259, 0.344254482537508], 'val_acc': [0.7337426543235779, 0.8019044995307922, 0.8665580749511719, 0.8864803910255432, 0.9045232534408569, 0.9104122519493103, 0.9166771173477173, 0.927703320980072, 0.9226914048194885, 0.9300839304924011, 0.9340934753417969, 0.9363488554954529, 0.9320887327194214, 0.9371005892753601, 0.9342187643051147, 0.9313369393348694, 0.9373512268066406, 0.9437413811683655, 0.9398571848869324, 0.9408595561981201, 0.9426137208938599, 0.940984845161438, 0.9418619275093079, 0.940233051776886, 0.9429895877838135, 0.9459967613220215, 0.9426137208938599, 0.942488431930542, 0.9449943900108337, 0.9434908032417297, 0.9448690414428711, 0.9446184635162354, 0.9466232061386108, 0.9449943900108337], 'val_macro_f1': [0.25563217997550963, 0.4258631706237793, 0.4925556302070618, 0.5644500263035297, 0.6605897396802902, 0.6481914460659027, 0.6419639542698861, 0.7157428205013275, 0.6868925541639328, 0.7115589350461959, 0.7237682700157165, 0.7301222652196884, 0.7366464972496033, 0.75023912191391, 0.7489551603794098, 0.7396779775619506, 0.7594958484172821, 0.7720971286296845, 0.7650878190994262, 0.7692525207996368, 0.7812960267066955, 0.781977504491806, 0.7527119517326355, 0.7653768301010132, 0.7698875844478608, 0.7791596174240112, 0.7649200439453125, 0.7692913234233856, 0.7667480885982514, 0.7550920963287353, 0.7592658579349518, 0.7803106427192688, 0.7745525240898132, 0.7651763260364532], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0015929297094468453, 'batch_size': 512, 'epochs': 34, 'weight_decay': 0.0003133210652195563, 'dropout': 0.33136238573111804, 'stem_channels': 22, 'embed_channels': 44, 'se_reduction': 4, 'd_model': 21, 'num_heads': 2, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.024734943675345792, 'grad_clip': 0.9066668505226394, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 17}, 'model_parameter_count': 468160, 'model_storage_size_kb': 2011.6250000000002, 'model_size_validation': 'FAIL'}
2025-09-29 13:03:13,838 - INFO - _models.training_function_executor - BO Objective: base=0.9450, size_penalty=0.8000, final=0.1450
2025-09-29 13:03:13,838 - INFO - _models.training_function_executor - Model: 468,160 parameters, 2011.6KB (FAIL 256KB limit)
2025-09-29 13:03:13,838 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 35.361s
2025-09-29 13:03:13,935 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1450
2025-09-29 13:03:13,935 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-09-29 13:03:13,935 - INFO - bo.run_bo - Recorded observation #11: hparams={'lr': 0.0015929297094468453, 'batch_size': np.int64(512), 'epochs': np.int64(34), 'weight_decay': 0.0003133210652195563, 'dropout': 0.33136238573111804, 'stem_channels': np.int64(22), 'embed_channels': np.int64(44), 'se_reduction': np.int64(4), 'd_model': np.int64(21), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(500), 'class_weighting': np.str_('none'), 'label_smoothing': 0.024734943675345792, 'grad_clip': 0.9066668505226394, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(17)}, value=0.1450
2025-09-29 13:03:13,935 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 11: {'lr': 0.0015929297094468453, 'batch_size': np.int64(512), 'epochs': np.int64(34), 'weight_decay': 0.0003133210652195563, 'dropout': 0.33136238573111804, 'stem_channels': np.int64(22), 'embed_channels': np.int64(44), 'se_reduction': np.int64(4), 'd_model': np.int64(21), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(500), 'class_weighting': np.str_('none'), 'label_smoothing': 0.024734943675345792, 'grad_clip': 0.9066668505226394, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(17)} -> 0.1450
2025-09-29 13:03:13,936 - INFO - bo.run_bo - ðŸ”BO Trial 12: Using RF surrogate + Expected Improvement
2025-09-29 13:03:13,936 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:03:13,936 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:03:13,936 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:03:13,936 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0009795855677013886, 'batch_size': 512, 'epochs': 48, 'weight_decay': 1.5437162245948655e-05, 'dropout': 0.12851197691732816, 'stem_channels': 28, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 19, 'num_heads': 2, 'num_layers': 1, 'patch_size': 25, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.04360703539402519, 'grad_clip': 0.8828160570050244, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}
2025-09-29 13:03:13,937 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0009795855677013886, 'batch_size': 512, 'epochs': 48, 'weight_decay': 1.5437162245948655e-05, 'dropout': 0.12851197691732816, 'stem_channels': 28, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 19, 'num_heads': 2, 'num_layers': 1, 'patch_size': 25, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.04360703539402519, 'grad_clip': 0.8828160570050244, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}
2025-09-29 13:04:02,900 - INFO - _models.training_function_executor - Model: 27,749 parameters, 59.6KB storage
2025-09-29 13:04:02,900 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.602289082512023, 1.3318640031511821, 1.2253326319512867, 1.143065091163393, 1.0771363131583682, 1.0362269585094754, 1.010132923012688, 0.9910905399019756, 0.9696054032870701, 0.9650598764419556, 0.9518966618038359, 0.9412690665986803, 0.9277572385848515, 0.9161243996922932, 0.9098026033431764, 0.900508047096313, 0.9025478675251916, 0.8840546097074237, 0.8846972736101302, 0.8781013791523282, 0.8631460855877588, 0.8598855866326226, 0.8545878936373998, 0.8525442149904039, 0.8461607174267844, 0.8439153186858647, 0.8454453178814479, 0.8342020331867157, 0.8317721107649425, 0.8280188791335575, 0.8240517585996597, 0.8166245742449685, 0.8105667299694486, 0.8108331144802154, 0.8102463398660932, 0.8038302716754732, 0.8044276426708887, 0.8020792357505314, 0.7982072319303241, 0.7932932443088956, 0.789598768665677, 0.7912405691449604, 0.7850712887824528, 0.7833466217631385, 0.7796289873501611, 0.7771855895481412, 0.7713752511947874, 0.7714406838492741], 'val_losses': [1.4290568605065346, 1.2564745023846626, 1.1705759689211845, 1.1063463874161243, 1.0685362629592419, 1.0478999726474285, 1.0283905565738678, 0.9887764938175678, 1.0015035904943943, 0.9875586330890656, 0.9631345495581627, 1.0057132802903652, 0.951150368899107, 0.9583904556930065, 0.9399121701717377, 0.9328150376677513, 0.9343735091388226, 0.9264383055269718, 0.9427182339131832, 0.9334102384746075, 0.9190617613494396, 0.9345003180205822, 0.9110082276165485, 0.9364967122673988, 0.9109066836535931, 0.9390060976147652, 0.9087223783135414, 0.9000323936343193, 0.9203702546656132, 0.9237745441496372, 0.9215287268161774, 0.9005436860024929, 0.9197431020438671, 0.9317445792257786, 0.9038286805152893, 0.9082768708467484, 0.9214642494916916, 0.9176525808870792, 0.908666118979454, 0.9376019462943077, 0.9237920641899109, 0.91414849832654, 0.8959152698516846, 0.9154631160199642, 0.9134273566305637, 0.8952952809631824, 0.9128924943506718, 0.9176912344992161], 'val_acc': [0.4044605791568756, 0.5757423639297485, 0.6510462164878845, 0.7681995034217834, 0.7495301365852356, 0.7456458806991577, 0.7457712292671204, 0.7690765857696533, 0.7471494674682617, 0.7779726982116699, 0.7946372628211975, 0.8341060280799866, 0.7693271636962891, 0.833103597164154, 0.8289688229560852, 0.843127429485321, 0.8165643215179443, 0.7421375513076782, 0.7452700138092041, 0.8161884546279907, 0.8536524176597595, 0.8576619625091553, 0.859416127204895, 0.8654304146766663, 0.7487783432006836, 0.7937601804733276, 0.8498935103416443, 0.8368625640869141, 0.8645533323287964, 0.8366119265556335, 0.870442271232605, 0.8619220852851868, 0.8691893219947815, 0.8688134551048279, 0.8505200147628784, 0.867184579372406, 0.8530259132385254, 0.8763312697410583, 0.8430021405220032, 0.912918210029602, 0.8794637322425842, 0.8322265148162842, 0.8825961947441101, 0.9040220379829407, 0.8792131543159485, 0.874953031539917, 0.907655656337738, 0.881969690322876], 'val_macro_f1': [0.3512304499745369, 0.46440582275390624, 0.5318353652954102, 0.6015604794025421, 0.5956837832927704, 0.6043716669082642, 0.6151088118553162, 0.6154514074325561, 0.6140416473150253, 0.6198946952819824, 0.635906982421875, 0.649396151304245, 0.6221404314041138, 0.6611782133579254, 0.6587435245513916, 0.6712959051132202, 0.6576972544193268, 0.6101284474134445, 0.6143421083688736, 0.6537911236286164, 0.6857485830783844, 0.6937458157539368, 0.6925513029098511, 0.69526988863945, 0.6217114210128785, 0.6459308445453644, 0.6813124418258667, 0.6737044513225555, 0.6948617398738861, 0.6677525877952576, 0.6982726156711578, 0.6969588100910187, 0.6991323530673981, 0.6955523192882538, 0.6878081023693084, 0.6989527106285095, 0.6844522774219512, 0.707659912109375, 0.6799693167209625, 0.7522647500038147, 0.7150771200656891, 0.665409243106842, 0.7191747903823853, 0.7387343347072601, 0.7135298430919648, 0.7133586347103119, 0.7488462030887604, 0.7168644309043884], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0009795855677013886, 'batch_size': 512, 'epochs': 48, 'weight_decay': 1.5437162245948655e-05, 'dropout': 0.12851197691732816, 'stem_channels': 28, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 19, 'num_heads': 2, 'num_layers': 1, 'patch_size': 25, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.04360703539402519, 'grad_clip': 0.8828160570050244, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}, 'model_parameter_count': 27749, 'model_storage_size_kb': 59.6169921875, 'model_size_validation': 'PASS'}
2025-09-29 13:04:02,900 - INFO - _models.training_function_executor - BO Objective: base=0.8820, size_penalty=0.0000, final=0.8820
2025-09-29 13:04:02,900 - INFO - _models.training_function_executor - Model: 27,749 parameters, 59.6KB (PASS 256KB limit)
2025-09-29 13:04:02,900 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 48.965s
2025-09-29 13:04:02,998 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8820
2025-09-29 13:04:02,999 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-09-29 13:04:02,999 - INFO - bo.run_bo - Recorded observation #12: hparams={'lr': 0.0009795855677013886, 'batch_size': np.int64(512), 'epochs': np.int64(48), 'weight_decay': 1.5437162245948655e-05, 'dropout': 0.12851197691732816, 'stem_channels': np.int64(28), 'embed_channels': np.int64(44), 'se_reduction': np.int64(2), 'd_model': np.int64(19), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(25), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.04360703539402519, 'grad_clip': 0.8828160570050244, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(16)}, value=0.8820
2025-09-29 13:04:02,999 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 12: {'lr': 0.0009795855677013886, 'batch_size': np.int64(512), 'epochs': np.int64(48), 'weight_decay': 1.5437162245948655e-05, 'dropout': 0.12851197691732816, 'stem_channels': np.int64(28), 'embed_channels': np.int64(44), 'se_reduction': np.int64(2), 'd_model': np.int64(19), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(25), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.04360703539402519, 'grad_clip': 0.8828160570050244, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(16)} -> 0.8820
2025-09-29 13:04:02,999 - INFO - bo.run_bo - ðŸ”BO Trial 13: Using RF surrogate + Expected Improvement
2025-09-29 13:04:02,999 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:04:02,999 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:04:02,999 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:04:02,999 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0008720178718620544, 'batch_size': 256, 'epochs': 40, 'weight_decay': 1.4214911411654497e-05, 'dropout': 0.04772469523689922, 'stem_channels': 16, 'embed_channels': 48, 'se_reduction': 4, 'd_model': 21, 'num_heads': 2, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09723559842072246, 'grad_clip': 0.9704804523630403, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 6}
2025-09-29 13:04:03,000 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0008720178718620544, 'batch_size': 256, 'epochs': 40, 'weight_decay': 1.4214911411654497e-05, 'dropout': 0.04772469523689922, 'stem_channels': 16, 'embed_channels': 48, 'se_reduction': 4, 'd_model': 21, 'num_heads': 2, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09723559842072246, 'grad_clip': 0.9704804523630403, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 6}
2025-09-29 13:04:47,865 - INFO - _models.training_function_executor - Model: 50,279 parameters, 216.0KB storage
2025-09-29 13:04:47,865 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [2.0189284009933472, 1.7714488468170166, 1.6474031677246095, 1.5616278009414672, 1.511856822013855, 1.480281497001648, 1.4463079109191894, 1.422495111465454, 1.4067725410461427, 1.3897745628356934, 1.3829277400970459, 1.3749369082450866, 1.360843430519104, 1.3607225933074951, 1.3480210542678832, 1.3411439304351807, 1.3398298721313477, 1.3288433227539063, 1.3254477672576905, 1.3197186341285705, 1.3167410478591919, 1.3084323835372924, 1.303989338874817, 1.3012149543762208, 1.2966120557785035, 1.2913727068901062, 1.2919050722122192, 1.2875001277923583, 1.286138409614563, 1.2790724782943725, 1.278027621269226, 1.2754965777397156, 1.2782764415740966, 1.277274547100067, 1.2676027555465699, 1.2714892892837524, 1.2728403806686401, 1.268510633945465, 1.2657890424728393, 1.2678590936660767], 'val_losses': [1.8912093043327332, 1.7259619198739529, 1.6009776815772057, 1.5315806493163109, 1.5508816540241241, 1.4844282381236553, 1.4539503082633018, 1.4438256099820137, 1.431164763867855, 1.4117102697491646, 1.3997142687439919, 1.4066339209675789, 1.4119424261152744, 1.3875571861863136, 1.395166639238596, 1.4176773726940155, 1.3900398313999176, 1.378209836781025, 1.3776395581662655, 1.3776382319629192, 1.3749043494462967, 1.3756233230233192, 1.3771314360201359, 1.371523916721344, 1.3596919812262058, 1.3634238056838512, 1.3592248409986496, 1.3615935668349266, 1.3614991046488285, 1.3570791445672512, 1.357692588120699, 1.358528759330511, 1.3558288477361202, 1.3630497381091118, 1.354874148964882, 1.3561988808214664, 1.3586555048823357, 1.3567524254322052, 1.3563130907714367, 1.3563901409506798], 'val_acc': [0.08194462209939957, 0.238566592335701, 0.29507580399513245, 0.3705049455165863, 0.5133441686630249, 0.4859040081501007, 0.552812933921814, 0.6009271740913391, 0.6610700488090515, 0.5546923875808716, 0.6158376336097717, 0.6746021509170532, 0.5556947588920593, 0.740634024143219, 0.5749906301498413, 0.39193084836006165, 0.7327402830123901, 0.6906402707099915, 0.6207242012023926, 0.715825080871582, 0.6831223964691162, 0.6836236119270325, 0.5731111168861389, 0.7722089886665344, 0.7139456272125244, 0.6392682790756226, 0.7169527411460876, 0.7641899585723877, 0.7643152475357056, 0.7494048476219177, 0.7200852036476135, 0.7055506706237793, 0.7134444117546082, 0.7956396341323853, 0.7338679432868958, 0.7714571952819824, 0.776343822479248, 0.7588021755218506, 0.7621852159500122, 0.7615587115287781], 'val_macro_f1': [0.1601954872428905, 0.30545002073049543, 0.3782613888382912, 0.4269543498754501, 0.4950209781527519, 0.48740801513195037, 0.5292539983987808, 0.5504256993532181, 0.5738032639026642, 0.530645951628685, 0.5592683613300323, 0.5830528378486634, 0.5386332184076309, 0.6146843016147614, 0.5507693529129029, 0.4638571873307228, 0.6080477327108383, 0.5913424640893936, 0.5725487023591995, 0.6033452033996582, 0.5870039850473404, 0.5879621207714081, 0.5511473774909973, 0.6296742796897888, 0.6093354731798172, 0.5778749585151672, 0.6080266952514648, 0.6292733818292617, 0.6308046013116837, 0.6217242330312729, 0.6120944142341613, 0.6029175907373429, 0.6059692561626434, 0.6468405961990357, 0.6149223953485489, 0.6338135153055191, 0.6361918896436691, 0.6262049496173858, 0.6283648163080215, 0.6280708372592926], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0008720178718620544, 'batch_size': 256, 'epochs': 40, 'weight_decay': 1.4214911411654497e-05, 'dropout': 0.04772469523689922, 'stem_channels': 16, 'embed_channels': 48, 'se_reduction': 4, 'd_model': 21, 'num_heads': 2, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09723559842072246, 'grad_clip': 0.9704804523630403, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 6}, 'model_parameter_count': 50279, 'model_storage_size_kb': 216.042578125, 'model_size_validation': 'PASS'}
2025-09-29 13:04:47,866 - INFO - _models.training_function_executor - BO Objective: base=0.7616, size_penalty=0.0000, final=0.7616
2025-09-29 13:04:47,866 - INFO - _models.training_function_executor - Model: 50,279 parameters, 216.0KB (PASS 256KB limit)
2025-09-29 13:04:47,866 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 44.867s
2025-09-29 13:04:47,965 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7616
2025-09-29 13:04:47,966 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.100s
2025-09-29 13:04:47,966 - INFO - bo.run_bo - Recorded observation #13: hparams={'lr': 0.0008720178718620544, 'batch_size': np.int64(256), 'epochs': np.int64(40), 'weight_decay': 1.4214911411654497e-05, 'dropout': 0.04772469523689922, 'stem_channels': np.int64(16), 'embed_channels': np.int64(48), 'se_reduction': np.int64(4), 'd_model': np.int64(21), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(40), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09723559842072246, 'grad_clip': 0.9704804523630403, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(6)}, value=0.7616
2025-09-29 13:04:47,966 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 13: {'lr': 0.0008720178718620544, 'batch_size': np.int64(256), 'epochs': np.int64(40), 'weight_decay': 1.4214911411654497e-05, 'dropout': 0.04772469523689922, 'stem_channels': np.int64(16), 'embed_channels': np.int64(48), 'se_reduction': np.int64(4), 'd_model': np.int64(21), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(40), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09723559842072246, 'grad_clip': 0.9704804523630403, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(6)} -> 0.7616
2025-09-29 13:04:47,966 - INFO - bo.run_bo - ðŸ”BO Trial 14: Using RF surrogate + Expected Improvement
2025-09-29 13:04:47,966 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:04:47,966 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:04:47,966 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:04:47,966 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.005569176655600184, 'batch_size': 64, 'epochs': 48, 'weight_decay': 0.002509380647256807, 'dropout': 0.29656676976877533, 'stem_channels': 32, 'embed_channels': 39, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 2, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.060191117408990344, 'grad_clip': 0.9693920573613328, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 22}
2025-09-29 13:04:47,967 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.005569176655600184, 'batch_size': 64, 'epochs': 48, 'weight_decay': 0.002509380647256807, 'dropout': 0.29656676976877533, 'stem_channels': 32, 'embed_channels': 39, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 2, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.060191117408990344, 'grad_clip': 0.9693920573613328, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 22}
2025-09-29 13:06:24,959 - INFO - _models.training_function_executor - Model: 338,557 parameters, 1454.7KB storage
2025-09-29 13:06:24,959 - WARNING - _models.training_function_executor - Model storage 1454.7KB exceeds 256KB limit!
2025-09-29 13:06:24,959 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7562254356716821, 0.5657765716015696, 0.49134674387608834, 0.44270997875200246, 0.4212055292898763, 0.4065187492208156, 0.39624350850950024, 0.3855844075550775, 0.373724621438789, 0.36645612114655945, 0.3579416935572882, 0.3535783827185392, 0.34905772875688357, 0.339083715765653, 0.3422046496060664, 0.33134466343986724, 0.3285494625926734, 0.32797220307504965, 0.32239887339318685, 0.3179518870098557, 0.31748437146863384, 0.31261936666253576, 0.3129388941433243, 0.3109104539564473, 0.308535927163814, 0.3061941202155096, 0.3070626526414034, 0.3036190879966071, 0.30264280160108886, 0.29984750226886575, 0.3053798447988315, 0.3013257472691889, 0.30159941853167777, 0.29568949520946264, 0.29987553699699815, 0.2954809264334027, 0.29664578866624164, 0.2930256238800729, 0.29479018636122495, 0.2955941011408766, 0.2922320270347213, 0.2913984633041527, 0.29199628188519294, 0.2924046237506943, 0.2891193679076636, 0.29138446779910454, 0.28809077103056746, 0.2888935818700848], 'val_losses': [0.6141130192279816, 0.5317385075092316, 0.4601723704338074, 0.43266638088226317, 0.4299989457130432, 0.4257071135044098, 0.41240631985664367, 0.4125806586742401, 0.4227584965229034, 0.4234081978797913, 0.4093323621749878, 0.4176252362728119, 0.40370206379890444, 0.4208709774017334, 0.40926953506469727, 0.43628756880760194, 0.4205010178089142, 0.427894561290741, 0.4108957197666168, 0.40955604910850524, 0.40762513971328734, 0.4157247722148895, 0.43803421878814697, 0.42069912695884704, 0.41966338610649107, 0.4187022681236267, 0.4041493704319, 0.43585438466072085, 0.4232791740894318, 0.4270864853858948, 0.41748197937011716, 0.41787294316291806, 0.41490308380126956, 0.42837257504463194, 0.4169746255874634, 0.4200367410182953, 0.418337810754776, 0.41412377142906187, 0.441134265422821, 0.41828937268257144, 0.4345205247402191, 0.41738631582260133, 0.4308680760860443, 0.42899942421913145, 0.42845138478279116, 0.42881534099578855, 0.41500578927993775, 0.42216213488578797], 'val_acc': [0.8674351572990417, 0.8987595438957214, 0.9235684871673584, 0.9338428974151611, 0.9364741444587708, 0.9376018047332764, 0.9434908032417297, 0.9413607120513916, 0.9383535981178284, 0.940233051776886, 0.9462473392486572, 0.9427390098571777, 0.9492544531822205, 0.9466232061386108, 0.9459967613220215, 0.9397318363189697, 0.9447437524795532, 0.9453702569007874, 0.9482520818710327, 0.9506327509880066, 0.9518857002258301, 0.9523869156837463, 0.9442425966262817, 0.9476256370544434, 0.950256884098053, 0.950256884098053, 0.9525122046470642, 0.9473749995231628, 0.9496303796768188, 0.9508833289146423, 0.9512592554092407, 0.9488785862922668, 0.949505090713501, 0.9500062465667725, 0.949505090713501, 0.9517604112625122, 0.949505090713501, 0.950256884098053, 0.9422377943992615, 0.9503821730613708, 0.9473749995231628, 0.9497556686401367, 0.9497556686401367, 0.949505090713501, 0.9486280083656311, 0.9490038752555847, 0.9541410803794861, 0.9508833289146423], 'val_macro_f1': [0.5619461417198182, 0.6354691050946712, 0.6359617941081523, 0.7297381341457367, 0.7077537342905998, 0.716690993309021, 0.7427831292152405, 0.7544435560703278, 0.7492794036865235, 0.7622384011745453, 0.7526425123214722, 0.7564262390136719, 0.7918221831321717, 0.7604083716869354, 0.7644519686698914, 0.7749406039714813, 0.773609334230423, 0.7592852056026459, 0.7834942221641541, 0.7767977058887482, 0.8047911167144776, 0.7769204199314117, 0.7597117722034454, 0.7831065773963928, 0.7827137053012848, 0.7802235782146454, 0.7979461491107941, 0.785298901796341, 0.7831231951713562, 0.7675962388515473, 0.7778992235660553, 0.7820940732955932, 0.7728706240653992, 0.792862719297409, 0.7821492433547974, 0.7790446162223816, 0.7923194944858551, 0.77728670835495, 0.7716338038444519, 0.7819610476493836, 0.7900328218936921, 0.7834668636322022, 0.7675621628761291, 0.7842179715633393, 0.7819703161716461, 0.7857698559761047, 0.7950148463249207, 0.7771857380867004], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.005569176655600184, 'batch_size': 64, 'epochs': 48, 'weight_decay': 0.002509380647256807, 'dropout': 0.29656676976877533, 'stem_channels': 32, 'embed_channels': 39, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 2, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.060191117408990344, 'grad_clip': 0.9693920573613328, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 22}, 'model_parameter_count': 338557, 'model_storage_size_kb': 1454.737109375, 'model_size_validation': 'FAIL'}
2025-09-29 13:06:24,959 - INFO - _models.training_function_executor - BO Objective: base=0.9509, size_penalty=0.8000, final=0.1509
2025-09-29 13:06:24,959 - INFO - _models.training_function_executor - Model: 338,557 parameters, 1454.7KB (FAIL 256KB limit)
2025-09-29 13:06:24,959 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 96.994s
2025-09-29 13:06:25,060 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1509
2025-09-29 13:06:25,060 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-09-29 13:06:25,060 - INFO - bo.run_bo - Recorded observation #14: hparams={'lr': 0.005569176655600184, 'batch_size': np.int64(64), 'epochs': np.int64(48), 'weight_decay': 0.002509380647256807, 'dropout': 0.29656676976877533, 'stem_channels': np.int64(32), 'embed_channels': np.int64(39), 'se_reduction': np.int64(8), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(500), 'class_weighting': np.str_('none'), 'label_smoothing': 0.060191117408990344, 'grad_clip': 0.9693920573613328, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(22)}, value=0.1509
2025-09-29 13:06:25,060 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 14: {'lr': 0.005569176655600184, 'batch_size': np.int64(64), 'epochs': np.int64(48), 'weight_decay': 0.002509380647256807, 'dropout': 0.29656676976877533, 'stem_channels': np.int64(32), 'embed_channels': np.int64(39), 'se_reduction': np.int64(8), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(500), 'class_weighting': np.str_('none'), 'label_smoothing': 0.060191117408990344, 'grad_clip': 0.9693920573613328, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(22)} -> 0.1509
2025-09-29 13:06:25,060 - INFO - bo.run_bo - ðŸ”BO Trial 15: Using RF surrogate + Expected Improvement
2025-09-29 13:06:25,060 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:06:25,060 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:06:25,060 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:06:25,060 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00113904853239697, 'batch_size': 128, 'epochs': 23, 'weight_decay': 1.7756222590696724e-06, 'dropout': 0.2576341098140817, 'stem_channels': 30, 'embed_channels': 47, 'se_reduction': 2, 'd_model': 20, 'num_heads': 2, 'num_layers': 2, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0849790472365026, 'grad_clip': 0.891326365314356, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}
2025-09-29 13:06:25,062 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00113904853239697, 'batch_size': 128, 'epochs': 23, 'weight_decay': 1.7756222590696724e-06, 'dropout': 0.2576341098140817, 'stem_channels': 30, 'embed_channels': 47, 'se_reduction': 2, 'd_model': 20, 'num_heads': 2, 'num_layers': 2, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0849790472365026, 'grad_clip': 0.891326365314356, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}
2025-09-29 13:07:03,255 - INFO - _models.training_function_executor - Model: 245,976 parameters, 1056.9KB storage
2025-09-29 13:07:03,255 - WARNING - _models.training_function_executor - Model storage 1056.9KB exceeds 256KB limit!
2025-09-29 13:07:03,255 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8550190079212189, 0.6276747674942017, 0.5432344051599503, 0.5100130556821824, 0.4900348650217056, 0.47615560388565065, 0.46799965906143187, 0.4587556645870209, 0.4498630074262619, 0.4454824583530426, 0.4369576871395111, 0.43101011848449705, 0.42531389331817626, 0.4189204791784287, 0.41797912871837617, 0.4094669607877731, 0.40881666457653043, 0.4047109431028366, 0.402352322101593, 0.39759711706638334, 0.3954364161491394, 0.3913047709465027, 0.3879702923297882], 'val_losses': [0.6911587771915254, 0.5652319462526412, 0.5197121141448854, 0.5096354948149787, 0.5052752234633007, 0.4939861728085412, 0.48461615566223387, 0.48858361821325996, 0.47781579362021553, 0.4810321454017881, 0.4788803623782264, 0.4695462366891286, 0.4768329707403032, 0.47301703360345626, 0.46648497430105057, 0.4761850129044245, 0.47003818173257134, 0.4774562773250398, 0.4716326107108404, 0.4867489621752784, 0.47902204451106845, 0.4773756450130826, 0.4903140101167891], 'val_acc': [0.8527753353118896, 0.9065279960632324, 0.9274526834487915, 0.9333416819572449, 0.9344693422317505, 0.940233051776886, 0.9421125054359436, 0.9408595561981201, 0.9462473392486572, 0.9467485547065735, 0.9458714723587036, 0.9513845443725586, 0.9488785862922668, 0.9511339664459229, 0.9532639980316162, 0.9521363377571106, 0.9530134201049805, 0.9510086178779602, 0.9541410803794861, 0.9510086178779602, 0.9516351222991943, 0.9537652134895325, 0.9512592554092407], 'val_macro_f1': [0.47181163281202315, 0.6497384548187256, 0.6702674508094788, 0.6941153258085251, 0.7028512224555016, 0.7605476260185242, 0.7580258131027222, 0.7554091453552246, 0.7925737082958222, 0.789339679479599, 0.7975130796432495, 0.7978641390800476, 0.7949350476264954, 0.8087963581085205, 0.8134740948677063, 0.8065036654472351, 0.804132604598999, 0.808066987991333, 0.8148160934448242, 0.7898745715618134, 0.8062827229499817, 0.8096074223518371, 0.8061501860618592], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00113904853239697, 'batch_size': 128, 'epochs': 23, 'weight_decay': 1.7756222590696724e-06, 'dropout': 0.2576341098140817, 'stem_channels': 30, 'embed_channels': 47, 'se_reduction': 2, 'd_model': 20, 'num_heads': 2, 'num_layers': 2, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0849790472365026, 'grad_clip': 0.891326365314356, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}, 'model_parameter_count': 245976, 'model_storage_size_kb': 1056.9281250000001, 'model_size_validation': 'FAIL'}
2025-09-29 13:07:03,255 - INFO - _models.training_function_executor - BO Objective: base=0.9513, size_penalty=0.8000, final=0.1513
2025-09-29 13:07:03,255 - INFO - _models.training_function_executor - Model: 245,976 parameters, 1056.9KB (FAIL 256KB limit)
2025-09-29 13:07:03,255 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 38.195s
2025-09-29 13:07:03,356 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1513
2025-09-29 13:07:03,356 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-09-29 13:07:03,357 - INFO - bo.run_bo - Recorded observation #15: hparams={'lr': 0.00113904853239697, 'batch_size': np.int64(128), 'epochs': np.int64(23), 'weight_decay': 1.7756222590696724e-06, 'dropout': 0.2576341098140817, 'stem_channels': np.int64(30), 'embed_channels': np.int64(47), 'se_reduction': np.int64(2), 'd_model': np.int64(20), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0849790472365026, 'grad_clip': 0.891326365314356, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(11)}, value=0.1513
2025-09-29 13:07:03,357 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 15: {'lr': 0.00113904853239697, 'batch_size': np.int64(128), 'epochs': np.int64(23), 'weight_decay': 1.7756222590696724e-06, 'dropout': 0.2576341098140817, 'stem_channels': np.int64(30), 'embed_channels': np.int64(47), 'se_reduction': np.int64(2), 'd_model': np.int64(20), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0849790472365026, 'grad_clip': 0.891326365314356, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(11)} -> 0.1513
2025-09-29 13:07:03,357 - INFO - bo.run_bo - ðŸ”BO Trial 16: Using RF surrogate + Expected Improvement
2025-09-29 13:07:03,357 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:07:03,357 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:07:03,357 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:07:03,357 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0001313238223503053, 'batch_size': 64, 'epochs': 15, 'weight_decay': 0.003690490107453365, 'dropout': 0.1385044437759886, 'stem_channels': 30, 'embed_channels': 48, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09605478779209534, 'grad_clip': 0.9607503628008766, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}
2025-09-29 13:07:03,358 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0001313238223503053, 'batch_size': 64, 'epochs': 15, 'weight_decay': 0.003690490107453365, 'dropout': 0.1385044437759886, 'stem_channels': 30, 'embed_channels': 48, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09605478779209534, 'grad_clip': 0.9607503628008766, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}
2025-09-29 13:07:28,265 - INFO - _models.training_function_executor - Model: 209,019 parameters, 898.1KB storage
2025-09-29 13:07:28,265 - WARNING - _models.training_function_executor - Model storage 898.1KB exceeds 256KB limit!
2025-09-29 13:07:28,265 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9924498568316977, 0.8908475987419098, 0.8150717215929815, 0.7530940486816223, 0.7149959142079095, 0.6972445072176939, 0.662829118525098, 0.6328772333915343, 0.6095737232593353, 0.5997235533708561, 0.5781181377614428, 0.5650786368068091, 0.5544415437028499, 0.5428760761249519, 0.534043046181092], 'val_losses': [0.9196460084915161, 0.8309415431022644, 0.7617379665374756, 0.719896423816681, 0.698273964881897, 0.6867025618553162, 0.6606874134540558, 0.6430864748954773, 0.6232139859199524, 0.6152242658138275, 0.5911842889785767, 0.5862645909786225, 0.594091518163681, 0.5848414752483367, 0.5701656775474548], 'val_acc': [0.7421375513076782, 0.8143090009689331, 0.831474781036377, 0.853151261806488, 0.8561583757400513, 0.860919713973999, 0.8800902366638184, 0.8871068954467773, 0.9008896350860596, 0.9062774181365967, 0.9147976636886597, 0.9139205813407898, 0.9116652011871338, 0.9116652011871338, 0.9221901893615723], 'val_macro_f1': [0.2781029663980007, 0.4284742474555969, 0.4450153112411499, 0.47836344242095946, 0.48746254444122317, 0.4965998291969299, 0.5084855079650878, 0.525345990806818, 0.5635305047035217, 0.5699918180704117, 0.6183028250932694, 0.634969262033701, 0.6290753617882728, 0.6540504664182663, 0.6687177568674088], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0001313238223503053, 'batch_size': 64, 'epochs': 15, 'weight_decay': 0.003690490107453365, 'dropout': 0.1385044437759886, 'stem_channels': 30, 'embed_channels': 48, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09605478779209534, 'grad_clip': 0.9607503628008766, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}, 'model_parameter_count': 209019, 'model_storage_size_kb': 898.1285156250001, 'model_size_validation': 'FAIL'}
2025-09-29 13:07:28,265 - INFO - _models.training_function_executor - BO Objective: base=0.9222, size_penalty=0.8000, final=0.1222
2025-09-29 13:07:28,265 - INFO - _models.training_function_executor - Model: 209,019 parameters, 898.1KB (FAIL 256KB limit)
2025-09-29 13:07:28,265 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 24.909s
2025-09-29 13:07:28,366 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1222
2025-09-29 13:07:28,366 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-09-29 13:07:28,366 - INFO - bo.run_bo - Recorded observation #16: hparams={'lr': 0.0001313238223503053, 'batch_size': np.int64(64), 'epochs': np.int64(15), 'weight_decay': 0.003690490107453365, 'dropout': 0.1385044437759886, 'stem_channels': np.int64(30), 'embed_channels': np.int64(48), 'se_reduction': np.int64(8), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09605478779209534, 'grad_clip': 0.9607503628008766, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(16)}, value=0.1222
2025-09-29 13:07:28,367 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 16: {'lr': 0.0001313238223503053, 'batch_size': np.int64(64), 'epochs': np.int64(15), 'weight_decay': 0.003690490107453365, 'dropout': 0.1385044437759886, 'stem_channels': np.int64(30), 'embed_channels': np.int64(48), 'se_reduction': np.int64(8), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09605478779209534, 'grad_clip': 0.9607503628008766, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(16)} -> 0.1222
2025-09-29 13:07:28,367 - INFO - bo.run_bo - ðŸ”BO Trial 17: Using RF surrogate + Expected Improvement
2025-09-29 13:07:28,367 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:07:28,367 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:07:28,367 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:07:28,367 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.008048635987744171, 'batch_size': 256, 'epochs': 25, 'weight_decay': 0.0012899605391349385, 'dropout': 0.010931587449158732, 'stem_channels': 29, 'embed_channels': 38, 'se_reduction': 2, 'd_model': 18, 'num_heads': 2, 'num_layers': 2, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0858723361129094, 'grad_clip': 0.6407233556327376, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 30}
2025-09-29 13:07:28,368 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.008048635987744171, 'batch_size': 256, 'epochs': 25, 'weight_decay': 0.0012899605391349385, 'dropout': 0.010931587449158732, 'stem_channels': 29, 'embed_channels': 38, 'se_reduction': 2, 'd_model': 18, 'num_heads': 2, 'num_layers': 2, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0858723361129094, 'grad_clip': 0.6407233556327376, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 30}
2025-09-29 13:08:03,158 - INFO - _models.training_function_executor - Model: 350,628 parameters, 1506.6KB storage
2025-09-29 13:08:03,158 - WARNING - _models.training_function_executor - Model storage 1506.6KB exceeds 256KB limit!
2025-09-29 13:08:03,158 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8520941443443298, 0.6092033805847168, 0.5331596431732177, 0.4880141315460205, 0.46450725889205935, 0.44745443725585937, 0.43628764581680296, 0.425708881855011, 0.41535451316833494, 0.40525838327407837, 0.3981974649429321, 0.3937120320796966, 0.3879506964683533, 0.383044816493988, 0.38008401441574097, 0.37651396679878235, 0.3723654115200043, 0.3705441539287567, 0.3682512376308441, 0.3687993731498718, 0.3660984389781952, 0.36381342363357544, 0.3635757343769073, 0.362916802406311, 0.35933434009552], 'val_losses': [0.6680144872516394, 0.5826089102774858, 0.517373408190906, 0.5116190686821938, 0.49344007577747107, 0.4914218820631504, 0.4908045558258891, 0.49039219971746206, 0.49132661428302526, 0.48554826341569424, 0.48007369972765446, 0.482403757981956, 0.5030755260959268, 0.4872502340003848, 0.4913008753210306, 0.5013571605086327, 0.49006674718111753, 0.4910000767558813, 0.4912374271079898, 0.5030700881034136, 0.48252064920961857, 0.48536567855626345, 0.49455398693680763, 0.4880584329366684, 0.4911895487457514], 'val_acc': [0.8590402007102966, 0.8950006365776062, 0.9218143224716187, 0.9256985187530518, 0.9381030201911926, 0.9384788870811462, 0.9383535981178284, 0.9388547539710999, 0.9418619275093079, 0.9456208348274231, 0.9452449679374695, 0.9477509260177612, 0.9389801025390625, 0.9473749995231628, 0.9421125054359436, 0.940984845161438, 0.9444931745529175, 0.9467485547065735, 0.9442425966262817, 0.9423630833625793, 0.9491291642189026, 0.9473749995231628, 0.9475002884864807, 0.9469991326332092, 0.9463726282119751], 'val_macro_f1': [0.549581515789032, 0.6619388028979302, 0.6731573440134525, 0.7357833504676818, 0.7489256501197815, 0.7736278533935547, 0.7488879382610321, 0.7533879101276397, 0.7609408974647522, 0.7887611269950867, 0.771483325958252, 0.7916473507881164, 0.7720883667469025, 0.782800018787384, 0.7935457706451416, 0.7691208481788635, 0.784513795375824, 0.7949768245220185, 0.7951236426830292, 0.7944650650024414, 0.8031176447868347, 0.7990551471710206, 0.7899246335029602, 0.8024718642234803, 0.7981744706630707], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.008048635987744171, 'batch_size': 256, 'epochs': 25, 'weight_decay': 0.0012899605391349385, 'dropout': 0.010931587449158732, 'stem_channels': 29, 'embed_channels': 38, 'se_reduction': 2, 'd_model': 18, 'num_heads': 2, 'num_layers': 2, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0858723361129094, 'grad_clip': 0.6407233556327376, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 30}, 'model_parameter_count': 350628, 'model_storage_size_kb': 1506.6046875000002, 'model_size_validation': 'FAIL'}
2025-09-29 13:08:03,158 - INFO - _models.training_function_executor - BO Objective: base=0.9464, size_penalty=0.8000, final=0.1464
2025-09-29 13:08:03,158 - INFO - _models.training_function_executor - Model: 350,628 parameters, 1506.6KB (FAIL 256KB limit)
2025-09-29 13:08:03,158 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 34.791s
2025-09-29 13:08:03,262 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1464
2025-09-29 13:08:03,262 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-09-29 13:08:03,262 - INFO - bo.run_bo - Recorded observation #17: hparams={'lr': 0.008048635987744171, 'batch_size': np.int64(256), 'epochs': np.int64(25), 'weight_decay': 0.0012899605391349385, 'dropout': 0.010931587449158732, 'stem_channels': np.int64(29), 'embed_channels': np.int64(38), 'se_reduction': np.int64(2), 'd_model': np.int64(18), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(500), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0858723361129094, 'grad_clip': 0.6407233556327376, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(30)}, value=0.1464
2025-09-29 13:08:03,262 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 17: {'lr': 0.008048635987744171, 'batch_size': np.int64(256), 'epochs': np.int64(25), 'weight_decay': 0.0012899605391349385, 'dropout': 0.010931587449158732, 'stem_channels': np.int64(29), 'embed_channels': np.int64(38), 'se_reduction': np.int64(2), 'd_model': np.int64(18), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(500), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0858723361129094, 'grad_clip': 0.6407233556327376, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(30)} -> 0.1464
2025-09-29 13:08:03,262 - INFO - bo.run_bo - ðŸ”BO Trial 18: Using RF surrogate + Expected Improvement
2025-09-29 13:08:03,262 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:08:03,262 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:08:03,262 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:08:03,262 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002510795247864168, 'batch_size': 64, 'epochs': 27, 'weight_decay': 0.0043718465911552935, 'dropout': 0.1755409675346485, 'stem_channels': 29, 'embed_channels': 42, 'se_reduction': 2, 'd_model': 19, 'num_heads': 4, 'num_layers': 1, 'patch_size': 125, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.06918354867159492, 'grad_clip': 0.5462807832134015, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 3}
2025-09-29 13:08:03,264 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002510795247864168, 'batch_size': 64, 'epochs': 27, 'weight_decay': 0.0043718465911552935, 'dropout': 0.1755409675346485, 'stem_channels': 29, 'embed_channels': 42, 'se_reduction': 2, 'd_model': 19, 'num_heads': 4, 'num_layers': 1, 'patch_size': 125, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.06918354867159492, 'grad_clip': 0.5462807832134015, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 3}
2025-09-29 13:08:46,879 - INFO - _models.training_function_executor - Model: 106,352 parameters, 228.5KB storage
2025-09-29 13:08:46,879 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7073573339917139, 1.4260167189255983, 1.3352501890463437, 1.2874022096335769, 1.2450768373055545, 1.2159797487134685, 1.1845324178019123, 1.1670012425086302, 1.151802362205987, 1.1335792763677532, 1.1203446416912193, 1.103788351964855, 1.1029749811292888, 1.0823331445395827, 1.0728745796159656, 1.0715891421438457, 1.0616307275328702, 1.0525734456842075, 1.0451931389634739, 1.0393813871190638, 1.0254250952380453, 1.0286911644773158, 1.0239137199694264, 1.0283746441046078, 1.0155961271039469, 1.0247301702986737, 1.0163611060153983], 'val_losses': [1.4481519632339477, 1.3690325298309327, 1.2928433113098146, 1.276653284072876, 1.229680998802185, 1.2170501136779786, 1.2008919339179993, 1.191564552783966, 1.1847547531127929, 1.1810282802581786, 1.216766769886017, 1.1624427886009217, 1.1798186898231506, 1.2202727031707763, 1.1928081431388855, 1.2012956800460814, 1.1975297937393188, 1.2131651482582093, 1.204834008693695, 1.2180929727554322, 1.2316689233779907, 1.2395134444236755, 1.2230388522148132, 1.2667174773216248, 1.2580418486595153, 1.2375863451957703, 1.2099828424453736], 'val_acc': [0.49617841839790344, 0.6291191577911377, 0.5851396918296814, 0.6942738890647888, 0.7644405364990234, 0.7037965059280396, 0.7942613959312439, 0.8268387317657471, 0.8228292465209961, 0.8069164156913757, 0.8076682090759277, 0.875704824924469, 0.8328530192375183, 0.89825838804245, 0.856408953666687, 0.8753288984298706, 0.9082821607589722, 0.9203107357025146, 0.9200601577758789, 0.9047738313674927, 0.8866056799888611, 0.9038967490196228, 0.9070292115211487, 0.9344693422317505, 0.9319633841514587, 0.9251973628997803, 0.9312116503715515], 'val_macro_f1': [0.45230178236961366, 0.5359781563282013, 0.5277801990509033, 0.5641673117876053, 0.6181436061859131, 0.5828063488006592, 0.6331506431102752, 0.668270605802536, 0.660045063495636, 0.6532586872577667, 0.6460867047309875, 0.7233739912509918, 0.6763468384742737, 0.7290933907032013, 0.686792641878128, 0.712075001001358, 0.7475287854671478, 0.7723089635372162, 0.7613791823387146, 0.750484299659729, 0.7141547262668609, 0.7363193750381469, 0.7379345953464508, 0.7701639115810395, 0.780747240781784, 0.7658333003520965, 0.7900749981403351], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002510795247864168, 'batch_size': 64, 'epochs': 27, 'weight_decay': 0.0043718465911552935, 'dropout': 0.1755409675346485, 'stem_channels': 29, 'embed_channels': 42, 'se_reduction': 2, 'd_model': 19, 'num_heads': 4, 'num_layers': 1, 'patch_size': 125, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.06918354867159492, 'grad_clip': 0.5462807832134015, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 3}, 'model_parameter_count': 106352, 'model_storage_size_kb': 228.49062500000002, 'model_size_validation': 'PASS'}
2025-09-29 13:08:46,879 - INFO - _models.training_function_executor - BO Objective: base=0.9312, size_penalty=0.0000, final=0.9312
2025-09-29 13:08:46,879 - INFO - _models.training_function_executor - Model: 106,352 parameters, 228.5KB (PASS 256KB limit)
2025-09-29 13:08:46,879 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 43.617s
2025-09-29 13:08:46,982 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9312
2025-09-29 13:08:46,982 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-09-29 13:08:46,982 - INFO - bo.run_bo - Recorded observation #18: hparams={'lr': 0.002510795247864168, 'batch_size': np.int64(64), 'epochs': np.int64(27), 'weight_decay': 0.0043718465911552935, 'dropout': 0.1755409675346485, 'stem_channels': np.int64(29), 'embed_channels': np.int64(42), 'se_reduction': np.int64(2), 'd_model': np.int64(19), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(125), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.06918354867159492, 'grad_clip': 0.5462807832134015, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(3)}, value=0.9312
2025-09-29 13:08:46,982 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 18: {'lr': 0.002510795247864168, 'batch_size': np.int64(64), 'epochs': np.int64(27), 'weight_decay': 0.0043718465911552935, 'dropout': 0.1755409675346485, 'stem_channels': np.int64(29), 'embed_channels': np.int64(42), 'se_reduction': np.int64(2), 'd_model': np.int64(19), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(125), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.06918354867159492, 'grad_clip': 0.5462807832134015, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(3)} -> 0.9312
2025-09-29 13:08:46,983 - INFO - bo.run_bo - ðŸ”BO Trial 19: Using RF surrogate + Expected Improvement
2025-09-29 13:08:46,983 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:08:46,983 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:08:46,983 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:08:46,983 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00406395017584432, 'batch_size': 512, 'epochs': 48, 'weight_decay': 7.770923105095206e-05, 'dropout': 0.016423193149431418, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 26, 'num_heads': 4, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.06489531993551037, 'grad_clip': 0.6662340812147884, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 3}
2025-09-29 13:08:46,984 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00406395017584432, 'batch_size': 512, 'epochs': 48, 'weight_decay': 7.770923105095206e-05, 'dropout': 0.016423193149431418, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 26, 'num_heads': 4, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.06489531993551037, 'grad_clip': 0.6662340812147884, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 3}
2025-09-29 13:09:39,424 - INFO - _models.training_function_executor - Model: 568,319 parameters, 2442.0KB storage
2025-09-29 13:09:39,424 - WARNING - _models.training_function_executor - Model storage 2442.0KB exceeds 256KB limit!
2025-09-29 13:09:39,424 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8874792380938454, 0.6424405395038544, 0.5503911513184744, 0.48505162530475193, 0.4315520316835434, 0.40699819203407045, 0.38275960466218373, 0.3672136328523121, 0.34982193793569294, 0.3374490676418183, 0.3267663423977201, 0.31868853077055914, 0.3119180453202081, 0.3074732560013968, 0.30308768153190613, 0.2993833058410221, 0.29528711050275774, 0.2922766852000403, 0.29057484581356957, 0.2890785237153371, 0.287936254153176, 0.28882479573053027, 0.29009258889016654, 0.28779563071235775, 0.2862241958814954, 0.2860385330896529, 0.28430859295148697, 0.2823359190471589, 0.28447230041973176, 0.2855021348075261, 0.2867856342641134, 0.28459148274527657, 0.2839211594490778, 0.28231081886897014, 0.28189449130542693, 0.2812081002999866, 0.28005273332671515, 0.28000538311307394, 0.2800058031839038, 0.2811959892038315, 0.2842618752093542, 0.28383801380793255, 0.2824615765185583, 0.28270987953458515, 0.2842893245674315, 0.28276845718187, 0.2813185935928708, 0.2800419647542257], 'val_losses': [0.7344873882830143, 0.5961930081248283, 0.5287246555089951, 0.4707978591322899, 0.45425307378172874, 0.44932991452515125, 0.4413823913782835, 0.4251058790832758, 0.42595393769443035, 0.4191414453089237, 0.43178695254027843, 0.4377753045409918, 0.42024029418826103, 0.4350426383316517, 0.43172304704785347, 0.42653525434434414, 0.4278976358473301, 0.4276984613388777, 0.4301018286496401, 0.4298058170825243, 0.4380056131631136, 0.44180151261389256, 0.4432217311114073, 0.42491859197616577, 0.44725286215543747, 0.42653203196823597, 0.43050093948841095, 0.4262226615101099, 0.43646792136132717, 0.43958628363907337, 0.4338583014905453, 0.43156931176781654, 0.4231442101299763, 0.42246258817613125, 0.4286478441208601, 0.4206837844103575, 0.4206050578504801, 0.42233520932495594, 0.4183512683957815, 0.43911944702267647, 0.42771171033382416, 0.4251926578581333, 0.4249078594148159, 0.43286699429154396, 0.42633524164557457, 0.4223210122436285, 0.42060208320617676, 0.430269880220294], 'val_acc': [0.8067911267280579, 0.8638015389442444, 0.8966295123100281, 0.9240696430206299, 0.930961012840271, 0.9327151775360107, 0.9372259378433228, 0.9441173076629639, 0.9461220502853394, 0.9469991326332092, 0.940984845161438, 0.9412354230880737, 0.947249710559845, 0.9404836297035217, 0.9469991326332092, 0.9485027194023132, 0.9475002884864807, 0.9475002884864807, 0.9461220502853394, 0.9452449679374695, 0.9421125054359436, 0.9427390098571777, 0.9404836297035217, 0.9467485547065735, 0.9397318363189697, 0.9476256370544434, 0.9471244215965271, 0.9492544531822205, 0.9448690414428711, 0.9439919590950012, 0.9442425966262817, 0.9467485547065735, 0.9469991326332092, 0.9485027194023132, 0.9492544531822205, 0.9508833289146423, 0.9513845443725586, 0.9492544531822205, 0.9501315355300903, 0.9441173076629639, 0.9481267929077148, 0.948001503944397, 0.9486280083656311, 0.9453702569007874, 0.9488785862922668, 0.9512592554092407, 0.9503821730613708, 0.948001503944397], 'val_macro_f1': [0.47743015438318254, 0.5932037778198719, 0.6610263049602508, 0.7325617492198944, 0.7164522171020508, 0.7325552403926849, 0.7462774276733398, 0.7745795130729676, 0.7655580043792725, 0.7804843544960022, 0.7816891551017762, 0.7810251355171204, 0.7981098294258118, 0.7834819197654724, 0.7918521821498871, 0.8126872420310974, 0.8029998660087585, 0.789661955833435, 0.8061306595802307, 0.7864092290401459, 0.7741901695728302, 0.7814029216766357, 0.7913463592529297, 0.7948780000209809, 0.7752532184123992, 0.8000189781188964, 0.8052633881568909, 0.8065976858139038, 0.7778062343597412, 0.7893082618713378, 0.7705926418304443, 0.8053480863571167, 0.7987338721752166, 0.7976074635982513, 0.806760847568512, 0.809444522857666, 0.805504459142685, 0.7995407462120057, 0.809938645362854, 0.7836007058620453, 0.7943467915058136, 0.7897340416908264, 0.8073949575424194, 0.7844232857227326, 0.7972834765911102, 0.8082525968551636, 0.8099979043006897, 0.7931585907936096], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00406395017584432, 'batch_size': 512, 'epochs': 48, 'weight_decay': 7.770923105095206e-05, 'dropout': 0.016423193149431418, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 26, 'num_heads': 4, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('none'), 'label_smoothing': 0.06489531993551037, 'grad_clip': 0.6662340812147884, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 3}, 'model_parameter_count': 568319, 'model_storage_size_kb': 2441.995703125, 'model_size_validation': 'FAIL'}
2025-09-29 13:09:39,424 - INFO - _models.training_function_executor - BO Objective: base=0.9480, size_penalty=0.8000, final=0.1480
2025-09-29 13:09:39,424 - INFO - _models.training_function_executor - Model: 568,319 parameters, 2442.0KB (FAIL 256KB limit)
2025-09-29 13:09:39,424 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 52.441s
2025-09-29 13:09:39,528 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1480
2025-09-29 13:09:39,528 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-09-29 13:09:39,528 - INFO - bo.run_bo - Recorded observation #19: hparams={'lr': 0.00406395017584432, 'batch_size': np.int64(512), 'epochs': np.int64(48), 'weight_decay': 7.770923105095206e-05, 'dropout': 0.016423193149431418, 'stem_channels': np.int64(29), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(26), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(500), 'class_weighting': np.str_('none'), 'label_smoothing': 0.06489531993551037, 'grad_clip': 0.6662340812147884, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(3)}, value=0.1480
2025-09-29 13:09:39,528 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 19: {'lr': 0.00406395017584432, 'batch_size': np.int64(512), 'epochs': np.int64(48), 'weight_decay': 7.770923105095206e-05, 'dropout': 0.016423193149431418, 'stem_channels': np.int64(29), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(26), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(500), 'class_weighting': np.str_('none'), 'label_smoothing': 0.06489531993551037, 'grad_clip': 0.6662340812147884, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(3)} -> 0.1480
2025-09-29 13:09:39,528 - INFO - bo.run_bo - ðŸ”BO Trial 20: Using RF surrogate + Expected Improvement
2025-09-29 13:09:39,528 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:09:39,529 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:09:39,529 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:09:39,529 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0028977934735162107, 'batch_size': 512, 'epochs': 45, 'weight_decay': 0.002513003926565015, 'dropout': 0.1056100104352635, 'stem_channels': 20, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 19, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0801216660706742, 'grad_clip': 0.9700835476925451, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 6}
2025-09-29 13:09:39,530 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0028977934735162107, 'batch_size': 512, 'epochs': 45, 'weight_decay': 0.002513003926565015, 'dropout': 0.1056100104352635, 'stem_channels': 20, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 19, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0801216660706742, 'grad_clip': 0.9700835476925451, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 6}
2025-09-29 13:10:55,795 - INFO - _models.training_function_executor - Model: 18,209 parameters, 39.1KB storage
2025-09-29 13:10:55,795 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.8865104913711548, 1.6063045338978843, 1.436128332501366, 1.3732333012989588, 1.335724533550323, 1.2937588786321974, 1.26795418489547, 1.2609262031222146, 1.2385960628115942, 1.2239964102941847, 1.2117298595489017, 1.202469990366981, 1.1920988976009308, 1.1833697424994574, 1.1748044036683583, 1.1774083773295085, 1.1666851100467501, 1.1528879848737565, 1.1548787431111411, 1.150250860622951, 1.1479187938902113, 1.141423679533459, 1.13403828749581, 1.1344491555577232, 1.1316572844036041, 1.1312830088630554, 1.124697552786933, 1.122649299719977, 1.115189586366926, 1.1211672491497464, 1.1137402748304701, 1.1064376007942927, 1.1095415230781314, 1.1043137378162808, 1.1038054681959606, 1.1017988362009563, 1.0970826243597365, 1.0952146630438546, 1.1022258230618067, 1.090083109954047, 1.0970892224993025, 1.08047274180821, 1.0951017765771776, 1.0820451378822327, 1.0908908304714022], 'val_losses': [1.7247781231999397, 1.565960444509983, 1.448269672691822, 1.414364218711853, 1.360389083623886, 1.3299059569835663, 1.304186999797821, 1.2820475399494171, 1.2683313935995102, 1.2688588500022888, 1.244995854794979, 1.2388916164636612, 1.2434203177690506, 1.208518274128437, 1.2143513560295105, 1.2059433460235596, 1.2075738310813904, 1.1978880017995834, 1.2205749228596687, 1.233890824019909, 1.2219145596027374, 1.195923075079918, 1.237701676785946, 1.1972310170531273, 1.1921450048685074, 1.2205472365021706, 1.179240807890892, 1.1978697553277016, 1.1880176812410355, 1.1887752264738083, 1.175389014184475, 1.187564767897129, 1.2044588327407837, 1.1756119430065155, 1.1642311736941338, 1.1744581460952759, 1.1668296679854393, 1.1840839087963104, 1.1881487667560577, 1.1701861023902893, 1.1947535648941994, 1.2089541032910347, 1.1660956665873528, 1.173566035926342, 1.1763634383678436], 'val_acc': [0.13983209431171417, 0.24220022559165955, 0.7386292219161987, 0.6680867075920105, 0.6489161849021912, 0.5812554955482483, 0.6813682317733765, 0.6754792928695679, 0.7224658727645874, 0.7700789570808411, 0.8329783082008362, 0.522490918636322, 0.6363863945007324, 0.7445182204246521, 0.6594411730766296, 0.654554545879364, 0.7489036321640015, 0.7866182327270508, 0.7386292219161987, 0.5966671109199524, 0.5995489358901978, 0.6695902943611145, 0.8170655369758606, 0.8082947134971619, 0.86492919921875, 0.7669464945793152, 0.8204485774040222, 0.8287181854248047, 0.8413732647895813, 0.8903645873069763, 0.8700664043426514, 0.8287181854248047, 0.7511590123176575, 0.8739506602287292, 0.8901140093803406, 0.8919934630393982, 0.8612955808639526, 0.8016539216041565, 0.8427515625953674, 0.8942488431930542, 0.8698158264160156, 0.7581756711006165, 0.8496428728103638, 0.8830973505973816, 0.8240821957588196], 'val_macro_f1': [0.2160110667347908, 0.34258618354797366, 0.5954814285039902, 0.5587166011333465, 0.5799263417720795, 0.5307474136352539, 0.5863038390874863, 0.5789983004331589, 0.6088092535734176, 0.6393494933843613, 0.6731031835079193, 0.5370559081435203, 0.5951082319021225, 0.6327420830726623, 0.5917595744132995, 0.5969862282276154, 0.6282647252082825, 0.6522750437259675, 0.6192030638456345, 0.5711745455861091, 0.5848927542567253, 0.6034115344285965, 0.670515102148056, 0.6677291512489318, 0.7128087282180786, 0.653424859046936, 0.6751669853925705, 0.6747663021087646, 0.6862006664276123, 0.7284133434295654, 0.7179365992546082, 0.6831664800643921, 0.6437238305807114, 0.7157489836215973, 0.7304421365261078, 0.7322565913200378, 0.7068289637565612, 0.6600669533014297, 0.6860169887542724, 0.7358702778816223, 0.7094210982322693, 0.6566909432411194, 0.6951449394226075, 0.723753136396408, 0.6801561564207077], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0028977934735162107, 'batch_size': 512, 'epochs': 45, 'weight_decay': 0.002513003926565015, 'dropout': 0.1056100104352635, 'stem_channels': 20, 'embed_channels': 44, 'se_reduction': 2, 'd_model': 19, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0801216660706742, 'grad_clip': 0.9700835476925451, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 6}, 'model_parameter_count': 18209, 'model_storage_size_kb': 39.1208984375, 'model_size_validation': 'PASS'}
2025-09-29 13:10:55,795 - INFO - _models.training_function_executor - BO Objective: base=0.8241, size_penalty=0.0000, final=0.8241
2025-09-29 13:10:55,795 - INFO - _models.training_function_executor - Model: 18,209 parameters, 39.1KB (PASS 256KB limit)
2025-09-29 13:10:55,795 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 76.266s
2025-09-29 13:10:55,900 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8241
2025-09-29 13:10:55,900 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.105s
2025-09-29 13:10:55,900 - INFO - bo.run_bo - Recorded observation #20: hparams={'lr': 0.0028977934735162107, 'batch_size': np.int64(512), 'epochs': np.int64(45), 'weight_decay': 0.002513003926565015, 'dropout': 0.1056100104352635, 'stem_channels': np.int64(20), 'embed_channels': np.int64(44), 'se_reduction': np.int64(2), 'd_model': np.int64(19), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(10), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0801216660706742, 'grad_clip': 0.9700835476925451, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(6)}, value=0.8241
2025-09-29 13:10:55,900 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 20: {'lr': 0.0028977934735162107, 'batch_size': np.int64(512), 'epochs': np.int64(45), 'weight_decay': 0.002513003926565015, 'dropout': 0.1056100104352635, 'stem_channels': np.int64(20), 'embed_channels': np.int64(44), 'se_reduction': np.int64(2), 'd_model': np.int64(19), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(10), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0801216660706742, 'grad_clip': 0.9700835476925451, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(6)} -> 0.8241
2025-09-29 13:10:55,900 - INFO - bo.run_bo - ðŸ”BO Trial 21: Using RF surrogate + Expected Improvement
2025-09-29 13:10:55,900 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:10:55,900 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:10:55,900 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:10:55,900 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0009574111982642528, 'batch_size': 64, 'epochs': 36, 'weight_decay': 0.0007974089464670998, 'dropout': 0.1734120111720053, 'stem_channels': 26, 'embed_channels': 46, 'se_reduction': 2, 'd_model': 26, 'num_heads': 2, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08633022081366294, 'grad_clip': 0.8487235031002973, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 7}
2025-09-29 13:10:55,902 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0009574111982642528, 'batch_size': 64, 'epochs': 36, 'weight_decay': 0.0007974089464670998, 'dropout': 0.1734120111720053, 'stem_channels': 26, 'embed_channels': 46, 'se_reduction': 2, 'd_model': 26, 'num_heads': 2, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08633022081366294, 'grad_clip': 0.8487235031002973, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 7}
2025-09-29 13:12:05,141 - INFO - _models.training_function_executor - Model: 601,837 parameters, 646.5KB storage
2025-09-29 13:12:05,141 - WARNING - _models.training_function_executor - Model storage 646.5KB exceeds 256KB limit!
2025-09-29 13:12:05,142 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.8663377281659113, 1.593656846779382, 1.5036195790122648, 1.4435716641689829, 1.409725782627572, 1.3737825424016596, 1.3444280700836488, 1.3147781542642323, 1.288739927665504, 1.264453541539714, 1.2571581023967338, 1.2415891178624185, 1.2246249994199596, 1.212237002973805, 1.2042409126648683, 1.1916115907485596, 1.1863537687576844, 1.184361952459645, 1.174552224442094, 1.174100297486376, 1.1642387294339274, 1.1667579309734888, 1.1498125688824243, 1.1528519774247745, 1.1458104632660477, 1.1422219283595114, 1.1395967436696819, 1.1425388093462927, 1.1361996432344517, 1.1343642648809658, 1.1366850357495233, 1.1384467574541937, 1.1297091342404275, 1.1274025938315, 1.1304469846771332, 1.1232408899104667], 'val_losses': [1.6134867601394653, 1.5129009218215943, 1.4681510577201844, 1.4527276873588562, 1.448192677974701, 1.4178797907829284, 1.4105008125305176, 1.3997100720405578, 1.3865961327552796, 1.4049304442405701, 1.4268027482032777, 1.4283877582550049, 1.3832031579017638, 1.4029226808547974, 1.412142822265625, 1.405710608959198, 1.4264767122268678, 1.412469033241272, 1.4087248663902283, 1.4089937558174133, 1.4373110976219177, 1.4411704654693605, 1.4231146473884582, 1.4181067342758178, 1.4184692721366883, 1.4412587070465088, 1.4347121257781983, 1.419462882041931, 1.4282210416793824, 1.444068063735962, 1.4446420407295226, 1.4454513168334961, 1.4278343467712402, 1.4515864143371582, 1.4373837399482727, 1.465929394721985], 'val_acc': [0.5008144378662109, 0.5181055068969727, 0.5375266075134277, 0.6434030532836914, 0.6768575310707092, 0.7665706276893616, 0.7222152352333069, 0.7952637672424316, 0.8061646223068237, 0.7867435216903687, 0.8402456045150757, 0.8196967840194702, 0.8143090009689331, 0.840120255947113, 0.8445057272911072, 0.8698158264160156, 0.870442271232605, 0.8753288984298706, 0.8800902366638184, 0.8976318836212158, 0.8942488431930542, 0.9139205813407898, 0.9067785739898682, 0.9105375409126282, 0.9046485424041748, 0.9119157791137695, 0.9045232534408569, 0.9168024063110352, 0.9210625290870667, 0.9120410680770874, 0.9260744452476501, 0.918431282043457, 0.9201854467391968, 0.9145470261573792, 0.9208119511604309, 0.9214383959770203], 'val_macro_f1': [0.43667419254779816, 0.491896690428257, 0.5030752956867218, 0.5437196791172028, 0.5588618218898773, 0.6129891246557235, 0.5891941666603089, 0.6340827792882919, 0.6401800453662873, 0.6232280969619751, 0.6702560156583786, 0.642574542760849, 0.6397718846797943, 0.6671832442283631, 0.6692687809467316, 0.6942597270011902, 0.6867041468620301, 0.6873122870922088, 0.7051338076591491, 0.7235257089138031, 0.7117404878139496, 0.7434147953987121, 0.7285228967666626, 0.7404984533786774, 0.7279911041259766, 0.7435621976852417, 0.7350517690181733, 0.7464738190174103, 0.7514722049236298, 0.738233494758606, 0.7585810482501983, 0.7447345554828644, 0.7546682536602021, 0.7450748383998871, 0.7514270424842835, 0.7506838202476501], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0009574111982642528, 'batch_size': 64, 'epochs': 36, 'weight_decay': 0.0007974089464670998, 'dropout': 0.1734120111720053, 'stem_channels': 26, 'embed_channels': 46, 'se_reduction': 2, 'd_model': 26, 'num_heads': 2, 'num_layers': 1, 'patch_size': 500, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08633022081366294, 'grad_clip': 0.8487235031002973, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 7}, 'model_parameter_count': 601837, 'model_storage_size_kb': 646.5045898437501, 'model_size_validation': 'FAIL'}
2025-09-29 13:12:05,142 - INFO - _models.training_function_executor - BO Objective: base=0.9214, size_penalty=0.7627, final=0.1587
2025-09-29 13:12:05,142 - INFO - _models.training_function_executor - Model: 601,837 parameters, 646.5KB (FAIL 256KB limit)
2025-09-29 13:12:05,142 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 69.241s
2025-09-29 13:12:05,248 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1587
2025-09-29 13:12:05,248 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.106s
2025-09-29 13:12:05,248 - INFO - bo.run_bo - Recorded observation #21: hparams={'lr': 0.0009574111982642528, 'batch_size': np.int64(64), 'epochs': np.int64(36), 'weight_decay': 0.0007974089464670998, 'dropout': 0.1734120111720053, 'stem_channels': np.int64(26), 'embed_channels': np.int64(46), 'se_reduction': np.int64(2), 'd_model': np.int64(26), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(500), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08633022081366294, 'grad_clip': 0.8487235031002973, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(7)}, value=0.1587
2025-09-29 13:12:05,248 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 21: {'lr': 0.0009574111982642528, 'batch_size': np.int64(64), 'epochs': np.int64(36), 'weight_decay': 0.0007974089464670998, 'dropout': 0.1734120111720053, 'stem_channels': np.int64(26), 'embed_channels': np.int64(46), 'se_reduction': np.int64(2), 'd_model': np.int64(26), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(500), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08633022081366294, 'grad_clip': 0.8487235031002973, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(7)} -> 0.1587
2025-09-29 13:12:05,249 - INFO - bo.run_bo - ðŸ”BO Trial 22: Using RF surrogate + Expected Improvement
2025-09-29 13:12:05,249 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:12:05,249 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:12:05,249 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:12:05,249 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0009728279743964679, 'batch_size': 256, 'epochs': 46, 'weight_decay': 0.00047570306469398927, 'dropout': 0.1762679532702708, 'stem_channels': 31, 'embed_channels': 40, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07775216999791411, 'grad_clip': 0.9877253361751938, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}
2025-09-29 13:12:05,250 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0009728279743964679, 'batch_size': 256, 'epochs': 46, 'weight_decay': 0.00047570306469398927, 'dropout': 0.1762679532702708, 'stem_channels': 31, 'embed_channels': 40, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07775216999791411, 'grad_clip': 0.9877253361751938, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}
2025-09-29 13:12:56,415 - INFO - _models.training_function_executor - Model: 18,326 parameters, 78.7KB storage
2025-09-29 13:12:56,416 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.8108420782089234, 1.59111674785614, 1.4627107915878297, 1.4159914541244507, 1.3700299043655395, 1.3430411119461059, 1.3096571664810182, 1.2984650106430053, 1.285622031211853, 1.2693569221496581, 1.2622068839073182, 1.254284791469574, 1.2491283884048463, 1.2361695041656495, 1.2322039160728455, 1.22784126329422, 1.2145835990905762, 1.2118521838188172, 1.2039365105628967, 1.2056028232574463, 1.194324981212616, 1.1857501282691956, 1.1876354546546937, 1.183102819442749, 1.1820897974967957, 1.1758947229385377, 1.1749891605377196, 1.1732543158531188, 1.16081685590744, 1.1627230405807496, 1.1530181946754456, 1.1549968228340148, 1.155534246444702, 1.143903609275818, 1.143049919128418, 1.1396012811660767, 1.1389479689598083, 1.1404157452583312, 1.1332993206977844, 1.136399287223816, 1.1328191919326782, 1.1258358888626099, 1.1240187377929687, 1.1214351768493653, 1.1184637246131897, 1.1142560801506043], 'val_losses': [1.665658786892891, 1.4948446601629257, 1.4640337377786636, 1.393558856099844, 1.3873136416077614, 1.3745639249682426, 1.3410852923989296, 1.3507390655577183, 1.3123334757983685, 1.3224680088460445, 1.3061474300920963, 1.3136287666857243, 1.288195390254259, 1.2825215123593807, 1.290755107998848, 1.2716847658157349, 1.323450792580843, 1.271698847413063, 1.2704430855810642, 1.2765054777264595, 1.2713513411581516, 1.252025045454502, 1.258048888295889, 1.2593371346592903, 1.2685112431645393, 1.2555738650262356, 1.241451509296894, 1.2348697707057, 1.2596322558820248, 1.2476076036691666, 1.2531442679464817, 1.2337761372327805, 1.226723749190569, 1.2377415485680103, 1.2310563251376152, 1.2197417877614498, 1.2369069419801235, 1.2193524204194546, 1.24974025785923, 1.2256534583866596, 1.2663861475884914, 1.222860798239708, 1.2429522536695004, 1.2294702641665936, 1.225481539964676, 1.248179618269205], 'val_acc': [0.3153740167617798, 0.4387921392917633, 0.41924571990966797, 0.6322516202926636, 0.6640771627426147, 0.6429018974304199, 0.7347450256347656, 0.7017917633056641, 0.6974063515663147, 0.6710938215255737, 0.7348703145980835, 0.7006641030311584, 0.775592029094696, 0.7757173180580139, 0.7728354930877686, 0.7009146809577942, 0.7921313047409058, 0.8029069304466248, 0.7308607697486877, 0.7876206040382385, 0.7872446775436401, 0.7342438101768494, 0.8366119265556335, 0.8254604935646057, 0.7296078205108643, 0.7947625517845154, 0.7608069181442261, 0.8427515625953674, 0.8094223737716675, 0.8234556913375854, 0.7782232761383057, 0.8544042110443115, 0.7772209048271179, 0.8128054141998291, 0.7898759841918945, 0.7817316055297852, 0.8768324851989746, 0.8337301015853882, 0.8762059807777405, 0.8654304146766663, 0.8392431735992432, 0.8376143574714661, 0.8775842785835266, 0.864177405834198, 0.8655557036399841, 0.9225661158561707], 'val_macro_f1': [0.32103887051343916, 0.43094225525856017, 0.4671059504151344, 0.5415736764669419, 0.5654707014560699, 0.5547321885824203, 0.600430715084076, 0.5924399465322494, 0.5955055832862854, 0.574946928024292, 0.6059516221284866, 0.5855528324842453, 0.6281799435615539, 0.627888759970665, 0.6190352320671082, 0.5921698540449143, 0.6303052961826324, 0.6467455983161926, 0.6088903576135636, 0.6353279829025269, 0.6346642673015594, 0.6120810359716415, 0.6675251424312592, 0.6582224845886231, 0.6077501744031906, 0.6481506735086441, 0.6274046242237091, 0.6765818119049072, 0.6501612961292267, 0.6670155346393585, 0.6417448610067368, 0.6882732689380646, 0.6421829402446747, 0.6541551053524017, 0.6510759770870209, 0.6378353416919709, 0.7091608166694641, 0.6757749557495117, 0.7089114844799042, 0.7003410458564758, 0.685041406750679, 0.6790677964687347, 0.7076854884624482, 0.6968378841876983, 0.702116322517395, 0.7726110517978668], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0009728279743964679, 'batch_size': 256, 'epochs': 46, 'weight_decay': 0.00047570306469398927, 'dropout': 0.1762679532702708, 'stem_channels': 31, 'embed_channels': 40, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07775216999791411, 'grad_clip': 0.9877253361751938, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}, 'model_parameter_count': 18326, 'model_storage_size_kb': 78.74453125000001, 'model_size_validation': 'PASS'}
2025-09-29 13:12:56,416 - INFO - _models.training_function_executor - BO Objective: base=0.9226, size_penalty=0.0000, final=0.9226
2025-09-29 13:12:56,416 - INFO - _models.training_function_executor - Model: 18,326 parameters, 78.7KB (PASS 256KB limit)
2025-09-29 13:12:56,416 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 51.167s
2025-09-29 13:12:56,522 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9226
2025-09-29 13:12:56,523 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-09-29 13:12:56,523 - INFO - bo.run_bo - Recorded observation #22: hparams={'lr': 0.0009728279743964679, 'batch_size': np.int64(256), 'epochs': np.int64(46), 'weight_decay': 0.00047570306469398927, 'dropout': 0.1762679532702708, 'stem_channels': np.int64(31), 'embed_channels': np.int64(40), 'se_reduction': np.int64(8), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(20), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07775216999791411, 'grad_clip': 0.9877253361751938, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(11)}, value=0.9226
2025-09-29 13:12:56,523 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 22: {'lr': 0.0009728279743964679, 'batch_size': np.int64(256), 'epochs': np.int64(46), 'weight_decay': 0.00047570306469398927, 'dropout': 0.1762679532702708, 'stem_channels': np.int64(31), 'embed_channels': np.int64(40), 'se_reduction': np.int64(8), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(20), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.07775216999791411, 'grad_clip': 0.9877253361751938, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(11)} -> 0.9226
2025-09-29 13:12:56,523 - INFO - bo.run_bo - ðŸ”BO Trial 23: Using RF surrogate + Expected Improvement
2025-09-29 13:12:56,523 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:12:56,523 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:12:56,523 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:12:56,523 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002441222965902701, 'batch_size': 128, 'epochs': 40, 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': 29, 'embed_channels': 32, 'se_reduction': 2, 'd_model': 29, 'num_heads': 2, 'num_layers': 1, 'patch_size': 10, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 9}
2025-09-29 13:12:56,524 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002441222965902701, 'batch_size': 128, 'epochs': 40, 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': 29, 'embed_channels': 32, 'se_reduction': 2, 'd_model': 29, 'num_heads': 2, 'num_layers': 1, 'patch_size': 10, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 9}
2025-09-29 13:13:53,057 - INFO - _models.training_function_executor - Model: 11,960 parameters, 12.8KB storage
2025-09-29 13:13:53,057 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7452789511680603, 0.5419625388383865, 0.49558185732364657, 0.476866508603096, 0.4615834630727768, 0.4490930755138397, 0.4395703754425049, 0.43110024774074557, 0.4263309063911438, 0.42030450320243834, 0.41739421904087065, 0.4128816879987717, 0.41040155708789827, 0.4080392497777939, 0.4040216442346573, 0.40091040885448453, 0.39878608405590055, 0.3964552022218704, 0.3967699508666992, 0.3914999886751175, 0.3906887984275818, 0.38656157290935517, 0.38449260556697845, 0.3878355996608734, 0.3815317693948746, 0.3819207322597504, 0.3792733486890793, 0.3765407929420471, 0.3761066497564316, 0.3739303560256958, 0.3749314342737198, 0.3714591661691666, 0.37082490265369417, 0.3695266370773315, 0.36900211238861086, 0.3668886009454727, 0.36719873797893526, 0.36698207032680513, 0.3652229892015457, 0.3640089693069458], 'val_losses': [0.6023627283081175, 0.531005012610602, 0.4905250233317178, 0.4869891892349909, 0.4779425717535473, 0.4602754532344758, 0.4560437874188499, 0.4409463954350305, 0.4532822427295503, 0.42642809521584285, 0.43111276390060543, 0.42175181091777864, 0.41983296615736826, 0.4216289122899373, 0.420841090735935, 0.4223670808095781, 0.4209026765255701, 0.4167063841744075, 0.40811342284792945, 0.4162412101314181, 0.4049524669609373, 0.40861601583541385, 0.4145018042079986, 0.4068091100170499, 0.4107845335725754, 0.40813417519841877, 0.40767076564213584, 0.4033194993223463, 0.40150860377720426, 0.4062275006657555, 0.4074639285367633, 0.3964114288489024, 0.39990247857002986, 0.395958249531095, 0.3982678798456041, 0.39621688591109383, 0.3972018034685226, 0.38836560268250725, 0.39296745970135644, 0.3997441085558089], 'val_acc': [0.887482762336731, 0.915424108505249, 0.9312116503715515, 0.9337176084518433, 0.9376018047332764, 0.9398571848869324, 0.9439919590950012, 0.9473749995231628, 0.9469991326332092, 0.9537652134895325, 0.9518857002258301, 0.9553940892219543, 0.9541410803794861, 0.9553940892219543, 0.9552687406539917, 0.9562711715698242, 0.9573988318443298, 0.9605312347412109, 0.9604059457778931, 0.9602806568145752, 0.9607818722724915, 0.9611577391624451, 0.9609071612358093, 0.9596541523933411, 0.9611577391624451, 0.9604059457778931, 0.9622853994369507, 0.9665455222129822, 0.9646660685539246, 0.9614083170890808, 0.963538408279419, 0.9646660685539246, 0.9659190773963928, 0.9688009023666382, 0.9684250354766846, 0.9670467376708984, 0.9662949442863464, 0.9706803560256958, 0.9688009023666382, 0.9662949442863464], 'val_macro_f1': [0.510217809677124, 0.6430746078491211, 0.6854168951511384, 0.6742174863815308, 0.7354345619678497, 0.755920660495758, 0.7529542088508606, 0.7448364198207855, 0.7341663688421249, 0.8114537000656128, 0.7585120737552643, 0.8055981397628784, 0.8086058139801026, 0.793714439868927, 0.8008172512054443, 0.8024882316589356, 0.8026523768901825, 0.8230608582496644, 0.8263256192207337, 0.8341742396354676, 0.8327261328697204, 0.8349452376365661, 0.8417848944664001, 0.8294855713844299, 0.8496503710746766, 0.846640121936798, 0.8521074533462525, 0.8581888556480408, 0.8616563200950622, 0.8478744864463806, 0.8583780646324157, 0.8352632999420166, 0.8634233355522156, 0.871524167060852, 0.8688308358192444, 0.8607638478279114, 0.8437065243721008, 0.8742310166358948, 0.8564311861991882, 0.8686591386795044], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002441222965902701, 'batch_size': 128, 'epochs': 40, 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': 29, 'embed_channels': 32, 'se_reduction': 2, 'd_model': 29, 'num_heads': 2, 'num_layers': 1, 'patch_size': 10, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 9}, 'model_parameter_count': 11960, 'model_storage_size_kb': 12.847656250000002, 'model_size_validation': 'PASS'}
2025-09-29 13:13:53,057 - INFO - _models.training_function_executor - BO Objective: base=0.9663, size_penalty=0.0000, final=0.9663
2025-09-29 13:13:53,057 - INFO - _models.training_function_executor - Model: 11,960 parameters, 12.8KB (PASS 256KB limit)
2025-09-29 13:13:53,057 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 56.535s
2025-09-29 13:13:53,164 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9663
2025-09-29 13:13:53,164 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.106s
2025-09-29 13:13:53,164 - INFO - bo.run_bo - Recorded observation #23: hparams={'lr': 0.002441222965902701, 'batch_size': np.int64(128), 'epochs': np.int64(40), 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': np.int64(29), 'embed_channels': np.int64(32), 'se_reduction': np.int64(2), 'd_model': np.int64(29), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(10), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(9)}, value=0.9663
2025-09-29 13:13:53,164 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 23: {'lr': 0.002441222965902701, 'batch_size': np.int64(128), 'epochs': np.int64(40), 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': np.int64(29), 'embed_channels': np.int64(32), 'se_reduction': np.int64(2), 'd_model': np.int64(29), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(10), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(9)} -> 0.9663
2025-09-29 13:13:53,164 - INFO - bo.run_bo - ðŸ”BO Trial 24: Using RF surrogate + Expected Improvement
2025-09-29 13:13:53,164 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:13:53,164 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:13:53,164 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:13:53,164 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.008380305622321841, 'batch_size': 512, 'epochs': 33, 'weight_decay': 0.00042693533987786433, 'dropout': 0.14038269635421927, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 38, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09717715409256815, 'grad_clip': 0.1539531873883793, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 3}
2025-09-29 13:13:53,165 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.008380305622321841, 'batch_size': 512, 'epochs': 33, 'weight_decay': 0.00042693533987786433, 'dropout': 0.14038269635421927, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 38, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09717715409256815, 'grad_clip': 0.1539531873883793, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 3}
2025-09-29 13:14:29,977 - INFO - _models.training_function_executor - Model: 342,503 parameters, 1471.7KB storage
2025-09-29 13:14:29,977 - WARNING - _models.training_function_executor - Model storage 1471.7KB exceeds 256KB limit!
2025-09-29 13:14:29,977 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.921634610683199, 0.6647077146030608, 0.5731969712272523, 0.5370353706299312, 0.5181352742134578, 0.508441815773646, 0.49680285605173263, 0.4872978372233255, 0.47992910137252204, 0.4707341988881429, 0.46522818103669183, 0.46199816181546166, 0.45307611236496576, 0.4514303500690157, 0.44592019442528014, 0.4413841281618391, 0.43740671683871557, 0.4366447428862254, 0.4334784911738502, 0.4290641702356793, 0.4264619009835379, 0.4254162150716025, 0.42348947789933944, 0.4203049583094461, 0.4179925142772614, 0.4172804786099328, 0.41497604619889034, 0.41283997372975423, 0.4097698699860346, 0.4091299483700404, 0.40880317536611405, 0.4066028500360156, 0.40652794308132595], 'val_losses': [0.7611154243350029, 0.6070999279618263, 0.5516744628548622, 0.5413011088967323, 0.5219969339668751, 0.5130512975156307, 0.5058926232159138, 0.5053560677915812, 0.5039098151028156, 0.4972681887447834, 0.5021879803389311, 0.5038040708750486, 0.49095829017460346, 0.4990189950913191, 0.5013535264879465, 0.5060765724629164, 0.5132547058165073, 0.5041412562131882, 0.5016662273555994, 0.510263105854392, 0.5052928254008293, 0.50629479624331, 0.5063117891550064, 0.508768904954195, 0.5190371796488762, 0.5020225085318089, 0.5045217163860798, 0.5060147922486067, 0.5105696581304073, 0.5190950408577919, 0.5109472274780273, 0.5198789872229099, 0.5090679805725813], 'val_acc': [0.8337301015853882, 0.9020172953605652, 0.9305851459503174, 0.9344693422317505, 0.9391053915023804, 0.9437413811683655, 0.9481267929077148, 0.9498809576034546, 0.9507580399513245, 0.9522616267204285, 0.9527627825737, 0.9510086178779602, 0.958025336265564, 0.9501315355300903, 0.9531387090682983, 0.9513845443725586, 0.9507580399513245, 0.9508833289146423, 0.9516351222991943, 0.9497556686401367, 0.9537652134895325, 0.9543916583061218, 0.9525122046470642, 0.9500062465667725, 0.9507580399513245, 0.9533892869949341, 0.9553940892219543, 0.9531387090682983, 0.9510086178779602, 0.9521363377571106, 0.9496303796768188, 0.9485027194023132, 0.9533892869949341], 'val_macro_f1': [0.4530907154083252, 0.6398290179669857, 0.6812013864517212, 0.6901564776897431, 0.7303756952285767, 0.7618725597858429, 0.7604083120822906, 0.7661880910396576, 0.790482348203659, 0.8009019494056702, 0.8092323303222656, 0.7827656626701355, 0.8306158304214477, 0.805321991443634, 0.7982356131076813, 0.795505577325821, 0.7880450904369354, 0.7845867335796356, 0.7956226706504822, 0.800068324804306, 0.798893666267395, 0.8118133544921875, 0.7904677867889405, 0.7999560594558716, 0.7914500176906586, 0.7904572904109954, 0.8131764888763428, 0.8026845633983613, 0.7856387674808503, 0.8003493845462799, 0.7988749384880066, 0.787317442893982, 0.8044391334056854], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.008380305622321841, 'batch_size': 512, 'epochs': 33, 'weight_decay': 0.00042693533987786433, 'dropout': 0.14038269635421927, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 38, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09717715409256815, 'grad_clip': 0.1539531873883793, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 3}, 'model_parameter_count': 342503, 'model_storage_size_kb': 1471.6925781250002, 'model_size_validation': 'FAIL'}
2025-09-29 13:14:29,977 - INFO - _models.training_function_executor - BO Objective: base=0.9534, size_penalty=0.8000, final=0.1534
2025-09-29 13:14:29,977 - INFO - _models.training_function_executor - Model: 342,503 parameters, 1471.7KB (FAIL 256KB limit)
2025-09-29 13:14:29,977 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 36.813s
2025-09-29 13:14:30,202 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1534
2025-09-29 13:14:30,202 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.225s
2025-09-29 13:14:30,202 - INFO - bo.run_bo - Recorded observation #24: hparams={'lr': 0.008380305622321841, 'batch_size': np.int64(512), 'epochs': np.int64(33), 'weight_decay': 0.00042693533987786433, 'dropout': 0.14038269635421927, 'stem_channels': np.int64(29), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(38), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09717715409256815, 'grad_clip': 0.1539531873883793, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(3)}, value=0.1534
2025-09-29 13:14:30,202 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 24: {'lr': 0.008380305622321841, 'batch_size': np.int64(512), 'epochs': np.int64(33), 'weight_decay': 0.00042693533987786433, 'dropout': 0.14038269635421927, 'stem_channels': np.int64(29), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(38), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09717715409256815, 'grad_clip': 0.1539531873883793, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(3)} -> 0.1534
2025-09-29 13:14:30,203 - INFO - bo.run_bo - ðŸ”BO Trial 25: Using RF surrogate + Expected Improvement
2025-09-29 13:14:30,203 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:14:30,203 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:14:30,203 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:14:30,203 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001609180694072096, 'batch_size': 64, 'epochs': 42, 'weight_decay': 5.8389793725520306e-05, 'dropout': 0.1512908772052959, 'stem_channels': 29, 'embed_channels': 42, 'se_reduction': 8, 'd_model': 32, 'num_heads': 2, 'num_layers': 1, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0884563045887561, 'grad_clip': 0.38173091069048803, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 12}
2025-09-29 13:14:30,204 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001609180694072096, 'batch_size': 64, 'epochs': 42, 'weight_decay': 5.8389793725520306e-05, 'dropout': 0.1512908772052959, 'stem_channels': 29, 'embed_channels': 42, 'se_reduction': 8, 'd_model': 32, 'num_heads': 2, 'num_layers': 1, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0884563045887561, 'grad_clip': 0.38173091069048803, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 12}
2025-09-29 13:15:34,221 - INFO - _models.training_function_executor - Model: 64,636 parameters, 277.7KB storage
2025-09-29 13:15:34,221 - WARNING - _models.training_function_executor - Model storage 277.7KB exceeds 256KB limit!
2025-09-29 13:15:34,222 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.754973905239411, 0.5588149256959468, 0.5138508694802592, 0.4930964415680192, 0.4804442447865893, 0.472057290569336, 0.4613202195129318, 0.45491150057387497, 0.4493901933242897, 0.4416166674159094, 0.43674687650017363, 0.43144456752555405, 0.4281992916473167, 0.4241293450156768, 0.4199370683911807, 0.4169203998569496, 0.41256864073281296, 0.40983571306259214, 0.4064610520441212, 0.40392883053284606, 0.4003595347275476, 0.397986685823582, 0.39526730978895047, 0.3931413394415785, 0.3905553176909506, 0.38842426106064976, 0.38654636846993395, 0.38466201200036104, 0.38257718779042155, 0.3805820820087899, 0.37910537251489673, 0.37774445346457686, 0.37702449541053695, 0.37511561539225685, 0.37440757940192976, 0.37373335298173177, 0.3731774755255254, 0.37257470139759574, 0.3722633252401868, 0.37175114515549196, 0.37147029296668593, 0.3714197831067867], 'val_losses': [0.5931255648136139, 0.5277759473323822, 0.5092322220802307, 0.5029916231632232, 0.4924579174518585, 0.47645974612236025, 0.4749579598903656, 0.46553544664382934, 0.4666427385807037, 0.4675561881065369, 0.46011630129814146, 0.4595748243331909, 0.4635392246246338, 0.4606233468055725, 0.4629805188179016, 0.46026474475860596, 0.46066708135604856, 0.4531463379859924, 0.4508802466392517, 0.4726402087211609, 0.46725470495224, 0.468002907037735, 0.46707268166542054, 0.4632822592258453, 0.46268515682220457, 0.4604874680042267, 0.4604433624744415, 0.46621517300605775, 0.4597735257148743, 0.4641067183017731, 0.4652576913833618, 0.4684586997032166, 0.4668293650150299, 0.4723450198173523, 0.467323260307312, 0.4694623885154724, 0.46786902594566343, 0.46863273477554324, 0.46905543994903565, 0.4694008116722107, 0.4694934277534485, 0.4694525723457336], 'val_acc': [0.9032702445983887, 0.9314622282981873, 0.9423630833625793, 0.9452449679374695, 0.948001503944397, 0.9515098333358765, 0.9526374936103821, 0.9562711715698242, 0.9545170068740845, 0.9537652134895325, 0.955769956111908, 0.9576494097709656, 0.9566470384597778, 0.9581506252288818, 0.9594035744667053, 0.9597795009613037, 0.9566470384597778, 0.9614083170890808, 0.9617842435836792, 0.9584012031555176, 0.9600300788879395, 0.958025336265564, 0.9597795009613037, 0.9621601104736328, 0.9617842435836792, 0.9626613259315491, 0.9627866148948669, 0.9606565833091736, 0.9646660685539246, 0.9621601104736328, 0.9625360369682312, 0.9624107480049133, 0.9604059457778931, 0.9591529965400696, 0.9629119038581848, 0.9620348215103149, 0.9627866148948669, 0.9615336656570435, 0.9619095325469971, 0.9619095325469971, 0.9621601104736328, 0.9624107480049133], 'val_macro_f1': [0.6351923823356629, 0.6854893237352371, 0.7249074339866638, 0.723136481642723, 0.7649704873561859, 0.7898787558078766, 0.7934664070606232, 0.8058234214782715, 0.7955203890800476, 0.8004873991012573, 0.8200909495353699, 0.808820766210556, 0.7965607702732086, 0.8219628930091858, 0.825852346420288, 0.8126852154731751, 0.8372822165489197, 0.8361538767814636, 0.8454414486885071, 0.8086524546146393, 0.8246041893959045, 0.8300797343254089, 0.8324970126152038, 0.8489440560340882, 0.833779489994049, 0.8428393483161927, 0.8456011652946472, 0.8332818388938904, 0.8443955421447754, 0.8397395372390747, 0.8455531358718872, 0.8430149674415588, 0.8415084958076477, 0.8383265018463135, 0.8463022351264954, 0.8428099393844605, 0.8451891660690307, 0.8413004279136658, 0.8417583346366883, 0.8435022830963135, 0.8440897703170777, 0.8443912744522095], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001609180694072096, 'batch_size': 64, 'epochs': 42, 'weight_decay': 5.8389793725520306e-05, 'dropout': 0.1512908772052959, 'stem_channels': 29, 'embed_channels': 42, 'se_reduction': 8, 'd_model': 32, 'num_heads': 2, 'num_layers': 1, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0884563045887561, 'grad_clip': 0.38173091069048803, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 12}, 'model_parameter_count': 64636, 'model_storage_size_kb': 277.7328125, 'model_size_validation': 'FAIL'}
2025-09-29 13:15:34,222 - INFO - _models.training_function_executor - BO Objective: base=0.9624, size_penalty=0.0424, final=0.9200
2025-09-29 13:15:34,222 - INFO - _models.training_function_executor - Model: 64,636 parameters, 277.7KB (FAIL 256KB limit)
2025-09-29 13:15:34,222 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 64.019s
2025-09-29 13:15:34,330 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9200
2025-09-29 13:15:34,330 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-09-29 13:15:34,330 - INFO - bo.run_bo - Recorded observation #25: hparams={'lr': 0.001609180694072096, 'batch_size': np.int64(64), 'epochs': np.int64(42), 'weight_decay': 5.8389793725520306e-05, 'dropout': 0.1512908772052959, 'stem_channels': np.int64(29), 'embed_channels': np.int64(42), 'se_reduction': np.int64(8), 'd_model': np.int64(32), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(40), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0884563045887561, 'grad_clip': 0.38173091069048803, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(12)}, value=0.9200
2025-09-29 13:15:34,330 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 25: {'lr': 0.001609180694072096, 'batch_size': np.int64(64), 'epochs': np.int64(42), 'weight_decay': 5.8389793725520306e-05, 'dropout': 0.1512908772052959, 'stem_channels': np.int64(29), 'embed_channels': np.int64(42), 'se_reduction': np.int64(8), 'd_model': np.int64(32), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(40), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0884563045887561, 'grad_clip': 0.38173091069048803, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(12)} -> 0.9200
2025-09-29 13:15:34,330 - INFO - bo.run_bo - ðŸ”BO Trial 26: Using RF surrogate + Expected Improvement
2025-09-29 13:15:34,330 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:15:34,330 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:15:34,330 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:15:34,330 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0025449551542547867, 'batch_size': 512, 'epochs': 38, 'weight_decay': 1.459176606621144e-06, 'dropout': 0.12516817927641785, 'stem_channels': 32, 'embed_channels': 32, 'se_reduction': 4, 'd_model': 27, 'num_heads': 2, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0928316343196925, 'grad_clip': 0.622992700095102, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 2}
2025-09-29 13:15:34,332 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0025449551542547867, 'batch_size': 512, 'epochs': 38, 'weight_decay': 1.459176606621144e-06, 'dropout': 0.12516817927641785, 'stem_channels': 32, 'embed_channels': 32, 'se_reduction': 4, 'd_model': 27, 'num_heads': 2, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0928316343196925, 'grad_clip': 0.622992700095102, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 2}
2025-09-29 13:16:07,442 - INFO - _models.training_function_executor - Model: 218,074 parameters, 234.3KB storage
2025-09-29 13:16:07,442 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9832655749623738, 0.7624575883623154, 0.6272127704014854, 0.5682624843385484, 0.5438773982108586, 0.5262593787813944, 0.5123171257594276, 0.5029313133822547, 0.49182864124812775, 0.4828281809413244, 0.47773323125309414, 0.4699162112341987, 0.4641162109753442, 0.4601670153557308, 0.4518771493245685, 0.44838383699220324, 0.44517632940458873, 0.4374682217363327, 0.43444311571499655, 0.4301106362115769, 0.4269174829361931, 0.42284382477639215, 0.4205501798599485, 0.418337551374284, 0.4157612068312509, 0.41401486027808415, 0.41025484317824956, 0.4088993649634104, 0.40531072162446524, 0.4043437980470203, 0.40161951903312926, 0.4006072155066899, 0.3988080563999358, 0.3991886429370396, 0.3979117397278074, 0.3946155049498119, 0.3934627851796529, 0.39143727175773135], 'val_losses': [0.8883640021085739, 0.6818908154964447, 0.5983322747051716, 0.5749227218329906, 0.5442552790045738, 0.5348582528531551, 0.5333248898386955, 0.5203668959438801, 0.5213501304388046, 0.508768692612648, 0.5180058889091015, 0.5179431457072496, 0.5206558294594288, 0.508400484919548, 0.5027352515608072, 0.5145155731588602, 0.5081222355365753, 0.5161799769848585, 0.516644936054945, 0.5101667512208223, 0.5058326534926891, 0.5056605730205774, 0.5126731060445309, 0.5141078643500805, 0.511549225077033, 0.5109124425798655, 0.508309680968523, 0.5140232183039188, 0.5107156969606876, 0.5110348053276539, 0.515337135642767, 0.510820496827364, 0.5161901451647282, 0.5199880488216877, 0.5131615903228521, 0.5114638637751341, 0.521183405071497, 0.5122512243688107], 'val_acc': [0.7669464945793152, 0.8668086528778076, 0.9010149240493774, 0.9112893342971802, 0.9250720739364624, 0.9278286099433899, 0.9313369393348694, 0.9352211356163025, 0.933968186378479, 0.9419872164726257, 0.9378523826599121, 0.9383535981178284, 0.9365994334220886, 0.9428642988204956, 0.9441173076629639, 0.9381030201911926, 0.9442425966262817, 0.9411101341247559, 0.9411101341247559, 0.9428642988204956, 0.9451196789741516, 0.9463726282119751, 0.9434908032417297, 0.9443678855895996, 0.9485027194023132, 0.9437413811683655, 0.9482520818710327, 0.9444931745529175, 0.9446184635162354, 0.9473749995231628, 0.9447437524795532, 0.9461220502853394, 0.9469991326332092, 0.9453702569007874, 0.9481267929077148, 0.9475002884864807, 0.9447437524795532, 0.9477509260177612], 'val_macro_f1': [0.36355937123298643, 0.49824090451002123, 0.6024978578090667, 0.6563565254211425, 0.708087506890297, 0.6951021939516068, 0.7000701993703842, 0.7347136795520782, 0.7009365677833557, 0.7548260629177094, 0.7351557672023773, 0.7686943531036377, 0.6957818508148194, 0.7744316995143891, 0.772600793838501, 0.7580612063407898, 0.764958655834198, 0.7670337438583374, 0.7403215765953064, 0.7650419116020203, 0.762379264831543, 0.778674590587616, 0.7640282809734344, 0.7427782654762268, 0.7658168733119964, 0.765953803062439, 0.7767420291900635, 0.7749393880367279, 0.7669523000717163, 0.7760029733181, 0.7613654613494873, 0.7694324433803559, 0.7803314805030823, 0.7654369473457336, 0.7797247111797333, 0.7788507163524627, 0.7644922614097596, 0.777164512872696], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0025449551542547867, 'batch_size': 512, 'epochs': 38, 'weight_decay': 1.459176606621144e-06, 'dropout': 0.12516817927641785, 'stem_channels': 32, 'embed_channels': 32, 'se_reduction': 4, 'd_model': 27, 'num_heads': 2, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0928316343196925, 'grad_clip': 0.622992700095102, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 2}, 'model_parameter_count': 218074, 'model_storage_size_kb': 234.25917968750002, 'model_size_validation': 'PASS'}
2025-09-29 13:16:07,442 - INFO - _models.training_function_executor - BO Objective: base=0.9478, size_penalty=0.0000, final=0.9478
2025-09-29 13:16:07,442 - INFO - _models.training_function_executor - Model: 218,074 parameters, 234.3KB (PASS 256KB limit)
2025-09-29 13:16:07,442 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 33.112s
2025-09-29 13:16:07,667 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9478
2025-09-29 13:16:07,668 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.225s
2025-09-29 13:16:07,668 - INFO - bo.run_bo - Recorded observation #26: hparams={'lr': 0.0025449551542547867, 'batch_size': np.int64(512), 'epochs': np.int64(38), 'weight_decay': 1.459176606621144e-06, 'dropout': 0.12516817927641785, 'stem_channels': np.int64(32), 'embed_channels': np.int64(32), 'se_reduction': np.int64(4), 'd_model': np.int64(27), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0928316343196925, 'grad_clip': 0.622992700095102, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(2)}, value=0.9478
2025-09-29 13:16:07,668 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 26: {'lr': 0.0025449551542547867, 'batch_size': np.int64(512), 'epochs': np.int64(38), 'weight_decay': 1.459176606621144e-06, 'dropout': 0.12516817927641785, 'stem_channels': np.int64(32), 'embed_channels': np.int64(32), 'se_reduction': np.int64(4), 'd_model': np.int64(27), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0928316343196925, 'grad_clip': 0.622992700095102, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(2)} -> 0.9478
2025-09-29 13:16:07,668 - INFO - bo.run_bo - ðŸ”BO Trial 27: Using RF surrogate + Expected Improvement
2025-09-29 13:16:07,668 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:16:07,668 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:16:07,668 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:16:07,668 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.005393798624382209, 'batch_size': 512, 'epochs': 42, 'weight_decay': 6.524072165854006e-06, 'dropout': 0.07612295363855716, 'stem_channels': 30, 'embed_channels': 38, 'se_reduction': 8, 'd_model': 18, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.056195345756988, 'grad_clip': 0.12343196562367734, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 4}
2025-09-29 13:16:07,669 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.005393798624382209, 'batch_size': 512, 'epochs': 42, 'weight_decay': 6.524072165854006e-06, 'dropout': 0.07612295363855716, 'stem_channels': 30, 'embed_channels': 38, 'se_reduction': 8, 'd_model': 18, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.056195345756988, 'grad_clip': 0.12343196562367734, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 4}
2025-09-29 13:16:44,876 - INFO - _models.training_function_executor - Model: 73,155 parameters, 314.3KB storage
2025-09-29 13:16:44,876 - WARNING - _models.training_function_executor - Model storage 314.3KB exceeds 256KB limit!
2025-09-29 13:16:44,876 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9102977315584818, 0.6388689435663677, 0.49634072704920695, 0.44264183205271523, 0.4171596983122447, 0.3981495125899239, 0.38412164459152826, 0.3738501587557414, 0.36429910953082734, 0.3553462615088811, 0.34776612359379966, 0.342858103059587, 0.3364129586825295, 0.3291484330381666, 0.32387220291864305, 0.3201332503841037, 0.3161861168013679, 0.31054135305540903, 0.3082963195112016, 0.30258873767322964, 0.30029017726580304, 0.296923177582877, 0.29340902207389713, 0.2903230403150831, 0.2876309213184175, 0.28485723336537677, 0.28220952739791266, 0.28014500888567123, 0.27821333966557943, 0.27580698804249837, 0.27473085645645384, 0.27260084142760627, 0.27201120200611295, 0.27050841233086964, 0.2696822654633295, 0.2682370557671502, 0.2676603278470418, 0.2674927408733065, 0.2668854849679129, 0.26668356524573433, 0.2664379912709433, 0.26609285909032065], 'val_losses': [0.7811178416013718, 0.5558131635189056, 0.46527514420449734, 0.4360365495085716, 0.42100766114890575, 0.4207031484693289, 0.3849569000303745, 0.38380808010697365, 0.3838960751891136, 0.3767991829663515, 0.37817735224962234, 0.37192763201892376, 0.3692520372569561, 0.3696250095963478, 0.3745036143809557, 0.3661103490740061, 0.3620356824249029, 0.360770296305418, 0.3631732575595379, 0.36815469339489937, 0.3641164433211088, 0.3687812201678753, 0.37138977088034153, 0.3724040724337101, 0.36666697077453136, 0.3730903137475252, 0.3702150844037533, 0.3713532369583845, 0.3734565246850252, 0.3760759551078081, 0.3744957521557808, 0.37492154724895954, 0.3747240509837866, 0.37835060618817806, 0.37934152223169804, 0.3811387922614813, 0.38203248009085655, 0.38053048215806484, 0.380904795601964, 0.38106107898056507, 0.38058329932391644, 0.3807420264929533], 'val_acc': [0.7953890562057495, 0.8844756484031677, 0.9214383959770203, 0.9298333525657654, 0.9340934753417969, 0.9386041760444641, 0.9461220502853394, 0.948001503944397, 0.9478762149810791, 0.9493798017501831, 0.9477509260177612, 0.9497556686401367, 0.9531387090682983, 0.9512592554092407, 0.9501315355300903, 0.9546422958374023, 0.9573988318443298, 0.9567723274230957, 0.9556446671485901, 0.9545170068740845, 0.9561458230018616, 0.955018162727356, 0.9571482539176941, 0.9570229053497314, 0.9555193781852722, 0.9567723274230957, 0.9591529965400696, 0.9577746987342834, 0.9567723274230957, 0.9562711715698242, 0.9577746987342834, 0.9577746987342834, 0.9578999876976013, 0.9553940892219543, 0.9560205340385437, 0.957273542881012, 0.9558952450752258, 0.9558952450752258, 0.9562711715698242, 0.9560205340385437, 0.9556446671485901, 0.9556446671485901], 'val_macro_f1': [0.39515420198440554, 0.6203351974487304, 0.673218822479248, 0.6918949209153652, 0.7004716724157334, 0.7264257103204728, 0.751481893658638, 0.7685663342475891, 0.7664929807186127, 0.7889160275459289, 0.7758088409900665, 0.7946198284626007, 0.7844768404960633, 0.7953675568103791, 0.7995151460170746, 0.7987066149711609, 0.8217363834381104, 0.8114922940731049, 0.8073784530162811, 0.8101671814918519, 0.8262806415557862, 0.8214670777320862, 0.812643301486969, 0.8227449893951416, 0.819279944896698, 0.8265058875083924, 0.8355268478393555, 0.8259140372276306, 0.8211274385452271, 0.8144283294677734, 0.8240541696548462, 0.8259539008140564, 0.8238457322120667, 0.8110546946525574, 0.8204310297966003, 0.8218072056770325, 0.8153550624847412, 0.8104403018951416, 0.8151578903198242, 0.8151302695274353, 0.8114388942718506, 0.8115181088447571], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.005393798624382209, 'batch_size': 512, 'epochs': 42, 'weight_decay': 6.524072165854006e-06, 'dropout': 0.07612295363855716, 'stem_channels': 30, 'embed_channels': 38, 'se_reduction': 8, 'd_model': 18, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.056195345756988, 'grad_clip': 0.12343196562367734, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 4}, 'model_parameter_count': 73155, 'model_storage_size_kb': 314.337890625, 'model_size_validation': 'FAIL'}
2025-09-29 13:16:44,876 - INFO - _models.training_function_executor - BO Objective: base=0.9556, size_penalty=0.1139, final=0.8417
2025-09-29 13:16:44,876 - INFO - _models.training_function_executor - Model: 73,155 parameters, 314.3KB (FAIL 256KB limit)
2025-09-29 13:16:44,876 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 37.208s
2025-09-29 13:16:44,986 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8417
2025-09-29 13:16:44,986 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-09-29 13:16:44,986 - INFO - bo.run_bo - Recorded observation #27: hparams={'lr': 0.005393798624382209, 'batch_size': np.int64(512), 'epochs': np.int64(42), 'weight_decay': 6.524072165854006e-06, 'dropout': 0.07612295363855716, 'stem_channels': np.int64(30), 'embed_channels': np.int64(38), 'se_reduction': np.int64(8), 'd_model': np.int64(18), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.056195345756988, 'grad_clip': 0.12343196562367734, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(4)}, value=0.8417
2025-09-29 13:16:44,986 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 27: {'lr': 0.005393798624382209, 'batch_size': np.int64(512), 'epochs': np.int64(42), 'weight_decay': 6.524072165854006e-06, 'dropout': 0.07612295363855716, 'stem_channels': np.int64(30), 'embed_channels': np.int64(38), 'se_reduction': np.int64(8), 'd_model': np.int64(18), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.056195345756988, 'grad_clip': 0.12343196562367734, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(4)} -> 0.8417
2025-09-29 13:16:44,986 - INFO - bo.run_bo - ðŸ”BO Trial 28: Using RF surrogate + Expected Improvement
2025-09-29 13:16:44,986 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:16:44,986 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:16:44,986 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:16:44,986 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0010650364373586037, 'batch_size': 128, 'epochs': 38, 'weight_decay': 0.0004493121723217502, 'dropout': 0.16578265630836655, 'stem_channels': 29, 'embed_channels': 34, 'se_reduction': 8, 'd_model': 18, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08866003229400199, 'grad_clip': 0.9557624168563201, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 14}
2025-09-29 13:16:44,988 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0010650364373586037, 'batch_size': 128, 'epochs': 38, 'weight_decay': 0.0004493121723217502, 'dropout': 0.16578265630836655, 'stem_channels': 29, 'embed_channels': 34, 'se_reduction': 8, 'd_model': 18, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08866003229400199, 'grad_clip': 0.9557624168563201, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 14}
2025-09-29 13:18:08,050 - INFO - _models.training_function_executor - Model: 14,619 parameters, 62.8KB storage
2025-09-29 13:18:08,050 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8408033123016357, 0.6044572352170944, 0.5293356108665467, 0.5033541804552079, 0.48745242750644685, 0.4767197107076645, 0.4700734702348709, 0.4648325023651123, 0.45917235600948336, 0.4507318519353867, 0.4504531503915787, 0.44605998051166534, 0.4420169179439545, 0.43750142550468446, 0.4366329404115677, 0.4339531853199005, 0.43249195408821106, 0.4318050481081009, 0.42725432884693143, 0.4247291054725647, 0.42339814341068266, 0.42217939233779905, 0.42095295488834383, 0.4190662076473236, 0.41930308878421785, 0.4182944638729095, 0.4156314803361893, 0.41639665603637693, 0.413486945271492, 0.4142129951715469, 0.41192174661159514, 0.4105852746963501, 0.41095155048370363, 0.41102316772937775, 0.4078672876358032, 0.40754983270168305, 0.40738197791576386, 0.4049811879396439], 'val_losses': [0.6682596358041915, 0.5732532744369809, 0.523705590338934, 0.5047410447446127, 0.5007654073692503, 0.4915031379177457, 0.5279409237324245, 0.4723984244323912, 0.4755294919013977, 0.467070625414924, 0.4758684715581319, 0.4596516825850048, 0.4652891457080841, 0.45851514973337687, 0.45203580742790583, 0.4599091571474832, 0.4500035776032342, 0.4532660983857654, 0.44997646505870514, 0.4452290804613204, 0.44927600357267594, 0.444065746333864, 0.4651701824059562, 0.44551471821845523, 0.4581108802840823, 0.4420317941241794, 0.4564282562997606, 0.44561140215586104, 0.4456403633904836, 0.4494625571228209, 0.4424529553405822, 0.44422945143684506, 0.44690369802808005, 0.4616163018203917, 0.4422091997805096, 0.44268744143228683, 0.4479437924566723, 0.45892461330171613], 'val_acc': [0.8645533323287964, 0.9163011908531189, 0.9355970621109009, 0.9397318363189697, 0.9428642988204956, 0.9478762149810791, 0.9303345680236816, 0.9531387090682983, 0.9520110487937927, 0.958025336265564, 0.9528881311416626, 0.9570229053497314, 0.9556446671485901, 0.9609071612358093, 0.9617842435836792, 0.9563964605331421, 0.9625360369682312, 0.9619095325469971, 0.9626613259315491, 0.9655431509017944, 0.9621601104736328, 0.9672973155975342, 0.9567723274230957, 0.9649167060852051, 0.9596541523933411, 0.9652925729751587, 0.9611577391624451, 0.9664202332496643, 0.9662949442863464, 0.9621601104736328, 0.9660443663597107, 0.965793788433075, 0.9666708707809448, 0.957273542881012, 0.9664202332496643, 0.9675479531288147, 0.9636636972427368, 0.9616589546203613], 'val_macro_f1': [0.4826458692550659, 0.6556731343269349, 0.738613384962082, 0.7164021492004394, 0.7314948171377182, 0.8042732000350952, 0.76546550989151, 0.8077962279319764, 0.8174970984458924, 0.8355815887451172, 0.8183822751045227, 0.8413885116577149, 0.8335788369178772, 0.8300047636032104, 0.8465698599815369, 0.8378403425216675, 0.8336705207824707, 0.8535246849060059, 0.85171879529953, 0.8588350296020508, 0.8531798720359802, 0.8703278779983521, 0.8473077297210694, 0.8568656206130981, 0.8502711057662964, 0.8515964984893799, 0.8526506781578064, 0.863546884059906, 0.8580166220664978, 0.8310406923294067, 0.8570776462554932, 0.8714852929115295, 0.8726026058197022, 0.8387011885643005, 0.8646426200866699, 0.8730902791023254, 0.85531085729599, 0.8585254430770874], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0010650364373586037, 'batch_size': 128, 'epochs': 38, 'weight_decay': 0.0004493121723217502, 'dropout': 0.16578265630836655, 'stem_channels': 29, 'embed_channels': 34, 'se_reduction': 8, 'd_model': 18, 'num_heads': 4, 'num_layers': 2, 'patch_size': 10, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08866003229400199, 'grad_clip': 0.9557624168563201, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 14}, 'model_parameter_count': 14619, 'model_storage_size_kb': 62.816015625000006, 'model_size_validation': 'PASS'}
2025-09-29 13:18:08,050 - INFO - _models.training_function_executor - BO Objective: base=0.9617, size_penalty=0.0000, final=0.9617
2025-09-29 13:18:08,050 - INFO - _models.training_function_executor - Model: 14,619 parameters, 62.8KB (PASS 256KB limit)
2025-09-29 13:18:08,050 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 83.064s
2025-09-29 13:18:08,160 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9617
2025-09-29 13:18:08,160 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-09-29 13:18:08,160 - INFO - bo.run_bo - Recorded observation #28: hparams={'lr': 0.0010650364373586037, 'batch_size': np.int64(128), 'epochs': np.int64(38), 'weight_decay': 0.0004493121723217502, 'dropout': 0.16578265630836655, 'stem_channels': np.int64(29), 'embed_channels': np.int64(34), 'se_reduction': np.int64(8), 'd_model': np.int64(18), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(10), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08866003229400199, 'grad_clip': 0.9557624168563201, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(14)}, value=0.9617
2025-09-29 13:18:08,160 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 28: {'lr': 0.0010650364373586037, 'batch_size': np.int64(128), 'epochs': np.int64(38), 'weight_decay': 0.0004493121723217502, 'dropout': 0.16578265630836655, 'stem_channels': np.int64(29), 'embed_channels': np.int64(34), 'se_reduction': np.int64(8), 'd_model': np.int64(18), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(10), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08866003229400199, 'grad_clip': 0.9557624168563201, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(14)} -> 0.9617
2025-09-29 13:18:08,160 - INFO - bo.run_bo - ðŸ”BO Trial 29: Using RF surrogate + Expected Improvement
2025-09-29 13:18:08,160 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:18:08,161 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:18:08,161 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:18:08,161 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0031618003590175065, 'batch_size': 128, 'epochs': 28, 'weight_decay': 4.0859852074426746e-05, 'dropout': 0.22613286480637845, 'stem_channels': 29, 'embed_channels': 38, 'se_reduction': 4, 'd_model': 22, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09094181958976948, 'grad_clip': 0.60316924876695, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 10}
2025-09-29 13:18:08,162 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0031618003590175065, 'batch_size': 128, 'epochs': 28, 'weight_decay': 4.0859852074426746e-05, 'dropout': 0.22613286480637845, 'stem_channels': 29, 'embed_channels': 38, 'se_reduction': 4, 'd_model': 22, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09094181958976948, 'grad_clip': 0.60316924876695, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 10}
2025-09-29 13:18:47,799 - INFO - _models.training_function_executor - Model: 31,742 parameters, 68.2KB storage
2025-09-29 13:18:47,799 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7690461665391922, 0.5598461911678314, 0.5197489603757858, 0.49810314428806307, 0.48435291802883146, 0.475547630906105, 0.4666313676834106, 0.46228762578964233, 0.4562237300872803, 0.4535213214159012, 0.4496127783060074, 0.4433645315170288, 0.4396436443328857, 0.43829360949993135, 0.4346641196012497, 0.4307267507314682, 0.4299244776964188, 0.42795980513095855, 0.4256553809642792, 0.4232274934053421, 0.4207837415933609, 0.4215227075815201, 0.42003459906578067, 0.41824887657165527, 0.41551492643356325, 0.4154761002063751, 0.4143302754163742, 0.414225422501564], 'val_losses': [0.5750361969546666, 0.5569464815041375, 0.5215269842791179, 0.5052194581145332, 0.48838730511211215, 0.490807339785591, 0.4829305722599938, 0.48502970735232037, 0.47459230063453556, 0.46425304952121915, 0.46519228768727133, 0.46527137973951915, 0.4635996378603436, 0.4619129319039602, 0.4631627968379429, 0.46301843675356064, 0.47047027614381576, 0.4611731597355434, 0.4521191224219307, 0.454024853214385, 0.4605334074724288, 0.4518293322078765, 0.46331553705154904, 0.4594223802051847, 0.45748598282299346, 0.45878399979500545, 0.45567056962421965, 0.4590131910074325], 'val_acc': [0.9107881188392639, 0.9270768165588379, 0.9349705576896667, 0.9442425966262817, 0.9497556686401367, 0.9531387090682983, 0.9531387090682983, 0.9526374936103821, 0.955018162727356, 0.9587770700454712, 0.9597795009613037, 0.9627866148948669, 0.9615336656570435, 0.9637889862060547, 0.9621601104736328, 0.9627866148948669, 0.9604059457778931, 0.965041995048523, 0.9671720266342163, 0.9655431509017944, 0.9639142751693726, 0.9661696553230286, 0.9625360369682312, 0.9644154906272888, 0.9659190773963928, 0.9679238200187683, 0.9694274067878723, 0.9659190773963928], 'val_macro_f1': [0.6075349152088165, 0.6720465466380119, 0.6907169312238693, 0.7188005700707436, 0.7688688814640046, 0.734115532040596, 0.7821811974048615, 0.7694582462310791, 0.8103938817977905, 0.8236040711402893, 0.8205826282501221, 0.8195161461830139, 0.8331120491027832, 0.8434774875640869, 0.8238501906394958, 0.8210863709449768, 0.7858955144882203, 0.8401206612586976, 0.8400644779205322, 0.8479570031166077, 0.8468268156051636, 0.8439381003379822, 0.8141703426837921, 0.8490501999855041, 0.848443067073822, 0.8536263108253479, 0.8723127126693726, 0.843160605430603], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0031618003590175065, 'batch_size': 128, 'epochs': 28, 'weight_decay': 4.0859852074426746e-05, 'dropout': 0.22613286480637845, 'stem_channels': 29, 'embed_channels': 38, 'se_reduction': 4, 'd_model': 22, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09094181958976948, 'grad_clip': 0.60316924876695, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 10}, 'model_parameter_count': 31742, 'model_storage_size_kb': 68.19570312500001, 'model_size_validation': 'PASS'}
2025-09-29 13:18:47,799 - INFO - _models.training_function_executor - BO Objective: base=0.9659, size_penalty=0.0000, final=0.9659
2025-09-29 13:18:47,799 - INFO - _models.training_function_executor - Model: 31,742 parameters, 68.2KB (PASS 256KB limit)
2025-09-29 13:18:47,799 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 39.639s
2025-09-29 13:18:47,911 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9659
2025-09-29 13:18:47,911 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.112s
2025-09-29 13:18:47,911 - INFO - bo.run_bo - Recorded observation #29: hparams={'lr': 0.0031618003590175065, 'batch_size': np.int64(128), 'epochs': np.int64(28), 'weight_decay': 4.0859852074426746e-05, 'dropout': 0.22613286480637845, 'stem_channels': np.int64(29), 'embed_channels': np.int64(38), 'se_reduction': np.int64(4), 'd_model': np.int64(22), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(25), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09094181958976948, 'grad_clip': 0.60316924876695, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(10)}, value=0.9659
2025-09-29 13:18:47,911 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 29: {'lr': 0.0031618003590175065, 'batch_size': np.int64(128), 'epochs': np.int64(28), 'weight_decay': 4.0859852074426746e-05, 'dropout': 0.22613286480637845, 'stem_channels': np.int64(29), 'embed_channels': np.int64(38), 'se_reduction': np.int64(4), 'd_model': np.int64(22), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(25), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09094181958976948, 'grad_clip': 0.60316924876695, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(10)} -> 0.9659
2025-09-29 13:18:47,911 - INFO - bo.run_bo - ðŸ”BO Trial 30: Using RF surrogate + Expected Improvement
2025-09-29 13:18:47,911 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:18:47,911 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:18:47,911 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:18:47,911 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009482151471826832, 'batch_size': 64, 'epochs': 44, 'weight_decay': 2.8116063594865563e-05, 'dropout': 0.2759018153271753, 'stem_channels': 32, 'embed_channels': 41, 'se_reduction': 4, 'd_model': 17, 'num_heads': 4, 'num_layers': 2, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07280489775151205, 'grad_clip': 0.5876553710536478, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 2}
2025-09-29 13:18:47,913 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009482151471826832, 'batch_size': 64, 'epochs': 44, 'weight_decay': 2.8116063594865563e-05, 'dropout': 0.2759018153271753, 'stem_channels': 32, 'embed_channels': 41, 'se_reduction': 4, 'd_model': 17, 'num_heads': 4, 'num_layers': 2, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07280489775151205, 'grad_clip': 0.5876553710536478, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 2}
2025-09-29 13:20:11,155 - INFO - _models.training_function_executor - Model: 181,897 parameters, 390.8KB storage
2025-09-29 13:20:11,155 - WARNING - _models.training_function_executor - Model storage 390.8KB exceeds 256KB limit!
2025-09-29 13:20:11,155 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7205314498267814, 0.523186722117101, 0.4833027868567106, 0.46043072709578553, 0.44150039894069604, 0.42793911546170116, 0.4227465907772462, 0.4131273552028832, 0.40600067968358977, 0.39993030931763274, 0.3926370618099679, 0.3901068494769041, 0.384476242239824, 0.37970361573423794, 0.37736764627850367, 0.3752614130715808, 0.3713300424013921, 0.3677967733037257, 0.36522464970787444, 0.3619627854628171, 0.3577269140130771, 0.35501663168828806, 0.3530881361875362, 0.352959504287563, 0.3499739839581545, 0.3500011702458223, 0.34638084301012073, 0.34573249193375, 0.345676114599786, 0.3425744592785119, 0.3430407481465884, 0.33943771527620975, 0.34102369859844506, 0.3384747421574258, 0.33826998975090605, 0.3386046537655389, 0.33432129557003715, 0.3393278599740986, 0.33710045733289395, 0.3354193847141189, 0.33417167154724947, 0.33141108654543966, 0.33384794229734877, 0.3330370171633894], 'val_losses': [0.5623283009529114, 0.5077865226268768, 0.46777224659919736, 0.46132830023765564, 0.4364288721084595, 0.43700763368606566, 0.440946182012558, 0.4316091706752777, 0.4315123701095581, 0.4316404356956482, 0.42618428778648376, 0.44608774280548097, 0.42145763683319093, 0.4222256290912628, 0.41958385133743287, 0.4353031234741211, 0.4291493854522705, 0.430806519985199, 0.41730483770370486, 0.4291575038433075, 0.426667489528656, 0.42646595311164853, 0.4364025053977966, 0.4253372025489807, 0.427178097486496, 0.43463481569290163, 0.4214481704235077, 0.42133207035064696, 0.43180859756469725, 0.4232315270900726, 0.43147768926620483, 0.46004469466209413, 0.43629961371421816, 0.4281189684867859, 0.42550774908065797, 0.42591316080093383, 0.43927344942092894, 0.4295927155017853, 0.4290499942302704, 0.44306980991363526, 0.43179838109016416, 0.43852608966827394, 0.4137328622341156, 0.43203451347351074], 'val_acc': [0.8996366262435913, 0.9198095202445984, 0.9353464245796204, 0.9416113495826721, 0.9496303796768188, 0.9510086178779602, 0.9490038752555847, 0.9490038752555847, 0.9511339664459229, 0.9517604112625122, 0.954266369342804, 0.9462473392486572, 0.9523869156837463, 0.9551434516906738, 0.9560205340385437, 0.9541410803794861, 0.9541410803794861, 0.9532639980316162, 0.9585264921188354, 0.9582759141921997, 0.954266369342804, 0.9582759141921997, 0.9553940892219543, 0.9575241208076477, 0.9585264921188354, 0.9527627825737, 0.9584012031555176, 0.9573988318443298, 0.9556446671485901, 0.9585264921188354, 0.9560205340385437, 0.9507580399513245, 0.9558952450752258, 0.9606565833091736, 0.9595288634300232, 0.9589024186134338, 0.958025336265564, 0.9553940892219543, 0.9609071612358093, 0.957273542881012, 0.9578999876976013, 0.9570229053497314, 0.9631624817848206, 0.9573988318443298], 'val_macro_f1': [0.6420921802520752, 0.6644153833389282, 0.6723245933651925, 0.718405568599701, 0.7617518186569214, 0.7374005019664764, 0.7609784781932831, 0.7266749322414399, 0.7597664892673492, 0.7541997194290161, 0.782900083065033, 0.7716752707958221, 0.7961503207683563, 0.7730997443199158, 0.7947064518928528, 0.7946916460990906, 0.7911421895027161, 0.7777021527290344, 0.810608184337616, 0.7906982481479645, 0.7875560879707336, 0.8157873630523682, 0.7822362422943115, 0.8030927896499633, 0.79921395778656, 0.7870856344699859, 0.8001190006732941, 0.8112528145313262, 0.8050231337547302, 0.7933351457118988, 0.7968173146247863, 0.790647441148758, 0.8129605114459991, 0.8136872291564942, 0.8138389766216279, 0.8096138119697571, 0.797621899843216, 0.7914004802703858, 0.7995095372200012, 0.7899941980838776, 0.8008753955364227, 0.8108333766460418, 0.8294353485107422, 0.7943805813789367], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009482151471826832, 'batch_size': 64, 'epochs': 44, 'weight_decay': 2.8116063594865563e-05, 'dropout': 0.2759018153271753, 'stem_channels': 32, 'embed_channels': 41, 'se_reduction': 4, 'd_model': 17, 'num_heads': 4, 'num_layers': 2, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07280489775151205, 'grad_clip': 0.5876553710536478, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 2}, 'model_parameter_count': 181897, 'model_storage_size_kb': 390.7943359375, 'model_size_validation': 'FAIL'}
2025-09-29 13:20:11,155 - INFO - _models.training_function_executor - BO Objective: base=0.9574, size_penalty=0.2633, final=0.6941
2025-09-29 13:20:11,155 - INFO - _models.training_function_executor - Model: 181,897 parameters, 390.8KB (FAIL 256KB limit)
2025-09-29 13:20:11,155 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 83.244s
2025-09-29 13:20:11,266 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6941
2025-09-29 13:20:11,266 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-09-29 13:20:11,266 - INFO - bo.run_bo - Recorded observation #30: hparams={'lr': 0.009482151471826832, 'batch_size': np.int64(64), 'epochs': np.int64(44), 'weight_decay': 2.8116063594865563e-05, 'dropout': 0.2759018153271753, 'stem_channels': np.int64(32), 'embed_channels': np.int64(41), 'se_reduction': np.int64(4), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07280489775151205, 'grad_clip': 0.5876553710536478, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(2)}, value=0.6941
2025-09-29 13:20:11,266 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 30: {'lr': 0.009482151471826832, 'batch_size': np.int64(64), 'epochs': np.int64(44), 'weight_decay': 2.8116063594865563e-05, 'dropout': 0.2759018153271753, 'stem_channels': np.int64(32), 'embed_channels': np.int64(41), 'se_reduction': np.int64(4), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07280489775151205, 'grad_clip': 0.5876553710536478, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(2)} -> 0.6941
2025-09-29 13:20:11,267 - INFO - bo.run_bo - ðŸ”BO Trial 31: Using RF surrogate + Expected Improvement
2025-09-29 13:20:11,267 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:20:11,267 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:20:11,267 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:20:11,267 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.161769847297527e-05, 'batch_size': 512, 'epochs': 33, 'weight_decay': 1.1415983572877761e-06, 'dropout': 0.14495550888722594, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 27, 'num_heads': 2, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0810337120629357, 'grad_clip': 0.9452195069759479, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 26}
2025-09-29 13:20:11,268 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.161769847297527e-05, 'batch_size': 512, 'epochs': 33, 'weight_decay': 1.1415983572877761e-06, 'dropout': 0.14495550888722594, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 27, 'num_heads': 2, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0810337120629357, 'grad_clip': 0.9452195069759479, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 26}
2025-09-29 13:20:48,001 - INFO - _models.training_function_executor - Model: 33,075 parameters, 142.1KB storage
2025-09-29 13:20:48,001 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0183426472875807, 0.9565480635279701, 0.9081378314230177, 0.8400554108241248, 0.7705416348245409, 0.7351994618536934, 0.6985797995612735, 0.6694396422022865, 0.6559114295338827, 0.642118823906732, 0.6274775578862145, 0.6134724806225489, 0.6162989035485282, 0.6001359820365906, 0.5904532841273716, 0.5841784458311777, 0.5817768327773564, 0.5744809073115152, 0.571490866797311, 0.5678584755413116, 0.5621557330328321, 0.5578181185419597, 0.5541724695099725, 0.5501730460969229, 0.5481380285724761, 0.5472627925494361, 0.5446541157979814, 0.5438386693833366, 0.5428011530921573, 0.5417768898464385, 0.5411909180028098, 0.5406232783718715, 0.540664666701877], 'val_losses': [0.9758404344320297, 0.950230285525322, 0.889303982257843, 0.7834592014551163, 0.7284532785415649, 0.6961083114147186, 0.6627319306135178, 0.6376855559647083, 0.7350781932473183, 0.6213960461318493, 0.6029230803251266, 0.6029580570757389, 0.5917258039116859, 0.5945750810205936, 0.5777465514838696, 0.5781286619603634, 0.579989816993475, 0.5687330588698387, 0.565169844776392, 0.5602621883153915, 0.5624957457184792, 0.5592266023159027, 0.5539038814604282, 0.5513208024203777, 0.5499649420380592, 0.5514938794076443, 0.5461742915213108, 0.5479660257697105, 0.5442077964544296, 0.5443715788424015, 0.5444278456270695, 0.5441983006894588, 0.5437677502632141], 'val_acc': [0.7200852036476135, 0.7263500690460205, 0.7494048476219177, 0.8092970848083496, 0.8341060280799866, 0.8406214714050293, 0.8587896227836609, 0.8715699911117554, 0.8092970848083496, 0.8777095675468445, 0.885979175567627, 0.8871068954467773, 0.8884851336479187, 0.8839744329452515, 0.89825838804245, 0.896754801273346, 0.896754801273346, 0.9002631306648254, 0.9041473269462585, 0.9046485424041748, 0.9052750468254089, 0.9065279960632324, 0.9086580872535706, 0.9105375409126282, 0.9116652011871338, 0.9111639857292175, 0.9144217371940613, 0.911414623260498, 0.9135446548461914, 0.9131687879562378, 0.9137952923774719, 0.9140458703041077, 0.9137952923774719], 'val_macro_f1': [0.16745338439941407, 0.23566207513213158, 0.30109073519706725, 0.4212411046028137, 0.4479601263999939, 0.45642980337142947, 0.4786376357078552, 0.49224101305007933, 0.46051204204559326, 0.4999092936515808, 0.5098518032580615, 0.5080575108528137, 0.5139717720448971, 0.5116035725921393, 0.5537103623151779, 0.5324242947623133, 0.5578822404146194, 0.5234132507815957, 0.5330063164234161, 0.5643728477880359, 0.5485855974256992, 0.5772614657878876, 0.5685512498021126, 0.5715796768665313, 0.6321645647287368, 0.6094754263758659, 0.6278692454099655, 0.5940133422613144, 0.6162648409605026, 0.6163039952516556, 0.618474331498146, 0.6189235180616379, 0.622755628824234], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.161769847297527e-05, 'batch_size': 512, 'epochs': 33, 'weight_decay': 1.1415983572877761e-06, 'dropout': 0.14495550888722594, 'stem_channels': 29, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 27, 'num_heads': 2, 'num_layers': 1, 'patch_size': 20, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0810337120629357, 'grad_clip': 0.9452195069759479, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 26}, 'model_parameter_count': 33075, 'model_storage_size_kb': 142.119140625, 'model_size_validation': 'PASS'}
2025-09-29 13:20:48,001 - INFO - _models.training_function_executor - BO Objective: base=0.9138, size_penalty=0.0000, final=0.9138
2025-09-29 13:20:48,001 - INFO - _models.training_function_executor - Model: 33,075 parameters, 142.1KB (PASS 256KB limit)
2025-09-29 13:20:48,001 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 36.734s
2025-09-29 13:20:48,113 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9138
2025-09-29 13:20:48,113 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.112s
2025-09-29 13:20:48,113 - INFO - bo.run_bo - Recorded observation #31: hparams={'lr': 8.161769847297527e-05, 'batch_size': np.int64(512), 'epochs': np.int64(33), 'weight_decay': 1.1415983572877761e-06, 'dropout': 0.14495550888722594, 'stem_channels': np.int64(29), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(27), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(20), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0810337120629357, 'grad_clip': 0.9452195069759479, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(26)}, value=0.9138
2025-09-29 13:20:48,113 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 31: {'lr': 8.161769847297527e-05, 'batch_size': np.int64(512), 'epochs': np.int64(33), 'weight_decay': 1.1415983572877761e-06, 'dropout': 0.14495550888722594, 'stem_channels': np.int64(29), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(27), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(20), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0810337120629357, 'grad_clip': 0.9452195069759479, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(26)} -> 0.9138
2025-09-29 13:20:48,113 - INFO - bo.run_bo - ðŸ”BO Trial 32: Using RF surrogate + Expected Improvement
2025-09-29 13:20:48,113 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:20:48,113 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:20:48,113 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:20:48,113 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0004822167484165264, 'batch_size': 64, 'epochs': 50, 'weight_decay': 0.00011725221855019513, 'dropout': 0.18712747883178085, 'stem_channels': 30, 'embed_channels': 43, 'se_reduction': 4, 'd_model': 28, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09263193110020451, 'grad_clip': 0.8474501196298833, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 7}
2025-09-29 13:20:48,114 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0004822167484165264, 'batch_size': 64, 'epochs': 50, 'weight_decay': 0.00011725221855019513, 'dropout': 0.18712747883178085, 'stem_channels': 30, 'embed_channels': 43, 'se_reduction': 4, 'd_model': 28, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09263193110020451, 'grad_clip': 0.8474501196298833, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 7}
2025-09-29 13:22:10,254 - INFO - _models.training_function_executor - Model: 129,747 parameters, 557.5KB storage
2025-09-29 13:22:10,254 - WARNING - _models.training_function_executor - Model storage 557.5KB exceeds 256KB limit!
2025-09-29 13:22:10,254 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8315643994268291, 0.6033917774179417, 0.5477081750461716, 0.5273481057378238, 0.5134306561970758, 0.5026633994493312, 0.49549019790603543, 0.4867950899448089, 0.4829118252995019, 0.47698278674381767, 0.4724457031022571, 0.4679657849735153, 0.4627152683142431, 0.45695692348575784, 0.45190444923116113, 0.4499564468263385, 0.4460165560364962, 0.4408434793681563, 0.4378277394838467, 0.4346120357513428, 0.43100550734925125, 0.42789078308250716, 0.4247750363990157, 0.42204462818965643, 0.41886537562391324, 0.4165491812334271, 0.4141911326763864, 0.4122806936203836, 0.40859105137880436, 0.40719328847581254, 0.4045314775679059, 0.40315409766170446, 0.4007267483131202, 0.399732443457376, 0.3976108728644843, 0.39689018611678617, 0.39474004614568187, 0.3939413410389352, 0.39328859797221627, 0.39192956375454613, 0.3909957967325298, 0.3902696744354072, 0.389848804008029, 0.3890140104389382, 0.38932892238209865, 0.3883974208741007, 0.3882888397855128, 0.38828256965161323, 0.38829954735979527, 0.3881719408627741], 'val_losses': [0.6890115957260132, 0.5719509525299072, 0.5524125728607178, 0.5356494748592376, 0.5286547875404358, 0.5170386779308319, 0.5195452561378479, 0.50827947640419, 0.5259719059467316, 0.5094790160655975, 0.5074065062999725, 0.501123071193695, 0.4988845262527466, 0.5078650324344635, 0.4966863000392914, 0.49570809173583985, 0.49763986802101134, 0.4967012393474579, 0.5023671972751618, 0.5031177835464478, 0.499655042886734, 0.5025034334659576, 0.5104209675788879, 0.5083117737770081, 0.5118264577388764, 0.510813581943512, 0.5142852122783661, 0.5135518069267273, 0.5201573243141174, 0.5138816955089569, 0.5178537485599518, 0.5160976288318634, 0.5184666285514832, 0.5158830966949463, 0.516305700302124, 0.5172937893867493, 0.5201243512630462, 0.519717970609665, 0.5199309358596802, 0.5187602112293244, 0.5204903633594513, 0.5201958789825439, 0.5208029899597167, 0.5216118748188019, 0.520912442445755, 0.5205605614185334, 0.5203334362506866, 0.5203810489177704, 0.5206852743625641, 0.5206328256130218], 'val_acc': [0.8680616617202759, 0.9204360246658325, 0.9300839304924011, 0.9388547539710999, 0.9371005892753601, 0.9434908032417297, 0.9441173076629639, 0.9456208348274231, 0.9414860010147095, 0.947249710559845, 0.9463726282119751, 0.9475002884864807, 0.9503821730613708, 0.9473749995231628, 0.9500062465667725, 0.9518857002258301, 0.9522616267204285, 0.9528881311416626, 0.9521363377571106, 0.9528881311416626, 0.9527627825737, 0.9537652134895325, 0.9483773708343506, 0.9516351222991943, 0.9500062465667725, 0.9511339664459229, 0.9500062465667725, 0.9511339664459229, 0.9507580399513245, 0.953514575958252, 0.9510086178779602, 0.9537652134895325, 0.9518857002258301, 0.9522616267204285, 0.9521363377571106, 0.9537652134895325, 0.9532639980316162, 0.9522616267204285, 0.9511339664459229, 0.9526374936103821, 0.9525122046470642, 0.953514575958252, 0.9533892869949341, 0.9521363377571106, 0.9533892869949341, 0.9536399245262146, 0.9540157914161682, 0.953514575958252, 0.9532639980316162, 0.9532639980316162], 'val_macro_f1': [0.5740819811820984, 0.6714300513267517, 0.6886198662221432, 0.7120708093047142, 0.7080358147621155, 0.7756677329540252, 0.7260170951485634, 0.7371594488620759, 0.7196151956915855, 0.7599710345268249, 0.7602438926696777, 0.7715206325054169, 0.7832931756973267, 0.775706124305725, 0.7794723212718964, 0.7874207496643066, 0.7985898137092591, 0.7913897812366486, 0.799450010061264, 0.8030236721038818, 0.8025214016437531, 0.7930485904216766, 0.7891434550285339, 0.7956353724002838, 0.7762141764163971, 0.7979987680912017, 0.7817645967006683, 0.7956728041172028, 0.8065208911895752, 0.8047780752182007, 0.7991594672203064, 0.8040530383586884, 0.7973005056381226, 0.7972409009933472, 0.7984629809856415, 0.8035140693187713, 0.804232269525528, 0.7998139023780823, 0.7990184962749481, 0.7954987943172455, 0.8022433936595916, 0.8083068490028381, 0.8049904644489289, 0.8008015155792236, 0.8035867214202881, 0.8051938533782959, 0.8037764430046082, 0.8036358654499054, 0.8029155254364013, 0.8031095445156098], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0004822167484165264, 'batch_size': 64, 'epochs': 50, 'weight_decay': 0.00011725221855019513, 'dropout': 0.18712747883178085, 'stem_channels': 30, 'embed_channels': 43, 'se_reduction': 4, 'd_model': 28, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09263193110020451, 'grad_clip': 0.8474501196298833, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 7}, 'model_parameter_count': 129747, 'model_storage_size_kb': 557.506640625, 'model_size_validation': 'FAIL'}
2025-09-29 13:22:10,255 - INFO - _models.training_function_executor - BO Objective: base=0.9533, size_penalty=0.5889, final=0.3644
2025-09-29 13:22:10,255 - INFO - _models.training_function_executor - Model: 129,747 parameters, 557.5KB (FAIL 256KB limit)
2025-09-29 13:22:10,255 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 82.141s
2025-09-29 13:22:10,367 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.3644
2025-09-29 13:22:10,367 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.113s
2025-09-29 13:22:10,367 - INFO - bo.run_bo - Recorded observation #32: hparams={'lr': 0.0004822167484165264, 'batch_size': np.int64(64), 'epochs': np.int64(50), 'weight_decay': 0.00011725221855019513, 'dropout': 0.18712747883178085, 'stem_channels': np.int64(30), 'embed_channels': np.int64(43), 'se_reduction': np.int64(4), 'd_model': np.int64(28), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09263193110020451, 'grad_clip': 0.8474501196298833, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(7)}, value=0.3644
2025-09-29 13:22:10,367 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 32: {'lr': 0.0004822167484165264, 'batch_size': np.int64(64), 'epochs': np.int64(50), 'weight_decay': 0.00011725221855019513, 'dropout': 0.18712747883178085, 'stem_channels': np.int64(30), 'embed_channels': np.int64(43), 'se_reduction': np.int64(4), 'd_model': np.int64(28), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09263193110020451, 'grad_clip': 0.8474501196298833, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(7)} -> 0.3644
2025-09-29 13:22:10,368 - INFO - bo.run_bo - ðŸ”BO Trial 33: Using RF surrogate + Expected Improvement
2025-09-29 13:22:10,368 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:22:10,368 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:22:10,368 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:22:10,368 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00027292115539878436, 'batch_size': 128, 'epochs': 38, 'weight_decay': 4.885812992480261e-05, 'dropout': 0.159403872104433, 'stem_channels': 29, 'embed_channels': 39, 'se_reduction': 4, 'd_model': 23, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08479158230370418, 'grad_clip': 0.6497313249197417, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 28}
2025-09-29 13:22:10,369 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00027292115539878436, 'batch_size': 128, 'epochs': 38, 'weight_decay': 4.885812992480261e-05, 'dropout': 0.159403872104433, 'stem_channels': 29, 'embed_channels': 39, 'se_reduction': 4, 'd_model': 23, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08479158230370418, 'grad_clip': 0.6497313249197417, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 28}
2025-09-29 13:23:05,472 - INFO - _models.training_function_executor - Model: 190,743 parameters, 819.6KB storage
2025-09-29 13:23:05,472 - WARNING - _models.training_function_executor - Model storage 819.6KB exceeds 256KB limit!
2025-09-29 13:23:05,472 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9051574096679688, 0.7174861829280853, 0.6469459183216095, 0.5937900655269622, 0.5631649622917175, 0.5404783091545105, 0.5224719754457474, 0.5090690449476242, 0.4977780419588089, 0.4919648905992508, 0.4837703177928925, 0.47789215970039367, 0.4727930277585983, 0.4663430738449097, 0.4617850041389465, 0.45735779440402985, 0.45385740053653717, 0.44882020580768583, 0.44611841094493865, 0.44170932614803315, 0.43868734323978426, 0.435385910987854, 0.4318735724687576, 0.4290112760066986, 0.42635875356197356, 0.42208255803585054, 0.4211358278989792, 0.4187303935289383, 0.41710654497146604, 0.4160289461612701, 0.414739554643631, 0.4125210223197937, 0.41226184904575347, 0.4116006592512131, 0.4099172168970108, 0.4111888539791107, 0.41110589635372163, 0.40942234349250795], 'val_losses': [0.7653966905578734, 0.6947575211524963, 0.6051199313194032, 0.5864057971371545, 0.5514953439197843, 0.5476781063609653, 0.5385925627890087, 0.5217371871547093, 0.5210837721824646, 0.5098641254599132, 0.509055866608544, 0.5090132010361504, 0.5043437547153897, 0.509314160025309, 0.5015144579940372, 0.5085923543998173, 0.5097126837760683, 0.49652771107734195, 0.4997210048493885, 0.5027434324461316, 0.495690403476594, 0.5011310657811543, 0.5048446172759646, 0.4968930743043385, 0.4990019164388142, 0.5004014533663553, 0.49511664017798407, 0.49546460357923355, 0.49574653686039033, 0.4952235709107111, 0.49290403108748176, 0.49437112798766486, 0.4950990577538808, 0.4939378835852184, 0.4948601628106738, 0.4951490220569429, 0.494779576384832, 0.4949649756863004], 'val_acc': [0.8188197016716003, 0.8490164279937744, 0.8893622159957886, 0.9038967490196228, 0.915424108505249, 0.9201854467391968, 0.9238190650939941, 0.9278286099433899, 0.9310863018035889, 0.9350958466529846, 0.9340934753417969, 0.9355970621109009, 0.9371005892753601, 0.9377270936965942, 0.940984845161438, 0.935471773147583, 0.9360982179641724, 0.9418619275093079, 0.9404836297035217, 0.9389801025390625, 0.9413607120513916, 0.9411101341247559, 0.9384788870811462, 0.9442425966262817, 0.942488431930542, 0.9422377943992615, 0.9448690414428711, 0.9459967613220215, 0.9444931745529175, 0.9444931745529175, 0.9458714723587036, 0.9454955458641052, 0.9442425966262817, 0.9448690414428711, 0.9453702569007874, 0.9451196789741516, 0.945746123790741, 0.9453702569007874], 'val_macro_f1': [0.44237828254699707, 0.46326651573181155, 0.5696052990853786, 0.6153301626443863, 0.6631384558975697, 0.6792509883642197, 0.6907421186566353, 0.7143899351358414, 0.7251485407352447, 0.7211911648511886, 0.728564316034317, 0.7353009104728698, 0.744360888004303, 0.7406465411186218, 0.7451104760169983, 0.7602897047996521, 0.7409275710582733, 0.7692421197891235, 0.7691908776760101, 0.7674886405467987, 0.7765502452850341, 0.7753300607204437, 0.7775810360908508, 0.7792032063007355, 0.7742845177650451, 0.786564177274704, 0.7856675148010254, 0.789637291431427, 0.7832918286323547, 0.7856606185436249, 0.785035353899002, 0.7819844961166382, 0.7788186252117157, 0.7848206341266633, 0.7849381685256958, 0.7851742804050446, 0.78880575299263, 0.7873603761196136], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00027292115539878436, 'batch_size': 128, 'epochs': 38, 'weight_decay': 4.885812992480261e-05, 'dropout': 0.159403872104433, 'stem_channels': 29, 'embed_channels': 39, 'se_reduction': 4, 'd_model': 23, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08479158230370418, 'grad_clip': 0.6497313249197417, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 28}, 'model_parameter_count': 190743, 'model_storage_size_kb': 819.5988281250001, 'model_size_validation': 'FAIL'}
2025-09-29 13:23:05,472 - INFO - _models.training_function_executor - BO Objective: base=0.9454, size_penalty=0.8000, final=0.1454
2025-09-29 13:23:05,472 - INFO - _models.training_function_executor - Model: 190,743 parameters, 819.6KB (FAIL 256KB limit)
2025-09-29 13:23:05,472 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 55.104s
2025-09-29 13:23:05,586 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1454
2025-09-29 13:23:05,587 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.114s
2025-09-29 13:23:05,587 - INFO - bo.run_bo - Recorded observation #33: hparams={'lr': 0.00027292115539878436, 'batch_size': np.int64(128), 'epochs': np.int64(38), 'weight_decay': 4.885812992480261e-05, 'dropout': 0.159403872104433, 'stem_channels': np.int64(29), 'embed_channels': np.int64(39), 'se_reduction': np.int64(4), 'd_model': np.int64(23), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08479158230370418, 'grad_clip': 0.6497313249197417, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(28)}, value=0.1454
2025-09-29 13:23:05,587 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 33: {'lr': 0.00027292115539878436, 'batch_size': np.int64(128), 'epochs': np.int64(38), 'weight_decay': 4.885812992480261e-05, 'dropout': 0.159403872104433, 'stem_channels': np.int64(29), 'embed_channels': np.int64(39), 'se_reduction': np.int64(4), 'd_model': np.int64(23), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08479158230370418, 'grad_clip': 0.6497313249197417, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(28)} -> 0.1454
2025-09-29 13:23:05,587 - INFO - bo.run_bo - ðŸ”BO Trial 34: Using RF surrogate + Expected Improvement
2025-09-29 13:23:05,587 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:23:05,587 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:23:05,587 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:23:05,587 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002043815761253014, 'batch_size': 512, 'epochs': 15, 'weight_decay': 7.928033025183507e-05, 'dropout': 0.17631505160957509, 'stem_channels': 29, 'embed_channels': 37, 'se_reduction': 2, 'd_model': 21, 'num_heads': 4, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0658698863301539, 'grad_clip': 0.10680865323626157, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 14}
2025-09-29 13:23:05,589 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002043815761253014, 'batch_size': 512, 'epochs': 15, 'weight_decay': 7.928033025183507e-05, 'dropout': 0.17631505160957509, 'stem_channels': 29, 'embed_channels': 37, 'se_reduction': 2, 'd_model': 21, 'num_heads': 4, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0658698863301539, 'grad_clip': 0.10680865323626157, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 14}
2025-09-29 13:23:22,234 - INFO - _models.training_function_executor - Model: 41,808 parameters, 179.6KB storage
2025-09-29 13:23:22,234 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9652380668927752, 0.6761447437225826, 0.5190329679421016, 0.4619901894576966, 0.4345010883278317, 0.42181431963330224, 0.40725005902941264, 0.40113442710467745, 0.39283305643096805, 0.38913299923851374, 0.3829687303966946, 0.37907746339601184, 0.37789425916141933, 0.3742633414646936, 0.3692914228590708], 'val_losses': [0.8192668780684471, 0.5651173368096352, 0.48613480664789677, 0.455280976369977, 0.4359108731150627, 0.42740246281027794, 0.41707324236631393, 0.42047736421227455, 0.40568242967128754, 0.4093530420213938, 0.4105978161096573, 0.4062471017241478, 0.4129027836024761, 0.3944362625479698, 0.4118493180721998], 'val_acc': [0.7873700261116028, 0.8891116380691528, 0.9179300665855408, 0.9345946907997131, 0.940233051776886, 0.9437413811683655, 0.9469991326332092, 0.948001503944397, 0.9522616267204285, 0.9505074620246887, 0.9497556686401367, 0.9486280083656311, 0.9515098333358765, 0.9584012031555176, 0.9501315355300903], 'val_macro_f1': [0.4064947724342346, 0.5617036819458008, 0.6253179669380188, 0.6915864750742913, 0.7425938367843627, 0.7726738691329956, 0.7832318305969238, 0.7899666368961334, 0.8146555066108704, 0.809148621559143, 0.8143934607505798, 0.8039294958114624, 0.8039875149726867, 0.8279642462730408, 0.7995125889778137], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002043815761253014, 'batch_size': 512, 'epochs': 15, 'weight_decay': 7.928033025183507e-05, 'dropout': 0.17631505160957509, 'stem_channels': 29, 'embed_channels': 37, 'se_reduction': 2, 'd_model': 21, 'num_heads': 4, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0658698863301539, 'grad_clip': 0.10680865323626157, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 14}, 'model_parameter_count': 41808, 'model_storage_size_kb': 179.64375, 'model_size_validation': 'PASS'}
2025-09-29 13:23:22,234 - INFO - _models.training_function_executor - BO Objective: base=0.9501, size_penalty=0.0000, final=0.9501
2025-09-29 13:23:22,234 - INFO - _models.training_function_executor - Model: 41,808 parameters, 179.6KB (PASS 256KB limit)
2025-09-29 13:23:22,234 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 16.647s
2025-09-29 13:23:22,348 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9501
2025-09-29 13:23:22,348 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.114s
2025-09-29 13:23:22,348 - INFO - bo.run_bo - Recorded observation #34: hparams={'lr': 0.002043815761253014, 'batch_size': np.int64(512), 'epochs': np.int64(15), 'weight_decay': 7.928033025183507e-05, 'dropout': 0.17631505160957509, 'stem_channels': np.int64(29), 'embed_channels': np.int64(37), 'se_reduction': np.int64(2), 'd_model': np.int64(21), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(40), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0658698863301539, 'grad_clip': 0.10680865323626157, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(14)}, value=0.9501
2025-09-29 13:23:22,348 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 34: {'lr': 0.002043815761253014, 'batch_size': np.int64(512), 'epochs': np.int64(15), 'weight_decay': 7.928033025183507e-05, 'dropout': 0.17631505160957509, 'stem_channels': np.int64(29), 'embed_channels': np.int64(37), 'se_reduction': np.int64(2), 'd_model': np.int64(21), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(40), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0658698863301539, 'grad_clip': 0.10680865323626157, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(14)} -> 0.9501
2025-09-29 13:23:22,349 - INFO - bo.run_bo - ðŸ”BO Trial 35: Using RF surrogate + Expected Improvement
2025-09-29 13:23:22,349 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:23:22,349 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:23:22,349 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:23:22,349 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0018939289561165004, 'batch_size': 128, 'epochs': 34, 'weight_decay': 0.0005904631292775465, 'dropout': 0.05001626808082217, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 2, 'd_model': 32, 'num_heads': 4, 'num_layers': 2, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07934809171931069, 'grad_clip': 0.8138847696633269, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 27}
2025-09-29 13:23:22,350 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0018939289561165004, 'batch_size': 128, 'epochs': 34, 'weight_decay': 0.0005904631292775465, 'dropout': 0.05001626808082217, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 2, 'd_model': 32, 'num_heads': 4, 'num_layers': 2, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07934809171931069, 'grad_clip': 0.8138847696633269, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 27}
2025-09-29 13:24:06,336 - INFO - _models.training_function_executor - Model: 132,039 parameters, 567.4KB storage
2025-09-29 13:24:06,336 - WARNING - _models.training_function_executor - Model storage 567.4KB exceeds 256KB limit!
2025-09-29 13:24:06,336 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7697919553518295, 0.5047000457048416, 0.46504665791988375, 0.44438485383987425, 0.43098803317546847, 0.42163261342048647, 0.4125270793437958, 0.40482693231105804, 0.39591219162940977, 0.39027688539028166, 0.38653192412853243, 0.3815103396177292, 0.3752105194330215, 0.37305448508262634, 0.3706148375272751, 0.3673359054327011, 0.36340766298770905, 0.36124801957607267, 0.35940446412563326, 0.35666132605075834, 0.35528055799007413, 0.3549081130027771, 0.35232211112976075, 0.34990147256851195, 0.34881426668167115, 0.347861012339592, 0.3469362142086029, 0.3453193598985672, 0.3441313160657883, 0.34452270197868345, 0.3441368405818939, 0.34330345261096956, 0.3421853063106537, 0.33889993834495546], 'val_losses': [0.5602494700560494, 0.48458162044721936, 0.478400666089285, 0.46468938626940287, 0.4518494620209649, 0.4481378490962679, 0.43182823724216884, 0.4279927701231033, 0.43444280823071796, 0.42584736905400716, 0.4264497818454864, 0.42162287046038915, 0.42224310172928703, 0.41915456028211684, 0.43299040151020834, 0.42454210775239126, 0.4295673176409706, 0.41796648455044577, 0.43829223087855745, 0.43121778444638326, 0.4303735125632513, 0.4245661534960308, 0.420956205754053, 0.4245354982595595, 0.42648202843136257, 0.4368161369883825, 0.43195576563714044, 0.4321629201608991, 0.4324450421900976, 0.43342523300458513, 0.4404727267840552, 0.43181282707623075, 0.43065984097738114, 0.42945171963600887], 'val_acc': [0.9031449556350708, 0.9342187643051147, 0.9383535981178284, 0.9413607120513916, 0.9496303796768188, 0.9497556686401367, 0.955769956111908, 0.9570229053497314, 0.9558952450752258, 0.9587770700454712, 0.9590277075767517, 0.9614083170890808, 0.9625360369682312, 0.9614083170890808, 0.9589024186134338, 0.9600300788879395, 0.9591529965400696, 0.9621601104736328, 0.9553940892219543, 0.958025336265564, 0.9616589546203613, 0.9624107480049133, 0.964290201663971, 0.9622853994369507, 0.9627866148948669, 0.9585264921188354, 0.9615336656570435, 0.9605312347412109, 0.9629119038581848, 0.9611577391624451, 0.9597795009613037, 0.9629119038581848, 0.9625360369682312, 0.9616589546203613], 'val_macro_f1': [0.6438709639012814, 0.7645726799964905, 0.7234459489583969, 0.6955258816480636, 0.7587826907634735, 0.76259486079216, 0.8211036562919617, 0.8319750905036927, 0.8148882627487183, 0.8417551517486572, 0.8350220322608948, 0.8405360221862793, 0.8546443343162536, 0.8500258445739746, 0.8353362321853638, 0.8416955709457398, 0.8346478104591369, 0.8374605774879456, 0.8320817112922668, 0.8343948125839233, 0.8331273436546326, 0.8453565955162048, 0.8614458680152893, 0.850057053565979, 0.8598163485527038, 0.834516704082489, 0.8416025757789611, 0.8516076445579529, 0.844941520690918, 0.843921160697937, 0.8347981333732605, 0.852174973487854, 0.8484721422195435, 0.8528914213180542], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0018939289561165004, 'batch_size': 128, 'epochs': 34, 'weight_decay': 0.0005904631292775465, 'dropout': 0.05001626808082217, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 2, 'd_model': 32, 'num_heads': 4, 'num_layers': 2, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07934809171931069, 'grad_clip': 0.8138847696633269, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 27}, 'model_parameter_count': 132039, 'model_storage_size_kb': 567.3550781250001, 'model_size_validation': 'FAIL'}
2025-09-29 13:24:06,336 - INFO - _models.training_function_executor - BO Objective: base=0.9617, size_penalty=0.6081, final=0.3535
2025-09-29 13:24:06,336 - INFO - _models.training_function_executor - Model: 132,039 parameters, 567.4KB (FAIL 256KB limit)
2025-09-29 13:24:06,336 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 43.988s
2025-09-29 13:24:06,451 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.3535
2025-09-29 13:24:06,451 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.115s
2025-09-29 13:24:06,451 - INFO - bo.run_bo - Recorded observation #35: hparams={'lr': 0.0018939289561165004, 'batch_size': np.int64(128), 'epochs': np.int64(34), 'weight_decay': 0.0005904631292775465, 'dropout': 0.05001626808082217, 'stem_channels': np.int64(29), 'embed_channels': np.int64(35), 'se_reduction': np.int64(2), 'd_model': np.int64(32), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07934809171931069, 'grad_clip': 0.8138847696633269, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(27)}, value=0.3535
2025-09-29 13:24:06,451 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 35: {'lr': 0.0018939289561165004, 'batch_size': np.int64(128), 'epochs': np.int64(34), 'weight_decay': 0.0005904631292775465, 'dropout': 0.05001626808082217, 'stem_channels': np.int64(29), 'embed_channels': np.int64(35), 'se_reduction': np.int64(2), 'd_model': np.int64(32), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07934809171931069, 'grad_clip': 0.8138847696633269, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(27)} -> 0.3535
2025-09-29 13:24:06,451 - INFO - bo.run_bo - ðŸ”BO Trial 36: Using RF surrogate + Expected Improvement
2025-09-29 13:24:06,451 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:24:06,451 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:24:06,451 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:24:06,451 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004295866657789783, 'batch_size': 256, 'epochs': 12, 'weight_decay': 0.0010116027621858738, 'dropout': 0.19523059145944682, 'stem_channels': 31, 'embed_channels': 37, 'se_reduction': 2, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08981576610205495, 'grad_clip': 0.5443175498357852, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 31}
2025-09-29 13:24:06,453 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004295866657789783, 'batch_size': 256, 'epochs': 12, 'weight_decay': 0.0010116027621858738, 'dropout': 0.19523059145944682, 'stem_channels': 31, 'embed_channels': 37, 'se_reduction': 2, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08981576610205495, 'grad_clip': 0.5443175498357852, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 31}
2025-09-29 13:24:18,614 - INFO - _models.training_function_executor - Model: 131,282 parameters, 564.1KB storage
2025-09-29 13:24:18,615 - WARNING - _models.training_function_executor - Model storage 564.1KB exceeds 256KB limit!
2025-09-29 13:24:18,615 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.850908073425293, 1.5741487035751343, 1.5055905046463012, 1.4614779500961304, 1.430505350112915, 1.4032883796691895, 1.3775606594085694, 1.3586987409591675, 1.3376905708312987, 1.3240361471176147, 1.3083036556243897, 1.2965286936759948], 'val_losses': [1.6160326302051544, 1.5182731449604034, 1.4859919734299183, 1.4666657075285912, 1.4410629719495773, 1.4160285145044327, 1.3992251493036747, 1.3796603083610535, 1.3757206611335278, 1.3745793588459492, 1.3554379604756832, 1.3841003961861134], 'val_acc': [0.45796266198158264, 0.46372634172439575, 0.4882846772670746, 0.6600676774978638, 0.6112015843391418, 0.6298709511756897, 0.5624608397483826, 0.6940233111381531, 0.590026319026947, 0.646786093711853, 0.6678361296653748, 0.7099360823631287], 'val_macro_f1': [0.4148260220885277, 0.4611750438809395, 0.46174153983592986, 0.5508467584848404, 0.52836295068264, 0.5497443526983261, 0.5316650420427322, 0.5925982624292374, 0.5423892676830292, 0.5906193733215332, 0.577584421634674, 0.589959979057312], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004295866657789783, 'batch_size': 256, 'epochs': 12, 'weight_decay': 0.0010116027621858738, 'dropout': 0.19523059145944682, 'stem_channels': 31, 'embed_channels': 37, 'se_reduction': 2, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08981576610205495, 'grad_clip': 0.5443175498357852, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 31}, 'model_parameter_count': 131282, 'model_storage_size_kb': 564.10234375, 'model_size_validation': 'FAIL'}
2025-09-29 13:24:18,615 - INFO - _models.training_function_executor - BO Objective: base=0.7099, size_penalty=0.6018, final=0.1082
2025-09-29 13:24:18,615 - INFO - _models.training_function_executor - Model: 131,282 parameters, 564.1KB (FAIL 256KB limit)
2025-09-29 13:24:18,615 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 12.163s
2025-09-29 13:24:18,731 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1082
2025-09-29 13:24:18,731 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.116s
2025-09-29 13:24:18,731 - INFO - bo.run_bo - Recorded observation #36: hparams={'lr': 0.004295866657789783, 'batch_size': np.int64(256), 'epochs': np.int64(12), 'weight_decay': 0.0010116027621858738, 'dropout': 0.19523059145944682, 'stem_channels': np.int64(31), 'embed_channels': np.int64(37), 'se_reduction': np.int64(2), 'd_model': np.int64(17), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(200), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08981576610205495, 'grad_clip': 0.5443175498357852, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(31)}, value=0.1082
2025-09-29 13:24:18,731 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 36: {'lr': 0.004295866657789783, 'batch_size': np.int64(256), 'epochs': np.int64(12), 'weight_decay': 0.0010116027621858738, 'dropout': 0.19523059145944682, 'stem_channels': np.int64(31), 'embed_channels': np.int64(37), 'se_reduction': np.int64(2), 'd_model': np.int64(17), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(200), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.08981576610205495, 'grad_clip': 0.5443175498357852, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(31)} -> 0.1082
2025-09-29 13:24:18,731 - INFO - bo.run_bo - ðŸ”BO Trial 37: Using RF surrogate + Expected Improvement
2025-09-29 13:24:18,731 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:24:18,731 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:24:18,731 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:24:18,731 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0027511683241637046, 'batch_size': 128, 'epochs': 16, 'weight_decay': 0.00015215931284981687, 'dropout': 0.24119611294750848, 'stem_channels': 29, 'embed_channels': 39, 'se_reduction': 8, 'd_model': 26, 'num_heads': 2, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08752728013335401, 'grad_clip': 0.03989672875625639, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 9}
2025-09-29 13:24:18,733 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0027511683241637046, 'batch_size': 128, 'epochs': 16, 'weight_decay': 0.00015215931284981687, 'dropout': 0.24119611294750848, 'stem_channels': 29, 'embed_channels': 39, 'se_reduction': 8, 'd_model': 26, 'num_heads': 2, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08752728013335401, 'grad_clip': 0.03989672875625639, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 9}
2025-09-29 13:24:41,601 - INFO - _models.training_function_executor - Model: 255,467 parameters, 274.4KB storage
2025-09-29 13:24:41,601 - WARNING - _models.training_function_executor - Model storage 274.4KB exceeds 256KB limit!
2025-09-29 13:24:41,601 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7855091459751129, 0.5664026762247085, 0.5155682213306427, 0.4933968085050583, 0.4766847252845764, 0.4619614654779434, 0.4499317101240158, 0.4403200323581696, 0.4308880089521408, 0.4236510540246963, 0.41341209125518796, 0.40688665843009947, 0.40153931283950806, 0.3980910873413086, 0.394705327630043, 0.39337424337863924], 'val_losses': [0.60691152394764, 0.5313587524588146, 0.5031217398151518, 0.5016522204119062, 0.4882235834522853, 0.48416480895072694, 0.4846749494946192, 0.4819216860665215, 0.4820486472712623, 0.4801510364290268, 0.483486983511183, 0.4861759997549511, 0.48110695206929766, 0.4835335810979207, 0.4865231126073807, 0.4858351657314906], 'val_acc': [0.896003007888794, 0.9253226518630981, 0.9371005892753601, 0.9398571848869324, 0.9447437524795532, 0.948753297328949, 0.948001503944397, 0.950256884098053, 0.9526374936103821, 0.9521363377571106, 0.9521363377571106, 0.953514575958252, 0.9567723274230957, 0.955018162727356, 0.9543916583061218, 0.9546422958374023], 'val_macro_f1': [0.6023876011371613, 0.6830337688326835, 0.7138492092490196, 0.7502123534679412, 0.7743714988231659, 0.7967515826225281, 0.7799089133739472, 0.7995461225509644, 0.7948936402797699, 0.7981139183044433, 0.8091920614242554, 0.7988224446773529, 0.8075426757335663, 0.8036253154277802, 0.8070334553718567, 0.8055684804916382], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0027511683241637046, 'batch_size': 128, 'epochs': 16, 'weight_decay': 0.00015215931284981687, 'dropout': 0.24119611294750848, 'stem_channels': 29, 'embed_channels': 39, 'se_reduction': 8, 'd_model': 26, 'num_heads': 2, 'num_layers': 1, 'patch_size': 250, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08752728013335401, 'grad_clip': 0.03989672875625639, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 9}, 'model_parameter_count': 255467, 'model_storage_size_kb': 274.42744140625, 'model_size_validation': 'FAIL'}
2025-09-29 13:24:41,601 - INFO - _models.training_function_executor - BO Objective: base=0.9546, size_penalty=0.0360, final=0.9187
2025-09-29 13:24:41,601 - INFO - _models.training_function_executor - Model: 255,467 parameters, 274.4KB (FAIL 256KB limit)
2025-09-29 13:24:41,601 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 22.870s
2025-09-29 13:24:41,717 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9187
2025-09-29 13:24:41,717 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.116s
2025-09-29 13:24:41,717 - INFO - bo.run_bo - Recorded observation #37: hparams={'lr': 0.0027511683241637046, 'batch_size': np.int64(128), 'epochs': np.int64(16), 'weight_decay': 0.00015215931284981687, 'dropout': 0.24119611294750848, 'stem_channels': np.int64(29), 'embed_channels': np.int64(39), 'se_reduction': np.int64(8), 'd_model': np.int64(26), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08752728013335401, 'grad_clip': 0.03989672875625639, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(9)}, value=0.9187
2025-09-29 13:24:41,717 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 37: {'lr': 0.0027511683241637046, 'batch_size': np.int64(128), 'epochs': np.int64(16), 'weight_decay': 0.00015215931284981687, 'dropout': 0.24119611294750848, 'stem_channels': np.int64(29), 'embed_channels': np.int64(39), 'se_reduction': np.int64(8), 'd_model': np.int64(26), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(250), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08752728013335401, 'grad_clip': 0.03989672875625639, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(9)} -> 0.9187
2025-09-29 13:24:41,718 - INFO - bo.run_bo - ðŸ”BO Trial 38: Using RF surrogate + Expected Improvement
2025-09-29 13:24:41,718 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:24:41,718 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:24:41,718 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:24:41,718 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001969713082937137, 'batch_size': 128, 'epochs': 35, 'weight_decay': 1.714697571305638e-05, 'dropout': 0.42605862223130775, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09760628695239065, 'grad_clip': 0.5059021402309899, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 8}
2025-09-29 13:24:41,719 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001969713082937137, 'batch_size': 128, 'epochs': 35, 'weight_decay': 1.714697571305638e-05, 'dropout': 0.42605862223130775, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09760628695239065, 'grad_clip': 0.5059021402309899, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 8}
2025-09-29 13:25:21,642 - INFO - _models.training_function_executor - Model: 63,774 parameters, 137.0KB storage
2025-09-29 13:25:21,642 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.9692034220695496, 1.7073335189819336, 1.6238133354187012, 1.5762568912506103, 1.5298972005844116, 1.5044946150779723, 1.4788112049102784, 1.4802229633331299, 1.4620440406799315, 1.4517637512683867, 1.4293770575523377, 1.4277216827869414, 1.4120172550678254, 1.4069110279083252, 1.3989222118854523, 1.3890469970703125, 1.3828760573863983, 1.3711663386821746, 1.3671150381565094, 1.3630843462944031, 1.3623605434894561, 1.3532672550678253, 1.3544341506958009, 1.3466914339065552, 1.3448816020488739, 1.3367069056034089, 1.334645196199417, 1.3342829296588898, 1.322907679080963, 1.322950484752655, 1.3216828515529633, 1.3192901887893678, 1.3146054916381835, 1.31113378572464, 1.3041107587814331], 'val_losses': [1.750985787028358, 1.6535742528854855, 1.6019711361991034, 1.6073874045932104, 1.5587578160422189, 1.5450968969435919, 1.5322054246115306, 1.5546391615791926, 1.5379867307723514, 1.512160057113284, 1.5086128825233096, 1.5086999261190022, 1.4969044564262268, 1.4974086644157532, 1.507695442154294, 1.4942146407233343, 1.5035239533772544, 1.509550068113539, 1.506795058174739, 1.4942248586624387, 1.4742847794578189, 1.4859713334885856, 1.5045860438119798, 1.501410998995342, 1.4986096544871255, 1.4878807786911252, 1.5051441798134455, 1.5059578248432703, 1.5432104288585602, 1.514148647823031, 1.5145192335522364, 1.5254019593435622, 1.521056850751241, 1.511991510315547, 1.5227532746299866], 'val_acc': [0.22453325986862183, 0.24032075703144073, 0.5010650157928467, 0.6782358288764954, 0.5115900039672852, 0.7050495147705078, 0.6960280537605286, 0.6897631883621216, 0.7054253816604614, 0.6787369847297668, 0.6882596015930176, 0.745395302772522, 0.7858664393424988, 0.8334795236587524, 0.822954535484314, 0.8527753353118896, 0.795890212059021, 0.8714447021484375, 0.855657160282135, 0.8602932095527649, 0.8189449906349182, 0.8297205567359924, 0.8455080986022949, 0.8569101691246033, 0.8775842785835266, 0.8332289457321167, 0.8918681740760803, 0.8521488308906555, 0.8673098683357239, 0.858664333820343, 0.8779601454734802, 0.8939982652664185, 0.8700664043426514, 0.8936223387718201, 0.8896128535270691], 'val_macro_f1': [0.29725506603717805, 0.35532733276486395, 0.49162319898605344, 0.5692664623260498, 0.5040110364556313, 0.5831592321395874, 0.5918591797351838, 0.5745599150657654, 0.5952108770608902, 0.5785153478384018, 0.580781888961792, 0.623036116361618, 0.6367862612009049, 0.6647753357887268, 0.6748880803585052, 0.6797745287418365, 0.6405712008476258, 0.6956336855888366, 0.6858055889606476, 0.7036272466182709, 0.6648150086402893, 0.6866444259881973, 0.6749786794185638, 0.6972388446331024, 0.7063032567501069, 0.6670308172702789, 0.7237800896167755, 0.674628061056137, 0.7012241899967193, 0.6810146927833557, 0.7106597244739532, 0.7222286641597748, 0.7051274955272675, 0.7200512826442719, 0.7299484670162201], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001969713082937137, 'batch_size': 128, 'epochs': 35, 'weight_decay': 1.714697571305638e-05, 'dropout': 0.42605862223130775, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 8, 'd_model': 17, 'num_heads': 4, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09760628695239065, 'grad_clip': 0.5059021402309899, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 8}, 'model_parameter_count': 63774, 'model_storage_size_kb': 137.01445312500002, 'model_size_validation': 'PASS'}
2025-09-29 13:25:21,642 - INFO - _models.training_function_executor - BO Objective: base=0.8896, size_penalty=0.0000, final=0.8896
2025-09-29 13:25:21,642 - INFO - _models.training_function_executor - Model: 63,774 parameters, 137.0KB (PASS 256KB limit)
2025-09-29 13:25:21,642 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 39.924s
2025-09-29 13:25:21,760 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8896
2025-09-29 13:25:21,760 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.118s
2025-09-29 13:25:21,760 - INFO - bo.run_bo - Recorded observation #38: hparams={'lr': 0.001969713082937137, 'batch_size': np.int64(128), 'epochs': np.int64(35), 'weight_decay': 1.714697571305638e-05, 'dropout': 0.42605862223130775, 'stem_channels': np.int64(29), 'embed_channels': np.int64(35), 'se_reduction': np.int64(8), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09760628695239065, 'grad_clip': 0.5059021402309899, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(8)}, value=0.8896
2025-09-29 13:25:21,760 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 38: {'lr': 0.001969713082937137, 'batch_size': np.int64(128), 'epochs': np.int64(35), 'weight_decay': 1.714697571305638e-05, 'dropout': 0.42605862223130775, 'stem_channels': np.int64(29), 'embed_channels': np.int64(35), 'se_reduction': np.int64(8), 'd_model': np.int64(17), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.09760628695239065, 'grad_clip': 0.5059021402309899, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(8)} -> 0.8896
2025-09-29 13:25:21,760 - INFO - bo.run_bo - ðŸ”BO Trial 39: Using RF surrogate + Expected Improvement
2025-09-29 13:25:21,760 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:25:21,760 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:25:21,760 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:25:21,760 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 4.446436196268295e-05, 'batch_size': 512, 'epochs': 6, 'weight_decay': 2.855038910102652e-06, 'dropout': 0.13307078633393085, 'stem_channels': 31, 'embed_channels': 35, 'se_reduction': 4, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08292691718506504, 'grad_clip': 0.5583477589033419, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 1}
2025-09-29 13:25:21,762 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 4.446436196268295e-05, 'batch_size': 512, 'epochs': 6, 'weight_decay': 2.855038910102652e-06, 'dropout': 0.13307078633393085, 'stem_channels': 31, 'embed_channels': 35, 'se_reduction': 4, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08292691718506504, 'grad_clip': 0.5583477589033419, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 1}
2025-09-29 13:25:27,292 - INFO - _models.training_function_executor - Model: 121,113 parameters, 130.1KB storage
2025-09-29 13:25:27,292 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1072810642302982, 0.9922695916796488, 0.9622987593923297, 0.9408709756911747, 0.9239806277411324, 0.9096922883911739], 'val_losses': [0.9957207664847374, 0.9641212522983551, 0.9427526481449604, 0.9271158874034882, 0.9124842956662178, 0.9029025696218014], 'val_acc': [0.7200852036476135, 0.7168274521827698, 0.7259742021560669, 0.7375015616416931, 0.7431399822235107, 0.7490289211273193], 'val_macro_f1': [0.16745338439941407, 0.16815336914733053, 0.2268088638782501, 0.2674533810466528, 0.2917629897594452, 0.3130321234464645], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 4.446436196268295e-05, 'batch_size': 512, 'epochs': 6, 'weight_decay': 2.855038910102652e-06, 'dropout': 0.13307078633393085, 'stem_channels': 31, 'embed_channels': 35, 'se_reduction': 4, 'd_model': 17, 'num_heads': 2, 'num_layers': 1, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08292691718506504, 'grad_clip': 0.5583477589033419, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 1}, 'model_parameter_count': 121113, 'model_storage_size_kb': 130.10185546875002, 'model_size_validation': 'PASS'}
2025-09-29 13:25:27,292 - INFO - _models.training_function_executor - BO Objective: base=0.7490, size_penalty=0.0000, final=0.7490
2025-09-29 13:25:27,292 - INFO - _models.training_function_executor - Model: 121,113 parameters, 130.1KB (PASS 256KB limit)
2025-09-29 13:25:27,292 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 5.532s
2025-09-29 13:25:27,409 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7490
2025-09-29 13:25:27,409 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.117s
2025-09-29 13:25:27,409 - INFO - bo.run_bo - Recorded observation #39: hparams={'lr': 4.446436196268295e-05, 'batch_size': np.int64(512), 'epochs': np.int64(6), 'weight_decay': 2.855038910102652e-06, 'dropout': 0.13307078633393085, 'stem_channels': np.int64(31), 'embed_channels': np.int64(35), 'se_reduction': np.int64(4), 'd_model': np.int64(17), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08292691718506504, 'grad_clip': 0.5583477589033419, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(1)}, value=0.7490
2025-09-29 13:25:27,409 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 39: {'lr': 4.446436196268295e-05, 'batch_size': np.int64(512), 'epochs': np.int64(6), 'weight_decay': 2.855038910102652e-06, 'dropout': 0.13307078633393085, 'stem_channels': np.int64(31), 'embed_channels': np.int64(35), 'se_reduction': np.int64(4), 'd_model': np.int64(17), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08292691718506504, 'grad_clip': 0.5583477589033419, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(1)} -> 0.7490
2025-09-29 13:25:27,409 - INFO - bo.run_bo - ðŸ”BO Trial 40: Using RF surrogate + Expected Improvement
2025-09-29 13:25:27,409 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:25:27,409 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:25:27,410 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:25:27,410 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0010173371140224127, 'batch_size': 256, 'epochs': 14, 'weight_decay': 8.533172193042995e-05, 'dropout': 0.21845721739212248, 'stem_channels': 29, 'embed_channels': 47, 'se_reduction': 8, 'd_model': 20, 'num_heads': 2, 'num_layers': 2, 'patch_size': 125, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0829945555147884, 'grad_clip': 0.9907793325770865, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}
2025-09-29 13:25:27,411 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0010173371140224127, 'batch_size': 256, 'epochs': 14, 'weight_decay': 8.533172193042995e-05, 'dropout': 0.21845721739212248, 'stem_channels': 29, 'embed_channels': 47, 'se_reduction': 8, 'd_model': 20, 'num_heads': 2, 'num_layers': 2, 'patch_size': 125, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0829945555147884, 'grad_clip': 0.9907793325770865, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}
2025-09-29 13:25:43,874 - INFO - _models.training_function_executor - Model: 126,743 parameters, 544.6KB storage
2025-09-29 13:25:43,874 - WARNING - _models.training_function_executor - Model storage 544.6KB exceeds 256KB limit!
2025-09-29 13:25:43,874 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8909835662841797, 0.6006010479927063, 0.5349642794132232, 0.5064972932338715, 0.488147310256958, 0.4759382531642914, 0.4664156560897827, 0.45984021258354185, 0.4488559420108795, 0.44481532645225524, 0.43668800687789916, 0.4310521590709686, 0.4273015794754028, 0.42351999044418337], 'val_losses': [0.6635240279138088, 0.55326759070158, 0.5235235868021846, 0.49991522170603275, 0.49430372286587954, 0.5025733755901456, 0.4820429487153888, 0.4786991085857153, 0.47790154814720154, 0.48216242622584105, 0.4790610773488879, 0.4851329019293189, 0.4869196554645896, 0.47301527112722397], 'val_acc': [0.8615461587905884, 0.9122917056083679, 0.9273273944854736, 0.9372259378433228, 0.939481258392334, 0.9334669709205627, 0.9433655142784119, 0.9453702569007874, 0.9475002884864807, 0.9432401657104492, 0.9483773708343506, 0.9408595561981201, 0.9444931745529175, 0.9483773708343506], 'val_macro_f1': [0.4754342794418335, 0.6251718461513519, 0.6579462051391601, 0.7142860025167466, 0.7250551223754883, 0.7330874413251877, 0.7757985591888428, 0.7610263288021087, 0.7814996540546417, 0.7848882377147675, 0.7913638293743134, 0.7908004701137543, 0.7787075638771057, 0.7889896392822265], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0010173371140224127, 'batch_size': 256, 'epochs': 14, 'weight_decay': 8.533172193042995e-05, 'dropout': 0.21845721739212248, 'stem_channels': 29, 'embed_channels': 47, 'se_reduction': 8, 'd_model': 20, 'num_heads': 2, 'num_layers': 2, 'patch_size': 125, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0829945555147884, 'grad_clip': 0.9907793325770865, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calibrate_batches': 11}, 'model_parameter_count': 126743, 'model_storage_size_kb': 544.5988281250001, 'model_size_validation': 'FAIL'}
2025-09-29 13:25:43,874 - INFO - _models.training_function_executor - BO Objective: base=0.9484, size_penalty=0.5637, final=0.3847
2025-09-29 13:25:43,874 - INFO - _models.training_function_executor - Model: 126,743 parameters, 544.6KB (FAIL 256KB limit)
2025-09-29 13:25:43,875 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 16.465s
2025-09-29 13:25:43,994 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.3847
2025-09-29 13:25:43,994 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.119s
2025-09-29 13:25:43,994 - INFO - bo.run_bo - Recorded observation #40: hparams={'lr': 0.0010173371140224127, 'batch_size': np.int64(256), 'epochs': np.int64(14), 'weight_decay': 8.533172193042995e-05, 'dropout': 0.21845721739212248, 'stem_channels': np.int64(29), 'embed_channels': np.int64(47), 'se_reduction': np.int64(8), 'd_model': np.int64(20), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(125), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0829945555147884, 'grad_clip': 0.9907793325770865, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(11)}, value=0.3847
2025-09-29 13:25:43,994 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 40: {'lr': 0.0010173371140224127, 'batch_size': np.int64(256), 'epochs': np.int64(14), 'weight_decay': 8.533172193042995e-05, 'dropout': 0.21845721739212248, 'stem_channels': np.int64(29), 'embed_channels': np.int64(47), 'se_reduction': np.int64(8), 'd_model': np.int64(20), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(125), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0829945555147884, 'grad_clip': 0.9907793325770865, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(11)} -> 0.3847
2025-09-29 13:25:43,994 - INFO - bo.run_bo - ðŸ”BO Trial 41: Using RF surrogate + Expected Improvement
2025-09-29 13:25:43,994 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:25:43,994 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:25:43,994 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:25:43,994 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0010263099121988778, 'batch_size': 128, 'epochs': 36, 'weight_decay': 0.00018365107719372982, 'dropout': 0.02077865921404837, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 2, 'd_model': 52, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09764518789857256, 'grad_clip': 0.6987013248629805, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 7}
2025-09-29 13:25:43,996 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0010263099121988778, 'batch_size': 128, 'epochs': 36, 'weight_decay': 0.00018365107719372982, 'dropout': 0.02077865921404837, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 2, 'd_model': 52, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09764518789857256, 'grad_clip': 0.6987013248629805, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 7}
2025-09-29 13:26:27,454 - INFO - _models.training_function_executor - Model: 207,201 parameters, 445.2KB storage
2025-09-29 13:26:27,454 - WARNING - _models.training_function_executor - Model storage 445.2KB exceeds 256KB limit!
2025-09-29 13:26:27,454 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8485019550323486, 0.6058176016807556, 0.5451983709335327, 0.5214818123579025, 0.5050768070220947, 0.4934071936607361, 0.4829496293067932, 0.4749765524864197, 0.46640234637260436, 0.4607115263938904, 0.45496311616897583, 0.44925740325450897, 0.44461218106746675, 0.43918837559223173, 0.43552335786819457, 0.4314905353784561, 0.426670458316803, 0.4225254124403, 0.4188393087387085, 0.4165209686756134, 0.412788621544838, 0.4101924177408218, 0.40743390953540803, 0.4052487030029297, 0.40272844648361206, 0.4009106996059418, 0.39951041400432585, 0.39844357800483704, 0.39690835344791414, 0.3962709045410156, 0.395448716878891, 0.39487338733673094, 0.39453044509887697, 0.39426273357868197, 0.39405457389354703, 0.39394753515720365], 'val_losses': [0.6846841583176265, 0.561314111191129, 0.5418547547998882, 0.5182396665452018, 0.5135514736175537, 0.5136101704741282, 0.5034111742935483, 0.49658200333988856, 0.5023126034509569, 0.4905850139875261, 0.49325492788874914, 0.4874028714876326, 0.49107748317340066, 0.48712552681801813, 0.48811701413184877, 0.48695593599289183, 0.4903142646191612, 0.4906728097370693, 0.49095066719584995, 0.4893563853369819, 0.49095836991355535, 0.4909982198760623, 0.493725353763217, 0.4918233723867507, 0.4926140469218057, 0.4940629256150079, 0.4938163393073612, 0.49344931377304924, 0.4956481972384074, 0.49573155575328404, 0.4960085744895632, 0.4958966364936223, 0.4958489764304388, 0.4960059533043513, 0.4960723736929515, 0.4960818158255683], 'val_acc': [0.8597919940948486, 0.925447940826416, 0.92695152759552, 0.9407342672348022, 0.9448690414428711, 0.9443678855895996, 0.948753297328949, 0.950256884098053, 0.9481267929077148, 0.9530134201049805, 0.9500062465667725, 0.9546422958374023, 0.9531387090682983, 0.9563964605331421, 0.955018162727356, 0.9561458230018616, 0.9556446671485901, 0.9556446671485901, 0.9556446671485901, 0.9555193781852722, 0.9560205340385437, 0.9562711715698242, 0.9566470384597778, 0.9567723274230957, 0.9571482539176941, 0.9560205340385437, 0.9551434516906738, 0.9555193781852722, 0.9566470384597778, 0.9556446671485901, 0.955769956111908, 0.9562711715698242, 0.9562711715698242, 0.9556446671485901, 0.9558952450752258, 0.955769956111908], 'val_macro_f1': [0.49110981840640305, 0.6789780639111995, 0.6564519971609115, 0.7288817733526229, 0.7618951797485352, 0.7578895509243011, 0.7771545588970185, 0.7838968276977539, 0.8056400299072266, 0.7819210827350617, 0.7838775813579559, 0.80573371052742, 0.8086562633514405, 0.8129455327987671, 0.8096521377563477, 0.8232615232467652, 0.8055086076259613, 0.8084330141544342, 0.8079206585884094, 0.8110976815223694, 0.8012424051761627, 0.8123425424098969, 0.811292290687561, 0.8086167812347412, 0.8073636054992676, 0.8035943388938904, 0.8036845803260804, 0.8042358994483948, 0.8020979106426239, 0.8019867062568664, 0.8033639430999756, 0.806018340587616, 0.8051670134067536, 0.8024045884609222, 0.802961403131485, 0.8025616705417633], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0010263099121988778, 'batch_size': 128, 'epochs': 36, 'weight_decay': 0.00018365107719372982, 'dropout': 0.02077865921404837, 'stem_channels': 29, 'embed_channels': 35, 'se_reduction': 2, 'd_model': 52, 'num_heads': 2, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.09764518789857256, 'grad_clip': 0.6987013248629805, 'scheduler': np.str_('cosine'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 7}, 'model_parameter_count': 207201, 'model_storage_size_kb': 445.1583984375, 'model_size_validation': 'FAIL'}
2025-09-29 13:26:27,454 - INFO - _models.training_function_executor - BO Objective: base=0.9558, size_penalty=0.3694, final=0.5863
2025-09-29 13:26:27,454 - INFO - _models.training_function_executor - Model: 207,201 parameters, 445.2KB (FAIL 256KB limit)
2025-09-29 13:26:27,454 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 43.460s
2025-09-29 13:26:27,572 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5863
2025-09-29 13:26:27,572 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.118s
2025-09-29 13:26:27,572 - INFO - bo.run_bo - Recorded observation #41: hparams={'lr': 0.0010263099121988778, 'batch_size': np.int64(128), 'epochs': np.int64(36), 'weight_decay': 0.00018365107719372982, 'dropout': 0.02077865921404837, 'stem_channels': np.int64(29), 'embed_channels': np.int64(35), 'se_reduction': np.int64(2), 'd_model': np.int64(52), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09764518789857256, 'grad_clip': 0.6987013248629805, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(7)}, value=0.5863
2025-09-29 13:26:27,572 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 41: {'lr': 0.0010263099121988778, 'batch_size': np.int64(128), 'epochs': np.int64(36), 'weight_decay': 0.00018365107719372982, 'dropout': 0.02077865921404837, 'stem_channels': np.int64(29), 'embed_channels': np.int64(35), 'se_reduction': np.int64(2), 'd_model': np.int64(52), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.09764518789857256, 'grad_clip': 0.6987013248629805, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(7)} -> 0.5863
2025-09-29 13:26:27,573 - INFO - bo.run_bo - ðŸ”BO Trial 42: Using RF surrogate + Expected Improvement
2025-09-29 13:26:27,573 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:26:27,573 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:26:27,573 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:26:27,573 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0018293964826296353, 'batch_size': 128, 'epochs': 37, 'weight_decay': 1.716706555666334e-06, 'dropout': 0.14302296284307767, 'stem_channels': 28, 'embed_channels': 40, 'se_reduction': 8, 'd_model': 25, 'num_heads': 2, 'num_layers': 2, 'patch_size': 50, 'class_weighting': np.str_('none'), 'label_smoothing': 0.039161428363254445, 'grad_clip': 0.26072605707026714, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 12}
2025-09-29 13:26:27,574 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0018293964826296353, 'batch_size': 128, 'epochs': 37, 'weight_decay': 1.716706555666334e-06, 'dropout': 0.14302296284307767, 'stem_channels': 28, 'embed_channels': 40, 'se_reduction': 8, 'd_model': 25, 'num_heads': 2, 'num_layers': 2, 'patch_size': 50, 'class_weighting': np.str_('none'), 'label_smoothing': 0.039161428363254445, 'grad_clip': 0.26072605707026714, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 12}
2025-09-29 13:27:16,401 - INFO - _models.training_function_executor - Model: 62,676 parameters, 269.3KB storage
2025-09-29 13:27:16,401 - WARNING - _models.training_function_executor - Model storage 269.3KB exceeds 256KB limit!
2025-09-29 13:27:16,401 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.6447797274589538, 0.3945763212442398, 0.355463340818882, 0.33293909692764284, 0.3188984426259994, 0.31199036771059035, 0.3013735219836235, 0.29700171446800233, 0.28923297560214994, 0.28674116188287735, 0.27783077251911165, 0.2713842681646347, 0.26739100414514544, 0.26255848741531373, 0.25849716186523436, 0.2521701718568802, 0.24869617170095443, 0.24488244235515594, 0.24001727998256683, 0.23754970633983613, 0.23462583386898042, 0.23036795383691788, 0.2273235220313072, 0.22294543606042863, 0.22016273301839828, 0.21757035231590272, 0.21529915571212768, 0.21169843286275863, 0.210196376144886, 0.2086655450463295, 0.20739105582237244, 0.20588526046276093, 0.20593690115213395, 0.2055585486292839, 0.20397679966688156, 0.20339577442407608, 0.2028014798760414], 'val_losses': [0.45443412472331335, 0.3827470909981501, 0.35186770889494157, 0.3413581266289666, 0.331173370754908, 0.3443931464164976, 0.3210038620801199, 0.3179358400049664, 0.31804148521688247, 0.34670016689906047, 0.30968964336410404, 0.3203690108798799, 0.3132404077147681, 0.3214900888620861, 0.3284644408831521, 0.30420957955103073, 0.31074060026615385, 0.3084651352394195, 0.3154250267479155, 0.30821745499732, 0.3088371107975642, 0.31448461753981455, 0.3109084502572105, 0.31246690783235764, 0.32592621114518905, 0.3167066488947187, 0.32027212755074574, 0.32414110832744175, 0.31933279311846174, 0.3242210826230428, 0.3260799003025842, 0.3234964767618785, 0.3245895826627338, 0.32627320526138187, 0.3263886036380889, 0.3263787501861179, 0.32634814059923567], 'val_acc': [0.9127928614616394, 0.9323393106460571, 0.9406089186668396, 0.9447437524795532, 0.9478762149810791, 0.9434908032417297, 0.9515098333358765, 0.9543916583061218, 0.953514575958252, 0.9498809576034546, 0.9567723274230957, 0.9566470384597778, 0.9547675848007202, 0.9568976163864136, 0.9563964605331421, 0.9614083170890808, 0.9599047899246216, 0.9595288634300232, 0.9592782855033875, 0.9620348215103149, 0.9600300788879395, 0.9602806568145752, 0.9609071612358093, 0.9607818722724915, 0.9594035744667053, 0.9597795009613037, 0.9611577391624451, 0.9610324501991272, 0.9615336656570435, 0.9606565833091736, 0.9596541523933411, 0.9599047899246216, 0.9604059457778931, 0.9602806568145752, 0.9604059457778931, 0.9597795009613037, 0.9599047899246216], 'val_macro_f1': [0.6066984117031098, 0.7071558028459549, 0.7046465396881103, 0.7483901798725128, 0.7729982495307922, 0.7484033703804016, 0.8060160636901855, 0.8017853140830994, 0.804616779088974, 0.7801561892032624, 0.8070013463497162, 0.8025472700595856, 0.8233012676239013, 0.800776994228363, 0.8194660305976867, 0.8347553730010986, 0.8297824382781982, 0.8215056657791138, 0.8170275807380676, 0.8424923658370972, 0.8279605269432068, 0.8370030760765076, 0.8319457650184632, 0.8272149562835693, 0.8222007155418396, 0.8304338097572327, 0.83029705286026, 0.8269671559333801, 0.838573670387268, 0.8339180231094361, 0.8315994381904602, 0.8327651619911194, 0.8359644770622253, 0.8342002391815185, 0.8339095830917358, 0.8336461424827576, 0.8349730849266053], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0018293964826296353, 'batch_size': 128, 'epochs': 37, 'weight_decay': 1.716706555666334e-06, 'dropout': 0.14302296284307767, 'stem_channels': 28, 'embed_channels': 40, 'se_reduction': 8, 'd_model': 25, 'num_heads': 2, 'num_layers': 2, 'patch_size': 50, 'class_weighting': np.str_('none'), 'label_smoothing': 0.039161428363254445, 'grad_clip': 0.26072605707026714, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 12}, 'model_parameter_count': 62676, 'model_storage_size_kb': 269.3109375, 'model_size_validation': 'FAIL'}
2025-09-29 13:27:16,401 - INFO - _models.training_function_executor - BO Objective: base=0.9599, size_penalty=0.0260, final=0.9339
2025-09-29 13:27:16,401 - INFO - _models.training_function_executor - Model: 62,676 parameters, 269.3KB (FAIL 256KB limit)
2025-09-29 13:27:16,401 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 48.828s
2025-09-29 13:27:16,519 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9339
2025-09-29 13:27:16,519 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.118s
2025-09-29 13:27:16,520 - INFO - bo.run_bo - Recorded observation #42: hparams={'lr': 0.0018293964826296353, 'batch_size': np.int64(128), 'epochs': np.int64(37), 'weight_decay': 1.716706555666334e-06, 'dropout': 0.14302296284307767, 'stem_channels': np.int64(28), 'embed_channels': np.int64(40), 'se_reduction': np.int64(8), 'd_model': np.int64(25), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(50), 'class_weighting': np.str_('none'), 'label_smoothing': 0.039161428363254445, 'grad_clip': 0.26072605707026714, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(12)}, value=0.9339
2025-09-29 13:27:16,520 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 42: {'lr': 0.0018293964826296353, 'batch_size': np.int64(128), 'epochs': np.int64(37), 'weight_decay': 1.716706555666334e-06, 'dropout': 0.14302296284307767, 'stem_channels': np.int64(28), 'embed_channels': np.int64(40), 'se_reduction': np.int64(8), 'd_model': np.int64(25), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(50), 'class_weighting': np.str_('none'), 'label_smoothing': 0.039161428363254445, 'grad_clip': 0.26072605707026714, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(12)} -> 0.9339
2025-09-29 13:27:16,520 - INFO - bo.run_bo - ðŸ”BO Trial 43: Using RF surrogate + Expected Improvement
2025-09-29 13:27:16,520 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:27:16,520 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:27:16,520 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:27:16,520 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0019069907026310403, 'batch_size': 64, 'epochs': 33, 'weight_decay': 1.0286606503599868e-05, 'dropout': 0.4567871743886329, 'stem_channels': 29, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 24, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08393888712523367, 'grad_clip': 0.5316540196426803, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 17}
2025-09-29 13:27:16,521 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0019069907026310403, 'batch_size': 64, 'epochs': 33, 'weight_decay': 1.0286606503599868e-05, 'dropout': 0.4567871743886329, 'stem_channels': 29, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 24, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08393888712523367, 'grad_clip': 0.5316540196426803, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 17}
2025-09-29 13:28:15,533 - INFO - _models.training_function_executor - Model: 21,917 parameters, 23.5KB storage
2025-09-29 13:28:15,534 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7066165172384832, 0.5196150222976127, 0.4897077697551322, 0.4738877656942379, 0.4632250243174528, 0.4539997115402757, 0.44662101521998465, 0.44117313038132233, 0.43487319523442486, 0.4333636539135285, 0.4266524946761275, 0.4235052051310071, 0.42092870519252007, 0.4182466254205646, 0.41396387330515827, 0.4118894090752802, 0.4094225970322718, 0.4061180259397847, 0.40293684984017947, 0.4011389392769647, 0.3977887410080743, 0.39620253610945416, 0.39337409008480984, 0.39228406500720786, 0.39068965443628345, 0.38790888406470686, 0.3878344829550726, 0.38548606395243645, 0.38493095795233884, 0.3835294265188053, 0.3823032420957256, 0.3821956726138243, 0.381220437899859], 'val_losses': [0.5718561437129974, 0.5436497478485107, 0.5379205777645111, 0.5130829825401306, 0.49192403054237366, 0.49801394653320313, 0.49913278889656065, 0.5106500773429871, 0.49616132378578187, 0.48938432574272156, 0.4880648412704468, 0.5108685004711151, 0.4854715585708618, 0.47380588722229006, 0.4860128285884857, 0.47693048310279845, 0.4713870544433594, 0.4736558516025543, 0.4800210213661194, 0.4800181126594543, 0.4717312521934509, 0.4774475526809692, 0.4895024480819702, 0.49131744480133055, 0.48561864614486694, 0.48915158009529114, 0.4913604030609131, 0.4849037525653839, 0.48722725081443785, 0.4870340957641602, 0.48898614072799684, 0.49065063619613647, 0.4902296380996704], 'val_acc': [0.9216890335083008, 0.9358476400375366, 0.938729465007782, 0.9423630833625793, 0.9496303796768188, 0.9511339664459229, 0.9515098333358765, 0.9522616267204285, 0.953514575958252, 0.9567723274230957, 0.9577746987342834, 0.9538905024528503, 0.9591529965400696, 0.9609071612358093, 0.958025336265564, 0.9615336656570435, 0.9629119038581848, 0.9636636972427368, 0.9617842435836792, 0.9631624817848206, 0.9640396237373352, 0.9646660685539246, 0.9620348215103149, 0.9624107480049133, 0.9637889862060547, 0.9630371928215027, 0.9637889862060547, 0.9637889862060547, 0.9637889862060547, 0.9637889862060547, 0.963538408279419, 0.9634131193161011, 0.9636636972427368], 'val_macro_f1': [0.6607920527458191, 0.6931324481964112, 0.7241564512252807, 0.7780442893505096, 0.7882981061935425, 0.7889131605625153, 0.7743440985679626, 0.8042142629623413, 0.8068842768669129, 0.7946316540241242, 0.8249082922935486, 0.7919370055198669, 0.8337180733680725, 0.835238242149353, 0.8316385626792908, 0.8334407210350037, 0.8502627849578858, 0.8464309573173523, 0.846854293346405, 0.8508289098739624, 0.8542060613632202, 0.8488211989402771, 0.8385356426239013, 0.8456683278083801, 0.8493058562278748, 0.849922525882721, 0.848186194896698, 0.8505917668342591, 0.854631221294403, 0.851467514038086, 0.852452552318573, 0.8508161425590515, 0.8522905468940735], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0019069907026310403, 'batch_size': 64, 'epochs': 33, 'weight_decay': 1.0286606503599868e-05, 'dropout': 0.4567871743886329, 'stem_channels': 29, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 24, 'num_heads': 2, 'num_layers': 2, 'patch_size': 25, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08393888712523367, 'grad_clip': 0.5316540196426803, 'scheduler': np.str_('cosine'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 17}, 'model_parameter_count': 21917, 'model_storage_size_kb': 23.54365234375, 'model_size_validation': 'PASS'}
2025-09-29 13:28:15,534 - INFO - _models.training_function_executor - BO Objective: base=0.9637, size_penalty=0.0000, final=0.9637
2025-09-29 13:28:15,534 - INFO - _models.training_function_executor - Model: 21,917 parameters, 23.5KB (PASS 256KB limit)
2025-09-29 13:28:15,534 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 59.014s
2025-09-29 13:28:15,772 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9637
2025-09-29 13:28:15,772 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.238s
2025-09-29 13:28:15,772 - INFO - bo.run_bo - Recorded observation #43: hparams={'lr': 0.0019069907026310403, 'batch_size': np.int64(64), 'epochs': np.int64(33), 'weight_decay': 1.0286606503599868e-05, 'dropout': 0.4567871743886329, 'stem_channels': np.int64(29), 'embed_channels': np.int64(33), 'se_reduction': np.int64(8), 'd_model': np.int64(24), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(25), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08393888712523367, 'grad_clip': 0.5316540196426803, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(17)}, value=0.9637
2025-09-29 13:28:15,772 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 43: {'lr': 0.0019069907026310403, 'batch_size': np.int64(64), 'epochs': np.int64(33), 'weight_decay': 1.0286606503599868e-05, 'dropout': 0.4567871743886329, 'stem_channels': np.int64(29), 'embed_channels': np.int64(33), 'se_reduction': np.int64(8), 'd_model': np.int64(24), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(25), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08393888712523367, 'grad_clip': 0.5316540196426803, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(17)} -> 0.9637
2025-09-29 13:28:15,773 - INFO - bo.run_bo - ðŸ”BO Trial 44: Using RF surrogate + Expected Improvement
2025-09-29 13:28:15,773 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:28:15,773 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:28:15,773 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:28:15,773 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0012151074427680254, 'batch_size': 128, 'epochs': 38, 'weight_decay': 1.285446733416751e-05, 'dropout': 0.18522526919516305, 'stem_channels': 29, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 25, 'num_heads': 4, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08106383876512814, 'grad_clip': 0.557323878585626, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 18}
2025-09-29 13:28:15,774 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0012151074427680254, 'batch_size': 128, 'epochs': 38, 'weight_decay': 1.285446733416751e-05, 'dropout': 0.18522526919516305, 'stem_channels': 29, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 25, 'num_heads': 4, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08106383876512814, 'grad_clip': 0.557323878585626, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 18}
2025-09-29 13:28:57,920 - INFO - _models.training_function_executor - Model: 89,536 parameters, 384.7KB storage
2025-09-29 13:28:57,920 - WARNING - _models.training_function_executor - Model storage 384.7KB exceeds 256KB limit!
2025-09-29 13:28:57,921 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8145421671867371, 0.5869698057174683, 0.5295032428503037, 0.5040392452478408, 0.4867585719823837, 0.4752199455499649, 0.4638912572860718, 0.45544717168807985, 0.4486283608675003, 0.4409606173038483, 0.43671764349937436, 0.4293310099840164, 0.42421623873710634, 0.42042430984973905, 0.4150416941642761, 0.41214533042907714, 0.4058191816806793, 0.4028919191360474, 0.4001187642812729, 0.39505097711086273, 0.3921750422716141, 0.38891023683547976, 0.38590194833278657, 0.38286149823665616, 0.38025247311592103, 0.37724107241630556, 0.3753707855939865, 0.3738252999782562, 0.3712691260576248, 0.3697251771688461, 0.36765653812885285, 0.36689073491096497, 0.3659683549404144, 0.36500350272655485, 0.3645247983932495, 0.36451651275157926, 0.36373779535293577, 0.3632703471183777], 'val_losses': [0.6643197120182098, 0.558219995290514, 0.5231874353355832, 0.5293607380655077, 0.5076423093440041, 0.49195858741563464, 0.48812560287732926, 0.47812881214278086, 0.4806891031681545, 0.4752070705095927, 0.4707046515411801, 0.4730588509922936, 0.4710026392861018, 0.47974630622636705, 0.48362874937435935, 0.4707961432517521, 0.47693314249553376, 0.475147848564481, 0.47831053014785524, 0.4784843136393835, 0.48196125125128125, 0.47842928530677914, 0.4789480391948942, 0.4731294068079146, 0.47878821359740364, 0.485853201813168, 0.47761330907306976, 0.48138158047010027, 0.4840289784802331, 0.4843562235907903, 0.48505282070901656, 0.48365805120695204, 0.4825846817758348, 0.4859316708549621, 0.4853755273516216, 0.4850405322180854, 0.48543432260316516, 0.48540887473121525], 'val_acc': [0.8559077978134155, 0.9147976636886597, 0.9278286099433899, 0.930209219455719, 0.9315875172615051, 0.9353464245796204, 0.9373512268066406, 0.9448690414428711, 0.9432401657104492, 0.9469991326332092, 0.9468738436698914, 0.9471244215965271, 0.948753297328949, 0.9482520818710327, 0.9449943900108337, 0.9492544531822205, 0.9482520818710327, 0.9485027194023132, 0.9501315355300903, 0.9511339664459229, 0.9498809576034546, 0.949505090713501, 0.949505090713501, 0.9516351222991943, 0.9491291642189026, 0.9485027194023132, 0.9488785862922668, 0.9496303796768188, 0.948753297328949, 0.949505090713501, 0.9503821730613708, 0.9511339664459229, 0.950256884098053, 0.9501315355300903, 0.9501315355300903, 0.9506327509880066, 0.9506327509880066, 0.9503821730613708], 'val_macro_f1': [0.48377320151776076, 0.6636665225028991, 0.6786769986152649, 0.675220075249672, 0.7206583976745605, 0.7395614445209503, 0.7427830874919892, 0.7519346237182617, 0.763334208726883, 0.7640066564083099, 0.7677838325500488, 0.7762232542037963, 0.7774010241031647, 0.7696675419807434, 0.7650629758834839, 0.7827165305614472, 0.7927054762840271, 0.7865716218948364, 0.7862962007522583, 0.7886174261569977, 0.7805802166461945, 0.7889652013778686, 0.7870322406291962, 0.8006407499313355, 0.7906214952468872, 0.7923262774944305, 0.7856316328048706, 0.7909764587879181, 0.7954306781291962, 0.786721920967102, 0.7968746364116669, 0.7940673291683197, 0.7898059010505676, 0.7933102130889893, 0.7911055982112885, 0.793880432844162, 0.7935390055179596, 0.7930211365222931], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0012151074427680254, 'batch_size': 128, 'epochs': 38, 'weight_decay': 1.285446733416751e-05, 'dropout': 0.18522526919516305, 'stem_channels': 29, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 25, 'num_heads': 4, 'num_layers': 1, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08106383876512814, 'grad_clip': 0.557323878585626, 'scheduler': np.str_('cosine'), 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 18}, 'model_parameter_count': 89536, 'model_storage_size_kb': 384.725, 'model_size_validation': 'FAIL'}
2025-09-29 13:28:57,921 - INFO - _models.training_function_executor - BO Objective: base=0.9504, size_penalty=0.2514, final=0.6990
2025-09-29 13:28:57,921 - INFO - _models.training_function_executor - Model: 89,536 parameters, 384.7KB (FAIL 256KB limit)
2025-09-29 13:28:57,921 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 42.148s
2025-09-29 13:28:58,040 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6990
2025-09-29 13:28:58,040 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.120s
2025-09-29 13:28:58,040 - INFO - bo.run_bo - Recorded observation #44: hparams={'lr': 0.0012151074427680254, 'batch_size': np.int64(128), 'epochs': np.int64(38), 'weight_decay': 1.285446733416751e-05, 'dropout': 0.18522526919516305, 'stem_channels': np.int64(29), 'embed_channels': np.int64(33), 'se_reduction': np.int64(8), 'd_model': np.int64(25), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08106383876512814, 'grad_clip': 0.557323878585626, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(18)}, value=0.6990
2025-09-29 13:28:58,040 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 44: {'lr': 0.0012151074427680254, 'batch_size': np.int64(128), 'epochs': np.int64(38), 'weight_decay': 1.285446733416751e-05, 'dropout': 0.18522526919516305, 'stem_channels': np.int64(29), 'embed_channels': np.int64(33), 'se_reduction': np.int64(8), 'd_model': np.int64(25), 'num_heads': np.int64(4), 'num_layers': np.int64(1), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08106383876512814, 'grad_clip': 0.557323878585626, 'scheduler': np.str_('cosine'), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(18)} -> 0.6990
2025-09-29 13:28:58,041 - INFO - bo.run_bo - ðŸ”BO Trial 45: Using RF surrogate + Expected Improvement
2025-09-29 13:28:58,041 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:28:58,041 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:28:58,041 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:28:58,041 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.006386760614276071, 'batch_size': 64, 'epochs': 25, 'weight_decay': 5.723596724805491e-06, 'dropout': 0.24206404928275993, 'stem_channels': 29, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 23, 'num_heads': 2, 'num_layers': 2, 'patch_size': 20, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0935068925178314, 'grad_clip': 0.1640461542885048, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}
2025-09-29 13:28:58,042 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.006386760614276071, 'batch_size': 64, 'epochs': 25, 'weight_decay': 5.723596724805491e-06, 'dropout': 0.24206404928275993, 'stem_channels': 29, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 23, 'num_heads': 2, 'num_layers': 2, 'patch_size': 20, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0935068925178314, 'grad_clip': 0.1640461542885048, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}
2025-09-29 13:29:44,975 - INFO - _models.training_function_executor - Model: 16,669 parameters, 17.9KB storage
2025-09-29 13:29:44,976 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.733476846753237, 0.5487544689484254, 0.5300704651103468, 0.5117304713310364, 0.5018111055265209, 0.4913588144736204, 0.4821153178602039, 0.477342244319782, 0.4730890072538762, 0.4698588681483794, 0.46216629412704574, 0.46052229912104253, 0.4575567828390546, 0.45363534954124557, 0.4540986240149022, 0.4505996555985812, 0.44749372283776917, 0.44817098575030156, 0.445178447780246, 0.44404336505519126, 0.44442203097448557, 0.44109203611203807, 0.4402531285682518, 0.4371710395167968, 0.4366717886829185], 'val_losses': [0.5903623270988464, 0.5551713528633118, 0.5270691952705383, 0.5510760083198547, 0.5255673594474792, 0.5378562264442444, 0.5001791467666626, 0.5056376504898071, 0.5153119740486145, 0.49808392524719236, 0.5231968584060669, 0.5414322385787964, 0.49742232632637023, 0.48422153544425967, 0.4902808859348297, 0.47944797468185424, 0.5003020658493041, 0.47712971234321594, 0.4904141297340393, 0.48600500464439395, 0.4904152684211731, 0.4855604336261749, 0.4963774509429932, 0.4936060676574707, 0.4762513806819916], 'val_acc': [0.9201854467391968, 0.9314622282981873, 0.9451196789741516, 0.9355970621109009, 0.9428642988204956, 0.9466232061386108, 0.9551434516906738, 0.9538905024528503, 0.9556446671485901, 0.9562711715698242, 0.9540157914161682, 0.950256884098053, 0.9584012031555176, 0.9616589546203613, 0.9578999876976013, 0.9611577391624451, 0.9562711715698242, 0.9592782855033875, 0.9616589546203613, 0.9599047899246216, 0.9586517810821533, 0.9597795009613037, 0.9576494097709656, 0.9576494097709656, 0.9630371928215027], 'val_macro_f1': [0.6479686737060547, 0.671513032913208, 0.7023366928100586, 0.7218338966369628, 0.775231659412384, 0.7373338967561722, 0.7620844066143035, 0.7958625018596649, 0.7943192899227143, 0.7846422493457794, 0.78122279047966, 0.7822853267192841, 0.7886866748332977, 0.8199856877326965, 0.7915590882301331, 0.8259293556213378, 0.8028408527374268, 0.8255606651306152, 0.8004164040088654, 0.8213850498199463, 0.8108643293380737, 0.8024385273456573, 0.7866355001926422, 0.7863364398479462, 0.8339374542236329], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.006386760614276071, 'batch_size': 64, 'epochs': 25, 'weight_decay': 5.723596724805491e-06, 'dropout': 0.24206404928275993, 'stem_channels': 29, 'embed_channels': 32, 'se_reduction': 8, 'd_model': 23, 'num_heads': 2, 'num_layers': 2, 'patch_size': 20, 'class_weighting': np.str_('none'), 'label_smoothing': 0.0935068925178314, 'grad_clip': 0.1640461542885048, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 16}, 'model_parameter_count': 16669, 'model_storage_size_kb': 17.90615234375, 'model_size_validation': 'PASS'}
2025-09-29 13:29:44,976 - INFO - _models.training_function_executor - BO Objective: base=0.9630, size_penalty=0.0000, final=0.9630
2025-09-29 13:29:44,976 - INFO - _models.training_function_executor - Model: 16,669 parameters, 17.9KB (PASS 256KB limit)
2025-09-29 13:29:44,976 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 46.935s
2025-09-29 13:29:45,097 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9630
2025-09-29 13:29:45,097 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.121s
2025-09-29 13:29:45,097 - INFO - bo.run_bo - Recorded observation #45: hparams={'lr': 0.006386760614276071, 'batch_size': np.int64(64), 'epochs': np.int64(25), 'weight_decay': 5.723596724805491e-06, 'dropout': 0.24206404928275993, 'stem_channels': np.int64(29), 'embed_channels': np.int64(32), 'se_reduction': np.int64(8), 'd_model': np.int64(23), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(20), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0935068925178314, 'grad_clip': 0.1640461542885048, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(16)}, value=0.9630
2025-09-29 13:29:45,097 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 45: {'lr': 0.006386760614276071, 'batch_size': np.int64(64), 'epochs': np.int64(25), 'weight_decay': 5.723596724805491e-06, 'dropout': 0.24206404928275993, 'stem_channels': np.int64(29), 'embed_channels': np.int64(32), 'se_reduction': np.int64(8), 'd_model': np.int64(23), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(20), 'class_weighting': np.str_('none'), 'label_smoothing': 0.0935068925178314, 'grad_clip': 0.1640461542885048, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(16)} -> 0.9630
2025-09-29 13:29:45,097 - INFO - bo.run_bo - ðŸ”BO Trial 46: Using RF surrogate + Expected Improvement
2025-09-29 13:29:45,097 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:29:45,097 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:29:45,097 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:29:45,097 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002383629114697437, 'batch_size': 64, 'epochs': 28, 'weight_decay': 0.005031475153252525, 'dropout': 0.4980757220231453, 'stem_channels': 18, 'embed_channels': 32, 'se_reduction': 2, 'd_model': 20, 'num_heads': 4, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07358442398072308, 'grad_clip': 0.9443627452283823, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 10}
2025-09-29 13:29:45,099 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002383629114697437, 'batch_size': 64, 'epochs': 28, 'weight_decay': 0.005031475153252525, 'dropout': 0.4980757220231453, 'stem_channels': 18, 'embed_channels': 32, 'se_reduction': 2, 'd_model': 20, 'num_heads': 4, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07358442398072308, 'grad_clip': 0.9443627452283823, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 10}
2025-09-29 13:30:33,882 - INFO - _models.training_function_executor - Model: 136,915 parameters, 294.2KB storage
2025-09-29 13:30:33,882 - WARNING - _models.training_function_executor - Model storage 294.2KB exceeds 256KB limit!
2025-09-29 13:30:33,882 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7929448184365022, 0.5908124137498095, 0.5314569267815722, 0.5041037196506241, 0.4886148514632949, 0.4767544268367286, 0.4688880799528592, 0.45952508056569913, 0.45318095197897396, 0.444765430294679, 0.43942834445852075, 0.43487717393404973, 0.4307652871331614, 0.42506776991970313, 0.4202864917222866, 0.41586096366803965, 0.41106075968197686, 0.407639641680555, 0.40385770690226125, 0.40179941022324417, 0.39917298476538343, 0.39556188681321536, 0.3933468303365077, 0.38916659582115126, 0.3875337830167973, 0.38115123284603647, 0.38250030048624545, 0.37873621371561633], 'val_losses': [0.6110202357769012, 0.5334644336700439, 0.5149811704158783, 0.49625141215324403, 0.4975231056213379, 0.496526008605957, 0.48027685952186583, 0.48382614970207216, 0.47275908541679385, 0.46327513694763184, 0.483484801530838, 0.47585414099693296, 0.4680869529247284, 0.45300865602493284, 0.45375478386878965, 0.4570267174243927, 0.46547998785972594, 0.44934104800224306, 0.44821553444862366, 0.4641903865337372, 0.4527037470340729, 0.45454374647140505, 0.46401242446899416, 0.45467581391334533, 0.455797949552536, 0.47215198636054995, 0.4677197778224945, 0.4785212843418121], 'val_acc': [0.8784613609313965, 0.9198095202445984, 0.9219396114349365, 0.9337176084518433, 0.9305851459503174, 0.9340934753417969, 0.9381030201911926, 0.940233051776886, 0.9412354230880737, 0.9454955458641052, 0.9393559694290161, 0.9454955458641052, 0.9451196789741516, 0.9515098333358765, 0.9483773708343506, 0.9503821730613708, 0.9478762149810791, 0.9546422958374023, 0.9522616267204285, 0.9490038752555847, 0.9526374936103821, 0.9523869156837463, 0.9530134201049805, 0.9532639980316162, 0.9543916583061218, 0.9516351222991943, 0.9533892869949341, 0.9515098333358765], 'val_macro_f1': [0.5709537148475647, 0.6334098875522614, 0.6499195098876953, 0.698608161509037, 0.6765911489725113, 0.676506532728672, 0.715938213467598, 0.7269921898841858, 0.7307824730873108, 0.7705427289009095, 0.7330277353525162, 0.7810517847537994, 0.7246121823787689, 0.7928389787673951, 0.8002990007400512, 0.805185067653656, 0.783785605430603, 0.811123275756836, 0.8046144962310791, 0.806619119644165, 0.8153102159500122, 0.801515257358551, 0.7987259089946747, 0.8099854588508606, 0.8172104239463807, 0.8068347811698914, 0.799571692943573, 0.8033625841140747], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002383629114697437, 'batch_size': 64, 'epochs': 28, 'weight_decay': 0.005031475153252525, 'dropout': 0.4980757220231453, 'stem_channels': 18, 'embed_channels': 32, 'se_reduction': 2, 'd_model': 20, 'num_heads': 4, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07358442398072308, 'grad_clip': 0.9443627452283823, 'scheduler': np.str_('none'), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 10}, 'model_parameter_count': 136915, 'model_storage_size_kb': 294.1533203125, 'model_size_validation': 'FAIL'}
2025-09-29 13:30:33,882 - INFO - _models.training_function_executor - BO Objective: base=0.9515, size_penalty=0.0745, final=0.8770
2025-09-29 13:30:33,883 - INFO - _models.training_function_executor - Model: 136,915 parameters, 294.2KB (FAIL 256KB limit)
2025-09-29 13:30:33,883 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 48.785s
2025-09-29 13:30:34,004 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8770
2025-09-29 13:30:34,004 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.121s
2025-09-29 13:30:34,004 - INFO - bo.run_bo - Recorded observation #46: hparams={'lr': 0.002383629114697437, 'batch_size': np.int64(64), 'epochs': np.int64(28), 'weight_decay': 0.005031475153252525, 'dropout': 0.4980757220231453, 'stem_channels': np.int64(18), 'embed_channels': np.int64(32), 'se_reduction': np.int64(2), 'd_model': np.int64(20), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07358442398072308, 'grad_clip': 0.9443627452283823, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(10)}, value=0.8770
2025-09-29 13:30:34,004 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 46: {'lr': 0.002383629114697437, 'batch_size': np.int64(64), 'epochs': np.int64(28), 'weight_decay': 0.005031475153252525, 'dropout': 0.4980757220231453, 'stem_channels': np.int64(18), 'embed_channels': np.int64(32), 'se_reduction': np.int64(2), 'd_model': np.int64(20), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07358442398072308, 'grad_clip': 0.9443627452283823, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(10)} -> 0.8770
2025-09-29 13:30:34,005 - INFO - bo.run_bo - ðŸ”BO Trial 47: Using RF surrogate + Expected Improvement
2025-09-29 13:30:34,005 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:30:34,005 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:30:34,005 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:30:34,005 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00723809685771055, 'batch_size': 256, 'epochs': 23, 'weight_decay': 0.0005778424817419846, 'dropout': 0.17712764758843227, 'stem_channels': 27, 'embed_channels': 42, 'se_reduction': 4, 'd_model': 19, 'num_heads': 4, 'num_layers': 2, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08930933473178222, 'grad_clip': 0.4240185854703815, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}
2025-09-29 13:30:34,006 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00723809685771055, 'batch_size': 256, 'epochs': 23, 'weight_decay': 0.0005778424817419846, 'dropout': 0.17712764758843227, 'stem_channels': 27, 'embed_channels': 42, 'se_reduction': 4, 'd_model': 19, 'num_heads': 4, 'num_layers': 2, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08930933473178222, 'grad_clip': 0.4240185854703815, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}
2025-09-29 13:30:59,489 - INFO - _models.training_function_executor - Model: 88,487 parameters, 380.2KB storage
2025-09-29 13:30:59,489 - WARNING - _models.training_function_executor - Model storage 380.2KB exceeds 256KB limit!
2025-09-29 13:30:59,489 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9297902379035949, 0.7047055540084839, 0.6125323133468628, 0.5581953084468841, 0.5340386190414429, 0.5112531955242157, 0.4966964445114136, 0.4921380405426025, 0.48101342558860777, 0.47527106523513796, 0.46968856835365297, 0.46541781187057496, 0.4629202105998993, 0.4563946919441223, 0.4543122251033783, 0.44971095776557923, 0.44813593888282777, 0.4453016357421875, 0.4378578999042511, 0.43645064520835875, 0.4315874404907227, 0.4297561981678009, 0.4264008662700653], 'val_losses': [0.7739996090531349, 0.6211318336427212, 0.5528667876496911, 0.5729250609874725, 0.5157064059749246, 0.5061479266732931, 0.509022394195199, 0.4965855376794934, 0.49209695030003786, 0.4752841526642442, 0.4819376524537802, 0.47963837906718254, 0.4750261502340436, 0.4683390371501446, 0.4657618859782815, 0.4696819456294179, 0.47856882587075233, 0.4786865636706352, 0.4624830838292837, 0.457250258885324, 0.4549303902313113, 0.4656620668247342, 0.46626331470906734], 'val_acc': [0.8267134428024292, 0.8903645873069763, 0.9193083643913269, 0.9071545004844666, 0.9348452687263489, 0.9392306804656982, 0.9330911040306091, 0.942488431930542, 0.9466232061386108, 0.9508833289146423, 0.949505090713501, 0.9500062465667725, 0.9503821730613708, 0.9543916583061218, 0.9551434516906738, 0.9536399245262146, 0.9523869156837463, 0.9503821730613708, 0.9563964605331421, 0.9592782855033875, 0.9595288634300232, 0.9589024186134338, 0.9558952450752258], 'val_macro_f1': [0.442173433303833, 0.6263405203819274, 0.6679826736450195, 0.6548261046409607, 0.7021861329674721, 0.7239990890026092, 0.7181916952133178, 0.7608356595039367, 0.7258843898773193, 0.7937431514263154, 0.784734171628952, 0.7539250791072846, 0.8081137537956238, 0.8109514713287354, 0.8170167803764343, 0.8029000103473664, 0.8147132873535157, 0.8080647945404053, 0.811698853969574, 0.8342025876045227, 0.8162351727485657, 0.7948589026927948, 0.7872040629386902], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00723809685771055, 'batch_size': 256, 'epochs': 23, 'weight_decay': 0.0005778424817419846, 'dropout': 0.17712764758843227, 'stem_channels': 27, 'embed_channels': 42, 'se_reduction': 4, 'd_model': 19, 'num_heads': 4, 'num_layers': 2, 'patch_size': 100, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08930933473178222, 'grad_clip': 0.4240185854703815, 'scheduler': np.str_('none'), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 11}, 'model_parameter_count': 88487, 'model_storage_size_kb': 380.21757812500005, 'model_size_validation': 'FAIL'}
2025-09-29 13:30:59,489 - INFO - _models.training_function_executor - BO Objective: base=0.9559, size_penalty=0.2426, final=0.7133
2025-09-29 13:30:59,489 - INFO - _models.training_function_executor - Model: 88,487 parameters, 380.2KB (FAIL 256KB limit)
2025-09-29 13:30:59,489 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 25.485s
2025-09-29 13:30:59,611 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7133
2025-09-29 13:30:59,611 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.121s
2025-09-29 13:30:59,611 - INFO - bo.run_bo - Recorded observation #47: hparams={'lr': 0.00723809685771055, 'batch_size': np.int64(256), 'epochs': np.int64(23), 'weight_decay': 0.0005778424817419846, 'dropout': 0.17712764758843227, 'stem_channels': np.int64(27), 'embed_channels': np.int64(42), 'se_reduction': np.int64(4), 'd_model': np.int64(19), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08930933473178222, 'grad_clip': 0.4240185854703815, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(11)}, value=0.7133
2025-09-29 13:30:59,611 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 47: {'lr': 0.00723809685771055, 'batch_size': np.int64(256), 'epochs': np.int64(23), 'weight_decay': 0.0005778424817419846, 'dropout': 0.17712764758843227, 'stem_channels': np.int64(27), 'embed_channels': np.int64(42), 'se_reduction': np.int64(4), 'd_model': np.int64(19), 'num_heads': np.int64(4), 'num_layers': np.int64(2), 'patch_size': np.int64(100), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08930933473178222, 'grad_clip': 0.4240185854703815, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(11)} -> 0.7133
2025-09-29 13:30:59,611 - INFO - bo.run_bo - ðŸ”BO Trial 48: Using RF surrogate + Expected Improvement
2025-09-29 13:30:59,611 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:30:59,611 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:30:59,611 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:30:59,611 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0020549809819197097, 'batch_size': 512, 'epochs': 32, 'weight_decay': 0.001728210998820995, 'dropout': 0.2151934062656624, 'stem_channels': 31, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 18, 'num_heads': 2, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.05860349656599441, 'grad_clip': 0.9748106390960073, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 12}
2025-09-29 13:30:59,613 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0020549809819197097, 'batch_size': 512, 'epochs': 32, 'weight_decay': 0.001728210998820995, 'dropout': 0.2151934062656624, 'stem_channels': 31, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 18, 'num_heads': 2, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.05860349656599441, 'grad_clip': 0.9748106390960073, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 12}
2025-09-29 13:31:35,494 - INFO - _models.training_function_executor - Model: 34,862 parameters, 37.4KB storage
2025-09-29 13:31:35,494 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8868290640058971, 0.6416383035599239, 0.535148577084617, 0.4759144210626209, 0.4402836665274605, 0.4140303149109795, 0.39753442340426975, 0.3927902584038084, 0.37965632714922465, 0.376388748013784, 0.3730764899935041, 0.3650347770206512, 0.3617843687534332, 0.36023655912232777, 0.3530748093885089, 0.35141386304582867, 0.3469559034657857, 0.3451512735041361, 0.34383907583024764, 0.3396890007314228, 0.34008941669312737, 0.33617334801053245, 0.334581135284333, 0.33209086930941023, 0.3284966212416452, 0.33009303136477397, 0.3302689227792952, 0.3275200980050223, 0.3269883881485651, 0.3244863980346256, 0.3215176136720748, 0.3187064306130485], 'val_losses': [0.7652777582406998, 0.5624135620892048, 0.511103343218565, 0.451484989374876, 0.4278193525969982, 0.41276158578693867, 0.40807032957673073, 0.397316986694932, 0.40449269115924835, 0.382676986977458, 0.38214618153870106, 0.39121156372129917, 0.3816241789609194, 0.3874397836625576, 0.3796954248100519, 0.3804377354681492, 0.37462520599365234, 0.3755794521421194, 0.40506980009377, 0.3751161191612482, 0.3703643623739481, 0.37324546091258526, 0.3790430370718241, 0.3731236904859543, 0.36610946990549564, 0.3746618125587702, 0.3908876720815897, 0.37689264491200447, 0.3705873116850853, 0.3799178246408701, 0.3664898108690977, 0.3816128671169281], 'val_acc': [0.8087958693504333, 0.8840997219085693, 0.9033955931663513, 0.9278286099433899, 0.9362235069274902, 0.942488431930542, 0.9442425966262817, 0.9481267929077148, 0.9471244215965271, 0.9531387090682983, 0.9533892869949341, 0.9492544531822205, 0.9547675848007202, 0.9496303796768188, 0.9538905024528503, 0.955018162727356, 0.9596541523933411, 0.9553940892219543, 0.9416113495826721, 0.9600300788879395, 0.9590277075767517, 0.9577746987342834, 0.9558952450752258, 0.9582759141921997, 0.9610324501991272, 0.9573988318443298, 0.9528881311416626, 0.9584012031555176, 0.958025336265564, 0.9527627825737, 0.9605312347412109, 0.9555193781852722], 'val_macro_f1': [0.43143453598022463, 0.5391906201839447, 0.6456350803375244, 0.7253746032714844, 0.7264068484306335, 0.7624283075332642, 0.7831466972827912, 0.794023722410202, 0.7889059662818909, 0.8013378024101258, 0.8145222663879395, 0.7972581863403321, 0.8142432689666748, 0.814717960357666, 0.819490396976471, 0.8303382515907287, 0.8260494947433472, 0.8262590527534485, 0.8187264204025269, 0.8337336182594299, 0.832066535949707, 0.8319898247718811, 0.8117699742317199, 0.8327433824539184, 0.8370446681976318, 0.8383464336395263, 0.8143309473991394, 0.8341443061828613, 0.8473341703414917, 0.828636372089386, 0.8443061351776123, 0.832179319858551], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0020549809819197097, 'batch_size': 512, 'epochs': 32, 'weight_decay': 0.001728210998820995, 'dropout': 0.2151934062656624, 'stem_channels': 31, 'embed_channels': 43, 'se_reduction': 2, 'd_model': 18, 'num_heads': 2, 'num_layers': 2, 'patch_size': 40, 'class_weighting': np.str_('none'), 'label_smoothing': 0.05860349656599441, 'grad_clip': 0.9748106390960073, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calibrate_batches': 12}, 'model_parameter_count': 34862, 'model_storage_size_kb': 37.449414062500004, 'model_size_validation': 'PASS'}
2025-09-29 13:31:35,494 - INFO - _models.training_function_executor - BO Objective: base=0.9555, size_penalty=0.0000, final=0.9555
2025-09-29 13:31:35,494 - INFO - _models.training_function_executor - Model: 34,862 parameters, 37.4KB (PASS 256KB limit)
2025-09-29 13:31:35,494 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 35.883s
2025-09-29 13:31:35,616 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9555
2025-09-29 13:31:35,617 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.122s
2025-09-29 13:31:35,617 - INFO - bo.run_bo - Recorded observation #48: hparams={'lr': 0.0020549809819197097, 'batch_size': np.int64(512), 'epochs': np.int64(32), 'weight_decay': 0.001728210998820995, 'dropout': 0.2151934062656624, 'stem_channels': np.int64(31), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(18), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(40), 'class_weighting': np.str_('none'), 'label_smoothing': 0.05860349656599441, 'grad_clip': 0.9748106390960073, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(12)}, value=0.9555
2025-09-29 13:31:35,617 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 48: {'lr': 0.0020549809819197097, 'batch_size': np.int64(512), 'epochs': np.int64(32), 'weight_decay': 0.001728210998820995, 'dropout': 0.2151934062656624, 'stem_channels': np.int64(31), 'embed_channels': np.int64(43), 'se_reduction': np.int64(2), 'd_model': np.int64(18), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(40), 'class_weighting': np.str_('none'), 'label_smoothing': 0.05860349656599441, 'grad_clip': 0.9748106390960073, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(12)} -> 0.9555
2025-09-29 13:31:35,617 - INFO - bo.run_bo - ðŸ”BO Trial 49: Using RF surrogate + Expected Improvement
2025-09-29 13:31:35,617 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:31:35,617 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:31:35,617 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:31:35,617 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0005405479822947552, 'batch_size': 512, 'epochs': 42, 'weight_decay': 0.0001810395297812665, 'dropout': 0.3390484243688048, 'stem_channels': 32, 'embed_channels': 34, 'se_reduction': 2, 'd_model': 26, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08886962085543192, 'grad_clip': 0.9598236401660343, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 12}
2025-09-29 13:31:35,619 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0005405479822947552, 'batch_size': 512, 'epochs': 42, 'weight_decay': 0.0001810395297812665, 'dropout': 0.3390484243688048, 'stem_channels': 32, 'embed_channels': 34, 'se_reduction': 2, 'd_model': 26, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08886962085543192, 'grad_clip': 0.9598236401660343, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 12}
2025-09-29 13:32:14,911 - INFO - _models.training_function_executor - Model: 191,036 parameters, 820.9KB storage
2025-09-29 13:32:14,911 - WARNING - _models.training_function_executor - Model storage 820.9KB exceeds 256KB limit!
2025-09-29 13:32:14,911 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9885631099579826, 0.8797466102100554, 0.8043578096798488, 0.7402756110070243, 0.6941499757388282, 0.6521673524190509, 0.621739751762814, 0.5981572100094387, 0.5667370841616676, 0.572504186441028, 0.5401548572949001, 0.5343746244907379, 0.5282154135287754, 0.5207731364265321, 0.5056786149267166, 0.49982667631573147, 0.49533732211779036, 0.4876317963713691, 0.4813237649107736, 0.47848005474559846, 0.47349103575661067, 0.4727871905243586, 0.46901880181024946, 0.4627777465752193, 0.45859013426871525, 0.45666289424139356, 0.45330342603108237, 0.4508000844054752, 0.449317067861557, 0.4444529768966493, 0.4431219734842815, 0.4399844833782741, 0.43817047703833806, 0.43656202251949006, 0.4330607444520981, 0.43393770049488734, 0.43052259229478385, 0.43134788057160756, 0.42894481240756926, 0.4247763653596242, 0.42199707125860547, 0.4213710029919942], 'val_losses': [0.9277931898832321, 0.8201856352388859, 0.7969792671501637, 0.7011295445263386, 0.6740258112549782, 0.6437342837452888, 0.7017532549798489, 0.5867692083120346, 0.5590405501425266, 0.5718623399734497, 0.554947555065155, 0.5611944571137428, 0.5296171065419912, 0.5213705208152533, 0.5148994233459234, 0.5247902404516935, 0.5042158924043179, 0.5123997963964939, 0.5146004129201174, 0.5091901738196611, 0.5048799067735672, 0.5134016554802656, 0.5081089418381453, 0.5018594041466713, 0.5154279451817274, 0.5048709772527218, 0.5063768047839403, 0.5112603046000004, 0.5087808407843113, 0.5122357048094273, 0.5064244084060192, 0.5059949979186058, 0.5111784264445305, 0.5107592344284058, 0.5113395880907774, 0.5141187496483326, 0.5186162777245045, 0.5198535621166229, 0.5115469861775637, 0.5246042627841234, 0.5212726760655642, 0.5183631628751755], 'val_acc': [0.7382533550262451, 0.7866182327270508, 0.7789750695228577, 0.8527753353118896, 0.8658062815666199, 0.8858538866043091, 0.8425009250640869, 0.901390790939331, 0.9218143224716187, 0.9200601577758789, 0.925447940826416, 0.9147976636886597, 0.9325898885726929, 0.9382283091545105, 0.940233051776886, 0.930961012840271, 0.9428642988204956, 0.9398571848869324, 0.940984845161438, 0.9427390098571777, 0.9431148767471313, 0.9406089186668396, 0.9422377943992615, 0.9454955458641052, 0.940233051776886, 0.9466232061386108, 0.9456208348274231, 0.9448690414428711, 0.9453702569007874, 0.9452449679374695, 0.9454955458641052, 0.9467485547065735, 0.9452449679374695, 0.947249710559845, 0.9453702569007874, 0.945746123790741, 0.9427390098571777, 0.9446184635162354, 0.9488785862922668, 0.9434908032417297, 0.9446184635162354, 0.9462473392486572], 'val_macro_f1': [0.29293823093175886, 0.40569724440574645, 0.4262070536613464, 0.4844130888581276, 0.48099193572998045, 0.5153866715729236, 0.5158374518156051, 0.5954678453505039, 0.6547713067382575, 0.6510012401267886, 0.6702809453010559, 0.6667035341262817, 0.6900714337825775, 0.7166720777750015, 0.71772750467062, 0.7309067726135254, 0.7520213603973389, 0.7268173336982727, 0.7431840360164642, 0.7458624303340912, 0.7695079803466797, 0.7572592914104461, 0.768756526708603, 0.7722218215465546, 0.7935208916664124, 0.7804829895496368, 0.7718459725379944, 0.767552500963211, 0.7785123467445374, 0.7730725347995758, 0.7979266166687011, 0.7964671075344085, 0.7872250616550446, 0.7986854016780853, 0.8035703480243683, 0.7869402348995209, 0.7903751194477081, 0.7779422640800476, 0.8017815589904785, 0.7825238287448884, 0.7987575650215148, 0.7946831405162811], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0005405479822947552, 'batch_size': 512, 'epochs': 42, 'weight_decay': 0.0001810395297812665, 'dropout': 0.3390484243688048, 'stem_channels': 32, 'embed_channels': 34, 'se_reduction': 2, 'd_model': 26, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('none'), 'label_smoothing': 0.08886962085543192, 'grad_clip': 0.9598236401660343, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibrate_batches': 12}, 'model_parameter_count': 191036, 'model_storage_size_kb': 820.8578125, 'model_size_validation': 'FAIL'}
2025-09-29 13:32:14,911 - INFO - _models.training_function_executor - BO Objective: base=0.9462, size_penalty=0.8000, final=0.1462
2025-09-29 13:32:14,911 - INFO - _models.training_function_executor - Model: 191,036 parameters, 820.9KB (FAIL 256KB limit)
2025-09-29 13:32:14,911 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 39.294s
2025-09-29 13:32:15,034 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1462
2025-09-29 13:32:15,034 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.123s
2025-09-29 13:32:15,035 - INFO - bo.run_bo - Recorded observation #49: hparams={'lr': 0.0005405479822947552, 'batch_size': np.int64(512), 'epochs': np.int64(42), 'weight_decay': 0.0001810395297812665, 'dropout': 0.3390484243688048, 'stem_channels': np.int64(32), 'embed_channels': np.int64(34), 'se_reduction': np.int64(2), 'd_model': np.int64(26), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08886962085543192, 'grad_clip': 0.9598236401660343, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(12)}, value=0.1462
2025-09-29 13:32:15,035 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 49: {'lr': 0.0005405479822947552, 'batch_size': np.int64(512), 'epochs': np.int64(42), 'weight_decay': 0.0001810395297812665, 'dropout': 0.3390484243688048, 'stem_channels': np.int64(32), 'embed_channels': np.int64(34), 'se_reduction': np.int64(2), 'd_model': np.int64(26), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(200), 'class_weighting': np.str_('none'), 'label_smoothing': 0.08886962085543192, 'grad_clip': 0.9598236401660343, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calibrate_batches': np.int64(12)} -> 0.1462
2025-09-29 13:32:15,035 - INFO - bo.run_bo - ðŸ”BO Trial 50: Using RF surrogate + Expected Improvement
2025-09-29 13:32:15,035 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-29 13:32:15,035 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:32:15,035 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:32:15,035 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0021554455464053088, 'batch_size': 512, 'epochs': 33, 'weight_decay': 7.12654361482329e-06, 'dropout': 0.19642144418875113, 'stem_channels': 22, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 24, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0870231082703177, 'grad_clip': 0.7690374120463908, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 1}
2025-09-29 13:32:15,037 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0021554455464053088, 'batch_size': 512, 'epochs': 33, 'weight_decay': 7.12654361482329e-06, 'dropout': 0.19642144418875113, 'stem_channels': 22, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 24, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0870231082703177, 'grad_clip': 0.7690374120463908, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 1}
2025-09-29 13:32:44,688 - INFO - _models.training_function_executor - Model: 159,950 parameters, 171.8KB storage
2025-09-29 13:32:44,689 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.951670419602167, 1.6469447537074013, 1.5169801655269803, 1.460738329660325, 1.41671960126786, 1.3725440937375266, 1.3455108366315327, 1.3246287258844527, 1.2975997943726798, 1.2852754630739727, 1.2788828819517106, 1.2622495586909945, 1.249785408141121, 1.2384878813274323, 1.2302709325911507, 1.2229188018374972, 1.2200325065188937, 1.207155738558088, 1.2095253486481925, 1.191297313523671, 1.1902723728664337, 1.184088699401371, 1.176372772171384, 1.1690618726942275, 1.1613879317329043, 1.1764575876886882, 1.1474901948656355, 1.1499901319306993, 1.1469071015479073, 1.1441920730802748, 1.1318911512692769, 1.1369082681716434, 1.12831497570825], 'val_losses': [1.759962610900402, 1.538013033568859, 1.4804228469729424, 1.4408443570137024, 1.4168513044714928, 1.3832556754350662, 1.3593136966228485, 1.3555318415164948, 1.3315510302782059, 1.3445777669548988, 1.3217991217970848, 1.3041910752654076, 1.3377698138356209, 1.3041253089904785, 1.3054057136178017, 1.2989332377910614, 1.300838679075241, 1.3404492884874344, 1.3130090236663818, 1.314673125743866, 1.2931987792253494, 1.296671986579895, 1.2938768491148949, 1.3103798404335976, 1.331267572939396, 1.315434955060482, 1.3153240233659744, 1.3163613975048065, 1.3044328391551971, 1.2957760319113731, 1.2937187924981117, 1.3263740539550781, 1.3351879641413689], 'val_acc': [0.13256484270095825, 0.3624859154224396, 0.4979325830936432, 0.40045106410980225, 0.5073298811912537, 0.4801403284072876, 0.677108108997345, 0.524746298789978, 0.6445307731628418, 0.5742388367652893, 0.5926575660705566, 0.7225911617279053, 0.6703420877456665, 0.6913920640945435, 0.640521228313446, 0.7209622859954834, 0.7371256947517395, 0.8666833639144897, 0.7759678959846497, 0.8277158141136169, 0.8669339418411255, 0.8624232411384583, 0.8735747337341309, 0.881969690322876, 0.8275905251502991, 0.8774589896202087, 0.8738253116607666, 0.8614208698272705, 0.8443803787231445, 0.8546547889709473, 0.8934970498085022, 0.8931211829185486, 0.9026437997817993], 'val_macro_f1': [0.21321021392941475, 0.40053635835647583, 0.472081346809864, 0.43452484011650083, 0.4954005628824234, 0.49566360712051394, 0.5832905173301697, 0.5145343855023384, 0.5590187460184097, 0.5507037341594696, 0.5394165784120559, 0.5915897846221924, 0.5741775155067443, 0.5819611370563507, 0.5685052663087845, 0.6033632397651673, 0.6084896802902222, 0.694851553440094, 0.6302135825157166, 0.67577024102211, 0.7114526450634002, 0.6939183294773101, 0.7111155450344085, 0.7229418218135834, 0.6606704354286194, 0.7142604529857636, 0.7013044774532318, 0.6875278413295746, 0.6775303959846497, 0.6838546097278595, 0.7309833526611328, 0.7215537905693055, 0.7461116850376129], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0021554455464053088, 'batch_size': 512, 'epochs': 33, 'weight_decay': 7.12654361482329e-06, 'dropout': 0.19642144418875113, 'stem_channels': 22, 'embed_channels': 33, 'se_reduction': 8, 'd_model': 24, 'num_heads': 2, 'num_layers': 2, 'patch_size': 200, 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0870231082703177, 'grad_clip': 0.7690374120463908, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 1}, 'model_parameter_count': 159950, 'model_storage_size_kb': 171.8212890625, 'model_size_validation': 'PASS'}
2025-09-29 13:32:44,689 - INFO - _models.training_function_executor - BO Objective: base=0.9026, size_penalty=0.0000, final=0.9026
2025-09-29 13:32:44,689 - INFO - _models.training_function_executor - Model: 159,950 parameters, 171.8KB (PASS 256KB limit)
2025-09-29 13:32:44,689 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 29.653s
2025-09-29 13:32:44,811 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9026
2025-09-29 13:32:44,811 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.123s
2025-09-29 13:32:44,811 - INFO - bo.run_bo - Recorded observation #50: hparams={'lr': 0.0021554455464053088, 'batch_size': np.int64(512), 'epochs': np.int64(33), 'weight_decay': 7.12654361482329e-06, 'dropout': 0.19642144418875113, 'stem_channels': np.int64(22), 'embed_channels': np.int64(33), 'se_reduction': np.int64(8), 'd_model': np.int64(24), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(200), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0870231082703177, 'grad_clip': 0.7690374120463908, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(1)}, value=0.9026
2025-09-29 13:32:44,811 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 50: {'lr': 0.0021554455464053088, 'batch_size': np.int64(512), 'epochs': np.int64(33), 'weight_decay': 7.12654361482329e-06, 'dropout': 0.19642144418875113, 'stem_channels': np.int64(22), 'embed_channels': np.int64(33), 'se_reduction': np.int64(8), 'd_model': np.int64(24), 'num_heads': np.int64(2), 'num_layers': np.int64(2), 'patch_size': np.int64(200), 'class_weighting': np.str_('balanced'), 'label_smoothing': 0.0870231082703177, 'grad_clip': 0.7690374120463908, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(1)} -> 0.9026
2025-09-29 13:32:44,811 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.9663
2025-09-29 13:32:44,811 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.002441222965902701, 'batch_size': np.int64(128), 'epochs': np.int64(40), 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': np.int64(29), 'embed_channels': np.int64(32), 'se_reduction': np.int64(2), 'd_model': np.int64(29), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(10), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(9)}
2025-09-29 13:32:44,812 - INFO - visualization - Generating BO visualization charts with 50 trials...
2025-09-29 13:32:46,275 - INFO - visualization - BO summary saved to: charts/20250929_133244_BO_CAT-Net Tiny (1D CNN + Channel Attention + Transformer)/bo_summary.txt
2025-09-29 13:32:46,275 - INFO - visualization - BO charts saved to: charts/20250929_133244_BO_CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:32:46,275 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ“Š BO charts saved to: charts/20250929_133244_BO_CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:32:46,319 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸš€ STEP 4: Final Training Execution
2025-09-29 13:32:46,319 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (39904, 1000, 2), Val: (9977, 1000, 2), Test: (12471, 1000, 2)
2025-09-29 13:32:46,411 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-29 13:32:46,423 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-29 13:32:46,438 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-29 13:32:46,438 - INFO - _models.training_function_executor - Loaded training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:32:46,438 - INFO - _models.training_function_executor - Reasoning: No reasoning provided
2025-09-29 13:32:46,438 - INFO - evaluation.code_generation_pipeline_orchestrator - Executing final training with optimized params: {'lr': 0.002441222965902701, 'batch_size': np.int64(128), 'epochs': np.int64(40), 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': np.int64(29), 'embed_channels': np.int64(32), 'se_reduction': np.int64(2), 'd_model': np.int64(29), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(10), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(9)}
2025-09-29 13:32:46,438 - INFO - evaluation.code_generation_pipeline_orchestrator - Using test set for final training evaluation
2025-09-29 13:32:46,438 - INFO - _models.training_function_executor - Using device: cuda
2025-09-29 13:32:46,461 - INFO - _models.training_function_executor - Executing training function: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:32:46,461 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002441222965902701, 'batch_size': np.int64(128), 'epochs': np.int64(40), 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': np.int64(29), 'embed_channels': np.int64(32), 'se_reduction': np.int64(2), 'd_model': np.int64(29), 'num_heads': np.int64(2), 'num_layers': np.int64(1), 'patch_size': np.int64(10), 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calibrate_batches': np.int64(9)}
2025-09-29 13:32:46,462 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002441222965902701, 'batch_size': 128, 'epochs': 40, 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': 29, 'embed_channels': 32, 'se_reduction': 2, 'd_model': 29, 'num_heads': 2, 'num_layers': 1, 'patch_size': 10, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 9}
2025-09-29 13:33:59,493 - INFO - _models.training_function_executor - Model: 11,960 parameters, 12.8KB storage
2025-09-29 13:33:59,493 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7749044633446596, 0.5641544894912304, 0.5073727365487661, 0.47696732586392987, 0.46171759766263837, 0.44740044115445554, 0.4363232668584738, 0.4294637685211805, 0.42285194391241443, 0.4152524684293148, 0.4106301531577722, 0.40615122851270896, 0.40365314254393947, 0.3996985600544856, 0.3978549578250983, 0.39476675005295336, 0.3932092041732409, 0.38990222710447436, 0.38719692730750793, 0.3856836845859503, 0.38328892833147293, 0.3825567686595978, 0.38029699304547065, 0.3781921802422939, 0.3775326151114244, 0.37610130747541404, 0.37491070106625557, 0.3741508124348445, 0.37295944176805323, 0.37205201884110767, 0.3699004527850029, 0.36980107292915004, 0.3686159565471686, 0.3684068461641287, 0.36672512489633685, 0.36518563855534947, 0.36568393567815805, 0.3642292659825239, 0.3648614222422624, 0.3646394772789417], 'val_losses': [0.6165963520809096, 0.5347270454679217, 0.4995580388575184, 0.47326202447317084, 0.4619947355620715, 0.46191326179066483, 0.44273062476090025, 0.43618208382810864, 0.43911076382714875, 0.4375203750571426, 0.4176468459927306, 0.4186808305735491, 0.4214372601436109, 0.41493123313602137, 0.4153886191090759, 0.4203462993003884, 0.4015271350437281, 0.40652514537986445, 0.4018798935778287, 0.3987961396270869, 0.39851825334587876, 0.3947827563602097, 0.403165092881845, 0.4024952385498553, 0.3996552225886559, 0.3923765770634826, 0.3942824802836593, 0.3940059652133864, 0.38991088557000064, 0.3964876635950439, 0.393680495571117, 0.3873032358836155, 0.3883314594930532, 0.3950710181070834, 0.3909905324785077, 0.38683065133435385, 0.38844857745024625, 0.3867404454824876, 0.38458215795001205, 0.38224430138967475], 'val_acc': [0.8804426193237305, 0.9158848524093628, 0.9286344051361084, 0.9375351071357727, 0.9417849183082581, 0.9468366503715515, 0.9495629668235779, 0.9503648281097412, 0.9517279863357544, 0.9517279863357544, 0.9579825401306152, 0.9570202827453613, 0.9587844014167786, 0.9593456983566284, 0.9597465991973877, 0.9603078961372375, 0.9639964699745178, 0.9619116187095642, 0.9647983312606812, 0.964878499507904, 0.9660813212394714, 0.9688878059387207, 0.9666426181793213, 0.9651190638542175, 0.9671237468719482, 0.9713735580444336, 0.9686472415924072, 0.9688076376914978, 0.9702509641647339, 0.9704113602638245, 0.9675246477127075, 0.9703311920166016, 0.9697698950767517, 0.9679256081581116, 0.9684869050979614, 0.9707320928573608, 0.9690482020378113, 0.9717745184898376, 0.9708122611045837, 0.9731376767158508], 'val_macro_f1': [0.5905843555927277, 0.6694664001464844, 0.6805596441030503, 0.6931287467479705, 0.7374436736106873, 0.7319029450416565, 0.7533812254667283, 0.7925384402275085, 0.784240996837616, 0.7421177387237549, 0.8239642024040222, 0.8078158736228943, 0.8192232728004456, 0.8028729081153869, 0.813357537984848, 0.8060198485851288, 0.8410699844360352, 0.8363614201545715, 0.8515419602394104, 0.8432998061180115, 0.853666079044342, 0.8717796206474304, 0.8500302791595459, 0.8403588771820069, 0.8719810605049133, 0.8755990743637085, 0.8761059165000915, 0.8680553793907165, 0.8728011727333069, 0.8766939043998718, 0.8685420274734497, 0.8796023368835449, 0.8808905601501464, 0.8700283765792847, 0.8763001203536988, 0.8844945192337036, 0.8755034327507019, 0.880656623840332, 0.8733937501907348, 0.8872487306594848], 'model_name': 'CAT-Net Tiny (1D CNN + Channel Attention + Transformer)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002441222965902701, 'batch_size': 128, 'epochs': 40, 'weight_decay': 0.0007260605286391634, 'dropout': 0.1479640273233849, 'stem_channels': 29, 'embed_channels': 32, 'se_reduction': 2, 'd_model': 29, 'num_heads': 2, 'num_layers': 1, 'patch_size': 10, 'class_weighting': np.str_('none'), 'label_smoothing': 0.07401352981561041, 'grad_clip': 0.48441322903602624, 'scheduler': np.str_('none'), 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calibrate_batches': 9}, 'model_parameter_count': 11960, 'model_storage_size_kb': 12.847656250000002, 'model_size_validation': 'PASS'}
2025-09-29 13:33:59,493 - INFO - evaluation.code_generation_pipeline_orchestrator - Using final test metrics from training (avoids preprocessing mismatch)
2025-09-29 13:33:59,493 - INFO - evaluation.code_generation_pipeline_orchestrator - Final test metrics: {'acc': 0.9731376767158508, 'macro_f1': None}
2025-09-29 13:33:59,504 - INFO - evaluation.code_generation_pipeline_orchestrator - ðŸ“Š STEP 5: Performance Analysis
2025-09-29 13:33:59,504 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated Model: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:33:59,504 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Score: 0.9663
2025-09-29 13:33:59,504 - INFO - evaluation.code_generation_pipeline_orchestrator - Final Score: 0.9731
2025-09-29 13:33:59,504 - INFO - evaluation.code_generation_pipeline_orchestrator - CODE GENERATION PIPELINE COMPLETE!
2025-09-29 13:33:59,504 - INFO - evaluation.code_generation_pipeline_orchestrator - Model: CAT-Net Tiny (1D CNN + Channel Attention + Transformer)
2025-09-29 13:33:59,504 - INFO - evaluation.code_generation_pipeline_orchestrator - Score: 0.9731
2025-09-29 13:33:59,504 - INFO - __main__ - AI-enhanced training completed!
2025-09-29 13:33:59,504 - INFO - __main__ - Final model achieved: {'acc': 0.9731376767158508, 'macro_f1': None}
2025-09-29 13:33:59,504 - INFO - __main__ - Pipeline completed successfully in single attempt
2025-09-29 13:33:59,504 - INFO - __main__ - Pipeline completed: CAT-Net Tiny (1D CNN + Channel Attention + Transformer), metrics: {'acc': 0.9731376767158508, 'macro_f1': None}
2025-09-29 13:33:59,504 - INFO - __main__ - Pipeline summary saved to charts/pipeline_summary_20250929_133359.json
2025-09-29 13:33:59,507 - INFO - __main__ - Model saved: trained_models/best_model_CAT-Net Tiny (1D CNN + Channel Attention + Transformer)_20250929_133359.pth, performance: {'acc': 0.9731376767158508, 'macro_f1': None}
2025-09-29 13:33:59,508 - INFO - __main__ - AI-enhanced processing completed successfully
