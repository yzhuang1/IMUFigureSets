2025-09-15 20:39:27,431 - INFO - __main__ - Logging system initialized successfully
2025-09-15 20:39:27,433 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'y.npy', 'X.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-09-15 20:39:27,434 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-09-15 20:39:27,434 - INFO - __main__ - Attempting to load: y.npy
2025-09-15 20:39:27,435 - INFO - __main__ - Attempting to load: X.npy
2025-09-15 20:39:27,746 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-09-15 20:39:28,088 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-09-15 20:39:28,088 - INFO - __main__ - Starting AI-enhanced training with new pipeline flow
2025-09-15 20:39:28,088 - INFO - __main__ - Flow: Template Selection → BO → Evaluation → Feedback Loop
2025-09-15 20:39:28,101 - INFO - __main__ - Data profile: {'data_type': 'numpy_array', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-09-15 20:39:28,102 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized with max 4 attempts
2025-09-15 20:39:28,102 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution
2025-09-15 20:39:28,102 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation → JSON Storage → BO → Training Execution → Evaluation
2025-09-15 20:39:28,102 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-09-15 20:39:28,102 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-09-15 20:39:28,103 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-09-15 20:39:28,104 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-09-15 20:39:28,763 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-09-15 20:39:28,764 - INFO - class_balancing - Class imbalance analysis:
2025-09-15 20:39:28,764 - INFO - class_balancing -   Strategy: severe_imbalance
2025-09-15 20:39:28,764 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-09-15 20:39:28,764 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-09-15 20:39:28,764 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-09-15 20:39:28,765 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-09-15 20:39:28,765 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-09-15 20:39:28,766 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-09-15 20:39:28,766 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-09-15 20:39:30,111 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-09-15 20:39:30,114 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-09-15 20:39:30,117 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-15 20:39:30,117 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE ATTEMPT 1/4
2025-09-15 20:39:30,117 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-15 20:39:30,117 - INFO - evaluation.code_generation_pipeline_orchestrator - 🤖 STEP 1: AI Training Code Generation
2025-09-15 20:39:30,118 - INFO - models.ai_code_generator - Making API call to gpt-5
2025-09-15 20:39:30,118 - INFO - models.ai_code_generator - Prompt length: 1606 characters
2025-09-15 20:39:30,118 - INFO - models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-15 20:39:30,118 - INFO - models.ai_code_generator - Calling self.client.responses.create...
2025-09-15 20:39:30,118 - INFO - models.ai_code_generator - Model parameter: gpt-5
2025-09-15 20:39:30,118 - INFO - models.ai_code_generator - Input prompt preview: Generate PyTorch training function for 5-class classification.

Data: numpy_array, shape (1000, 2), 62352 samples

Dataset: MIT-BIH Arrhythmia Database
Source: https://physionet.org/content/mitdb/1.0....
2025-09-15 20:40:38,207 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-15 20:40:38,355 - INFO - models.ai_code_generator - API call completed successfully
2025-09-15 20:40:38,355 - INFO - models.ai_code_generator - Response type: <class 'openai.types.responses.response.Response'>
2025-09-15 20:40:38,356 - INFO - models.ai_code_generator - Response attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_request_id', '_setattr_handler', 'background', 'construct', 'conversation', 'copy', 'created_at', 'dict', 'error', 'from_orm', 'id', 'incomplete_details', 'instructions', 'json', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'object', 'output', 'output_text', 'parallel_tool_calls', 'parse_file', 'parse_obj', 'parse_raw', 'previous_response_id', 'prompt', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'schema', 'schema_json', 'service_tier', 'status', 'temperature', 'text', 'to_dict', 'to_json', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'update_forward_refs', 'usage', 'user', 'validate']
2025-09-15 20:40:38,356 - INFO - models.ai_code_generator - Using response.output_text
2025-09-15 20:40:38,356 - INFO - models.ai_code_generator - Extracted result length: 8670 characters
2025-09-15 20:40:38,356 - INFO - models.ai_code_generator - Result preview: {
    "model_name": "TinyECG1D-CNN",
    "training_code": "def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import torch\n    import torch.nn as nn\n    from torch.utils.da...
2025-09-15 20:40:38,356 - INFO - models.ai_code_generator - Successfully extracted response content
2025-09-15 20:40:38,356 - INFO - models.ai_code_generator - AI generated training function: TinyECG1D-CNN
2025-09-15 20:40:38,357 - INFO - models.ai_code_generator - Confidence: 0.90
2025-09-15 20:40:38,357 - INFO - models.ai_code_generator - Reasoning: A compact 1D CNN with depthwise-separable convolutions is effective and parameter-efficient for ECG waveform classification. MIT-BIH Arrhythmia is class-imbalanced; using macro-F1 for validation and optional inverse-frequency class weights can improve robustness. Global average pooling with a small MLP head keeps parameters well under 256K while preserving temporal receptive fields across the 1000-sample sequences.
2025-09-15 20:40:38,357 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: TinyECG1D-CNN
2025-09-15 20:40:38,357 - INFO - evaluation.code_generation_pipeline_orchestrator - Reasoning: A compact 1D CNN with depthwise-separable convolutions is effective and parameter-efficient for ECG waveform classification. MIT-BIH Arrhythmia is class-imbalanced; using macro-F1 for validation and optional inverse-frequency class weights can improve robustness. Global average pooling with a small MLP head keeps parameters well under 256K while preserving temporal receptive fields across the 1000-sample sequences.
2025-09-15 20:40:38,357 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'hidden_size', 'dropout']
2025-09-15 20:40:38,357 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.90
2025-09-15 20:40:38,357 - INFO - evaluation.code_generation_pipeline_orchestrator - 💾 STEP 2: Save Training Function to JSON
2025-09-15 20:40:38,358 - INFO - models.ai_code_generator - Training function saved to: generated_training_functions/training_function_numpy_array_TinyECG1D-CNN_1757968838.json
2025-09-15 20:40:38,358 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_numpy_array_TinyECG1D-CNN_1757968838.json
2025-09-15 20:40:38,363 - INFO - models.training_function_executor - Training function validation passed
2025-09-15 20:40:38,363 - INFO - evaluation.code_generation_pipeline_orchestrator - 🔍 STEP 3: Bayesian Optimization
2025-09-15 20:40:38,364 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: TinyECG1D-CNN
2025-09-15 20:40:38,409 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 5000 samples
2025-09-15 20:40:38,410 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'hidden_size', 'dropout']
2025-09-15 20:40:38,410 - INFO - models.training_function_executor - GPU available: NVIDIA H100 NVL
2025-09-15 20:40:38,410 - WARNING - models.training_function_executor - Using provided subset instead of centralized splits - this may cause data leakage
2025-09-15 20:40:38,998 - INFO - bo.run_bo - Using default search space
2025-09-15 20:40:39,000 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-15 20:40:39,009 - INFO - bo.run_bo - Using explicitly provided search space
2025-09-15 20:40:39,011 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-15 20:40:39,013 - INFO - bo.run_bo - BO Trial 1: Initial random exploration
2025-09-15 20:40:39,013 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-09-15 20:40:39,014 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:40:39,014 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:40:39,014 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': 10, 'hidden_size': 204, 'dropout': 0.41779511056254093}
2025-09-15 20:40:39,019 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.01535224694197351, 'epochs': 10, 'batch_size': 16, 'hidden_size': 204, 'dropout': 0.41779511056254093}
2025-09-15 20:41:05,770 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.4593979408740998, 1.2845862348079682, 1.1580091940164565, 1.0927256628274917, 1.1324594029188155, 1.0527471641302109, 0.9862140412926674, 0.9613072452545166, 0.868884459912777, 0.9401431449353695], 'val_loss': [1.2728223085403443, 1.16700661277771, 1.028020005941391, 1.050846670627594, 1.0511624393463135, 0.9481356290578842, 0.7962495045661926, 0.8240283646583557, 0.7731721816062928, 0.663641078710556], 'val_acc': [0.208, 0.357, 0.684, 0.544, 0.698, 0.719, 0.72, 0.768, 0.696, 0.823], 'val_f1': [0.25406724214553833, 0.3094714283943176, 0.4531661570072174, 0.42632561922073364, 0.4899781346321106, 0.49524015188217163, 0.6068404316902161, 0.561951756477356, 0.602306067943573, 0.6327149868011475], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.01535224694197351, 'epochs': 10, 'batch_size': 16, 'hidden_size': 204, 'dropout': 0.41779511056254093}}
2025-09-15 20:41:05,771 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 26.758s
2025-09-15 20:41:05,773 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:41:05,773 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.001s
2025-09-15 20:41:05,773 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}, value=0.0000
2025-09-15 20:41:05,774 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093} -> 0.0000
2025-09-15 20:41:05,777 - INFO - bo.run_bo - BO Trial 2: Initial random exploration
2025-09-15 20:41:05,777 - INFO - bo.run_bo - [PROFILE] suggest() took 0.003s
2025-09-15 20:41:05,777 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:41:05,777 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:41:05,777 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': 13, 'hidden_size': 103, 'dropout': 0.2335960277973153}
2025-09-15 20:41:05,782 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006071989493441302, 'epochs': 13, 'batch_size': 8, 'hidden_size': 103, 'dropout': 0.2335960277973153}
2025-09-15 20:42:04,604 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.2149792374372483, 0.8708110833466053, 0.698911525785923, 0.5870259260758758, 0.5122040259521454, 0.4733244292885065, 0.45566726437211036, 0.440745992641896, 0.403429748814553, 0.3958246269449592, 0.37695868219807743, 0.3752141699064523, 0.3383031013086438], 'val_loss': [0.9259229571819305, 0.69294958370924, 0.6296535260975361, 0.500158856511116, 0.4684961889833212, 0.42962322977185247, 0.4097912914454937, 0.3879600391536951, 0.3227583135962486, 0.3663786060810089, 0.3329424569904804, 0.30848098804801705, 0.3338765992745757], 'val_acc': [0.764, 0.862, 0.864, 0.936, 0.923, 0.919, 0.859, 0.933, 0.918, 0.839, 0.864, 0.935, 0.902], 'val_f1': [0.524886965751648, 0.6727461814880371, 0.6469678282737732, 0.7748361825942993, 0.7099800705909729, 0.750386118888855, 0.6866967678070068, 0.7698155641555786, 0.7589618563652039, 0.6706192493438721, 0.7190459966659546, 0.7855337858200073, 0.7418326139450073], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0006071989493441302, 'epochs': 13, 'batch_size': 8, 'hidden_size': 103, 'dropout': 0.2335960277973153}}
2025-09-15 20:42:04,605 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 58.828s
2025-09-15 20:42:04,607 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:42:04,607 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.001s
2025-09-15 20:42:04,607 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': np.int64(13), 'hidden_size': np.int64(103), 'dropout': 0.2335960277973153}, value=0.0000
2025-09-15 20:42:04,607 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 0.0006071989493441302, 'batch_size': 8, 'epochs': np.int64(13), 'hidden_size': np.int64(103), 'dropout': 0.2335960277973153} -> 0.0000
2025-09-15 20:42:04,610 - INFO - bo.run_bo - BO Trial 3: Initial random exploration
2025-09-15 20:42:04,610 - INFO - bo.run_bo - [PROFILE] suggest() took 0.003s
2025-09-15 20:42:04,611 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:42:04,611 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:42:04,611 - INFO - models.training_function_executor - Hyperparameters: {'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': 23, 'hidden_size': 273, 'dropout': 0.5053991405867774}
2025-09-15 20:42:04,616 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 3.727925903376984e-05, 'epochs': 23, 'batch_size': 64, 'hidden_size': 273, 'dropout': 0.5053991405867774}
2025-09-15 20:42:19,453 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.6100642070770264, 1.5764555959701538, 1.5466241750717162, 1.5250742149353027, 1.4988234796524047, 1.4653533506393432, 1.436242838859558, 1.4141033344268799, 1.3922711219787598, 1.3577686624526977, 1.3443551969528198, 1.317808141708374, 1.285095597267151, 1.2746179609298707, 1.2584964971542358, 1.2505380153656005, 1.2300386428833008, 1.1997670650482177, 1.1971922826766968, 1.1845005702972413, 1.1681768832206727, 1.1511629734039306, 1.153594027519226], 'val_loss': [1.5876724004745484, 1.560418664932251, 1.5367823152542115, 1.5124908304214477, 1.491762725830078, 1.4652335405349732, 1.4412519836425781, 1.4141217775344848, 1.3925316514968873, 1.371439076423645, 1.3496312398910522, 1.3351333961486815, 1.3113788242340088, 1.2951216249465942, 1.28479727268219, 1.2642124795913696, 1.2564797878265381, 1.243678406715393, 1.2247556762695313, 1.2130761365890503, 1.1989304704666137, 1.1910486822128297, 1.175712737083435], 'val_acc': [0.136, 0.267, 0.321, 0.336, 0.351, 0.355, 0.368, 0.381, 0.377, 0.371, 0.392, 0.377, 0.388, 0.405, 0.453, 0.436, 0.431, 0.446, 0.451, 0.473, 0.455, 0.469, 0.486], 'val_f1': [0.08752965927124023, 0.153290793299675, 0.16964788734912872, 0.1757463961839676, 0.18526683747768402, 0.20154926180839539, 0.21857118606567383, 0.25509709119796753, 0.26334625482559204, 0.2730713188648224, 0.2857487201690674, 0.28067609667778015, 0.2877742648124695, 0.31036901473999023, 0.3377908766269684, 0.33377543091773987, 0.33681225776672363, 0.3469100296497345, 0.350782185792923, 0.3726227879524231, 0.36918315291404724, 0.3739262521266937, 0.3891924023628235], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 3.727925903376984e-05, 'epochs': 23, 'batch_size': 64, 'hidden_size': 273, 'dropout': 0.5053991405867774}}
2025-09-15 20:42:19,454 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 14.843s
2025-09-15 20:42:19,854 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:42:19,854 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.400s
2025-09-15 20:42:19,854 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': np.int64(23), 'hidden_size': np.int64(273), 'dropout': 0.5053991405867774}, value=0.0000
2025-09-15 20:42:19,854 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 3.727925903376984e-05, 'batch_size': 64, 'epochs': np.int64(23), 'hidden_size': np.int64(273), 'dropout': 0.5053991405867774} -> 0.0000
2025-09-15 20:42:19,855 - INFO - bo.run_bo - BO Trial 4: Using RF surrogate + Expected Improvement
2025-09-15 20:42:19,855 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:42:19,855 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:42:19,855 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:42:19,855 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.05678201970293135, 'batch_size': 32, 'epochs': 5, 'hidden_size': 183, 'dropout': 0.08439771317838103}
2025-09-15 20:42:19,859 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.05678201970293135, 'epochs': 5, 'batch_size': 32, 'hidden_size': 183, 'dropout': 0.08439771317838103}
2025-09-15 20:42:25,796 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.654302119255066, 1.5185429191589355, 1.4376126828193665, 1.4378001480102538, 1.3497596917152406], 'val_loss': [1.5651122808456421, 1.4746946058273316, 1.3994951972961425, 1.4138120861053467, 1.338953242301941], 'val_acc': [0.082, 0.28, 0.401, 0.736, 0.281], 'val_f1': [0.08681686222553253, 0.21245691180229187, 0.24641819298267365, 0.29418104887008667, 0.21962258219718933], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.05678201970293135, 'epochs': 5, 'batch_size': 32, 'hidden_size': 183, 'dropout': 0.08439771317838103}}
2025-09-15 20:42:25,797 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 5.942s
2025-09-15 20:42:26,190 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:42:26,190 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.393s
2025-09-15 20:42:26,190 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 0.05678201970293135, 'batch_size': np.int64(32), 'epochs': np.int64(5), 'hidden_size': np.int64(183), 'dropout': 0.08439771317838103}, value=0.0000
2025-09-15 20:42:26,190 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 0.05678201970293135, 'batch_size': np.int64(32), 'epochs': np.int64(5), 'hidden_size': np.int64(183), 'dropout': 0.08439771317838103} -> 0.0000
2025-09-15 20:42:26,191 - INFO - bo.run_bo - BO Trial 5: Using RF surrogate + Expected Improvement
2025-09-15 20:42:26,191 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:42:26,191 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:42:26,191 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:42:26,191 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006550049531232524, 'batch_size': 256, 'epochs': 6, 'hidden_size': 373, 'dropout': 0.4568590869235105}
2025-09-15 20:42:26,196 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006550049531232524, 'epochs': 6, 'batch_size': 256, 'hidden_size': 373, 'dropout': 0.4568590869235105}
2025-09-15 20:42:27,621 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.5155789442062377, 1.330994475364685, 1.182081280708313, 1.089703293800354, 0.9891267433166504, 0.8982369356155395], 'val_loss': [1.5986010332107543, 1.4272700119018555, 1.2252898559570313, 1.1013430547714234, 1.0242287673950194, 0.9592926940917968], 'val_acc': [0.039, 0.333, 0.469, 0.468, 0.593, 0.565], 'val_f1': [0.04018223285675049, 0.27648019790649414, 0.3865501284599304, 0.3948022425174713, 0.46477261185646057, 0.46155062317848206], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0006550049531232524, 'epochs': 6, 'batch_size': 256, 'hidden_size': 373, 'dropout': 0.4568590869235105}}
2025-09-15 20:42:27,622 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 1.431s
2025-09-15 20:42:28,006 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:42:28,007 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.385s
2025-09-15 20:42:28,007 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 0.0006550049531232524, 'batch_size': np.int64(256), 'epochs': np.int64(6), 'hidden_size': np.int64(373), 'dropout': 0.4568590869235105}, value=0.0000
2025-09-15 20:42:28,007 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 0.0006550049531232524, 'batch_size': np.int64(256), 'epochs': np.int64(6), 'hidden_size': np.int64(373), 'dropout': 0.4568590869235105} -> 0.0000
2025-09-15 20:42:28,007 - INFO - bo.run_bo - BO Trial 6: Using RF surrogate + Expected Improvement
2025-09-15 20:42:28,007 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:42:28,008 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:42:28,008 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:42:28,008 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0006302883671688219, 'batch_size': 128, 'epochs': 24, 'hidden_size': 432, 'dropout': 0.24572406269266053}
2025-09-15 20:42:28,012 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006302883671688219, 'epochs': 24, 'batch_size': 128, 'hidden_size': 432, 'dropout': 0.24572406269266053}
2025-09-15 20:42:36,773 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.436491723060608, 1.1800552082061768, 1.00728374004364, 0.8630254387855529, 0.7619209785461426, 0.6835789341926575, 0.5944492750167847, 0.5884365656375885, 0.5447904443740845, 0.49671568608283995, 0.4534485101699829, 0.4040144743919373, 0.35857633090019225, 0.3412571225166321, 0.34630345678329466, 0.31143988823890684, 0.2986564974784851, 0.2790489871501923, 0.2863132531642914, 0.25561638367176054, 0.23092354857921601, 0.21326779133081436, 0.22193541669845582, 0.20782919287681578], 'val_loss': [1.4125574102401734, 1.1262137823104859, 0.9483953428268432, 0.8315681209564209, 0.7357888255119324, 0.6734183659553528, 0.6267862520217895, 0.5571944642066956, 0.5149272913932801, 0.5485463399887085, 0.49632237005233765, 0.4728080220222473, 0.46154280233383177, 0.43996027898788453, 0.4462187032699585, 0.39298267889022825, 0.4009851279258728, 0.44270935440063475, 0.3192805633544922, 0.45292503929138184, 0.3518012886047363, 0.39175574111938477, 0.4237534537315369, 0.40204681301116946], 'val_acc': [0.355, 0.47, 0.531, 0.633, 0.633, 0.7, 0.749, 0.678, 0.755, 0.842, 0.756, 0.864, 0.882, 0.829, 0.853, 0.753, 0.91, 0.854, 0.85, 0.916, 0.865, 0.857, 0.875, 0.874], 'val_f1': [0.327464759349823, 0.379873126745224, 0.42874079942703247, 0.5155843496322632, 0.5282946825027466, 0.5617293119430542, 0.5945019125938416, 0.5699237585067749, 0.6133040189743042, 0.6631283760070801, 0.6179773807525635, 0.6962250471115112, 0.6962718367576599, 0.6671282052993774, 0.6812023520469666, 0.6333886384963989, 0.7701297998428345, 0.705085039138794, 0.6926736831665039, 0.7714160680770874, 0.7094451189041138, 0.6960015296936035, 0.7110832929611206, 0.7187455892562866], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0006302883671688219, 'epochs': 24, 'batch_size': 128, 'hidden_size': 432, 'dropout': 0.24572406269266053}}
2025-09-15 20:42:36,774 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 8.767s
2025-09-15 20:42:37,166 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:42:37,166 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.392s
2025-09-15 20:42:37,166 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.0006302883671688219, 'batch_size': np.int64(128), 'epochs': np.int64(24), 'hidden_size': np.int64(432), 'dropout': 0.24572406269266053}, value=0.0000
2025-09-15 20:42:37,166 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.0006302883671688219, 'batch_size': np.int64(128), 'epochs': np.int64(24), 'hidden_size': np.int64(432), 'dropout': 0.24572406269266053} -> 0.0000
2025-09-15 20:42:37,167 - INFO - bo.run_bo - BO Trial 7: Using RF surrogate + Expected Improvement
2025-09-15 20:42:37,167 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:42:37,167 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:42:37,167 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:42:37,167 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.04222247265603969, 'batch_size': 16, 'epochs': 18, 'hidden_size': 51, 'dropout': 0.25007875594551915}
2025-09-15 20:42:37,171 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.04222247265603969, 'epochs': 18, 'batch_size': 16, 'hidden_size': 51, 'dropout': 0.25007875594551915}
2025-09-15 20:43:18,245 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.5106576886177063, 1.4996838750839234, 1.4863204762935638, 1.4622907514572143, 1.444349412202835, 1.471786948442459, 1.451854615688324, 1.4651554956436157, 1.43818137717247, 1.441066093683243, 1.4618465359210968, 1.4325996823310851, 1.4472100868225097, 1.4373047716617584, 1.418583196401596, 1.3976945333480835, 1.3563075087070464, 1.3384105422496795], 'val_loss': [1.45133034324646, 1.4187447528839112, 1.4354781742095948, 1.3821777143478393, 1.383244605064392, 1.4243114624023439, 1.4276321983337403, 1.3764426469802857, 1.3701857376098632, 1.4310462265014647, 1.3768369550704955, 1.3772076292037965, 1.4926116399765015, 1.4211496210098267, 1.3470767154693604, 1.9984077196121215, 1.2390103006362916, 1.2100288133621215], 'val_acc': [0.523, 0.752, 0.202, 0.243, 0.245, 0.753, 0.233, 0.406, 0.204, 0.199, 0.716, 0.741, 0.555, 0.735, 0.744, 0.645, 0.431, 0.499], 'val_f1': [0.2889489531517029, 0.3192189633846283, 0.18124422430992126, 0.18549880385398865, 0.19525983929634094, 0.2999996542930603, 0.19527174532413483, 0.2721934914588928, 0.16653697192668915, 0.18024109303951263, 0.2711334526538849, 0.28853073716163635, 0.2031160593032837, 0.2849225103855133, 0.3077562749385834, 0.23755893111228943, 0.2509482800960541, 0.35112014412879944], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.04222247265603969, 'epochs': 18, 'batch_size': 16, 'hidden_size': 51, 'dropout': 0.25007875594551915}}
2025-09-15 20:43:18,246 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 41.079s
2025-09-15 20:43:18,645 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:43:18,645 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.398s
2025-09-15 20:43:18,645 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 0.04222247265603969, 'batch_size': np.int64(16), 'epochs': np.int64(18), 'hidden_size': np.int64(51), 'dropout': 0.25007875594551915}, value=0.0000
2025-09-15 20:43:18,646 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 0.04222247265603969, 'batch_size': np.int64(16), 'epochs': np.int64(18), 'hidden_size': np.int64(51), 'dropout': 0.25007875594551915} -> 0.0000
2025-09-15 20:43:18,646 - INFO - bo.run_bo - BO Trial 8: Using RF surrogate + Expected Improvement
2025-09-15 20:43:18,646 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:43:18,646 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:43:18,646 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:43:18,646 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.015831723490615644, 'batch_size': 32, 'epochs': 12, 'hidden_size': 319, 'dropout': 0.2621266723153076}
2025-09-15 20:43:18,651 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.015831723490615644, 'epochs': 12, 'batch_size': 32, 'hidden_size': 319, 'dropout': 0.2621266723153076}
2025-09-15 20:43:32,908 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.4306427972316742, 1.2700286955833435, 1.0751471943855286, 1.044192343235016, 0.9896791439056396, 0.9115591983795166, 0.8934484157562256, 0.7416109654903412, 0.6681060576438904, 0.6652577517032623, 0.6220426661968231, 0.5637272476553917], 'val_loss': [1.2857151498794557, 1.3347654943466187, 1.0099559173583985, 0.9662139348983765, 0.8140513048171997, 0.7181424541473389, 0.7427938928604126, 0.6740528635978699, 0.5035053055286407, 0.9632565912008285, 0.4820404841899872, 0.47621582126617434], 'val_acc': [0.306, 0.412, 0.684, 0.694, 0.693, 0.776, 0.822, 0.772, 0.88, 0.85, 0.839, 0.769], 'val_f1': [0.3001723885536194, 0.29494133591651917, 0.5663146376609802, 0.5328201055526733, 0.5368105173110962, 0.6456766128540039, 0.6394566297531128, 0.5943516492843628, 0.743401288986206, 0.6661275625228882, 0.7002600431442261, 0.6155637502670288], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.015831723490615644, 'epochs': 12, 'batch_size': 32, 'hidden_size': 319, 'dropout': 0.2621266723153076}}
2025-09-15 20:43:32,909 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 14.263s
2025-09-15 20:43:33,294 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:43:33,294 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.385s
2025-09-15 20:43:33,294 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 0.015831723490615644, 'batch_size': np.int64(32), 'epochs': np.int64(12), 'hidden_size': np.int64(319), 'dropout': 0.2621266723153076}, value=0.0000
2025-09-15 20:43:33,295 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 0.015831723490615644, 'batch_size': np.int64(32), 'epochs': np.int64(12), 'hidden_size': np.int64(319), 'dropout': 0.2621266723153076} -> 0.0000
2025-09-15 20:43:33,295 - INFO - bo.run_bo - BO Trial 9: Using RF surrogate + Expected Improvement
2025-09-15 20:43:33,295 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:43:33,295 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:43:33,295 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:43:33,296 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0004582655140915009, 'batch_size': 8, 'epochs': 22, 'hidden_size': 288, 'dropout': 0.2979985056070939}
2025-09-15 20:43:33,299 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0004582655140915009, 'epochs': 22, 'batch_size': 8, 'hidden_size': 288, 'dropout': 0.2979985056070939}
2025-09-15 20:45:13,347 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.2084343555569648, 0.9086552864015103, 0.7367565907090903, 0.5879030313864351, 0.5198683670684695, 0.44998247526586055, 0.43087275037541983, 0.4139967649858445, 0.3590395325329155, 0.3812187255732715, 0.34542614888958634, 0.33586880086362364, 0.311066162455827, 0.30518346607871355, 0.3126686946162954, 0.2975404397603124, 0.2738699112832546, 0.3028955482589081, 0.2733125790571794, 0.24321564113534988, 0.24337620528228582, 0.2457895805677399], 'val_loss': [0.9774348999261856, 0.7113517075777054, 0.5615591493248939, 0.4817561586201191, 0.428893409460783, 0.4874990597367287, 0.4454831845462322, 0.3594977733194828, 0.3603847044110298, 0.40177457973361014, 0.3059037832580507, 0.29580656233616176, 0.48099341602623463, 0.363716776587069, 0.3107724895179272, 0.2627896177861839, 0.3300322985947132, 0.3007039435878396, 0.24587857642769814, 0.26746365511976183, 0.27677757206186654, 0.29245752535387876], 'val_acc': [0.767, 0.809, 0.841, 0.895, 0.855, 0.856, 0.916, 0.887, 0.906, 0.887, 0.947, 0.929, 0.748, 0.887, 0.927, 0.938, 0.866, 0.918, 0.941, 0.939, 0.916, 0.941], 'val_f1': [0.50174880027771, 0.5838192105293274, 0.6490346193313599, 0.6887121796607971, 0.6837712526321411, 0.7053013443946838, 0.7638804912567139, 0.7046555280685425, 0.734383225440979, 0.7181493043899536, 0.8009743690490723, 0.7752472162246704, 0.6411023139953613, 0.7216849327087402, 0.7715758681297302, 0.7922128438949585, 0.6993522644042969, 0.7614140510559082, 0.8171502947807312, 0.7776066064834595, 0.765792191028595, 0.8214958310127258], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0004582655140915009, 'epochs': 22, 'batch_size': 8, 'hidden_size': 288, 'dropout': 0.2979985056070939}}
2025-09-15 20:45:13,348 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 100.052s
2025-09-15 20:45:13,744 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:45:13,745 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.397s
2025-09-15 20:45:13,745 - INFO - bo.run_bo - Recorded observation #9: hparams={'lr': 0.0004582655140915009, 'batch_size': np.int64(8), 'epochs': np.int64(22), 'hidden_size': np.int64(288), 'dropout': 0.2979985056070939}, value=0.0000
2025-09-15 20:45:13,745 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'lr': 0.0004582655140915009, 'batch_size': np.int64(8), 'epochs': np.int64(22), 'hidden_size': np.int64(288), 'dropout': 0.2979985056070939} -> 0.0000
2025-09-15 20:45:13,746 - INFO - bo.run_bo - BO Trial 10: Using RF surrogate + Expected Improvement
2025-09-15 20:45:13,746 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-15 20:45:13,746 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:45:13,746 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:45:13,746 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.0019299580918507716, 'batch_size': 16, 'epochs': 25, 'hidden_size': 367, 'dropout': 0.5945242340829255}
2025-09-15 20:45:13,751 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0019299580918507716, 'epochs': 25, 'batch_size': 16, 'hidden_size': 367, 'dropout': 0.5945242340829255}
2025-09-15 20:46:11,758 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.3429994490146637, 0.9399727961421013, 0.7817313979268075, 0.6049060733467341, 0.5701851803660393, 0.49251313208788633, 0.513052967146039, 0.45083275423943997, 0.43196901883184907, 0.41281538335233925, 0.43648222902417183, 0.39721613281965257, 0.3479417226985097, 0.3216607955954969, 0.3399749949276447, 0.35230314227566123, 0.2792602551151067, 0.3247394604831934, 0.31146182157844304, 0.29945506785437465, 0.30483405166864397, 0.2918620869666338, 0.24050030967593192, 0.26306592094525694, 0.25993025429360567], 'val_loss': [0.9962689080238343, 0.7980257799625396, 0.5256644462347031, 0.568209028840065, 0.46038057875633237, 0.39435115647315977, 0.3472679795026779, 0.33392738914489745, 0.4492356190085411, 0.3876844374984503, 0.3190125554651022, 0.327367755651474, 0.4374567865729332, 0.3769695507586002, 0.36165882223844525, 0.3414168400019407, 0.3455346262231469, 0.4045639215707779, 0.3285375357940793, 0.306763846822083, 0.27231504023820163, 0.329879775300622, 0.3557069476097822, 0.4206993222385645, 0.2605126172825694], 'val_acc': [0.59, 0.79, 0.876, 0.905, 0.894, 0.908, 0.871, 0.912, 0.92, 0.917, 0.904, 0.838, 0.898, 0.943, 0.921, 0.904, 0.902, 0.725, 0.947, 0.916, 0.927, 0.922, 0.941, 0.925, 0.931], 'val_f1': [0.4352182447910309, 0.593601405620575, 0.6811436414718628, 0.7017116546630859, 0.7369959950447083, 0.7563445568084717, 0.7044509649276733, 0.7454698085784912, 0.7521703839302063, 0.7522376775741577, 0.7483558654785156, 0.6747645139694214, 0.7312935590744019, 0.8055146336555481, 0.7865971326828003, 0.7640579342842102, 0.7508736848831177, 0.6210976243019104, 0.8163759112358093, 0.7576137781143188, 0.7806462049484253, 0.7632139921188354, 0.803429901599884, 0.7785617709159851, 0.7805665135383606], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0019299580918507716, 'epochs': 25, 'batch_size': 16, 'hidden_size': 367, 'dropout': 0.5945242340829255}}
2025-09-15 20:46:11,759 - INFO - models.training_function_executor - [PROFILE] objective(train+eval) took 58.013s
2025-09-15 20:46:12,153 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0000
2025-09-15 20:46:12,153 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.394s
2025-09-15 20:46:12,154 - INFO - bo.run_bo - Recorded observation #10: hparams={'lr': 0.0019299580918507716, 'batch_size': np.int64(16), 'epochs': np.int64(25), 'hidden_size': np.int64(367), 'dropout': 0.5945242340829255}, value=0.0000
2025-09-15 20:46:12,154 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'lr': 0.0019299580918507716, 'batch_size': np.int64(16), 'epochs': np.int64(25), 'hidden_size': np.int64(367), 'dropout': 0.5945242340829255} -> 0.0000
2025-09-15 20:46:12,154 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.0000
2025-09-15 20:46:12,154 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}
2025-09-15 20:46:12,155 - INFO - visualization - Generating BO visualization charts with 10 trials...
2025-09-15 20:46:21,303 - INFO - visualization - BO summary saved to: charts/BO_TinyECG1D-CNN_20250915_204612/bo_summary.txt
2025-09-15 20:46:21,303 - INFO - visualization - BO charts saved to: charts/BO_TinyECG1D-CNN_20250915_204612
2025-09-15 20:46:21,303 - INFO - evaluation.code_generation_pipeline_orchestrator - 📊 BO charts saved to: charts/BO_TinyECG1D-CNN_20250915_204612
2025-09-15 20:46:21,303 - INFO - evaluation.code_generation_pipeline_orchestrator - 🚀 STEP 4: Final Training Execution
2025-09-15 20:46:21,303 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (39904, 1000, 2), Val: (9977, 1000, 2), Test: (12471, 1000, 2)
2025-09-15 20:46:21,603 - INFO - models.training_function_executor - Loaded training function: TinyECG1D-CNN
2025-09-15 20:46:21,603 - INFO - models.training_function_executor - Reasoning: A compact 1D CNN with depthwise-separable convolutions is effective and parameter-efficient for ECG waveform classification. MIT-BIH Arrhythmia is class-imbalanced; using macro-F1 for validation and optional inverse-frequency class weights can improve robustness. Global average pooling with a small MLP head keeps parameters well under 256K while preserving temporal receptive fields across the 1000-sample sequences.
2025-09-15 20:46:21,603 - INFO - evaluation.code_generation_pipeline_orchestrator - Executing final training with optimized params: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}
2025-09-15 20:46:21,603 - INFO - models.training_function_executor - Using device: cuda
2025-09-15 20:46:21,692 - INFO - models.training_function_executor - Executing training function: TinyECG1D-CNN
2025-09-15 20:46:21,692 - INFO - models.training_function_executor - Hyperparameters: {'lr': 0.01535224694197351, 'batch_size': 16, 'epochs': np.int64(10), 'hidden_size': np.int64(204), 'dropout': 0.41779511056254093}
2025-09-15 20:46:21,697 - INFO - models.training_function_executor - Starting training with hyperparameters: {'lr': 0.01535224694197351, 'epochs': 10, 'batch_size': 16, 'hidden_size': 204, 'dropout': 0.41779511056254093}
2025-09-15 20:50:10,902 - INFO - models.training_function_executor - Training completed successfully: {'train_loss': [1.2465418070172345, 1.0116612115858457, 0.7624240634065202, 0.6404214550867234, 0.5925659113104285, 0.5798982084014042, 0.5312774753221927, 0.48736411350635095, 0.4699436101066165, 0.44004443916772235], 'val_loss': [0.9865022598890595, 0.6261135192681879, 0.46677938871958624, 0.4688653981618727, 0.3874781069993507, 0.3711852811211943, 0.3545620784819144, 0.3318799040928577, 0.4432742632996454, 0.3075860871157594], 'val_acc': [0.6727473188333166, 0.865991781096522, 0.8942567906184223, 0.9264307908188835, 0.9273328655908589, 0.9143028966623233, 0.8968627844041295, 0.9010724666733487, 0.8690989275333266, 0.9470782800441014], 'val_f1': [0.4865579605102539, 0.6875609159469604, 0.7204753756523132, 0.7640195488929749, 0.7755471467971802, 0.7467832565307617, 0.7399401068687439, 0.7771424651145935, 0.7098706960678101, 0.8120538592338562], 'model_name': 'TinyECG1D-CNN', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.01535224694197351, 'epochs': 10, 'batch_size': 16, 'hidden_size': 204, 'dropout': 0.41779511056254093}}
2025-09-15 20:50:10,913 - ERROR - evaluation.code_generation_pipeline_orchestrator - Pipeline attempt 1 failed: Given groups=1, weight of size [32, 2, 7], expected input[64, 1000, 2] to have 2 channels, but got 1000 channels instead
2025-09-15 20:50:10,972 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-15 20:50:10,972 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE ATTEMPT 2/4
2025-09-15 20:50:10,972 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-15 20:50:10,972 - INFO - evaluation.code_generation_pipeline_orchestrator - 🤖 STEP 1: AI Training Code Generation
2025-09-15 20:50:10,972 - INFO - models.ai_code_generator - Making API call to gpt-5
2025-09-15 20:50:10,973 - INFO - models.ai_code_generator - Prompt length: 1606 characters
2025-09-15 20:50:10,973 - INFO - models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-15 20:50:10,973 - INFO - models.ai_code_generator - Calling self.client.responses.create...
2025-09-15 20:50:10,973 - INFO - models.ai_code_generator - Model parameter: gpt-5
2025-09-15 20:50:10,973 - INFO - models.ai_code_generator - Input prompt preview: Generate PyTorch training function for 5-class classification.

Data: numpy_array, shape (1000, 2), 62352 samples

Dataset: MIT-BIH Arrhythmia Database
Source: https://physionet.org/content/mitdb/1.0....
