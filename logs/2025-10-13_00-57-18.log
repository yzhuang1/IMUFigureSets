2025-10-13 00:57:18,995 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-13 00:57:19,133 - INFO - __main__ - Logging system initialized successfully
2025-10-13 00:57:19,133 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-10-13 00:57:19,133 - INFO - __main__ - Starting real data processing from data/dataset3/ directory
2025-10-13 00:57:19,133 - INFO - __main__ - Found 4 data files: ['sleep_sample.csv', 'X.npy', 'y.npy', 'sleep_metadata.json']
2025-10-13 00:57:19,133 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-10-13 00:57:19,133 - INFO - __main__ - Attempting to load: X.npy
2025-10-13 00:57:28,882 - INFO - __main__ - Successfully loaded NPY data: X(89283, 6, 6000), y(89283,)
2025-10-13 00:57:48,324 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (89283, 6, 6000), device: cuda
2025-10-13 00:57:48,333 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-10-13 00:57:48,340 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-10-13 00:57:48,340 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-10-13 00:57:48,388 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-13 00:57:48,388 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (89283, 6, 6000), 'dtype': 'float32', 'feature_count': 6000, 'sample_count': 89283, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-10-13 00:57:48,403 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-10-13 00:57:48,403 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-10-13 00:57:48,403 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-10-13 00:57:48,403 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-10-13 00:57:48,404 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-10-13 00:57:48,405 - INFO - data_splitting - Input data shape: X=(89283, 6, 6000), y=(89283,)
2025-10-13 00:57:48,410 - INFO - data_splitting - Class distribution: [20758 11387 28006 17266 11866]
2025-10-13 00:58:01,156 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.8602182913059842), np.int64(1): np.float64(1.5682722656786057), np.int64(2): np.float64(0.6375808971211783), np.int64(3): np.float64(1.03420814479638), np.int64(4): np.float64(1.5048722675796682)}
2025-10-13 00:58:01,158 - INFO - class_balancing - Class imbalance analysis:
2025-10-13 00:58:01,158 - INFO - class_balancing -   Strategy: mild_imbalance
2025-10-13 00:58:01,158 - INFO - class_balancing -   Imbalance ratio: 2.46
2025-10-13 00:58:01,158 - INFO - class_balancing -   Recommendations: Standard training should work, Consider class_weight='balanced'
2025-10-13 00:58:01,158 - INFO - data_splitting - Final splits - Train: 57140, Val: 14286, Test: 17857
2025-10-13 00:58:01,158 - INFO - data_splitting - Train class distribution: [13285  7287 17924 11050  7594]
2025-10-13 00:58:01,158 - INFO - data_splitting - Val class distribution: [3321 1822 4481 2763 1899]
2025-10-13 00:58:01,159 - INFO - data_splitting - Test class distribution: [4152 2278 5601 3453 2373]
2025-10-13 00:58:01,159 - INFO - data_splitting - Recommended balancing strategy: mild_imbalance
2025-10-13 00:58:04,986 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 6000]), std shape: torch.Size([1, 6000])
2025-10-13 00:58:05,005 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-10-13 00:58:05,005 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-10-13 00:58:05,017 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-10-13 00:58:05,017 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-10-13 00:58:05,017 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-10-13 00:58:05,019 - INFO - _models.ai_code_generator - Conducting literature review before code generation...
2025-10-13 01:00:19,959 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-13 01:00:20,014 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-10-13 01:00:20,014 - INFO - _models.ai_code_generator - Prompt length: 4900 characters
2025-10-13 01:00:20,014 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-10-13 01:00:20,014 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-10-13 01:00:20,014 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-10-13 01:04:14,422 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-13 01:04:14,423 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-10-13 01:04:14,423 - INFO - _models.ai_code_generator - AI generated training function: ST-USleepNet-Tiny
2025-10-13 01:04:14,423 - INFO - _models.ai_code_generator - Confidence: 0.86
2025-10-13 01:04:14,423 - INFO - _models.ai_code_generator - Literature review informed code generation (confidence: 0.72)
2025-10-13 01:04:14,423 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: ST-USleepNet-Tiny
2025-10-13 01:04:14,423 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'grad_clip', 'use_amp', 'num_workers', 'base_channels', 'kernel_size_enc', 'kernel_size_dec', 'partitions', 'gcn_hidden_dim', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calib_batches']
2025-10-13 01:04:14,423 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.86
2025-10-13 01:04:14,426 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-10-13 01:04:14,427 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions/training_function_torch_tensor_ST-USleepNet-Tiny_1760335454.json
2025-10-13 01:04:14,427 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_torch_tensor_ST-USleepNet-Tiny_1760335454.json
2025-10-13 01:04:14,427 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-10-13 01:04:14,427 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: ST-USleepNet-Tiny
2025-10-13 01:04:14,427 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-10-13 01:04:14,438 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-10-13 01:04:14,441 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-10-13 01:04:14,441 - INFO - package_installer - Available packages: {'torch'}
2025-10-13 01:04:14,441 - INFO - package_installer - Missing packages: set()
2025-10-13 01:04:14,441 - INFO - package_installer - ‚úÖ All required packages are already available
2025-10-13 01:04:14,441 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-10-13 01:04:14,441 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-13 01:04:14,441 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 57140 samples (using bo_sample_num=100000000000000)
2025-10-13 01:04:14,441 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'grad_clip', 'use_amp', 'num_workers', 'base_channels', 'kernel_size_enc', 'kernel_size_dec', 'partitions', 'gcn_hidden_dim', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calib_batches']
2025-10-13 01:04:14,443 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-13 01:04:14,443 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-13 01:04:14,443 - INFO - _models.training_function_executor - Using BO subset for optimization: 57140 samples (bo_sample_num=100000000000000)
2025-10-13 01:04:16,472 - INFO - _models.training_function_executor - BO splits - Train: 45712, Val: 11428
2025-10-13 01:04:17,687 - INFO - bo.run_bo - Converted GPT search space: 17 parameters
2025-10-13 01:04:17,687 - INFO - bo.run_bo - Using GPT-generated search space
2025-10-13 01:04:17,688 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-10-13 01:04:17,690 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-10-13 01:04:17,690 - INFO - bo.run_bo - [PROFILE] suggest() took 0.002s
2025-10-13 01:04:17,690 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 1 (NaN monitoring active)
2025-10-13 01:04:17,690 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:04:17,690 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:04:17,690 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001412035543062636, 'batch_size': 32, 'epochs': 12, 'weight_decay': 2.4810409748678097e-05, 'dropout': 0.07800932022121827, 'grad_clip': 0.7799726016810133, 'use_amp': True, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 5, 'kernel_size_dec': 5, 'partitions': 3, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 22}
2025-10-13 01:04:17,692 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001412035543062636, 'batch_size': 32, 'epochs': 12, 'weight_decay': 2.4810409748678097e-05, 'dropout': 0.07800932022121827, 'grad_clip': 0.7799726016810133, 'use_amp': True, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 5, 'kernel_size_dec': 5, 'partitions': 3, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 22}
2025-10-13 01:04:38,342 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.18284 val_loss=0.94849 val_acc=0.6233 time=19.8s
2025-10-13 01:04:45,006 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.94926 val_loss=0.89826 val_acc=0.6581 time=6.7s
2025-10-13 01:04:51,667 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.89589 val_loss=0.82079 val_acc=0.6782 time=6.7s
2025-10-13 01:04:58,357 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.84076 val_loss=0.77653 val_acc=0.6848 time=6.7s
2025-10-13 01:05:05,029 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.79464 val_loss=0.73507 val_acc=0.7063 time=6.7s
2025-10-13 01:05:11,698 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.76140 val_loss=0.70793 val_acc=0.7213 time=6.7s
2025-10-13 01:05:18,370 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.74671 val_loss=0.72208 val_acc=0.7195 time=6.7s
2025-10-13 01:05:25,047 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.73623 val_loss=0.69167 val_acc=0.7279 time=6.7s
2025-10-13 01:05:31,724 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.72541 val_loss=0.69444 val_acc=0.7269 time=6.7s
2025-10-13 01:05:38,406 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.71271 val_loss=0.72472 val_acc=0.7069 time=6.7s
2025-10-13 01:05:45,086 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.71326 val_loss=0.67795 val_acc=0.7321 time=6.7s
2025-10-13 01:05:51,778 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.70743 val_loss=0.67541 val_acc=0.7361 time=6.7s
2025-10-13 01:05:53,229 - INFO - _models.training_function_executor - Model: 4,856 parameters, 20.9KB storage
2025-10-13 01:05:53,229 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1828400607621457, 0.9492577391568706, 0.8958922425975405, 0.8407591798733614, 0.7946433782535789, 0.7613993391191204, 0.7467147891947887, 0.7362250972344903, 0.7254125692020733, 0.7127091804813329, 0.7132604437292478, 0.7074264680584035], 'val_losses': [0.9484857683378707, 0.8982648900392216, 0.8207857840788043, 0.7765287029647227, 0.7350669115374961, 0.7079325124313667, 0.7220804938120069, 0.6916696001254974, 0.6944418312954994, 0.7247209263966139, 0.6779496837922397, 0.6754089444927874], 'val_acc': [0.6232936646832342, 0.658120406020301, 0.678246412320616, 0.6848092404620231, 0.7063353167658383, 0.7212985649282464, 0.7195484774238712, 0.7279488974448722, 0.7268988449422471, 0.7069478473923696, 0.732061603080154, 0.736086804340217], 'quantization': {'bits': 32, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 20720}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001412035543062636, 'batch_size': 32, 'epochs': 12, 'weight_decay': 2.4810409748678097e-05, 'dropout': 0.07800932022121827, 'grad_clip': 0.7799726016810133, 'use_amp': True, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 5, 'kernel_size_dec': 5, 'partitions': 3, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 22}, 'model_parameter_count': 4856, 'model_storage_size_kb': 20.865625, 'model_size_validation': 'PASS'}
2025-10-13 01:05:53,229 - INFO - _models.training_function_executor - BO Objective: base=0.7361, size_penalty=0.0000, final=0.7361
2025-10-13 01:05:53,229 - INFO - _models.training_function_executor - Model: 4,856 parameters, 20.9KB (PASS 256KB limit)
2025-10-13 01:05:53,229 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 95.539s
2025-10-13 01:05:53,233 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7361
2025-10-13 01:05:53,233 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-13 01:05:53,233 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.001412035543062636, 'batch_size': 32, 'epochs': np.int64(12), 'weight_decay': 2.4810409748678097e-05, 'dropout': 0.07800932022121827, 'grad_clip': 0.7799726016810133, 'use_amp': True, 'num_workers': 4, 'base_channels': np.int64(9), 'kernel_size_enc': 5, 'kernel_size_dec': 5, 'partitions': 3, 'gcn_hidden_dim': np.int64(11), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': np.int64(22)}, value=0.7361
2025-10-13 01:05:53,233 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.001412035543062636, 'batch_size': 32, 'epochs': np.int64(12), 'weight_decay': 2.4810409748678097e-05, 'dropout': 0.07800932022121827, 'grad_clip': 0.7799726016810133, 'use_amp': True, 'num_workers': 4, 'base_channels': np.int64(9), 'kernel_size_enc': 5, 'kernel_size_dec': 5, 'partitions': 3, 'gcn_hidden_dim': np.int64(11), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': np.int64(22)} -> 0.7361
2025-10-13 01:05:53,233 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-10-13 01:05:53,233 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 01:05:53,233 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 2 (NaN monitoring active)
2025-10-13 01:05:53,233 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:05:53,234 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:05:53,234 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00046404924745583524, 'batch_size': 128, 'epochs': 48, 'weight_decay': 1.2366582530130827e-07, 'dropout': 0.26238733012919463, 'grad_clip': 1.9993048585762778, 'use_amp': True, 'num_workers': 4, 'base_channels': 8, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 8, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 5}
2025-10-13 01:05:53,235 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00046404924745583524, 'batch_size': 128, 'epochs': 48, 'weight_decay': 1.2366582530130827e-07, 'dropout': 0.26238733012919463, 'grad_clip': 1.9993048585762778, 'use_amp': True, 'num_workers': 4, 'base_channels': 8, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 8, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 5}
2025-10-13 01:06:11,041 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.53461 val_loss=1.42256 val_acc=0.4297 time=17.8s
2025-10-13 01:06:16,390 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.36628 val_loss=1.25203 val_acc=0.5090 time=5.3s
2025-10-13 01:06:21,753 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.23656 val_loss=1.13983 val_acc=0.5655 time=5.4s
2025-10-13 01:06:27,113 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.15312 val_loss=1.05641 val_acc=0.5896 time=5.4s
2025-10-13 01:06:32,474 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.10161 val_loss=1.03852 val_acc=0.5900 time=5.4s
2025-10-13 01:06:37,845 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.06946 val_loss=0.98594 val_acc=0.6027 time=5.4s
2025-10-13 01:06:43,216 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.04344 val_loss=0.97044 val_acc=0.6038 time=5.4s
2025-10-13 01:06:48,590 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.02201 val_loss=0.95375 val_acc=0.6067 time=5.4s
2025-10-13 01:06:53,966 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.99865 val_loss=0.90412 val_acc=0.6304 time=5.4s
2025-10-13 01:06:59,332 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.96934 val_loss=0.89763 val_acc=0.6312 time=5.4s
2025-10-13 01:07:04,701 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.94864 val_loss=0.88495 val_acc=0.6372 time=5.4s
2025-10-13 01:07:10,081 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.93979 val_loss=0.86801 val_acc=0.6478 time=5.4s
2025-10-13 01:07:15,453 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.92652 val_loss=0.85534 val_acc=0.6460 time=5.4s
2025-10-13 01:07:20,832 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.92173 val_loss=0.84736 val_acc=0.6499 time=5.4s
2025-10-13 01:07:26,207 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.91120 val_loss=0.83963 val_acc=0.6577 time=5.4s
2025-10-13 01:07:31,572 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.90640 val_loss=0.82562 val_acc=0.6603 time=5.4s
2025-10-13 01:07:36,953 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.89852 val_loss=0.84016 val_acc=0.6582 time=5.4s
2025-10-13 01:07:42,333 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.88806 val_loss=0.81149 val_acc=0.6706 time=5.4s
2025-10-13 01:07:47,711 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.87948 val_loss=0.82190 val_acc=0.6761 time=5.4s
2025-10-13 01:07:53,092 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.87847 val_loss=0.79608 val_acc=0.6773 time=5.4s
2025-10-13 01:07:58,473 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.87187 val_loss=0.81207 val_acc=0.6770 time=5.4s
2025-10-13 01:08:03,841 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.86584 val_loss=0.80603 val_acc=0.6817 time=5.4s
2025-10-13 01:08:09,216 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.85827 val_loss=0.77030 val_acc=0.6887 time=5.4s
2025-10-13 01:08:14,582 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.85400 val_loss=0.78718 val_acc=0.6887 time=5.4s
2025-10-13 01:08:19,955 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.85007 val_loss=0.77453 val_acc=0.6827 time=5.4s
2025-10-13 01:08:25,332 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.84925 val_loss=0.75913 val_acc=0.6922 time=5.4s
2025-10-13 01:08:30,704 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.83923 val_loss=0.77168 val_acc=0.6800 time=5.4s
2025-10-13 01:08:36,084 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.84080 val_loss=0.75452 val_acc=0.6946 time=5.4s
2025-10-13 01:08:41,465 - INFO - _models.training_function_executor - Epoch 029: train_loss=0.83657 val_loss=0.75392 val_acc=0.6939 time=5.4s
2025-10-13 01:08:46,846 - INFO - _models.training_function_executor - Epoch 030: train_loss=0.83449 val_loss=0.75057 val_acc=0.6974 time=5.4s
2025-10-13 01:08:52,223 - INFO - _models.training_function_executor - Epoch 031: train_loss=0.83197 val_loss=0.74724 val_acc=0.7007 time=5.4s
2025-10-13 01:08:57,585 - INFO - _models.training_function_executor - Epoch 032: train_loss=0.82995 val_loss=0.75049 val_acc=0.6931 time=5.4s
2025-10-13 01:09:02,961 - INFO - _models.training_function_executor - Epoch 033: train_loss=0.83200 val_loss=0.74382 val_acc=0.7055 time=5.4s
2025-10-13 01:09:08,330 - INFO - _models.training_function_executor - Epoch 034: train_loss=0.82733 val_loss=0.74214 val_acc=0.6990 time=5.4s
2025-10-13 01:09:13,715 - INFO - _models.training_function_executor - Epoch 035: train_loss=0.82523 val_loss=0.74089 val_acc=0.7017 time=5.4s
2025-10-13 01:09:19,092 - INFO - _models.training_function_executor - Epoch 036: train_loss=0.82161 val_loss=0.73905 val_acc=0.7027 time=5.4s
2025-10-13 01:09:24,467 - INFO - _models.training_function_executor - Epoch 037: train_loss=0.82089 val_loss=0.74043 val_acc=0.7001 time=5.4s
2025-10-13 01:09:29,832 - INFO - _models.training_function_executor - Epoch 038: train_loss=0.82442 val_loss=0.73661 val_acc=0.7078 time=5.4s
2025-10-13 01:09:35,200 - INFO - _models.training_function_executor - Epoch 039: train_loss=0.82152 val_loss=0.73597 val_acc=0.7062 time=5.4s
2025-10-13 01:09:40,567 - INFO - _models.training_function_executor - Epoch 040: train_loss=0.81847 val_loss=0.73528 val_acc=0.7055 time=5.4s
2025-10-13 01:09:45,938 - INFO - _models.training_function_executor - Epoch 041: train_loss=0.82415 val_loss=0.73461 val_acc=0.7076 time=5.4s
2025-10-13 01:09:51,319 - INFO - _models.training_function_executor - Epoch 042: train_loss=0.81945 val_loss=0.73487 val_acc=0.7059 time=5.4s
2025-10-13 01:09:56,699 - INFO - _models.training_function_executor - Epoch 043: train_loss=0.81975 val_loss=0.73442 val_acc=0.7093 time=5.4s
2025-10-13 01:10:02,073 - INFO - _models.training_function_executor - Epoch 044: train_loss=0.81821 val_loss=0.73372 val_acc=0.7076 time=5.4s
2025-10-13 01:10:07,447 - INFO - _models.training_function_executor - Epoch 045: train_loss=0.82085 val_loss=0.73344 val_acc=0.7088 time=5.4s
2025-10-13 01:10:12,822 - INFO - _models.training_function_executor - Epoch 046: train_loss=0.81921 val_loss=0.73306 val_acc=0.7071 time=5.4s
2025-10-13 01:10:18,199 - INFO - _models.training_function_executor - Epoch 047: train_loss=0.81775 val_loss=0.73308 val_acc=0.7080 time=5.4s
2025-10-13 01:10:23,582 - INFO - _models.training_function_executor - Epoch 048: train_loss=0.81831 val_loss=0.73306 val_acc=0.7081 time=5.4s
2025-10-13 01:10:24,686 - INFO - _models.training_function_executor - Model: 4,167 parameters, 9.0KB storage
2025-10-13 01:10:24,686 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5346054465027177, 1.3662845623589164, 1.2365624862072724, 1.1531211196604332, 1.1016133821298495, 1.0694644572144836, 1.0434357736926, 1.0220094583315744, 0.998651212773041, 0.9693395636655001, 0.9486404031066574, 0.9397906374171934, 0.9265199181580401, 0.9217304791192471, 0.9111984113441884, 0.9063998448669306, 0.8985237020439812, 0.8880596240792693, 0.8794780413421001, 0.8784660844691032, 0.8718739953707013, 0.86584493418778, 0.8582664783242119, 0.8540029225960285, 0.8500700123793269, 0.849246357886742, 0.8392270151284511, 0.8407958899922917, 0.8365665031222143, 0.8344934376378471, 0.8319653899343356, 0.8299508686244258, 0.8319951680143021, 0.8273264627941513, 0.8252284717092491, 0.8216090050451315, 0.8208922750681983, 0.8244177611674468, 0.8215200621471732, 0.8184683355452258, 0.8241515336105112, 0.8194455748302018, 0.8197504910798519, 0.8182060706853282, 0.8208473263648076, 0.8192095138995765, 0.8177525861554518, 0.8183149385168538], 'val_losses': [1.4225559151168465, 1.2520314207601098, 1.1398322139121788, 1.056407944447601, 1.0385214323591927, 0.9859434079573127, 0.970441540555183, 0.9537530469861029, 0.9041166810418577, 0.8976330486760925, 0.884950451472025, 0.868005614452609, 0.8553371877364858, 0.8473563182800434, 0.8396340525146126, 0.8256232224855967, 0.8401624534903684, 0.8114936672226716, 0.8218963346699965, 0.796081318715923, 0.8120653581527467, 0.8060315798786832, 0.7703013595351399, 0.7871841455532363, 0.7745308884382666, 0.7591348646569177, 0.7716819468936513, 0.7545150016044293, 0.7539180686810153, 0.7505674034638717, 0.7472422216628705, 0.7504901678194147, 0.7438248019557254, 0.7421409059830967, 0.740892306799483, 0.7390450301978152, 0.7404332502680222, 0.7366143214272836, 0.735966126089293, 0.7352841618096949, 0.7346090101302818, 0.7348678550146074, 0.7344212375156187, 0.7337237188646666, 0.7334386330406942, 0.733062266844488, 0.7330824019903064, 0.7330625136915854], 'val_acc': [0.429733986699335, 0.5090129506475324, 0.565540777038852, 0.5896044802240112, 0.5899544977248863, 0.6027301365068254, 0.6037801890094505, 0.6066678333916696, 0.6303815190759537, 0.6311690584529226, 0.6372068603430171, 0.6477948897444872, 0.646044802240112, 0.6498949947497374, 0.6576828841442072, 0.66030801540077, 0.6582079103955197, 0.6706335316765838, 0.676058802940147, 0.6772838641932096, 0.6770213510675533, 0.6817465873293664, 0.6887469373468673, 0.6887469373468673, 0.6827091354567728, 0.692159607980399, 0.6799964998249912, 0.6946097304865243, 0.6939096954847742, 0.6974098704935247, 0.7007350367518376, 0.6931221561078054, 0.7055477773888694, 0.6989849492474624, 0.7016975848792439, 0.7027476373818691, 0.7001225061253062, 0.7078228911445572, 0.7061603080154008, 0.7055477773888694, 0.7076478823941197, 0.7058977948897445, 0.7093104655232761, 0.7076478823941197, 0.7087854392719636, 0.7071228561428071, 0.7079978998949947, 0.7080854042702135], 'quantization': {'bits': 16, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 10926}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00046404924745583524, 'batch_size': 128, 'epochs': 48, 'weight_decay': 1.2366582530130827e-07, 'dropout': 0.26238733012919463, 'grad_clip': 1.9993048585762778, 'use_amp': True, 'num_workers': 4, 'base_channels': 8, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 8, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 5}, 'model_parameter_count': 4167, 'model_storage_size_kb': 8.952539062500001, 'model_size_validation': 'PASS'}
2025-10-13 01:10:24,686 - INFO - _models.training_function_executor - BO Objective: base=0.7081, size_penalty=0.0000, final=0.7081
2025-10-13 01:10:24,686 - INFO - _models.training_function_executor - Model: 4,167 parameters, 9.0KB (PASS 256KB limit)
2025-10-13 01:10:24,686 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 271.453s
2025-10-13 01:10:24,696 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7081
2025-10-13 01:10:24,696 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-13 01:10:24,696 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 0.00046404924745583524, 'batch_size': 128, 'epochs': np.int64(48), 'weight_decay': 1.2366582530130827e-07, 'dropout': 0.26238733012919463, 'grad_clip': 1.9993048585762778, 'use_amp': True, 'num_workers': 4, 'base_channels': np.int64(8), 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': np.int64(8), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': np.int64(5)}, value=0.7081
2025-10-13 01:10:24,696 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 0.00046404924745583524, 'batch_size': 128, 'epochs': np.int64(48), 'weight_decay': 1.2366582530130827e-07, 'dropout': 0.26238733012919463, 'grad_clip': 1.9993048585762778, 'use_amp': True, 'num_workers': 4, 'base_channels': np.int64(8), 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': np.int64(8), 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': np.int64(5)} -> 0.7081
2025-10-13 01:10:24,697 - INFO - bo.run_bo - üîçBO Trial 3: Initial random exploration
2025-10-13 01:10:24,697 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 01:10:24,697 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 3 (NaN monitoring active)
2025-10-13 01:10:24,697 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:10:24,697 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:10:24,697 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003491196364203329, 'batch_size': 128, 'epochs': 13, 'weight_decay': 1.1584172310543985e-07, 'dropout': 0.11544691281107453, 'grad_clip': 1.2051273301300587, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 5}
2025-10-13 01:10:24,698 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003491196364203329, 'batch_size': 128, 'epochs': 13, 'weight_decay': 1.1584172310543985e-07, 'dropout': 0.11544691281107453, 'grad_clip': 1.2051273301300587, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 5}
2025-10-13 01:10:36,271 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.20633 val_loss=0.94916 val_acc=0.6205 time=11.6s
2025-10-13 01:10:44,652 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.90012 val_loss=0.79010 val_acc=0.6880 time=8.4s
2025-10-13 01:10:53,026 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.80791 val_loss=0.75163 val_acc=0.7004 time=8.4s
2025-10-13 01:11:01,427 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.76087 val_loss=0.67744 val_acc=0.7316 time=8.4s
2025-10-13 01:11:09,839 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.73492 val_loss=0.65296 val_acc=0.7342 time=8.4s
2025-10-13 01:11:18,255 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.70269 val_loss=0.65782 val_acc=0.7372 time=8.4s
2025-10-13 01:11:26,667 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.67645 val_loss=0.61234 val_acc=0.7524 time=8.4s
2025-10-13 01:11:35,085 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.65964 val_loss=0.60911 val_acc=0.7613 time=8.4s
2025-10-13 01:11:43,494 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.64553 val_loss=0.59327 val_acc=0.7630 time=8.4s
2025-10-13 01:11:51,909 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.63486 val_loss=0.58574 val_acc=0.7658 time=8.4s
2025-10-13 01:12:00,320 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.62455 val_loss=0.58161 val_acc=0.7623 time=8.4s
2025-10-13 01:12:08,728 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.61577 val_loss=0.58096 val_acc=0.7665 time=8.4s
2025-10-13 01:12:17,137 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.61258 val_loss=0.57482 val_acc=0.7682 time=8.4s
2025-10-13 01:12:18,229 - INFO - _models.training_function_executor - Model: 9,274 parameters, 39.8KB storage
2025-10-13 01:12:18,229 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2063290522071002, 0.9001176849628271, 0.8079072415599216, 0.7608685815588845, 0.7349154247993934, 0.7026936255596216, 0.6764452316813591, 0.6596393006474646, 0.645530875471033, 0.6348580841964719, 0.6245538247687273, 0.6157710972806979, 0.6125778266922093], 'val_losses': [0.9491609427158675, 0.7901002271299726, 0.7516273682168367, 0.6774399338963568, 0.6529583862331058, 0.6578192765119404, 0.6123380875061724, 0.6091077635869889, 0.5932670409002628, 0.5857365749956304, 0.5816114446396673, 0.580962037764774, 0.574821198387166], 'val_acc': [0.6204935246762339, 0.6879593979698985, 0.7003850192509625, 0.7316240812040602, 0.734249212460623, 0.7372243612180609, 0.7523626181309065, 0.7612880644032202, 0.7630381519075954, 0.7658382919145957, 0.7623381169058453, 0.7664508225411271, 0.7682009100455023], 'quantization': {'bits': 32, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 39400}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003491196364203329, 'batch_size': 128, 'epochs': 13, 'weight_decay': 1.1584172310543985e-07, 'dropout': 0.11544691281107453, 'grad_clip': 1.2051273301300587, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 5}, 'model_parameter_count': 9274, 'model_storage_size_kb': 39.849218750000006, 'model_size_validation': 'PASS'}
2025-10-13 01:12:18,229 - INFO - _models.training_function_executor - BO Objective: base=0.7682, size_penalty=0.0000, final=0.7682
2025-10-13 01:12:18,229 - INFO - _models.training_function_executor - Model: 9,274 parameters, 39.8KB (PASS 256KB limit)
2025-10-13 01:12:18,230 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 113.533s
2025-10-13 01:12:18,336 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7682
2025-10-13 01:12:18,336 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.086s
2025-10-13 01:12:18,336 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 0.003491196364203329, 'batch_size': 128, 'epochs': np.int64(13), 'weight_decay': 1.1584172310543985e-07, 'dropout': 0.11544691281107453, 'grad_clip': 1.2051273301300587, 'use_amp': False, 'num_workers': 4, 'base_channels': np.int64(13), 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': np.int64(11), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': np.int64(5)}, value=0.7682
2025-10-13 01:12:18,336 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 0.003491196364203329, 'batch_size': 128, 'epochs': np.int64(13), 'weight_decay': 1.1584172310543985e-07, 'dropout': 0.11544691281107453, 'grad_clip': 1.2051273301300587, 'use_amp': False, 'num_workers': 4, 'base_channels': np.int64(13), 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': np.int64(11), 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': np.int64(5)} -> 0.7682
2025-10-13 01:12:18,336 - INFO - bo.run_bo - üîçBO Trial 4: Using RF surrogate + Expected Improvement
2025-10-13 01:12:18,336 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:12:18,336 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 4 (NaN monitoring active)
2025-10-13 01:12:18,336 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:12:18,336 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:12:18,336 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 3.1543990308330964e-05, 'batch_size': 256, 'epochs': 8, 'weight_decay': 0.0006007621083872604, 'dropout': 0.2748805239701428, 'grad_clip': 3.8166503358427093, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 8, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 21}
2025-10-13 01:12:18,338 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 3.1543990308330964e-05, 'batch_size': 256, 'epochs': 8, 'weight_decay': 0.0006007621083872604, 'dropout': 0.2748805239701428, 'grad_clip': 3.8166503358427093, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 8, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 21}
2025-10-13 01:12:30,371 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.65825 val_loss=1.65022 val_acc=0.1936 time=12.0s
2025-10-13 01:12:38,711 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.64559 val_loss=1.63974 val_acc=0.1934 time=8.3s
2025-10-13 01:12:47,039 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.63635 val_loss=1.63146 val_acc=0.1934 time=8.3s
2025-10-13 01:12:55,365 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.62878 val_loss=1.62485 val_acc=0.1934 time=8.3s
2025-10-13 01:13:03,684 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.62353 val_loss=1.62002 val_acc=0.1934 time=8.3s
2025-10-13 01:13:12,007 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.61964 val_loss=1.61689 val_acc=0.1934 time=8.3s
2025-10-13 01:13:20,326 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.61702 val_loss=1.61537 val_acc=0.1934 time=8.3s
2025-10-13 01:13:28,655 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.61682 val_loss=1.61497 val_acc=0.1933 time=8.3s
2025-10-13 01:13:29,746 - INFO - _models.training_function_executor - Model: 9,226 parameters, 39.6KB storage
2025-10-13 01:13:29,746 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.658254159969761, 1.645591900237674, 1.6363515603947063, 1.628775605464424, 1.6235282301777596, 1.6196388328747187, 1.6170217354563845, 1.616820323079209], 'val_losses': [1.6502231739599638, 1.6397416387190134, 1.6314569892773145, 1.624849759952397, 1.6200240250855507, 1.6168908475786394, 1.615365412296179, 1.61497219571877], 'val_acc': [0.1935596779838992, 0.19338466923346168, 0.19338466923346168, 0.19338466923346168, 0.19338466923346168, 0.19338466923346168, 0.19338466923346168, 0.19329716485824291], 'quantization': {'bits': 8, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 51304}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 3.1543990308330964e-05, 'batch_size': 256, 'epochs': 8, 'weight_decay': 0.0006007621083872604, 'dropout': 0.2748805239701428, 'grad_clip': 3.8166503358427093, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 8, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 21}, 'model_parameter_count': 9226, 'model_storage_size_kb': 39.64296875, 'model_size_validation': 'PASS'}
2025-10-13 01:13:29,746 - INFO - _models.training_function_executor - BO Objective: base=0.1933, size_penalty=0.0000, final=0.1933
2025-10-13 01:13:29,746 - INFO - _models.training_function_executor - Model: 9,226 parameters, 39.6KB (PASS 256KB limit)
2025-10-13 01:13:29,746 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 71.410s
2025-10-13 01:13:29,859 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1933
2025-10-13 01:13:29,859 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.083s
2025-10-13 01:13:29,859 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 3.1543990308330964e-05, 'batch_size': np.int64(256), 'epochs': np.int64(8), 'weight_decay': 0.0006007621083872604, 'dropout': 0.2748805239701428, 'grad_clip': 3.8166503358427093, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(8), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(21)}, value=0.1933
2025-10-13 01:13:29,859 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 3.1543990308330964e-05, 'batch_size': np.int64(256), 'epochs': np.int64(8), 'weight_decay': 0.0006007621083872604, 'dropout': 0.2748805239701428, 'grad_clip': 3.8166503358427093, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(8), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(21)} -> 0.1933
2025-10-13 01:13:29,859 - INFO - bo.run_bo - üîçBO Trial 5: Using RF surrogate + Expected Improvement
2025-10-13 01:13:29,859 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:13:29,859 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 5 (NaN monitoring active)
2025-10-13 01:13:29,859 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:13:29,859 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:13:29,859 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0015181070862954505, 'batch_size': 256, 'epochs': 28, 'weight_decay': 1.0335692126587572e-07, 'dropout': 0.22890465887886513, 'grad_clip': 1.9809557773804907, 'use_amp': True, 'num_workers': 4, 'base_channels': 12, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 7, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 28}
2025-10-13 01:13:29,861 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0015181070862954505, 'batch_size': 256, 'epochs': 28, 'weight_decay': 1.0335692126587572e-07, 'dropout': 0.22890465887886513, 'grad_clip': 1.9809557773804907, 'use_amp': True, 'num_workers': 4, 'base_channels': 12, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 7, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 28}
2025-10-13 01:13:50,519 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.49164 val_loss=1.22971 val_acc=0.5216 time=20.7s
2025-10-13 01:13:56,821 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.17960 val_loss=1.04145 val_acc=0.5801 time=6.3s
2025-10-13 01:14:03,123 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.05463 val_loss=0.94654 val_acc=0.6092 time=6.3s
2025-10-13 01:14:09,432 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.98595 val_loss=0.89698 val_acc=0.6262 time=6.3s
2025-10-13 01:14:15,752 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.95772 val_loss=0.88629 val_acc=0.6308 time=6.3s
2025-10-13 01:14:22,066 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.94436 val_loss=0.86611 val_acc=0.6395 time=6.3s
2025-10-13 01:14:28,373 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.92994 val_loss=0.86158 val_acc=0.6436 time=6.3s
2025-10-13 01:14:34,678 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.91615 val_loss=0.85630 val_acc=0.6481 time=6.3s
2025-10-13 01:14:40,994 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.90059 val_loss=0.88814 val_acc=0.6279 time=6.3s
2025-10-13 01:14:47,307 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.89629 val_loss=0.82255 val_acc=0.6629 time=6.3s
2025-10-13 01:14:53,609 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.87933 val_loss=0.86803 val_acc=0.6481 time=6.3s
2025-10-13 01:14:59,930 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.87057 val_loss=0.81826 val_acc=0.6786 time=6.3s
2025-10-13 01:15:06,249 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.86249 val_loss=0.79464 val_acc=0.6746 time=6.3s
2025-10-13 01:15:12,551 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.85352 val_loss=0.78102 val_acc=0.6915 time=6.3s
2025-10-13 01:15:18,863 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.85206 val_loss=0.77965 val_acc=0.6921 time=6.3s
2025-10-13 01:15:25,176 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.84361 val_loss=0.77051 val_acc=0.6920 time=6.3s
2025-10-13 01:15:31,498 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.83452 val_loss=0.76342 val_acc=0.6929 time=6.3s
2025-10-13 01:15:37,814 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.83163 val_loss=0.77013 val_acc=0.6915 time=6.3s
2025-10-13 01:15:44,152 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.82614 val_loss=0.75099 val_acc=0.7045 time=6.3s
2025-10-13 01:15:50,483 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.82022 val_loss=0.75777 val_acc=0.6967 time=6.3s
2025-10-13 01:15:56,805 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.81766 val_loss=0.74434 val_acc=0.7100 time=6.3s
2025-10-13 01:16:03,131 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.81115 val_loss=0.74354 val_acc=0.7112 time=6.3s
2025-10-13 01:16:09,482 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.80836 val_loss=0.73820 val_acc=0.7113 time=6.4s
2025-10-13 01:16:15,810 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.80887 val_loss=0.73939 val_acc=0.7120 time=6.3s
2025-10-13 01:16:22,136 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.80519 val_loss=0.73624 val_acc=0.7129 time=6.3s
2025-10-13 01:16:28,456 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.80355 val_loss=0.73464 val_acc=0.7132 time=6.3s
2025-10-13 01:16:34,782 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.80528 val_loss=0.73385 val_acc=0.7130 time=6.3s
2025-10-13 01:16:41,103 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.80055 val_loss=0.73371 val_acc=0.7139 time=6.3s
2025-10-13 01:16:42,176 - INFO - _models.training_function_executor - Model: 7,526 parameters, 16.2KB storage
2025-10-13 01:16:42,177 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4916411358282873, 1.1796047945393104, 1.0546339518714294, 0.9859450045773563, 0.95772329704053, 0.944359202859783, 0.9299380716678352, 0.9161494021487478, 0.9005860661475609, 0.8962865474969305, 0.8793266433955157, 0.8705660076378358, 0.862489753976167, 0.8535237989310497, 0.8520583863603848, 0.8436101736578442, 0.8345202389279153, 0.8316341333135592, 0.8261386872923453, 0.8202212861379544, 0.8176564386268992, 0.8111514468313223, 0.8083567672940789, 0.8088715799963887, 0.805193106653309, 0.8035473328684859, 0.8052759543139492, 0.8005540209046852], 'val_losses': [1.2297059367660212, 1.0414472666494405, 0.9465446165278111, 0.8969844778100635, 0.8862864085331971, 0.8661106922720795, 0.8615817572839368, 0.8562972922820832, 0.8881391538871015, 0.8225526587087707, 0.868031629491278, 0.8182569431766247, 0.7946416145235582, 0.7810205871674161, 0.7796490898823296, 0.7705125796824099, 0.763422010159384, 0.770133021664778, 0.7509942431111081, 0.7577734524485195, 0.744338031619589, 0.7435407871585815, 0.7381967085827302, 0.7393930652653123, 0.7362375990218702, 0.7346414730270968, 0.7338487121831048, 0.7337088395049616], 'val_acc': [0.521613580679034, 0.5800665033251663, 0.6092054602730137, 0.6261813090654532, 0.6308190409520475, 0.6394819740987049, 0.6435946797339867, 0.6481449072453622, 0.6279313965698284, 0.6629331466573328, 0.6481449072453622, 0.678596429821491, 0.674571228561428, 0.6914595729786489, 0.6920721036051802, 0.6919845992299615, 0.6928596429821491, 0.6914595729786489, 0.7044977248862443, 0.6967098354917746, 0.7100105005250262, 0.7112355617780889, 0.7113230661533076, 0.7120231011550577, 0.7128981449072453, 0.7131606580329016, 0.7129856492824641, 0.7139481974098705], 'quantization': {'bits': 16, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 16852}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0015181070862954505, 'batch_size': 256, 'epochs': 28, 'weight_decay': 1.0335692126587572e-07, 'dropout': 0.22890465887886513, 'grad_clip': 1.9809557773804907, 'use_amp': True, 'num_workers': 4, 'base_channels': 12, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 7, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 28}, 'model_parameter_count': 7526, 'model_storage_size_kb': 16.169140625, 'model_size_validation': 'PASS'}
2025-10-13 01:16:42,177 - INFO - _models.training_function_executor - BO Objective: base=0.7139, size_penalty=0.0000, final=0.7139
2025-10-13 01:16:42,177 - INFO - _models.training_function_executor - Model: 7,526 parameters, 16.2KB (PASS 256KB limit)
2025-10-13 01:16:42,177 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 192.317s
2025-10-13 01:16:42,282 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7139
2025-10-13 01:16:42,282 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.086s
2025-10-13 01:16:42,282 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 0.0015181070862954505, 'batch_size': np.int64(256), 'epochs': np.int64(28), 'weight_decay': 1.0335692126587572e-07, 'dropout': 0.22890465887886513, 'grad_clip': 1.9809557773804907, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(12), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(7), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(28)}, value=0.7139
2025-10-13 01:16:42,282 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 0.0015181070862954505, 'batch_size': np.int64(256), 'epochs': np.int64(28), 'weight_decay': 1.0335692126587572e-07, 'dropout': 0.22890465887886513, 'grad_clip': 1.9809557773804907, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(12), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(7), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(28)} -> 0.7139
2025-10-13 01:16:42,282 - INFO - bo.run_bo - üîçBO Trial 6: Using RF surrogate + Expected Improvement
2025-10-13 01:16:42,282 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:16:42,282 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 6 (NaN monitoring active)
2025-10-13 01:16:42,282 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:16:42,282 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:16:42,282 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002074563416119347, 'batch_size': 256, 'epochs': 24, 'weight_decay': 5.519131842702146e-07, 'dropout': 0.07325266245563446, 'grad_clip': 4.941906896132577, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 5, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 21}
2025-10-13 01:16:42,284 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002074563416119347, 'batch_size': 256, 'epochs': 24, 'weight_decay': 5.519131842702146e-07, 'dropout': 0.07325266245563446, 'grad_clip': 4.941906896132577, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 5, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 21}
2025-10-13 01:16:55,384 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.35828 val_loss=1.07737 val_acc=0.5621 time=13.1s
2025-10-13 01:17:04,843 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.98857 val_loss=1.01876 val_acc=0.5914 time=9.5s
2025-10-13 01:17:14,294 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.88871 val_loss=0.88995 val_acc=0.6489 time=9.5s
2025-10-13 01:17:23,764 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.84412 val_loss=0.80557 val_acc=0.6791 time=9.5s
2025-10-13 01:17:33,226 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.80607 val_loss=0.77143 val_acc=0.6918 time=9.5s
2025-10-13 01:17:42,682 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.78063 val_loss=0.74666 val_acc=0.7025 time=9.5s
2025-10-13 01:17:52,148 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.74525 val_loss=0.71199 val_acc=0.7200 time=9.5s
2025-10-13 01:18:01,620 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.72919 val_loss=0.70814 val_acc=0.7227 time=9.5s
2025-10-13 01:18:11,093 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.71059 val_loss=0.68563 val_acc=0.7312 time=9.5s
2025-10-13 01:18:20,564 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.69839 val_loss=0.68215 val_acc=0.7286 time=9.5s
2025-10-13 01:18:30,041 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.68270 val_loss=0.65066 val_acc=0.7442 time=9.5s
2025-10-13 01:18:39,497 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.67309 val_loss=0.64178 val_acc=0.7440 time=9.5s
2025-10-13 01:18:48,955 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.66378 val_loss=0.64320 val_acc=0.7475 time=9.5s
2025-10-13 01:18:58,426 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.65585 val_loss=0.63005 val_acc=0.7522 time=9.5s
2025-10-13 01:19:07,890 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.64415 val_loss=0.62548 val_acc=0.7539 time=9.5s
2025-10-13 01:19:17,351 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.63775 val_loss=0.63816 val_acc=0.7440 time=9.5s
2025-10-13 01:19:26,818 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.63369 val_loss=0.61263 val_acc=0.7586 time=9.5s
2025-10-13 01:19:36,288 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.62754 val_loss=0.61164 val_acc=0.7581 time=9.5s
2025-10-13 01:19:45,747 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.62193 val_loss=0.60910 val_acc=0.7611 time=9.5s
2025-10-13 01:19:55,226 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.61805 val_loss=0.60346 val_acc=0.7626 time=9.5s
2025-10-13 01:20:04,694 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.61725 val_loss=0.60066 val_acc=0.7630 time=9.5s
2025-10-13 01:20:14,159 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.61356 val_loss=0.59934 val_acc=0.7627 time=9.5s
2025-10-13 01:20:23,633 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.61267 val_loss=0.59908 val_acc=0.7638 time=9.5s
2025-10-13 01:20:33,108 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.61091 val_loss=0.59852 val_acc=0.7626 time=9.5s
2025-10-13 01:20:40,107 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 01:20:40,108 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.358284012229033, 0.9885678396051398, 0.8887099328056097, 0.8441195038594188, 0.8060667199983353, 0.7806294243111241, 0.7452515678719537, 0.7291910987155689, 0.7105930496397075, 0.6983875396120661, 0.6827033237013985, 0.6730895951197287, 0.6637773055232485, 0.6558472669996663, 0.6441483005677898, 0.6377473278900189, 0.6336901054167021, 0.6275381031552102, 0.6219331879777678, 0.6180522593118363, 0.6172502948806383, 0.6135596229682071, 0.6126666525505955, 0.6109092512204174], 'val_losses': [1.0773696439183589, 1.0187610012482713, 0.8899493835629139, 0.8055723951669852, 0.7714256763792054, 0.7466635410502778, 0.711989638623467, 0.708137697488393, 0.6856287488538484, 0.6821461040572265, 0.6506600890244727, 0.6417759703638506, 0.6432021284462232, 0.6300522007431482, 0.6254793281817211, 0.6381625354936751, 0.6126298978064166, 0.611637249249948, 0.609098991627538, 0.6034560662113706, 0.6006587983679846, 0.5993438159246982, 0.5990801134182934, 0.5985239289171594], 'val_acc': [0.5621281064053203, 0.5914420721036052, 0.6489324466223311, 0.6791214560728036, 0.691809590479524, 0.7024851242562128, 0.719985999299965, 0.7226986349317466, 0.7311865593279664, 0.7285614280714036, 0.7442247112355618, 0.7440497024851243, 0.7475498774938747, 0.752187609380469, 0.7539376968848442, 0.7440497024851243, 0.7585754287714386, 0.758050402520126, 0.7611130556527826, 0.7626006300315016, 0.7629506475323766, 0.7626881344067203, 0.7638256912845642, 0.7626006300315016], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 32931}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002074563416119347, 'batch_size': 256, 'epochs': 24, 'weight_decay': 5.519131842702146e-07, 'dropout': 0.07325266245563446, 'grad_clip': 4.941906896132577, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 5, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 21}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 01:20:40,108 - INFO - _models.training_function_executor - BO Objective: base=0.7626, size_penalty=0.0000, final=0.7626
2025-10-13 01:20:40,108 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 01:20:40,108 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 237.825s
2025-10-13 01:20:40,220 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7626
2025-10-13 01:20:40,221 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.083s
2025-10-13 01:20:40,221 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.002074563416119347, 'batch_size': np.int64(256), 'epochs': np.int64(24), 'weight_decay': 5.519131842702146e-07, 'dropout': 0.07325266245563446, 'grad_clip': 4.941906896132577, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(5), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(21)}, value=0.7626
2025-10-13 01:20:40,221 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.002074563416119347, 'batch_size': np.int64(256), 'epochs': np.int64(24), 'weight_decay': 5.519131842702146e-07, 'dropout': 0.07325266245563446, 'grad_clip': 4.941906896132577, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(5), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(21)} -> 0.7626
2025-10-13 01:20:40,221 - INFO - bo.run_bo - üîçBO Trial 7: Using RF surrogate + Expected Improvement
2025-10-13 01:20:40,221 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:20:40,221 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 7 (NaN monitoring active)
2025-10-13 01:20:40,221 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:20:40,221 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:20:40,221 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 5.058978159060473e-05, 'batch_size': 64, 'epochs': 9, 'weight_decay': 0.0005653663977843696, 'dropout': 0.14529599168399907, 'grad_clip': 0.760492923693682, 'use_amp': False, 'num_workers': 4, 'base_channels': 8, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 6, 'gcn_hidden_dim': 12, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 3}
2025-10-13 01:20:40,222 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 5.058978159060473e-05, 'batch_size': 64, 'epochs': 9, 'weight_decay': 0.0005653663977843696, 'dropout': 0.14529599168399907, 'grad_clip': 0.760492923693682, 'use_amp': False, 'num_workers': 4, 'base_channels': 8, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 6, 'gcn_hidden_dim': 12, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 3}
2025-10-13 01:20:49,086 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.56592 val_loss=1.55176 val_acc=0.3183 time=8.9s
2025-10-13 01:20:54,951 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.54425 val_loss=1.53344 val_acc=0.3204 time=5.9s
2025-10-13 01:21:00,820 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.52909 val_loss=1.51749 val_acc=0.3519 time=5.9s
2025-10-13 01:21:06,689 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.51437 val_loss=1.50227 val_acc=0.3584 time=5.9s
2025-10-13 01:21:12,557 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.50039 val_loss=1.48963 val_acc=0.3710 time=5.9s
2025-10-13 01:21:18,426 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.49067 val_loss=1.48141 val_acc=0.3726 time=5.9s
2025-10-13 01:21:24,292 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.48547 val_loss=1.47677 val_acc=0.3742 time=5.9s
2025-10-13 01:21:30,162 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.48158 val_loss=1.47469 val_acc=0.3743 time=5.9s
2025-10-13 01:21:36,032 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.48093 val_loss=1.47418 val_acc=0.3743 time=5.9s
2025-10-13 01:21:37,479 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 01:21:37,479 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5659204329232632, 1.5442548563816683, 1.5290944972654135, 1.5143705918566097, 1.500391478258119, 1.4906738827100867, 1.485471229850307, 1.4815828049145339, 1.480933410870182], 'val_losses': [1.5517563123489369, 1.533436239996614, 1.5174919437352368, 1.502271182978533, 1.4896258946102652, 1.4814148590119935, 1.476769937599377, 1.4746850383502852, 1.4741761953963406], 'val_acc': [0.3182534126706335, 0.32035351767588377, 0.3519425971298565, 0.3584179208960448, 0.3710185509275464, 0.3725936296814841, 0.37416870843542177, 0.37425621281064053, 0.3743437171858593], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 9158}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 5.058978159060473e-05, 'batch_size': 64, 'epochs': 9, 'weight_decay': 0.0005653663977843696, 'dropout': 0.14529599168399907, 'grad_clip': 0.760492923693682, 'use_amp': False, 'num_workers': 4, 'base_channels': 8, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 6, 'gcn_hidden_dim': 12, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 3}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 01:21:37,479 - INFO - _models.training_function_executor - BO Objective: base=0.3743, size_penalty=0.0000, final=0.3743
2025-10-13 01:21:37,479 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 01:21:37,479 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 57.258s
2025-10-13 01:21:37,571 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.3743
2025-10-13 01:21:37,571 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.085s
2025-10-13 01:21:37,571 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 5.058978159060473e-05, 'batch_size': np.int64(64), 'epochs': np.int64(9), 'weight_decay': 0.0005653663977843696, 'dropout': 0.14529599168399907, 'grad_clip': 0.760492923693682, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(8), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(12), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(3)}, value=0.3743
2025-10-13 01:21:37,571 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 5.058978159060473e-05, 'batch_size': np.int64(64), 'epochs': np.int64(9), 'weight_decay': 0.0005653663977843696, 'dropout': 0.14529599168399907, 'grad_clip': 0.760492923693682, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(8), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(12), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(3)} -> 0.3743
2025-10-13 01:21:37,571 - INFO - bo.run_bo - üîçBO Trial 8: Using RF surrogate + Expected Improvement
2025-10-13 01:21:37,571 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:21:37,571 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 8 (NaN monitoring active)
2025-10-13 01:21:37,571 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:21:37,571 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:21:37,571 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0008700324467850657, 'batch_size': 64, 'epochs': 7, 'weight_decay': 7.557007500618105e-07, 'dropout': 0.00583989701317006, 'grad_clip': 0.23232920947668437, 'use_amp': True, 'num_workers': 4, 'base_channels': 11, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 4, 'gcn_hidden_dim': 14, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 15}
2025-10-13 01:21:37,573 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0008700324467850657, 'batch_size': 64, 'epochs': 7, 'weight_decay': 7.557007500618105e-07, 'dropout': 0.00583989701317006, 'grad_clip': 0.23232920947668437, 'use_amp': True, 'num_workers': 4, 'base_channels': 11, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 4, 'gcn_hidden_dim': 14, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 15}
2025-10-13 01:21:56,691 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.29436 val_loss=1.08635 val_acc=0.5679 time=19.1s
2025-10-13 01:22:03,610 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.03806 val_loss=1.00316 val_acc=0.6171 time=6.9s
2025-10-13 01:22:10,534 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.94993 val_loss=0.92297 val_acc=0.6397 time=6.9s
2025-10-13 01:22:17,456 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.90818 val_loss=0.87482 val_acc=0.6601 time=6.9s
2025-10-13 01:22:24,376 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.87309 val_loss=0.86102 val_acc=0.6585 time=6.9s
2025-10-13 01:22:31,283 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.84944 val_loss=0.83467 val_acc=0.6691 time=6.9s
2025-10-13 01:22:38,206 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.83722 val_loss=0.83278 val_acc=0.6696 time=6.9s
2025-10-13 01:22:39,297 - INFO - _models.training_function_executor - Model: 7,106 parameters, 15.3KB storage
2025-10-13 01:22:39,297 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2943646152577786, 1.0380598211939367, 0.9499273578896154, 0.9081816693306971, 0.8730879297279835, 0.8494419566726285, 0.8372230224355685], 'val_losses': [1.0863481915660533, 1.0031627707019068, 0.9229736196272933, 0.8748188630075024, 0.8610154044432035, 0.834674784884321, 0.8327762067505726], 'val_acc': [0.5679033951697585, 0.6170808540427022, 0.6396569828491424, 0.6601330066503325, 0.658470423521176, 0.6690584529226461, 0.6695834791739587], 'quantization': {'bits': 16, 'weights': True, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 15364}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0008700324467850657, 'batch_size': 64, 'epochs': 7, 'weight_decay': 7.557007500618105e-07, 'dropout': 0.00583989701317006, 'grad_clip': 0.23232920947668437, 'use_amp': True, 'num_workers': 4, 'base_channels': 11, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 4, 'gcn_hidden_dim': 14, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 15}, 'model_parameter_count': 7106, 'model_storage_size_kb': 15.266796875, 'model_size_validation': 'PASS'}
2025-10-13 01:22:39,297 - INFO - _models.training_function_executor - BO Objective: base=0.6696, size_penalty=0.0000, final=0.6696
2025-10-13 01:22:39,297 - INFO - _models.training_function_executor - Model: 7,106 parameters, 15.3KB (PASS 256KB limit)
2025-10-13 01:22:39,297 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 61.726s
2025-10-13 01:22:39,388 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6696
2025-10-13 01:22:39,388 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.086s
2025-10-13 01:22:39,389 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 0.0008700324467850657, 'batch_size': np.int64(64), 'epochs': np.int64(7), 'weight_decay': 7.557007500618105e-07, 'dropout': 0.00583989701317006, 'grad_clip': 0.23232920947668437, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(11), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(15)}, value=0.6696
2025-10-13 01:22:39,389 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 0.0008700324467850657, 'batch_size': np.int64(64), 'epochs': np.int64(7), 'weight_decay': 7.557007500618105e-07, 'dropout': 0.00583989701317006, 'grad_clip': 0.23232920947668437, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(11), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(15)} -> 0.6696
2025-10-13 01:22:39,389 - INFO - bo.run_bo - üîçBO Trial 9: Using RF surrogate + Expected Improvement
2025-10-13 01:22:39,389 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:22:39,389 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 9 (NaN monitoring active)
2025-10-13 01:22:39,389 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:22:39,389 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:22:39,389 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003585358695532363, 'batch_size': 128, 'epochs': 34, 'weight_decay': 0.0002651811362987809, 'dropout': 0.1003300932636815, 'grad_clip': 1.0147241642067442, 'use_amp': True, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 01:22:39,390 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003585358695532363, 'batch_size': 128, 'epochs': 34, 'weight_decay': 0.0002651811362987809, 'dropout': 0.1003300932636815, 'grad_clip': 1.0147241642067442, 'use_amp': True, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 01:22:58,441 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.24151 val_loss=1.05934 val_acc=0.5847 time=19.0s
2025-10-13 01:23:06,258 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.01506 val_loss=0.98759 val_acc=0.6103 time=7.8s
2025-10-13 01:23:14,090 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.92402 val_loss=0.85408 val_acc=0.6660 time=7.8s
2025-10-13 01:23:21,916 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.88622 val_loss=0.85380 val_acc=0.6560 time=7.8s
2025-10-13 01:23:29,740 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.84095 val_loss=0.76753 val_acc=0.6989 time=7.8s
2025-10-13 01:23:37,567 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.81356 val_loss=0.75550 val_acc=0.7062 time=7.8s
2025-10-13 01:23:45,386 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.80374 val_loss=0.73627 val_acc=0.7162 time=7.8s
2025-10-13 01:23:53,207 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.77887 val_loss=0.73559 val_acc=0.7132 time=7.8s
2025-10-13 01:24:01,030 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.76982 val_loss=0.78601 val_acc=0.6852 time=7.8s
2025-10-13 01:24:08,843 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.76211 val_loss=0.68709 val_acc=0.7364 time=7.8s
2025-10-13 01:24:16,671 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.74501 val_loss=0.68179 val_acc=0.7414 time=7.8s
2025-10-13 01:24:24,501 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.74253 val_loss=0.67342 val_acc=0.7405 time=7.8s
2025-10-13 01:24:32,335 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.73157 val_loss=0.69595 val_acc=0.7324 time=7.8s
2025-10-13 01:24:40,161 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.71526 val_loss=0.67095 val_acc=0.7431 time=7.8s
2025-10-13 01:24:47,981 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.71512 val_loss=0.74745 val_acc=0.7141 time=7.8s
2025-10-13 01:24:55,810 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.70349 val_loss=0.68148 val_acc=0.7391 time=7.8s
2025-10-13 01:25:03,641 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.71021 val_loss=0.64535 val_acc=0.7513 time=7.8s
2025-10-13 01:25:11,471 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.68860 val_loss=0.67932 val_acc=0.7260 time=7.8s
2025-10-13 01:25:19,301 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.68431 val_loss=0.64294 val_acc=0.7521 time=7.8s
2025-10-13 01:25:27,128 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.67773 val_loss=0.62760 val_acc=0.7580 time=7.8s
2025-10-13 01:25:34,959 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.67873 val_loss=0.65511 val_acc=0.7437 time=7.8s
2025-10-13 01:25:42,799 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.66835 val_loss=0.62306 val_acc=0.7602 time=7.8s
2025-10-13 01:25:50,628 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.66848 val_loss=0.63167 val_acc=0.7592 time=7.8s
2025-10-13 01:25:58,463 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.66066 val_loss=0.63396 val_acc=0.7532 time=7.8s
2025-10-13 01:26:06,304 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.65614 val_loss=0.61074 val_acc=0.7655 time=7.8s
2025-10-13 01:26:14,131 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.65181 val_loss=0.61364 val_acc=0.7629 time=7.8s
2025-10-13 01:26:21,961 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.65108 val_loss=0.61149 val_acc=0.7675 time=7.8s
2025-10-13 01:26:29,789 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.64592 val_loss=0.61501 val_acc=0.7614 time=7.8s
2025-10-13 01:26:37,616 - INFO - _models.training_function_executor - Epoch 029: train_loss=0.64643 val_loss=0.60980 val_acc=0.7658 time=7.8s
2025-10-13 01:26:45,439 - INFO - _models.training_function_executor - Epoch 030: train_loss=0.64312 val_loss=0.60667 val_acc=0.7667 time=7.8s
2025-10-13 01:26:53,275 - INFO - _models.training_function_executor - Epoch 031: train_loss=0.64228 val_loss=0.60695 val_acc=0.7664 time=7.8s
2025-10-13 01:27:01,107 - INFO - _models.training_function_executor - Epoch 032: train_loss=0.63603 val_loss=0.60566 val_acc=0.7664 time=7.8s
2025-10-13 01:27:08,930 - INFO - _models.training_function_executor - Epoch 033: train_loss=0.63750 val_loss=0.60577 val_acc=0.7673 time=7.8s
2025-10-13 01:27:16,755 - INFO - _models.training_function_executor - Epoch 034: train_loss=0.63778 val_loss=0.60488 val_acc=0.7678 time=7.8s
2025-10-13 01:27:17,846 - INFO - _models.training_function_executor - Model: 10,293 parameters, 44.2KB storage
2025-10-13 01:27:17,846 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2415079815136538, 1.0150624755215802, 0.9240162768979818, 0.8862242180023487, 0.8409489710764072, 0.8135555931267556, 0.8037399739955412, 0.7788729490748143, 0.7698182659129141, 0.7621116269540236, 0.7450144150831252, 0.7425308443884938, 0.7315740781436235, 0.715260968326813, 0.7151238579286076, 0.7034876107084697, 0.7102083316790628, 0.6886039088145394, 0.6843070956765249, 0.6777264723045074, 0.6787342671376657, 0.6683498247545167, 0.6684755528770129, 0.6606591067449338, 0.6561394735028537, 0.6518081810076336, 0.651081568050685, 0.6459202874069828, 0.6464281725975279, 0.6431238600370723, 0.6422794394907019, 0.6360299601436371, 0.6374982008055285, 0.6377758050156841], 'val_losses': [1.0593433701829307, 0.9875881909322689, 0.854077827504852, 0.8538019905400769, 0.767531235087865, 0.7554957150244654, 0.7362712723081413, 0.7355934275294002, 0.7860061448898021, 0.6870852274455764, 0.6817897756407634, 0.6734170272586477, 0.6959492987504905, 0.670948636064506, 0.7474540046849449, 0.6814778951401889, 0.645351829522967, 0.6793190176185712, 0.6429396457592006, 0.6275954875113208, 0.6551093691956718, 0.6230638852309713, 0.6316699841700946, 0.6339559126534494, 0.610742332094985, 0.6136357042394738, 0.6114916172234546, 0.6150052636955683, 0.6097966264001047, 0.6066667519126441, 0.6069544173221635, 0.6056603634319899, 0.6057667733699157, 0.6048841009742528], 'val_acc': [0.5847042352117606, 0.6102555127756388, 0.6659957997899895, 0.6560203010150507, 0.6988974448722436, 0.7061603080154008, 0.7162233111655583, 0.7131606580329016, 0.6851592579628981, 0.736436821841092, 0.7414245712285614, 0.7405495274763738, 0.732411620581029, 0.7430871543577179, 0.714123206160308, 0.7391494574728736, 0.7513125656282814, 0.7260238011900595, 0.7521001050052503, 0.7579628981449072, 0.7436996849842492, 0.760238011900595, 0.7591879593979699, 0.7532376618830942, 0.7654882744137207, 0.7628631431571579, 0.7675008750437522, 0.7613755687784389, 0.7658382919145957, 0.7667133356667833, 0.7663633181659083, 0.7663633181659083, 0.7673258662933147, 0.7677633881694085], 'quantization': {'bits': 32, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 43476}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003585358695532363, 'batch_size': 128, 'epochs': 34, 'weight_decay': 0.0002651811362987809, 'dropout': 0.1003300932636815, 'grad_clip': 1.0147241642067442, 'use_amp': True, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}, 'model_parameter_count': 10293, 'model_storage_size_kb': 44.227734375000004, 'model_size_validation': 'PASS'}
2025-10-13 01:27:17,846 - INFO - _models.training_function_executor - BO Objective: base=0.7678, size_penalty=0.0000, final=0.7678
2025-10-13 01:27:17,846 - INFO - _models.training_function_executor - Model: 10,293 parameters, 44.2KB (PASS 256KB limit)
2025-10-13 01:27:17,846 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 278.457s
2025-10-13 01:27:17,946 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7678
2025-10-13 01:27:17,946 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.088s
2025-10-13 01:27:17,946 - INFO - bo.run_bo - Recorded observation #9: hparams={'lr': 0.003585358695532363, 'batch_size': np.int64(128), 'epochs': np.int64(34), 'weight_decay': 0.0002651811362987809, 'dropout': 0.1003300932636815, 'grad_clip': 1.0147241642067442, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(14), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)}, value=0.7678
2025-10-13 01:27:17,946 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'lr': 0.003585358695532363, 'batch_size': np.int64(128), 'epochs': np.int64(34), 'weight_decay': 0.0002651811362987809, 'dropout': 0.1003300932636815, 'grad_clip': 1.0147241642067442, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(14), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)} -> 0.7678
2025-10-13 01:27:17,946 - INFO - bo.run_bo - üîçBO Trial 10: Using RF surrogate + Expected Improvement
2025-10-13 01:27:17,946 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:27:17,946 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 10 (NaN monitoring active)
2025-10-13 01:27:17,946 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:27:17,947 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:27:17,947 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003029380228035655, 'batch_size': 128, 'epochs': 12, 'weight_decay': 3.572518780427504e-07, 'dropout': 0.20163337162043227, 'grad_clip': 4.6815764197961345, 'use_amp': False, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 01:27:17,948 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003029380228035655, 'batch_size': 128, 'epochs': 12, 'weight_decay': 3.572518780427504e-07, 'dropout': 0.20163337162043227, 'grad_clip': 4.6815764197961345, 'use_amp': False, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 01:27:27,403 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.24744 val_loss=0.99527 val_acc=0.5997 time=9.5s
2025-10-13 01:27:33,769 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.00006 val_loss=0.90056 val_acc=0.6335 time=6.4s
2025-10-13 01:27:40,154 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.93325 val_loss=0.85439 val_acc=0.6626 time=6.4s
2025-10-13 01:27:46,556 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.89556 val_loss=0.83266 val_acc=0.6570 time=6.4s
2025-10-13 01:27:52,960 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.86883 val_loss=0.79166 val_acc=0.6824 time=6.4s
2025-10-13 01:27:59,360 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.83900 val_loss=0.77577 val_acc=0.6866 time=6.4s
2025-10-13 01:28:05,768 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.82156 val_loss=0.75891 val_acc=0.6952 time=6.4s
2025-10-13 01:28:12,163 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.80520 val_loss=0.75365 val_acc=0.6961 time=6.4s
2025-10-13 01:28:18,555 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.78693 val_loss=0.77632 val_acc=0.6985 time=6.4s
2025-10-13 01:28:24,964 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.78095 val_loss=0.71449 val_acc=0.7222 time=6.4s
2025-10-13 01:28:31,360 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.76920 val_loss=0.71122 val_acc=0.7225 time=6.4s
2025-10-13 01:28:37,754 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.76088 val_loss=0.70561 val_acc=0.7245 time=6.4s
2025-10-13 01:28:38,851 - INFO - _models.training_function_executor - Model: 4,984 parameters, 21.4KB storage
2025-10-13 01:28:38,851 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2474383641090434, 1.0000585725685496, 0.9332450448235808, 0.8955636660369243, 0.8688311469817771, 0.83900059569245, 0.821556168521331, 0.8052034855911187, 0.7869349242842276, 0.7809544743713817, 0.7692023171884512, 0.7608765740055783], 'val_losses': [0.9952733381085768, 0.900563290851868, 0.8543900075516252, 0.8326614388728584, 0.7916597233896786, 0.7757683341470597, 0.7589092445740718, 0.7536510868134263, 0.7763193743730451, 0.7144851079761544, 0.7112159263766392, 0.7056062590796337], 'val_acc': [0.5996674833741688, 0.6335316765838291, 0.6625831291564578, 0.6569828491424571, 0.6824466223311165, 0.686646832341617, 0.6952222611130556, 0.6960973048652432, 0.6984599229961498, 0.722173608680434, 0.722523626181309, 0.7245362268113406], 'quantization': {'bits': 8, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 21232}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003029380228035655, 'batch_size': 128, 'epochs': 12, 'weight_decay': 3.572518780427504e-07, 'dropout': 0.20163337162043227, 'grad_clip': 4.6815764197961345, 'use_amp': False, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 10}, 'model_parameter_count': 4984, 'model_storage_size_kb': 21.415625000000002, 'model_size_validation': 'PASS'}
2025-10-13 01:28:38,851 - INFO - _models.training_function_executor - BO Objective: base=0.7245, size_penalty=0.0000, final=0.7245
2025-10-13 01:28:38,851 - INFO - _models.training_function_executor - Model: 4,984 parameters, 21.4KB (PASS 256KB limit)
2025-10-13 01:28:38,851 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 80.905s
2025-10-13 01:28:38,958 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7245
2025-10-13 01:28:38,959 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.091s
2025-10-13 01:28:38,959 - INFO - bo.run_bo - Recorded observation #10: hparams={'lr': 0.003029380228035655, 'batch_size': np.int64(128), 'epochs': np.int64(12), 'weight_decay': 3.572518780427504e-07, 'dropout': 0.20163337162043227, 'grad_clip': 4.6815764197961345, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(9), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)}, value=0.7245
2025-10-13 01:28:38,959 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'lr': 0.003029380228035655, 'batch_size': np.int64(128), 'epochs': np.int64(12), 'weight_decay': 3.572518780427504e-07, 'dropout': 0.20163337162043227, 'grad_clip': 4.6815764197961345, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(9), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)} -> 0.7245
2025-10-13 01:28:38,959 - INFO - bo.run_bo - üîçBO Trial 11: Using RF surrogate + Expected Improvement
2025-10-13 01:28:38,959 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:28:38,959 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 11 (NaN monitoring active)
2025-10-13 01:28:38,959 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:28:38,959 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:28:38,959 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0027699326727849897, 'batch_size': 128, 'epochs': 49, 'weight_decay': 0.0001103368126296825, 'dropout': 0.301059380718852, 'grad_clip': 2.975964885512658, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 31}
2025-10-13 01:28:38,960 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0027699326727849897, 'batch_size': 128, 'epochs': 49, 'weight_decay': 0.0001103368126296825, 'dropout': 0.301059380718852, 'grad_clip': 2.975964885512658, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 31}
2025-10-13 01:28:50,167 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.24082 val_loss=1.05053 val_acc=0.5758 time=11.2s
2025-10-13 01:28:58,643 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.02348 val_loss=0.94033 val_acc=0.6124 time=8.5s
2025-10-13 01:29:07,099 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.95128 val_loss=0.92410 val_acc=0.5993 time=8.5s
2025-10-13 01:29:15,571 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.92088 val_loss=0.91689 val_acc=0.6333 time=8.5s
2025-10-13 01:29:24,046 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.89802 val_loss=0.83951 val_acc=0.6618 time=8.5s
2025-10-13 01:29:32,514 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.87429 val_loss=0.79832 val_acc=0.6811 time=8.5s
2025-10-13 01:29:40,988 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.85343 val_loss=0.81565 val_acc=0.6648 time=8.5s
2025-10-13 01:29:49,475 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.84479 val_loss=0.76930 val_acc=0.6908 time=8.5s
2025-10-13 01:29:57,950 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.83373 val_loss=0.79215 val_acc=0.6896 time=8.5s
2025-10-13 01:30:06,430 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.82407 val_loss=0.75448 val_acc=0.7079 time=8.5s
2025-10-13 01:30:14,904 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.80752 val_loss=0.74418 val_acc=0.7068 time=8.5s
2025-10-13 01:30:23,380 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.79743 val_loss=0.75662 val_acc=0.6917 time=8.5s
2025-10-13 01:30:31,859 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.79040 val_loss=0.73162 val_acc=0.7091 time=8.5s
2025-10-13 01:30:40,330 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.78837 val_loss=0.70875 val_acc=0.7147 time=8.5s
2025-10-13 01:30:48,810 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.77531 val_loss=0.69472 val_acc=0.7258 time=8.5s
2025-10-13 01:30:57,283 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.77398 val_loss=0.70792 val_acc=0.7279 time=8.5s
2025-10-13 01:31:05,755 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.76281 val_loss=0.70660 val_acc=0.7223 time=8.5s
2025-10-13 01:31:14,223 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.75399 val_loss=0.71256 val_acc=0.7258 time=8.5s
2025-10-13 01:31:22,690 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.75264 val_loss=0.76850 val_acc=0.7013 time=8.5s
2025-10-13 01:31:31,164 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.74267 val_loss=0.68631 val_acc=0.7311 time=8.5s
2025-10-13 01:31:39,645 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.73833 val_loss=0.66696 val_acc=0.7403 time=8.5s
2025-10-13 01:31:48,121 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.73744 val_loss=0.70465 val_acc=0.7215 time=8.5s
2025-10-13 01:31:56,592 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.73056 val_loss=0.66822 val_acc=0.7402 time=8.5s
2025-10-13 01:32:05,069 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.72288 val_loss=0.66599 val_acc=0.7421 time=8.5s
2025-10-13 01:32:13,545 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.72141 val_loss=0.65233 val_acc=0.7410 time=8.5s
2025-10-13 01:32:22,023 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.72246 val_loss=0.66634 val_acc=0.7355 time=8.5s
2025-10-13 01:32:30,496 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.71480 val_loss=0.65605 val_acc=0.7409 time=8.5s
2025-10-13 01:32:38,973 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.70490 val_loss=0.64637 val_acc=0.7476 time=8.5s
2025-10-13 01:32:47,454 - INFO - _models.training_function_executor - Epoch 029: train_loss=0.70104 val_loss=0.64705 val_acc=0.7484 time=8.5s
2025-10-13 01:32:55,922 - INFO - _models.training_function_executor - Epoch 030: train_loss=0.69856 val_loss=0.64032 val_acc=0.7461 time=8.5s
2025-10-13 01:33:04,398 - INFO - _models.training_function_executor - Epoch 031: train_loss=0.69810 val_loss=0.63415 val_acc=0.7461 time=8.5s
2025-10-13 01:33:12,875 - INFO - _models.training_function_executor - Epoch 032: train_loss=0.69338 val_loss=0.65276 val_acc=0.7444 time=8.5s
2025-10-13 01:33:21,352 - INFO - _models.training_function_executor - Epoch 033: train_loss=0.69379 val_loss=0.62420 val_acc=0.7587 time=8.5s
2025-10-13 01:33:29,828 - INFO - _models.training_function_executor - Epoch 034: train_loss=0.68912 val_loss=0.65402 val_acc=0.7488 time=8.5s
2025-10-13 01:33:38,300 - INFO - _models.training_function_executor - Epoch 035: train_loss=0.68882 val_loss=0.62554 val_acc=0.7563 time=8.5s
2025-10-13 01:33:46,779 - INFO - _models.training_function_executor - Epoch 036: train_loss=0.68406 val_loss=0.62871 val_acc=0.7554 time=8.5s
2025-10-13 01:33:55,256 - INFO - _models.training_function_executor - Epoch 037: train_loss=0.67665 val_loss=0.62114 val_acc=0.7607 time=8.5s
2025-10-13 01:34:03,733 - INFO - _models.training_function_executor - Epoch 038: train_loss=0.67736 val_loss=0.62420 val_acc=0.7609 time=8.5s
2025-10-13 01:34:12,210 - INFO - _models.training_function_executor - Epoch 039: train_loss=0.67576 val_loss=0.62560 val_acc=0.7562 time=8.5s
2025-10-13 01:34:20,676 - INFO - _models.training_function_executor - Epoch 040: train_loss=0.67232 val_loss=0.62252 val_acc=0.7581 time=8.5s
2025-10-13 01:34:29,154 - INFO - _models.training_function_executor - Epoch 041: train_loss=0.67190 val_loss=0.62004 val_acc=0.7610 time=8.5s
2025-10-13 01:34:37,631 - INFO - _models.training_function_executor - Epoch 042: train_loss=0.66927 val_loss=0.61557 val_acc=0.7611 time=8.5s
2025-10-13 01:34:46,103 - INFO - _models.training_function_executor - Epoch 043: train_loss=0.66695 val_loss=0.61516 val_acc=0.7626 time=8.5s
2025-10-13 01:34:54,574 - INFO - _models.training_function_executor - Epoch 044: train_loss=0.66604 val_loss=0.61443 val_acc=0.7619 time=8.5s
2025-10-13 01:35:03,050 - INFO - _models.training_function_executor - Epoch 045: train_loss=0.66538 val_loss=0.61430 val_acc=0.7621 time=8.5s
2025-10-13 01:35:11,518 - INFO - _models.training_function_executor - Epoch 046: train_loss=0.66600 val_loss=0.61384 val_acc=0.7625 time=8.5s
2025-10-13 01:35:19,992 - INFO - _models.training_function_executor - Epoch 047: train_loss=0.66308 val_loss=0.61364 val_acc=0.7619 time=8.5s
2025-10-13 01:35:28,470 - INFO - _models.training_function_executor - Epoch 048: train_loss=0.66391 val_loss=0.61390 val_acc=0.7623 time=8.5s
2025-10-13 01:35:36,939 - INFO - _models.training_function_executor - Epoch 049: train_loss=0.66492 val_loss=0.61383 val_acc=0.7623 time=8.5s
2025-10-13 01:35:47,116 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 01:35:47,116 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2408227674769987, 1.0234800149687613, 0.9512847892713163, 0.9208785608009229, 0.8980202673613963, 0.8742899430937228, 0.8534303129366072, 0.844785037472985, 0.8337346342714007, 0.8240715317013466, 0.807518019787198, 0.7974308422073269, 0.7903957889553213, 0.7883735096533898, 0.7753097777146328, 0.773976525894862, 0.7628114163604365, 0.7539930681603164, 0.7526364936710114, 0.7426734191160499, 0.7383348925947351, 0.7374423516560235, 0.7305611280824156, 0.7228762038863118, 0.7214120016842402, 0.7224648093943584, 0.7148014005139277, 0.7049025079358655, 0.7010420854165915, 0.6985635593257086, 0.6980982788968512, 0.6933795411060187, 0.6937886862476097, 0.6891223739234141, 0.6888248543034995, 0.6840569231949948, 0.6766459978999564, 0.6773647249975862, 0.6757645498926005, 0.6723210716898473, 0.6718992954540554, 0.6692686411814545, 0.6669524246301941, 0.6660406927483291, 0.6653752351583281, 0.6660024035444283, 0.6630832409166063, 0.6639052412499069, 0.6649164346535389], 'val_losses': [1.050529756243929, 0.9403291654453271, 0.9241039258514955, 0.9168920209869289, 0.8395121443885, 0.7983191183158306, 0.8156541244191726, 0.7693018139681284, 0.792152097582358, 0.7544782128958256, 0.7441846694110114, 0.7566157865240559, 0.7316213450650465, 0.7087493722239365, 0.6947160346089938, 0.7079212576682892, 0.7066033588533932, 0.7125604905195907, 0.768496188534946, 0.6863117962606228, 0.666962788286099, 0.7046496325078276, 0.6682187732717229, 0.66599171396148, 0.6523284220303277, 0.6663396795980155, 0.6560506150987042, 0.6463670302488856, 0.6470489382618659, 0.6403172603636552, 0.6341475655158834, 0.6527619543174034, 0.6242023515959991, 0.654018310595944, 0.6255442345104811, 0.6287098641699329, 0.6211392430521452, 0.6241976370292399, 0.6255980480121991, 0.6225224546840402, 0.6200366550948931, 0.6155746280834063, 0.6151559823745191, 0.6144295890388849, 0.6143049147732407, 0.6138421875803797, 0.6136388978759517, 0.6138999308369817, 0.6138341174828326], 'val_acc': [0.575778788939447, 0.6124431221561079, 0.5993174658732937, 0.6332691634581729, 0.6617955897794889, 0.6811340567028351, 0.6647707385369268, 0.6907595379768988, 0.6896219810990549, 0.707910395519776, 0.7067728386419321, 0.6917220861043052, 0.7091354567728386, 0.7147357367868393, 0.725848792439622, 0.7279488974448722, 0.7223486174308715, 0.725848792439622, 0.7013475673783689, 0.7310990549527476, 0.7402870143507175, 0.7214735736786839, 0.7401995099754988, 0.7421246062303115, 0.7409870493524676, 0.7354742737136857, 0.7408995449772489, 0.7476373818690935, 0.7484249212460623, 0.7461498074903745, 0.7460623031151558, 0.7443997199859993, 0.7586629331466573, 0.7487749387469373, 0.7563003150157508, 0.7554252712635632, 0.7606755337766888, 0.7608505425271264, 0.756212810640532, 0.7581379068953448, 0.7610255512775639, 0.7611130556527826, 0.7626006300315016, 0.7619005950297515, 0.762075603780189, 0.7625131256562828, 0.7619005950297515, 0.7623381169058453, 0.7623381169058453], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 14749}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0027699326727849897, 'batch_size': 128, 'epochs': 49, 'weight_decay': 0.0001103368126296825, 'dropout': 0.301059380718852, 'grad_clip': 2.975964885512658, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 31}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 01:35:47,116 - INFO - _models.training_function_executor - BO Objective: base=0.7623, size_penalty=0.0000, final=0.7623
2025-10-13 01:35:47,116 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 01:35:47,116 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 428.158s
2025-10-13 01:35:47,263 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7623
2025-10-13 01:35:47,263 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.126s
2025-10-13 01:35:47,263 - INFO - bo.run_bo - Recorded observation #11: hparams={'lr': 0.0027699326727849897, 'batch_size': np.int64(128), 'epochs': np.int64(49), 'weight_decay': 0.0001103368126296825, 'dropout': 0.301059380718852, 'grad_clip': 2.975964885512658, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(31)}, value=0.7623
2025-10-13 01:35:47,263 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 11: {'lr': 0.0027699326727849897, 'batch_size': np.int64(128), 'epochs': np.int64(49), 'weight_decay': 0.0001103368126296825, 'dropout': 0.301059380718852, 'grad_clip': 2.975964885512658, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(31)} -> 0.7623
2025-10-13 01:35:47,264 - INFO - bo.run_bo - üîçBO Trial 12: Using RF surrogate + Expected Improvement
2025-10-13 01:35:47,264 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:35:47,264 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 12 (NaN monitoring active)
2025-10-13 01:35:47,264 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:35:47,264 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:35:47,264 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0014263470098439966, 'batch_size': 64, 'epochs': 12, 'weight_decay': 0.0005390438700237766, 'dropout': 0.33702710532728797, 'grad_clip': 3.29760316814705, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 15}
2025-10-13 01:35:47,265 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0014263470098439966, 'batch_size': 64, 'epochs': 12, 'weight_decay': 0.0005390438700237766, 'dropout': 0.33702710532728797, 'grad_clip': 3.29760316814705, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 15}
2025-10-13 01:35:59,068 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.33466 val_loss=1.16542 val_acc=0.5242 time=11.8s
2025-10-13 01:36:07,831 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.13436 val_loss=1.03560 val_acc=0.5887 time=8.8s
2025-10-13 01:36:16,604 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.05492 val_loss=0.96430 val_acc=0.6099 time=8.8s
2025-10-13 01:36:25,376 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.00554 val_loss=0.93699 val_acc=0.6167 time=8.8s
2025-10-13 01:36:34,160 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.98092 val_loss=0.91301 val_acc=0.6251 time=8.8s
2025-10-13 01:36:42,941 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.96712 val_loss=0.91376 val_acc=0.6278 time=8.8s
2025-10-13 01:36:51,728 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.95158 val_loss=0.87799 val_acc=0.6439 time=8.8s
2025-10-13 01:37:00,515 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.94749 val_loss=0.86937 val_acc=0.6454 time=8.8s
2025-10-13 01:37:09,316 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.93456 val_loss=0.86495 val_acc=0.6482 time=8.8s
2025-10-13 01:37:18,108 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.92729 val_loss=0.86121 val_acc=0.6530 time=8.8s
2025-10-13 01:37:26,907 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.92783 val_loss=0.85901 val_acc=0.6553 time=8.8s
2025-10-13 01:37:35,694 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.92367 val_loss=0.85727 val_acc=0.6537 time=8.8s
2025-10-13 01:37:36,784 - INFO - _models.training_function_executor - Model: 9,442 parameters, 40.6KB storage
2025-10-13 01:37:36,784 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3346635631468482, 1.1343607650505816, 1.054922733976159, 1.005543651262029, 0.9809214074919597, 0.9671193595987373, 0.9515773025391858, 0.9474864138520427, 0.9345622228749949, 0.9272897567914256, 0.9278273768344875, 0.9236735366089259], 'val_losses': [1.16542180735288, 1.0355950868501085, 0.964304363723397, 0.9369927574213793, 0.9130050462569896, 0.9137626586779873, 0.8779948140759547, 0.8693733064494936, 0.86494878584328, 0.861210956288085, 0.8590073683564797, 0.8572682659860503], 'val_acc': [0.5242387119355968, 0.5887294364718236, 0.6099054952747638, 0.6167308365418271, 0.6251312565628281, 0.6278438921946097, 0.6439446972348617, 0.6454322716135806, 0.648232411620581, 0.6529576478823941, 0.6553202660133006, 0.6536576828841442], 'quantization': {'bits': 32, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 58504}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0014263470098439966, 'batch_size': 64, 'epochs': 12, 'weight_decay': 0.0005390438700237766, 'dropout': 0.33702710532728797, 'grad_clip': 3.29760316814705, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 15}, 'model_parameter_count': 9442, 'model_storage_size_kb': 40.57109375, 'model_size_validation': 'PASS'}
2025-10-13 01:37:36,784 - INFO - _models.training_function_executor - BO Objective: base=0.6537, size_penalty=0.0000, final=0.6537
2025-10-13 01:37:36,785 - INFO - _models.training_function_executor - Model: 9,442 parameters, 40.6KB (PASS 256KB limit)
2025-10-13 01:37:36,785 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 109.521s
2025-10-13 01:37:36,890 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6537
2025-10-13 01:37:36,890 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-13 01:37:36,890 - INFO - bo.run_bo - Recorded observation #12: hparams={'lr': 0.0014263470098439966, 'batch_size': np.int64(64), 'epochs': np.int64(12), 'weight_decay': 0.0005390438700237766, 'dropout': 0.33702710532728797, 'grad_clip': 3.29760316814705, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(15)}, value=0.6537
2025-10-13 01:37:36,890 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 12: {'lr': 0.0014263470098439966, 'batch_size': np.int64(64), 'epochs': np.int64(12), 'weight_decay': 0.0005390438700237766, 'dropout': 0.33702710532728797, 'grad_clip': 3.29760316814705, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(15)} -> 0.6537
2025-10-13 01:37:36,890 - INFO - bo.run_bo - üîçBO Trial 13: Using RF surrogate + Expected Improvement
2025-10-13 01:37:36,890 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:37:36,890 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 13 (NaN monitoring active)
2025-10-13 01:37:36,891 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:37:36,891 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:37:36,891 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0042652160711040875, 'batch_size': 32, 'epochs': 25, 'weight_decay': 0.0003798753737920946, 'dropout': 0.061833140366387776, 'grad_clip': 3.1434906620731784, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 9, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 22}
2025-10-13 01:37:36,892 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0042652160711040875, 'batch_size': 32, 'epochs': 25, 'weight_decay': 0.0003798753737920946, 'dropout': 0.061833140366387776, 'grad_clip': 3.1434906620731784, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 9, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 22}
2025-10-13 01:37:49,483 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.14749 val_loss=1.06072 val_acc=0.5745 time=12.6s
2025-10-13 01:37:59,156 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.00625 val_loss=0.93807 val_acc=0.6325 time=9.7s
2025-10-13 01:38:08,834 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.93998 val_loss=0.88086 val_acc=0.6620 time=9.7s
2025-10-13 01:38:18,503 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.90883 val_loss=0.84260 val_acc=0.6769 time=9.7s
2025-10-13 01:38:28,180 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.87943 val_loss=0.82250 val_acc=0.6838 time=9.7s
2025-10-13 01:38:37,846 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.85533 val_loss=0.79247 val_acc=0.7069 time=9.7s
2025-10-13 01:38:47,511 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.84255 val_loss=0.79113 val_acc=0.6992 time=9.7s
2025-10-13 01:38:57,174 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.82045 val_loss=0.75328 val_acc=0.7127 time=9.7s
2025-10-13 01:39:06,839 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.79193 val_loss=0.75266 val_acc=0.7117 time=9.7s
2025-10-13 01:39:16,493 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.77454 val_loss=0.73298 val_acc=0.7174 time=9.7s
2025-10-13 01:39:26,155 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.75900 val_loss=0.71266 val_acc=0.7226 time=9.7s
2025-10-13 01:39:35,815 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.74749 val_loss=0.71741 val_acc=0.7214 time=9.7s
2025-10-13 01:39:45,482 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.73571 val_loss=0.68806 val_acc=0.7335 time=9.7s
2025-10-13 01:39:55,150 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.72748 val_loss=0.68632 val_acc=0.7316 time=9.7s
2025-10-13 01:40:04,816 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.71884 val_loss=0.68358 val_acc=0.7317 time=9.7s
2025-10-13 01:40:14,590 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.70696 val_loss=0.68349 val_acc=0.7362 time=9.7s
2025-10-13 01:40:24,261 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.70139 val_loss=0.65893 val_acc=0.7446 time=9.7s
2025-10-13 01:40:33,920 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.69218 val_loss=0.66097 val_acc=0.7398 time=9.7s
2025-10-13 01:40:43,584 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.68868 val_loss=0.66033 val_acc=0.7437 time=9.7s
2025-10-13 01:40:53,243 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.68226 val_loss=0.65158 val_acc=0.7468 time=9.7s
2025-10-13 01:41:02,910 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.68024 val_loss=0.64827 val_acc=0.7488 time=9.7s
2025-10-13 01:41:12,567 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.67449 val_loss=0.64785 val_acc=0.7500 time=9.7s
2025-10-13 01:41:22,235 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.67076 val_loss=0.64503 val_acc=0.7472 time=9.7s
2025-10-13 01:41:31,897 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.67069 val_loss=0.64219 val_acc=0.7511 time=9.7s
2025-10-13 01:41:41,560 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.66872 val_loss=0.64176 val_acc=0.7514 time=9.7s
2025-10-13 01:41:42,646 - INFO - _models.training_function_executor - Model: 9,470 parameters, 40.7KB storage
2025-10-13 01:41:42,646 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1474924491425682, 1.006247504591149, 0.9399761950423094, 0.9088330906214396, 0.8794302615536899, 0.8553294327695511, 0.8425540695000162, 0.8204541810542751, 0.7919334857289425, 0.7745382387528772, 0.7589994428622626, 0.7474851871771874, 0.7357142272636445, 0.7274793688968049, 0.71884404029469, 0.7069575712110848, 0.7013858575523838, 0.6921820538754141, 0.6886841711732613, 0.6822584898145541, 0.6802353994346474, 0.6744859095716292, 0.670760742383776, 0.6706865668129912, 0.6687175894810012], 'val_losses': [1.0607150991270915, 0.9380657954110856, 0.8808644649904843, 0.8426030064363517, 0.8224961849038401, 0.7924704068934622, 0.791129834279757, 0.7532848817591989, 0.752657660600978, 0.7329822438223027, 0.7126627092516669, 0.7174083563594664, 0.6880645253752594, 0.6863188597761254, 0.6835759374325118, 0.6834923695716818, 0.658928811070299, 0.6609677372798245, 0.6603292165663762, 0.651577593669384, 0.6482716661923241, 0.647848959564954, 0.645031567779003, 0.6421913191451866, 0.6417636084815277], 'val_acc': [0.5744662233111656, 0.632481624081204, 0.6619705985299265, 0.6769338466923346, 0.6838466923346167, 0.7068603430171508, 0.6992474623731186, 0.7127231361568078, 0.7116730836541827, 0.7173608680434022, 0.7226111305565278, 0.7213860693034652, 0.7335491774588729, 0.7316240812040602, 0.731711585579279, 0.7361743087154358, 0.7445747287364368, 0.7398494924746237, 0.7436996849842492, 0.7468498424921246, 0.7487749387469373, 0.75, 0.7471998599929996, 0.7511375568778439, 0.7514000700035002], 'quantization': {'bits': 16, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 21532}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0042652160711040875, 'batch_size': 32, 'epochs': 25, 'weight_decay': 0.0003798753737920946, 'dropout': 0.061833140366387776, 'grad_clip': 3.1434906620731784, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 9, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 22}, 'model_parameter_count': 9470, 'model_storage_size_kb': 40.69140625, 'model_size_validation': 'PASS'}
2025-10-13 01:41:42,646 - INFO - _models.training_function_executor - BO Objective: base=0.7514, size_penalty=0.0000, final=0.7514
2025-10-13 01:41:42,646 - INFO - _models.training_function_executor - Model: 9,470 parameters, 40.7KB (PASS 256KB limit)
2025-10-13 01:41:42,646 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 245.755s
2025-10-13 01:41:42,871 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7514
2025-10-13 01:41:42,871 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.219s
2025-10-13 01:41:42,871 - INFO - bo.run_bo - Recorded observation #13: hparams={'lr': 0.0042652160711040875, 'batch_size': np.int64(32), 'epochs': np.int64(25), 'weight_decay': 0.0003798753737920946, 'dropout': 0.061833140366387776, 'grad_clip': 3.1434906620731784, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(9), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(22)}, value=0.7514
2025-10-13 01:41:42,871 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 13: {'lr': 0.0042652160711040875, 'batch_size': np.int64(32), 'epochs': np.int64(25), 'weight_decay': 0.0003798753737920946, 'dropout': 0.061833140366387776, 'grad_clip': 3.1434906620731784, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(9), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(22)} -> 0.7514
2025-10-13 01:41:42,872 - INFO - bo.run_bo - üîçBO Trial 14: Using RF surrogate + Expected Improvement
2025-10-13 01:41:42,872 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:41:42,872 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 14 (NaN monitoring active)
2025-10-13 01:41:42,872 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:41:42,872 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:41:42,872 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002613664705980508, 'batch_size': 32, 'epochs': 27, 'weight_decay': 0.0009543663236172027, 'dropout': 0.021738010522352805, 'grad_clip': 1.4160227781543664, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 8, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 21}
2025-10-13 01:41:42,873 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002613664705980508, 'batch_size': 32, 'epochs': 27, 'weight_decay': 0.0009543663236172027, 'dropout': 0.021738010522352805, 'grad_clip': 1.4160227781543664, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 8, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 21}
2025-10-13 01:42:01,819 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.17900 val_loss=1.08528 val_acc=0.5850 time=18.9s
2025-10-13 01:42:10,486 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.04566 val_loss=1.00967 val_acc=0.6258 time=8.7s
2025-10-13 01:42:19,160 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.98507 val_loss=0.94179 val_acc=0.6425 time=8.7s
2025-10-13 01:42:27,843 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.94358 val_loss=0.91288 val_acc=0.6491 time=8.7s
2025-10-13 01:42:36,518 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.91726 val_loss=0.93561 val_acc=0.6402 time=8.7s
2025-10-13 01:42:45,202 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.90066 val_loss=0.88205 val_acc=0.6621 time=8.7s
2025-10-13 01:42:53,877 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.88855 val_loss=0.91229 val_acc=0.6537 time=8.7s
2025-10-13 01:43:02,556 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.87558 val_loss=0.88735 val_acc=0.6564 time=8.7s
2025-10-13 01:43:11,252 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.86348 val_loss=0.83651 val_acc=0.6753 time=8.7s
2025-10-13 01:43:19,934 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.85282 val_loss=0.84672 val_acc=0.6743 time=8.7s
2025-10-13 01:43:28,626 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.84542 val_loss=0.83099 val_acc=0.6859 time=8.7s
2025-10-13 01:43:37,311 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.83976 val_loss=0.81883 val_acc=0.6859 time=8.7s
2025-10-13 01:43:45,989 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.82958 val_loss=0.81336 val_acc=0.6898 time=8.7s
2025-10-13 01:43:54,676 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.82555 val_loss=0.81643 val_acc=0.6858 time=8.7s
2025-10-13 01:44:03,354 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.82091 val_loss=0.80257 val_acc=0.6920 time=8.7s
2025-10-13 01:44:12,032 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.80766 val_loss=0.80752 val_acc=0.6895 time=8.7s
2025-10-13 01:44:20,703 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.80439 val_loss=0.81164 val_acc=0.6888 time=8.7s
2025-10-13 01:44:29,383 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.79966 val_loss=0.78622 val_acc=0.6959 time=8.7s
2025-10-13 01:44:38,068 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.79475 val_loss=0.78966 val_acc=0.6961 time=8.7s
2025-10-13 01:44:46,756 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.78876 val_loss=0.78419 val_acc=0.6978 time=8.7s
2025-10-13 01:44:55,446 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.78657 val_loss=0.78244 val_acc=0.6987 time=8.7s
2025-10-13 01:45:04,119 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.78112 val_loss=0.77933 val_acc=0.7003 time=8.7s
2025-10-13 01:45:12,789 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.77913 val_loss=0.77736 val_acc=0.7021 time=8.7s
2025-10-13 01:45:21,459 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.77714 val_loss=0.77587 val_acc=0.7006 time=8.7s
2025-10-13 01:45:30,140 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.77677 val_loss=0.77457 val_acc=0.7029 time=8.7s
2025-10-13 01:45:38,828 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.77255 val_loss=0.77460 val_acc=0.7020 time=8.7s
2025-10-13 01:45:47,510 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.77228 val_loss=0.77475 val_acc=0.7020 time=8.7s
2025-10-13 01:45:48,619 - INFO - _models.training_function_executor - Model: 9,562 parameters, 41.1KB storage
2025-10-13 01:45:48,619 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.178998919730008, 1.0456641237761617, 0.9850739141757312, 0.9435789139904173, 0.9172621399612747, 0.9006585456459598, 0.8885499622215122, 0.8755772629733848, 0.8634816368935532, 0.8528217845627342, 0.8454205972313005, 0.839764406829603, 0.8295827963404777, 0.8255455386901511, 0.8209054436473359, 0.807656632568772, 0.8043936805204366, 0.7996594190263732, 0.7947494142490289, 0.7887550491447168, 0.7865684454909229, 0.7811244862622885, 0.7791282109209487, 0.7771357879131292, 0.7767652359758176, 0.7725514581372865, 0.7722781276761297], 'val_losses': [1.0852832273039987, 1.0096654021159976, 0.9417942393940146, 0.9128832745310056, 0.9356082828469655, 0.8820496335244905, 0.9122863109394683, 0.8873527191884458, 0.8365071659785782, 0.8467244971745658, 0.8309880775882933, 0.8188260403762633, 0.8133575626299187, 0.8164278293432036, 0.8025698872934407, 0.8075175897032805, 0.8116429903142554, 0.78622369846348, 0.7896550719371658, 0.7841880286453402, 0.7824440350847975, 0.779327184827669, 0.7773593470980998, 0.7758723216996478, 0.7745734411684583, 0.774604521976053, 0.774748756746166], 'val_acc': [0.5849667483374169, 0.6258312915645782, 0.6424571228561428, 0.6491074553727686, 0.640182009100455, 0.6620581029051452, 0.6536576828841442, 0.6563703185159258, 0.6752712635631781, 0.6743087154357718, 0.685946797339867, 0.6858592929646482, 0.6897969898494924, 0.6857717885894294, 0.6919845992299615, 0.6895344767238362, 0.6888344417220861, 0.6959222961148057, 0.6960973048652432, 0.6977598879943997, 0.6987224361218061, 0.7002975148757438, 0.7021351067553377, 0.7006475323766188, 0.7029226461323066, 0.7019600980049002, 0.702047602380119], 'quantization': {'bits': 8, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 41848}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002613664705980508, 'batch_size': 32, 'epochs': 27, 'weight_decay': 0.0009543663236172027, 'dropout': 0.021738010522352805, 'grad_clip': 1.4160227781543664, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 8, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 21}, 'model_parameter_count': 9562, 'model_storage_size_kb': 41.08671875, 'model_size_validation': 'PASS'}
2025-10-13 01:45:48,619 - INFO - _models.training_function_executor - BO Objective: base=0.7020, size_penalty=0.0000, final=0.7020
2025-10-13 01:45:48,619 - INFO - _models.training_function_executor - Model: 9,562 parameters, 41.1KB (PASS 256KB limit)
2025-10-13 01:45:48,619 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 245.747s
2025-10-13 01:45:48,716 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7020
2025-10-13 01:45:48,717 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-13 01:45:48,717 - INFO - bo.run_bo - Recorded observation #14: hparams={'lr': 0.002613664705980508, 'batch_size': np.int64(32), 'epochs': np.int64(27), 'weight_decay': 0.0009543663236172027, 'dropout': 0.021738010522352805, 'grad_clip': 1.4160227781543664, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(8), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(21)}, value=0.7020
2025-10-13 01:45:48,717 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 14: {'lr': 0.002613664705980508, 'batch_size': np.int64(32), 'epochs': np.int64(27), 'weight_decay': 0.0009543663236172027, 'dropout': 0.021738010522352805, 'grad_clip': 1.4160227781543664, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(8), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(21)} -> 0.7020
2025-10-13 01:45:48,717 - INFO - bo.run_bo - üîçBO Trial 15: Using RF surrogate + Expected Improvement
2025-10-13 01:45:48,717 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:45:48,717 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 15 (NaN monitoring active)
2025-10-13 01:45:48,717 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:45:48,717 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:45:48,717 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004038075583399745, 'batch_size': 256, 'epochs': 49, 'weight_decay': 0.0005989223014505408, 'dropout': 0.08571841848080942, 'grad_clip': 3.8392513686213494, 'use_amp': False, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 7, 'kernel_size_dec': 5, 'partitions': 4, 'gcn_hidden_dim': 5, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 13}
2025-10-13 01:45:48,718 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004038075583399745, 'batch_size': 256, 'epochs': 49, 'weight_decay': 0.0005989223014505408, 'dropout': 0.08571841848080942, 'grad_clip': 3.8392513686213494, 'use_amp': False, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 7, 'kernel_size_dec': 5, 'partitions': 4, 'gcn_hidden_dim': 5, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 13}
2025-10-13 01:46:00,766 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.33848 val_loss=1.14276 val_acc=0.5558 time=12.0s
2025-10-13 01:46:09,299 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.10178 val_loss=1.04566 val_acc=0.5880 time=8.5s
2025-10-13 01:46:17,833 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.04325 val_loss=1.02070 val_acc=0.5914 time=8.5s
2025-10-13 01:46:26,351 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.99624 val_loss=0.98323 val_acc=0.6110 time=8.5s
2025-10-13 01:46:34,887 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.96805 val_loss=0.95235 val_acc=0.6275 time=8.5s
2025-10-13 01:46:43,425 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.94531 val_loss=0.94773 val_acc=0.6306 time=8.5s
2025-10-13 01:46:51,956 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.92698 val_loss=0.93120 val_acc=0.6432 time=8.5s
2025-10-13 01:47:00,490 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.91255 val_loss=0.91077 val_acc=0.6569 time=8.5s
2025-10-13 01:47:09,030 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.89855 val_loss=0.90500 val_acc=0.6635 time=8.5s
2025-10-13 01:47:17,575 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.88853 val_loss=0.90355 val_acc=0.6537 time=8.5s
2025-10-13 01:47:26,121 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.87242 val_loss=0.86272 val_acc=0.6756 time=8.5s
2025-10-13 01:47:34,672 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.85970 val_loss=0.85870 val_acc=0.6727 time=8.5s
2025-10-13 01:47:43,207 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.85514 val_loss=0.83954 val_acc=0.6796 time=8.5s
2025-10-13 01:47:51,755 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.84112 val_loss=0.82798 val_acc=0.6845 time=8.5s
2025-10-13 01:48:00,301 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.83512 val_loss=0.81986 val_acc=0.6877 time=8.5s
2025-10-13 01:48:08,858 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.82850 val_loss=0.81533 val_acc=0.6873 time=8.6s
2025-10-13 01:48:17,399 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.82369 val_loss=0.80916 val_acc=0.6903 time=8.5s
2025-10-13 01:48:25,950 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.82107 val_loss=0.80544 val_acc=0.6880 time=8.6s
2025-10-13 01:48:34,498 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.81532 val_loss=0.80524 val_acc=0.6950 time=8.5s
2025-10-13 01:48:43,051 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.81535 val_loss=0.81534 val_acc=0.6873 time=8.6s
2025-10-13 01:48:51,602 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.80780 val_loss=0.79178 val_acc=0.6947 time=8.6s
2025-10-13 01:49:00,143 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.80293 val_loss=0.80455 val_acc=0.6950 time=8.5s
2025-10-13 01:49:08,722 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.80019 val_loss=0.77991 val_acc=0.7020 time=8.6s
2025-10-13 01:49:17,263 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.79945 val_loss=0.78969 val_acc=0.7040 time=8.5s
2025-10-13 01:49:25,805 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.79378 val_loss=0.77606 val_acc=0.7051 time=8.5s
2025-10-13 01:49:34,361 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.79581 val_loss=0.77292 val_acc=0.7065 time=8.6s
2025-10-13 01:49:42,898 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.79153 val_loss=0.77306 val_acc=0.7034 time=8.5s
2025-10-13 01:49:51,436 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.78730 val_loss=0.77387 val_acc=0.7015 time=8.5s
2025-10-13 01:49:59,975 - INFO - _models.training_function_executor - Epoch 029: train_loss=0.78469 val_loss=0.76704 val_acc=0.7079 time=8.5s
2025-10-13 01:50:08,509 - INFO - _models.training_function_executor - Epoch 030: train_loss=0.78254 val_loss=0.76383 val_acc=0.7095 time=8.5s
2025-10-13 01:50:17,053 - INFO - _models.training_function_executor - Epoch 031: train_loss=0.77966 val_loss=0.77122 val_acc=0.7120 time=8.5s
2025-10-13 01:50:25,594 - INFO - _models.training_function_executor - Epoch 032: train_loss=0.78085 val_loss=0.75942 val_acc=0.7083 time=8.5s
2025-10-13 01:50:34,147 - INFO - _models.training_function_executor - Epoch 033: train_loss=0.77838 val_loss=0.75816 val_acc=0.7088 time=8.6s
2025-10-13 01:50:42,697 - INFO - _models.training_function_executor - Epoch 034: train_loss=0.77755 val_loss=0.75621 val_acc=0.7125 time=8.5s
2025-10-13 01:50:51,232 - INFO - _models.training_function_executor - Epoch 035: train_loss=0.77319 val_loss=0.75827 val_acc=0.7069 time=8.5s
2025-10-13 01:50:59,773 - INFO - _models.training_function_executor - Epoch 036: train_loss=0.77423 val_loss=0.75483 val_acc=0.7132 time=8.5s
2025-10-13 01:51:08,328 - INFO - _models.training_function_executor - Epoch 037: train_loss=0.77332 val_loss=0.75629 val_acc=0.7128 time=8.6s
2025-10-13 01:51:16,883 - INFO - _models.training_function_executor - Epoch 038: train_loss=0.76863 val_loss=0.75451 val_acc=0.7134 time=8.6s
2025-10-13 01:51:25,440 - INFO - _models.training_function_executor - Epoch 039: train_loss=0.76935 val_loss=0.75201 val_acc=0.7163 time=8.6s
2025-10-13 01:51:33,981 - INFO - _models.training_function_executor - Epoch 040: train_loss=0.76873 val_loss=0.74925 val_acc=0.7144 time=8.5s
2025-10-13 01:51:42,536 - INFO - _models.training_function_executor - Epoch 041: train_loss=0.76821 val_loss=0.74884 val_acc=0.7167 time=8.6s
2025-10-13 01:51:51,088 - INFO - _models.training_function_executor - Epoch 042: train_loss=0.76462 val_loss=0.74712 val_acc=0.7156 time=8.6s
2025-10-13 01:51:59,644 - INFO - _models.training_function_executor - Epoch 043: train_loss=0.76485 val_loss=0.74686 val_acc=0.7164 time=8.6s
2025-10-13 01:52:08,185 - INFO - _models.training_function_executor - Epoch 044: train_loss=0.76508 val_loss=0.74662 val_acc=0.7163 time=8.5s
2025-10-13 01:52:16,728 - INFO - _models.training_function_executor - Epoch 045: train_loss=0.76618 val_loss=0.74622 val_acc=0.7174 time=8.5s
2025-10-13 01:52:25,273 - INFO - _models.training_function_executor - Epoch 046: train_loss=0.76510 val_loss=0.74642 val_acc=0.7178 time=8.5s
2025-10-13 01:52:33,824 - INFO - _models.training_function_executor - Epoch 047: train_loss=0.76298 val_loss=0.74610 val_acc=0.7175 time=8.6s
2025-10-13 01:52:42,359 - INFO - _models.training_function_executor - Epoch 048: train_loss=0.76318 val_loss=0.74608 val_acc=0.7168 time=8.5s
2025-10-13 01:52:50,910 - INFO - _models.training_function_executor - Epoch 049: train_loss=0.76203 val_loss=0.74599 val_acc=0.7173 time=8.6s
2025-10-13 01:52:58,278 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 01:52:58,278 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3384770691958099, 1.1017764541791544, 1.0432501246055441, 0.9962357496480905, 0.9680450338978512, 0.9453052836863111, 0.9269793549533653, 0.9125497044071602, 0.8985502410068519, 0.8885251491020558, 0.872423438788879, 0.8597010774632455, 0.8551369847473582, 0.841122704283274, 0.8351184780212979, 0.82850064954267, 0.8236897991260199, 0.8210686146065536, 0.8153236079641601, 0.8153474213862527, 0.8078008768731245, 0.8029261016328308, 0.8001936705412045, 0.7994510912795062, 0.7937788955390057, 0.7958108650081676, 0.7915261426212323, 0.7872954806457001, 0.7846885871795412, 0.7825414767246961, 0.779655328717397, 0.7808484730288245, 0.7783769007992569, 0.7775545055982238, 0.7731926724299043, 0.7742279902554327, 0.773320826275765, 0.7686263445502692, 0.7693533255455584, 0.7687315664843826, 0.7682062921133499, 0.7646208451392561, 0.7648460770095609, 0.7650798518298012, 0.7661750873444504, 0.7650963521562842, 0.762980590343976, 0.7631835624351341, 0.7620310611269213], 'val_losses': [1.1427624154266127, 1.0456573906001572, 1.0206995630414493, 0.9832336778068276, 0.9523503404628325, 0.9477332316581545, 0.9312043769567381, 0.9107692829161455, 0.9049975992208767, 0.9035464089610253, 0.8627218985457416, 0.8587012726567115, 0.83953940104804, 0.8279835886791698, 0.819860629927749, 0.8153324412807201, 0.8091612611152428, 0.8054415273174023, 0.8052402741849777, 0.81533985483008, 0.791779897681975, 0.8045520273004331, 0.7799115765958472, 0.7896894924199201, 0.7760636035403798, 0.7729223568956043, 0.7730565338356744, 0.7738686756191447, 0.767036503830864, 0.7638342662795591, 0.7712208147769964, 0.7594225988715189, 0.7581568189463417, 0.7562073375279977, 0.758272946131242, 0.754832080706542, 0.756285323143673, 0.7545128787027024, 0.7520129501005967, 0.7492524036628448, 0.7488406463064928, 0.7471240612648565, 0.7468562091527637, 0.7466200484777189, 0.7462189742890446, 0.7464220912714375, 0.7461037262778705, 0.7460844846384318, 0.745987957784835], 'val_acc': [0.5558277913895695, 0.5880294014700735, 0.5914420721036052, 0.6109555477773889, 0.6274938746937346, 0.63064403220161, 0.6431571578578928, 0.6568953447672383, 0.6635456772838642, 0.6536576828841442, 0.6756212810640532, 0.6727336366818341, 0.6796464823241162, 0.684459222961148, 0.6876968848442422, 0.6872593629681484, 0.690322016100805, 0.6880469023451172, 0.6949597479873993, 0.6873468673433671, 0.6946972348617431, 0.6949597479873993, 0.702047602380119, 0.7039726986349317, 0.7051102555127756, 0.7065103255162758, 0.7034476723836192, 0.7015225761288064, 0.707910395519776, 0.7094854742737137, 0.7120231011550577, 0.7083479173958698, 0.7087854392719636, 0.7124606230311515, 0.7069478473923696, 0.7132481624081204, 0.7128106405320266, 0.7134231711585579, 0.716310815540777, 0.7143857192859643, 0.7166608330416521, 0.7156107805390269, 0.7163983199159958, 0.716310815540777, 0.7174483724186209, 0.717798389919496, 0.7175358767938397, 0.7168358417920896, 0.7172733636681834], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 12780}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004038075583399745, 'batch_size': 256, 'epochs': 49, 'weight_decay': 0.0005989223014505408, 'dropout': 0.08571841848080942, 'grad_clip': 3.8392513686213494, 'use_amp': False, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 7, 'kernel_size_dec': 5, 'partitions': 4, 'gcn_hidden_dim': 5, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 13}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 01:52:58,278 - INFO - _models.training_function_executor - BO Objective: base=0.7173, size_penalty=0.0000, final=0.7173
2025-10-13 01:52:58,278 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 01:52:58,278 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 429.561s
2025-10-13 01:52:58,402 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7173
2025-10-13 01:52:58,402 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-13 01:52:58,402 - INFO - bo.run_bo - Recorded observation #15: hparams={'lr': 0.004038075583399745, 'batch_size': np.int64(256), 'epochs': np.int64(49), 'weight_decay': 0.0005989223014505408, 'dropout': 0.08571841848080942, 'grad_clip': 3.8392513686213494, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(14), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(5), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(13)}, value=0.7173
2025-10-13 01:52:58,402 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 15: {'lr': 0.004038075583399745, 'batch_size': np.int64(256), 'epochs': np.int64(49), 'weight_decay': 0.0005989223014505408, 'dropout': 0.08571841848080942, 'grad_clip': 3.8392513686213494, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(14), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(5), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(13)} -> 0.7173
2025-10-13 01:52:58,402 - INFO - bo.run_bo - üîçBO Trial 16: Using RF surrogate + Expected Improvement
2025-10-13 01:52:58,402 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:52:58,402 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 16 (NaN monitoring active)
2025-10-13 01:52:58,402 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:52:58,402 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:52:58,402 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0033103996767633384, 'batch_size': 32, 'epochs': 7, 'weight_decay': 1.357496208874004e-06, 'dropout': 0.20225254735056641, 'grad_clip': 4.159824096647204, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 12}
2025-10-13 01:52:58,404 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0033103996767633384, 'batch_size': 32, 'epochs': 7, 'weight_decay': 1.357496208874004e-06, 'dropout': 0.20225254735056641, 'grad_clip': 4.159824096647204, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 12}
2025-10-13 01:53:12,450 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.04357 val_loss=0.79626 val_acc=0.6937 time=14.0s
2025-10-13 01:53:23,531 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.80444 val_loss=0.76584 val_acc=0.6932 time=11.1s
2025-10-13 01:53:34,615 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.72403 val_loss=0.67898 val_acc=0.7444 time=11.1s
2025-10-13 01:53:45,692 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.66450 val_loss=0.64851 val_acc=0.7433 time=11.1s
2025-10-13 01:53:56,786 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.62163 val_loss=0.58186 val_acc=0.7833 time=11.1s
2025-10-13 01:54:07,882 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.59277 val_loss=0.54249 val_acc=0.7868 time=11.1s
2025-10-13 01:54:18,974 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.56870 val_loss=0.52702 val_acc=0.7908 time=11.1s
2025-10-13 01:54:20,054 - INFO - _models.training_function_executor - Model: 13,800 parameters, 59.3KB storage
2025-10-13 01:54:20,054 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0435686590874325, 0.8044380123147107, 0.7240273671881235, 0.6645041045126149, 0.6216343053371121, 0.5927681097376793, 0.5686994696418681], 'val_losses': [0.7962627633701975, 0.7658350563650161, 0.6789800109544499, 0.6485146179998676, 0.5818631396161789, 0.5424887607846178, 0.5270169989646295], 'val_acc': [0.6937346867343367, 0.6932096604830241, 0.7443997199859993, 0.7432621631081554, 0.7833391669583479, 0.7867518375918796, 0.7907770388519426], 'quantization': {'bits': 16, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 30192}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0033103996767633384, 'batch_size': 32, 'epochs': 7, 'weight_decay': 1.357496208874004e-06, 'dropout': 0.20225254735056641, 'grad_clip': 4.159824096647204, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 12}, 'model_parameter_count': 13800, 'model_storage_size_kb': 59.29687500000001, 'model_size_validation': 'PASS'}
2025-10-13 01:54:20,054 - INFO - _models.training_function_executor - BO Objective: base=0.7908, size_penalty=0.0000, final=0.7908
2025-10-13 01:54:20,054 - INFO - _models.training_function_executor - Model: 13,800 parameters, 59.3KB (PASS 256KB limit)
2025-10-13 01:54:20,054 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 81.652s
2025-10-13 01:54:20,157 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7908
2025-10-13 01:54:20,157 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-13 01:54:20,157 - INFO - bo.run_bo - Recorded observation #16: hparams={'lr': 0.0033103996767633384, 'batch_size': np.int64(32), 'epochs': np.int64(7), 'weight_decay': 1.357496208874004e-06, 'dropout': 0.20225254735056641, 'grad_clip': 4.159824096647204, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(12)}, value=0.7908
2025-10-13 01:54:20,157 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 16: {'lr': 0.0033103996767633384, 'batch_size': np.int64(32), 'epochs': np.int64(7), 'weight_decay': 1.357496208874004e-06, 'dropout': 0.20225254735056641, 'grad_clip': 4.159824096647204, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(12)} -> 0.7908
2025-10-13 01:54:20,157 - INFO - bo.run_bo - üîçBO Trial 17: Using RF surrogate + Expected Improvement
2025-10-13 01:54:20,157 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:54:20,157 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 17 (NaN monitoring active)
2025-10-13 01:54:20,157 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:54:20,158 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:54:20,158 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004585337356087599, 'batch_size': 128, 'epochs': 10, 'weight_decay': 5.07397903476409e-06, 'dropout': 0.27766146945753284, 'grad_clip': 0.03714350032345993, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 6, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 3}
2025-10-13 01:54:20,159 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004585337356087599, 'batch_size': 128, 'epochs': 10, 'weight_decay': 5.07397903476409e-06, 'dropout': 0.27766146945753284, 'grad_clip': 0.03714350032345993, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 6, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 3}
2025-10-13 01:54:32,900 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.31641 val_loss=1.07705 val_acc=0.5688 time=12.7s
2025-10-13 01:54:42,507 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.10495 val_loss=0.99467 val_acc=0.5872 time=9.6s
2025-10-13 01:54:52,101 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.01856 val_loss=1.02602 val_acc=0.5643 time=9.6s
2025-10-13 01:55:01,688 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.98719 val_loss=0.92920 val_acc=0.6292 time=9.6s
2025-10-13 01:55:11,276 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.96528 val_loss=0.86701 val_acc=0.6556 time=9.6s
2025-10-13 01:55:20,876 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.95045 val_loss=0.84071 val_acc=0.6542 time=9.6s
2025-10-13 01:55:30,477 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.92833 val_loss=0.83117 val_acc=0.6586 time=9.6s
2025-10-13 01:55:40,070 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.91514 val_loss=0.82051 val_acc=0.6734 time=9.6s
2025-10-13 01:55:49,661 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.91181 val_loss=0.81892 val_acc=0.6752 time=9.6s
2025-10-13 01:55:59,259 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.90142 val_loss=0.80641 val_acc=0.6692 time=9.6s
2025-10-13 01:56:00,352 - INFO - _models.training_function_executor - Model: 11,708 parameters, 50.3KB storage
2025-10-13 01:56:00,353 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3164097489199107, 1.104950403265908, 1.018560103615723, 0.987194654404971, 0.96527534833854, 0.9504457339566197, 0.9283306672099925, 0.9151351128085159, 0.911813269889893, 0.9014150026506338], 'val_losses': [1.0770469259289457, 0.9946659690314839, 1.0260211597759072, 0.9291992119070447, 0.8670074912606314, 0.8407123261579568, 0.8311684561810545, 0.8205135793672561, 0.8189154171551446, 0.8064089260361684], 'val_acc': [0.5687784389219461, 0.5871543577178859, 0.5643157157857893, 0.6292439621981099, 0.6555827791389569, 0.6541827091354567, 0.6586454322716135, 0.6734336716835841, 0.6751837591879594, 0.6692334616730836], 'quantization': {'bits': 32, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 49136}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004585337356087599, 'batch_size': 128, 'epochs': 10, 'weight_decay': 5.07397903476409e-06, 'dropout': 0.27766146945753284, 'grad_clip': 0.03714350032345993, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 6, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 3}, 'model_parameter_count': 11708, 'model_storage_size_kb': 50.307812500000004, 'model_size_validation': 'PASS'}
2025-10-13 01:56:00,353 - INFO - _models.training_function_executor - BO Objective: base=0.6692, size_penalty=0.0000, final=0.6692
2025-10-13 01:56:00,353 - INFO - _models.training_function_executor - Model: 11,708 parameters, 50.3KB (PASS 256KB limit)
2025-10-13 01:56:00,353 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 100.195s
2025-10-13 01:56:00,470 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6692
2025-10-13 01:56:00,470 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.096s
2025-10-13 01:56:00,470 - INFO - bo.run_bo - Recorded observation #17: hparams={'lr': 0.004585337356087599, 'batch_size': np.int64(128), 'epochs': np.int64(10), 'weight_decay': 5.07397903476409e-06, 'dropout': 0.27766146945753284, 'grad_clip': 0.03714350032345993, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(6), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(3)}, value=0.6692
2025-10-13 01:56:00,470 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 17: {'lr': 0.004585337356087599, 'batch_size': np.int64(128), 'epochs': np.int64(10), 'weight_decay': 5.07397903476409e-06, 'dropout': 0.27766146945753284, 'grad_clip': 0.03714350032345993, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(6), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(3)} -> 0.6692
2025-10-13 01:56:00,470 - INFO - bo.run_bo - üîçBO Trial 18: Using RF surrogate + Expected Improvement
2025-10-13 01:56:00,470 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:56:00,470 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 18 (NaN monitoring active)
2025-10-13 01:56:00,470 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:56:00,470 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:56:00,470 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.6435830484299135e-05, 'batch_size': 32, 'epochs': 17, 'weight_decay': 2.5208767325182086e-06, 'dropout': 0.1265785017410402, 'grad_clip': 3.496058656353121, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 10, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 24}
2025-10-13 01:56:00,471 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.6435830484299135e-05, 'batch_size': 32, 'epochs': 17, 'weight_decay': 2.5208767325182086e-06, 'dropout': 0.1265785017410402, 'grad_clip': 3.496058656353121, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 10, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 24}
2025-10-13 01:56:12,652 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.56289 val_loss=1.54533 val_acc=0.3252 time=12.2s
2025-10-13 01:56:21,113 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.53906 val_loss=1.52543 val_acc=0.3234 time=8.5s
2025-10-13 01:56:29,575 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.51613 val_loss=1.49463 val_acc=0.3610 time=8.5s
2025-10-13 01:56:38,042 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.45283 val_loss=1.39335 val_acc=0.4895 time=8.5s
2025-10-13 01:56:46,506 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.36146 val_loss=1.31570 val_acc=0.4956 time=8.5s
2025-10-13 01:56:54,980 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.30334 val_loss=1.26821 val_acc=0.5095 time=8.5s
2025-10-13 01:57:03,449 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.26374 val_loss=1.23119 val_acc=0.5334 time=8.5s
2025-10-13 01:57:11,904 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.23623 val_loss=1.20873 val_acc=0.5375 time=8.5s
2025-10-13 01:57:20,359 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.21779 val_loss=1.19485 val_acc=0.5357 time=8.5s
2025-10-13 01:57:28,817 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.20564 val_loss=1.18482 val_acc=0.5323 time=8.5s
2025-10-13 01:57:37,284 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.19952 val_loss=1.17888 val_acc=0.5291 time=8.5s
2025-10-13 01:57:45,747 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.19325 val_loss=1.17344 val_acc=0.5319 time=8.5s
2025-10-13 01:57:54,211 - INFO - _models.training_function_executor - Epoch 013: train_loss=1.19020 val_loss=1.16934 val_acc=0.5375 time=8.5s
2025-10-13 01:58:02,667 - INFO - _models.training_function_executor - Epoch 014: train_loss=1.18781 val_loss=1.16735 val_acc=0.5361 time=8.5s
2025-10-13 01:58:11,126 - INFO - _models.training_function_executor - Epoch 015: train_loss=1.18581 val_loss=1.16593 val_acc=0.5391 time=8.5s
2025-10-13 01:58:19,601 - INFO - _models.training_function_executor - Epoch 016: train_loss=1.18319 val_loss=1.16545 val_acc=0.5371 time=8.5s
2025-10-13 01:58:28,058 - INFO - _models.training_function_executor - Epoch 017: train_loss=1.18286 val_loss=1.16530 val_acc=0.5374 time=8.5s
2025-10-13 01:58:29,184 - INFO - _models.training_function_executor - Model: 9,187 parameters, 19.7KB storage
2025-10-13 01:58:29,184 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5628864007435106, 1.5390575688161505, 1.516134257662075, 1.452829857409981, 1.3614594801180755, 1.3033424343393532, 1.2637409589738748, 1.2362264135645786, 1.2177913639985225, 1.205638779098436, 1.1995159287864945, 1.1932481264876118, 1.1902032721322193, 1.1878112560391718, 1.1858138731404706, 1.1831934222984781, 1.1828605651772017], 'val_losses': [1.545329203128314, 1.5254328467022258, 1.4946327486946152, 1.3933511654897548, 1.3157029406441063, 1.2682051571841668, 1.231194826807223, 1.2087255003655086, 1.1948524457322662, 1.1848229440017142, 1.1788786827453919, 1.173441818263675, 1.16934318362227, 1.1673522197495068, 1.1659258422544465, 1.1654528426589938, 1.165302734505183], 'val_acc': [0.3251662583129156, 0.3234161708085404, 0.3610430521526076, 0.4894994749737487, 0.49562478123906195, 0.509537976898845, 0.5334266713335667, 0.5374518725936297, 0.5357017850892545, 0.5322891144557228, 0.5290514525726286, 0.5319390969548478, 0.5374518725936297, 0.5361393069653483, 0.5391144557227862, 0.5371018550927547, 0.5373643682184109], 'quantization': {'bits': 16, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 25574}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.6435830484299135e-05, 'batch_size': 32, 'epochs': 17, 'weight_decay': 2.5208767325182086e-06, 'dropout': 0.1265785017410402, 'grad_clip': 3.496058656353121, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 10, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 24}, 'model_parameter_count': 9187, 'model_storage_size_kb': 19.7376953125, 'model_size_validation': 'PASS'}
2025-10-13 01:58:29,184 - INFO - _models.training_function_executor - BO Objective: base=0.5374, size_penalty=0.0000, final=0.5374
2025-10-13 01:58:29,184 - INFO - _models.training_function_executor - Model: 9,187 parameters, 19.7KB (PASS 256KB limit)
2025-10-13 01:58:29,184 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 148.714s
2025-10-13 01:58:29,286 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5374
2025-10-13 01:58:29,286 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.099s
2025-10-13 01:58:29,286 - INFO - bo.run_bo - Recorded observation #18: hparams={'lr': 2.6435830484299135e-05, 'batch_size': np.int64(32), 'epochs': np.int64(17), 'weight_decay': 2.5208767325182086e-06, 'dropout': 0.1265785017410402, 'grad_clip': 3.496058656353121, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(10), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(24)}, value=0.5374
2025-10-13 01:58:29,286 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 18: {'lr': 2.6435830484299135e-05, 'batch_size': np.int64(32), 'epochs': np.int64(17), 'weight_decay': 2.5208767325182086e-06, 'dropout': 0.1265785017410402, 'grad_clip': 3.496058656353121, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(10), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(24)} -> 0.5374
2025-10-13 01:58:29,286 - INFO - bo.run_bo - üîçBO Trial 19: Using RF surrogate + Expected Improvement
2025-10-13 01:58:29,286 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 01:58:29,286 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 19 (NaN monitoring active)
2025-10-13 01:58:29,286 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 01:58:29,287 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 01:58:29,287 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0006669036008607155, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.1831327949651908e-07, 'dropout': 0.11673541455351852, 'grad_clip': 4.407158090317987, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 01:58:29,288 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006669036008607155, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.1831327949651908e-07, 'dropout': 0.11673541455351852, 'grad_clip': 4.407158090317987, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 01:58:43,402 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.17747 val_loss=0.96242 val_acc=0.5966 time=14.1s
2025-10-13 01:58:54,738 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.93144 val_loss=0.82723 val_acc=0.6619 time=11.3s
2025-10-13 01:59:06,076 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.85090 val_loss=0.84166 val_acc=0.6564 time=11.3s
2025-10-13 01:59:17,414 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.79485 val_loss=0.72464 val_acc=0.7037 time=11.3s
2025-10-13 01:59:28,754 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.76467 val_loss=0.71252 val_acc=0.7153 time=11.3s
2025-10-13 01:59:40,108 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.73012 val_loss=0.73358 val_acc=0.7080 time=11.4s
2025-10-13 01:59:51,456 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.70203 val_loss=0.64143 val_acc=0.7442 time=11.3s
2025-10-13 02:00:02,806 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.67411 val_loss=0.68063 val_acc=0.7249 time=11.3s
2025-10-13 02:00:14,164 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.65403 val_loss=0.60898 val_acc=0.7562 time=11.4s
2025-10-13 02:00:25,516 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.63835 val_loss=0.61177 val_acc=0.7541 time=11.4s
2025-10-13 02:00:36,869 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.62415 val_loss=0.59839 val_acc=0.7601 time=11.4s
2025-10-13 02:00:48,225 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.61041 val_loss=0.58704 val_acc=0.7638 time=11.4s
2025-10-13 02:00:59,584 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.60084 val_loss=0.57927 val_acc=0.7662 time=11.4s
2025-10-13 02:01:10,938 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.59664 val_loss=0.59403 val_acc=0.7628 time=11.4s
2025-10-13 02:01:22,293 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.59090 val_loss=0.57509 val_acc=0.7672 time=11.4s
2025-10-13 02:01:33,635 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.59119 val_loss=0.57432 val_acc=0.7675 time=11.3s
2025-10-13 02:01:35,388 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 02:01:35,388 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1774689599605637, 0.9314350405480422, 0.8509036601111319, 0.7948475704979221, 0.7646706014777715, 0.7301203293695206, 0.7020325936092795, 0.6741050574635141, 0.6540272984422918, 0.638354935385691, 0.624153196498736, 0.6104111036596742, 0.6008362686629891, 0.5966352030535782, 0.5908998498914122, 0.5911891665915989], 'val_losses': [0.9624226014848601, 0.8272317311627739, 0.8416634681636235, 0.7246378654569106, 0.7125243454451823, 0.733575916108778, 0.6414343855119812, 0.6806348814678893, 0.6089829860615655, 0.6117676811323409, 0.5983923775022331, 0.5870424725394338, 0.5792725576484875, 0.5940301375223033, 0.5750894777667159, 0.5743205598654929], 'val_acc': [0.5966048302415121, 0.6618830941547077, 0.6563703185159258, 0.7037101855092754, 0.7152607630381519, 0.7079978998949947, 0.7442247112355618, 0.7248862443122156, 0.756212810640532, 0.7541127056352818, 0.7600630031501575, 0.7638256912845642, 0.7661883094154708, 0.7627756387819391, 0.7672383619180959, 0.7675008750437522], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 34774}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0006669036008607155, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.1831327949651908e-07, 'dropout': 0.11673541455351852, 'grad_clip': 4.407158090317987, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 02:01:35,388 - INFO - _models.training_function_executor - BO Objective: base=0.7675, size_penalty=0.0000, final=0.7675
2025-10-13 02:01:35,388 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 02:01:35,388 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 186.102s
2025-10-13 02:01:35,495 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7675
2025-10-13 02:01:35,495 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.099s
2025-10-13 02:01:35,495 - INFO - bo.run_bo - Recorded observation #19: hparams={'lr': 0.0006669036008607155, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 1.1831327949651908e-07, 'dropout': 0.11673541455351852, 'grad_clip': 4.407158090317987, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)}, value=0.7675
2025-10-13 02:01:35,495 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 19: {'lr': 0.0006669036008607155, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 1.1831327949651908e-07, 'dropout': 0.11673541455351852, 'grad_clip': 4.407158090317987, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)} -> 0.7675
2025-10-13 02:01:35,495 - INFO - bo.run_bo - üîçBO Trial 20: Using RF surrogate + Expected Improvement
2025-10-13 02:01:35,495 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:01:35,495 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 20 (NaN monitoring active)
2025-10-13 02:01:35,495 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:01:35,496 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:01:35,496 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00046328341563656893, 'batch_size': 32, 'epochs': 20, 'weight_decay': 0.00011317070922801906, 'dropout': 0.09089597260901834, 'grad_clip': 3.4060167269322674, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 8, 'gcn_hidden_dim': 12, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 7}
2025-10-13 02:01:35,497 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00046328341563656893, 'batch_size': 32, 'epochs': 20, 'weight_decay': 0.00011317070922801906, 'dropout': 0.09089597260901834, 'grad_clip': 3.4060167269322674, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 8, 'gcn_hidden_dim': 12, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 7}
2025-10-13 02:01:49,472 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.27455 val_loss=1.04357 val_acc=0.5744 time=14.0s
2025-10-13 02:02:00,680 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.97508 val_loss=0.90378 val_acc=0.6314 time=11.2s
2025-10-13 02:02:11,899 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.89379 val_loss=0.84578 val_acc=0.6583 time=11.2s
2025-10-13 02:02:23,110 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.84846 val_loss=0.81349 val_acc=0.6726 time=11.2s
2025-10-13 02:02:34,322 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.81905 val_loss=0.78328 val_acc=0.6848 time=11.2s
2025-10-13 02:02:45,542 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.79456 val_loss=0.76773 val_acc=0.6909 time=11.2s
2025-10-13 02:02:56,762 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.77838 val_loss=0.78903 val_acc=0.6833 time=11.2s
2025-10-13 02:03:07,985 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.76078 val_loss=0.73880 val_acc=0.7101 time=11.2s
2025-10-13 02:03:19,185 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.74522 val_loss=0.70945 val_acc=0.7237 time=11.2s
2025-10-13 02:03:30,394 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.72669 val_loss=0.69976 val_acc=0.7235 time=11.2s
2025-10-13 02:03:41,596 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.71026 val_loss=0.70212 val_acc=0.7215 time=11.2s
2025-10-13 02:03:52,804 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.69462 val_loss=0.69094 val_acc=0.7272 time=11.2s
2025-10-13 02:04:04,016 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.68667 val_loss=0.67065 val_acc=0.7373 time=11.2s
2025-10-13 02:04:15,234 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.67828 val_loss=0.65354 val_acc=0.7461 time=11.2s
2025-10-13 02:04:26,450 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.66700 val_loss=0.64645 val_acc=0.7484 time=11.2s
2025-10-13 02:04:37,666 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.66309 val_loss=0.65052 val_acc=0.7459 time=11.2s
2025-10-13 02:04:48,887 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.66011 val_loss=0.64537 val_acc=0.7508 time=11.2s
2025-10-13 02:05:00,101 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.65630 val_loss=0.64202 val_acc=0.7514 time=11.2s
2025-10-13 02:05:11,315 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.65320 val_loss=0.64088 val_acc=0.7512 time=11.2s
2025-10-13 02:05:22,529 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.65158 val_loss=0.64076 val_acc=0.7511 time=11.2s
2025-10-13 02:05:23,630 - INFO - _models.training_function_executor - Model: 13,751 parameters, 59.1KB storage
2025-10-13 02:05:23,630 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2745488806541958, 0.9750827556729609, 0.8937865450409771, 0.8484603492455087, 0.8190482478271968, 0.7945550389752173, 0.7783758927776883, 0.7607782965445794, 0.7452166778539752, 0.7266891328738543, 0.7102611263732123, 0.6946191865746107, 0.6866658965440576, 0.6782799361467278, 0.6670038132847795, 0.6630903949343662, 0.660107206705779, 0.656297404302097, 0.6532011917724783, 0.651582261754117], 'val_losses': [1.0435674787193567, 0.9037772802610601, 0.8457784086079876, 0.813494297166283, 0.7832801345974405, 0.7677349129631088, 0.7890315326227356, 0.7387967650649178, 0.7094480414093479, 0.6997635997505842, 0.7021226801778788, 0.6909436726428263, 0.670646659782144, 0.6535394979516318, 0.6464524794426004, 0.6505226482867694, 0.6453699924372526, 0.642024726708285, 0.640881217585855, 0.6407557318667076], 'val_acc': [0.5743787189359468, 0.6314315715785789, 0.6582954147707385, 0.6725586279313965, 0.6848092404620231, 0.6909345467273363, 0.6833216660833041, 0.710098004900245, 0.723661183059153, 0.7234861743087154, 0.7214735736786839, 0.7272488624431221, 0.7373118655932797, 0.7460623031151558, 0.7484249212460623, 0.7458872943647182, 0.7507875393769688, 0.7514000700035002, 0.7512250612530627, 0.7510500525026251], 'quantization': {'bits': 32, 'weights': True, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 64220}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00046328341563656893, 'batch_size': 32, 'epochs': 20, 'weight_decay': 0.00011317070922801906, 'dropout': 0.09089597260901834, 'grad_clip': 3.4060167269322674, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 8, 'gcn_hidden_dim': 12, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 7}, 'model_parameter_count': 13751, 'model_storage_size_kb': 59.086328125, 'model_size_validation': 'PASS'}
2025-10-13 02:05:23,630 - INFO - _models.training_function_executor - BO Objective: base=0.7511, size_penalty=0.0000, final=0.7511
2025-10-13 02:05:23,630 - INFO - _models.training_function_executor - Model: 13,751 parameters, 59.1KB (PASS 256KB limit)
2025-10-13 02:05:23,630 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 228.135s
2025-10-13 02:05:23,739 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7511
2025-10-13 02:05:23,739 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-10-13 02:05:23,739 - INFO - bo.run_bo - Recorded observation #20: hparams={'lr': 0.00046328341563656893, 'batch_size': np.int64(32), 'epochs': np.int64(20), 'weight_decay': 0.00011317070922801906, 'dropout': 0.09089597260901834, 'grad_clip': 3.4060167269322674, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(8), 'gcn_hidden_dim': np.int64(12), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(7)}, value=0.7511
2025-10-13 02:05:23,739 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 20: {'lr': 0.00046328341563656893, 'batch_size': np.int64(32), 'epochs': np.int64(20), 'weight_decay': 0.00011317070922801906, 'dropout': 0.09089597260901834, 'grad_clip': 3.4060167269322674, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(8), 'gcn_hidden_dim': np.int64(12), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(7)} -> 0.7511
2025-10-13 02:05:23,739 - INFO - bo.run_bo - üîçBO Trial 21: Using RF surrogate + Expected Improvement
2025-10-13 02:05:23,739 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:05:23,739 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 21 (NaN monitoring active)
2025-10-13 02:05:23,740 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:05:23,740 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:05:23,740 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00023579504074053382, 'batch_size': 128, 'epochs': 49, 'weight_decay': 9.580036505402894e-07, 'dropout': 0.08250997370059283, 'grad_clip': 4.228201388609788, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 5}
2025-10-13 02:05:23,741 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00023579504074053382, 'batch_size': 128, 'epochs': 49, 'weight_decay': 9.580036505402894e-07, 'dropout': 0.08250997370059283, 'grad_clip': 4.228201388609788, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 5}
2025-10-13 02:05:37,024 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.48549 val_loss=1.32022 val_acc=0.5010 time=13.3s
2025-10-13 02:05:47,191 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.20003 val_loss=1.09938 val_acc=0.5718 time=10.2s
2025-10-13 02:05:57,367 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.08735 val_loss=1.03107 val_acc=0.5959 time=10.2s
2025-10-13 02:06:07,530 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.02816 val_loss=0.98592 val_acc=0.6026 time=10.2s
2025-10-13 02:06:17,700 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.99762 val_loss=0.96360 val_acc=0.6109 time=10.2s
2025-10-13 02:06:27,878 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.96330 val_loss=0.91900 val_acc=0.6297 time=10.2s
2025-10-13 02:06:38,053 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.93446 val_loss=0.89383 val_acc=0.6405 time=10.2s
2025-10-13 02:06:48,233 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.91249 val_loss=0.87140 val_acc=0.6492 time=10.2s
2025-10-13 02:06:58,403 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.88919 val_loss=0.85751 val_acc=0.6624 time=10.2s
2025-10-13 02:07:08,574 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.86846 val_loss=0.83327 val_acc=0.6747 time=10.2s
2025-10-13 02:07:18,744 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.85391 val_loss=0.81974 val_acc=0.6761 time=10.2s
2025-10-13 02:07:28,916 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.84096 val_loss=0.83294 val_acc=0.6754 time=10.2s
2025-10-13 02:07:39,092 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.83059 val_loss=0.80869 val_acc=0.6873 time=10.2s
2025-10-13 02:07:49,268 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.82200 val_loss=0.81461 val_acc=0.6830 time=10.2s
2025-10-13 02:07:59,442 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.81434 val_loss=0.78514 val_acc=0.6927 time=10.2s
2025-10-13 02:08:09,611 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.80249 val_loss=0.81025 val_acc=0.6811 time=10.2s
2025-10-13 02:08:19,780 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.79986 val_loss=0.77895 val_acc=0.6948 time=10.2s
2025-10-13 02:08:29,955 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.79293 val_loss=0.79454 val_acc=0.6893 time=10.2s
2025-10-13 02:08:40,132 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.78558 val_loss=0.76475 val_acc=0.7001 time=10.2s
2025-10-13 02:08:50,303 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.78015 val_loss=0.75337 val_acc=0.7029 time=10.2s
2025-10-13 02:09:00,476 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.76956 val_loss=0.75402 val_acc=0.7042 time=10.2s
2025-10-13 02:09:10,648 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.76981 val_loss=0.74804 val_acc=0.7057 time=10.2s
2025-10-13 02:09:20,813 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.76149 val_loss=0.73822 val_acc=0.7077 time=10.2s
2025-10-13 02:09:30,979 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.75835 val_loss=0.73452 val_acc=0.7108 time=10.2s
2025-10-13 02:09:41,151 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.75709 val_loss=0.73113 val_acc=0.7147 time=10.2s
2025-10-13 02:09:51,322 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.75131 val_loss=0.72596 val_acc=0.7125 time=10.2s
2025-10-13 02:10:01,498 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.74632 val_loss=0.72590 val_acc=0.7149 time=10.2s
2025-10-13 02:10:11,663 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.74315 val_loss=0.72138 val_acc=0.7165 time=10.2s
2025-10-13 02:10:21,838 - INFO - _models.training_function_executor - Epoch 029: train_loss=0.74003 val_loss=0.72035 val_acc=0.7173 time=10.2s
2025-10-13 02:10:32,008 - INFO - _models.training_function_executor - Epoch 030: train_loss=0.73817 val_loss=0.71861 val_acc=0.7164 time=10.2s
2025-10-13 02:10:42,181 - INFO - _models.training_function_executor - Epoch 031: train_loss=0.73374 val_loss=0.72713 val_acc=0.7145 time=10.2s
2025-10-13 02:10:52,352 - INFO - _models.training_function_executor - Epoch 032: train_loss=0.73058 val_loss=0.71204 val_acc=0.7202 time=10.2s
2025-10-13 02:11:02,530 - INFO - _models.training_function_executor - Epoch 033: train_loss=0.72987 val_loss=0.70862 val_acc=0.7211 time=10.2s
2025-10-13 02:11:12,708 - INFO - _models.training_function_executor - Epoch 034: train_loss=0.72782 val_loss=0.70642 val_acc=0.7216 time=10.2s
2025-10-13 02:11:22,880 - INFO - _models.training_function_executor - Epoch 035: train_loss=0.72572 val_loss=0.70787 val_acc=0.7209 time=10.2s
2025-10-13 02:11:33,052 - INFO - _models.training_function_executor - Epoch 036: train_loss=0.72252 val_loss=0.70755 val_acc=0.7226 time=10.2s
2025-10-13 02:11:43,219 - INFO - _models.training_function_executor - Epoch 037: train_loss=0.72230 val_loss=0.70342 val_acc=0.7212 time=10.2s
2025-10-13 02:11:53,384 - INFO - _models.training_function_executor - Epoch 038: train_loss=0.72113 val_loss=0.70348 val_acc=0.7214 time=10.2s
2025-10-13 02:12:03,557 - INFO - _models.training_function_executor - Epoch 039: train_loss=0.72128 val_loss=0.70365 val_acc=0.7214 time=10.2s
2025-10-13 02:12:13,736 - INFO - _models.training_function_executor - Epoch 040: train_loss=0.71777 val_loss=0.70342 val_acc=0.7219 time=10.2s
2025-10-13 02:12:23,911 - INFO - _models.training_function_executor - Epoch 041: train_loss=0.71770 val_loss=0.70108 val_acc=0.7245 time=10.2s
2025-10-13 02:12:34,084 - INFO - _models.training_function_executor - Epoch 042: train_loss=0.71705 val_loss=0.70148 val_acc=0.7236 time=10.2s
2025-10-13 02:12:44,257 - INFO - _models.training_function_executor - Epoch 043: train_loss=0.71722 val_loss=0.69949 val_acc=0.7237 time=10.2s
2025-10-13 02:12:54,439 - INFO - _models.training_function_executor - Epoch 044: train_loss=0.71454 val_loss=0.69930 val_acc=0.7235 time=10.2s
2025-10-13 02:13:04,612 - INFO - _models.training_function_executor - Epoch 045: train_loss=0.71667 val_loss=0.69919 val_acc=0.7246 time=10.2s
2025-10-13 02:13:14,787 - INFO - _models.training_function_executor - Epoch 046: train_loss=0.71605 val_loss=0.69952 val_acc=0.7241 time=10.2s
2025-10-13 02:13:24,954 - INFO - _models.training_function_executor - Epoch 047: train_loss=0.71493 val_loss=0.69908 val_acc=0.7245 time=10.2s
2025-10-13 02:13:35,126 - INFO - _models.training_function_executor - Epoch 048: train_loss=0.71158 val_loss=0.69939 val_acc=0.7243 time=10.2s
2025-10-13 02:13:45,301 - INFO - _models.training_function_executor - Epoch 049: train_loss=0.71654 val_loss=0.69923 val_acc=0.7244 time=10.2s
2025-10-13 02:13:46,427 - INFO - _models.training_function_executor - Model: 13,138 parameters, 14.1KB storage
2025-10-13 02:13:46,427 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4854911512789462, 1.2000256573190045, 1.0873525889553222, 1.0281564043583802, 0.9976242436868643, 0.963295625188278, 0.9344572511051433, 0.9124881188937072, 0.8891901303347399, 0.8684594135498057, 0.8539106469493167, 0.8409612986813653, 0.8305881104354137, 0.822003326092227, 0.8143444698842456, 0.8024939439244149, 0.7998626011002927, 0.7929325120032648, 0.7855752124041997, 0.7801531478580078, 0.7695564515197615, 0.7698075372854813, 0.7614869651654237, 0.7583463923848506, 0.7570886927590655, 0.7513101571166185, 0.7463150293751116, 0.7431486109398777, 0.7400320068413785, 0.7381693343829141, 0.7337444809023884, 0.7305763502887883, 0.7298695721491092, 0.7278235592873813, 0.7257155911944152, 0.7225178915969467, 0.7223018429936084, 0.7211347359813174, 0.7212772017222916, 0.7177661940648417, 0.7177041658038312, 0.7170503997368791, 0.7172220466768654, 0.7145390205338238, 0.7166680681317429, 0.7160504985239525, 0.7149332579842055, 0.7115782862323792, 0.716537331049368], 'val_losses': [1.3202163490499697, 1.0993839814022868, 1.0310747654320354, 0.9859162528989697, 0.9635950854745077, 0.918997959194377, 0.8938260326278681, 0.8714042098780049, 0.8575120653186513, 0.8332657155391425, 0.8197396993011205, 0.8329417509218175, 0.80869164168939, 0.8146073498173447, 0.7851397257857612, 0.8102483890421289, 0.7789495232057688, 0.794536545784022, 0.7647466731104853, 0.7533688136735995, 0.7540209481129497, 0.7480435262913048, 0.7382184708915392, 0.7345165277345221, 0.7311261669922676, 0.7259552811132597, 0.7259045986391508, 0.7213801895149279, 0.7203520791155915, 0.7186142387071355, 0.7271260582027963, 0.712039586981986, 0.7086225068356384, 0.706422719665036, 0.7078653609665032, 0.7075545560825443, 0.7034153603238996, 0.7034810830297527, 0.7036502950042121, 0.7034186767789088, 0.7010780374070001, 0.7014789627613953, 0.6994947739986009, 0.6992993182888972, 0.6991898096396366, 0.6995224851305184, 0.6990782337502496, 0.6993931419664969, 0.6992252461134991], 'val_acc': [0.5009625481274064, 0.5718410920546028, 0.595904795239762, 0.6025551277563879, 0.6108680434021702, 0.6296814840742037, 0.64053202660133, 0.6491949597479874, 0.6624081204060203, 0.6746587329366468, 0.6761463073153657, 0.6754462723136156, 0.6873468673433671, 0.6829716485824291, 0.6926846342317116, 0.6811340567028351, 0.6947847392369618, 0.6892719635981799, 0.7001225061253062, 0.7029226461323066, 0.704235211760588, 0.705722786139307, 0.7077353867693384, 0.7107980399019951, 0.7147357367868393, 0.7124606230311515, 0.7149107455372768, 0.7164858242912145, 0.7172733636681834, 0.7163983199159958, 0.714473223661183, 0.7202485124256213, 0.7211235561778089, 0.7216485824291214, 0.7209485474273714, 0.7226111305565278, 0.7212110605530276, 0.7213860693034652, 0.7213860693034652, 0.7219110955547777, 0.7245362268113406, 0.7235736786839342, 0.723661183059153, 0.7234861743087154, 0.7246237311865593, 0.7240987049352468, 0.7245362268113406, 0.7242737136856843, 0.724361218060903], 'quantization': {'bits': 8, 'weights': True, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 73348}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00023579504074053382, 'batch_size': 128, 'epochs': 49, 'weight_decay': 9.580036505402894e-07, 'dropout': 0.08250997370059283, 'grad_clip': 4.228201388609788, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 12, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 5}, 'model_parameter_count': 13138, 'model_storage_size_kb': 14.113085937500001, 'model_size_validation': 'PASS'}
2025-10-13 02:13:46,427 - INFO - _models.training_function_executor - BO Objective: base=0.7244, size_penalty=0.0000, final=0.7244
2025-10-13 02:13:46,427 - INFO - _models.training_function_executor - Model: 13,138 parameters, 14.1KB (PASS 256KB limit)
2025-10-13 02:13:46,427 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 502.687s
2025-10-13 02:13:46,552 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7244
2025-10-13 02:13:46,552 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-13 02:13:46,552 - INFO - bo.run_bo - Recorded observation #21: hparams={'lr': 0.00023579504074053382, 'batch_size': np.int64(128), 'epochs': np.int64(49), 'weight_decay': 9.580036505402894e-07, 'dropout': 0.08250997370059283, 'grad_clip': 4.228201388609788, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(5)}, value=0.7244
2025-10-13 02:13:46,552 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 21: {'lr': 0.00023579504074053382, 'batch_size': np.int64(128), 'epochs': np.int64(49), 'weight_decay': 9.580036505402894e-07, 'dropout': 0.08250997370059283, 'grad_clip': 4.228201388609788, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(5)} -> 0.7244
2025-10-13 02:13:46,552 - INFO - bo.run_bo - üîçBO Trial 22: Using RF surrogate + Expected Improvement
2025-10-13 02:13:46,552 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:13:46,552 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 22 (NaN monitoring active)
2025-10-13 02:13:46,552 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:13:46,552 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:13:46,552 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00444480347615418, 'batch_size': 256, 'epochs': 10, 'weight_decay': 0.0008086426829003728, 'dropout': 0.1591311542518186, 'grad_clip': 4.360696299314595, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 8, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 2}
2025-10-13 02:13:46,554 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00444480347615418, 'batch_size': 256, 'epochs': 10, 'weight_decay': 0.0008086426829003728, 'dropout': 0.1591311542518186, 'grad_clip': 4.360696299314595, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 8, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 2}
2025-10-13 02:13:59,552 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.34315 val_loss=1.15060 val_acc=0.5488 time=13.0s
2025-10-13 02:14:09,026 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.13041 val_loss=1.07401 val_acc=0.5711 time=9.5s
2025-10-13 02:14:18,495 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.08726 val_loss=1.04361 val_acc=0.5762 time=9.5s
2025-10-13 02:14:27,967 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.05719 val_loss=1.00340 val_acc=0.6008 time=9.5s
2025-10-13 02:14:37,438 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.03220 val_loss=0.98773 val_acc=0.6124 time=9.5s
2025-10-13 02:14:46,906 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.01163 val_loss=0.95867 val_acc=0.6255 time=9.5s
2025-10-13 02:14:56,379 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.99304 val_loss=0.95347 val_acc=0.6282 time=9.5s
2025-10-13 02:15:05,873 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.98075 val_loss=0.94317 val_acc=0.6362 time=9.5s
2025-10-13 02:15:15,360 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.97405 val_loss=0.93614 val_acc=0.6382 time=9.5s
2025-10-13 02:15:24,841 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.97104 val_loss=0.93419 val_acc=0.6406 time=9.5s
2025-10-13 02:15:25,949 - INFO - _models.training_function_executor - Model: 12,306 parameters, 13.2KB storage
2025-10-13 02:15:25,950 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3431541963519857, 1.1304133091099746, 1.0872570480297277, 1.057191926030208, 1.0321977597080747, 1.0116341825043942, 0.9930423499405446, 0.9807543594769593, 0.974050499110277, 0.9710449493970327], 'val_losses': [1.1505988991506708, 1.0740063066953205, 1.043607017753589, 1.0034012982467275, 0.9877311778435726, 0.958671848925002, 0.9534744316562723, 0.9431735668350943, 0.9361442233200127, 0.9341905533662408], 'val_acc': [0.5488274413720686, 0.5711410570528527, 0.5762163108155408, 0.6008050402520126, 0.6123556177808891, 0.6254812740637031, 0.6281939096954847, 0.636156807840392, 0.6381694084704235, 0.6406195309765488], 'quantization': {'bits': 8, 'weights': True, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 58500}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00444480347615418, 'batch_size': 256, 'epochs': 10, 'weight_decay': 0.0008086426829003728, 'dropout': 0.1591311542518186, 'grad_clip': 4.360696299314595, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 8, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 2}, 'model_parameter_count': 12306, 'model_storage_size_kb': 13.2193359375, 'model_size_validation': 'PASS'}
2025-10-13 02:15:25,950 - INFO - _models.training_function_executor - BO Objective: base=0.6406, size_penalty=0.0000, final=0.6406
2025-10-13 02:15:25,950 - INFO - _models.training_function_executor - Model: 12,306 parameters, 13.2KB (PASS 256KB limit)
2025-10-13 02:15:25,950 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 99.397s
2025-10-13 02:15:26,082 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6406
2025-10-13 02:15:26,083 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-10-13 02:15:26,083 - INFO - bo.run_bo - Recorded observation #22: hparams={'lr': 0.00444480347615418, 'batch_size': np.int64(256), 'epochs': np.int64(10), 'weight_decay': 0.0008086426829003728, 'dropout': 0.1591311542518186, 'grad_clip': 4.360696299314595, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(8), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(2)}, value=0.6406
2025-10-13 02:15:26,083 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 22: {'lr': 0.00444480347615418, 'batch_size': np.int64(256), 'epochs': np.int64(10), 'weight_decay': 0.0008086426829003728, 'dropout': 0.1591311542518186, 'grad_clip': 4.360696299314595, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(8), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(2)} -> 0.6406
2025-10-13 02:15:26,083 - INFO - bo.run_bo - üîçBO Trial 23: Using RF surrogate + Expected Improvement
2025-10-13 02:15:26,083 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:15:26,083 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 23 (NaN monitoring active)
2025-10-13 02:15:26,083 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:15:26,083 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:15:26,083 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0002568276718299283, 'batch_size': 128, 'epochs': 21, 'weight_decay': 1.69926724612138e-06, 'dropout': 0.11869479888333487, 'grad_clip': 3.735258410080114, 'use_amp': False, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 27}
2025-10-13 02:15:26,084 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0002568276718299283, 'batch_size': 128, 'epochs': 21, 'weight_decay': 1.69926724612138e-06, 'dropout': 0.11869479888333487, 'grad_clip': 3.735258410080114, 'use_amp': False, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 27}
2025-10-13 02:15:38,036 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.53812 val_loss=1.45740 val_acc=0.3677 time=11.9s
2025-10-13 02:15:46,946 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.30156 val_loss=1.14174 val_acc=0.5589 time=8.9s
2025-10-13 02:15:55,864 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.15398 val_loss=1.07987 val_acc=0.5787 time=8.9s
2025-10-13 02:16:04,777 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.09801 val_loss=1.04023 val_acc=0.5820 time=8.9s
2025-10-13 02:16:13,694 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.05582 val_loss=1.01398 val_acc=0.5897 time=8.9s
2025-10-13 02:16:22,613 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.02163 val_loss=1.01292 val_acc=0.5935 time=8.9s
2025-10-13 02:16:31,526 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.99855 val_loss=0.96856 val_acc=0.6067 time=8.9s
2025-10-13 02:16:40,436 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.98345 val_loss=0.96088 val_acc=0.6124 time=8.9s
2025-10-13 02:16:49,354 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.96926 val_loss=0.94131 val_acc=0.6247 time=8.9s
2025-10-13 02:16:58,266 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.95923 val_loss=0.92988 val_acc=0.6319 time=8.9s
2025-10-13 02:17:07,187 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.94737 val_loss=0.92335 val_acc=0.6335 time=8.9s
2025-10-13 02:17:16,101 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.94017 val_loss=0.91368 val_acc=0.6350 time=8.9s
2025-10-13 02:17:25,012 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.93438 val_loss=0.90639 val_acc=0.6390 time=8.9s
2025-10-13 02:17:33,933 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.92757 val_loss=0.90808 val_acc=0.6376 time=8.9s
2025-10-13 02:17:42,844 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.92490 val_loss=0.89954 val_acc=0.6420 time=8.9s
2025-10-13 02:17:51,762 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.91827 val_loss=0.89595 val_acc=0.6439 time=8.9s
2025-10-13 02:18:00,681 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.91566 val_loss=0.89319 val_acc=0.6459 time=8.9s
2025-10-13 02:18:09,593 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.90966 val_loss=0.89186 val_acc=0.6464 time=8.9s
2025-10-13 02:18:18,499 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.91248 val_loss=0.89156 val_acc=0.6465 time=8.9s
2025-10-13 02:18:27,416 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.91148 val_loss=0.89016 val_acc=0.6466 time=8.9s
2025-10-13 02:18:36,344 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.91163 val_loss=0.89010 val_acc=0.6468 time=8.9s
2025-10-13 02:18:37,447 - INFO - _models.training_function_executor - Model: 10,507 parameters, 22.6KB storage
2025-10-13 02:18:37,448 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5381219962864103, 1.3015607805322174, 1.153983023269301, 1.0980144656117579, 1.0558151438555852, 1.021627192569021, 0.998551519195809, 0.9834525364447525, 0.9692585093598705, 0.9592262556138137, 0.9473680092982157, 0.9401679627954606, 0.9343766197275356, 0.9275655262446044, 0.9249024432899654, 0.9182651560749672, 0.9156610624832752, 0.909659251784544, 0.9124754939122679, 0.9114801875769696, 0.9116293333358685], 'val_losses': [1.4573956414207028, 1.141742041363848, 1.0798704804012231, 1.040231772807665, 1.0139820490594422, 1.0129192805932792, 0.9685630882207772, 0.9608754895139834, 0.9413053187449412, 0.9298768488518792, 0.9233472742398469, 0.9136772346863765, 0.9063890862181172, 0.908075116295726, 0.899539934512323, 0.8959462272357307, 0.8931922437971941, 0.8918584977199366, 0.8915647073020708, 0.8901603585738255, 0.890103143476547], 'val_acc': [0.36769338466923346, 0.5588904445222261, 0.5786664333216661, 0.581991599579979, 0.58969198459923, 0.5935421771088555, 0.6066678333916696, 0.6124431221561079, 0.6246937346867344, 0.6318690934546727, 0.6335316765838291, 0.6350192509625481, 0.6390444522226111, 0.6375568778438921, 0.642019600980049, 0.6439446972348617, 0.6458697934896744, 0.646394819740987, 0.6464823241162058, 0.6465698284914245, 0.6468323416170808], 'quantization': {'bits': 16, 'weights': True, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 22166}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0002568276718299283, 'batch_size': 128, 'epochs': 21, 'weight_decay': 1.69926724612138e-06, 'dropout': 0.11869479888333487, 'grad_clip': 3.735258410080114, 'use_amp': False, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 27}, 'model_parameter_count': 10507, 'model_storage_size_kb': 22.5736328125, 'model_size_validation': 'PASS'}
2025-10-13 02:18:37,448 - INFO - _models.training_function_executor - BO Objective: base=0.6468, size_penalty=0.0000, final=0.6468
2025-10-13 02:18:37,448 - INFO - _models.training_function_executor - Model: 10,507 parameters, 22.6KB (PASS 256KB limit)
2025-10-13 02:18:37,448 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 191.365s
2025-10-13 02:18:37,569 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6468
2025-10-13 02:18:37,569 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-13 02:18:37,570 - INFO - bo.run_bo - Recorded observation #23: hparams={'lr': 0.0002568276718299283, 'batch_size': np.int64(128), 'epochs': np.int64(21), 'weight_decay': 1.69926724612138e-06, 'dropout': 0.11869479888333487, 'grad_clip': 3.735258410080114, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(14), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(27)}, value=0.6468
2025-10-13 02:18:37,570 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 23: {'lr': 0.0002568276718299283, 'batch_size': np.int64(128), 'epochs': np.int64(21), 'weight_decay': 1.69926724612138e-06, 'dropout': 0.11869479888333487, 'grad_clip': 3.735258410080114, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(14), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(27)} -> 0.6468
2025-10-13 02:18:37,570 - INFO - bo.run_bo - üîçBO Trial 24: Using RF surrogate + Expected Improvement
2025-10-13 02:18:37,570 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:18:37,570 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 24 (NaN monitoring active)
2025-10-13 02:18:37,570 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:18:37,570 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:18:37,570 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00015495531497724196, 'batch_size': 128, 'epochs': 44, 'weight_decay': 0.0003972216266515658, 'dropout': 0.10355829032294259, 'grad_clip': 1.3146049112860057, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 6, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 02:18:37,571 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00015495531497724196, 'batch_size': 128, 'epochs': 44, 'weight_decay': 0.0003972216266515658, 'dropout': 0.10355829032294259, 'grad_clip': 1.3146049112860057, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 6, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 02:18:49,848 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.56027 val_loss=1.53273 val_acc=0.3342 time=12.3s
2025-10-13 02:18:59,344 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.49989 val_loss=1.42221 val_acc=0.4475 time=9.5s
2025-10-13 02:19:08,840 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.36182 val_loss=1.28790 val_acc=0.4731 time=9.5s
2025-10-13 02:19:18,342 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.27198 val_loss=1.22113 val_acc=0.5114 time=9.5s
2025-10-13 02:19:27,839 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.24296 val_loss=1.20300 val_acc=0.5122 time=9.5s
2025-10-13 02:19:37,346 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.21806 val_loss=1.18685 val_acc=0.5159 time=9.5s
2025-10-13 02:19:46,842 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.20919 val_loss=1.17639 val_acc=0.5226 time=9.5s
2025-10-13 02:19:56,338 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.19578 val_loss=1.16786 val_acc=0.5249 time=9.5s
2025-10-13 02:20:05,840 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.18003 val_loss=1.15203 val_acc=0.5298 time=9.5s
2025-10-13 02:20:15,339 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.16595 val_loss=1.13810 val_acc=0.5388 time=9.5s
2025-10-13 02:20:24,843 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.14926 val_loss=1.12771 val_acc=0.5420 time=9.5s
2025-10-13 02:20:34,348 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.13535 val_loss=1.11859 val_acc=0.5525 time=9.5s
2025-10-13 02:20:43,840 - INFO - _models.training_function_executor - Epoch 013: train_loss=1.12779 val_loss=1.11001 val_acc=0.5611 time=9.5s
2025-10-13 02:20:53,332 - INFO - _models.training_function_executor - Epoch 014: train_loss=1.11738 val_loss=1.10312 val_acc=0.5642 time=9.5s
2025-10-13 02:21:02,827 - INFO - _models.training_function_executor - Epoch 015: train_loss=1.11020 val_loss=1.09668 val_acc=0.5722 time=9.5s
2025-10-13 02:21:12,318 - INFO - _models.training_function_executor - Epoch 016: train_loss=1.10158 val_loss=1.08563 val_acc=0.5806 time=9.5s
2025-10-13 02:21:21,815 - INFO - _models.training_function_executor - Epoch 017: train_loss=1.09624 val_loss=1.07974 val_acc=0.5835 time=9.5s
2025-10-13 02:21:31,316 - INFO - _models.training_function_executor - Epoch 018: train_loss=1.08780 val_loss=1.07321 val_acc=0.5909 time=9.5s
2025-10-13 02:21:40,821 - INFO - _models.training_function_executor - Epoch 019: train_loss=1.08280 val_loss=1.06643 val_acc=0.5947 time=9.5s
2025-10-13 02:21:50,330 - INFO - _models.training_function_executor - Epoch 020: train_loss=1.07648 val_loss=1.06089 val_acc=0.6014 time=9.5s
2025-10-13 02:21:59,836 - INFO - _models.training_function_executor - Epoch 021: train_loss=1.06848 val_loss=1.05720 val_acc=0.6002 time=9.5s
2025-10-13 02:22:09,353 - INFO - _models.training_function_executor - Epoch 022: train_loss=1.06311 val_loss=1.04938 val_acc=0.6089 time=9.5s
2025-10-13 02:22:18,860 - INFO - _models.training_function_executor - Epoch 023: train_loss=1.05708 val_loss=1.04406 val_acc=0.6106 time=9.5s
2025-10-13 02:22:28,358 - INFO - _models.training_function_executor - Epoch 024: train_loss=1.05140 val_loss=1.03875 val_acc=0.6114 time=9.5s
2025-10-13 02:22:37,864 - INFO - _models.training_function_executor - Epoch 025: train_loss=1.04640 val_loss=1.03358 val_acc=0.6131 time=9.5s
2025-10-13 02:22:47,372 - INFO - _models.training_function_executor - Epoch 026: train_loss=1.04248 val_loss=1.02849 val_acc=0.6176 time=9.5s
2025-10-13 02:22:56,877 - INFO - _models.training_function_executor - Epoch 027: train_loss=1.03705 val_loss=1.02378 val_acc=0.6193 time=9.5s
2025-10-13 02:23:06,385 - INFO - _models.training_function_executor - Epoch 028: train_loss=1.03246 val_loss=1.02103 val_acc=0.6177 time=9.5s
2025-10-13 02:23:15,899 - INFO - _models.training_function_executor - Epoch 029: train_loss=1.02737 val_loss=1.01638 val_acc=0.6203 time=9.5s
2025-10-13 02:23:25,408 - INFO - _models.training_function_executor - Epoch 030: train_loss=1.02573 val_loss=1.01295 val_acc=0.6229 time=9.5s
2025-10-13 02:23:34,916 - INFO - _models.training_function_executor - Epoch 031: train_loss=1.02217 val_loss=1.01008 val_acc=0.6257 time=9.5s
2025-10-13 02:23:44,428 - INFO - _models.training_function_executor - Epoch 032: train_loss=1.02123 val_loss=1.00789 val_acc=0.6248 time=9.5s
2025-10-13 02:23:53,939 - INFO - _models.training_function_executor - Epoch 033: train_loss=1.01737 val_loss=1.00559 val_acc=0.6257 time=9.5s
2025-10-13 02:24:03,444 - INFO - _models.training_function_executor - Epoch 034: train_loss=1.01414 val_loss=1.00561 val_acc=0.6222 time=9.5s
2025-10-13 02:24:12,946 - INFO - _models.training_function_executor - Epoch 035: train_loss=1.01369 val_loss=1.00190 val_acc=0.6275 time=9.5s
2025-10-13 02:24:22,459 - INFO - _models.training_function_executor - Epoch 036: train_loss=1.01007 val_loss=1.00049 val_acc=0.6284 time=9.5s
2025-10-13 02:24:31,964 - INFO - _models.training_function_executor - Epoch 037: train_loss=1.01150 val_loss=0.99927 val_acc=0.6301 time=9.5s
2025-10-13 02:24:41,472 - INFO - _models.training_function_executor - Epoch 038: train_loss=1.01070 val_loss=0.99861 val_acc=0.6305 time=9.5s
2025-10-13 02:24:50,981 - INFO - _models.training_function_executor - Epoch 039: train_loss=1.01040 val_loss=0.99832 val_acc=0.6282 time=9.5s
2025-10-13 02:25:00,494 - INFO - _models.training_function_executor - Epoch 040: train_loss=1.00860 val_loss=0.99762 val_acc=0.6309 time=9.5s
2025-10-13 02:25:10,002 - INFO - _models.training_function_executor - Epoch 041: train_loss=1.00788 val_loss=0.99733 val_acc=0.6306 time=9.5s
2025-10-13 02:25:19,512 - INFO - _models.training_function_executor - Epoch 042: train_loss=1.00816 val_loss=0.99753 val_acc=0.6281 time=9.5s
2025-10-13 02:25:29,025 - INFO - _models.training_function_executor - Epoch 043: train_loss=1.00791 val_loss=0.99721 val_acc=0.6292 time=9.5s
2025-10-13 02:25:38,544 - INFO - _models.training_function_executor - Epoch 044: train_loss=1.00739 val_loss=0.99717 val_acc=0.6294 time=9.5s
2025-10-13 02:25:42,774 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 02:25:42,775 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5602708395269311, 1.4998939487122138, 1.361818346728551, 1.2719848449721718, 1.2429578948529985, 1.2180640926968604, 1.209193685733233, 1.195781741394294, 1.1800322298991919, 1.165950848499628, 1.1492572456212322, 1.1353548709270542, 1.1277924970517343, 1.117381670777932, 1.110195856558346, 1.1015773584344482, 1.0962358943056634, 1.087803512947268, 1.0828010555451928, 1.076479288010402, 1.0684804014280036, 1.063108159125498, 1.0570771355790862, 1.0513968029179104, 1.046402222800597, 1.0424801985784389, 1.0370464687127103, 1.0324647464158028, 1.0273715669056482, 1.0257261255048646, 1.0221747556765846, 1.021234237275676, 1.0173723615046184, 1.0141358735221726, 1.0136937579784855, 1.0100655777703893, 1.0115034544764177, 1.0107045314259406, 1.0104020667902271, 1.0085972658937779, 1.0078825167020717, 1.0081584922992812, 1.0079056824426114, 1.0073934449238255], 'val_losses': [1.5327287011935988, 1.4222051663377044, 1.2878952051819643, 1.2211267775407737, 1.2030025210295434, 1.186854834735164, 1.1763888530727864, 1.1678586967099076, 1.1520337072919205, 1.1380974441964935, 1.1277135150767224, 1.1185884532454466, 1.1100127225911904, 1.1031178095810557, 1.0966808507189618, 1.0856292531504512, 1.0797350326951334, 1.0732116438018136, 1.066430399582275, 1.060889141643886, 1.057201975536046, 1.049379914216658, 1.0440591105556922, 1.0387454453906606, 1.0335781163254691, 1.028488791902707, 1.023777327839628, 1.021026676211025, 1.0163772246367788, 1.0129517116119364, 1.0100806585591617, 1.0078880947955555, 1.0055924877654767, 1.005611593380315, 1.0019014050670967, 1.0004920284773946, 0.9992673526412755, 0.9986136384389181, 0.9983216785742012, 0.9976245577534805, 0.9973278487942876, 0.9975266255487877, 0.9972128423310929, 0.9971693450852963], 'val_acc': [0.334179208960448, 0.4474973748687434, 0.4731361568078404, 0.5113755687784389, 0.5121631081554078, 0.5159257962898145, 0.5225761288064403, 0.5248512425621281, 0.5298389919495975, 0.5387644382219111, 0.5420021001050053, 0.5525026251312566, 0.5610780539026952, 0.5642282114105706, 0.5721911095554778, 0.5805915295764789, 0.583479173958698, 0.5909170458522927, 0.5946797339866994, 0.601417570878544, 0.6001925096254813, 0.6089429471473574, 0.6106055302765139, 0.6113930696534827, 0.6130556527826392, 0.6176058802940148, 0.6192684634231712, 0.6176933846692335, 0.6203185159257963, 0.6229436471823592, 0.6257437871893594, 0.6247812390619532, 0.6257437871893594, 0.6221561078053903, 0.6274938746937346, 0.6283689184459222, 0.6301190059502975, 0.6304690234511725, 0.6281939096954847, 0.6309065453272663, 0.63064403220161, 0.628106405320266, 0.6291564578228911, 0.6294189709485474], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 14307}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00015495531497724196, 'batch_size': 128, 'epochs': 44, 'weight_decay': 0.0003972216266515658, 'dropout': 0.10355829032294259, 'grad_clip': 1.3146049112860057, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 6, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 10}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 02:25:42,775 - INFO - _models.training_function_executor - BO Objective: base=0.6294, size_penalty=0.0000, final=0.6294
2025-10-13 02:25:42,775 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 02:25:42,775 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 425.205s
2025-10-13 02:25:42,901 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6294
2025-10-13 02:25:42,901 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.105s
2025-10-13 02:25:42,901 - INFO - bo.run_bo - Recorded observation #24: hparams={'lr': 0.00015495531497724196, 'batch_size': np.int64(128), 'epochs': np.int64(44), 'weight_decay': 0.0003972216266515658, 'dropout': 0.10355829032294259, 'grad_clip': 1.3146049112860057, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(6), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)}, value=0.6294
2025-10-13 02:25:42,901 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 24: {'lr': 0.00015495531497724196, 'batch_size': np.int64(128), 'epochs': np.int64(44), 'weight_decay': 0.0003972216266515658, 'dropout': 0.10355829032294259, 'grad_clip': 1.3146049112860057, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(6), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)} -> 0.6294
2025-10-13 02:25:42,901 - INFO - bo.run_bo - üîçBO Trial 25: Using RF surrogate + Expected Improvement
2025-10-13 02:25:42,901 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:25:42,901 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 25 (NaN monitoring active)
2025-10-13 02:25:42,901 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:25:42,902 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:25:42,902 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0002018245285140836, 'batch_size': 32, 'epochs': 29, 'weight_decay': 1.2418533982131923e-07, 'dropout': 0.2942673155791552, 'grad_clip': 4.111700600429591, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 12, 'gcn_hidden_dim': 14, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 9}
2025-10-13 02:25:42,903 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0002018245285140836, 'batch_size': 32, 'epochs': 29, 'weight_decay': 1.2418533982131923e-07, 'dropout': 0.2942673155791552, 'grad_clip': 4.111700600429591, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 12, 'gcn_hidden_dim': 14, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 9}
2025-10-13 02:25:56,395 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.49402 val_loss=1.36073 val_acc=0.4236 time=13.5s
2025-10-13 02:26:07,060 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.28392 val_loss=1.18777 val_acc=0.5166 time=10.7s
2025-10-13 02:26:17,752 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.12370 val_loss=1.04064 val_acc=0.5805 time=10.7s
2025-10-13 02:26:28,447 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.04218 val_loss=0.98664 val_acc=0.5957 time=10.7s
2025-10-13 02:26:39,143 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.99599 val_loss=0.93811 val_acc=0.6117 time=10.7s
2025-10-13 02:26:49,843 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.96624 val_loss=0.89377 val_acc=0.6420 time=10.7s
2025-10-13 02:27:00,537 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.93494 val_loss=0.88294 val_acc=0.6492 time=10.7s
2025-10-13 02:27:11,227 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.91132 val_loss=0.83948 val_acc=0.6683 time=10.7s
2025-10-13 02:27:21,927 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.88896 val_loss=0.82064 val_acc=0.6740 time=10.7s
2025-10-13 02:27:32,615 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.87302 val_loss=0.79890 val_acc=0.6832 time=10.7s
2025-10-13 02:27:43,311 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.85855 val_loss=0.77746 val_acc=0.6952 time=10.7s
2025-10-13 02:27:54,004 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.84026 val_loss=0.76621 val_acc=0.7030 time=10.7s
2025-10-13 02:28:04,694 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.83230 val_loss=0.76221 val_acc=0.7066 time=10.7s
2025-10-13 02:28:15,384 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.82934 val_loss=0.76021 val_acc=0.7055 time=10.7s
2025-10-13 02:28:26,076 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.81753 val_loss=0.75670 val_acc=0.7079 time=10.7s
2025-10-13 02:28:36,763 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.81137 val_loss=0.74392 val_acc=0.7131 time=10.7s
2025-10-13 02:28:47,459 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.80880 val_loss=0.74158 val_acc=0.7118 time=10.7s
2025-10-13 02:28:58,155 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.79783 val_loss=0.73783 val_acc=0.7141 time=10.7s
2025-10-13 02:29:08,842 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.79846 val_loss=0.73211 val_acc=0.7149 time=10.7s
2025-10-13 02:29:19,538 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.79158 val_loss=0.72498 val_acc=0.7204 time=10.7s
2025-10-13 02:29:30,234 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.79164 val_loss=0.72199 val_acc=0.7215 time=10.7s
2025-10-13 02:29:40,934 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.78769 val_loss=0.72189 val_acc=0.7202 time=10.7s
2025-10-13 02:29:51,627 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.78531 val_loss=0.72229 val_acc=0.7198 time=10.7s
2025-10-13 02:30:02,323 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.78587 val_loss=0.71681 val_acc=0.7213 time=10.7s
2025-10-13 02:30:13,012 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.78722 val_loss=0.72198 val_acc=0.7211 time=10.7s
2025-10-13 02:30:23,704 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.77860 val_loss=0.71506 val_acc=0.7223 time=10.7s
2025-10-13 02:30:34,400 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.78391 val_loss=0.71483 val_acc=0.7224 time=10.7s
2025-10-13 02:30:45,089 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.78242 val_loss=0.71463 val_acc=0.7217 time=10.7s
2025-10-13 02:30:55,776 - INFO - _models.training_function_executor - Epoch 029: train_loss=0.77928 val_loss=0.71459 val_acc=0.7227 time=10.7s
2025-10-13 02:30:56,894 - INFO - _models.training_function_executor - Model: 13,095 parameters, 56.3KB storage
2025-10-13 02:30:56,894 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4940165206190168, 1.283915001694289, 1.1237025330606607, 1.042183001808324, 0.9959861320509625, 0.9662373968050285, 0.9349429998357771, 0.9113188135402788, 0.8889574555821631, 0.873017017141188, 0.8585466056342387, 0.8402569854138487, 0.8323011567928927, 0.8293383858359941, 0.817525496840018, 0.8113687103095905, 0.8088018356981835, 0.797832493666047, 0.7984621260063524, 0.7915817572180107, 0.791643644509968, 0.7876911345669804, 0.7853058515456243, 0.7858674074955073, 0.7872236342667115, 0.7786049359863689, 0.7839059694104566, 0.7824176617506546, 0.7792829708448856], 'val_losses': [1.3607338285546309, 1.1877666513611898, 1.0406378751707361, 0.9866374330917855, 0.9381112344706438, 0.8937654961728533, 0.882940027631994, 0.8394839731512848, 0.8206352817874544, 0.798897379797407, 0.7774626055004132, 0.7662109236304978, 0.762210205108668, 0.7602057562118065, 0.7566976833059773, 0.7439155608238271, 0.7415823547373629, 0.7378336473657904, 0.7321074648173822, 0.7249795729186846, 0.7219859014076497, 0.7218886661829963, 0.7222909728338304, 0.7168125389420907, 0.7219782964224409, 0.715058921202939, 0.7148327966190361, 0.7146297241784411, 0.7145948953089448], 'val_acc': [0.4236086804340217, 0.5166258312915646, 0.5805040252012601, 0.5957297864893245, 0.6117430871543578, 0.642019600980049, 0.6491949597479874, 0.6682709135456772, 0.6740462023101155, 0.6832341617080854, 0.6952222611130556, 0.7030101505075254, 0.7065978298914946, 0.7055477773888694, 0.707910395519776, 0.7130731536576829, 0.7117605880294015, 0.714123206160308, 0.7149107455372768, 0.7204235211760588, 0.7214735736786839, 0.7202485124256213, 0.7198109905495275, 0.7212985649282464, 0.7211235561778089, 0.7222611130556528, 0.7224361218060903, 0.7217360868043402, 0.7226986349317466], 'quantization': {'bits': 32, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 73116}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0002018245285140836, 'batch_size': 32, 'epochs': 29, 'weight_decay': 1.2418533982131923e-07, 'dropout': 0.2942673155791552, 'grad_clip': 4.111700600429591, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 12, 'gcn_hidden_dim': 14, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 9}, 'model_parameter_count': 13095, 'model_storage_size_kb': 56.26757812500001, 'model_size_validation': 'PASS'}
2025-10-13 02:30:56,894 - INFO - _models.training_function_executor - BO Objective: base=0.7227, size_penalty=0.0000, final=0.7227
2025-10-13 02:30:56,894 - INFO - _models.training_function_executor - Model: 13,095 parameters, 56.3KB (PASS 256KB limit)
2025-10-13 02:30:56,894 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 313.993s
2025-10-13 02:30:57,008 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7227
2025-10-13 02:30:57,009 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.106s
2025-10-13 02:30:57,009 - INFO - bo.run_bo - Recorded observation #25: hparams={'lr': 0.0002018245285140836, 'batch_size': np.int64(32), 'epochs': np.int64(29), 'weight_decay': 1.2418533982131923e-07, 'dropout': 0.2942673155791552, 'grad_clip': 4.111700600429591, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(9)}, value=0.7227
2025-10-13 02:30:57,009 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 25: {'lr': 0.0002018245285140836, 'batch_size': np.int64(32), 'epochs': np.int64(29), 'weight_decay': 1.2418533982131923e-07, 'dropout': 0.2942673155791552, 'grad_clip': 4.111700600429591, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(9)} -> 0.7227
2025-10-13 02:30:57,009 - INFO - bo.run_bo - üîçBO Trial 26: Using RF surrogate + Expected Improvement
2025-10-13 02:30:57,009 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:30:57,009 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 26 (NaN monitoring active)
2025-10-13 02:30:57,009 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:30:57,009 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:30:57,009 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00018109046364948235, 'batch_size': 32, 'epochs': 9, 'weight_decay': 1.1853291666510355e-06, 'dropout': 0.11324421673620202, 'grad_clip': 0.8505167401525289, 'use_amp': False, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 5, 'kernel_size_dec': 5, 'partitions': 5, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 3}
2025-10-13 02:30:57,011 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00018109046364948235, 'batch_size': 32, 'epochs': 9, 'weight_decay': 1.1853291666510355e-06, 'dropout': 0.11324421673620202, 'grad_clip': 0.8505167401525289, 'use_amp': False, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 5, 'kernel_size_dec': 5, 'partitions': 5, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 3}
2025-10-13 02:31:06,697 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.49616 val_loss=1.35994 val_acc=0.4763 time=9.7s
2025-10-13 02:31:13,520 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.26507 val_loss=1.16442 val_acc=0.5353 time=6.8s
2025-10-13 02:31:20,336 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.15230 val_loss=1.11320 val_acc=0.5415 time=6.8s
2025-10-13 02:31:27,169 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.11642 val_loss=1.08148 val_acc=0.5564 time=6.8s
2025-10-13 02:31:33,998 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.08942 val_loss=1.05562 val_acc=0.5806 time=6.8s
2025-10-13 02:31:40,820 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.07123 val_loss=1.04735 val_acc=0.5813 time=6.8s
2025-10-13 02:31:47,636 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.05730 val_loss=1.03547 val_acc=0.5845 time=6.8s
2025-10-13 02:31:54,467 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.05125 val_loss=1.02947 val_acc=0.5847 time=6.8s
2025-10-13 02:32:01,292 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.04628 val_loss=1.02711 val_acc=0.5860 time=6.8s
2025-10-13 02:32:02,409 - INFO - _models.training_function_executor - Model: 4,856 parameters, 20.9KB storage
2025-10-13 02:32:02,409 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4961569743595384, 1.2650681778731194, 1.152302967613295, 1.1164186226140798, 1.0894203769355375, 1.0712294149198522, 1.0572976680915174, 1.051254769555747, 1.0462796863326251], 'val_losses': [1.3599410198099513, 1.1644198053317927, 1.113196122383462, 1.0814807949092866, 1.0556181955471045, 1.0473490069285532, 1.0354657204450741, 1.0294673058758843, 1.0271094728275576], 'val_acc': [0.4762863143157158, 0.5352642632131607, 0.5414770738536927, 0.5564403220161008, 0.5805915295764789, 0.581291564578229, 0.5845292264613231, 0.5847042352117606, 0.586016800840042], 'quantization': {'bits': 8, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 23024}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00018109046364948235, 'batch_size': 32, 'epochs': 9, 'weight_decay': 1.1853291666510355e-06, 'dropout': 0.11324421673620202, 'grad_clip': 0.8505167401525289, 'use_amp': False, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 5, 'kernel_size_dec': 5, 'partitions': 5, 'gcn_hidden_dim': 11, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 3}, 'model_parameter_count': 4856, 'model_storage_size_kb': 20.865625, 'model_size_validation': 'PASS'}
2025-10-13 02:32:02,409 - INFO - _models.training_function_executor - BO Objective: base=0.5860, size_penalty=0.0000, final=0.5860
2025-10-13 02:32:02,409 - INFO - _models.training_function_executor - Model: 4,856 parameters, 20.9KB (PASS 256KB limit)
2025-10-13 02:32:02,409 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 65.400s
2025-10-13 02:32:02,519 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5860
2025-10-13 02:32:02,520 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.106s
2025-10-13 02:32:02,520 - INFO - bo.run_bo - Recorded observation #26: hparams={'lr': 0.00018109046364948235, 'batch_size': np.int64(32), 'epochs': np.int64(9), 'weight_decay': 1.1853291666510355e-06, 'dropout': 0.11324421673620202, 'grad_clip': 0.8505167401525289, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(9), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(3)}, value=0.5860
2025-10-13 02:32:02,520 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 26: {'lr': 0.00018109046364948235, 'batch_size': np.int64(32), 'epochs': np.int64(9), 'weight_decay': 1.1853291666510355e-06, 'dropout': 0.11324421673620202, 'grad_clip': 0.8505167401525289, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(9), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(3)} -> 0.5860
2025-10-13 02:32:02,520 - INFO - bo.run_bo - üîçBO Trial 27: Using RF surrogate + Expected Improvement
2025-10-13 02:32:02,520 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:32:02,520 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 27 (NaN monitoring active)
2025-10-13 02:32:02,520 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:32:02,520 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:32:02,520 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0001787109610618706, 'batch_size': 32, 'epochs': 22, 'weight_decay': 0.00025846341172909766, 'dropout': 0.002354650740598874, 'grad_clip': 4.629084095851643, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 19}
2025-10-13 02:32:02,521 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0001787109610618706, 'batch_size': 32, 'epochs': 22, 'weight_decay': 0.00025846341172909766, 'dropout': 0.002354650740598874, 'grad_clip': 4.629084095851643, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 19}
2025-10-13 02:32:24,635 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.48479 val_loss=1.38379 val_acc=0.4465 time=22.1s
2025-10-13 02:32:34,219 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.30297 val_loss=1.24071 val_acc=0.5393 time=9.6s
2025-10-13 02:32:43,858 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.15386 val_loss=1.12308 val_acc=0.5746 time=9.6s
2025-10-13 02:32:53,495 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.05458 val_loss=1.06756 val_acc=0.5986 time=9.6s
2025-10-13 02:33:03,138 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.00490 val_loss=1.03133 val_acc=0.6060 time=9.6s
2025-10-13 02:33:12,775 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.97984 val_loss=1.01405 val_acc=0.6154 time=9.6s
2025-10-13 02:33:22,404 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.96231 val_loss=0.99326 val_acc=0.6284 time=9.6s
2025-10-13 02:33:32,039 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.94572 val_loss=0.96446 val_acc=0.6324 time=9.6s
2025-10-13 02:33:41,660 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.93263 val_loss=0.95036 val_acc=0.6431 time=9.6s
2025-10-13 02:33:51,278 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.92486 val_loss=0.93450 val_acc=0.6511 time=9.6s
2025-10-13 02:34:00,898 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.91370 val_loss=0.93463 val_acc=0.6551 time=9.6s
2025-10-13 02:34:10,534 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.90590 val_loss=0.91114 val_acc=0.6624 time=9.6s
2025-10-13 02:34:20,164 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.89973 val_loss=0.90804 val_acc=0.6614 time=9.6s
2025-10-13 02:34:29,803 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.89116 val_loss=0.89652 val_acc=0.6654 time=9.6s
2025-10-13 02:34:39,442 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.88625 val_loss=0.89299 val_acc=0.6656 time=9.6s
2025-10-13 02:34:49,075 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.88133 val_loss=0.88682 val_acc=0.6670 time=9.6s
2025-10-13 02:34:58,700 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.87873 val_loss=0.88363 val_acc=0.6689 time=9.6s
2025-10-13 02:35:08,339 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.87555 val_loss=0.88200 val_acc=0.6704 time=9.6s
2025-10-13 02:35:17,969 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.87414 val_loss=0.88121 val_acc=0.6691 time=9.6s
2025-10-13 02:35:27,590 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.87276 val_loss=0.87944 val_acc=0.6692 time=9.6s
2025-10-13 02:35:37,221 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.87331 val_loss=0.87908 val_acc=0.6697 time=9.6s
2025-10-13 02:35:46,862 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.87170 val_loss=0.87900 val_acc=0.6699 time=9.6s
2025-10-13 02:35:48,013 - INFO - _models.training_function_executor - Model: 14,327 parameters, 61.6KB storage
2025-10-13 02:35:48,013 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4847865471023758, 1.3029737772122103, 1.153855193274648, 1.0545761213462839, 1.0049011060563176, 0.9798449513417339, 0.962312804805594, 0.9457170979142981, 0.9326255666571227, 0.924855669186505, 0.9136960891981328, 0.9059032895242078, 0.8997333629130483, 0.891164483538365, 0.8862450564495951, 0.8813328985822422, 0.8787341075716296, 0.8755472984437472, 0.8741418725967741, 0.8727567027530597, 0.8733108881932687, 0.8717026293465504], 'val_losses': [1.3837931386899565, 1.2407072773754158, 1.1230759080323383, 1.0675600823882079, 1.0313312397747554, 1.0140540445856503, 0.9932609586019719, 0.9644588223695337, 0.9503595611621001, 0.9344955287198317, 0.934628431055151, 0.9111435731933548, 0.9080425011848794, 0.89652281131701, 0.8929890412987217, 0.8868152864504244, 0.8836325221976326, 0.8820035006351558, 0.8812054403603473, 0.8794382210582297, 0.8790778147410713, 0.879001693371755], 'val_acc': [0.44653482674133704, 0.5392894644732237, 0.5746412320616031, 0.5986174308715436, 0.6059677983899195, 0.6154182709135457, 0.6283689184459222, 0.6323941197059852, 0.6430696534826741, 0.6511200560028001, 0.6551452572628631, 0.6624081204060203, 0.6614455722786139, 0.6653832691634581, 0.6655582779138957, 0.6670458522926146, 0.6688834441722086, 0.6703710185509275, 0.6690584529226461, 0.6692334616730836, 0.6696709835491774, 0.6699334966748337], 'quantization': {'bits': 32, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 71708}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0001787109610618706, 'batch_size': 32, 'epochs': 22, 'weight_decay': 0.00025846341172909766, 'dropout': 0.002354650740598874, 'grad_clip': 4.629084095851643, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 19}, 'model_parameter_count': 14327, 'model_storage_size_kb': 61.561328125, 'model_size_validation': 'PASS'}
2025-10-13 02:35:48,013 - INFO - _models.training_function_executor - BO Objective: base=0.6699, size_penalty=0.0000, final=0.6699
2025-10-13 02:35:48,013 - INFO - _models.training_function_executor - Model: 14,327 parameters, 61.6KB (PASS 256KB limit)
2025-10-13 02:35:48,013 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 225.493s
2025-10-13 02:35:48,124 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6699
2025-10-13 02:35:48,124 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-13 02:35:48,124 - INFO - bo.run_bo - Recorded observation #27: hparams={'lr': 0.0001787109610618706, 'batch_size': np.int64(32), 'epochs': np.int64(22), 'weight_decay': 0.00025846341172909766, 'dropout': 0.002354650740598874, 'grad_clip': 4.629084095851643, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(19)}, value=0.6699
2025-10-13 02:35:48,124 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 27: {'lr': 0.0001787109610618706, 'batch_size': np.int64(32), 'epochs': np.int64(22), 'weight_decay': 0.00025846341172909766, 'dropout': 0.002354650740598874, 'grad_clip': 4.629084095851643, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(19)} -> 0.6699
2025-10-13 02:35:48,124 - INFO - bo.run_bo - üîçBO Trial 28: Using RF surrogate + Expected Improvement
2025-10-13 02:35:48,124 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:35:48,125 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 28 (NaN monitoring active)
2025-10-13 02:35:48,125 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:35:48,125 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:35:48,125 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0032392282096682014, 'batch_size': 128, 'epochs': 9, 'weight_decay': 2.12900986423147e-06, 'dropout': 0.15515717603534498, 'grad_clip': 0.5767500102929564, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 23}
2025-10-13 02:35:48,126 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0032392282096682014, 'batch_size': 128, 'epochs': 9, 'weight_decay': 2.12900986423147e-06, 'dropout': 0.15515717603534498, 'grad_clip': 0.5767500102929564, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 23}
2025-10-13 02:36:00,565 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.15201 val_loss=0.88205 val_acc=0.6323 time=12.4s
2025-10-13 02:36:10,185 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.87544 val_loss=0.83618 val_acc=0.6779 time=9.6s
2025-10-13 02:36:19,820 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.79591 val_loss=0.73863 val_acc=0.7160 time=9.6s
2025-10-13 02:36:29,445 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.74172 val_loss=0.76004 val_acc=0.6959 time=9.6s
2025-10-13 02:36:39,082 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.71706 val_loss=0.66950 val_acc=0.7368 time=9.6s
2025-10-13 02:36:48,717 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.68632 val_loss=0.63885 val_acc=0.7523 time=9.6s
2025-10-13 02:36:58,349 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.65613 val_loss=0.62693 val_acc=0.7586 time=9.6s
2025-10-13 02:37:07,974 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.63933 val_loss=0.61218 val_acc=0.7643 time=9.6s
2025-10-13 02:37:17,607 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.62897 val_loss=0.60853 val_acc=0.7642 time=9.6s
2025-10-13 02:37:25,347 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 02:37:25,347 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1520066321793243, 0.8754441607111102, 0.7959101804286648, 0.7417241138180194, 0.7170580143606409, 0.6863235615957939, 0.6561264707193452, 0.6393337556437091, 0.6289725261507312], 'val_losses': [0.8820533517110503, 0.8361836747560711, 0.738627542283596, 0.7600448536297054, 0.6695037361287887, 0.6388461263729719, 0.6269256294837647, 0.6121778704922308, 0.6085333862962279], 'val_acc': [0.6323066153307665, 0.677896394819741, 0.715960798039902, 0.6959222961148057, 0.7367868393419671, 0.7522751137556878, 0.7585754287714386, 0.764263213160658, 0.7641757087854393], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 17571}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0032392282096682014, 'batch_size': 128, 'epochs': 9, 'weight_decay': 2.12900986423147e-06, 'dropout': 0.15515717603534498, 'grad_clip': 0.5767500102929564, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 23}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 02:37:25,347 - INFO - _models.training_function_executor - BO Objective: base=0.7642, size_penalty=0.0000, final=0.7642
2025-10-13 02:37:25,347 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 02:37:25,347 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 97.223s
2025-10-13 02:37:25,476 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7642
2025-10-13 02:37:25,476 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-13 02:37:25,476 - INFO - bo.run_bo - Recorded observation #28: hparams={'lr': 0.0032392282096682014, 'batch_size': np.int64(128), 'epochs': np.int64(9), 'weight_decay': 2.12900986423147e-06, 'dropout': 0.15515717603534498, 'grad_clip': 0.5767500102929564, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(23)}, value=0.7642
2025-10-13 02:37:25,476 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 28: {'lr': 0.0032392282096682014, 'batch_size': np.int64(128), 'epochs': np.int64(9), 'weight_decay': 2.12900986423147e-06, 'dropout': 0.15515717603534498, 'grad_clip': 0.5767500102929564, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(23)} -> 0.7642
2025-10-13 02:37:25,477 - INFO - bo.run_bo - üîçBO Trial 29: Using RF surrogate + Expected Improvement
2025-10-13 02:37:25,477 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:37:25,477 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 29 (NaN monitoring active)
2025-10-13 02:37:25,477 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:37:25,477 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:37:25,477 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00016720681827377926, 'batch_size': 32, 'epochs': 18, 'weight_decay': 5.681489033934742e-06, 'dropout': 0.4575440444088665, 'grad_clip': 1.6087203283480935, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 3, 'gcn_hidden_dim': 13, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 7}
2025-10-13 02:37:25,478 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00016720681827377926, 'batch_size': 32, 'epochs': 18, 'weight_decay': 5.681489033934742e-06, 'dropout': 0.4575440444088665, 'grad_clip': 1.6087203283480935, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 3, 'gcn_hidden_dim': 13, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 7}
2025-10-13 02:37:42,120 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.54497 val_loss=1.31044 val_acc=0.5158 time=16.6s
2025-10-13 02:37:51,234 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.28805 val_loss=1.13795 val_acc=0.5709 time=9.1s
2025-10-13 02:38:00,339 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.17202 val_loss=1.08330 val_acc=0.5864 time=9.1s
2025-10-13 02:38:09,451 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.10816 val_loss=1.04241 val_acc=0.5977 time=9.1s
2025-10-13 02:38:18,576 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.07621 val_loss=1.00965 val_acc=0.6032 time=9.1s
2025-10-13 02:38:27,690 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.04016 val_loss=0.98769 val_acc=0.6088 time=9.1s
2025-10-13 02:38:36,809 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.02498 val_loss=0.97417 val_acc=0.6125 time=9.1s
2025-10-13 02:38:45,917 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.00348 val_loss=0.95046 val_acc=0.6145 time=9.1s
2025-10-13 02:38:55,014 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.98782 val_loss=0.93689 val_acc=0.6225 time=9.1s
2025-10-13 02:39:04,129 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.97953 val_loss=0.91926 val_acc=0.6234 time=9.1s
2025-10-13 02:39:13,238 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.96579 val_loss=0.91037 val_acc=0.6270 time=9.1s
2025-10-13 02:39:22,352 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.95717 val_loss=0.90233 val_acc=0.6276 time=9.1s
2025-10-13 02:39:31,459 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.95699 val_loss=0.90345 val_acc=0.6270 time=9.1s
2025-10-13 02:39:40,568 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.95073 val_loss=0.89412 val_acc=0.6309 time=9.1s
2025-10-13 02:39:49,664 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.94397 val_loss=0.89048 val_acc=0.6319 time=9.1s
2025-10-13 02:39:58,775 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.94534 val_loss=0.88819 val_acc=0.6325 time=9.1s
2025-10-13 02:40:07,886 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.94406 val_loss=0.88910 val_acc=0.6325 time=9.1s
2025-10-13 02:40:16,998 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.94583 val_loss=0.88785 val_acc=0.6334 time=9.1s
2025-10-13 02:40:18,103 - INFO - _models.training_function_executor - Model: 12,987 parameters, 55.8KB storage
2025-10-13 02:40:18,104 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5449701623980048, 1.2880452497046353, 1.1720203249280086, 1.1081560674062507, 1.0762105446659604, 1.0401559556577855, 1.0249767651456112, 1.0034750706255748, 0.987817872601203, 0.9795318692140242, 0.9657938313893101, 0.9571698743812179, 0.956994568462926, 0.9507263891338926, 0.943971794970936, 0.9453409954639511, 0.9440562495786409, 0.9458270971492158], 'val_losses': [1.3104401037415132, 1.1379452897486755, 1.0833009889086602, 1.0424130562096992, 1.0096506043501905, 0.9876863116103116, 0.9741713269256737, 0.950457855375822, 0.9368875619202675, 0.9192564811245896, 0.9103726169468015, 0.902330726771076, 0.9034549217771558, 0.8941222902858095, 0.8904800337429934, 0.8881938496293578, 0.8891005788101447, 0.8878482612313446], 'val_acc': [0.515750787539377, 0.5708785439271964, 0.5863668183409171, 0.5976548827441373, 0.6031676583829192, 0.6087679383969199, 0.6125306265313266, 0.6144557227861394, 0.6225061253062654, 0.623381169058453, 0.6269688484424221, 0.6275813790689534, 0.6269688484424221, 0.6309065453272663, 0.6318690934546727, 0.632481624081204, 0.632481624081204, 0.6333566678333916], 'quantization': {'bits': 32, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 53244}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00016720681827377926, 'batch_size': 32, 'epochs': 18, 'weight_decay': 5.681489033934742e-06, 'dropout': 0.4575440444088665, 'grad_clip': 1.6087203283480935, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 3, 'gcn_hidden_dim': 13, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 7}, 'model_parameter_count': 12987, 'model_storage_size_kb': 55.803515625, 'model_size_validation': 'PASS'}
2025-10-13 02:40:18,104 - INFO - _models.training_function_executor - BO Objective: base=0.6334, size_penalty=0.0000, final=0.6334
2025-10-13 02:40:18,104 - INFO - _models.training_function_executor - Model: 12,987 parameters, 55.8KB (PASS 256KB limit)
2025-10-13 02:40:18,104 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 172.627s
2025-10-13 02:40:18,346 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6334
2025-10-13 02:40:18,346 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.239s
2025-10-13 02:40:18,346 - INFO - bo.run_bo - Recorded observation #29: hparams={'lr': 0.00016720681827377926, 'batch_size': np.int64(32), 'epochs': np.int64(18), 'weight_decay': 5.681489033934742e-06, 'dropout': 0.4575440444088665, 'grad_clip': 1.6087203283480935, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(13), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(7)}, value=0.6334
2025-10-13 02:40:18,346 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 29: {'lr': 0.00016720681827377926, 'batch_size': np.int64(32), 'epochs': np.int64(18), 'weight_decay': 5.681489033934742e-06, 'dropout': 0.4575440444088665, 'grad_clip': 1.6087203283480935, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(13), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(7)} -> 0.6334
2025-10-13 02:40:18,347 - INFO - bo.run_bo - üîçBO Trial 30: Using RF surrogate + Expected Improvement
2025-10-13 02:40:18,347 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:40:18,347 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 30 (NaN monitoring active)
2025-10-13 02:40:18,347 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:40:18,347 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:40:18,347 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003262292489420982, 'batch_size': 256, 'epochs': 23, 'weight_decay': 0.0008368254195321026, 'dropout': 0.14798270950582001, 'grad_clip': 0.27706225134639556, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 13, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 7}
2025-10-13 02:40:18,348 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003262292489420982, 'batch_size': 256, 'epochs': 23, 'weight_decay': 0.0008368254195321026, 'dropout': 0.14798270950582001, 'grad_clip': 0.27706225134639556, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 13, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 7}
2025-10-13 02:40:30,887 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.35095 val_loss=1.14402 val_acc=0.5588 time=12.5s
2025-10-13 02:40:40,691 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.10596 val_loss=1.06521 val_acc=0.5881 time=9.8s
2025-10-13 02:40:50,495 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.05355 val_loss=1.05794 val_acc=0.5914 time=9.8s
2025-10-13 02:41:00,308 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.02851 val_loss=1.03915 val_acc=0.6011 time=9.8s
2025-10-13 02:41:10,116 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.00405 val_loss=0.99250 val_acc=0.6231 time=9.8s
2025-10-13 02:41:19,923 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.98440 val_loss=0.98402 val_acc=0.6171 time=9.8s
2025-10-13 02:41:29,718 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.97051 val_loss=0.96736 val_acc=0.6400 time=9.8s
2025-10-13 02:41:39,526 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.95557 val_loss=0.95532 val_acc=0.6339 time=9.8s
2025-10-13 02:41:49,339 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.94588 val_loss=0.94849 val_acc=0.6375 time=9.8s
2025-10-13 02:41:59,169 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.94075 val_loss=0.93414 val_acc=0.6392 time=9.8s
2025-10-13 02:42:09,004 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.93260 val_loss=0.93251 val_acc=0.6434 time=9.8s
2025-10-13 02:42:18,842 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.92335 val_loss=0.92397 val_acc=0.6467 time=9.8s
2025-10-13 02:42:28,676 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.91713 val_loss=0.92037 val_acc=0.6488 time=9.8s
2025-10-13 02:42:38,509 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.91673 val_loss=0.92153 val_acc=0.6469 time=9.8s
2025-10-13 02:42:48,340 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.91042 val_loss=0.91278 val_acc=0.6537 time=9.8s
2025-10-13 02:42:58,174 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.90660 val_loss=0.90874 val_acc=0.6558 time=9.8s
2025-10-13 02:43:08,022 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.90301 val_loss=0.90409 val_acc=0.6517 time=9.8s
2025-10-13 02:43:17,857 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.89919 val_loss=0.90117 val_acc=0.6575 time=9.8s
2025-10-13 02:43:27,704 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.89801 val_loss=0.89966 val_acc=0.6558 time=9.8s
2025-10-13 02:43:37,538 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.89442 val_loss=0.89761 val_acc=0.6580 time=9.8s
2025-10-13 02:43:47,383 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.89444 val_loss=0.89658 val_acc=0.6585 time=9.8s
2025-10-13 02:43:57,216 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.89139 val_loss=0.89540 val_acc=0.6591 time=9.8s
2025-10-13 02:44:07,049 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.89314 val_loss=0.89558 val_acc=0.6590 time=9.8s
2025-10-13 02:44:12,520 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 02:44:12,521 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3509487084337661, 1.1059557728555431, 1.0535523894787002, 1.0285118941998708, 1.0040544529123077, 0.9843997605872563, 0.9705083986491977, 0.9555721169466066, 0.9458757170355733, 0.9407534153677594, 0.9326027452132065, 0.9233491724506308, 0.9171251070470212, 0.9167279359298776, 0.9104168676270193, 0.9066001995067977, 0.9030088229241136, 0.899191859555403, 0.898013119790201, 0.8944167327038007, 0.8944350140345944, 0.8913896284322035, 0.8931394376911648], 'val_losses': [1.1440227235327411, 1.0652096908243545, 1.057935808937492, 1.039151315406189, 0.9925014655574201, 0.9840171057359297, 0.9673558678458444, 0.9553189624177855, 0.9484944743921508, 0.9341363339604387, 0.9325133161107518, 0.923965878510834, 0.9203714541634522, 0.9215311883920383, 0.9127830237327524, 0.9087412893709538, 0.904092118086663, 0.9011678488095156, 0.899657965394889, 0.8976109576342112, 0.8965777103868363, 0.8953953768600315, 0.8955829812589958], 'val_acc': [0.5588029401470074, 0.5881169058452923, 0.5914420721036052, 0.6010675533776689, 0.6231186559327967, 0.6170808540427022, 0.6400070003500175, 0.6338816940847042, 0.6374693734686734, 0.6392194609730486, 0.6434196709835491, 0.646744837241862, 0.6488449422471123, 0.6469198459922996, 0.6537451872593629, 0.6557577878893944, 0.6517325866293314, 0.6575078753937696, 0.6558452922646132, 0.6580329016450822, 0.658470423521176, 0.6590829541477073, 0.6589954497724886], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 27826}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003262292489420982, 'batch_size': 256, 'epochs': 23, 'weight_decay': 0.0008368254195321026, 'dropout': 0.14798270950582001, 'grad_clip': 0.27706225134639556, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 13, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 7}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 02:44:12,521 - INFO - _models.training_function_executor - BO Objective: base=0.6590, size_penalty=0.0000, final=0.6590
2025-10-13 02:44:12,521 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 02:44:12,521 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 234.174s
2025-10-13 02:44:12,663 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6590
2025-10-13 02:44:12,663 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.109s
2025-10-13 02:44:12,663 - INFO - bo.run_bo - Recorded observation #30: hparams={'lr': 0.003262292489420982, 'batch_size': np.int64(256), 'epochs': np.int64(23), 'weight_decay': 0.0008368254195321026, 'dropout': 0.14798270950582001, 'grad_clip': 0.27706225134639556, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(13), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(7)}, value=0.6590
2025-10-13 02:44:12,663 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 30: {'lr': 0.003262292489420982, 'batch_size': np.int64(256), 'epochs': np.int64(23), 'weight_decay': 0.0008368254195321026, 'dropout': 0.14798270950582001, 'grad_clip': 0.27706225134639556, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(13), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(7)} -> 0.6590
2025-10-13 02:44:12,663 - INFO - bo.run_bo - üîçBO Trial 31: Using RF surrogate + Expected Improvement
2025-10-13 02:44:12,663 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:44:12,663 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 31 (NaN monitoring active)
2025-10-13 02:44:12,663 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:44:12,663 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:44:12,663 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00017265095788112568, 'batch_size': 256, 'epochs': 39, 'weight_decay': 6.143114585883614e-07, 'dropout': 0.47142322043068136, 'grad_clip': 4.529567093321831, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 8, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 18}
2025-10-13 02:44:12,665 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00017265095788112568, 'batch_size': 256, 'epochs': 39, 'weight_decay': 6.143114585883614e-07, 'dropout': 0.47142322043068136, 'grad_clip': 4.529567093321831, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 8, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 18}
2025-10-13 02:44:39,336 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.60509 val_loss=1.56531 val_acc=0.2321 time=26.7s
2025-10-13 02:44:47,314 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.55413 val_loss=1.50145 val_acc=0.3348 time=8.0s
2025-10-13 02:44:55,278 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.49619 val_loss=1.42621 val_acc=0.4276 time=8.0s
2025-10-13 02:45:03,271 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.43122 val_loss=1.34749 val_acc=0.5041 time=8.0s
2025-10-13 02:45:11,259 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.37512 val_loss=1.29307 val_acc=0.5289 time=8.0s
2025-10-13 02:45:19,243 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.32826 val_loss=1.24222 val_acc=0.5383 time=8.0s
2025-10-13 02:45:27,224 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.28495 val_loss=1.19139 val_acc=0.5476 time=8.0s
2025-10-13 02:45:35,216 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.24601 val_loss=1.15105 val_acc=0.5622 time=8.0s
2025-10-13 02:45:43,176 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.20753 val_loss=1.11316 val_acc=0.5664 time=8.0s
2025-10-13 02:45:51,153 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.18271 val_loss=1.08220 val_acc=0.5700 time=8.0s
2025-10-13 02:45:59,122 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.15631 val_loss=1.05419 val_acc=0.5778 time=8.0s
2025-10-13 02:46:07,115 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.13284 val_loss=1.03419 val_acc=0.5826 time=8.0s
2025-10-13 02:46:15,109 - INFO - _models.training_function_executor - Epoch 013: train_loss=1.12020 val_loss=1.01970 val_acc=0.5863 time=8.0s
2025-10-13 02:46:23,093 - INFO - _models.training_function_executor - Epoch 014: train_loss=1.10340 val_loss=1.00405 val_acc=0.5869 time=8.0s
2025-10-13 02:46:31,065 - INFO - _models.training_function_executor - Epoch 015: train_loss=1.08915 val_loss=1.00085 val_acc=0.5881 time=8.0s
2025-10-13 02:46:39,063 - INFO - _models.training_function_executor - Epoch 016: train_loss=1.08186 val_loss=0.98160 val_acc=0.5978 time=8.0s
2025-10-13 02:46:47,034 - INFO - _models.training_function_executor - Epoch 017: train_loss=1.07079 val_loss=0.97520 val_acc=0.5973 time=8.0s
2025-10-13 02:46:54,990 - INFO - _models.training_function_executor - Epoch 018: train_loss=1.06585 val_loss=0.96935 val_acc=0.6027 time=8.0s
2025-10-13 02:47:02,977 - INFO - _models.training_function_executor - Epoch 019: train_loss=1.05817 val_loss=0.96163 val_acc=0.6036 time=8.0s
2025-10-13 02:47:10,970 - INFO - _models.training_function_executor - Epoch 020: train_loss=1.05169 val_loss=0.95576 val_acc=0.6031 time=8.0s
2025-10-13 02:47:18,960 - INFO - _models.training_function_executor - Epoch 021: train_loss=1.04522 val_loss=0.94832 val_acc=0.6047 time=8.0s
2025-10-13 02:47:26,969 - INFO - _models.training_function_executor - Epoch 022: train_loss=1.04322 val_loss=0.94341 val_acc=0.6083 time=8.0s
2025-10-13 02:47:34,946 - INFO - _models.training_function_executor - Epoch 023: train_loss=1.03772 val_loss=0.93875 val_acc=0.6096 time=8.0s
2025-10-13 02:47:42,939 - INFO - _models.training_function_executor - Epoch 024: train_loss=1.03564 val_loss=0.93377 val_acc=0.6084 time=8.0s
2025-10-13 02:47:50,942 - INFO - _models.training_function_executor - Epoch 025: train_loss=1.02648 val_loss=0.93042 val_acc=0.6106 time=8.0s
2025-10-13 02:47:58,928 - INFO - _models.training_function_executor - Epoch 026: train_loss=1.02568 val_loss=0.92806 val_acc=0.6114 time=8.0s
2025-10-13 02:48:06,938 - INFO - _models.training_function_executor - Epoch 027: train_loss=1.02092 val_loss=0.92553 val_acc=0.6143 time=8.0s
2025-10-13 02:48:14,934 - INFO - _models.training_function_executor - Epoch 028: train_loss=1.01913 val_loss=0.92143 val_acc=0.6153 time=8.0s
2025-10-13 02:48:22,928 - INFO - _models.training_function_executor - Epoch 029: train_loss=1.01469 val_loss=0.92042 val_acc=0.6146 time=8.0s
2025-10-13 02:48:30,925 - INFO - _models.training_function_executor - Epoch 030: train_loss=1.01535 val_loss=0.91869 val_acc=0.6152 time=8.0s
2025-10-13 02:48:38,925 - INFO - _models.training_function_executor - Epoch 031: train_loss=1.01706 val_loss=0.91787 val_acc=0.6165 time=8.0s
2025-10-13 02:48:46,911 - INFO - _models.training_function_executor - Epoch 032: train_loss=1.01455 val_loss=0.91773 val_acc=0.6155 time=8.0s
2025-10-13 02:48:54,891 - INFO - _models.training_function_executor - Epoch 033: train_loss=1.01521 val_loss=0.91606 val_acc=0.6166 time=8.0s
2025-10-13 02:49:02,894 - INFO - _models.training_function_executor - Epoch 034: train_loss=1.01294 val_loss=0.91506 val_acc=0.6166 time=8.0s
2025-10-13 02:49:10,892 - INFO - _models.training_function_executor - Epoch 035: train_loss=1.01196 val_loss=0.91532 val_acc=0.6165 time=8.0s
2025-10-13 02:49:18,878 - INFO - _models.training_function_executor - Epoch 036: train_loss=1.01628 val_loss=0.91457 val_acc=0.6172 time=8.0s
2025-10-13 02:49:26,870 - INFO - _models.training_function_executor - Epoch 037: train_loss=1.01053 val_loss=0.91438 val_acc=0.6174 time=8.0s
2025-10-13 02:49:34,859 - INFO - _models.training_function_executor - Epoch 038: train_loss=1.01075 val_loss=0.91433 val_acc=0.6173 time=8.0s
2025-10-13 02:49:42,854 - INFO - _models.training_function_executor - Epoch 039: train_loss=1.00941 val_loss=0.91432 val_acc=0.6173 time=8.0s
2025-10-13 02:49:43,948 - INFO - _models.training_function_executor - Model: 13,255 parameters, 57.0KB storage
2025-10-13 02:49:43,949 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.60508872968649, 1.554133076579328, 1.496193229964366, 1.4312216777420979, 1.3751177770673373, 1.3282602609852039, 1.2849481238491016, 1.2460107304309689, 1.2075269965805038, 1.18271410406825, 1.1563115138710485, 1.1328437551151926, 1.120199181251606, 1.1034039898606334, 1.0891483970818339, 1.0818634625702919, 1.0707872066207393, 1.065848676963081, 1.0581651375266192, 1.051689474491711, 1.0452190074713696, 1.0432211857055675, 1.0377203843207221, 1.0356406205010071, 1.0264758521708568, 1.0256840782354126, 1.0209226880325568, 1.019131669766176, 1.0146927368319614, 1.0153509272868124, 1.0170611160636824, 1.0145476532433055, 1.0152123630735312, 1.0129413186648446, 1.0119575843303654, 1.0162817705833374, 1.0105291784831933, 1.0107529182971504, 1.009413736201184], 'val_losses': [1.5653066465726966, 1.5014549445805534, 1.4262139382043584, 1.3474888097251008, 1.2930686523499588, 1.2422171862424984, 1.1913892322376052, 1.1510520378192237, 1.1131620211829911, 1.0821957272334994, 1.0541870094155115, 1.0341898316389035, 1.0196992796035675, 1.0040467152822505, 1.0008467079919663, 0.9816010249090812, 0.9751967892681839, 0.9693512623861698, 0.9616321981850311, 0.9557620437778623, 0.9483239561016843, 0.9434120333566088, 0.9387455444716473, 0.9337728894754102, 0.9304194929593921, 0.9280560495638955, 0.9255285477529759, 0.9214303389395039, 0.9204188777635178, 0.9186908252013076, 0.9178741767058475, 0.9177348207960105, 0.9160550540462423, 0.9150589357984621, 0.9153153420662938, 0.9145745374249293, 0.9143804601743416, 0.9143256432617048, 0.9143154807219274], 'val_acc': [0.232061603080154, 0.33479173958697933, 0.4276338816940847, 0.5041127056352818, 0.5288764438221911, 0.5383269163458173, 0.547602380119006, 0.562215610780539, 0.5664158207910396, 0.5700035001750088, 0.5777913895694785, 0.5826041302065104, 0.5862793139656983, 0.5868918445922297, 0.5881169058452923, 0.5978298914945748, 0.5973048652432622, 0.6027301365068254, 0.603605180259013, 0.6030801540077004, 0.6047427371368569, 0.6083304165208261, 0.6096429821491075, 0.6084179208960449, 0.6106055302765139, 0.6113930696534827, 0.6142807140357018, 0.615330766538327, 0.6146307315365769, 0.6151557577878894, 0.6164683234161709, 0.6155057752887645, 0.6165558277913896, 0.6166433321666084, 0.6164683234161709, 0.617168358417921, 0.6174308715435772, 0.6172558627931397, 0.6172558627931397], 'quantization': {'bits': 32, 'weights': True, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 58204}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00017265095788112568, 'batch_size': 256, 'epochs': 39, 'weight_decay': 6.143114585883614e-07, 'dropout': 0.47142322043068136, 'grad_clip': 4.529567093321831, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 8, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 18}, 'model_parameter_count': 13255, 'model_storage_size_kb': 56.95507812500001, 'model_size_validation': 'PASS'}
2025-10-13 02:49:43,949 - INFO - _models.training_function_executor - BO Objective: base=0.6173, size_penalty=0.0000, final=0.6173
2025-10-13 02:49:43,949 - INFO - _models.training_function_executor - Model: 13,255 parameters, 57.0KB (PASS 256KB limit)
2025-10-13 02:49:43,949 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 331.286s
2025-10-13 02:49:44,077 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6173
2025-10-13 02:49:44,077 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 02:49:44,077 - INFO - bo.run_bo - Recorded observation #31: hparams={'lr': 0.00017265095788112568, 'batch_size': np.int64(256), 'epochs': np.int64(39), 'weight_decay': 6.143114585883614e-07, 'dropout': 0.47142322043068136, 'grad_clip': 4.529567093321831, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(8), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(18)}, value=0.6173
2025-10-13 02:49:44,077 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 31: {'lr': 0.00017265095788112568, 'batch_size': np.int64(256), 'epochs': np.int64(39), 'weight_decay': 6.143114585883614e-07, 'dropout': 0.47142322043068136, 'grad_clip': 4.529567093321831, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(8), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(18)} -> 0.6173
2025-10-13 02:49:44,078 - INFO - bo.run_bo - üîçBO Trial 32: Using RF surrogate + Expected Improvement
2025-10-13 02:49:44,078 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:49:44,078 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 32 (NaN monitoring active)
2025-10-13 02:49:44,078 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:49:44,078 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:49:44,078 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003301426858739867, 'batch_size': 128, 'epochs': 16, 'weight_decay': 1.7192787754542241e-07, 'dropout': 0.08177962176609367, 'grad_clip': 1.3506954842365402, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 14, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 3}
2025-10-13 02:49:44,079 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003301426858739867, 'batch_size': 128, 'epochs': 16, 'weight_decay': 1.7192787754542241e-07, 'dropout': 0.08177962176609367, 'grad_clip': 1.3506954842365402, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 14, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 3}
2025-10-13 02:49:54,817 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.17585 val_loss=0.96670 val_acc=0.6020 time=10.7s
2025-10-13 02:50:02,768 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.87443 val_loss=0.85048 val_acc=0.6640 time=8.0s
2025-10-13 02:50:10,727 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.81102 val_loss=0.95610 val_acc=0.6232 time=8.0s
2025-10-13 02:50:18,680 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.76971 val_loss=0.79543 val_acc=0.6755 time=8.0s
2025-10-13 02:50:26,637 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.73658 val_loss=0.69766 val_acc=0.7242 time=8.0s
2025-10-13 02:50:34,587 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.70205 val_loss=0.68311 val_acc=0.7384 time=8.0s
2025-10-13 02:50:42,540 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.68218 val_loss=0.69895 val_acc=0.7295 time=8.0s
2025-10-13 02:50:50,489 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.65954 val_loss=0.61634 val_acc=0.7572 time=7.9s
2025-10-13 02:50:58,443 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.64021 val_loss=0.74458 val_acc=0.7100 time=8.0s
2025-10-13 02:51:06,404 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.62707 val_loss=0.60190 val_acc=0.7662 time=8.0s
2025-10-13 02:51:14,365 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.61152 val_loss=0.58632 val_acc=0.7717 time=8.0s
2025-10-13 02:51:22,312 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.60710 val_loss=0.57723 val_acc=0.7731 time=7.9s
2025-10-13 02:51:30,269 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.59391 val_loss=0.57131 val_acc=0.7764 time=8.0s
2025-10-13 02:51:38,219 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.58365 val_loss=0.56952 val_acc=0.7753 time=7.9s
2025-10-13 02:51:46,176 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.58118 val_loss=0.56528 val_acc=0.7775 time=8.0s
2025-10-13 02:51:54,131 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.57810 val_loss=0.56406 val_acc=0.7791 time=8.0s
2025-10-13 02:51:55,220 - INFO - _models.training_function_executor - Model: 8,997 parameters, 38.7KB storage
2025-10-13 02:51:55,220 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1758462637089164, 0.8744343356064745, 0.8110213287026056, 0.7697094960942067, 0.7365817234864133, 0.7020460717695595, 0.6821779103224036, 0.6595449590332491, 0.6402107424822812, 0.6270650126193844, 0.6115226060475425, 0.6071032760316023, 0.5939107132325191, 0.5836507094920328, 0.5811800101773906, 0.5781012539330337], 'val_losses': [0.9666983224229876, 0.8504750013017638, 0.9560966623134032, 0.7954316817883808, 0.6976607098085379, 0.6831146538528814, 0.698948316925424, 0.6163363342398649, 0.7445823137977968, 0.601899901010542, 0.5863150536575892, 0.5772291498456253, 0.5713112387032955, 0.5695167382384331, 0.5652812530955194, 0.5640618215710457], 'val_acc': [0.6020301015050753, 0.663983199159958, 0.6232061603080155, 0.6755337766888344, 0.7241862093104655, 0.7383619180959048, 0.7295239761988099, 0.7571753587679384, 0.7100105005250262, 0.7661883094154708, 0.7717010850542527, 0.7731011550577529, 0.7764263213160658, 0.7752887644382219, 0.777476373818691, 0.7791389569478474], 'quantization': {'bits': 8, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 39588}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003301426858739867, 'batch_size': 128, 'epochs': 16, 'weight_decay': 1.7192787754542241e-07, 'dropout': 0.08177962176609367, 'grad_clip': 1.3506954842365402, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 14, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 3}, 'model_parameter_count': 8997, 'model_storage_size_kb': 38.658984375, 'model_size_validation': 'PASS'}
2025-10-13 02:51:55,220 - INFO - _models.training_function_executor - BO Objective: base=0.7791, size_penalty=0.0000, final=0.7791
2025-10-13 02:51:55,220 - INFO - _models.training_function_executor - Model: 8,997 parameters, 38.7KB (PASS 256KB limit)
2025-10-13 02:51:55,220 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 131.142s
2025-10-13 02:51:55,353 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7791
2025-10-13 02:51:55,353 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.112s
2025-10-13 02:51:55,353 - INFO - bo.run_bo - Recorded observation #32: hparams={'lr': 0.003301426858739867, 'batch_size': np.int64(128), 'epochs': np.int64(16), 'weight_decay': 1.7192787754542241e-07, 'dropout': 0.08177962176609367, 'grad_clip': 1.3506954842365402, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(3)}, value=0.7791
2025-10-13 02:51:55,353 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 32: {'lr': 0.003301426858739867, 'batch_size': np.int64(128), 'epochs': np.int64(16), 'weight_decay': 1.7192787754542241e-07, 'dropout': 0.08177962176609367, 'grad_clip': 1.3506954842365402, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(3)} -> 0.7791
2025-10-13 02:51:55,353 - INFO - bo.run_bo - üîçBO Trial 33: Using RF surrogate + Expected Improvement
2025-10-13 02:51:55,353 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:51:55,353 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 33 (NaN monitoring active)
2025-10-13 02:51:55,353 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:51:55,353 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:51:55,353 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00020001109421198467, 'batch_size': 32, 'epochs': 19, 'weight_decay': 1.8085437195850498e-07, 'dropout': 0.0800021306885373, 'grad_clip': 2.468807894864217, 'use_amp': False, 'num_workers': 4, 'base_channels': 10, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 9}
2025-10-13 02:51:55,355 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00020001109421198467, 'batch_size': 32, 'epochs': 19, 'weight_decay': 1.8085437195850498e-07, 'dropout': 0.0800021306885373, 'grad_clip': 2.468807894864217, 'use_amp': False, 'num_workers': 4, 'base_channels': 10, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 9}
2025-10-13 02:52:06,051 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.38097 val_loss=1.17613 val_acc=0.5454 time=10.7s
2025-10-13 02:52:13,834 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.14507 val_loss=1.09263 val_acc=0.5671 time=7.8s
2025-10-13 02:52:21,608 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.08443 val_loss=1.04677 val_acc=0.5735 time=7.8s
2025-10-13 02:52:29,389 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.04184 val_loss=1.00686 val_acc=0.5956 time=7.8s
2025-10-13 02:52:37,172 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.00244 val_loss=0.97009 val_acc=0.6095 time=7.8s
2025-10-13 02:52:44,967 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.96927 val_loss=0.94158 val_acc=0.6266 time=7.8s
2025-10-13 02:52:52,754 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.94293 val_loss=0.91235 val_acc=0.6372 time=7.8s
2025-10-13 02:53:00,537 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.92094 val_loss=0.90039 val_acc=0.6418 time=7.8s
2025-10-13 02:53:08,322 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.90599 val_loss=0.89007 val_acc=0.6462 time=7.8s
2025-10-13 02:53:16,104 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.89244 val_loss=0.87928 val_acc=0.6528 time=7.8s
2025-10-13 02:53:23,883 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.88404 val_loss=0.86584 val_acc=0.6576 time=7.8s
2025-10-13 02:53:31,661 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.87632 val_loss=0.86682 val_acc=0.6554 time=7.8s
2025-10-13 02:53:39,441 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.86821 val_loss=0.86186 val_acc=0.6551 time=7.8s
2025-10-13 02:53:47,220 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.86575 val_loss=0.85278 val_acc=0.6614 time=7.8s
2025-10-13 02:53:55,002 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.86039 val_loss=0.84977 val_acc=0.6593 time=7.8s
2025-10-13 02:54:02,783 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.85865 val_loss=0.84825 val_acc=0.6593 time=7.8s
2025-10-13 02:54:10,559 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.85443 val_loss=0.84713 val_acc=0.6627 time=7.8s
2025-10-13 02:54:18,339 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.85325 val_loss=0.84775 val_acc=0.6629 time=7.8s
2025-10-13 02:54:26,114 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.85110 val_loss=0.84637 val_acc=0.6618 time=7.8s
2025-10-13 02:54:27,214 - INFO - _models.training_function_executor - Model: 6,569 parameters, 28.2KB storage
2025-10-13 02:54:27,215 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3809707859074023, 1.1450691775170747, 1.0844293145145367, 1.041841453215773, 1.002443091911914, 0.9692728277015485, 0.9429252679255362, 0.9209403047037575, 0.9059910135833291, 0.8924412391675616, 0.8840442895680656, 0.8763225793337797, 0.8682116457412073, 0.8657520771819393, 0.8603941146668997, 0.8586536675931525, 0.8544286375576523, 0.8532490727990751, 0.8510981909787275], 'val_losses': [1.1761268477444888, 1.0926261977962484, 1.046771619425898, 1.0068564767974384, 0.9700886452160475, 0.9415827645344211, 0.9123543977820877, 0.9003899797593792, 0.8900678630554472, 0.8792813942905569, 0.8658401184579397, 0.8668248115989516, 0.8618632980189125, 0.8527817525853634, 0.8497681363420884, 0.8482529357633768, 0.8471263404029377, 0.8477454277281583, 0.8463713545293544], 'val_acc': [0.545414770738537, 0.5671158557927897, 0.5735036751837592, 0.595554777738887, 0.60946797339867, 0.626618830941547, 0.6372068603430171, 0.6417570878543927, 0.6462198109905495, 0.6527826391319566, 0.6575953797689884, 0.6554077703885194, 0.6550577528876443, 0.6614455722786139, 0.6593454672733636, 0.6593454672733636, 0.6626706335316765, 0.6629331466573328, 0.6617955897794889], 'quantization': {'bits': 32, 'weights': True, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 29876}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00020001109421198467, 'batch_size': 32, 'epochs': 19, 'weight_decay': 1.8085437195850498e-07, 'dropout': 0.0800021306885373, 'grad_clip': 2.468807894864217, 'use_amp': False, 'num_workers': 4, 'base_channels': 10, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 9}, 'model_parameter_count': 6569, 'model_storage_size_kb': 28.226171875000002, 'model_size_validation': 'PASS'}
2025-10-13 02:54:27,215 - INFO - _models.training_function_executor - BO Objective: base=0.6618, size_penalty=0.0000, final=0.6618
2025-10-13 02:54:27,215 - INFO - _models.training_function_executor - Model: 6,569 parameters, 28.2KB (PASS 256KB limit)
2025-10-13 02:54:27,215 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 151.861s
2025-10-13 02:54:27,334 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6618
2025-10-13 02:54:27,334 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.114s
2025-10-13 02:54:27,334 - INFO - bo.run_bo - Recorded observation #33: hparams={'lr': 0.00020001109421198467, 'batch_size': np.int64(32), 'epochs': np.int64(19), 'weight_decay': 1.8085437195850498e-07, 'dropout': 0.0800021306885373, 'grad_clip': 2.468807894864217, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(10), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(9)}, value=0.6618
2025-10-13 02:54:27,334 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 33: {'lr': 0.00020001109421198467, 'batch_size': np.int64(32), 'epochs': np.int64(19), 'weight_decay': 1.8085437195850498e-07, 'dropout': 0.0800021306885373, 'grad_clip': 2.468807894864217, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(10), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(9)} -> 0.6618
2025-10-13 02:54:27,335 - INFO - bo.run_bo - üîçBO Trial 34: Using RF surrogate + Expected Improvement
2025-10-13 02:54:27,335 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:54:27,335 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 34 (NaN monitoring active)
2025-10-13 02:54:27,335 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:54:27,335 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:54:27,335 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003626818757229864, 'batch_size': 64, 'epochs': 5, 'weight_decay': 3.62820922138298e-07, 'dropout': 0.35833252501933605, 'grad_clip': 1.522984077246332, 'use_amp': True, 'num_workers': 4, 'base_channels': 12, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 10, 'gcn_hidden_dim': 14, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 10}
2025-10-13 02:54:27,336 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003626818757229864, 'batch_size': 64, 'epochs': 5, 'weight_decay': 3.62820922138298e-07, 'dropout': 0.35833252501933605, 'grad_clip': 1.522984077246332, 'use_amp': True, 'num_workers': 4, 'base_channels': 12, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 10, 'gcn_hidden_dim': 14, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 10}
2025-10-13 02:54:45,791 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.20093 val_loss=0.97324 val_acc=0.6026 time=18.5s
2025-10-13 02:54:52,856 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.02148 val_loss=0.90906 val_acc=0.6130 time=7.1s
2025-10-13 02:54:59,929 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.93518 val_loss=0.81317 val_acc=0.6587 time=7.1s
2025-10-13 02:55:06,996 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.89249 val_loss=0.82636 val_acc=0.6831 time=7.1s
2025-10-13 02:55:14,070 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.85531 val_loss=0.75789 val_acc=0.6857 time=7.1s
2025-10-13 02:55:15,159 - INFO - _models.training_function_executor - Model: 8,195 parameters, 35.2KB storage
2025-10-13 02:55:15,159 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2009336565356177, 1.0214763986175612, 0.9351843131727633, 0.8924878735120036, 0.8553123914740659], 'val_losses': [0.9732384930801926, 0.9090615389519819, 0.8131706799749816, 0.8263608200340619, 0.7578911031506719], 'val_acc': [0.6026426321316066, 0.6129681484074204, 0.6587329366468323, 0.6831466573328666, 0.6856842842142107], 'quantization': {'bits': 32, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 47180}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003626818757229864, 'batch_size': 64, 'epochs': 5, 'weight_decay': 3.62820922138298e-07, 'dropout': 0.35833252501933605, 'grad_clip': 1.522984077246332, 'use_amp': True, 'num_workers': 4, 'base_channels': 12, 'kernel_size_enc': 11, 'kernel_size_dec': 3, 'partitions': 10, 'gcn_hidden_dim': 14, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 10}, 'model_parameter_count': 8195, 'model_storage_size_kb': 35.212890625, 'model_size_validation': 'PASS'}
2025-10-13 02:55:15,159 - INFO - _models.training_function_executor - BO Objective: base=0.6857, size_penalty=0.0000, final=0.6857
2025-10-13 02:55:15,159 - INFO - _models.training_function_executor - Model: 8,195 parameters, 35.2KB (PASS 256KB limit)
2025-10-13 02:55:15,159 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 47.825s
2025-10-13 02:55:15,278 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6857
2025-10-13 02:55:15,278 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.113s
2025-10-13 02:55:15,278 - INFO - bo.run_bo - Recorded observation #34: hparams={'lr': 0.003626818757229864, 'batch_size': np.int64(64), 'epochs': np.int64(5), 'weight_decay': 3.62820922138298e-07, 'dropout': 0.35833252501933605, 'grad_clip': 1.522984077246332, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(12), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(10)}, value=0.6857
2025-10-13 02:55:15,278 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 34: {'lr': 0.003626818757229864, 'batch_size': np.int64(64), 'epochs': np.int64(5), 'weight_decay': 3.62820922138298e-07, 'dropout': 0.35833252501933605, 'grad_clip': 1.522984077246332, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(12), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(10)} -> 0.6857
2025-10-13 02:55:15,279 - INFO - bo.run_bo - üîçBO Trial 35: Using RF surrogate + Expected Improvement
2025-10-13 02:55:15,279 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 02:55:15,279 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 35 (NaN monitoring active)
2025-10-13 02:55:15,279 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 02:55:15,279 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 02:55:15,279 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00016642915164680796, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.4447641872686198e-05, 'dropout': 0.046257016744814645, 'grad_clip': 3.3039630908217568, 'use_amp': True, 'num_workers': 4, 'base_channels': 10, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 18}
2025-10-13 02:55:15,280 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00016642915164680796, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.4447641872686198e-05, 'dropout': 0.046257016744814645, 'grad_clip': 3.3039630908217568, 'use_amp': True, 'num_workers': 4, 'base_channels': 10, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 18}
2025-10-13 02:55:32,593 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.55865 val_loss=1.50477 val_acc=0.4130 time=17.3s
2025-10-13 02:55:39,406 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.35675 val_loss=1.22425 val_acc=0.5328 time=6.8s
2025-10-13 02:55:46,199 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.17312 val_loss=1.12626 val_acc=0.5682 time=6.8s
2025-10-13 02:55:52,999 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.10245 val_loss=1.10638 val_acc=0.5753 time=6.8s
2025-10-13 02:55:59,809 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.05861 val_loss=1.02986 val_acc=0.5971 time=6.8s
2025-10-13 02:56:06,610 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.03092 val_loss=1.00478 val_acc=0.6063 time=6.8s
2025-10-13 02:56:13,410 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.01573 val_loss=1.00288 val_acc=0.6046 time=6.8s
2025-10-13 02:56:20,205 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.00644 val_loss=0.98526 val_acc=0.6107 time=6.8s
2025-10-13 02:56:26,993 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.99435 val_loss=0.97884 val_acc=0.6163 time=6.8s
2025-10-13 02:56:33,789 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.98317 val_loss=0.96292 val_acc=0.6194 time=6.8s
2025-10-13 02:56:40,596 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.97104 val_loss=0.95000 val_acc=0.6239 time=6.8s
2025-10-13 02:56:47,402 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.95888 val_loss=0.95594 val_acc=0.6212 time=6.8s
2025-10-13 02:56:54,217 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.94514 val_loss=0.93468 val_acc=0.6254 time=6.8s
2025-10-13 02:57:01,017 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.93455 val_loss=0.91739 val_acc=0.6292 time=6.8s
2025-10-13 02:57:07,826 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.91965 val_loss=0.90853 val_acc=0.6300 time=6.8s
2025-10-13 02:57:14,626 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.90145 val_loss=0.87679 val_acc=0.6472 time=6.8s
2025-10-13 02:57:21,435 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.88537 val_loss=0.86691 val_acc=0.6564 time=6.8s
2025-10-13 02:57:28,239 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.87677 val_loss=0.85536 val_acc=0.6579 time=6.8s
2025-10-13 02:57:35,044 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.86472 val_loss=0.84986 val_acc=0.6607 time=6.8s
2025-10-13 02:57:41,856 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.85552 val_loss=0.84496 val_acc=0.6618 time=6.8s
2025-10-13 02:57:48,676 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.84700 val_loss=0.84527 val_acc=0.6597 time=6.8s
2025-10-13 02:57:55,493 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.84181 val_loss=0.82873 val_acc=0.6697 time=6.8s
2025-10-13 02:58:02,307 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.83365 val_loss=0.83044 val_acc=0.6691 time=6.8s
2025-10-13 02:58:09,120 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.82519 val_loss=0.80762 val_acc=0.6765 time=6.8s
2025-10-13 02:58:15,948 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.82137 val_loss=0.80017 val_acc=0.6811 time=6.8s
2025-10-13 02:58:22,766 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.81567 val_loss=0.79826 val_acc=0.6803 time=6.8s
2025-10-13 02:58:29,586 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.80831 val_loss=0.79444 val_acc=0.6774 time=6.8s
2025-10-13 02:58:36,407 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.80718 val_loss=0.78805 val_acc=0.6860 time=6.8s
2025-10-13 02:58:43,225 - INFO - _models.training_function_executor - Epoch 029: train_loss=0.79940 val_loss=0.78941 val_acc=0.6838 time=6.8s
2025-10-13 02:58:50,054 - INFO - _models.training_function_executor - Epoch 030: train_loss=0.79515 val_loss=0.78060 val_acc=0.6926 time=6.8s
2025-10-13 02:58:56,876 - INFO - _models.training_function_executor - Epoch 031: train_loss=0.79370 val_loss=0.77862 val_acc=0.6929 time=6.8s
2025-10-13 02:59:03,699 - INFO - _models.training_function_executor - Epoch 032: train_loss=0.79068 val_loss=0.77595 val_acc=0.6927 time=6.8s
2025-10-13 02:59:10,513 - INFO - _models.training_function_executor - Epoch 033: train_loss=0.78356 val_loss=0.77040 val_acc=0.6938 time=6.8s
2025-10-13 02:59:17,340 - INFO - _models.training_function_executor - Epoch 034: train_loss=0.78537 val_loss=0.77331 val_acc=0.6957 time=6.8s
2025-10-13 02:59:24,155 - INFO - _models.training_function_executor - Epoch 035: train_loss=0.78211 val_loss=0.78921 val_acc=0.6890 time=6.8s
2025-10-13 02:59:30,972 - INFO - _models.training_function_executor - Epoch 036: train_loss=0.78062 val_loss=0.76574 val_acc=0.6943 time=6.8s
2025-10-13 02:59:37,776 - INFO - _models.training_function_executor - Epoch 037: train_loss=0.78120 val_loss=0.76498 val_acc=0.6951 time=6.8s
2025-10-13 02:59:44,600 - INFO - _models.training_function_executor - Epoch 038: train_loss=0.77646 val_loss=0.76528 val_acc=0.6977 time=6.8s
2025-10-13 02:59:51,419 - INFO - _models.training_function_executor - Epoch 039: train_loss=0.77805 val_loss=0.76256 val_acc=0.6982 time=6.8s
2025-10-13 02:59:58,235 - INFO - _models.training_function_executor - Epoch 040: train_loss=0.77430 val_loss=0.76172 val_acc=0.6980 time=6.8s
2025-10-13 03:00:05,045 - INFO - _models.training_function_executor - Epoch 041: train_loss=0.77399 val_loss=0.76193 val_acc=0.6969 time=6.8s
2025-10-13 03:00:11,860 - INFO - _models.training_function_executor - Epoch 042: train_loss=0.77588 val_loss=0.76177 val_acc=0.6992 time=6.8s
2025-10-13 03:00:18,677 - INFO - _models.training_function_executor - Epoch 043: train_loss=0.77124 val_loss=0.76143 val_acc=0.6973 time=6.8s
2025-10-13 03:00:25,488 - INFO - _models.training_function_executor - Epoch 044: train_loss=0.77126 val_loss=0.76064 val_acc=0.6982 time=6.8s
2025-10-13 03:00:32,294 - INFO - _models.training_function_executor - Epoch 045: train_loss=0.77240 val_loss=0.76061 val_acc=0.6981 time=6.8s
2025-10-13 03:00:39,112 - INFO - _models.training_function_executor - Epoch 046: train_loss=0.77145 val_loss=0.76059 val_acc=0.6985 time=6.8s
2025-10-13 03:00:40,234 - INFO - _models.training_function_executor - Model: 6,265 parameters, 26.9KB storage
2025-10-13 03:00:40,234 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5586477018629374, 1.356746822459989, 1.1731247472145527, 1.1024531133950153, 1.0586101293647294, 1.030920945058388, 1.0157305852157652, 1.0064371609379037, 0.9943468786011971, 0.9831664886848468, 0.9710353856993005, 0.9588829437084953, 0.9451433089299347, 0.9345458682951161, 0.9196495083524165, 0.9014532950778169, 0.8853661550021814, 0.8767679230833871, 0.8647159537027297, 0.8555225207749722, 0.8470042200826204, 0.8418050054323852, 0.8336484261355201, 0.8251906163132521, 0.8213719028169808, 0.8156710132085488, 0.8083116060209558, 0.8071782389094373, 0.7993971897581886, 0.7951492529713193, 0.7936965598899833, 0.7906846365062432, 0.7835553082127983, 0.7853685022026332, 0.7821074952434984, 0.7806232859715324, 0.7811971208120418, 0.7764623912848665, 0.7780485438599551, 0.774300419954641, 0.7739928051605064, 0.7758817644356263, 0.7712422713016688, 0.7712599501394499, 0.7723973479185815, 0.7714515103716345], 'val_losses': [1.504766414872324, 1.224245042996178, 1.1262618741414996, 1.1063782605500667, 1.0298565396655053, 1.0047753136768014, 1.0028794366745086, 0.9852594123005157, 0.9788437167121933, 0.9629176129900913, 0.9500017410648174, 0.9559400124611619, 0.9346845860159143, 0.9173943305875106, 0.9085273605399421, 0.8767890394422446, 0.8669118483583118, 0.8553556426446839, 0.8498582272918482, 0.8449626369079093, 0.8452702270006441, 0.8287276033550699, 0.8304397824514067, 0.8076185043516549, 0.800168784548446, 0.7982594554642092, 0.7944440063288631, 0.7880483493339276, 0.7894082053958598, 0.7806043672444815, 0.7786162893672819, 0.7759454191920221, 0.7704006752477145, 0.7733073682688232, 0.7892087830460734, 0.7657400978416841, 0.7649824420889233, 0.7652792557787136, 0.7625578491680264, 0.7617188647029531, 0.7619330208744667, 0.7617730546089415, 0.7614312204481799, 0.7606397831736221, 0.7606142032050486, 0.7605883554432582], 'val_acc': [0.41302065103255164, 0.5328141407070354, 0.5681659082954148, 0.5752537626881344, 0.5971298564928247, 0.6063178158907946, 0.6045677283864194, 0.6106930346517326, 0.6162933146657333, 0.6194434721736087, 0.6239061953097655, 0.621193559677984, 0.6253937696884844, 0.6291564578228911, 0.6300315015750787, 0.6471823591179559, 0.6563703185159258, 0.6579453972698635, 0.660658032901645, 0.6617955897794889, 0.6596954847742387, 0.6696709835491774, 0.6691459572978649, 0.6764963248162408, 0.6811340567028351, 0.6803465173258663, 0.6773713685684284, 0.6860343017150857, 0.6837591879593979, 0.6925971298564928, 0.6928596429821491, 0.6926846342317116, 0.6938221911095555, 0.6957472873643682, 0.6890094504725236, 0.694347217360868, 0.6951347567378369, 0.6976723836191809, 0.6981974098704935, 0.698022401120056, 0.6968848442422121, 0.6992474623731186, 0.6973223661183059, 0.6981974098704935, 0.6981099054952747, 0.6985474273713685], 'quantization': {'bits': 32, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 27364}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00016642915164680796, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.4447641872686198e-05, 'dropout': 0.046257016744814645, 'grad_clip': 3.3039630908217568, 'use_amp': True, 'num_workers': 4, 'base_channels': 10, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 11, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 18}, 'model_parameter_count': 6265, 'model_storage_size_kb': 26.919921875000004, 'model_size_validation': 'PASS'}
2025-10-13 03:00:40,234 - INFO - _models.training_function_executor - BO Objective: base=0.6985, size_penalty=0.0000, final=0.6985
2025-10-13 03:00:40,234 - INFO - _models.training_function_executor - Model: 6,265 parameters, 26.9KB (PASS 256KB limit)
2025-10-13 03:00:40,234 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 324.955s
2025-10-13 03:00:40,353 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6985
2025-10-13 03:00:40,353 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.113s
2025-10-13 03:00:40,353 - INFO - bo.run_bo - Recorded observation #35: hparams={'lr': 0.00016642915164680796, 'batch_size': np.int64(64), 'epochs': np.int64(46), 'weight_decay': 1.4447641872686198e-05, 'dropout': 0.046257016744814645, 'grad_clip': 3.3039630908217568, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(10), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(18)}, value=0.6985
2025-10-13 03:00:40,353 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 35: {'lr': 0.00016642915164680796, 'batch_size': np.int64(64), 'epochs': np.int64(46), 'weight_decay': 1.4447641872686198e-05, 'dropout': 0.046257016744814645, 'grad_clip': 3.3039630908217568, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(10), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(11), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(18)} -> 0.6985
2025-10-13 03:00:40,354 - INFO - bo.run_bo - üîçBO Trial 36: Using RF surrogate + Expected Improvement
2025-10-13 03:00:40,354 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:00:40,354 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 36 (NaN monitoring active)
2025-10-13 03:00:40,354 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:00:40,354 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:00:40,354 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00016078563665888367, 'batch_size': 32, 'epochs': 49, 'weight_decay': 0.0008449867293999438, 'dropout': 0.02598833086850167, 'grad_clip': 4.914904463123159, 'use_amp': True, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 3, 'gcn_hidden_dim': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 14}
2025-10-13 03:00:40,355 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00016078563665888367, 'batch_size': 32, 'epochs': 49, 'weight_decay': 0.0008449867293999438, 'dropout': 0.02598833086850167, 'grad_clip': 4.914904463123159, 'use_amp': True, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 3, 'gcn_hidden_dim': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 14}
2025-10-13 03:00:51,628 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.56612 val_loss=1.52696 val_acc=0.3610 time=11.3s
2025-10-13 03:00:58,405 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.41051 val_loss=1.31313 val_acc=0.5123 time=6.8s
2025-10-13 03:01:05,195 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.28418 val_loss=1.25910 val_acc=0.5166 time=6.8s
2025-10-13 03:01:11,969 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.24326 val_loss=1.22682 val_acc=0.5211 time=6.8s
2025-10-13 03:01:18,759 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.22265 val_loss=1.21064 val_acc=0.5254 time=6.8s
2025-10-13 03:01:25,545 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.20579 val_loss=1.19432 val_acc=0.5288 time=6.8s
2025-10-13 03:01:32,334 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.18653 val_loss=1.17706 val_acc=0.5337 time=6.8s
2025-10-13 03:01:39,110 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.16401 val_loss=1.15857 val_acc=0.5377 time=6.8s
2025-10-13 03:01:45,898 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.14659 val_loss=1.14267 val_acc=0.5390 time=6.8s
2025-10-13 03:01:52,682 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.13031 val_loss=1.13468 val_acc=0.5400 time=6.8s
2025-10-13 03:01:59,482 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.12140 val_loss=1.12141 val_acc=0.5459 time=6.8s
2025-10-13 03:02:06,268 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.11060 val_loss=1.11524 val_acc=0.5501 time=6.8s
2025-10-13 03:02:13,060 - INFO - _models.training_function_executor - Epoch 013: train_loss=1.10351 val_loss=1.10918 val_acc=0.5582 time=6.8s
2025-10-13 03:02:19,860 - INFO - _models.training_function_executor - Epoch 014: train_loss=1.09650 val_loss=1.09757 val_acc=0.5590 time=6.8s
2025-10-13 03:02:26,640 - INFO - _models.training_function_executor - Epoch 015: train_loss=1.09054 val_loss=1.09234 val_acc=0.5631 time=6.8s
2025-10-13 03:02:33,411 - INFO - _models.training_function_executor - Epoch 016: train_loss=1.08712 val_loss=1.08783 val_acc=0.5649 time=6.8s
2025-10-13 03:02:40,201 - INFO - _models.training_function_executor - Epoch 017: train_loss=1.08078 val_loss=1.08149 val_acc=0.5667 time=6.8s
2025-10-13 03:02:46,979 - INFO - _models.training_function_executor - Epoch 018: train_loss=1.07668 val_loss=1.08322 val_acc=0.5662 time=6.8s
2025-10-13 03:02:53,747 - INFO - _models.training_function_executor - Epoch 019: train_loss=1.07412 val_loss=1.07605 val_acc=0.5699 time=6.8s
2025-10-13 03:03:00,524 - INFO - _models.training_function_executor - Epoch 020: train_loss=1.07032 val_loss=1.07147 val_acc=0.5711 time=6.8s
2025-10-13 03:03:07,296 - INFO - _models.training_function_executor - Epoch 021: train_loss=1.06571 val_loss=1.06911 val_acc=0.5732 time=6.8s
2025-10-13 03:03:14,073 - INFO - _models.training_function_executor - Epoch 022: train_loss=1.06271 val_loss=1.06803 val_acc=0.5740 time=6.8s
2025-10-13 03:03:20,854 - INFO - _models.training_function_executor - Epoch 023: train_loss=1.06142 val_loss=1.06489 val_acc=0.5799 time=6.8s
2025-10-13 03:03:27,639 - INFO - _models.training_function_executor - Epoch 024: train_loss=1.05983 val_loss=1.06086 val_acc=0.5783 time=6.8s
2025-10-13 03:03:34,414 - INFO - _models.training_function_executor - Epoch 025: train_loss=1.05789 val_loss=1.05748 val_acc=0.5820 time=6.8s
2025-10-13 03:03:41,190 - INFO - _models.training_function_executor - Epoch 026: train_loss=1.05564 val_loss=1.05705 val_acc=0.5837 time=6.8s
2025-10-13 03:03:47,964 - INFO - _models.training_function_executor - Epoch 027: train_loss=1.05301 val_loss=1.05420 val_acc=0.5827 time=6.8s
2025-10-13 03:03:54,742 - INFO - _models.training_function_executor - Epoch 028: train_loss=1.05109 val_loss=1.05278 val_acc=0.5844 time=6.8s
2025-10-13 03:04:01,522 - INFO - _models.training_function_executor - Epoch 029: train_loss=1.05004 val_loss=1.05079 val_acc=0.5844 time=6.8s
2025-10-13 03:04:08,306 - INFO - _models.training_function_executor - Epoch 030: train_loss=1.04964 val_loss=1.05268 val_acc=0.5874 time=6.8s
2025-10-13 03:04:15,086 - INFO - _models.training_function_executor - Epoch 031: train_loss=1.04624 val_loss=1.04857 val_acc=0.5888 time=6.8s
2025-10-13 03:04:21,863 - INFO - _models.training_function_executor - Epoch 032: train_loss=1.04588 val_loss=1.04678 val_acc=0.5898 time=6.8s
2025-10-13 03:04:28,642 - INFO - _models.training_function_executor - Epoch 033: train_loss=1.04441 val_loss=1.04587 val_acc=0.5907 time=6.8s
2025-10-13 03:04:35,434 - INFO - _models.training_function_executor - Epoch 034: train_loss=1.04293 val_loss=1.04531 val_acc=0.5901 time=6.8s
2025-10-13 03:04:42,211 - INFO - _models.training_function_executor - Epoch 035: train_loss=1.04360 val_loss=1.04447 val_acc=0.5916 time=6.8s
2025-10-13 03:04:48,984 - INFO - _models.training_function_executor - Epoch 036: train_loss=1.04176 val_loss=1.04396 val_acc=0.5918 time=6.8s
2025-10-13 03:04:55,763 - INFO - _models.training_function_executor - Epoch 037: train_loss=1.04367 val_loss=1.04366 val_acc=0.5913 time=6.8s
2025-10-13 03:05:02,538 - INFO - _models.training_function_executor - Epoch 038: train_loss=1.04049 val_loss=1.04286 val_acc=0.5935 time=6.8s
2025-10-13 03:05:09,322 - INFO - _models.training_function_executor - Epoch 039: train_loss=1.04141 val_loss=1.04227 val_acc=0.5929 time=6.8s
2025-10-13 03:05:16,092 - INFO - _models.training_function_executor - Epoch 040: train_loss=1.03987 val_loss=1.04256 val_acc=0.5921 time=6.8s
2025-10-13 03:05:22,865 - INFO - _models.training_function_executor - Epoch 041: train_loss=1.03949 val_loss=1.04196 val_acc=0.5929 time=6.8s
2025-10-13 03:05:29,656 - INFO - _models.training_function_executor - Epoch 042: train_loss=1.03930 val_loss=1.04169 val_acc=0.5934 time=6.8s
2025-10-13 03:05:36,450 - INFO - _models.training_function_executor - Epoch 043: train_loss=1.04097 val_loss=1.04155 val_acc=0.5940 time=6.8s
2025-10-13 03:05:43,227 - INFO - _models.training_function_executor - Epoch 044: train_loss=1.03979 val_loss=1.04176 val_acc=0.5928 time=6.8s
2025-10-13 03:05:50,012 - INFO - _models.training_function_executor - Epoch 045: train_loss=1.04057 val_loss=1.04134 val_acc=0.5936 time=6.8s
2025-10-13 03:05:56,785 - INFO - _models.training_function_executor - Epoch 046: train_loss=1.03879 val_loss=1.04129 val_acc=0.5942 time=6.8s
2025-10-13 03:06:03,562 - INFO - _models.training_function_executor - Epoch 047: train_loss=1.03938 val_loss=1.04133 val_acc=0.5941 time=6.8s
2025-10-13 03:06:10,333 - INFO - _models.training_function_executor - Epoch 048: train_loss=1.03865 val_loss=1.04132 val_acc=0.5939 time=6.8s
2025-10-13 03:06:17,116 - INFO - _models.training_function_executor - Epoch 049: train_loss=1.03837 val_loss=1.04132 val_acc=0.5940 time=6.8s
2025-10-13 03:06:18,245 - INFO - _models.training_function_executor - Model: 4,516 parameters, 19.4KB storage
2025-10-13 03:06:18,245 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5661210810174298, 1.410513243309718, 1.284176705264945, 1.2432624707490696, 1.222652811957357, 1.2057868154223332, 1.1865325992158295, 1.1640064390464224, 1.146594752537691, 1.1303120763893515, 1.1214011401031916, 1.110602799812146, 1.1035096840629806, 1.0965008115200967, 1.090542615816065, 1.0871235143900502, 1.0807757337150934, 1.076681202969269, 1.0741199796167253, 1.0703219206215495, 1.0657064242090928, 1.0627111361333028, 1.0614178217412877, 1.0598289364903883, 1.0578922399658401, 1.0556391883572374, 1.0530124344022949, 1.0510892300994654, 1.05003942782369, 1.0496353438821004, 1.046244394666547, 1.0458785169058677, 1.0444123692807927, 1.0429262616728667, 1.0436042603137905, 1.041759313759288, 1.0436698650203888, 1.0404893481151432, 1.0414125737210942, 1.0398671337470835, 1.0394922242450013, 1.0392973242750692, 1.040969769667611, 1.039785731577314, 1.040574698544984, 1.0387931615270682, 1.0393843497685882, 1.038652732566724, 1.0383723896201524], 'val_losses': [1.5269606856979354, 1.313134768979717, 1.2590995510850371, 1.226820308385214, 1.2106449068281089, 1.1943155300546284, 1.1770589951247155, 1.1585740638355047, 1.1426703410837924, 1.1346761816483426, 1.1214137140754057, 1.1152374343852043, 1.1091766254777544, 1.0975671371130165, 1.0923396960229443, 1.0878322144509363, 1.0814857070663821, 1.0832219326625472, 1.0760473803202089, 1.0714687155308655, 1.0691053880692196, 1.0680287922434262, 1.0648889422291512, 1.0608615026550774, 1.0574833606563752, 1.0570484275454026, 1.0542018220772642, 1.0527801809087265, 1.0507935862629656, 1.0526817653159974, 1.0485688515130065, 1.0467791589440523, 1.045866246861013, 1.0453127587555087, 1.0444666909553975, 1.0439627170562744, 1.043657849959072, 1.042859960945912, 1.0422737844598682, 1.0425612010611993, 1.0419623767908195, 1.0416903724443425, 1.0415548210090635, 1.0417568405316266, 1.0413444920941421, 1.0412943654432554, 1.041332242536428, 1.041322043111452, 1.0413162386580117], 'val_acc': [0.36095554777738886, 0.5122506125306265, 0.5166258312915646, 0.5210885544277214, 0.5253762688134407, 0.5287889394469724, 0.533689184459223, 0.537714385719286, 0.5390269513475674, 0.5399894994749738, 0.5458522926146308, 0.5500525026251313, 0.558190409520476, 0.5589779488974449, 0.5630906545327267, 0.5649282464123206, 0.5666783339166959, 0.5661533076653833, 0.56991599579979, 0.5710535526776339, 0.5731536576828842, 0.5740287014350718, 0.5798914945747288, 0.5783164158207911, 0.581991599579979, 0.5837416870843543, 0.5826916345817291, 0.5844417220861043, 0.5843542177108856, 0.5874168708435422, 0.5888169408470424, 0.5897794889744488, 0.5906545327266364, 0.5901295064753238, 0.5916170808540427, 0.5917920896044803, 0.5912670633531677, 0.5934546727336367, 0.5929296464823242, 0.5920546027301365, 0.5929296464823242, 0.593367168358418, 0.5939796989849493, 0.5928421421071054, 0.5936296814840742, 0.5942422121106056, 0.594067203360168, 0.5938921946097305, 0.5939796989849493], 'quantization': {'bits': 32, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 19360}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00016078563665888367, 'batch_size': 32, 'epochs': 49, 'weight_decay': 0.0008449867293999438, 'dropout': 0.02598833086850167, 'grad_clip': 4.914904463123159, 'use_amp': True, 'num_workers': 4, 'base_channels': 9, 'kernel_size_enc': 9, 'kernel_size_dec': 3, 'partitions': 3, 'gcn_hidden_dim': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 14}, 'model_parameter_count': 4516, 'model_storage_size_kb': 19.4046875, 'model_size_validation': 'PASS'}
2025-10-13 03:06:18,245 - INFO - _models.training_function_executor - BO Objective: base=0.5940, size_penalty=0.0000, final=0.5940
2025-10-13 03:06:18,245 - INFO - _models.training_function_executor - Model: 4,516 parameters, 19.4KB (PASS 256KB limit)
2025-10-13 03:06:18,245 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 337.892s
2025-10-13 03:06:18,360 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5940
2025-10-13 03:06:18,360 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 03:06:18,360 - INFO - bo.run_bo - Recorded observation #36: hparams={'lr': 0.00016078563665888367, 'batch_size': np.int64(32), 'epochs': np.int64(49), 'weight_decay': 0.0008449867293999438, 'dropout': 0.02598833086850167, 'grad_clip': 4.914904463123159, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(9), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(14)}, value=0.5940
2025-10-13 03:06:18,360 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 36: {'lr': 0.00016078563665888367, 'batch_size': np.int64(32), 'epochs': np.int64(49), 'weight_decay': 0.0008449867293999438, 'dropout': 0.02598833086850167, 'grad_clip': 4.914904463123159, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(9), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(14)} -> 0.5940
2025-10-13 03:06:18,360 - INFO - bo.run_bo - üîçBO Trial 37: Using RF surrogate + Expected Improvement
2025-10-13 03:06:18,361 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 03:06:18,361 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 37 (NaN monitoring active)
2025-10-13 03:06:18,361 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:06:18,361 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:06:18,361 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00013012016316453175, 'batch_size': 128, 'epochs': 45, 'weight_decay': 2.75770962957325e-05, 'dropout': 0.06794104977581279, 'grad_clip': 3.3420621473964833, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 16}
2025-10-13 03:06:18,362 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00013012016316453175, 'batch_size': 128, 'epochs': 45, 'weight_decay': 2.75770962957325e-05, 'dropout': 0.06794104977581279, 'grad_clip': 3.3420621473964833, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 16}
2025-10-13 03:06:29,728 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.56101 val_loss=1.50976 val_acc=0.3783 time=11.4s
2025-10-13 03:06:38,303 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.42230 val_loss=1.30974 val_acc=0.4996 time=8.6s
2025-10-13 03:06:46,866 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.25876 val_loss=1.20083 val_acc=0.5294 time=8.6s
2025-10-13 03:06:55,471 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.20372 val_loss=1.18804 val_acc=0.5229 time=8.6s
2025-10-13 03:07:04,065 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.17350 val_loss=1.14708 val_acc=0.5389 time=8.6s
2025-10-13 03:07:12,647 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.14874 val_loss=1.12469 val_acc=0.5438 time=8.6s
2025-10-13 03:07:21,232 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.12586 val_loss=1.10237 val_acc=0.5569 time=8.6s
2025-10-13 03:07:29,803 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.09982 val_loss=1.07860 val_acc=0.5716 time=8.6s
2025-10-13 03:07:38,395 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.07784 val_loss=1.05453 val_acc=0.5859 time=8.6s
2025-10-13 03:07:46,981 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.05236 val_loss=1.03251 val_acc=0.5928 time=8.6s
2025-10-13 03:07:55,562 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.03210 val_loss=1.00985 val_acc=0.6012 time=8.6s
2025-10-13 03:08:04,127 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.00828 val_loss=0.98899 val_acc=0.6077 time=8.6s
2025-10-13 03:08:12,715 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.98700 val_loss=0.96541 val_acc=0.6171 time=8.6s
2025-10-13 03:08:21,307 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.96858 val_loss=0.94551 val_acc=0.6186 time=8.6s
2025-10-13 03:08:29,881 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.94914 val_loss=0.92501 val_acc=0.6281 time=8.6s
2025-10-13 03:08:38,460 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.93526 val_loss=0.91301 val_acc=0.6336 time=8.6s
2025-10-13 03:08:47,051 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.92397 val_loss=0.90153 val_acc=0.6387 time=8.6s
2025-10-13 03:08:55,636 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.91416 val_loss=0.89531 val_acc=0.6386 time=8.6s
2025-10-13 03:09:04,210 - INFO - _models.training_function_executor - Epoch 019: train_loss=0.90598 val_loss=0.88813 val_acc=0.6472 time=8.6s
2025-10-13 03:09:12,786 - INFO - _models.training_function_executor - Epoch 020: train_loss=0.89723 val_loss=0.88255 val_acc=0.6469 time=8.6s
2025-10-13 03:09:21,369 - INFO - _models.training_function_executor - Epoch 021: train_loss=0.89364 val_loss=0.87568 val_acc=0.6509 time=8.6s
2025-10-13 03:09:29,952 - INFO - _models.training_function_executor - Epoch 022: train_loss=0.88514 val_loss=0.87302 val_acc=0.6493 time=8.6s
2025-10-13 03:09:38,530 - INFO - _models.training_function_executor - Epoch 023: train_loss=0.88079 val_loss=0.86583 val_acc=0.6532 time=8.6s
2025-10-13 03:09:47,106 - INFO - _models.training_function_executor - Epoch 024: train_loss=0.87504 val_loss=0.86704 val_acc=0.6488 time=8.6s
2025-10-13 03:09:55,680 - INFO - _models.training_function_executor - Epoch 025: train_loss=0.87266 val_loss=0.85896 val_acc=0.6540 time=8.6s
2025-10-13 03:10:04,273 - INFO - _models.training_function_executor - Epoch 026: train_loss=0.86510 val_loss=0.85342 val_acc=0.6577 time=8.6s
2025-10-13 03:10:12,850 - INFO - _models.training_function_executor - Epoch 027: train_loss=0.86430 val_loss=0.85528 val_acc=0.6578 time=8.6s
2025-10-13 03:10:21,433 - INFO - _models.training_function_executor - Epoch 028: train_loss=0.86204 val_loss=0.85034 val_acc=0.6586 time=8.6s
2025-10-13 03:10:30,010 - INFO - _models.training_function_executor - Epoch 029: train_loss=0.85681 val_loss=0.84511 val_acc=0.6601 time=8.6s
2025-10-13 03:10:38,582 - INFO - _models.training_function_executor - Epoch 030: train_loss=0.85242 val_loss=0.84572 val_acc=0.6635 time=8.6s
2025-10-13 03:10:47,171 - INFO - _models.training_function_executor - Epoch 031: train_loss=0.85349 val_loss=0.84083 val_acc=0.6614 time=8.6s
2025-10-13 03:10:55,742 - INFO - _models.training_function_executor - Epoch 032: train_loss=0.84962 val_loss=0.83888 val_acc=0.6621 time=8.6s
2025-10-13 03:11:04,333 - INFO - _models.training_function_executor - Epoch 033: train_loss=0.84734 val_loss=0.83860 val_acc=0.6608 time=8.6s
2025-10-13 03:11:12,905 - INFO - _models.training_function_executor - Epoch 034: train_loss=0.84547 val_loss=0.84162 val_acc=0.6641 time=8.6s
2025-10-13 03:11:21,472 - INFO - _models.training_function_executor - Epoch 035: train_loss=0.84480 val_loss=0.83703 val_acc=0.6627 time=8.6s
2025-10-13 03:11:30,059 - INFO - _models.training_function_executor - Epoch 036: train_loss=0.84334 val_loss=0.83437 val_acc=0.6638 time=8.6s
2025-10-13 03:11:38,632 - INFO - _models.training_function_executor - Epoch 037: train_loss=0.84142 val_loss=0.83464 val_acc=0.6643 time=8.6s
2025-10-13 03:11:47,219 - INFO - _models.training_function_executor - Epoch 038: train_loss=0.84147 val_loss=0.83284 val_acc=0.6646 time=8.6s
2025-10-13 03:11:55,789 - INFO - _models.training_function_executor - Epoch 039: train_loss=0.84051 val_loss=0.83238 val_acc=0.6656 time=8.6s
2025-10-13 03:12:04,368 - INFO - _models.training_function_executor - Epoch 040: train_loss=0.83991 val_loss=0.83222 val_acc=0.6669 time=8.6s
2025-10-13 03:12:12,944 - INFO - _models.training_function_executor - Epoch 041: train_loss=0.84051 val_loss=0.83167 val_acc=0.6657 time=8.6s
2025-10-13 03:12:21,531 - INFO - _models.training_function_executor - Epoch 042: train_loss=0.83822 val_loss=0.83156 val_acc=0.6656 time=8.6s
2025-10-13 03:12:30,106 - INFO - _models.training_function_executor - Epoch 043: train_loss=0.84015 val_loss=0.83154 val_acc=0.6656 time=8.6s
2025-10-13 03:12:38,681 - INFO - _models.training_function_executor - Epoch 044: train_loss=0.83937 val_loss=0.83147 val_acc=0.6657 time=8.6s
2025-10-13 03:12:47,258 - INFO - _models.training_function_executor - Epoch 045: train_loss=0.84081 val_loss=0.83147 val_acc=0.6655 time=8.6s
2025-10-13 03:12:48,392 - INFO - _models.training_function_executor - Model: 10,118 parameters, 43.5KB storage
2025-10-13 03:12:48,392 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5610064361994191, 1.4222965707802298, 1.2587626772324105, 1.2037161956269047, 1.1734955159358558, 1.1487428591223834, 1.1258571361135177, 1.0998170748848493, 1.0778411474935568, 1.0523605140973773, 1.0320995492371055, 1.0082812849191005, 0.9870042594780153, 0.9685790199560848, 0.9491394900090635, 0.9352568493967587, 0.9239676569907616, 0.9141640428441948, 0.9059830614850368, 0.8972273166253928, 0.8936381665275862, 0.8851394843587852, 0.8807855548665037, 0.8750437821464018, 0.8726622168943521, 0.8650993879416375, 0.8643039394434741, 0.8620359414434116, 0.8568110172257041, 0.852420030167606, 0.8534863426587695, 0.8496216976605055, 0.8473354441576334, 0.8454655583688417, 0.8447954936756886, 0.8433377092895201, 0.8414249446870232, 0.8414697703215306, 0.8405050108138189, 0.8399097645328644, 0.8405086113662206, 0.8382238073285576, 0.8401499208888267, 0.839366012617638, 0.8408076741038647], 'val_losses': [1.5097577286467587, 1.3097405221272818, 1.2008320817089515, 1.1880353443014233, 1.1470809007884324, 1.1246945786651381, 1.1023749083040644, 1.078602208889236, 1.0545339428297824, 1.03250856753367, 1.0098467836189737, 0.9889880543953479, 0.9654065680161698, 0.9455091896322502, 0.9250068697722424, 0.91301401372051, 0.9015271828898108, 0.8953057577403892, 0.8881292693841111, 0.8825535698290843, 0.8756795976184488, 0.8730214498741542, 0.8658267743403067, 0.8670417798913188, 0.8589574749919556, 0.8534212070284167, 0.8552821453609873, 0.8503385300314172, 0.8451091443737111, 0.8457186919724061, 0.8408266809131033, 0.8388834629269134, 0.8386026703063784, 0.8416162279046913, 0.8370259199519653, 0.8343678338985824, 0.8346375206111819, 0.8328433613031112, 0.8323816098989955, 0.8322170720385804, 0.8316685899721813, 0.8315575570963378, 0.8315371121816131, 0.831469356408685, 0.8314693764785724], 'val_acc': [0.37828141407070354, 0.49964998249912496, 0.5294014700735037, 0.5229261463073154, 0.5389394469723486, 0.5437521876093805, 0.5568778438921946, 0.5715785789289465, 0.5859292964648233, 0.5927546377318866, 0.6012425621281065, 0.6077178858942948, 0.6170808540427022, 0.6185684284214211, 0.628106405320266, 0.6336191809590479, 0.638694434721736, 0.6386069303465173, 0.6471823591179559, 0.6469198459922996, 0.6509450472523626, 0.6492824641232061, 0.6532201610080504, 0.6487574378718935, 0.6540077003850192, 0.6576828841442072, 0.6577703885194259, 0.6586454322716135, 0.6601330066503325, 0.6635456772838642, 0.6614455722786139, 0.6620581029051452, 0.6608330416520826, 0.6640707035351767, 0.6626706335316765, 0.6638081904095204, 0.664333216660833, 0.6645957297864893, 0.6656457822891144, 0.6668708435421771, 0.6657332866643332, 0.6656457822891144, 0.6656457822891144, 0.6657332866643332, 0.6654707735386769], 'quantization': {'bits': 32, 'weights': True, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 41768}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00013012016316453175, 'batch_size': 128, 'epochs': 45, 'weight_decay': 2.75770962957325e-05, 'dropout': 0.06794104977581279, 'grad_clip': 3.3420621473964833, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 16}, 'model_parameter_count': 10118, 'model_storage_size_kb': 43.475781250000004, 'model_size_validation': 'PASS'}
2025-10-13 03:12:48,392 - INFO - _models.training_function_executor - BO Objective: base=0.6655, size_penalty=0.0000, final=0.6655
2025-10-13 03:12:48,392 - INFO - _models.training_function_executor - Model: 10,118 parameters, 43.5KB (PASS 256KB limit)
2025-10-13 03:12:48,392 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 390.032s
2025-10-13 03:12:48,534 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6655
2025-10-13 03:12:48,534 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.121s
2025-10-13 03:12:48,534 - INFO - bo.run_bo - Recorded observation #37: hparams={'lr': 0.00013012016316453175, 'batch_size': np.int64(128), 'epochs': np.int64(45), 'weight_decay': 2.75770962957325e-05, 'dropout': 0.06794104977581279, 'grad_clip': 3.3420621473964833, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(16)}, value=0.6655
2025-10-13 03:12:48,534 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 37: {'lr': 0.00013012016316453175, 'batch_size': np.int64(128), 'epochs': np.int64(45), 'weight_decay': 2.75770962957325e-05, 'dropout': 0.06794104977581279, 'grad_clip': 3.3420621473964833, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(16)} -> 0.6655
2025-10-13 03:12:48,535 - INFO - bo.run_bo - üîçBO Trial 38: Using RF surrogate + Expected Improvement
2025-10-13 03:12:48,535 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:12:48,535 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 38 (NaN monitoring active)
2025-10-13 03:12:48,535 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:12:48,535 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:12:48,535 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 9.659013514287277e-05, 'batch_size': 128, 'epochs': 43, 'weight_decay': 4.0885089810366764e-05, 'dropout': 0.03559244413873192, 'grad_clip': 2.0545938754121096, 'use_amp': True, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 15, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 11}
2025-10-13 03:12:48,538 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 9.659013514287277e-05, 'batch_size': 128, 'epochs': 43, 'weight_decay': 4.0885089810366764e-05, 'dropout': 0.03559244413873192, 'grad_clip': 2.0545938754121096, 'use_amp': True, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 15, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 11}
2025-10-13 03:13:00,387 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.59222 val_loss=1.55333 val_acc=0.3169 time=11.8s
2025-10-13 03:13:08,303 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.53995 val_loss=1.52818 val_acc=0.3387 time=7.9s
2025-10-13 03:13:16,206 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.52098 val_loss=1.51111 val_acc=0.3493 time=7.9s
2025-10-13 03:13:24,120 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.50304 val_loss=1.49001 val_acc=0.3519 time=7.9s
2025-10-13 03:13:32,009 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.47332 val_loss=1.45088 val_acc=0.3764 time=7.9s
2025-10-13 03:13:39,929 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.43085 val_loss=1.41074 val_acc=0.3876 time=7.9s
2025-10-13 03:13:47,825 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.39075 val_loss=1.37599 val_acc=0.4053 time=7.9s
2025-10-13 03:13:55,716 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.35746 val_loss=1.34247 val_acc=0.4373 time=7.9s
2025-10-13 03:14:03,608 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.32837 val_loss=1.31250 val_acc=0.4586 time=7.9s
2025-10-13 03:14:11,501 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.30084 val_loss=1.28496 val_acc=0.4696 time=7.9s
2025-10-13 03:14:19,398 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.27136 val_loss=1.25363 val_acc=0.4793 time=7.9s
2025-10-13 03:14:27,296 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.23796 val_loss=1.21714 val_acc=0.4914 time=7.9s
2025-10-13 03:14:35,197 - INFO - _models.training_function_executor - Epoch 013: train_loss=1.20225 val_loss=1.17551 val_acc=0.5092 time=7.9s
2025-10-13 03:14:43,101 - INFO - _models.training_function_executor - Epoch 014: train_loss=1.16958 val_loss=1.14609 val_acc=0.5149 time=7.9s
2025-10-13 03:14:50,994 - INFO - _models.training_function_executor - Epoch 015: train_loss=1.14288 val_loss=1.11206 val_acc=0.5270 time=7.9s
2025-10-13 03:14:58,905 - INFO - _models.training_function_executor - Epoch 016: train_loss=1.12113 val_loss=1.09071 val_acc=0.5424 time=7.9s
2025-10-13 03:15:06,808 - INFO - _models.training_function_executor - Epoch 017: train_loss=1.10396 val_loss=1.07315 val_acc=0.5514 time=7.9s
2025-10-13 03:15:14,716 - INFO - _models.training_function_executor - Epoch 018: train_loss=1.08689 val_loss=1.06334 val_acc=0.5631 time=7.9s
2025-10-13 03:15:22,609 - INFO - _models.training_function_executor - Epoch 019: train_loss=1.08000 val_loss=1.05123 val_acc=0.5693 time=7.9s
2025-10-13 03:15:30,495 - INFO - _models.training_function_executor - Epoch 020: train_loss=1.06736 val_loss=1.04409 val_acc=0.5750 time=7.9s
2025-10-13 03:15:38,397 - INFO - _models.training_function_executor - Epoch 021: train_loss=1.06132 val_loss=1.03746 val_acc=0.5803 time=7.9s
2025-10-13 03:15:46,304 - INFO - _models.training_function_executor - Epoch 022: train_loss=1.05396 val_loss=1.03038 val_acc=0.5858 time=7.9s
2025-10-13 03:15:54,196 - INFO - _models.training_function_executor - Epoch 023: train_loss=1.04712 val_loss=1.02512 val_acc=0.5923 time=7.9s
2025-10-13 03:16:02,099 - INFO - _models.training_function_executor - Epoch 024: train_loss=1.03933 val_loss=1.01411 val_acc=0.5994 time=7.9s
2025-10-13 03:16:09,990 - INFO - _models.training_function_executor - Epoch 025: train_loss=1.03347 val_loss=1.01007 val_acc=0.6027 time=7.9s
2025-10-13 03:16:17,890 - INFO - _models.training_function_executor - Epoch 026: train_loss=1.02919 val_loss=1.00792 val_acc=0.6071 time=7.9s
2025-10-13 03:16:25,778 - INFO - _models.training_function_executor - Epoch 027: train_loss=1.02472 val_loss=1.00385 val_acc=0.6068 time=7.9s
2025-10-13 03:16:33,680 - INFO - _models.training_function_executor - Epoch 028: train_loss=1.02229 val_loss=0.99875 val_acc=0.6124 time=7.9s
2025-10-13 03:16:41,580 - INFO - _models.training_function_executor - Epoch 029: train_loss=1.00980 val_loss=0.99508 val_acc=0.6129 time=7.9s
2025-10-13 03:16:49,474 - INFO - _models.training_function_executor - Epoch 030: train_loss=1.01476 val_loss=0.99302 val_acc=0.6170 time=7.9s
2025-10-13 03:16:57,367 - INFO - _models.training_function_executor - Epoch 031: train_loss=1.01115 val_loss=0.99030 val_acc=0.6180 time=7.9s
2025-10-13 03:17:05,263 - INFO - _models.training_function_executor - Epoch 032: train_loss=1.01102 val_loss=0.98720 val_acc=0.6174 time=7.9s
2025-10-13 03:17:13,152 - INFO - _models.training_function_executor - Epoch 033: train_loss=1.00101 val_loss=0.98539 val_acc=0.6178 time=7.9s
2025-10-13 03:17:21,044 - INFO - _models.training_function_executor - Epoch 034: train_loss=1.00516 val_loss=0.98406 val_acc=0.6201 time=7.9s
2025-10-13 03:17:28,940 - INFO - _models.training_function_executor - Epoch 035: train_loss=1.00600 val_loss=0.98276 val_acc=0.6202 time=7.9s
2025-10-13 03:17:36,848 - INFO - _models.training_function_executor - Epoch 036: train_loss=1.00323 val_loss=0.98188 val_acc=0.6229 time=7.9s
2025-10-13 03:17:44,740 - INFO - _models.training_function_executor - Epoch 037: train_loss=1.00367 val_loss=0.98179 val_acc=0.6213 time=7.9s
2025-10-13 03:17:52,635 - INFO - _models.training_function_executor - Epoch 038: train_loss=1.00254 val_loss=0.98054 val_acc=0.6225 time=7.9s
2025-10-13 03:18:00,541 - INFO - _models.training_function_executor - Epoch 039: train_loss=1.00004 val_loss=0.98056 val_acc=0.6208 time=7.9s
2025-10-13 03:18:08,442 - INFO - _models.training_function_executor - Epoch 040: train_loss=1.00132 val_loss=0.97998 val_acc=0.6215 time=7.9s
2025-10-13 03:18:16,336 - INFO - _models.training_function_executor - Epoch 041: train_loss=1.00209 val_loss=0.98010 val_acc=0.6220 time=7.9s
2025-10-13 03:18:24,223 - INFO - _models.training_function_executor - Epoch 042: train_loss=0.99978 val_loss=0.97987 val_acc=0.6217 time=7.9s
2025-10-13 03:18:32,099 - INFO - _models.training_function_executor - Epoch 043: train_loss=1.00282 val_loss=0.97988 val_acc=0.6216 time=7.9s
2025-10-13 03:18:36,299 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB storage
2025-10-13 03:18:36,300 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5922188937434543, 1.539951047406649, 1.5209823504251996, 1.5030365036966753, 1.4733194071469626, 1.4308527438090655, 1.390750546533827, 1.3574643477218569, 1.3283703192823368, 1.3008388957236252, 1.27135989096017, 1.2379592745964203, 1.2022519346964204, 1.1695817811196194, 1.1428808515039324, 1.1211262795739045, 1.1039622356560332, 1.0868878037853595, 1.0800018502483428, 1.0673550114082548, 1.061320798064096, 1.0539611202876886, 1.0471158680233206, 1.0393269049524636, 1.033465349761848, 1.0291876050196704, 1.0247214602806538, 1.0222868616029355, 1.0098001757492583, 1.014761700261336, 1.0111524510475403, 1.0110234569994185, 1.0010095245153035, 1.0051607478945916, 1.0059974862012906, 1.0032302456215874, 1.0036670389732865, 1.0025378728939347, 1.0000437164707203, 1.001323829967324, 1.002093090975998, 0.9997781361989471, 1.0028215329213954], 'val_losses': [1.5533281138279573, 1.5281752672569293, 1.511112735702894, 1.49001172801436, 1.4508849187543187, 1.4107403573265516, 1.3759943820564824, 1.3424712169575115, 1.3124996800918365, 1.284959073495648, 1.253629835452239, 1.2171419453779466, 1.175510668696162, 1.1460940020877997, 1.112056351100226, 1.090712815220639, 1.0731458986894542, 1.0633369579906016, 1.0512308608747087, 1.0440891053987875, 1.0374600129983707, 1.0303801795924756, 1.025123324267381, 1.0141128094662808, 1.010072133446808, 1.0079164227531388, 1.0038529268544498, 0.9987516654384775, 0.9950806172444013, 0.993022591449349, 0.990299999192331, 0.98720213830325, 0.9853898610190824, 0.9840591633949908, 0.9827631034340356, 0.9818811155842616, 0.9817861204260832, 0.9805401051674517, 0.9805554058070278, 0.9799809415398004, 0.9800961762823173, 0.979874087748596, 0.9798770090229327], 'val_acc': [0.31685334266713333, 0.3387294364718236, 0.34931746587329365, 0.3519425971298565, 0.37644382219110956, 0.3875568778438922, 0.4053202660133007, 0.43725936296814844, 0.45861043052152606, 0.46963598179908994, 0.47926146307315365, 0.4914245712285614, 0.5091879593979699, 0.5148757437871894, 0.5270388519425971, 0.5424396219810991, 0.5513650682534127, 0.5630906545327267, 0.5693034651732587, 0.5749912495624782, 0.5803290164508226, 0.5857542877143858, 0.5923171158557928, 0.5994049702485125, 0.6027301365068254, 0.6071053552677634, 0.6067553377668884, 0.6124431221561079, 0.6128806440322017, 0.6169933496674834, 0.6179558977948898, 0.6174308715435772, 0.6177808890444523, 0.6200560028001401, 0.6202310115505776, 0.6228561428071404, 0.6212810640532027, 0.6225061253062654, 0.6207560378018901, 0.621543577178859, 0.6219810990549528, 0.6217185859292965, 0.6216310815540778], 'quantization': {'bits': 8, 'weights': True, 'activations': True, 'static_ptq_used': True, 'estimated_state_dict_size_bytes': 25420}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 9.659013514287277e-05, 'batch_size': 128, 'epochs': 43, 'weight_decay': 4.0885089810366764e-05, 'dropout': 0.03559244413873192, 'grad_clip': 2.0545938754121096, 'use_amp': True, 'num_workers': 4, 'base_channels': 14, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 10, 'gcn_hidden_dim': 15, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'calib_batches': 11}, 'model_parameter_count': 0, 'model_storage_size_kb': 0.0, 'model_size_validation': 'PASS'}
2025-10-13 03:18:36,300 - INFO - _models.training_function_executor - BO Objective: base=0.6216, size_penalty=0.0000, final=0.6216
2025-10-13 03:18:36,300 - INFO - _models.training_function_executor - Model: 0 parameters, 0.0KB (PASS 256KB limit)
2025-10-13 03:18:36,300 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 347.765s
2025-10-13 03:18:36,426 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6216
2025-10-13 03:18:36,426 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.115s
2025-10-13 03:18:36,426 - INFO - bo.run_bo - Recorded observation #38: hparams={'lr': 9.659013514287277e-05, 'batch_size': np.int64(128), 'epochs': np.int64(43), 'weight_decay': 4.0885089810366764e-05, 'dropout': 0.03559244413873192, 'grad_clip': 2.0545938754121096, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(14), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(11)}, value=0.6216
2025-10-13 03:18:36,426 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 38: {'lr': 9.659013514287277e-05, 'batch_size': np.int64(128), 'epochs': np.int64(43), 'weight_decay': 4.0885089810366764e-05, 'dropout': 0.03559244413873192, 'grad_clip': 2.0545938754121096, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(14), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'calib_batches': np.int64(11)} -> 0.6216
2025-10-13 03:18:36,426 - INFO - bo.run_bo - üîçBO Trial 39: Using RF surrogate + Expected Improvement
2025-10-13 03:18:36,426 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:18:36,426 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 39 (NaN monitoring active)
2025-10-13 03:18:36,426 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:18:36,427 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:18:36,427 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00010936207988968599, 'batch_size': 256, 'epochs': 25, 'weight_decay': 6.189481858848655e-05, 'dropout': 0.05581206062235318, 'grad_clip': 3.1720055844585175, 'use_amp': True, 'num_workers': 4, 'base_channels': 11, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 28}
2025-10-13 03:18:36,428 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00010936207988968599, 'batch_size': 256, 'epochs': 25, 'weight_decay': 6.189481858848655e-05, 'dropout': 0.05581206062235318, 'grad_clip': 3.1720055844585175, 'use_amp': True, 'num_workers': 4, 'base_channels': 11, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 28}
2025-10-13 03:18:58,864 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.60338 val_loss=1.59247 val_acc=0.3148 time=22.4s
2025-10-13 03:19:05,505 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.58046 val_loss=1.55965 val_acc=0.3847 time=6.6s
2025-10-13 03:19:12,147 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.52668 val_loss=1.49378 val_acc=0.3918 time=6.6s
2025-10-13 03:19:18,792 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.47239 val_loss=1.43318 val_acc=0.4754 time=6.6s
2025-10-13 03:19:25,428 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.40249 val_loss=1.34422 val_acc=0.4912 time=6.6s
2025-10-13 03:19:32,083 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.31652 val_loss=1.26312 val_acc=0.5095 time=6.7s
2025-10-13 03:19:38,740 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.24773 val_loss=1.20725 val_acc=0.5151 time=6.7s
2025-10-13 03:19:45,367 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.20510 val_loss=1.18060 val_acc=0.5296 time=6.6s
2025-10-13 03:19:52,013 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.18429 val_loss=1.16700 val_acc=0.5407 time=6.6s
2025-10-13 03:19:58,649 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.17180 val_loss=1.15514 val_acc=0.5498 time=6.6s
2025-10-13 03:20:05,291 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.16074 val_loss=1.14661 val_acc=0.5516 time=6.6s
2025-10-13 03:20:11,930 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.15340 val_loss=1.14474 val_acc=0.5484 time=6.6s
2025-10-13 03:20:18,551 - INFO - _models.training_function_executor - Epoch 013: train_loss=1.14885 val_loss=1.13423 val_acc=0.5550 time=6.6s
2025-10-13 03:20:25,188 - INFO - _models.training_function_executor - Epoch 014: train_loss=1.14274 val_loss=1.13176 val_acc=0.5523 time=6.6s
2025-10-13 03:20:31,823 - INFO - _models.training_function_executor - Epoch 015: train_loss=1.13714 val_loss=1.12303 val_acc=0.5585 time=6.6s
2025-10-13 03:20:38,464 - INFO - _models.training_function_executor - Epoch 016: train_loss=1.13324 val_loss=1.12012 val_acc=0.5586 time=6.6s
2025-10-13 03:20:45,108 - INFO - _models.training_function_executor - Epoch 017: train_loss=1.13041 val_loss=1.11667 val_acc=0.5603 time=6.6s
2025-10-13 03:20:51,757 - INFO - _models.training_function_executor - Epoch 018: train_loss=1.12575 val_loss=1.11397 val_acc=0.5618 time=6.6s
2025-10-13 03:20:58,395 - INFO - _models.training_function_executor - Epoch 019: train_loss=1.12453 val_loss=1.11205 val_acc=0.5624 time=6.6s
2025-10-13 03:21:05,029 - INFO - _models.training_function_executor - Epoch 020: train_loss=1.12235 val_loss=1.10972 val_acc=0.5634 time=6.6s
2025-10-13 03:21:11,662 - INFO - _models.training_function_executor - Epoch 021: train_loss=1.12154 val_loss=1.10960 val_acc=0.5641 time=6.6s
2025-10-13 03:21:18,305 - INFO - _models.training_function_executor - Epoch 022: train_loss=1.12138 val_loss=1.10906 val_acc=0.5644 time=6.6s
2025-10-13 03:21:24,985 - INFO - _models.training_function_executor - Epoch 023: train_loss=1.12028 val_loss=1.10795 val_acc=0.5641 time=6.7s
2025-10-13 03:21:31,639 - INFO - _models.training_function_executor - Epoch 024: train_loss=1.11729 val_loss=1.10802 val_acc=0.5642 time=6.7s
2025-10-13 03:21:38,276 - INFO - _models.training_function_executor - Epoch 025: train_loss=1.11890 val_loss=1.10801 val_acc=0.5644 time=6.6s
2025-10-13 03:21:39,455 - INFO - _models.training_function_executor - Model: 7,784 parameters, 33.4KB storage
2025-10-13 03:21:39,455 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6033816459840688, 1.5804591714230125, 1.5266771165065345, 1.4723880134932346, 1.4024877130129891, 1.3165201354702745, 1.2477275543293003, 1.2051043166202977, 1.1842895436629075, 1.1718040542832864, 1.160741349304728, 1.1533998562649577, 1.148851300562684, 1.1427367321878286, 1.1371358802863505, 1.1332378389120186, 1.1304129284497195, 1.1257518425995876, 1.124527722461515, 1.1223464670571823, 1.1215369006241374, 1.121378047882697, 1.1202750329083397, 1.1172946605141614, 1.1188996850839228], 'val_losses': [1.5924745364584705, 1.5596527904324236, 1.493775142878972, 1.433177771166066, 1.3442187693138243, 1.2631171034648363, 1.2072471145320114, 1.1805981103465153, 1.1669960406263016, 1.1551355356764534, 1.1466056201104982, 1.144744600914223, 1.1342320181416348, 1.131760095231467, 1.1230261356712932, 1.1201223394526107, 1.1166735385988908, 1.1139693567708608, 1.112054773089683, 1.1097246651721242, 1.1096015458846367, 1.109063836006923, 1.107951827511572, 1.1080167975757853, 1.1080053781019377], 'val_acc': [0.31475323766188307, 0.3846692334616731, 0.3918445922296115, 0.47541127056352817, 0.4912495624781239, 0.5094504725236262, 0.5151382569128456, 0.5295764788239412, 0.5406895344767239, 0.549789989499475, 0.551627581379069, 0.5483899194959748, 0.5549527476373819, 0.5523276163808191, 0.5584529226461323, 0.5586279313965699, 0.5602905145257263, 0.5617780889044452, 0.5623906195309766, 0.563353167658383, 0.5641407070353518, 0.5644032201610081, 0.564053202660133, 0.5642282114105706, 0.5644032201610081], 'quantization': {'bits': 32, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 32432}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00010936207988968599, 'batch_size': 256, 'epochs': 25, 'weight_decay': 6.189481858848655e-05, 'dropout': 0.05581206062235318, 'grad_clip': 3.1720055844585175, 'use_amp': True, 'num_workers': 4, 'base_channels': 11, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 3, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 28}, 'model_parameter_count': 7784, 'model_storage_size_kb': 33.446875000000006, 'model_size_validation': 'PASS'}
2025-10-13 03:21:39,455 - INFO - _models.training_function_executor - BO Objective: base=0.5644, size_penalty=0.0000, final=0.5644
2025-10-13 03:21:39,455 - INFO - _models.training_function_executor - Model: 7,784 parameters, 33.4KB (PASS 256KB limit)
2025-10-13 03:21:39,455 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 183.029s
2025-10-13 03:21:39,587 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5644
2025-10-13 03:21:39,587 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.115s
2025-10-13 03:21:39,588 - INFO - bo.run_bo - Recorded observation #39: hparams={'lr': 0.00010936207988968599, 'batch_size': np.int64(256), 'epochs': np.int64(25), 'weight_decay': 6.189481858848655e-05, 'dropout': 0.05581206062235318, 'grad_clip': 3.1720055844585175, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(11), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(28)}, value=0.5644
2025-10-13 03:21:39,588 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 39: {'lr': 0.00010936207988968599, 'batch_size': np.int64(256), 'epochs': np.int64(25), 'weight_decay': 6.189481858848655e-05, 'dropout': 0.05581206062235318, 'grad_clip': 3.1720055844585175, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(11), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(3), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(28)} -> 0.5644
2025-10-13 03:21:39,588 - INFO - bo.run_bo - üîçBO Trial 40: Using RF surrogate + Expected Improvement
2025-10-13 03:21:39,588 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:21:39,588 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 40 (NaN monitoring active)
2025-10-13 03:21:39,588 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:21:39,588 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:21:39,588 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.977114825694412e-05, 'batch_size': 256, 'epochs': 39, 'weight_decay': 1.658376604028378e-07, 'dropout': 0.039712708204805665, 'grad_clip': 3.6147979764278664, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 8, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 11}
2025-10-13 03:21:39,590 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.977114825694412e-05, 'batch_size': 256, 'epochs': 39, 'weight_decay': 1.658376604028378e-07, 'dropout': 0.039712708204805665, 'grad_clip': 3.6147979764278664, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 8, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 11}
2025-10-13 03:22:00,520 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.58924 val_loss=1.57307 val_acc=0.2335 time=20.9s
2025-10-13 03:22:07,722 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.56408 val_loss=1.55394 val_acc=0.3585 time=7.2s
2025-10-13 03:22:14,919 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.53995 val_loss=1.52185 val_acc=0.3561 time=7.2s
2025-10-13 03:22:22,136 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.48549 val_loss=1.43784 val_acc=0.4688 time=7.2s
2025-10-13 03:22:29,322 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.40380 val_loss=1.36904 val_acc=0.4879 time=7.2s
2025-10-13 03:22:36,521 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.34968 val_loss=1.30870 val_acc=0.5052 time=7.2s
2025-10-13 03:22:43,727 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.29371 val_loss=1.25602 val_acc=0.5165 time=7.2s
2025-10-13 03:22:50,946 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.24493 val_loss=1.21148 val_acc=0.5211 time=7.2s
2025-10-13 03:22:58,154 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.21345 val_loss=1.18172 val_acc=0.5298 time=7.2s
2025-10-13 03:23:05,364 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.18555 val_loss=1.16680 val_acc=0.5326 time=7.2s
2025-10-13 03:23:12,571 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.16635 val_loss=1.14308 val_acc=0.5536 time=7.2s
2025-10-13 03:23:19,787 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.15038 val_loss=1.13027 val_acc=0.5587 time=7.2s
2025-10-13 03:23:27,000 - INFO - _models.training_function_executor - Epoch 013: train_loss=1.13811 val_loss=1.11690 val_acc=0.5616 time=7.2s
2025-10-13 03:23:34,214 - INFO - _models.training_function_executor - Epoch 014: train_loss=1.12755 val_loss=1.10634 val_acc=0.5648 time=7.2s
2025-10-13 03:23:41,431 - INFO - _models.training_function_executor - Epoch 015: train_loss=1.11629 val_loss=1.09848 val_acc=0.5677 time=7.2s
2025-10-13 03:23:48,645 - INFO - _models.training_function_executor - Epoch 016: train_loss=1.10564 val_loss=1.09105 val_acc=0.5709 time=7.2s
2025-10-13 03:23:55,864 - INFO - _models.training_function_executor - Epoch 017: train_loss=1.09927 val_loss=1.08390 val_acc=0.5706 time=7.2s
2025-10-13 03:24:03,090 - INFO - _models.training_function_executor - Epoch 018: train_loss=1.09119 val_loss=1.07794 val_acc=0.5735 time=7.2s
2025-10-13 03:24:10,303 - INFO - _models.training_function_executor - Epoch 019: train_loss=1.08520 val_loss=1.07120 val_acc=0.5748 time=7.2s
2025-10-13 03:24:17,510 - INFO - _models.training_function_executor - Epoch 020: train_loss=1.07703 val_loss=1.06387 val_acc=0.5776 time=7.2s
2025-10-13 03:24:24,721 - INFO - _models.training_function_executor - Epoch 021: train_loss=1.07342 val_loss=1.05919 val_acc=0.5777 time=7.2s
2025-10-13 03:24:31,934 - INFO - _models.training_function_executor - Epoch 022: train_loss=1.06938 val_loss=1.05454 val_acc=0.5802 time=7.2s
2025-10-13 03:24:39,161 - INFO - _models.training_function_executor - Epoch 023: train_loss=1.06368 val_loss=1.05015 val_acc=0.5807 time=7.2s
2025-10-13 03:24:46,370 - INFO - _models.training_function_executor - Epoch 024: train_loss=1.05822 val_loss=1.04636 val_acc=0.5818 time=7.2s
2025-10-13 03:24:53,582 - INFO - _models.training_function_executor - Epoch 025: train_loss=1.05507 val_loss=1.04306 val_acc=0.5823 time=7.2s
2025-10-13 03:25:00,806 - INFO - _models.training_function_executor - Epoch 026: train_loss=1.05597 val_loss=1.04036 val_acc=0.5827 time=7.2s
2025-10-13 03:25:08,005 - INFO - _models.training_function_executor - Epoch 027: train_loss=1.05031 val_loss=1.03851 val_acc=0.5829 time=7.2s
2025-10-13 03:25:15,204 - INFO - _models.training_function_executor - Epoch 028: train_loss=1.04821 val_loss=1.03583 val_acc=0.5839 time=7.2s
2025-10-13 03:25:22,413 - INFO - _models.training_function_executor - Epoch 029: train_loss=1.04685 val_loss=1.03442 val_acc=0.5838 time=7.2s
2025-10-13 03:25:29,618 - INFO - _models.training_function_executor - Epoch 030: train_loss=1.04520 val_loss=1.03265 val_acc=0.5849 time=7.2s
2025-10-13 03:25:36,819 - INFO - _models.training_function_executor - Epoch 031: train_loss=1.04394 val_loss=1.03142 val_acc=0.5856 time=7.2s
2025-10-13 03:25:44,022 - INFO - _models.training_function_executor - Epoch 032: train_loss=1.04173 val_loss=1.03040 val_acc=0.5861 time=7.2s
2025-10-13 03:25:51,236 - INFO - _models.training_function_executor - Epoch 033: train_loss=1.04123 val_loss=1.02976 val_acc=0.5864 time=7.2s
2025-10-13 03:25:58,466 - INFO - _models.training_function_executor - Epoch 034: train_loss=1.04109 val_loss=1.02928 val_acc=0.5850 time=7.2s
2025-10-13 03:26:05,662 - INFO - _models.training_function_executor - Epoch 035: train_loss=1.04012 val_loss=1.02873 val_acc=0.5857 time=7.2s
2025-10-13 03:26:12,881 - INFO - _models.training_function_executor - Epoch 036: train_loss=1.04007 val_loss=1.02855 val_acc=0.5854 time=7.2s
2025-10-13 03:26:20,093 - INFO - _models.training_function_executor - Epoch 037: train_loss=1.04075 val_loss=1.02831 val_acc=0.5857 time=7.2s
2025-10-13 03:26:27,312 - INFO - _models.training_function_executor - Epoch 038: train_loss=1.03853 val_loss=1.02824 val_acc=0.5858 time=7.2s
2025-10-13 03:26:34,522 - INFO - _models.training_function_executor - Epoch 039: train_loss=1.04039 val_loss=1.02823 val_acc=0.5858 time=7.2s
2025-10-13 03:26:35,692 - INFO - _models.training_function_executor - Model: 9,782 parameters, 42.0KB storage
2025-10-13 03:26:35,692 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5892376605555607, 1.5640811887202999, 1.5399484845529623, 1.4854913384588107, 1.4038035914661753, 1.3496771898560063, 1.2937128883080755, 1.2449266731134028, 1.2134522455407057, 1.1855454747393952, 1.1663499211864452, 1.1503779717913698, 1.1381069589086792, 1.127545077399353, 1.1162920743800728, 1.1056444508903378, 1.0992658122419519, 1.0911908143043185, 1.0852043480984932, 1.0770299876115936, 1.073418301679807, 1.0693826927018826, 1.06367726291774, 1.0582248875841962, 1.0550711162031052, 1.055968380074506, 1.050311218870241, 1.0482096391663838, 1.0468475355482785, 1.0451972272623908, 1.0439392508098535, 1.0417321975472342, 1.0412334122772937, 1.0410881794788305, 1.0401247493612378, 1.0400659921580693, 1.0407517732420626, 1.0385345329468927, 1.0403869207981045], 'val_losses': [1.5730692666854564, 1.553939707678934, 1.5218506016679523, 1.4378430191603497, 1.3690416536257741, 1.308696595446647, 1.2560200996235362, 1.2114794893952403, 1.1817207120705786, 1.1667956985040357, 1.1430759121998648, 1.1302671550577823, 1.1168983495022644, 1.1063445960052538, 1.0984800051340993, 1.091047150712352, 1.0838980503252515, 1.0779377291742471, 1.071204376212358, 1.0638667716819754, 1.0591886019765142, 1.054536792670341, 1.0501540127775242, 1.0463648498746787, 1.0430607862475871, 1.0403647302621555, 1.0385113448415721, 1.0358331129189593, 1.0344214285425595, 1.032649202492006, 1.0314170265264515, 1.0303976145665212, 1.0297565986778838, 1.0292828371360414, 1.0287256993569818, 1.0285451207746774, 1.028308803859106, 1.0282431167032404, 1.0282304338278951], 'val_acc': [0.23346167308365418, 0.35850542527126356, 0.356142807140357, 0.46876093804690233, 0.487924396219811, 0.5051627581379069, 0.5164508225411271, 0.5210885544277214, 0.5297514875743787, 0.5325516275813791, 0.5535526776338817, 0.5587154357717886, 0.5616030801540077, 0.5648407420371019, 0.567728386419321, 0.5708785439271964, 0.5706160308015401, 0.5735036751837592, 0.5748162408120406, 0.577616380819041, 0.5777038851942597, 0.580154007700385, 0.5806790339516976, 0.5818165908295415, 0.5823416170808541, 0.5826916345817291, 0.5828666433321666, 0.5839166958347918, 0.583829191459573, 0.5848792439621981, 0.5855792789639482, 0.5861043052152608, 0.5863668183409171, 0.5849667483374169, 0.585666783339167, 0.5854042702135107, 0.585666783339167, 0.5857542877143858, 0.5858417920896045], 'quantization': {'bits': 32, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 48344}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.977114825694412e-05, 'batch_size': 256, 'epochs': 39, 'weight_decay': 1.658376604028378e-07, 'dropout': 0.039712708204805665, 'grad_clip': 3.6147979764278664, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 8, 'gcn_hidden_dim': 15, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 11}, 'model_parameter_count': 9782, 'model_storage_size_kb': 42.03203125, 'model_size_validation': 'PASS'}
2025-10-13 03:26:35,692 - INFO - _models.training_function_executor - BO Objective: base=0.5858, size_penalty=0.0000, final=0.5858
2025-10-13 03:26:35,692 - INFO - _models.training_function_executor - Model: 9,782 parameters, 42.0KB (PASS 256KB limit)
2025-10-13 03:26:35,692 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 296.104s
2025-10-13 03:26:35,824 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5858
2025-10-13 03:26:35,824 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.114s
2025-10-13 03:26:35,824 - INFO - bo.run_bo - Recorded observation #40: hparams={'lr': 8.977114825694412e-05, 'batch_size': np.int64(256), 'epochs': np.int64(39), 'weight_decay': 1.658376604028378e-07, 'dropout': 0.039712708204805665, 'grad_clip': 3.6147979764278664, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(8), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(11)}, value=0.5858
2025-10-13 03:26:35,824 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 40: {'lr': 8.977114825694412e-05, 'batch_size': np.int64(256), 'epochs': np.int64(39), 'weight_decay': 1.658376604028378e-07, 'dropout': 0.039712708204805665, 'grad_clip': 3.6147979764278664, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(8), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(11)} -> 0.5858
2025-10-13 03:26:35,825 - INFO - bo.run_bo - üîçBO Trial 41: Using RF surrogate + Expected Improvement
2025-10-13 03:26:35,825 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:26:35,825 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 41 (NaN monitoring active)
2025-10-13 03:26:35,825 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:26:35,825 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:26:35,825 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0034649096920132114, 'batch_size': 32, 'epochs': 8, 'weight_decay': 5.517598896447052e-07, 'dropout': 0.14043910186901862, 'grad_clip': 1.6558548234185075, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 12, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 7}
2025-10-13 03:26:35,826 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0034649096920132114, 'batch_size': 32, 'epochs': 8, 'weight_decay': 5.517598896447052e-07, 'dropout': 0.14043910186901862, 'grad_clip': 1.6558548234185075, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 12, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 7}
2025-10-13 03:26:50,012 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.01573 val_loss=0.78281 val_acc=0.6733 time=14.2s
2025-10-13 03:26:59,450 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.76879 val_loss=0.86478 val_acc=0.6551 time=9.4s
2025-10-13 03:27:08,880 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.69304 val_loss=0.58879 val_acc=0.7609 time=9.4s
2025-10-13 03:27:18,314 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.64955 val_loss=0.63570 val_acc=0.7544 time=9.4s
2025-10-13 03:27:27,741 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.61808 val_loss=0.56982 val_acc=0.7756 time=9.4s
2025-10-13 03:27:37,157 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.59116 val_loss=0.57564 val_acc=0.7812 time=9.4s
2025-10-13 03:27:46,561 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.56802 val_loss=0.53757 val_acc=0.7819 time=9.4s
2025-10-13 03:27:55,959 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.55252 val_loss=0.52071 val_acc=0.7876 time=9.4s
2025-10-13 03:27:57,116 - INFO - _models.training_function_executor - Model: 13,343 parameters, 57.3KB storage
2025-10-13 03:27:57,116 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.015730382326311, 0.7687933811742524, 0.6930383444666904, 0.6495525879400111, 0.6180774230388733, 0.5911578427547752, 0.568023294898902, 0.5525220899386635], 'val_losses': [0.7828060559430321, 0.8647810010214055, 0.5887861460457743, 0.6357016857839941, 0.5698245585715809, 0.5756408130638575, 0.537574505405406, 0.520707463087383], 'val_acc': [0.6732586629331466, 0.6551452572628631, 0.7608505425271264, 0.754375218760938, 0.7755512775638782, 0.7812390619530977, 0.781851592579629, 0.7876268813440672], 'quantization': {'bits': 8, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 58556}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0034649096920132114, 'batch_size': 32, 'epochs': 8, 'weight_decay': 5.517598896447052e-07, 'dropout': 0.14043910186901862, 'grad_clip': 1.6558548234185075, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 5, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 12, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 7}, 'model_parameter_count': 13343, 'model_storage_size_kb': 57.333203125000004, 'model_size_validation': 'PASS'}
2025-10-13 03:27:57,116 - INFO - _models.training_function_executor - BO Objective: base=0.7876, size_penalty=0.0000, final=0.7876
2025-10-13 03:27:57,117 - INFO - _models.training_function_executor - Model: 13,343 parameters, 57.3KB (PASS 256KB limit)
2025-10-13 03:27:57,117 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 81.292s
2025-10-13 03:27:57,237 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7876
2025-10-13 03:27:57,237 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.117s
2025-10-13 03:27:57,237 - INFO - bo.run_bo - Recorded observation #41: hparams={'lr': 0.0034649096920132114, 'batch_size': np.int64(32), 'epochs': np.int64(8), 'weight_decay': 5.517598896447052e-07, 'dropout': 0.14043910186901862, 'grad_clip': 1.6558548234185075, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(12), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(7)}, value=0.7876
2025-10-13 03:27:57,237 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 41: {'lr': 0.0034649096920132114, 'batch_size': np.int64(32), 'epochs': np.int64(8), 'weight_decay': 5.517598896447052e-07, 'dropout': 0.14043910186901862, 'grad_clip': 1.6558548234185075, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(12), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(7)} -> 0.7876
2025-10-13 03:27:57,238 - INFO - bo.run_bo - üîçBO Trial 42: Using RF surrogate + Expected Improvement
2025-10-13 03:27:57,238 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:27:57,238 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 42 (NaN monitoring active)
2025-10-13 03:27:57,238 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:27:57,238 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:27:57,238 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004392926686541046, 'batch_size': 256, 'epochs': 7, 'weight_decay': 3.880859976737164e-05, 'dropout': 0.12711522157718388, 'grad_clip': 2.589395928931149, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 03:27:57,239 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004392926686541046, 'batch_size': 256, 'epochs': 7, 'weight_decay': 3.880859976737164e-05, 'dropout': 0.12711522157718388, 'grad_clip': 2.589395928931149, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 10}
2025-10-13 03:28:08,886 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.29988 val_loss=1.04591 val_acc=0.5863 time=11.6s
2025-10-13 03:28:17,757 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.99124 val_loss=0.86669 val_acc=0.6619 time=8.9s
2025-10-13 03:28:26,621 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.87267 val_loss=0.79400 val_acc=0.6943 time=8.9s
2025-10-13 03:28:35,502 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.81560 val_loss=0.75014 val_acc=0.7064 time=8.9s
2025-10-13 03:28:44,377 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.77014 val_loss=0.73127 val_acc=0.7140 time=8.9s
2025-10-13 03:28:53,267 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.74085 val_loss=0.71433 val_acc=0.7246 time=8.9s
2025-10-13 03:29:02,154 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.72967 val_loss=0.69580 val_acc=0.7274 time=8.9s
2025-10-13 03:29:03,312 - INFO - _models.training_function_executor - Model: 11,612 parameters, 49.9KB storage
2025-10-13 03:29:03,312 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.29988398746381, 0.9912371347740809, 0.8726704443172846, 0.8156048158352551, 0.7701435590858513, 0.740853903883606, 0.7296686903930519], 'val_losses': [1.0459059926651557, 0.8666903279359248, 0.794002343755441, 0.7501356877310943, 0.7312709102899326, 0.7143300688471208, 0.6958016180307831], 'val_acc': [0.5862793139656983, 0.6618830941547077, 0.694347217360868, 0.706422821141057, 0.7140357017850892, 0.7246237311865593, 0.7274238711935597], 'quantization': {'bits': 16, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 25024}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004392926686541046, 'batch_size': 256, 'epochs': 7, 'weight_decay': 3.880859976737164e-05, 'dropout': 0.12711522157718388, 'grad_clip': 2.589395928931149, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 3, 'partitions': 5, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 10}, 'model_parameter_count': 11612, 'model_storage_size_kb': 49.8953125, 'model_size_validation': 'PASS'}
2025-10-13 03:29:03,312 - INFO - _models.training_function_executor - BO Objective: base=0.7274, size_penalty=0.0000, final=0.7274
2025-10-13 03:29:03,312 - INFO - _models.training_function_executor - Model: 11,612 parameters, 49.9KB (PASS 256KB limit)
2025-10-13 03:29:03,312 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 66.074s
2025-10-13 03:29:03,457 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7274
2025-10-13 03:29:03,457 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.116s
2025-10-13 03:29:03,457 - INFO - bo.run_bo - Recorded observation #42: hparams={'lr': 0.004392926686541046, 'batch_size': np.int64(256), 'epochs': np.int64(7), 'weight_decay': 3.880859976737164e-05, 'dropout': 0.12711522157718388, 'grad_clip': 2.589395928931149, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)}, value=0.7274
2025-10-13 03:29:03,457 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 42: {'lr': 0.004392926686541046, 'batch_size': np.int64(256), 'epochs': np.int64(7), 'weight_decay': 3.880859976737164e-05, 'dropout': 0.12711522157718388, 'grad_clip': 2.589395928931149, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(10)} -> 0.7274
2025-10-13 03:29:03,458 - INFO - bo.run_bo - üîçBO Trial 43: Using RF surrogate + Expected Improvement
2025-10-13 03:29:03,458 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:29:03,458 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 43 (NaN monitoring active)
2025-10-13 03:29:03,458 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:29:03,458 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:29:03,458 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0019203590294280771, 'batch_size': 128, 'epochs': 16, 'weight_decay': 3.1293337295870316e-07, 'dropout': 0.1144308431845211, 'grad_clip': 2.2108856896084053, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 22}
2025-10-13 03:29:03,459 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0019203590294280771, 'batch_size': 128, 'epochs': 16, 'weight_decay': 3.1293337295870316e-07, 'dropout': 0.1144308431845211, 'grad_clip': 2.2108856896084053, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 22}
2025-10-13 03:29:18,912 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.27220 val_loss=1.01637 val_acc=0.5796 time=15.5s
2025-10-13 03:29:26,354 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.93838 val_loss=0.84271 val_acc=0.6540 time=7.4s
2025-10-13 03:29:33,806 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.83024 val_loss=0.81486 val_acc=0.6821 time=7.5s
2025-10-13 03:29:41,255 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.79191 val_loss=0.74664 val_acc=0.6968 time=7.4s
2025-10-13 03:29:48,706 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.74723 val_loss=0.77090 val_acc=0.6886 time=7.5s
2025-10-13 03:29:56,144 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.72097 val_loss=0.66990 val_acc=0.7300 time=7.4s
2025-10-13 03:30:03,573 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.69102 val_loss=0.64570 val_acc=0.7430 time=7.4s
2025-10-13 03:30:11,028 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.66920 val_loss=0.66516 val_acc=0.7323 time=7.5s
2025-10-13 03:30:18,473 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.64836 val_loss=0.62671 val_acc=0.7479 time=7.4s
2025-10-13 03:30:25,926 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.62987 val_loss=0.61920 val_acc=0.7548 time=7.5s
2025-10-13 03:30:33,377 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.61839 val_loss=0.61732 val_acc=0.7574 time=7.5s
2025-10-13 03:30:40,824 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.60753 val_loss=0.58818 val_acc=0.7638 time=7.4s
2025-10-13 03:30:48,273 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.59828 val_loss=0.58176 val_acc=0.7711 time=7.4s
2025-10-13 03:30:55,719 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.58996 val_loss=0.58049 val_acc=0.7686 time=7.4s
2025-10-13 03:31:03,171 - INFO - _models.training_function_executor - Epoch 015: train_loss=0.58670 val_loss=0.57556 val_acc=0.7729 time=7.5s
2025-10-13 03:31:10,611 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.58530 val_loss=0.57230 val_acc=0.7716 time=7.4s
2025-10-13 03:31:11,770 - INFO - _models.training_function_executor - Model: 10,030 parameters, 43.1KB storage
2025-10-13 03:31:11,770 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.272197948455143, 0.9383817632005562, 0.8302355019579745, 0.7919086523726974, 0.7472269611839318, 0.7209701556445086, 0.6910163146614152, 0.6691959811792451, 0.648358696859785, 0.6298674717623745, 0.6183902254607822, 0.6075306358477599, 0.5982776806410435, 0.5899640251633, 0.5867000617970943, 0.5852979957786189], 'val_losses': [1.0163653776033967, 0.8427119222728782, 0.814860674668994, 0.7466417041991531, 0.7709012478224915, 0.6698998643628442, 0.6456999282424668, 0.6651615764362895, 0.6267132701721899, 0.6191994613978593, 0.6173219764236808, 0.5881778739280621, 0.5817609742716722, 0.5804872622763647, 0.5755638820039337, 0.5723020894818678], 'val_acc': [0.5796289814490725, 0.6540077003850192, 0.6820966048302415, 0.6967973398669933, 0.6885719285964298, 0.7299614980749037, 0.7429996499824991, 0.7323241162058103, 0.7478998949947497, 0.7548127406370319, 0.7573503675183759, 0.7638256912845642, 0.7710885544277214, 0.7685509275463773, 0.7729261463073154, 0.771613580679034], 'quantization': {'bits': 32, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 43720}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0019203590294280771, 'batch_size': 128, 'epochs': 16, 'weight_decay': 3.1293337295870316e-07, 'dropout': 0.1144308431845211, 'grad_clip': 2.2108856896084053, 'use_amp': True, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 5, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 22}, 'model_parameter_count': 10030, 'model_storage_size_kb': 43.09765625, 'model_size_validation': 'PASS'}
2025-10-13 03:31:11,770 - INFO - _models.training_function_executor - BO Objective: base=0.7716, size_penalty=0.0000, final=0.7716
2025-10-13 03:31:11,771 - INFO - _models.training_function_executor - Model: 10,030 parameters, 43.1KB (PASS 256KB limit)
2025-10-13 03:31:11,771 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 128.313s
2025-10-13 03:31:11,899 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7716
2025-10-13 03:31:11,900 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.118s
2025-10-13 03:31:11,900 - INFO - bo.run_bo - Recorded observation #43: hparams={'lr': 0.0019203590294280771, 'batch_size': np.int64(128), 'epochs': np.int64(16), 'weight_decay': 3.1293337295870316e-07, 'dropout': 0.1144308431845211, 'grad_clip': 2.2108856896084053, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(22)}, value=0.7716
2025-10-13 03:31:11,900 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 43: {'lr': 0.0019203590294280771, 'batch_size': np.int64(128), 'epochs': np.int64(16), 'weight_decay': 3.1293337295870316e-07, 'dropout': 0.1144308431845211, 'grad_clip': 2.2108856896084053, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(5), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(22)} -> 0.7716
2025-10-13 03:31:11,900 - INFO - bo.run_bo - üîçBO Trial 44: Using RF surrogate + Expected Improvement
2025-10-13 03:31:11,900 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:31:11,900 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 44 (NaN monitoring active)
2025-10-13 03:31:11,900 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:31:11,900 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:31:11,900 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0033807266416395, 'batch_size': 128, 'epochs': 14, 'weight_decay': 6.052278837309234e-07, 'dropout': 0.2762679495942097, 'grad_clip': 1.010985249110741, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 27}
2025-10-13 03:31:11,902 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0033807266416395, 'batch_size': 128, 'epochs': 14, 'weight_decay': 6.052278837309234e-07, 'dropout': 0.2762679495942097, 'grad_clip': 1.010985249110741, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 27}
2025-10-13 03:31:24,321 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.21805 val_loss=1.04877 val_acc=0.5871 time=12.4s
2025-10-13 03:31:33,912 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.93413 val_loss=0.85041 val_acc=0.6357 time=9.6s
2025-10-13 03:31:43,516 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.85917 val_loss=0.75801 val_acc=0.6811 time=9.6s
2025-10-13 03:31:53,106 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.80246 val_loss=0.70059 val_acc=0.7236 time=9.6s
2025-10-13 03:32:02,702 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.76978 val_loss=0.66127 val_acc=0.7370 time=9.6s
2025-10-13 03:32:12,295 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.73910 val_loss=0.67666 val_acc=0.7354 time=9.6s
2025-10-13 03:32:21,889 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.70849 val_loss=0.61503 val_acc=0.7595 time=9.6s
2025-10-13 03:32:31,490 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.69037 val_loss=0.60223 val_acc=0.7630 time=9.6s
2025-10-13 03:32:41,086 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.67158 val_loss=0.62147 val_acc=0.7516 time=9.6s
2025-10-13 03:32:50,691 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.65114 val_loss=0.60334 val_acc=0.7630 time=9.6s
2025-10-13 03:33:00,289 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.64514 val_loss=0.57078 val_acc=0.7757 time=9.6s
2025-10-13 03:33:09,885 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.63134 val_loss=0.56857 val_acc=0.7767 time=9.6s
2025-10-13 03:33:19,491 - INFO - _models.training_function_executor - Epoch 013: train_loss=0.62682 val_loss=0.56246 val_acc=0.7772 time=9.6s
2025-10-13 03:33:29,089 - INFO - _models.training_function_executor - Epoch 014: train_loss=0.62094 val_loss=0.55923 val_acc=0.7759 time=9.6s
2025-10-13 03:33:30,262 - INFO - _models.training_function_executor - Model: 12,473 parameters, 53.6KB storage
2025-10-13 03:33:30,262 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2180461530965818, 0.9341303730161198, 0.8591743767741347, 0.8024604730686192, 0.7697843425771261, 0.7391005236033505, 0.7084878045944305, 0.6903740864013682, 0.6715845020867997, 0.651136961065058, 0.6451365836316737, 0.6313405472956047, 0.6268195131253145, 0.6209368849284673], 'val_losses': [1.048765212558223, 0.850405417041091, 0.7580136842856176, 0.7005850748036098, 0.6612663915785701, 0.6766553911288218, 0.6150280000615211, 0.6022311288408354, 0.6214707370275044, 0.6033380620538834, 0.5707822560137454, 0.5685743001694857, 0.5624617470867116, 0.5592327783439057], 'val_acc': [0.5870668533426672, 0.6357192859642982, 0.6811340567028351, 0.7235736786839342, 0.7369618480924046, 0.7353867693384669, 0.759537976898845, 0.7629506475323766, 0.7515750787539377, 0.7629506475323766, 0.7757262863143157, 0.7766888344417221, 0.7772138606930347, 0.7759012950647532], 'quantization': {'bits': 32, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 52196}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0033807266416395, 'batch_size': 128, 'epochs': 14, 'weight_decay': 6.052278837309234e-07, 'dropout': 0.2762679495942097, 'grad_clip': 1.010985249110741, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 7, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 27}, 'model_parameter_count': 12473, 'model_storage_size_kb': 53.594921875000004, 'model_size_validation': 'PASS'}
2025-10-13 03:33:30,262 - INFO - _models.training_function_executor - BO Objective: base=0.7759, size_penalty=0.0000, final=0.7759
2025-10-13 03:33:30,262 - INFO - _models.training_function_executor - Model: 12,473 parameters, 53.6KB (PASS 256KB limit)
2025-10-13 03:33:30,262 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 138.362s
2025-10-13 03:33:30,399 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7759
2025-10-13 03:33:30,399 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.116s
2025-10-13 03:33:30,399 - INFO - bo.run_bo - Recorded observation #44: hparams={'lr': 0.0033807266416395, 'batch_size': np.int64(128), 'epochs': np.int64(14), 'weight_decay': 6.052278837309234e-07, 'dropout': 0.2762679495942097, 'grad_clip': 1.010985249110741, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(27)}, value=0.7759
2025-10-13 03:33:30,399 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 44: {'lr': 0.0033807266416395, 'batch_size': np.int64(128), 'epochs': np.int64(14), 'weight_decay': 6.052278837309234e-07, 'dropout': 0.2762679495942097, 'grad_clip': 1.010985249110741, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(27)} -> 0.7759
2025-10-13 03:33:30,400 - INFO - bo.run_bo - üîçBO Trial 45: Using RF surrogate + Expected Improvement
2025-10-13 03:33:30,400 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 03:33:30,400 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 45 (NaN monitoring active)
2025-10-13 03:33:30,400 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:33:30,400 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:33:30,400 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00020247221885531634, 'batch_size': 256, 'epochs': 18, 'weight_decay': 2.5798177328149865e-07, 'dropout': 0.14745173492616362, 'grad_clip': 0.6858107136034121, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 5, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 22}
2025-10-13 03:33:30,401 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00020247221885531634, 'batch_size': 256, 'epochs': 18, 'weight_decay': 2.5798177328149865e-07, 'dropout': 0.14745173492616362, 'grad_clip': 0.6858107136034121, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 5, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 22}
2025-10-13 03:33:42,829 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.56197 val_loss=1.53741 val_acc=0.3355 time=12.4s
2025-10-13 03:33:52,458 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.50731 val_loss=1.44786 val_acc=0.4426 time=9.6s
2025-10-13 03:34:02,083 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.38232 val_loss=1.28845 val_acc=0.5245 time=9.6s
2025-10-13 03:34:11,700 - INFO - _models.training_function_executor - Epoch 004: train_loss=1.23770 val_loss=1.16650 val_acc=0.5499 time=9.6s
2025-10-13 03:34:21,306 - INFO - _models.training_function_executor - Epoch 005: train_loss=1.15900 val_loss=1.10705 val_acc=0.5564 time=9.6s
2025-10-13 03:34:30,929 - INFO - _models.training_function_executor - Epoch 006: train_loss=1.11232 val_loss=1.06724 val_acc=0.5757 time=9.6s
2025-10-13 03:34:40,562 - INFO - _models.training_function_executor - Epoch 007: train_loss=1.07948 val_loss=1.04319 val_acc=0.5872 time=9.6s
2025-10-13 03:34:50,192 - INFO - _models.training_function_executor - Epoch 008: train_loss=1.06088 val_loss=1.02567 val_acc=0.5928 time=9.6s
2025-10-13 03:34:59,820 - INFO - _models.training_function_executor - Epoch 009: train_loss=1.04439 val_loss=1.01793 val_acc=0.5998 time=9.6s
2025-10-13 03:35:09,448 - INFO - _models.training_function_executor - Epoch 010: train_loss=1.02751 val_loss=1.00381 val_acc=0.6022 time=9.6s
2025-10-13 03:35:19,083 - INFO - _models.training_function_executor - Epoch 011: train_loss=1.01737 val_loss=1.01039 val_acc=0.6003 time=9.6s
2025-10-13 03:35:28,705 - INFO - _models.training_function_executor - Epoch 012: train_loss=1.01591 val_loss=0.99140 val_acc=0.6074 time=9.6s
2025-10-13 03:35:38,316 - INFO - _models.training_function_executor - Epoch 013: train_loss=1.00435 val_loss=0.98932 val_acc=0.6061 time=9.6s
2025-10-13 03:35:47,919 - INFO - _models.training_function_executor - Epoch 014: train_loss=1.00172 val_loss=0.98452 val_acc=0.6086 time=9.6s
2025-10-13 03:35:57,542 - INFO - _models.training_function_executor - Epoch 015: train_loss=1.00150 val_loss=0.98237 val_acc=0.6101 time=9.6s
2025-10-13 03:36:07,164 - INFO - _models.training_function_executor - Epoch 016: train_loss=0.99740 val_loss=0.98062 val_acc=0.6096 time=9.6s
2025-10-13 03:36:16,776 - INFO - _models.training_function_executor - Epoch 017: train_loss=0.99955 val_loss=0.97987 val_acc=0.6098 time=9.6s
2025-10-13 03:36:26,398 - INFO - _models.training_function_executor - Epoch 018: train_loss=0.99701 val_loss=0.97962 val_acc=0.6097 time=9.6s
2025-10-13 03:36:27,559 - INFO - _models.training_function_executor - Model: 13,707 parameters, 58.9KB storage
2025-10-13 03:36:27,559 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5619665247433496, 1.5073143273414662, 1.3823178374437672, 1.2377037659031884, 1.158997287231181, 1.1123204825013762, 1.0794766086108374, 1.0608795150243446, 1.044386130802941, 1.027507631103601, 1.0173749095875357, 1.0159093675640107, 1.0043544872348693, 1.001717947645124, 1.001501150676993, 0.9974023516794832, 0.9995504898919816, 0.9970108459452294], 'val_losses': [1.537410603564312, 1.447864567686888, 1.2884481321651284, 1.1665031912863402, 1.1070539090113494, 1.067236262015375, 1.0431850137183163, 1.0256743534361519, 1.0179348641815493, 1.0038102607565156, 1.0103854702659782, 0.9914032616605282, 0.9893249667813238, 0.9845210998927041, 0.982367012627608, 0.9806208050580637, 0.9798657044606648, 0.9796224883856955], 'val_acc': [0.3354917745887294, 0.4425971298564928, 0.5245012250612531, 0.5498774938746938, 0.5563528176408821, 0.5756912845642282, 0.5872418620931047, 0.5927546377318866, 0.5998424921246063, 0.6022051102555128, 0.6002800140007001, 0.6073678683934197, 0.6061428071403571, 0.6085929296464824, 0.6100805040252013, 0.6096429821491075, 0.609817990899545, 0.6097304865243263], 'quantization': {'bits': 32, 'weights': True, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 60012}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00020247221885531634, 'batch_size': 256, 'epochs': 18, 'weight_decay': 2.5798177328149865e-07, 'dropout': 0.14745173492616362, 'grad_clip': 0.6858107136034121, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 9, 'kernel_size_dec': 5, 'partitions': 6, 'gcn_hidden_dim': 16, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'calib_batches': 22}, 'model_parameter_count': 13707, 'model_storage_size_kb': 58.897265625, 'model_size_validation': 'PASS'}
2025-10-13 03:36:27,559 - INFO - _models.training_function_executor - BO Objective: base=0.6097, size_penalty=0.0000, final=0.6097
2025-10-13 03:36:27,559 - INFO - _models.training_function_executor - Model: 13,707 parameters, 58.9KB (PASS 256KB limit)
2025-10-13 03:36:27,559 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 177.159s
2025-10-13 03:36:28,041 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6097
2025-10-13 03:36:28,042 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.451s
2025-10-13 03:36:28,042 - INFO - bo.run_bo - Recorded observation #45: hparams={'lr': 0.00020247221885531634, 'batch_size': np.int64(256), 'epochs': np.int64(18), 'weight_decay': 2.5798177328149865e-07, 'dropout': 0.14745173492616362, 'grad_clip': 0.6858107136034121, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(22)}, value=0.6097
2025-10-13 03:36:28,042 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 45: {'lr': 0.00020247221885531634, 'batch_size': np.int64(256), 'epochs': np.int64(18), 'weight_decay': 2.5798177328149865e-07, 'dropout': 0.14745173492616362, 'grad_clip': 0.6858107136034121, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'calib_batches': np.int64(22)} -> 0.6097
2025-10-13 03:36:28,042 - INFO - bo.run_bo - üîçBO Trial 46: Using RF surrogate + Expected Improvement
2025-10-13 03:36:28,042 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 03:36:28,042 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 46 (NaN monitoring active)
2025-10-13 03:36:28,042 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:36:28,042 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:36:28,042 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0026192692174727213, 'batch_size': 32, 'epochs': 8, 'weight_decay': 4.9589403683765e-07, 'dropout': 0.17695394683084362, 'grad_clip': 3.5478354630458875, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 5, 'partitions': 12, 'gcn_hidden_dim': 12, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 30}
2025-10-13 03:36:28,046 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0026192692174727213, 'batch_size': 32, 'epochs': 8, 'weight_decay': 4.9589403683765e-07, 'dropout': 0.17695394683084362, 'grad_clip': 3.5478354630458875, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 5, 'partitions': 12, 'gcn_hidden_dim': 12, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 30}
2025-10-13 03:36:41,929 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.05141 val_loss=0.84644 val_acc=0.6479 time=13.9s
2025-10-13 03:36:53,001 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.84632 val_loss=0.79428 val_acc=0.6723 time=11.1s
2025-10-13 03:37:04,074 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.76936 val_loss=0.67526 val_acc=0.7244 time=11.1s
2025-10-13 03:37:15,153 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.70622 val_loss=0.62795 val_acc=0.7476 time=11.1s
2025-10-13 03:37:26,238 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.67271 val_loss=0.61340 val_acc=0.7614 time=11.1s
2025-10-13 03:37:37,313 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.64177 val_loss=0.63831 val_acc=0.7454 time=11.1s
2025-10-13 03:37:48,387 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.62265 val_loss=0.56228 val_acc=0.7827 time=11.1s
2025-10-13 03:37:59,456 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.59693 val_loss=0.55429 val_acc=0.7826 time=11.1s
2025-10-13 03:38:00,591 - INFO - _models.training_function_executor - Model: 13,539 parameters, 58.2KB storage
2025-10-13 03:38:00,591 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.051413857857581, 0.8463232994788921, 0.7693575155205105, 0.706216479040419, 0.6727098254085964, 0.6417716515619186, 0.6226483363453474, 0.5969306263299434], 'val_losses': [0.8464390833477144, 0.7942820677483545, 0.6752624084034039, 0.6279519260200872, 0.6134047197594608, 0.6383127962996337, 0.5622801264141004, 0.5542854620812029], 'val_acc': [0.6478823941197059, 0.6722961148057403, 0.724361218060903, 0.7476373818690935, 0.7613755687784389, 0.7454497724886244, 0.7827266363318166, 0.7826391319565978], 'quantization': {'bits': 32, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 74892}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0026192692174727213, 'batch_size': 32, 'epochs': 8, 'weight_decay': 4.9589403683765e-07, 'dropout': 0.17695394683084362, 'grad_clip': 3.5478354630458875, 'use_amp': False, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 5, 'partitions': 12, 'gcn_hidden_dim': 12, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 30}, 'model_parameter_count': 13539, 'model_storage_size_kb': 58.175390625000006, 'model_size_validation': 'PASS'}
2025-10-13 03:38:00,591 - INFO - _models.training_function_executor - BO Objective: base=0.7826, size_penalty=0.0000, final=0.7826
2025-10-13 03:38:00,591 - INFO - _models.training_function_executor - Model: 13,539 parameters, 58.2KB (PASS 256KB limit)
2025-10-13 03:38:00,591 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 92.549s
2025-10-13 03:38:00,719 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7826
2025-10-13 03:38:00,719 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.120s
2025-10-13 03:38:00,719 - INFO - bo.run_bo - Recorded observation #46: hparams={'lr': 0.0026192692174727213, 'batch_size': np.int64(32), 'epochs': np.int64(8), 'weight_decay': 4.9589403683765e-07, 'dropout': 0.17695394683084362, 'grad_clip': 3.5478354630458875, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(12), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(30)}, value=0.7826
2025-10-13 03:38:00,719 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 46: {'lr': 0.0026192692174727213, 'batch_size': np.int64(32), 'epochs': np.int64(8), 'weight_decay': 4.9589403683765e-07, 'dropout': 0.17695394683084362, 'grad_clip': 3.5478354630458875, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(12), 'gcn_hidden_dim': np.int64(12), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(30)} -> 0.7826
2025-10-13 03:38:00,720 - INFO - bo.run_bo - üîçBO Trial 47: Using RF surrogate + Expected Improvement
2025-10-13 03:38:00,720 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 03:38:00,720 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 47 (NaN monitoring active)
2025-10-13 03:38:00,720 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:38:00,720 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:38:00,720 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0033686994436349376, 'batch_size': 128, 'epochs': 9, 'weight_decay': 3.1946147051797744e-06, 'dropout': 0.19842017505672738, 'grad_clip': 4.675022320893094, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 13, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 14}
2025-10-13 03:38:00,721 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0033686994436349376, 'batch_size': 128, 'epochs': 9, 'weight_decay': 3.1946147051797744e-06, 'dropout': 0.19842017505672738, 'grad_clip': 4.675022320893094, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 13, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 14}
2025-10-13 03:38:12,043 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.22958 val_loss=0.94481 val_acc=0.6049 time=11.3s
2025-10-13 03:38:20,558 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.94591 val_loss=0.91069 val_acc=0.6382 time=8.5s
2025-10-13 03:38:29,075 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.85399 val_loss=0.76898 val_acc=0.6880 time=8.5s
2025-10-13 03:38:37,596 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.80312 val_loss=0.74106 val_acc=0.7095 time=8.5s
2025-10-13 03:38:46,111 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.75118 val_loss=0.70389 val_acc=0.7187 time=8.5s
2025-10-13 03:38:54,629 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.71513 val_loss=0.68084 val_acc=0.7394 time=8.5s
2025-10-13 03:39:03,148 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.68512 val_loss=0.64661 val_acc=0.7420 time=8.5s
2025-10-13 03:39:11,669 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.66160 val_loss=0.63423 val_acc=0.7519 time=8.5s
2025-10-13 03:39:20,193 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.65254 val_loss=0.62023 val_acc=0.7565 time=8.5s
2025-10-13 03:39:21,290 - INFO - _models.training_function_executor - Model: 9,770 parameters, 42.0KB storage
2025-10-13 03:39:21,290 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2295825853187552, 0.9459109319270304, 0.8539857303591345, 0.8031221513444409, 0.7511841176396531, 0.7151254280321991, 0.6851184443239152, 0.6615996220790301, 0.6525417761052452], 'val_losses': [0.9448069215947446, 0.9106929173492909, 0.7689767632611281, 0.7410591265351613, 0.7038856938789055, 0.6808416242569445, 0.6466093103410816, 0.6342346247234751, 0.6202289656320985], 'val_acc': [0.6049177458872944, 0.6381694084704235, 0.6880469023451172, 0.7094854742737137, 0.7186734336716836, 0.7394119705985299, 0.7420371018550928, 0.7519250962548127, 0.7564753237661883], 'quantization': {'bits': 8, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 41384}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0033686994436349376, 'batch_size': 128, 'epochs': 9, 'weight_decay': 3.1946147051797744e-06, 'dropout': 0.19842017505672738, 'grad_clip': 4.675022320893094, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 7, 'partitions': 4, 'gcn_hidden_dim': 13, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 14}, 'model_parameter_count': 9770, 'model_storage_size_kb': 41.98046875, 'model_size_validation': 'PASS'}
2025-10-13 03:39:21,290 - INFO - _models.training_function_executor - BO Objective: base=0.7565, size_penalty=0.0000, final=0.7565
2025-10-13 03:39:21,290 - INFO - _models.training_function_executor - Model: 9,770 parameters, 42.0KB (PASS 256KB limit)
2025-10-13 03:39:21,290 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 80.570s
2025-10-13 03:39:21,431 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7565
2025-10-13 03:39:21,431 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.119s
2025-10-13 03:39:21,431 - INFO - bo.run_bo - Recorded observation #47: hparams={'lr': 0.0033686994436349376, 'batch_size': np.int64(128), 'epochs': np.int64(9), 'weight_decay': 3.1946147051797744e-06, 'dropout': 0.19842017505672738, 'grad_clip': 4.675022320893094, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(13), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(14)}, value=0.7565
2025-10-13 03:39:21,431 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 47: {'lr': 0.0033686994436349376, 'batch_size': np.int64(128), 'epochs': np.int64(9), 'weight_decay': 3.1946147051797744e-06, 'dropout': 0.19842017505672738, 'grad_clip': 4.675022320893094, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(4), 'gcn_hidden_dim': np.int64(13), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(14)} -> 0.7565
2025-10-13 03:39:21,432 - INFO - bo.run_bo - üîçBO Trial 48: Using RF surrogate + Expected Improvement
2025-10-13 03:39:21,432 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 03:39:21,432 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 48 (NaN monitoring active)
2025-10-13 03:39:21,432 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:39:21,432 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:39:21,432 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0010194033390213747, 'batch_size': 256, 'epochs': 6, 'weight_decay': 5.162551400993056e-07, 'dropout': 0.16824091760834217, 'grad_clip': 1.8143921636230063, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 5, 'partitions': 8, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 24}
2025-10-13 03:39:21,433 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0010194033390213747, 'batch_size': 256, 'epochs': 6, 'weight_decay': 5.162551400993056e-07, 'dropout': 0.16824091760834217, 'grad_clip': 1.8143921636230063, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 5, 'partitions': 8, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 24}
2025-10-13 03:39:32,403 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.44181 val_loss=1.20201 val_acc=0.5212 time=11.0s
2025-10-13 03:39:40,568 - INFO - _models.training_function_executor - Epoch 002: train_loss=1.17510 val_loss=1.09008 val_acc=0.5550 time=8.2s
2025-10-13 03:39:48,723 - INFO - _models.training_function_executor - Epoch 003: train_loss=1.06107 val_loss=0.97723 val_acc=0.6008 time=8.2s
2025-10-13 03:39:56,868 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.98273 val_loss=0.92375 val_acc=0.6321 time=8.1s
2025-10-13 03:40:05,017 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.94729 val_loss=0.89501 val_acc=0.6410 time=8.1s
2025-10-13 03:40:13,161 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.92634 val_loss=0.88541 val_acc=0.6460 time=8.1s
2025-10-13 03:40:14,305 - INFO - _models.training_function_executor - Model: 9,612 parameters, 41.3KB storage
2025-10-13 03:40:14,305 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.441809749286159, 1.1751018498467114, 1.0610674877120017, 0.9827322354048, 0.9472912542879227, 0.9263385426635128], 'val_losses': [1.2020106188767767, 1.0900812951843346, 0.9772316255392542, 0.9237532624841195, 0.8950085064143954, 0.8854104262112653], 'val_acc': [0.5211760588029402, 0.5549527476373819, 0.6008050402520126, 0.632131606580329, 0.6409695484774238, 0.646044802240112], 'quantization': {'bits': 16, 'weights': False, 'activations': True, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 23832}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0010194033390213747, 'batch_size': 256, 'epochs': 6, 'weight_decay': 5.162551400993056e-07, 'dropout': 0.16824091760834217, 'grad_clip': 1.8143921636230063, 'use_amp': False, 'num_workers': 4, 'base_channels': 13, 'kernel_size_enc': 9, 'kernel_size_dec': 5, 'partitions': 8, 'gcn_hidden_dim': 15, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calib_batches': 24}, 'model_parameter_count': 9612, 'model_storage_size_kb': 41.3015625, 'model_size_validation': 'PASS'}
2025-10-13 03:40:14,305 - INFO - _models.training_function_executor - BO Objective: base=0.6460, size_penalty=0.0000, final=0.6460
2025-10-13 03:40:14,305 - INFO - _models.training_function_executor - Model: 9,612 parameters, 41.3KB (PASS 256KB limit)
2025-10-13 03:40:14,305 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 52.873s
2025-10-13 03:40:14,456 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6460
2025-10-13 03:40:14,456 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.120s
2025-10-13 03:40:14,456 - INFO - bo.run_bo - Recorded observation #48: hparams={'lr': 0.0010194033390213747, 'batch_size': np.int64(256), 'epochs': np.int64(6), 'weight_decay': 5.162551400993056e-07, 'dropout': 0.16824091760834217, 'grad_clip': 1.8143921636230063, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(8), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(24)}, value=0.6460
2025-10-13 03:40:14,456 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 48: {'lr': 0.0010194033390213747, 'batch_size': np.int64(256), 'epochs': np.int64(6), 'weight_decay': 5.162551400993056e-07, 'dropout': 0.16824091760834217, 'grad_clip': 1.8143921636230063, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(13), 'kernel_size_enc': np.int64(9), 'kernel_size_dec': np.int64(5), 'partitions': np.int64(8), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'calib_batches': np.int64(24)} -> 0.6460
2025-10-13 03:40:14,457 - INFO - bo.run_bo - üîçBO Trial 49: Using RF surrogate + Expected Improvement
2025-10-13 03:40:14,457 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 03:40:14,457 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 49 (NaN monitoring active)
2025-10-13 03:40:14,457 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:40:14,457 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:40:14,457 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00267082318077796, 'batch_size': 64, 'epochs': 12, 'weight_decay': 7.301447148289979e-07, 'dropout': 0.4087225693619313, 'grad_clip': 0.7285176460809019, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 5, 'kernel_size_dec': 3, 'partitions': 10, 'gcn_hidden_dim': 16, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 15}
2025-10-13 03:40:14,458 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00267082318077796, 'batch_size': 64, 'epochs': 12, 'weight_decay': 7.301447148289979e-07, 'dropout': 0.4087225693619313, 'grad_clip': 0.7285176460809019, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 5, 'kernel_size_dec': 3, 'partitions': 10, 'gcn_hidden_dim': 16, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 15}
2025-10-13 03:40:26,691 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.17688 val_loss=0.92452 val_acc=0.6122 time=12.2s
2025-10-13 03:40:35,960 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.92536 val_loss=0.77618 val_acc=0.6930 time=9.3s
2025-10-13 03:40:45,223 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.85414 val_loss=0.71526 val_acc=0.7090 time=9.3s
2025-10-13 03:40:54,491 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.80519 val_loss=0.71702 val_acc=0.7098 time=9.3s
2025-10-13 03:41:03,762 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.77783 val_loss=0.72567 val_acc=0.7195 time=9.3s
2025-10-13 03:41:13,040 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.75217 val_loss=0.63720 val_acc=0.7539 time=9.3s
2025-10-13 03:41:22,314 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.73655 val_loss=0.66256 val_acc=0.7306 time=9.3s
2025-10-13 03:41:31,583 - INFO - _models.training_function_executor - Epoch 008: train_loss=0.71436 val_loss=0.61187 val_acc=0.7560 time=9.3s
2025-10-13 03:41:40,855 - INFO - _models.training_function_executor - Epoch 009: train_loss=0.69771 val_loss=0.61486 val_acc=0.7553 time=9.3s
2025-10-13 03:41:50,117 - INFO - _models.training_function_executor - Epoch 010: train_loss=0.68990 val_loss=0.59821 val_acc=0.7636 time=9.3s
2025-10-13 03:41:59,393 - INFO - _models.training_function_executor - Epoch 011: train_loss=0.67809 val_loss=0.59305 val_acc=0.7628 time=9.3s
2025-10-13 03:42:08,671 - INFO - _models.training_function_executor - Epoch 012: train_loss=0.67829 val_loss=0.59069 val_acc=0.7645 time=9.3s
2025-10-13 03:42:09,849 - INFO - _models.training_function_executor - Model: 11,501 parameters, 49.4KB storage
2025-10-13 03:42:09,850 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1768752693670965, 0.9253587042238064, 0.8541374688887872, 0.8051915548254153, 0.7778332041075149, 0.7521696646062486, 0.7365495915341135, 0.7143589909943743, 0.6977103151847818, 0.6898988136512482, 0.6780899093832885, 0.6782925071773055], 'val_losses': [0.9245231320151175, 0.7761849486456495, 0.7152595753681422, 0.7170213378723326, 0.7256707181912183, 0.6371972842319971, 0.6625550368635814, 0.6118671417152878, 0.614863922807108, 0.5982065668546699, 0.5930495995677432, 0.5906901479309824], 'val_acc': [0.6121806090304516, 0.6930346517325866, 0.7090479523976199, 0.7098354917745887, 0.7194609730486524, 0.7538501925096255, 0.7305740287014351, 0.7559502975148757, 0.7552502625131257, 0.763563178158908, 0.7627756387819391, 0.7645257262863143], 'quantization': {'bits': 16, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 30202}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00267082318077796, 'batch_size': 64, 'epochs': 12, 'weight_decay': 7.301447148289979e-07, 'dropout': 0.4087225693619313, 'grad_clip': 0.7285176460809019, 'use_amp': False, 'num_workers': 4, 'base_channels': 15, 'kernel_size_enc': 5, 'kernel_size_dec': 3, 'partitions': 10, 'gcn_hidden_dim': 16, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 15}, 'model_parameter_count': 11501, 'model_storage_size_kb': 49.418359375, 'model_size_validation': 'PASS'}
2025-10-13 03:42:09,850 - INFO - _models.training_function_executor - BO Objective: base=0.7645, size_penalty=0.0000, final=0.7645
2025-10-13 03:42:09,850 - INFO - _models.training_function_executor - Model: 11,501 parameters, 49.4KB (PASS 256KB limit)
2025-10-13 03:42:09,850 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 115.393s
2025-10-13 03:42:09,983 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7645
2025-10-13 03:42:09,983 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.119s
2025-10-13 03:42:09,983 - INFO - bo.run_bo - Recorded observation #49: hparams={'lr': 0.00267082318077796, 'batch_size': np.int64(64), 'epochs': np.int64(12), 'weight_decay': 7.301447148289979e-07, 'dropout': 0.4087225693619313, 'grad_clip': 0.7285176460809019, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(15)}, value=0.7645
2025-10-13 03:42:09,983 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 49: {'lr': 0.00267082318077796, 'batch_size': np.int64(64), 'epochs': np.int64(12), 'weight_decay': 7.301447148289979e-07, 'dropout': 0.4087225693619313, 'grad_clip': 0.7285176460809019, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(15), 'kernel_size_enc': np.int64(5), 'kernel_size_dec': np.int64(3), 'partitions': np.int64(10), 'gcn_hidden_dim': np.int64(16), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(15)} -> 0.7645
2025-10-13 03:42:09,983 - INFO - bo.run_bo - üîçBO Trial 50: Using RF surrogate + Expected Improvement
2025-10-13 03:42:09,983 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 03:42:09,983 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 50 (NaN monitoring active)
2025-10-13 03:42:09,984 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:42:09,984 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny
2025-10-13 03:42:09,984 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0035499897827760947, 'batch_size': 128, 'epochs': 7, 'weight_decay': 1.3799651065771136e-06, 'dropout': 0.14341664838473864, 'grad_clip': 1.7251682824882384, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 14, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 32}
2025-10-13 03:42:09,985 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0035499897827760947, 'batch_size': 128, 'epochs': 7, 'weight_decay': 1.3799651065771136e-06, 'dropout': 0.14341664838473864, 'grad_clip': 1.7251682824882384, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 14, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 32}
2025-10-13 03:42:27,745 - INFO - _models.training_function_executor - Epoch 001: train_loss=1.16723 val_loss=0.86861 val_acc=0.6411 time=17.8s
2025-10-13 03:42:36,113 - INFO - _models.training_function_executor - Epoch 002: train_loss=0.84683 val_loss=0.74272 val_acc=0.7030 time=8.4s
2025-10-13 03:42:44,476 - INFO - _models.training_function_executor - Epoch 003: train_loss=0.73707 val_loss=0.67368 val_acc=0.7280 time=8.4s
2025-10-13 03:42:52,834 - INFO - _models.training_function_executor - Epoch 004: train_loss=0.69415 val_loss=0.66248 val_acc=0.7422 time=8.4s
2025-10-13 03:43:01,202 - INFO - _models.training_function_executor - Epoch 005: train_loss=0.66160 val_loss=0.64491 val_acc=0.7380 time=8.4s
2025-10-13 03:43:09,587 - INFO - _models.training_function_executor - Epoch 006: train_loss=0.64187 val_loss=0.63558 val_acc=0.7475 time=8.4s
2025-10-13 03:43:17,980 - INFO - _models.training_function_executor - Epoch 007: train_loss=0.62195 val_loss=0.59392 val_acc=0.7640 time=8.4s
2025-10-13 03:43:19,147 - INFO - _models.training_function_executor - Model: 14,131 parameters, 60.7KB storage
2025-10-13 03:43:19,147 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1672307510746498, 0.8468325809869977, 0.7370701644818684, 0.6941475299926, 0.6615953330272638, 0.6418677166620668, 0.6219488497918663], 'val_losses': [0.868609817995239, 0.7427234476498052, 0.6736819427414795, 0.6624838878610229, 0.6449124265434778, 0.6355839280094098, 0.5939160620035473], 'val_acc': [0.6410570528526426, 0.7030101505075254, 0.728036401820091, 0.7422121106055303, 0.7380119005950297, 0.7475498774938747, 0.7640007000350018], 'quantization': {'bits': 8, 'weights': False, 'activations': False, 'static_ptq_used': False, 'estimated_state_dict_size_bytes': 61708}, 'model_name': 'ST-USleepNet-Tiny', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0035499897827760947, 'batch_size': 128, 'epochs': 7, 'weight_decay': 1.3799651065771136e-06, 'dropout': 0.14341664838473864, 'grad_clip': 1.7251682824882384, 'use_amp': True, 'num_workers': 4, 'base_channels': 16, 'kernel_size_enc': 11, 'kernel_size_dec': 7, 'partitions': 6, 'gcn_hidden_dim': 14, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calib_batches': 32}, 'model_parameter_count': 14131, 'model_storage_size_kb': 60.719140625, 'model_size_validation': 'PASS'}
2025-10-13 03:43:19,147 - INFO - _models.training_function_executor - BO Objective: base=0.7640, size_penalty=0.0000, final=0.7640
2025-10-13 03:43:19,147 - INFO - _models.training_function_executor - Model: 14,131 parameters, 60.7KB (PASS 256KB limit)
2025-10-13 03:43:19,147 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 69.163s
2025-10-13 03:43:19,280 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7640
2025-10-13 03:43:19,280 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.121s
2025-10-13 03:43:19,280 - INFO - bo.run_bo - Recorded observation #50: hparams={'lr': 0.0035499897827760947, 'batch_size': np.int64(128), 'epochs': np.int64(7), 'weight_decay': 1.3799651065771136e-06, 'dropout': 0.14341664838473864, 'grad_clip': 1.7251682824882384, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(32)}, value=0.7640
2025-10-13 03:43:19,280 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 50: {'lr': 0.0035499897827760947, 'batch_size': np.int64(128), 'epochs': np.int64(7), 'weight_decay': 1.3799651065771136e-06, 'dropout': 0.14341664838473864, 'grad_clip': 1.7251682824882384, 'use_amp': np.True_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(11), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(14), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(32)} -> 0.7640
2025-10-13 03:43:19,280 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.7908
2025-10-13 03:43:19,280 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.0033103996767633384, 'batch_size': np.int64(32), 'epochs': np.int64(7), 'weight_decay': 1.357496208874004e-06, 'dropout': 0.20225254735056641, 'grad_clip': 4.159824096647204, 'use_amp': np.False_, 'num_workers': np.int64(4), 'base_channels': np.int64(16), 'kernel_size_enc': np.int64(7), 'kernel_size_dec': np.int64(7), 'partitions': np.int64(6), 'gcn_hidden_dim': np.int64(15), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'calib_batches': np.int64(12)}
2025-10-13 03:43:19,302 - INFO - visualization - Generating BO visualization charts with 50 trials...
2025-10-13 03:43:20,589 - INFO - visualization - BO summary saved to: charts/20251013_034319_BO_ST-USleepNet-Tiny/bo_summary.txt
2025-10-13 03:43:20,596 - INFO - visualization - Raw data saved to: charts/20251013_034319_BO_ST-USleepNet-Tiny/bo_raw_data.json
2025-10-13 03:43:20,596 - INFO - visualization - Numpy arrays saved to: charts/20251013_034319_BO_ST-USleepNet-Tiny/bo_raw_data.npz
2025-10-13 03:43:20,596 - INFO - visualization - BO charts saved to: charts/20251013_034319_BO_ST-USleepNet-Tiny
2025-10-13 03:43:20,596 - INFO - evaluation.code_generation_pipeline_orchestrator - üìä BO charts saved to: charts/20251013_034319_BO_ST-USleepNet-Tiny
2025-10-13 03:43:20,604 - INFO - evaluation.code_generation_pipeline_orchestrator - üöÄ STEP 4: Final Training Execution
2025-10-13 03:43:20,604 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (57140, 6, 6000), Val: (14286, 6, 6000), Test: (17857, 6, 6000)
