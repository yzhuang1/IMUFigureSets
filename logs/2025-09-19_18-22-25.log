2025-09-19 18:22:31,156 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti Laptop GPU
2025-09-19 18:22:31,785 - INFO - __main__ - Logging system initialized successfully
2025-09-19 18:22:31,785 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-09-19 18:22:31,786 - INFO - __main__ - Starting real data processing from data/ directory
2025-09-19 18:22:31,787 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'X.npy', 'y.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-09-19 18:22:31,787 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-09-19 18:22:31,788 - INFO - __main__ - Attempting to load: X.npy
2025-09-19 18:22:31,932 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-09-19 18:22:32,017 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (62352, 1000, 2), device: cuda
2025-09-19 18:22:32,018 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-09-19 18:22:32,018 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-09-19 18:22:32,018 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-09-19 18:22:32,021 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-19 18:22:32,021 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-09-19 18:22:32,021 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-09-19 18:22:32,021 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-09-19 18:22:32,021 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-09-19 18:22:32,021 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-09-19 18:22:32,021 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-09-19 18:22:32,021 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-09-19 18:22:32,021 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-09-19 18:22:32,230 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-09-19 18:22:32,230 - INFO - class_balancing - Class imbalance analysis:
2025-09-19 18:22:32,230 - INFO - class_balancing -   Strategy: severe_imbalance
2025-09-19 18:22:32,230 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-09-19 18:22:32,230 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-09-19 18:22:32,230 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-09-19 18:22:32,230 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-09-19 18:22:32,230 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-09-19 18:22:32,230 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-09-19 18:22:32,230 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-09-19 18:22:32,928 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-09-19 18:22:32,937 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-09-19 18:22:32,937 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-19 18:22:32,937 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-09-19 18:22:32,937 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-19 18:22:32,937 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-09-19 18:22:32,938 - INFO - _models.ai_code_generator - Conducting literature review before code generation...
2025-09-19 18:24:55,785 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-19 18:24:55,882 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-19 18:24:55,882 - INFO - _models.ai_code_generator - Prompt length: 3174 characters
2025-09-19 18:24:55,883 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-19 18:24:55,883 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-19 18:24:55,883 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-09-19 18:27:27,683 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-19 18:27:27,733 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-09-19 18:27:27,734 - INFO - _models.ai_code_generator - AI generated training function: CATNetLite-CNNTransformer-ECG
2025-09-19 18:27:27,734 - INFO - _models.ai_code_generator - Confidence: 0.90
2025-09-19 18:27:27,734 - INFO - _models.ai_code_generator - Literature review informed code generation (confidence: 0.78)
2025-09-19 18:27:27,734 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: CATNetLite-CNNTransformer-ECG
2025-09-19 18:27:27,734 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'grad_clip', 'cnn_base_channels', 'kernel_sizes', 'stride', 'se_reduction', 'transformer_d_model', 'transformer_nhead', 'transformer_ffn_dim', 'transformer_layers', 'loss_type', 'focal_gamma', 'label_smoothing', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_batches', 'per_channel']
2025-09-19 18:27:27,734 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.90
2025-09-19 18:27:27,736 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-09-19 18:27:27,740 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions\training_function_torch_tensor_CATNetLite-CNNTransformer-ECG_1758324447.json
2025-09-19 18:27:27,740 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions\training_function_torch_tensor_CATNetLite-CNNTransformer-ECG_1758324447.json
2025-09-19 18:27:27,742 - INFO - _models.training_function_executor - Training function validation passed
2025-09-19 18:27:27,742 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-09-19 18:27:27,743 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: CATNetLite-CNNTransformer-ECG
2025-09-19 18:27:27,743 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-09-19 18:27:27,744 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-09-19 18:27:27,744 - WARNING - package_installer - Could not parse code for imports due to syntax error: unexpected character after line continuation character (<unknown>, line 1)
2025-09-19 18:27:27,744 - INFO - package_installer - Extracted imports from code: set()
2025-09-19 18:27:27,744 - INFO - package_installer - ‚úÖ No external packages required
2025-09-19 18:27:27,744 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-09-19 18:27:27,744 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 62352 samples (using full dataset)
2025-09-19 18:27:27,745 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'grad_clip', 'cnn_base_channels', 'kernel_sizes', 'stride', 'se_reduction', 'transformer_d_model', 'transformer_nhead', 'transformer_ffn_dim', 'transformer_layers', 'loss_type', 'focal_gamma', 'label_smoothing', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_batches', 'per_channel']
2025-09-19 18:27:27,745 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti Laptop GPU
2025-09-19 18:27:27,745 - INFO - _models.training_function_executor - Using centralized data splits for BO objective
2025-09-19 18:27:28,639 - ERROR - __main__ - Unhandled exception: TypeError: unhashable type: 'list'
Traceback (most recent call last):
  File "D:\_A\GPT_research\ml_pipeline\main.py", line 484, in <module>
    processed_real_data = process_real_data()
  File "D:\_A\GPT_research\ml_pipeline\main.py", line 342, in process_real_data
    result = process_data_with_ai_enhanced_evaluation(
  File "D:\_A\GPT_research\ml_pipeline\main.py", line 136, in process_data_with_ai_enhanced_evaluation
    result = train_with_iterative_selection(data, labels, device=device, **kwargs)
  File "D:\_A\GPT_research\ml_pipeline\main.py", line 85, in train_with_iterative_selection
    best_model, pipeline_results = orchestrator.run_complete_pipeline(
  File "D:\_A\GPT_research\ml_pipeline\evaluation\code_generation_pipeline_orchestrator.py", line 92, in run_complete_pipeline
    bo_results = self._run_bayesian_optimization(X, y, device, code_rec)
  File "D:\_A\GPT_research\ml_pipeline\evaluation\code_generation_pipeline_orchestrator.py", line 216, in _run_bayesian_optimization
    bo_optimizer = BayesianOptimizer(gpt_search_space=search_space, n_initial_points=3)
  File "D:\_A\GPT_research\ml_pipeline\bo\run_bo.py", line 45, in __init__
    self.search_space = self._convert_gpt_search_space(gpt_search_space)
  File "D:\_A\GPT_research\ml_pipeline\bo\run_bo.py", line 102, in _convert_gpt_search_space
    search_space.append(Categorical(categories, name=param_name))
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\skopt\space\space.py", line 796, in __init__
    self.set_transformer(transform)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\skopt\space\space.py", line 814, in set_transformer
    self.transformer.fit(self.categories)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\skopt\space\transformers.py", line 110, in fit
    self.mapping_ = {v: i for i, v in enumerate(X)}
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\skopt\space\transformers.py", line 110, in <dictcomp>
    self.mapping_ = {v: i for i, v in enumerate(X)}
TypeError: unhashable type: 'list'

2025-09-19 18:27:28,640 - INFO - _models.ai_code_generator - Calling GPT to debug JSON formatting issues
2025-09-19 18:27:28,640 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-19 18:27:28,640 - INFO - _models.ai_code_generator - Prompt length: 343 characters
2025-09-19 18:27:28,640 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-19 18:27:28,640 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-19 18:27:28,640 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-09-19 18:27:28,693 - INFO - _models.ai_code_generator - Calling GPT to debug JSON formatting issues
2025-09-19 18:27:28,693 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-19 18:27:28,693 - INFO - _models.ai_code_generator - Prompt length: 418 characters
2025-09-19 18:27:28,693 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-19 18:27:28,693 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-19 18:27:28,693 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-09-19 18:27:50,467 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-19 18:27:50,467 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-09-19 18:27:50,467 - WARNING - _models.ai_code_generator - No valid JSON found in debug response
