2025-10-11 23:15:12,041 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-11 23:15:12,181 - INFO - __main__ - Logging system initialized successfully
2025-10-11 23:15:12,181 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-10-11 23:15:12,181 - INFO - __main__ - Starting real data processing from data/dataset3/ directory
2025-10-11 23:15:12,181 - INFO - __main__ - Found 4 data files: ['sleep_sample.csv', 'X.npy', 'y.npy', 'sleep_metadata.json']
2025-10-11 23:15:12,181 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-10-11 23:15:12,181 - INFO - __main__ - Attempting to load: X.npy
2025-10-11 23:15:18,369 - INFO - __main__ - Successfully loaded NPY data: X(89283, 6, 6000), y(89283,)
2025-10-11 23:15:23,342 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (89283, 6, 6000), device: cuda
2025-10-11 23:15:23,342 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-10-11 23:15:23,342 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-10-11 23:15:23,342 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-10-11 23:15:23,348 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-11 23:15:23,348 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (89283, 6, 6000), 'dtype': 'float32', 'feature_count': 6000, 'sample_count': 89283, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-10-11 23:15:23,348 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-10-11 23:15:23,348 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-10-11 23:15:23,348 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-10-11 23:15:23,348 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-10-11 23:15:23,348 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-10-11 23:15:23,348 - INFO - data_splitting - Input data shape: X=(89283, 6, 6000), y=(89283,)
2025-10-11 23:15:23,348 - INFO - data_splitting - Class distribution: [20758 11387 28006 17266 11866]
2025-10-11 23:15:31,810 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.8602182913059842), np.int64(1): np.float64(1.5682722656786057), np.int64(2): np.float64(0.6375808971211783), np.int64(3): np.float64(1.03420814479638), np.int64(4): np.float64(1.5048722675796682)}
2025-10-11 23:15:31,814 - INFO - class_balancing - Class imbalance analysis:
2025-10-11 23:15:31,814 - INFO - class_balancing -   Strategy: mild_imbalance
2025-10-11 23:15:31,814 - INFO - class_balancing -   Imbalance ratio: 2.46
2025-10-11 23:15:31,814 - INFO - class_balancing -   Recommendations: Standard training should work, Consider class_weight='balanced'
2025-10-11 23:15:31,814 - INFO - data_splitting - Final splits - Train: 57140, Val: 14286, Test: 17857
2025-10-11 23:15:31,816 - INFO - data_splitting - Train class distribution: [13285  7287 17924 11050  7594]
2025-10-11 23:15:31,816 - INFO - data_splitting - Val class distribution: [3321 1822 4481 2763 1899]
2025-10-11 23:15:31,816 - INFO - data_splitting - Test class distribution: [4152 2278 5601 3453 2373]
2025-10-11 23:15:31,816 - INFO - data_splitting - Recommended balancing strategy: mild_imbalance
2025-10-11 23:15:35,169 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 6000]), std shape: torch.Size([1, 6000])
2025-10-11 23:15:35,179 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-10-11 23:15:35,179 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-10-11 23:15:35,191 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-10-11 23:15:35,191 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-10-11 23:15:35,191 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-10-11 23:15:35,192 - INFO - _models.ai_code_generator - Conducting literature review before code generation...
2025-10-11 23:18:15,195 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-11 23:18:15,273 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-10-11 23:18:15,273 - INFO - _models.ai_code_generator - Prompt length: 4921 characters
2025-10-11 23:18:15,273 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-10-11 23:18:15,273 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-10-11 23:18:15,273 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-10-11 23:21:04,772 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-11 23:21:04,773 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-10-11 23:21:04,773 - INFO - _models.ai_code_generator - AI generated training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:21:04,773 - INFO - _models.ai_code_generator - Confidence: 0.80
2025-10-11 23:21:04,773 - INFO - _models.ai_code_generator - Literature review informed code generation (confidence: 0.74)
2025-10-11 23:21:04,773 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:21:04,773 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'weight_decay', 'base_channels', 'kernel_size', 'dropout', 'amp', 'grad_clip_norm', 'scheduler', 'imbalance_mode', 'focal_gamma', 'label_smoothing', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'quant_backend', 'calibration_batches']
2025-10-11 23:21:04,773 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.80
2025-10-11 23:21:04,775 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-10-11 23:21:04,776 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions/training_function_torch_tensor_ST-USleepNet-Tiny-1D-Graph_1760242864.json
2025-10-11 23:21:04,776 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_torch_tensor_ST-USleepNet-Tiny-1D-Graph_1760242864.json
2025-10-11 23:21:04,776 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-10-11 23:21:04,776 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:21:04,776 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-10-11 23:21:04,789 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-10-11 23:21:04,792 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-10-11 23:21:04,792 - INFO - package_installer - Available packages: {'torch'}
2025-10-11 23:21:04,792 - INFO - package_installer - Missing packages: set()
2025-10-11 23:21:04,792 - INFO - package_installer - ‚úÖ All required packages are already available
2025-10-11 23:21:04,792 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-10-11 23:21:04,792 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-11 23:21:04,792 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 57140 samples (using bo_sample_num=100000000000000)
2025-10-11 23:21:04,792 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'base_channels', 'kernel_size', 'dropout', 'amp', 'grad_clip_norm', 'scheduler', 'imbalance_mode', 'focal_gamma', 'label_smoothing', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'quant_backend', 'calibration_batches']
2025-10-11 23:21:04,794 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-11 23:21:04,794 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-11 23:21:04,794 - INFO - _models.training_function_executor - Using BO subset for optimization: 57140 samples (bo_sample_num=100000000000000)
2025-10-11 23:21:05,365 - INFO - _models.training_function_executor - BO splits - Train: 45712, Val: 11428
2025-10-11 23:21:06,962 - INFO - bo.run_bo - Converted GPT search space: 19 parameters
2025-10-11 23:21:06,963 - INFO - bo.run_bo - Using GPT-generated search space
2025-10-11 23:21:06,966 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-10-11 23:21:06,969 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-10-11 23:21:06,969 - INFO - bo.run_bo - [PROFILE] suggest() took 0.004s
2025-10-11 23:21:06,970 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:21:06,970 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:21:06,970 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001412035543062636, 'batch_size': 16, 'epochs': 12, 'weight_decay': 6.251373574521747e-05, 'base_channels': 10, 'kernel_size': 12, 'dropout': 0.0467983561008608, 'amp': True, 'grad_clip_norm': 0.8661761457749354, 'scheduler': 'onecycle', 'imbalance_mode': 'focal', 'focal_gamma': 1.041168988591605, 'label_smoothing': 0.1939819704323989, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'fbgemm', 'calibration_batches': 6}
2025-10-11 23:21:06,973 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001412035543062636, 'batch_size': 16, 'epochs': 12, 'weight_decay': 6.251373574521747e-05, 'base_channels': 10, 'kernel_size': 12, 'dropout': 0.0467983561008608, 'amp': True, 'grad_clip_norm': 0.8661761457749354, 'scheduler': 'onecycle', 'imbalance_mode': 'focal', 'focal_gamma': 1.041168988591605, 'label_smoothing': 0.1939819704323989, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'fbgemm', 'calibration_batches': 6}
2025-10-11 23:21:20,294 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.1017 | val_loss=0.9135 | val_acc=0.5393 | time=11.8s
2025-10-11 23:21:27,139 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.8724 | val_loss=0.7930 | val_acc=0.5948 | time=6.8s
2025-10-11 23:21:33,948 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.7549 | val_loss=0.7186 | val_acc=0.6285 | time=6.8s
2025-10-11 23:21:40,780 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6919 | val_loss=0.6468 | val_acc=0.6428 | time=6.8s
2025-10-11 23:21:47,614 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.6681 | val_loss=0.6423 | val_acc=0.6550 | time=6.8s
2025-10-11 23:21:54,463 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.6228 | val_loss=0.5721 | val_acc=0.7167 | time=6.8s
2025-10-11 23:22:01,322 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5929 | val_loss=0.5853 | val_acc=0.7131 | time=6.9s
2025-10-11 23:22:08,172 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.5594 | val_loss=0.5552 | val_acc=0.7164 | time=6.9s
2025-10-11 23:22:14,993 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.5398 | val_loss=0.5339 | val_acc=0.7180 | time=6.8s
2025-10-11 23:22:21,810 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.5226 | val_loss=0.5157 | val_acc=0.7310 | time=6.8s
2025-10-11 23:22:28,651 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.5105 | val_loss=0.5075 | val_acc=0.7429 | time=6.8s
2025-10-11 23:22:35,514 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.5043 | val_loss=0.5046 | val_acc=0.7422 | time=6.9s
2025-10-11 23:22:35,547 - INFO - _models.training_function_executor - Quantization failed (cannot assign 'torch.fx.graph.Graph' as child module 'graph' (torch.nn.Module or None expected)); returning FP32 CPU model.
2025-10-11 23:22:37,012 - INFO - _models.training_function_executor - Model: 1,975 parameters, 2.1KB storage
2025-10-11 23:22:37,013 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1016983434291916, 0.87239287607437, 0.7548841963208218, 0.6918994118992499, 0.6681212226452425, 0.6227721246360356, 0.5928820827529278, 0.5593724267535749, 0.5397577793485725, 0.5225977170736505, 0.510515289998551, 0.5042906547611332], 'val_losses': [0.9135378771311753, 0.7930186290424187, 0.7186362379497582, 0.6468012983565564, 0.6422791245517198, 0.5721436164804272, 0.5852766445466688, 0.5551575238054449, 0.5339083506510808, 0.5156575550774595, 0.5075417529036115, 0.5045871334892886], 'val_acc': [0.5392894644732237, 0.5947672383619181, 0.628456422821141, 0.6428071403570178, 0.6549702485124256, 0.7166608330416521, 0.7130731536576829, 0.7163983199159958, 0.7179733986699335, 0.7310115505775289, 0.7429121456072804, 0.7422121106055303], 'best_epoch': 11, 'total_params': 1975, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001412035543062636, 'batch_size': 16, 'epochs': 12, 'weight_decay': 6.251373574521747e-05, 'base_channels': 10, 'kernel_size': 12, 'dropout': 0.0467983561008608, 'amp': True, 'grad_clip_norm': 0.8661761457749354, 'scheduler': 'onecycle', 'imbalance_mode': 'focal', 'focal_gamma': 1.041168988591605, 'label_smoothing': 0.1939819704323989, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'fbgemm', 'calibration_batches': 6}, 'model_parameter_count': 1975, 'model_storage_size_kb': 2.12158203125, 'model_size_validation': 'PASS'}
2025-10-11 23:22:37,013 - INFO - _models.training_function_executor - BO Objective: base=0.7422, size_penalty=0.0000, final=0.7422
2025-10-11 23:22:37,013 - INFO - _models.training_function_executor - Model: 1,975 parameters, 2.1KB (PASS 256KB limit)
2025-10-11 23:22:37,013 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 90.043s
2025-10-11 23:22:37,014 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7422
2025-10-11 23:22:37,014 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-11 23:22:37,014 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.001412035543062636, 'batch_size': 16, 'epochs': np.int64(12), 'weight_decay': 6.251373574521747e-05, 'base_channels': np.int64(10), 'kernel_size': np.int64(12), 'dropout': 0.0467983561008608, 'amp': True, 'grad_clip_norm': 0.8661761457749354, 'scheduler': 'onecycle', 'imbalance_mode': 'focal', 'focal_gamma': 1.041168988591605, 'label_smoothing': 0.1939819704323989, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'fbgemm', 'calibration_batches': np.int64(6)}, value=0.7422
2025-10-11 23:22:37,014 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.001412035543062636, 'batch_size': 16, 'epochs': np.int64(12), 'weight_decay': 6.251373574521747e-05, 'base_channels': np.int64(10), 'kernel_size': np.int64(12), 'dropout': 0.0467983561008608, 'amp': True, 'grad_clip_norm': 0.8661761457749354, 'scheduler': 'onecycle', 'imbalance_mode': 'focal', 'focal_gamma': 1.041168988591605, 'label_smoothing': 0.1939819704323989, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'fbgemm', 'calibration_batches': np.int64(6)} -> 0.7422
2025-10-11 23:22:37,015 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-10-11 23:22:37,015 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-11 23:22:37,015 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:22:37,015 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:22:37,015 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.0448928221744368e-05, 'batch_size': 16, 'epochs': 31, 'weight_decay': 6.847920095574784e-05, 'base_channels': 13, 'kernel_size': 14, 'dropout': 0.2921266556524378, 'amp': True, 'grad_clip_norm': 0.09060643453282081, 'scheduler': 'onecycle', 'imbalance_mode': 'class_weights', 'focal_gamma': 2.966461771613577, 'label_smoothing': 0.09335257864959601, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'qnnpack', 'calibration_batches': 6}
2025-10-11 23:22:37,016 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.0448928221744368e-05, 'batch_size': 16, 'epochs': 31, 'weight_decay': 6.847920095574784e-05, 'base_channels': 13, 'kernel_size': 14, 'dropout': 0.2921266556524378, 'amp': True, 'grad_clip_norm': 0.09060643453282081, 'scheduler': 'onecycle', 'imbalance_mode': 'class_weights', 'focal_gamma': 2.966461771613577, 'label_smoothing': 0.09335257864959601, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'qnnpack', 'calibration_batches': 6}
2025-10-11 23:22:48,189 - INFO - _models.training_function_executor - Epoch 001 | train_loss=2.1598 | val_loss=2.1681 | val_acc=0.1299 | time=11.2s
2025-10-11 23:22:56,499 - INFO - _models.training_function_executor - Epoch 002 | train_loss=2.0954 | val_loss=2.0774 | val_acc=0.1296 | time=8.3s
2025-10-11 23:23:04,755 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.9812 | val_loss=1.9312 | val_acc=0.1314 | time=8.3s
2025-10-11 23:23:13,055 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.8270 | val_loss=1.7722 | val_acc=0.1189 | time=8.3s
2025-10-11 23:23:21,333 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.6898 | val_loss=1.6672 | val_acc=0.1826 | time=8.3s
2025-10-11 23:23:29,574 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.6352 | val_loss=1.6393 | val_acc=0.1845 | time=8.2s
2025-10-11 23:23:37,837 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.6258 | val_loss=1.6338 | val_acc=0.1877 | time=8.3s
2025-10-11 23:23:46,132 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.6195 | val_loss=1.6301 | val_acc=0.2421 | time=8.3s
2025-10-11 23:23:54,417 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.6093 | val_loss=1.6187 | val_acc=0.2645 | time=8.3s
2025-10-11 23:24:02,712 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.5916 | val_loss=1.6162 | val_acc=0.1691 | time=8.3s
2025-10-11 23:24:10,979 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.5677 | val_loss=1.6115 | val_acc=0.1810 | time=8.3s
2025-10-11 23:24:19,244 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.5442 | val_loss=1.6182 | val_acc=0.2199 | time=8.3s
2025-10-11 23:24:27,517 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.5233 | val_loss=1.6073 | val_acc=0.2394 | time=8.3s
2025-10-11 23:24:35,807 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.5099 | val_loss=1.5990 | val_acc=0.2505 | time=8.3s
2025-10-11 23:24:44,087 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.4974 | val_loss=1.6260 | val_acc=0.2297 | time=8.3s
2025-10-11 23:24:52,379 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.4874 | val_loss=1.6216 | val_acc=0.2292 | time=8.3s
2025-10-11 23:25:00,677 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.4783 | val_loss=1.6252 | val_acc=0.2279 | time=8.3s
2025-10-11 23:25:08,964 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.4691 | val_loss=1.6224 | val_acc=0.2337 | time=8.3s
2025-10-11 23:25:17,233 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.4617 | val_loss=1.6189 | val_acc=0.2366 | time=8.3s
2025-10-11 23:25:25,519 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.4561 | val_loss=1.6317 | val_acc=0.2363 | time=8.3s
2025-10-11 23:25:33,812 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.4448 | val_loss=1.6295 | val_acc=0.2391 | time=8.3s
2025-10-11 23:25:42,108 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.4402 | val_loss=1.6268 | val_acc=0.2439 | time=8.3s
2025-10-11 23:25:50,402 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.4337 | val_loss=1.6291 | val_acc=0.2446 | time=8.3s
2025-10-11 23:25:58,680 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.4274 | val_loss=1.6325 | val_acc=0.2457 | time=8.3s
2025-10-11 23:26:06,948 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.4245 | val_loss=1.6261 | val_acc=0.2479 | time=8.3s
2025-10-11 23:26:15,236 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.4213 | val_loss=1.6359 | val_acc=0.2453 | time=8.3s
2025-10-11 23:26:23,541 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.4159 | val_loss=1.6295 | val_acc=0.2482 | time=8.3s
2025-10-11 23:26:31,823 - INFO - _models.training_function_executor - Epoch 028 | train_loss=1.4149 | val_loss=1.6312 | val_acc=0.2482 | time=8.3s
2025-10-11 23:26:40,102 - INFO - _models.training_function_executor - Epoch 029 | train_loss=1.4134 | val_loss=1.6296 | val_acc=0.2483 | time=8.3s
2025-10-11 23:26:48,411 - INFO - _models.training_function_executor - Epoch 030 | train_loss=1.4137 | val_loss=1.6303 | val_acc=0.2484 | time=8.3s
2025-10-11 23:26:56,719 - INFO - _models.training_function_executor - Epoch 031 | train_loss=1.4154 | val_loss=1.6300 | val_acc=0.2483 | time=8.3s
2025-10-11 23:26:57,843 - INFO - _models.training_function_executor - Model: 2,843 parameters, 12.2KB storage
2025-10-11 23:26:57,843 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [2.159752470862002, 2.0953704407885225, 1.9812074696888322, 1.8270192161322392, 1.6897923459863178, 1.6351770868157856, 1.625775527152975, 1.6194808113020034, 1.6092501388048432, 1.5916045186900993, 1.56772816940584, 1.544152443835399, 1.523291916833877, 1.5098890787995192, 1.4974344740975434, 1.4874097760173461, 1.4783440691464258, 1.4691445113980859, 1.461678657116154, 1.456135825381481, 1.4447812179314077, 1.440155244224089, 1.4336981758772596, 1.4273965003651508, 1.4245335088770916, 1.4212871418994, 1.4159421904086231, 1.4148519014953358, 1.413406426271526, 1.4136528474365784, 1.415368160773375], 'val_losses': [2.1681424952887154, 2.0773723458910323, 1.9311804778092392, 1.7721561390203195, 1.667203534566439, 1.6393382164148185, 1.633779313681009, 1.6300721471959894, 1.6187055909550274, 1.616247239646378, 1.611534396585051, 1.6181811617804573, 1.6073460632270866, 1.5990303554734984, 1.6260078940358196, 1.6215802184351675, 1.625180610743436, 1.6223886574898567, 1.6188531920626448, 1.6317063501664808, 1.6295483759233167, 1.6268196789534775, 1.6291167454286055, 1.632463495047776, 1.6260556767870495, 1.6359279280775911, 1.6294966172505092, 1.6312100823942597, 1.6296380291451942, 1.6302523874736332, 1.6300448025856817], 'val_acc': [0.12994399719986, 0.12959397969898495, 0.13143157157857893, 0.11891844592229611, 0.18262163108155408, 0.18454672733636682, 0.1876968848442422, 0.2421246062303115, 0.2645257262863143, 0.16905845292264612, 0.18095904795239762, 0.21989849492474622, 0.23941197059852992, 0.25052502625131257, 0.22969898494924745, 0.2291739586979349, 0.22786139306965347, 0.23372418620931046, 0.23661183059152957, 0.23626181309065453, 0.23906195309765488, 0.24387469373468673, 0.24457472873643682, 0.2457122856142807, 0.24789989499474974, 0.2452747637381869, 0.24824991249562478, 0.24824991249562478, 0.24833741687084354, 0.2484249212460623, 0.24833741687084354], 'best_epoch': 9, 'total_params': 2843, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.0448928221744368e-05, 'batch_size': 16, 'epochs': 31, 'weight_decay': 6.847920095574784e-05, 'base_channels': 13, 'kernel_size': 14, 'dropout': 0.2921266556524378, 'amp': True, 'grad_clip_norm': 0.09060643453282081, 'scheduler': 'onecycle', 'imbalance_mode': 'class_weights', 'focal_gamma': 2.966461771613577, 'label_smoothing': 0.09335257864959601, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'qnnpack', 'calibration_batches': 6}, 'model_parameter_count': 2843, 'model_storage_size_kb': 12.216015625, 'model_size_validation': 'PASS'}
2025-10-11 23:26:57,843 - INFO - _models.training_function_executor - BO Objective: base=0.2483, size_penalty=0.0000, final=0.2483
2025-10-11 23:26:57,843 - INFO - _models.training_function_executor - Model: 2,843 parameters, 12.2KB (PASS 256KB limit)
2025-10-11 23:26:57,843 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 260.828s
2025-10-11 23:26:57,845 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2483
2025-10-11 23:26:57,845 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-11 23:26:57,845 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 1.0448928221744368e-05, 'batch_size': 16, 'epochs': np.int64(31), 'weight_decay': 6.847920095574784e-05, 'base_channels': np.int64(13), 'kernel_size': np.int64(14), 'dropout': 0.2921266556524378, 'amp': True, 'grad_clip_norm': 0.09060643453282081, 'scheduler': 'onecycle', 'imbalance_mode': 'class_weights', 'focal_gamma': 2.966461771613577, 'label_smoothing': 0.09335257864959601, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'qnnpack', 'calibration_batches': np.int64(6)}, value=0.2483
2025-10-11 23:26:57,845 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 1.0448928221744368e-05, 'batch_size': 16, 'epochs': np.int64(31), 'weight_decay': 6.847920095574784e-05, 'base_channels': np.int64(13), 'kernel_size': np.int64(14), 'dropout': 0.2921266556524378, 'amp': True, 'grad_clip_norm': 0.09060643453282081, 'scheduler': 'onecycle', 'imbalance_mode': 'class_weights', 'focal_gamma': 2.966461771613577, 'label_smoothing': 0.09335257864959601, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': 'qnnpack', 'calibration_batches': np.int64(6)} -> 0.2483
2025-10-11 23:26:57,846 - INFO - bo.run_bo - üîçBO Trial 3: Initial random exploration
2025-10-11 23:26:57,846 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-11 23:26:57,846 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:26:57,846 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:26:57,846 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0015199881220083972, 'batch_size': 16, 'epochs': 6, 'weight_decay': 0.0001129013355909267, 'base_channels': 15, 'kernel_size': 9, 'dropout': 0.1829989973347863, 'amp': False, 'grad_clip_norm': 0.1733646535077721, 'scheduler': 'none', 'imbalance_mode': 'none', 'focal_gamma': 2.5107228206353054, 'label_smoothing': 0.08503117489824896, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': 'fbgemm', 'calibration_batches': 2}
2025-10-11 23:26:57,848 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0015199881220083972, 'batch_size': 16, 'epochs': 6, 'weight_decay': 0.0001129013355909267, 'base_channels': 15, 'kernel_size': 9, 'dropout': 0.1829989973347863, 'amp': False, 'grad_clip_norm': 0.1733646535077721, 'scheduler': 'none', 'imbalance_mode': 'none', 'focal_gamma': 2.5107228206353054, 'label_smoothing': 0.08503117489824896, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': 'fbgemm', 'calibration_batches': 2}
2025-10-11 23:27:08,079 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.1884 | val_loss=1.0896 | val_acc=0.6566 | time=10.2s
2025-10-11 23:27:15,428 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.0618 | val_loss=1.1062 | val_acc=0.6628 | time=7.3s
2025-10-11 23:27:22,758 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.0211 | val_loss=1.0888 | val_acc=0.6565 | time=7.3s
2025-10-11 23:27:30,095 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0052 | val_loss=0.9884 | val_acc=0.7073 | time=7.3s
2025-10-11 23:27:37,428 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9950 | val_loss=0.9889 | val_acc=0.7189 | time=7.3s
2025-10-11 23:27:44,765 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9820 | val_loss=1.0295 | val_acc=0.6876 | time=7.3s
2025-10-11 23:27:45,869 - INFO - _models.training_function_executor - Model: 2,497 parameters, 5.4KB storage
2025-10-11 23:27:45,870 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1884456932607297, 1.061835629521945, 1.0211188110347222, 1.0051618302289864, 0.9950137748182508, 0.9819614229854855], 'val_losses': [1.0895959398963235, 1.1061657779700274, 1.088817269735403, 0.9883710779510178, 0.9888626047781297, 1.0295485831640816], 'val_acc': [0.656632831641582, 0.6628456422821141, 0.6565453272663633, 0.7072978648932446, 0.7189359467973399, 0.6876093804690234], 'best_epoch': 5, 'total_params': 2907, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0015199881220083972, 'batch_size': 16, 'epochs': 6, 'weight_decay': 0.0001129013355909267, 'base_channels': 15, 'kernel_size': 9, 'dropout': 0.1829989973347863, 'amp': False, 'grad_clip_norm': 0.1733646535077721, 'scheduler': 'none', 'imbalance_mode': 'none', 'focal_gamma': 2.5107228206353054, 'label_smoothing': 0.08503117489824896, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': 'fbgemm', 'calibration_batches': 2}, 'model_parameter_count': 2497, 'model_storage_size_kb': 5.3646484375000005, 'model_size_validation': 'PASS'}
2025-10-11 23:27:45,870 - INFO - _models.training_function_executor - BO Objective: base=0.6876, size_penalty=0.0000, final=0.6876
2025-10-11 23:27:45,870 - INFO - _models.training_function_executor - Model: 2,497 parameters, 5.4KB (PASS 256KB limit)
2025-10-11 23:27:45,870 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 48.023s
2025-10-11 23:27:45,955 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6876
2025-10-11 23:27:45,955 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.083s
2025-10-11 23:27:45,955 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 0.0015199881220083972, 'batch_size': 16, 'epochs': np.int64(6), 'weight_decay': 0.0001129013355909267, 'base_channels': np.int64(15), 'kernel_size': np.int64(9), 'dropout': 0.1829989973347863, 'amp': False, 'grad_clip_norm': 0.1733646535077721, 'scheduler': 'none', 'imbalance_mode': 'none', 'focal_gamma': 2.5107228206353054, 'label_smoothing': 0.08503117489824896, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': 'fbgemm', 'calibration_batches': np.int64(2)}, value=0.6876
2025-10-11 23:27:45,955 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 0.0015199881220083972, 'batch_size': 16, 'epochs': np.int64(6), 'weight_decay': 0.0001129013355909267, 'base_channels': np.int64(15), 'kernel_size': np.int64(9), 'dropout': 0.1829989973347863, 'amp': False, 'grad_clip_norm': 0.1733646535077721, 'scheduler': 'none', 'imbalance_mode': 'none', 'focal_gamma': 2.5107228206353054, 'label_smoothing': 0.08503117489824896, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': 'fbgemm', 'calibration_batches': np.int64(2)} -> 0.6876
2025-10-11 23:27:45,955 - INFO - bo.run_bo - üîçBO Trial 4: Using RF surrogate + Expected Improvement
2025-10-11 23:27:45,955 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:27:45,955 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:27:45,955 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:27:45,955 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002600831268726489, 'batch_size': 32, 'epochs': 21, 'weight_decay': 1.4185818447286229e-05, 'base_channels': 11, 'kernel_size': 3, 'dropout': 0.23534003741006435, 'amp': False, 'grad_clip_norm': 0.2221581912793799, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3046132164451518, 'label_smoothing': 0.0768101475135952, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 7}
2025-10-11 23:27:45,957 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002600831268726489, 'batch_size': 32, 'epochs': 21, 'weight_decay': 1.4185818447286229e-05, 'base_channels': 11, 'kernel_size': 3, 'dropout': 0.23534003741006435, 'amp': False, 'grad_clip_norm': 0.2221581912793799, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3046132164451518, 'label_smoothing': 0.0768101475135952, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 7}
2025-10-11 23:27:54,678 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3852 | val_loss=1.3155 | val_acc=0.5125 | time=8.7s
2025-10-11 23:28:00,576 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2788 | val_loss=1.2894 | val_acc=0.4926 | time=5.9s
2025-10-11 23:28:06,465 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2605 | val_loss=1.3223 | val_acc=0.4255 | time=5.9s
2025-10-11 23:28:12,350 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.2395 | val_loss=1.3832 | val_acc=0.3967 | time=5.9s
2025-10-11 23:28:18,231 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.2146 | val_loss=1.2097 | val_acc=0.4808 | time=5.9s
2025-10-11 23:28:24,127 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1823 | val_loss=1.2340 | val_acc=0.4895 | time=5.9s
2025-10-11 23:28:30,014 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1547 | val_loss=1.1619 | val_acc=0.5631 | time=5.9s
2025-10-11 23:28:35,906 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1442 | val_loss=1.2031 | val_acc=0.5257 | time=5.9s
2025-10-11 23:28:41,794 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1345 | val_loss=1.1724 | val_acc=0.5911 | time=5.9s
2025-10-11 23:28:47,689 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1286 | val_loss=1.1427 | val_acc=0.6033 | time=5.9s
2025-10-11 23:28:53,594 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.1210 | val_loss=1.1418 | val_acc=0.6180 | time=5.9s
2025-10-11 23:28:59,467 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.1139 | val_loss=1.1370 | val_acc=0.6117 | time=5.9s
2025-10-11 23:29:05,362 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.1120 | val_loss=1.1483 | val_acc=0.6143 | time=5.9s
2025-10-11 23:29:11,245 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.1049 | val_loss=1.0982 | val_acc=0.6376 | time=5.9s
2025-10-11 23:29:17,138 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.1016 | val_loss=1.1260 | val_acc=0.6281 | time=5.9s
2025-10-11 23:29:23,036 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.0977 | val_loss=1.1462 | val_acc=0.5889 | time=5.9s
2025-10-11 23:29:28,926 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.0976 | val_loss=1.1182 | val_acc=0.6299 | time=5.9s
2025-10-11 23:29:34,820 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.0952 | val_loss=1.1480 | val_acc=0.6246 | time=5.9s
2025-10-11 23:29:40,714 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.0896 | val_loss=1.1066 | val_acc=0.6173 | time=5.9s
2025-10-11 23:29:46,603 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0894 | val_loss=1.0863 | val_acc=0.6596 | time=5.9s
2025-10-11 23:29:52,485 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0876 | val_loss=1.1096 | val_acc=0.6345 | time=5.9s
2025-10-11 23:29:53,588 - INFO - _models.training_function_executor - Model: 1,543 parameters, 6.6KB storage
2025-10-11 23:29:53,588 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3852482144026759, 1.2787791056763134, 1.2605408284111903, 1.2395291592459148, 1.2146424165632943, 1.1822620813374423, 1.1546948235130043, 1.1441711093930618, 1.1345223177972583, 1.1286386749892905, 1.1209683754462476, 1.1138642259291454, 1.112001608726109, 1.1049393364146842, 1.10163303606989, 1.0977429134016523, 1.0976341570316286, 1.095176598298291, 1.0895648980324213, 1.0894276098908036, 1.0876040560870508], 'val_losses': [1.3155233047527974, 1.2894472309996963, 1.322347207775329, 1.383228843105572, 1.209693935496847, 1.2339894878131716, 1.161876104563974, 1.2031307873113195, 1.1724000050368921, 1.1427267263721488, 1.141798686048838, 1.1369622824245325, 1.1482955477091188, 1.0981827498148273, 1.125950746862582, 1.1461589526197764, 1.118209362363016, 1.1480028992258637, 1.1066472595297425, 1.0862975240419697, 1.109613753230878], 'val_acc': [0.5125131256562828, 0.4926496324816241, 0.42553377668883446, 0.3967448372418621, 0.48083654182709135, 0.4894994749737487, 0.5630906545327267, 0.5257262863143157, 0.5910920546027302, 0.603255162758138, 0.6179558977948898, 0.6117430871543578, 0.6142807140357018, 0.6376443822191109, 0.628106405320266, 0.5889044452222612, 0.6298564928246412, 0.6246062303115156, 0.6172558627931397, 0.6596079803990199, 0.6344942247112355], 'best_epoch': 20, 'total_params': 1543, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002600831268726489, 'batch_size': 32, 'epochs': 21, 'weight_decay': 1.4185818447286229e-05, 'base_channels': 11, 'kernel_size': 3, 'dropout': 0.23534003741006435, 'amp': False, 'grad_clip_norm': 0.2221581912793799, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3046132164451518, 'label_smoothing': 0.0768101475135952, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 7}, 'model_parameter_count': 1543, 'model_storage_size_kb': 6.630078125000001, 'model_size_validation': 'PASS'}
2025-10-11 23:29:53,588 - INFO - _models.training_function_executor - BO Objective: base=0.6345, size_penalty=0.0000, final=0.6345
2025-10-11 23:29:53,588 - INFO - _models.training_function_executor - Model: 1,543 parameters, 6.6KB (PASS 256KB limit)
2025-10-11 23:29:53,588 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 127.633s
2025-10-11 23:29:53,674 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6345
2025-10-11 23:29:53,674 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.081s
2025-10-11 23:29:53,674 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 0.002600831268726489, 'batch_size': np.int64(32), 'epochs': np.int64(21), 'weight_decay': 1.4185818447286229e-05, 'base_channels': np.int64(11), 'kernel_size': np.int64(3), 'dropout': 0.23534003741006435, 'amp': np.False_, 'grad_clip_norm': 0.2221581912793799, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3046132164451518, 'label_smoothing': 0.0768101475135952, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(7)}, value=0.6345
2025-10-11 23:29:53,674 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 0.002600831268726489, 'batch_size': np.int64(32), 'epochs': np.int64(21), 'weight_decay': 1.4185818447286229e-05, 'base_channels': np.int64(11), 'kernel_size': np.int64(3), 'dropout': 0.23534003741006435, 'amp': np.False_, 'grad_clip_norm': 0.2221581912793799, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3046132164451518, 'label_smoothing': 0.0768101475135952, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(7)} -> 0.6345
2025-10-11 23:29:53,674 - INFO - bo.run_bo - üîçBO Trial 5: Using RF surrogate + Expected Improvement
2025-10-11 23:29:53,674 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:29:53,674 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:29:53,674 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:29:53,674 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.5325844384112793e-05, 'batch_size': 64, 'epochs': 24, 'weight_decay': 1.7200540954363648e-06, 'base_channels': 12, 'kernel_size': 8, 'dropout': 0.16086323808125932, 'amp': False, 'grad_clip_norm': 0.649537307158841, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7801263308044617, 'label_smoothing': 0.09483829901118158, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 6}
2025-10-11 23:29:53,675 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.5325844384112793e-05, 'batch_size': 64, 'epochs': 24, 'weight_decay': 1.7200540954363648e-06, 'base_channels': 12, 'kernel_size': 8, 'dropout': 0.16086323808125932, 'amp': False, 'grad_clip_norm': 0.649537307158841, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7801263308044617, 'label_smoothing': 0.09483829901118158, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 6}
2025-10-11 23:30:01,433 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3034 | val_loss=1.0438 | val_acc=0.3180 | time=7.8s
2025-10-11 23:30:06,356 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.0238 | val_loss=1.0260 | val_acc=0.3806 | time=4.9s
2025-10-11 23:30:11,273 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.0148 | val_loss=1.0184 | val_acc=0.4007 | time=4.9s
2025-10-11 23:30:16,193 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0025 | val_loss=1.0087 | val_acc=0.4016 | time=4.9s
2025-10-11 23:30:21,112 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9833 | val_loss=0.9908 | val_acc=0.4279 | time=4.9s
2025-10-11 23:30:26,029 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9571 | val_loss=0.9658 | val_acc=0.4441 | time=4.9s
2025-10-11 23:30:30,949 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9280 | val_loss=0.9461 | val_acc=0.4538 | time=4.9s
2025-10-11 23:30:35,870 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.8999 | val_loss=0.9290 | val_acc=0.4835 | time=4.9s
2025-10-11 23:30:40,794 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.8768 | val_loss=0.9041 | val_acc=0.5094 | time=4.9s
2025-10-11 23:30:45,725 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8558 | val_loss=0.8921 | val_acc=0.5032 | time=4.9s
2025-10-11 23:30:50,655 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8387 | val_loss=0.8812 | val_acc=0.5033 | time=4.9s
2025-10-11 23:30:55,579 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.8234 | val_loss=0.8675 | val_acc=0.5049 | time=4.9s
2025-10-11 23:31:00,514 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.8108 | val_loss=0.8515 | val_acc=0.5081 | time=4.9s
2025-10-11 23:31:05,445 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.7982 | val_loss=0.8535 | val_acc=0.5008 | time=4.9s
2025-10-11 23:31:10,373 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.7880 | val_loss=0.8329 | val_acc=0.5064 | time=4.9s
2025-10-11 23:31:15,305 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7775 | val_loss=0.8275 | val_acc=0.5032 | time=4.9s
2025-10-11 23:31:20,237 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.7677 | val_loss=0.8017 | val_acc=0.5143 | time=4.9s
2025-10-11 23:31:25,171 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.7598 | val_loss=0.8022 | val_acc=0.5106 | time=4.9s
2025-10-11 23:31:30,102 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.7497 | val_loss=0.7866 | val_acc=0.5163 | time=4.9s
2025-10-11 23:31:35,040 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.7431 | val_loss=0.7789 | val_acc=0.5186 | time=4.9s
2025-10-11 23:31:39,976 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.7348 | val_loss=0.7627 | val_acc=0.5238 | time=4.9s
2025-10-11 23:31:44,903 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.7274 | val_loss=0.7691 | val_acc=0.5198 | time=4.9s
2025-10-11 23:31:49,827 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.7194 | val_loss=0.7497 | val_acc=0.5270 | time=4.9s
2025-10-11 23:31:54,759 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.7122 | val_loss=0.7403 | val_acc=0.5306 | time=4.9s
2025-10-11 23:31:55,841 - INFO - _models.training_function_executor - Model: 2,163 parameters, 9.3KB storage
2025-10-11 23:31:55,841 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.303369514592044, 1.023751808630003, 1.0147780590957696, 1.0025027644384157, 0.9833247431508311, 0.9571045256994821, 0.928012799132954, 0.8998781927815684, 0.8768380277640336, 0.8558144571897867, 0.8387040956037027, 0.8233667374490858, 0.8107719570606738, 0.7982032777546169, 0.7880121535354561, 0.7775450657297681, 0.7677238365986964, 0.7598001610149037, 0.7497184675890249, 0.7430964855881004, 0.7348295505647059, 0.7274483992086423, 0.7193941144676476, 0.7121617280519925], 'val_losses': [1.0438306265037154, 1.0260451226261076, 1.0183734437606855, 1.0087318347153051, 0.9907809948788009, 0.9658044250317792, 0.946058855709417, 0.9290024931204386, 0.9041415799263469, 0.8920513108455935, 0.8811996059710753, 0.8675035021824544, 0.851469694902111, 0.8534883060934824, 0.8328562182421125, 0.8275487532828774, 0.8017199532279755, 0.8022100798910556, 0.7866197514800386, 0.7789384812616104, 0.762699383930121, 0.7691387813850488, 0.7497333874249591, 0.7402577223724494], 'val_acc': [0.3179908995449772, 0.3806440322016101, 0.40068253412670635, 0.4016450822541127, 0.427896394819741, 0.44408470423521174, 0.4537976898844942, 0.48354917745887294, 0.5093629681484074, 0.5032376618830942, 0.5033251662583129, 0.5049002450122506, 0.508050402520126, 0.5007875393769688, 0.5063878193909696, 0.5031501575078754, 0.514263213160658, 0.5105880294014701, 0.5162758137906895, 0.5185509275463773, 0.523801190059503, 0.51977598879944, 0.5270388519425971, 0.5306265313265663], 'best_epoch': 24, 'total_params': 2163, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.5325844384112793e-05, 'batch_size': 64, 'epochs': 24, 'weight_decay': 1.7200540954363648e-06, 'base_channels': 12, 'kernel_size': 8, 'dropout': 0.16086323808125932, 'amp': False, 'grad_clip_norm': 0.649537307158841, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7801263308044617, 'label_smoothing': 0.09483829901118158, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 6}, 'model_parameter_count': 2163, 'model_storage_size_kb': 9.294140625, 'model_size_validation': 'PASS'}
2025-10-11 23:31:55,841 - INFO - _models.training_function_executor - BO Objective: base=0.5306, size_penalty=0.0000, final=0.5306
2025-10-11 23:31:55,841 - INFO - _models.training_function_executor - Model: 2,163 parameters, 9.3KB (PASS 256KB limit)
2025-10-11 23:31:55,841 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 122.167s
2025-10-11 23:31:55,932 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5306
2025-10-11 23:31:55,932 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.082s
2025-10-11 23:31:55,932 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 2.5325844384112793e-05, 'batch_size': np.int64(64), 'epochs': np.int64(24), 'weight_decay': 1.7200540954363648e-06, 'base_channels': np.int64(12), 'kernel_size': np.int64(8), 'dropout': 0.16086323808125932, 'amp': np.False_, 'grad_clip_norm': 0.649537307158841, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7801263308044617, 'label_smoothing': 0.09483829901118158, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(6)}, value=0.5306
2025-10-11 23:31:55,932 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 2.5325844384112793e-05, 'batch_size': np.int64(64), 'epochs': np.int64(24), 'weight_decay': 1.7200540954363648e-06, 'base_channels': np.int64(12), 'kernel_size': np.int64(8), 'dropout': 0.16086323808125932, 'amp': np.False_, 'grad_clip_norm': 0.649537307158841, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7801263308044617, 'label_smoothing': 0.09483829901118158, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(6)} -> 0.5306
2025-10-11 23:31:55,932 - INFO - bo.run_bo - üîçBO Trial 6: Using RF surrogate + Expected Improvement
2025-10-11 23:31:55,932 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:31:55,932 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:31:55,933 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:31:55,933 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0001642819730959757, 'batch_size': 32, 'epochs': 47, 'weight_decay': 6.994752957237263e-05, 'base_channels': 16, 'kernel_size': 10, 'dropout': 0.12448935973913747, 'amp': True, 'grad_clip_norm': 0.6254015079618731, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.052314661388803, 'label_smoothing': 0.038830404882529077, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 3}
2025-10-11 23:31:55,934 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0001642819730959757, 'batch_size': 32, 'epochs': 47, 'weight_decay': 6.994752957237263e-05, 'base_channels': 16, 'kernel_size': 10, 'dropout': 0.12448935973913747, 'amp': True, 'grad_clip_norm': 0.6254015079618731, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.052314661388803, 'label_smoothing': 0.038830404882529077, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 3}
2025-10-11 23:32:05,645 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.7565 | val_loss=1.6626 | val_acc=0.2262 | time=9.7s
2025-10-11 23:32:12,473 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.6145 | val_loss=1.5993 | val_acc=0.2159 | time=6.8s
2025-10-11 23:32:19,302 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.5901 | val_loss=1.5842 | val_acc=0.2884 | time=6.8s
2025-10-11 23:32:26,133 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.5633 | val_loss=1.5511 | val_acc=0.3373 | time=6.8s
2025-10-11 23:32:32,947 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.4889 | val_loss=1.4424 | val_acc=0.4236 | time=6.8s
2025-10-11 23:32:39,758 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.3891 | val_loss=1.3889 | val_acc=0.4321 | time=6.8s
2025-10-11 23:32:46,595 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.3326 | val_loss=1.3661 | val_acc=0.4460 | time=6.8s
2025-10-11 23:32:53,414 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.3043 | val_loss=1.3609 | val_acc=0.4252 | time=6.8s
2025-10-11 23:33:00,222 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.2766 | val_loss=1.3500 | val_acc=0.4408 | time=6.8s
2025-10-11 23:33:07,026 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.2440 | val_loss=1.3639 | val_acc=0.4305 | time=6.8s
2025-10-11 23:33:13,838 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.2268 | val_loss=1.2766 | val_acc=0.5330 | time=6.8s
2025-10-11 23:33:20,660 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.2073 | val_loss=1.3196 | val_acc=0.4763 | time=6.8s
2025-10-11 23:33:27,479 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.1914 | val_loss=1.3437 | val_acc=0.4720 | time=6.8s
2025-10-11 23:33:34,293 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.1740 | val_loss=1.2444 | val_acc=0.5353 | time=6.8s
2025-10-11 23:33:41,110 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.1574 | val_loss=1.2117 | val_acc=0.5374 | time=6.8s
2025-10-11 23:33:47,927 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.1448 | val_loss=1.2524 | val_acc=0.5300 | time=6.8s
2025-10-11 23:33:54,757 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.1284 | val_loss=1.2467 | val_acc=0.5390 | time=6.8s
2025-10-11 23:34:01,592 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.1182 | val_loss=1.1948 | val_acc=0.5531 | time=6.8s
2025-10-11 23:34:08,423 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.1039 | val_loss=1.1697 | val_acc=0.5897 | time=6.8s
2025-10-11 23:34:15,260 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0929 | val_loss=1.1728 | val_acc=0.5648 | time=6.8s
2025-10-11 23:34:22,085 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0810 | val_loss=1.2344 | val_acc=0.5267 | time=6.8s
2025-10-11 23:34:28,893 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.0707 | val_loss=1.1265 | val_acc=0.6044 | time=6.8s
2025-10-11 23:34:35,739 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.0636 | val_loss=1.1250 | val_acc=0.6061 | time=6.8s
2025-10-11 23:34:42,570 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.0571 | val_loss=1.2122 | val_acc=0.5452 | time=6.8s
2025-10-11 23:34:49,389 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.0508 | val_loss=1.1489 | val_acc=0.5852 | time=6.8s
2025-10-11 23:34:56,208 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.0466 | val_loss=1.1346 | val_acc=0.5873 | time=6.8s
2025-10-11 23:35:03,020 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.0384 | val_loss=1.1135 | val_acc=0.6084 | time=6.8s
2025-10-11 23:35:09,818 - INFO - _models.training_function_executor - Epoch 028 | train_loss=1.0376 | val_loss=1.1558 | val_acc=0.5940 | time=6.8s
2025-10-11 23:35:16,620 - INFO - _models.training_function_executor - Epoch 029 | train_loss=1.0321 | val_loss=1.0827 | val_acc=0.6334 | time=6.8s
2025-10-11 23:35:23,442 - INFO - _models.training_function_executor - Epoch 030 | train_loss=1.0298 | val_loss=1.1274 | val_acc=0.6096 | time=6.8s
2025-10-11 23:35:30,288 - INFO - _models.training_function_executor - Epoch 031 | train_loss=1.0253 | val_loss=1.1216 | val_acc=0.6105 | time=6.8s
2025-10-11 23:35:37,112 - INFO - _models.training_function_executor - Epoch 032 | train_loss=1.0218 | val_loss=1.1033 | val_acc=0.6192 | time=6.8s
2025-10-11 23:35:43,937 - INFO - _models.training_function_executor - Epoch 033 | train_loss=1.0185 | val_loss=1.1285 | val_acc=0.5978 | time=6.8s
2025-10-11 23:35:50,759 - INFO - _models.training_function_executor - Epoch 034 | train_loss=1.0160 | val_loss=1.1191 | val_acc=0.6066 | time=6.8s
2025-10-11 23:35:57,571 - INFO - _models.training_function_executor - Epoch 035 | train_loss=1.0134 | val_loss=1.1052 | val_acc=0.6205 | time=6.8s
2025-10-11 23:36:04,399 - INFO - _models.training_function_executor - Epoch 036 | train_loss=1.0093 | val_loss=1.0917 | val_acc=0.6271 | time=6.8s
2025-10-11 23:36:11,228 - INFO - _models.training_function_executor - Epoch 037 | train_loss=1.0058 | val_loss=1.1129 | val_acc=0.6125 | time=6.8s
2025-10-11 23:36:18,049 - INFO - _models.training_function_executor - Epoch 038 | train_loss=1.0071 | val_loss=1.0823 | val_acc=0.6292 | time=6.8s
2025-10-11 23:36:24,895 - INFO - _models.training_function_executor - Epoch 039 | train_loss=1.0046 | val_loss=1.1097 | val_acc=0.6122 | time=6.8s
2025-10-11 23:36:31,712 - INFO - _models.training_function_executor - Epoch 040 | train_loss=1.0032 | val_loss=1.1136 | val_acc=0.6103 | time=6.8s
2025-10-11 23:36:38,550 - INFO - _models.training_function_executor - Epoch 041 | train_loss=1.0013 | val_loss=1.0955 | val_acc=0.6214 | time=6.8s
2025-10-11 23:36:45,370 - INFO - _models.training_function_executor - Epoch 042 | train_loss=1.0011 | val_loss=1.0967 | val_acc=0.6200 | time=6.8s
2025-10-11 23:36:52,187 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.9992 | val_loss=1.0975 | val_acc=0.6191 | time=6.8s
2025-10-11 23:36:59,014 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.9999 | val_loss=1.1000 | val_acc=0.6193 | time=6.8s
2025-10-11 23:37:05,855 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.9991 | val_loss=1.1018 | val_acc=0.6161 | time=6.8s
2025-10-11 23:37:12,688 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.9988 | val_loss=1.0973 | val_acc=0.6212 | time=6.8s
2025-10-11 23:37:19,525 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.9987 | val_loss=1.0976 | val_acc=0.6209 | time=6.8s
2025-10-11 23:37:20,626 - INFO - _models.training_function_executor - Model: 3,351 parameters, 14.4KB storage
2025-10-11 23:37:20,627 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7564891978024268, 1.6145274322962244, 1.5901494646839864, 1.5633164164567845, 1.4889098840463904, 1.389100521740336, 1.3325966505673985, 1.3042547890070522, 1.2765781043124749, 1.2440442554678761, 1.2268147171586439, 1.2072616744241655, 1.1913917509303216, 1.1739968846443234, 1.1573672937796282, 1.1447580360799006, 1.1284498702904158, 1.1181907878629471, 1.1039300049160476, 1.0928889110924231, 1.0809508818609053, 1.070729874079673, 1.063588278497158, 1.0571320956615904, 1.050800379253585, 1.046561652459491, 1.0384393706865624, 1.0375510161785582, 1.0320807965674377, 1.0298222946570086, 1.0252954602825466, 1.0218262284931559, 1.0184763779666892, 1.0160335052505585, 1.013354253443577, 1.0093441669385361, 1.0058259378787602, 1.007143518155567, 1.0045540394943189, 1.0031525063464657, 1.0012964162482842, 1.0011102585545615, 0.999178582217161, 0.9998773332239449, 0.9990696099523567, 0.9988313786544692, 0.9987114336292088], 'val_losses': [1.662611651353996, 1.599319805313089, 1.584151806778082, 1.5511075967516978, 1.4424457000620539, 1.3889020794596751, 1.3660636171282337, 1.360862539134212, 1.3499958345343948, 1.3639413204939006, 1.2765706804211578, 1.3196063356359578, 1.3436860450486232, 1.2443902550795891, 1.2117343609892457, 1.2523913078800926, 1.246690026208675, 1.194798050479516, 1.1697337112946218, 1.1728229845702316, 1.2344333662667089, 1.1265051864378945, 1.12503759821034, 1.2122045715427932, 1.14885754258939, 1.1345923241623288, 1.1134897450495032, 1.1558436411719082, 1.0826778746517012, 1.1273673190084916, 1.1216418853019203, 1.1033390760421753, 1.1285219264097055, 1.1190703732674347, 1.1051582445978452, 1.0916675525670612, 1.1128540926472434, 1.0823474912670072, 1.109735731805503, 1.113614925625604, 1.0954896116722896, 1.0967364897275105, 1.0974931978313616, 1.099952214589998, 1.1018287223144616, 1.0972776945742815, 1.0975577007125876], 'val_acc': [0.22619880994049701, 0.21587329366468325, 0.28841442072103607, 0.3373293664683234, 0.4236086804340217, 0.43209660483024154, 0.4460098004900245, 0.4251837591879594, 0.4408470423521176, 0.43052152607630384, 0.5329891494574729, 0.4762863143157158, 0.4719985999299965, 0.5352642632131607, 0.5373643682184109, 0.530014000700035, 0.5390269513475674, 0.5531151557577879, 0.58969198459923, 0.5648407420371019, 0.5266888344417221, 0.6043927196359818, 0.6061428071403571, 0.5451522576128807, 0.5852292614630732, 0.5873293664683235, 0.6084179208960449, 0.5939796989849493, 0.6333566678333916, 0.6096429821491075, 0.6105180259012951, 0.6191809590479525, 0.5978298914945748, 0.6065803290164509, 0.6204935246762339, 0.6270563528176408, 0.6125306265313266, 0.6291564578228911, 0.6121806090304516, 0.6102555127756388, 0.6213685684284215, 0.6199684984249213, 0.6190934546727337, 0.6192684634231712, 0.6161183059152958, 0.621193559677984, 0.6209310465523277], 'best_epoch': 29, 'total_params': 3351, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0001642819730959757, 'batch_size': 32, 'epochs': 47, 'weight_decay': 6.994752957237263e-05, 'base_channels': 16, 'kernel_size': 10, 'dropout': 0.12448935973913747, 'amp': True, 'grad_clip_norm': 0.6254015079618731, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.052314661388803, 'label_smoothing': 0.038830404882529077, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 3}, 'model_parameter_count': 3351, 'model_storage_size_kb': 14.398828125000001, 'model_size_validation': 'PASS'}
2025-10-11 23:37:20,627 - INFO - _models.training_function_executor - BO Objective: base=0.6209, size_penalty=0.0000, final=0.6209
2025-10-11 23:37:20,627 - INFO - _models.training_function_executor - Model: 3,351 parameters, 14.4KB (PASS 256KB limit)
2025-10-11 23:37:20,627 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 324.694s
2025-10-11 23:37:20,711 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6209
2025-10-11 23:37:20,712 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.081s
2025-10-11 23:37:20,712 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.0001642819730959757, 'batch_size': np.int64(32), 'epochs': np.int64(47), 'weight_decay': 6.994752957237263e-05, 'base_channels': np.int64(16), 'kernel_size': np.int64(10), 'dropout': 0.12448935973913747, 'amp': np.True_, 'grad_clip_norm': 0.6254015079618731, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.052314661388803, 'label_smoothing': 0.038830404882529077, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(3)}, value=0.6209
2025-10-11 23:37:20,712 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.0001642819730959757, 'batch_size': np.int64(32), 'epochs': np.int64(47), 'weight_decay': 6.994752957237263e-05, 'base_channels': np.int64(16), 'kernel_size': np.int64(10), 'dropout': 0.12448935973913747, 'amp': np.True_, 'grad_clip_norm': 0.6254015079618731, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.052314661388803, 'label_smoothing': 0.038830404882529077, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(3)} -> 0.6209
2025-10-11 23:37:20,712 - INFO - bo.run_bo - üîçBO Trial 7: Using RF surrogate + Expected Improvement
2025-10-11 23:37:20,712 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:37:20,712 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:37:20,712 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:37:20,712 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0006893657258234715, 'batch_size': 32, 'epochs': 17, 'weight_decay': 1.5968689507937825e-06, 'base_channels': 7, 'kernel_size': 13, 'dropout': 0.1198375302038258, 'amp': True, 'grad_clip_norm': 0.8836745238050243, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.2739603435037352, 'label_smoothing': 0.040665905135210186, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-11 23:37:20,713 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0006893657258234715, 'batch_size': 32, 'epochs': 17, 'weight_decay': 1.5968689507937825e-06, 'base_channels': 7, 'kernel_size': 13, 'dropout': 0.1198375302038258, 'amp': True, 'grad_clip_norm': 0.8836745238050243, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.2739603435037352, 'label_smoothing': 0.040665905135210186, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-11 23:37:28,355 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3082 | val_loss=1.2177 | val_acc=0.5498 | time=7.6s
2025-10-11 23:37:33,137 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.1976 | val_loss=1.1759 | val_acc=0.5614 | time=4.8s
2025-10-11 23:37:37,919 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1393 | val_loss=1.1530 | val_acc=0.5746 | time=4.8s
2025-10-11 23:37:42,702 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0921 | val_loss=1.0743 | val_acc=0.5984 | time=4.8s
2025-10-11 23:37:47,491 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0567 | val_loss=1.0397 | val_acc=0.6214 | time=4.8s
2025-10-11 23:37:52,282 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0323 | val_loss=1.0755 | val_acc=0.6151 | time=4.8s
2025-10-11 23:37:57,076 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.0141 | val_loss=0.9938 | val_acc=0.6532 | time=4.8s
2025-10-11 23:38:01,874 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.9886 | val_loss=1.0258 | val_acc=0.6678 | time=4.8s
2025-10-11 23:38:06,668 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9744 | val_loss=0.9727 | val_acc=0.6777 | time=4.8s
2025-10-11 23:38:11,452 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9556 | val_loss=0.9497 | val_acc=0.6938 | time=4.8s
2025-10-11 23:38:16,229 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.9508 | val_loss=0.9642 | val_acc=0.6797 | time=4.8s
2025-10-11 23:38:21,011 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9400 | val_loss=0.9617 | val_acc=0.6772 | time=4.8s
2025-10-11 23:38:25,788 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9300 | val_loss=0.9275 | val_acc=0.7167 | time=4.8s
2025-10-11 23:38:30,562 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.9274 | val_loss=0.9500 | val_acc=0.6905 | time=4.8s
2025-10-11 23:38:35,343 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.9192 | val_loss=0.9092 | val_acc=0.7202 | time=4.8s
2025-10-11 23:38:40,121 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.9134 | val_loss=0.9207 | val_acc=0.7188 | time=4.8s
2025-10-11 23:38:44,892 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.9084 | val_loss=0.9006 | val_acc=0.7237 | time=4.8s
2025-10-11 23:38:46,005 - INFO - _models.training_function_executor - Model: 1,363 parameters, 5.9KB storage
2025-10-11 23:38:46,006 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3081656964697814, 1.1975910795827776, 1.1392845453458535, 1.0920712420204621, 1.0567406150659036, 1.0323121208173567, 1.0140786551361405, 0.9885537334886608, 0.9743540577741667, 0.9555914030782487, 0.9508486927348138, 0.9400095552143474, 0.9300460984775284, 0.9273726036700441, 0.9192355148770577, 0.913444592745843, 0.9084207015157664], 'val_losses': [1.2176720231937963, 1.1759303794892806, 1.1529815709790705, 1.0743327845075277, 1.0396698213822348, 1.075460496894474, 0.9937907875250171, 1.0258005507831467, 0.9727125592404904, 0.9496593290534099, 0.9642162561083639, 0.9617113900584215, 0.9275348524474565, 0.9500119837635722, 0.9092186129958936, 0.9207118741293859, 0.9006198916022338], 'val_acc': [0.549789989499475, 0.5614280714035702, 0.5746412320616031, 0.5984424221211061, 0.6213685684284215, 0.6150682534126707, 0.6532201610080504, 0.6678333916695834, 0.6777213860693034, 0.6938221911095555, 0.6797339866993349, 0.6771963598179909, 0.7166608330416521, 0.6904970248512425, 0.7202485124256213, 0.7188484424221211, 0.7237486874343717], 'best_epoch': 17, 'total_params': 1363, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0006893657258234715, 'batch_size': 32, 'epochs': 17, 'weight_decay': 1.5968689507937825e-06, 'base_channels': 7, 'kernel_size': 13, 'dropout': 0.1198375302038258, 'amp': True, 'grad_clip_norm': 0.8836745238050243, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.2739603435037352, 'label_smoothing': 0.040665905135210186, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}, 'model_parameter_count': 1363, 'model_storage_size_kb': 5.856640625000001, 'model_size_validation': 'PASS'}
2025-10-11 23:38:46,006 - INFO - _models.training_function_executor - BO Objective: base=0.7237, size_penalty=0.0000, final=0.7237
2025-10-11 23:38:46,006 - INFO - _models.training_function_executor - Model: 1,363 parameters, 5.9KB (PASS 256KB limit)
2025-10-11 23:38:46,006 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 85.294s
2025-10-11 23:38:46,088 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7237
2025-10-11 23:38:46,088 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.080s
2025-10-11 23:38:46,088 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 0.0006893657258234715, 'batch_size': np.int64(32), 'epochs': np.int64(17), 'weight_decay': 1.5968689507937825e-06, 'base_channels': np.int64(7), 'kernel_size': np.int64(13), 'dropout': 0.1198375302038258, 'amp': np.True_, 'grad_clip_norm': 0.8836745238050243, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.2739603435037352, 'label_smoothing': 0.040665905135210186, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)}, value=0.7237
2025-10-11 23:38:46,089 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 0.0006893657258234715, 'batch_size': np.int64(32), 'epochs': np.int64(17), 'weight_decay': 1.5968689507937825e-06, 'base_channels': np.int64(7), 'kernel_size': np.int64(13), 'dropout': 0.1198375302038258, 'amp': np.True_, 'grad_clip_norm': 0.8836745238050243, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.2739603435037352, 'label_smoothing': 0.040665905135210186, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)} -> 0.7237
2025-10-11 23:38:46,089 - INFO - bo.run_bo - üîçBO Trial 8: Using RF surrogate + Expected Improvement
2025-10-11 23:38:46,089 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:38:46,089 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:38:46,089 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:38:46,089 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0008872763269719729, 'batch_size': 16, 'epochs': 9, 'weight_decay': 7.409586782607159e-05, 'base_channels': 9, 'kernel_size': 3, 'dropout': 0.22307023655832445, 'amp': False, 'grad_clip_norm': 0.0696059558345299, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.7281537610577544, 'label_smoothing': 0.04288466723791749, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 1}
2025-10-11 23:38:46,090 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0008872763269719729, 'batch_size': 16, 'epochs': 9, 'weight_decay': 7.409586782607159e-05, 'base_channels': 9, 'kernel_size': 3, 'dropout': 0.22307023655832445, 'amp': False, 'grad_clip_norm': 0.0696059558345299, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.7281537610577544, 'label_smoothing': 0.04288466723791749, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 1}
2025-10-11 23:38:54,648 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3012 | val_loss=1.2345 | val_acc=0.5408 | time=8.6s
2025-10-11 23:39:00,356 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.1906 | val_loss=1.2439 | val_acc=0.5371 | time=5.7s
2025-10-11 23:39:06,063 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1711 | val_loss=1.2292 | val_acc=0.5731 | time=5.7s
2025-10-11 23:39:11,769 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1670 | val_loss=1.1804 | val_acc=0.5717 | time=5.7s
2025-10-11 23:39:17,460 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.1473 | val_loss=1.2426 | val_acc=0.5506 | time=5.7s
2025-10-11 23:39:23,149 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1248 | val_loss=1.2574 | val_acc=0.5536 | time=5.7s
2025-10-11 23:39:28,836 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1162 | val_loss=1.2318 | val_acc=0.5510 | time=5.7s
2025-10-11 23:39:34,537 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1075 | val_loss=1.3178 | val_acc=0.4847 | time=5.7s
2025-10-11 23:39:40,262 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.0974 | val_loss=1.1921 | val_acc=0.5859 | time=5.7s
2025-10-11 23:39:41,357 - INFO - _models.training_function_executor - Model: 1,179 parameters, 5.1KB storage
2025-10-11 23:39:41,357 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3012091616337476, 1.1906000864351385, 1.1711484453542107, 1.1669997131862047, 1.1473211027501886, 1.1248215942646516, 1.1162208030805498, 1.1075329008242614, 1.0973771039030125], 'val_losses': [1.2344615390250733, 1.2438710927129626, 1.2292092475857768, 1.180444273248419, 1.2425598718903281, 1.2573883941123536, 1.2317719899691069, 1.3178008111206803, 1.1920900273156332], 'val_acc': [0.5407770388519426, 0.5371018550927547, 0.5730661533076654, 0.5716660833041652, 0.5505775288764438, 0.5536401820091005, 0.5510150507525376, 0.48468673433671683, 0.5859292964648233], 'best_epoch': 9, 'total_params': 1179, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0008872763269719729, 'batch_size': 16, 'epochs': 9, 'weight_decay': 7.409586782607159e-05, 'base_channels': 9, 'kernel_size': 3, 'dropout': 0.22307023655832445, 'amp': False, 'grad_clip_norm': 0.0696059558345299, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.7281537610577544, 'label_smoothing': 0.04288466723791749, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 1}, 'model_parameter_count': 1179, 'model_storage_size_kb': 5.066015625, 'model_size_validation': 'PASS'}
2025-10-11 23:39:41,357 - INFO - _models.training_function_executor - BO Objective: base=0.5859, size_penalty=0.0000, final=0.5859
2025-10-11 23:39:41,357 - INFO - _models.training_function_executor - Model: 1,179 parameters, 5.1KB (PASS 256KB limit)
2025-10-11 23:39:41,357 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 55.269s
2025-10-11 23:39:41,444 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5859
2025-10-11 23:39:41,444 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.085s
2025-10-11 23:39:41,444 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 0.0008872763269719729, 'batch_size': np.int64(16), 'epochs': np.int64(9), 'weight_decay': 7.409586782607159e-05, 'base_channels': np.int64(9), 'kernel_size': np.int64(3), 'dropout': 0.22307023655832445, 'amp': np.False_, 'grad_clip_norm': 0.0696059558345299, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.7281537610577544, 'label_smoothing': 0.04288466723791749, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(1)}, value=0.5859
2025-10-11 23:39:41,444 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 0.0008872763269719729, 'batch_size': np.int64(16), 'epochs': np.int64(9), 'weight_decay': 7.409586782607159e-05, 'base_channels': np.int64(9), 'kernel_size': np.int64(3), 'dropout': 0.22307023655832445, 'amp': np.False_, 'grad_clip_norm': 0.0696059558345299, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.7281537610577544, 'label_smoothing': 0.04288466723791749, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(1)} -> 0.5859
2025-10-11 23:39:41,444 - INFO - bo.run_bo - üîçBO Trial 9: Using RF surrogate + Expected Improvement
2025-10-11 23:39:41,445 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:39:41,445 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:39:41,445 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:39:41,445 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002095328321213076, 'batch_size': 64, 'epochs': 15, 'weight_decay': 3.940885830816849e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.13326983354691246, 'amp': True, 'grad_clip_norm': 0.6462769269507518, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6674621969762917, 'label_smoothing': 0.10436660520690667, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}
2025-10-11 23:39:41,446 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002095328321213076, 'batch_size': 64, 'epochs': 15, 'weight_decay': 3.940885830816849e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.13326983354691246, 'amp': True, 'grad_clip_norm': 0.6462769269507518, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6674621969762917, 'label_smoothing': 0.10436660520690667, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}
2025-10-11 23:39:48,574 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.7642 | val_loss=0.6865 | val_acc=0.5394 | time=7.1s
2025-10-11 23:39:52,818 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.6333 | val_loss=0.6281 | val_acc=0.5595 | time=4.2s
2025-10-11 23:39:57,042 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5944 | val_loss=0.5828 | val_acc=0.6165 | time=4.2s
2025-10-11 23:40:01,265 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5700 | val_loss=0.5584 | val_acc=0.6296 | time=4.2s
2025-10-11 23:40:05,500 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5600 | val_loss=0.5659 | val_acc=0.6287 | time=4.2s
2025-10-11 23:40:09,729 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5396 | val_loss=0.5272 | val_acc=0.6656 | time=4.2s
2025-10-11 23:40:13,964 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5248 | val_loss=0.5278 | val_acc=0.6590 | time=4.2s
2025-10-11 23:40:18,204 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.5019 | val_loss=0.4965 | val_acc=0.6881 | time=4.2s
2025-10-11 23:40:22,444 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4767 | val_loss=0.5058 | val_acc=0.6756 | time=4.2s
2025-10-11 23:40:26,675 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4626 | val_loss=0.4574 | val_acc=0.7078 | time=4.2s
2025-10-11 23:40:30,911 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4573 | val_loss=0.4536 | val_acc=0.7088 | time=4.2s
2025-10-11 23:40:35,139 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4478 | val_loss=0.4443 | val_acc=0.7179 | time=4.2s
2025-10-11 23:40:39,366 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.4407 | val_loss=0.4301 | val_acc=0.7208 | time=4.2s
2025-10-11 23:40:43,602 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.4456 | val_loss=0.4483 | val_acc=0.7020 | time=4.2s
2025-10-11 23:40:47,846 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.4363 | val_loss=0.4302 | val_acc=0.7201 | time=4.2s
2025-10-11 23:40:48,969 - INFO - _models.training_function_executor - Model: 1,125 parameters, 2.4KB storage
2025-10-11 23:40:48,969 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7641659993391771, 0.6333261481948665, 0.594424499956878, 0.5700116075419046, 0.560039355454745, 0.539577014671339, 0.5248087543290811, 0.5018776946134501, 0.47669086502148555, 0.46257360663030533, 0.4573278564464796, 0.4477971146156738, 0.44067905249295536, 0.4456374856558713, 0.43631440286452955], 'val_losses': [0.6865062117576599, 0.6280766071221016, 0.5828210932915437, 0.5583563893200965, 0.5658682669674218, 0.5272004867399205, 0.5278266538454833, 0.4965478604732279, 0.5058069184172753, 0.45738913443501433, 0.4536466736700282, 0.4443003458683717, 0.43014572019683583, 0.4482729874509673, 0.4302227130815304], 'val_acc': [0.5393769688484424, 0.5595029751487575, 0.6164683234161709, 0.6295939796989849, 0.6287189359467973, 0.6655582779138957, 0.6589954497724886, 0.688134406720336, 0.6756212810640532, 0.7078228911445572, 0.7087854392719636, 0.7178858942947147, 0.7207735386769338, 0.702047602380119, 0.7200735036751837], 'best_epoch': 13, 'total_params': 1263, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002095328321213076, 'batch_size': 64, 'epochs': 15, 'weight_decay': 3.940885830816849e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.13326983354691246, 'amp': True, 'grad_clip_norm': 0.6462769269507518, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6674621969762917, 'label_smoothing': 0.10436660520690667, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}, 'model_parameter_count': 1125, 'model_storage_size_kb': 2.4169921875, 'model_size_validation': 'PASS'}
2025-10-11 23:40:48,969 - INFO - _models.training_function_executor - BO Objective: base=0.7201, size_penalty=0.0000, final=0.7201
2025-10-11 23:40:48,969 - INFO - _models.training_function_executor - Model: 1,125 parameters, 2.4KB (PASS 256KB limit)
2025-10-11 23:40:48,970 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 67.525s
2025-10-11 23:40:49,059 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7201
2025-10-11 23:40:49,060 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.086s
2025-10-11 23:40:49,060 - INFO - bo.run_bo - Recorded observation #9: hparams={'lr': 0.002095328321213076, 'batch_size': np.int64(64), 'epochs': np.int64(15), 'weight_decay': 3.940885830816849e-05, 'base_channels': np.int64(7), 'kernel_size': np.int64(10), 'dropout': 0.13326983354691246, 'amp': np.True_, 'grad_clip_norm': 0.6462769269507518, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6674621969762917, 'label_smoothing': 0.10436660520690667, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(5)}, value=0.7201
2025-10-11 23:40:49,060 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'lr': 0.002095328321213076, 'batch_size': np.int64(64), 'epochs': np.int64(15), 'weight_decay': 3.940885830816849e-05, 'base_channels': np.int64(7), 'kernel_size': np.int64(10), 'dropout': 0.13326983354691246, 'amp': np.True_, 'grad_clip_norm': 0.6462769269507518, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6674621969762917, 'label_smoothing': 0.10436660520690667, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(5)} -> 0.7201
2025-10-11 23:40:49,060 - INFO - bo.run_bo - üîçBO Trial 10: Using RF surrogate + Expected Improvement
2025-10-11 23:40:49,060 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:40:49,060 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:40:49,060 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:40:49,060 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0014847531925607554, 'batch_size': 16, 'epochs': 7, 'weight_decay': 1.010851297590104e-06, 'base_channels': 5, 'kernel_size': 10, 'dropout': 0.24525241859871338, 'amp': True, 'grad_clip_norm': 0.251308692531751, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4174035171248685, 'label_smoothing': 0.19264557243108293, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 1}
2025-10-11 23:40:49,061 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0014847531925607554, 'batch_size': 16, 'epochs': 7, 'weight_decay': 1.010851297590104e-06, 'base_channels': 5, 'kernel_size': 10, 'dropout': 0.24525241859871338, 'amp': True, 'grad_clip_norm': 0.251308692531751, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4174035171248685, 'label_smoothing': 0.19264557243108293, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 1}
2025-10-11 23:40:58,125 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0473 | val_loss=0.7981 | val_acc=0.5317 | time=9.1s
2025-10-11 23:41:04,320 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7100 | val_loss=0.8558 | val_acc=0.5146 | time=6.2s
2025-10-11 23:41:10,514 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6462 | val_loss=0.6001 | val_acc=0.6374 | time=6.2s
2025-10-11 23:41:16,754 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6066 | val_loss=0.5852 | val_acc=0.6677 | time=6.2s
2025-10-11 23:41:22,948 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5752 | val_loss=0.5713 | val_acc=0.6778 | time=6.2s
2025-10-11 23:41:29,149 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5484 | val_loss=0.5365 | val_acc=0.6973 | time=6.2s
2025-10-11 23:41:35,349 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5328 | val_loss=0.5476 | val_acc=0.6909 | time=6.2s
2025-10-11 23:41:36,465 - INFO - _models.training_function_executor - Model: 841 parameters, 1.8KB storage
2025-10-11 23:41:36,465 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0472835912794594, 0.70996848871168, 0.6462387083594433, 0.6066270126906733, 0.5752170069555865, 0.548407550062756, 0.5328184468009942], 'val_losses': [0.7981354232851442, 0.855775837381403, 0.6001422151818976, 0.5852299894277866, 0.5713164347243476, 0.5364977237436321, 0.547603930605875], 'val_acc': [0.5316765838291915, 0.5146132306615331, 0.6373818690934546, 0.6676583829191459, 0.6778088904445222, 0.6973223661183059, 0.6909345467273363], 'best_epoch': 6, 'total_params': 931, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0014847531925607554, 'batch_size': 16, 'epochs': 7, 'weight_decay': 1.010851297590104e-06, 'base_channels': 5, 'kernel_size': 10, 'dropout': 0.24525241859871338, 'amp': True, 'grad_clip_norm': 0.251308692531751, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4174035171248685, 'label_smoothing': 0.19264557243108293, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 1}, 'model_parameter_count': 841, 'model_storage_size_kb': 1.8068359375, 'model_size_validation': 'PASS'}
2025-10-11 23:41:36,465 - INFO - _models.training_function_executor - BO Objective: base=0.6909, size_penalty=0.0000, final=0.6909
2025-10-11 23:41:36,465 - INFO - _models.training_function_executor - Model: 841 parameters, 1.8KB (PASS 256KB limit)
2025-10-11 23:41:36,465 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 47.405s
2025-10-11 23:41:36,556 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6909
2025-10-11 23:41:36,556 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.089s
2025-10-11 23:41:36,556 - INFO - bo.run_bo - Recorded observation #10: hparams={'lr': 0.0014847531925607554, 'batch_size': np.int64(16), 'epochs': np.int64(7), 'weight_decay': 1.010851297590104e-06, 'base_channels': np.int64(5), 'kernel_size': np.int64(10), 'dropout': 0.24525241859871338, 'amp': np.True_, 'grad_clip_norm': 0.251308692531751, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4174035171248685, 'label_smoothing': 0.19264557243108293, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(1)}, value=0.6909
2025-10-11 23:41:36,556 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'lr': 0.0014847531925607554, 'batch_size': np.int64(16), 'epochs': np.int64(7), 'weight_decay': 1.010851297590104e-06, 'base_channels': np.int64(5), 'kernel_size': np.int64(10), 'dropout': 0.24525241859871338, 'amp': np.True_, 'grad_clip_norm': 0.251308692531751, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4174035171248685, 'label_smoothing': 0.19264557243108293, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(1)} -> 0.6909
2025-10-11 23:41:36,556 - INFO - bo.run_bo - üîçBO Trial 11: Using RF surrogate + Expected Improvement
2025-10-11 23:41:36,556 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:41:36,556 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:41:36,556 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:41:36,556 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0017067665214236434, 'batch_size': 16, 'epochs': 7, 'weight_decay': 2.1594206781412482e-05, 'base_channels': 16, 'kernel_size': 13, 'dropout': 0.23705217625594896, 'amp': True, 'grad_clip_norm': 0.38830951807005953, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3262480246035835, 'label_smoothing': 0.1482100145569159, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-11 23:41:36,557 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0017067665214236434, 'batch_size': 16, 'epochs': 7, 'weight_decay': 2.1594206781412482e-05, 'base_channels': 16, 'kernel_size': 13, 'dropout': 0.23705217625594896, 'amp': True, 'grad_clip_norm': 0.38830951807005953, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3262480246035835, 'label_smoothing': 0.1482100145569159, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-11 23:41:47,821 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5501 | val_loss=1.3681 | val_acc=0.5247 | time=11.3s
2025-10-11 23:41:56,202 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3365 | val_loss=1.2649 | val_acc=0.5632 | time=8.4s
2025-10-11 23:42:04,626 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2478 | val_loss=1.2432 | val_acc=0.6163 | time=8.4s
2025-10-11 23:42:13,046 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1981 | val_loss=1.1852 | val_acc=0.6497 | time=8.4s
2025-10-11 23:42:21,479 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.1631 | val_loss=1.2018 | val_acc=0.6394 | time=8.4s
2025-10-11 23:42:29,869 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1414 | val_loss=1.1780 | val_acc=0.6739 | time=8.4s
2025-10-11 23:42:38,279 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1275 | val_loss=1.1612 | val_acc=0.6838 | time=8.4s
2025-10-11 23:42:39,411 - INFO - _models.training_function_executor - Model: 3,523 parameters, 15.1KB storage
2025-10-11 23:42:39,411 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5501358058012822, 1.3364847985480606, 1.2478430240063305, 1.198065590620625, 1.1630711961259865, 1.1414173493278499, 1.1274982799714288], 'val_losses': [1.3680573911933631, 1.2648894134934965, 1.2431964748389237, 1.1851919260892, 1.2018479241357816, 1.178045377781341, 1.1612300395965576], 'val_acc': [0.5246762338116906, 0.5631781589079454, 0.6162933146657333, 0.6497199859992999, 0.6393944697234861, 0.673871193559678, 0.6837591879593979], 'best_epoch': 7, 'total_params': 3523, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0017067665214236434, 'batch_size': 16, 'epochs': 7, 'weight_decay': 2.1594206781412482e-05, 'base_channels': 16, 'kernel_size': 13, 'dropout': 0.23705217625594896, 'amp': True, 'grad_clip_norm': 0.38830951807005953, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3262480246035835, 'label_smoothing': 0.1482100145569159, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}, 'model_parameter_count': 3523, 'model_storage_size_kb': 15.137890625, 'model_size_validation': 'PASS'}
2025-10-11 23:42:39,411 - INFO - _models.training_function_executor - BO Objective: base=0.6838, size_penalty=0.0000, final=0.6838
2025-10-11 23:42:39,411 - INFO - _models.training_function_executor - Model: 3,523 parameters, 15.1KB (PASS 256KB limit)
2025-10-11 23:42:39,411 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 62.855s
2025-10-11 23:42:39,505 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6838
2025-10-11 23:42:39,505 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.091s
2025-10-11 23:42:39,505 - INFO - bo.run_bo - Recorded observation #11: hparams={'lr': 0.0017067665214236434, 'batch_size': np.int64(16), 'epochs': np.int64(7), 'weight_decay': 2.1594206781412482e-05, 'base_channels': np.int64(16), 'kernel_size': np.int64(13), 'dropout': 0.23705217625594896, 'amp': np.True_, 'grad_clip_norm': 0.38830951807005953, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3262480246035835, 'label_smoothing': 0.1482100145569159, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)}, value=0.6838
2025-10-11 23:42:39,505 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 11: {'lr': 0.0017067665214236434, 'batch_size': np.int64(16), 'epochs': np.int64(7), 'weight_decay': 2.1594206781412482e-05, 'base_channels': np.int64(16), 'kernel_size': np.int64(13), 'dropout': 0.23705217625594896, 'amp': np.True_, 'grad_clip_norm': 0.38830951807005953, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.3262480246035835, 'label_smoothing': 0.1482100145569159, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)} -> 0.6838
2025-10-11 23:42:39,505 - INFO - bo.run_bo - üîçBO Trial 12: Using RF surrogate + Expected Improvement
2025-10-11 23:42:39,505 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:42:39,506 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:42:39,506 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:42:39,506 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002882124680860368, 'batch_size': 16, 'epochs': 28, 'weight_decay': 5.380400545810427e-06, 'base_channels': 9, 'kernel_size': 15, 'dropout': 0.006481845710584656, 'amp': True, 'grad_clip_norm': 0.828139303524908, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4601238928286082, 'label_smoothing': 0.14753579397077407, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-11 23:42:39,507 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002882124680860368, 'batch_size': 16, 'epochs': 28, 'weight_decay': 5.380400545810427e-06, 'base_channels': 9, 'kernel_size': 15, 'dropout': 0.006481845710584656, 'amp': True, 'grad_clip_norm': 0.828139303524908, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4601238928286082, 'label_smoothing': 0.14753579397077407, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-11 23:42:49,329 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0213 | val_loss=0.8452 | val_acc=0.5211 | time=9.8s
2025-10-11 23:42:56,239 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.8080 | val_loss=0.7453 | val_acc=0.5723 | time=6.9s
2025-10-11 23:43:03,187 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.7123 | val_loss=0.7513 | val_acc=0.5908 | time=6.9s
2025-10-11 23:43:10,116 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6490 | val_loss=0.5813 | val_acc=0.6542 | time=6.9s
2025-10-11 23:43:17,002 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5940 | val_loss=0.5705 | val_acc=0.6664 | time=6.9s
2025-10-11 23:43:23,962 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5573 | val_loss=0.5798 | val_acc=0.6767 | time=7.0s
2025-10-11 23:43:30,890 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5413 | val_loss=0.4846 | val_acc=0.7181 | time=6.9s
2025-10-11 23:43:37,804 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.5310 | val_loss=0.5218 | val_acc=0.7224 | time=6.9s
2025-10-11 23:43:44,754 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.5102 | val_loss=0.5418 | val_acc=0.6734 | time=6.9s
2025-10-11 23:43:51,682 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.5060 | val_loss=0.4734 | val_acc=0.7152 | time=6.9s
2025-10-11 23:43:58,604 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4973 | val_loss=0.5137 | val_acc=0.7026 | time=6.9s
2025-10-11 23:44:05,546 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4835 | val_loss=0.4891 | val_acc=0.7110 | time=6.9s
2025-10-11 23:44:12,459 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.4859 | val_loss=0.4934 | val_acc=0.7101 | time=6.9s
2025-10-11 23:44:19,366 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.4681 | val_loss=0.4369 | val_acc=0.7493 | time=6.9s
2025-10-11 23:44:26,272 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.4643 | val_loss=0.4676 | val_acc=0.7309 | time=6.9s
2025-10-11 23:44:33,206 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.4613 | val_loss=0.4637 | val_acc=0.7306 | time=6.9s
2025-10-11 23:44:40,146 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.4524 | val_loss=0.4786 | val_acc=0.7151 | time=6.9s
2025-10-11 23:44:47,069 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.4386 | val_loss=0.4268 | val_acc=0.7460 | time=6.9s
2025-10-11 23:44:54,000 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.4326 | val_loss=0.4454 | val_acc=0.7520 | time=6.9s
2025-10-11 23:45:00,991 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.4236 | val_loss=0.4152 | val_acc=0.7537 | time=7.0s
2025-10-11 23:45:07,910 - INFO - _models.training_function_executor - Epoch 021 | train_loss=nan | val_loss=0.4385 | val_acc=0.7440 | time=6.9s
2025-10-11 23:45:14,839 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.4063 | val_loss=0.4134 | val_acc=0.7582 | time=6.9s
2025-10-11 23:45:21,720 - INFO - _models.training_function_executor - Epoch 023 | train_loss=nan | val_loss=0.4128 | val_acc=0.7601 | time=6.9s
2025-10-11 23:45:28,648 - INFO - _models.training_function_executor - Epoch 024 | train_loss=nan | val_loss=0.4252 | val_acc=0.7568 | time=6.9s
2025-10-11 23:45:35,575 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3898 | val_loss=0.4138 | val_acc=0.7621 | time=6.9s
2025-10-11 23:45:42,520 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.3890 | val_loss=0.4144 | val_acc=0.7620 | time=6.9s
2025-10-11 23:45:49,444 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.3855 | val_loss=0.4090 | val_acc=0.7612 | time=6.9s
2025-10-11 23:45:56,384 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.3841 | val_loss=0.4067 | val_acc=0.7623 | time=6.9s
2025-10-11 23:45:57,501 - INFO - _models.training_function_executor - Model: 1,875 parameters, 8.1KB storage
2025-10-11 23:45:57,501 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0213166097577402, 0.80804189373594, 0.7123206566013904, 0.6489952541353154, 0.5940298228063364, 0.5572642681818347, 0.54133840284441, 0.5309745458912758, 0.5101726026328702, 0.5059590476571909, 0.49731521338933743, 0.483475536389663, 0.4859310762841342, 0.46807588142038725, 0.46430677994511993, 0.46134692058097576, 0.4524197691114666, 0.43860432510171316, 0.43255520245372614, 0.42364624975588844, nan, 0.4062630027639499, nan, nan, 0.38982735700725385, 0.388978519573114, 0.3854788467196743, 0.38409087839798783], 'val_losses': [0.8451860970133668, 0.745337463675679, 0.751312746659859, 0.5813050737122556, 0.5704640598147066, 0.5797960763627833, 0.4845999579121183, 0.5217697112606122, 0.5418010878813017, 0.4733959433915732, 0.5137249712552224, 0.4890901976011016, 0.49335415307041647, 0.43691347416464266, 0.4676328255371614, 0.4637358510202461, 0.4785539594042551, 0.4267678406480309, 0.44535231843486534, 0.41518479408500913, 0.43852846130103496, 0.4133576223900268, 0.41275127524366745, 0.42516061824622686, 0.413793733184571, 0.4144378160263275, 0.40900926261202436, 0.4066952493849334], 'val_acc': [0.5210885544277214, 0.5722786139306966, 0.5908295414770739, 0.6541827091354567, 0.6664333216660833, 0.6766713335666783, 0.718148407420371, 0.7224361218060903, 0.6734336716835841, 0.7151732586629331, 0.7025726286314316, 0.7109730486524326, 0.710098004900245, 0.7492999649982499, 0.7309240462023101, 0.7305740287014351, 0.7150857542877144, 0.745974798739937, 0.7520126006300315, 0.753675183759188, 0.7439621981099055, 0.7582254112705635, 0.7600630031501575, 0.7568253412670634, 0.762075603780189, 0.7619880994049703, 0.7612005600280014, 0.7623381169058453], 'best_epoch': 28, 'total_params': 1875, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002882124680860368, 'batch_size': 16, 'epochs': 28, 'weight_decay': 5.380400545810427e-06, 'base_channels': 9, 'kernel_size': 15, 'dropout': 0.006481845710584656, 'amp': True, 'grad_clip_norm': 0.828139303524908, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4601238928286082, 'label_smoothing': 0.14753579397077407, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}, 'model_parameter_count': 1875, 'model_storage_size_kb': 8.056640625, 'model_size_validation': 'PASS'}
2025-10-11 23:45:57,501 - INFO - _models.training_function_executor - BO Objective: base=0.7623, size_penalty=0.0000, final=0.7623
2025-10-11 23:45:57,501 - INFO - _models.training_function_executor - Model: 1,875 parameters, 8.1KB (PASS 256KB limit)
2025-10-11 23:45:57,501 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 197.995s
2025-10-11 23:45:57,593 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7623
2025-10-11 23:45:57,593 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.091s
2025-10-11 23:45:57,593 - INFO - bo.run_bo - Recorded observation #12: hparams={'lr': 0.002882124680860368, 'batch_size': np.int64(16), 'epochs': np.int64(28), 'weight_decay': 5.380400545810427e-06, 'base_channels': np.int64(9), 'kernel_size': np.int64(15), 'dropout': 0.006481845710584656, 'amp': np.True_, 'grad_clip_norm': 0.828139303524908, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4601238928286082, 'label_smoothing': 0.14753579397077407, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}, value=0.7623
2025-10-11 23:45:57,593 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 12: {'lr': 0.002882124680860368, 'batch_size': np.int64(16), 'epochs': np.int64(28), 'weight_decay': 5.380400545810427e-06, 'base_channels': np.int64(9), 'kernel_size': np.int64(15), 'dropout': 0.006481845710584656, 'amp': np.True_, 'grad_clip_norm': 0.828139303524908, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4601238928286082, 'label_smoothing': 0.14753579397077407, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)} -> 0.7623
2025-10-11 23:45:57,593 - INFO - bo.run_bo - üîçBO Trial 13: Using RF surrogate + Expected Improvement
2025-10-11 23:45:57,593 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:45:57,594 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:45:57,594 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:45:57,594 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.000189960475762057, 'batch_size': 64, 'epochs': 48, 'weight_decay': 2.289550955557165e-05, 'base_channels': 4, 'kernel_size': 14, 'dropout': 0.1514272003535837, 'amp': False, 'grad_clip_norm': 0.9674477307630878, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.466082151389052, 'label_smoothing': 0.12754776440594373, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}
2025-10-11 23:45:57,595 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.000189960475762057, 'batch_size': 64, 'epochs': 48, 'weight_decay': 2.289550955557165e-05, 'base_channels': 4, 'kernel_size': 14, 'dropout': 0.1514272003535837, 'amp': False, 'grad_clip_norm': 0.9674477307630878, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.466082151389052, 'label_smoothing': 0.12754776440594373, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}
2025-10-11 23:46:04,184 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5923 | val_loss=1.5070 | val_acc=0.3913 | time=6.6s
2025-10-11 23:46:07,903 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.4583 | val_loss=1.4504 | val_acc=0.3999 | time=3.7s
2025-10-11 23:46:11,607 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.4318 | val_loss=1.4379 | val_acc=0.4069 | time=3.7s
2025-10-11 23:46:15,327 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.4174 | val_loss=1.4365 | val_acc=0.4093 | time=3.7s
2025-10-11 23:46:19,044 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.4075 | val_loss=1.4196 | val_acc=0.4278 | time=3.7s
2025-10-11 23:46:22,764 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.3994 | val_loss=1.4058 | val_acc=0.4364 | time=3.7s
2025-10-11 23:46:26,476 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.3934 | val_loss=1.3966 | val_acc=0.4461 | time=3.7s
2025-10-11 23:46:30,198 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.3867 | val_loss=1.4007 | val_acc=0.4522 | time=3.7s
2025-10-11 23:46:33,911 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.3813 | val_loss=1.3939 | val_acc=0.4494 | time=3.7s
2025-10-11 23:46:37,635 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.3778 | val_loss=1.3818 | val_acc=0.4597 | time=3.7s
2025-10-11 23:46:41,350 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.3735 | val_loss=1.3939 | val_acc=0.4629 | time=3.7s
2025-10-11 23:46:45,061 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.3721 | val_loss=1.3890 | val_acc=0.4574 | time=3.7s
2025-10-11 23:46:48,766 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.3686 | val_loss=1.3809 | val_acc=0.4671 | time=3.7s
2025-10-11 23:46:52,481 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.3684 | val_loss=1.3700 | val_acc=0.4902 | time=3.7s
2025-10-11 23:46:56,201 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.3664 | val_loss=1.4079 | val_acc=0.4392 | time=3.7s
2025-10-11 23:46:59,909 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.3671 | val_loss=1.3877 | val_acc=0.4672 | time=3.7s
2025-10-11 23:47:03,624 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.3636 | val_loss=1.4027 | val_acc=0.4626 | time=3.7s
2025-10-11 23:47:07,353 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.3640 | val_loss=1.3754 | val_acc=0.4800 | time=3.7s
2025-10-11 23:47:11,069 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.3638 | val_loss=1.3811 | val_acc=0.4680 | time=3.7s
2025-10-11 23:47:14,783 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.3625 | val_loss=1.4083 | val_acc=0.4443 | time=3.7s
2025-10-11 23:47:18,486 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.3600 | val_loss=1.3644 | val_acc=0.4782 | time=3.7s
2025-10-11 23:47:22,201 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.3558 | val_loss=1.3956 | val_acc=0.4602 | time=3.7s
2025-10-11 23:47:25,920 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.3516 | val_loss=1.3543 | val_acc=0.5021 | time=3.7s
2025-10-11 23:47:29,631 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.3488 | val_loss=1.3642 | val_acc=0.5034 | time=3.7s
2025-10-11 23:47:33,360 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.3476 | val_loss=1.4065 | val_acc=0.4857 | time=3.7s
2025-10-11 23:47:37,080 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.3435 | val_loss=1.3615 | val_acc=0.5293 | time=3.7s
2025-10-11 23:47:40,806 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.3389 | val_loss=1.3904 | val_acc=0.5056 | time=3.7s
2025-10-11 23:47:44,528 - INFO - _models.training_function_executor - Epoch 028 | train_loss=1.3375 | val_loss=1.3598 | val_acc=0.5305 | time=3.7s
2025-10-11 23:47:48,242 - INFO - _models.training_function_executor - Epoch 029 | train_loss=1.3322 | val_loss=1.4005 | val_acc=0.4996 | time=3.7s
2025-10-11 23:47:51,958 - INFO - _models.training_function_executor - Epoch 030 | train_loss=1.3263 | val_loss=1.3745 | val_acc=0.5112 | time=3.7s
2025-10-11 23:47:55,672 - INFO - _models.training_function_executor - Epoch 031 | train_loss=1.3245 | val_loss=1.3569 | val_acc=0.5327 | time=3.7s
2025-10-11 23:47:59,396 - INFO - _models.training_function_executor - Epoch 032 | train_loss=1.3197 | val_loss=1.3439 | val_acc=0.5473 | time=3.7s
2025-10-11 23:48:03,108 - INFO - _models.training_function_executor - Epoch 033 | train_loss=1.3150 | val_loss=1.3752 | val_acc=0.5178 | time=3.7s
2025-10-11 23:48:06,829 - INFO - _models.training_function_executor - Epoch 034 | train_loss=1.3136 | val_loss=1.3453 | val_acc=0.5382 | time=3.7s
2025-10-11 23:48:10,551 - INFO - _models.training_function_executor - Epoch 035 | train_loss=1.3101 | val_loss=1.3569 | val_acc=0.5337 | time=3.7s
2025-10-11 23:48:14,267 - INFO - _models.training_function_executor - Epoch 036 | train_loss=1.3071 | val_loss=1.3319 | val_acc=0.5377 | time=3.7s
2025-10-11 23:48:17,986 - INFO - _models.training_function_executor - Epoch 037 | train_loss=1.3036 | val_loss=1.3332 | val_acc=0.5427 | time=3.7s
2025-10-11 23:48:21,704 - INFO - _models.training_function_executor - Epoch 038 | train_loss=1.3010 | val_loss=1.3244 | val_acc=0.5480 | time=3.7s
2025-10-11 23:48:25,415 - INFO - _models.training_function_executor - Epoch 039 | train_loss=1.3001 | val_loss=1.3361 | val_acc=0.5375 | time=3.7s
2025-10-11 23:48:29,141 - INFO - _models.training_function_executor - Epoch 040 | train_loss=1.2958 | val_loss=1.3321 | val_acc=0.5422 | time=3.7s
2025-10-11 23:48:32,851 - INFO - _models.training_function_executor - Epoch 041 | train_loss=1.2926 | val_loss=1.3220 | val_acc=0.5466 | time=3.7s
2025-10-11 23:48:36,573 - INFO - _models.training_function_executor - Epoch 042 | train_loss=1.2902 | val_loss=1.3248 | val_acc=0.5341 | time=3.7s
2025-10-11 23:48:40,293 - INFO - _models.training_function_executor - Epoch 043 | train_loss=1.2884 | val_loss=1.3281 | val_acc=0.5400 | time=3.7s
2025-10-11 23:48:44,002 - INFO - _models.training_function_executor - Epoch 044 | train_loss=1.2851 | val_loss=1.3116 | val_acc=0.5580 | time=3.7s
2025-10-11 23:48:47,723 - INFO - _models.training_function_executor - Epoch 045 | train_loss=1.2827 | val_loss=1.3119 | val_acc=0.5492 | time=3.7s
2025-10-11 23:48:51,442 - INFO - _models.training_function_executor - Epoch 046 | train_loss=1.2788 | val_loss=1.3025 | val_acc=0.5641 | time=3.7s
2025-10-11 23:48:55,148 - INFO - _models.training_function_executor - Epoch 047 | train_loss=1.2773 | val_loss=1.3151 | val_acc=0.5438 | time=3.7s
2025-10-11 23:48:58,861 - INFO - _models.training_function_executor - Epoch 048 | train_loss=1.2764 | val_loss=1.3014 | val_acc=0.5653 | time=3.7s
2025-10-11 23:48:59,969 - INFO - _models.training_function_executor - Model: 935 parameters, 1.0KB storage
2025-10-11 23:48:59,969 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5923128253096468, 1.4582556777900748, 1.4318356330578144, 1.4173584214457264, 1.4075338413665344, 1.399376018397458, 1.3933545732831623, 1.3867483079016625, 1.3813041942102926, 1.3778193975662019, 1.3734754970857312, 1.3721017830855362, 1.3686205905634206, 1.368427470680717, 1.3664267955126461, 1.3671059036588336, 1.3635756495949272, 1.364032141978924, 1.3638079233102864, 1.3624577280524728, 1.3599887821224186, 1.3558042776334536, 1.3516044114853119, 1.348798841029614, 1.3476452075518095, 1.3434578287017929, 1.3389346417847212, 1.3374812404592553, 1.332180115559718, 1.326273477661026, 1.324468963629716, 1.319716935557919, 1.315039906635151, 1.3136463535415543, 1.310138434129995, 1.3070744724540444, 1.3035922175520784, 1.3009792521283343, 1.3001024774738126, 1.295794841459581, 1.2925565796298581, 1.29017786096026, 1.2884074409524877, 1.2850781770852895, 1.2826919147184679, 1.2787768620711106, 1.2773361726240677, 1.2763790118944396], 'val_losses': [1.5070026706716868, 1.4504144438152207, 1.4379173936790595, 1.4364884898649248, 1.4196019752065563, 1.405841870014894, 1.3965900230674104, 1.4006973012199615, 1.3939085386318868, 1.3818323831984451, 1.3939382244088796, 1.3890106065313244, 1.3809123778476395, 1.3700331915690247, 1.4078670573634142, 1.3877175300480933, 1.402665397974366, 1.3754257942711174, 1.381063351418053, 1.4083276147948962, 1.3643733489446799, 1.395552730427108, 1.3543114149370672, 1.364216659988105, 1.406530535420892, 1.3615428848639546, 1.3903793083222884, 1.3597926933672175, 1.4004736745823696, 1.3745443434688631, 1.356919632277675, 1.3438612489060984, 1.3751987898149969, 1.3452666824756387, 1.356915732335778, 1.3319131928449237, 1.3331742906037656, 1.3244000460182488, 1.3361400585600784, 1.332098333529254, 1.3220294614077945, 1.3247790429845203, 1.3281094721575688, 1.31156147125713, 1.3118938394098973, 1.3025013907661651, 1.315082058560249, 1.3014192481280704], 'val_acc': [0.3913195659782989, 0.3998949947497375, 0.4068953447672384, 0.4092579628981449, 0.42780889044452225, 0.4363843192159608, 0.44609730486524324, 0.4522226111305565, 0.44942247112355616, 0.4596604830241512, 0.46289814490724535, 0.4573853692684634, 0.4670983549177459, 0.49019950997549877, 0.4391844592229611, 0.46718585929296463, 0.46263563178158906, 0.47996149807490374, 0.4679733986699335, 0.44425971298564926, 0.4782114105705285, 0.46018550927546376, 0.5021001050052503, 0.5034126706335317, 0.48573678683934196, 0.5293139656982849, 0.5056002800140007, 0.5304515225761288, 0.4995624781239062, 0.5112005600280014, 0.5327266363318166, 0.5473398669933497, 0.5177633881694085, 0.5382394119705985, 0.533689184459223, 0.537714385719286, 0.5427021351067554, 0.547952397619881, 0.5374518725936297, 0.5421771088554428, 0.5465523276163808, 0.5341267063353168, 0.5399894994749738, 0.5580154007700385, 0.5491774588729437, 0.5641407070353518, 0.5438396919845992, 0.5652782639131957], 'best_epoch': 48, 'total_params': 935, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.000189960475762057, 'batch_size': 64, 'epochs': 48, 'weight_decay': 2.289550955557165e-05, 'base_channels': 4, 'kernel_size': 14, 'dropout': 0.1514272003535837, 'amp': False, 'grad_clip_norm': 0.9674477307630878, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.466082151389052, 'label_smoothing': 0.12754776440594373, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}, 'model_parameter_count': 935, 'model_storage_size_kb': 1.00439453125, 'model_size_validation': 'PASS'}
2025-10-11 23:48:59,969 - INFO - _models.training_function_executor - BO Objective: base=0.5653, size_penalty=0.0000, final=0.5653
2025-10-11 23:48:59,969 - INFO - _models.training_function_executor - Model: 935 parameters, 1.0KB (PASS 256KB limit)
2025-10-11 23:48:59,969 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 182.376s
2025-10-11 23:49:00,202 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.5653
2025-10-11 23:49:00,202 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.228s
2025-10-11 23:49:00,202 - INFO - bo.run_bo - Recorded observation #13: hparams={'lr': 0.000189960475762057, 'batch_size': np.int64(64), 'epochs': np.int64(48), 'weight_decay': 2.289550955557165e-05, 'base_channels': np.int64(4), 'kernel_size': np.int64(14), 'dropout': 0.1514272003535837, 'amp': np.False_, 'grad_clip_norm': 0.9674477307630878, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.466082151389052, 'label_smoothing': 0.12754776440594373, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(3)}, value=0.5653
2025-10-11 23:49:00,202 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 13: {'lr': 0.000189960475762057, 'batch_size': np.int64(64), 'epochs': np.int64(48), 'weight_decay': 2.289550955557165e-05, 'base_channels': np.int64(4), 'kernel_size': np.int64(14), 'dropout': 0.1514272003535837, 'amp': np.False_, 'grad_clip_norm': 0.9674477307630878, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 1.466082151389052, 'label_smoothing': 0.12754776440594373, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(3)} -> 0.5653
2025-10-11 23:49:00,202 - INFO - bo.run_bo - üîçBO Trial 14: Using RF surrogate + Expected Improvement
2025-10-11 23:49:00,202 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:49:00,202 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:49:00,202 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:49:00,202 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0026709557267038, 'batch_size': 32, 'epochs': 25, 'weight_decay': 8.308774921641045e-05, 'base_channels': 5, 'kernel_size': 11, 'dropout': 0.006923183312818916, 'amp': True, 'grad_clip_norm': 0.8447053548189536, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.3407915606587912, 'label_smoothing': 0.09441805349045114, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}
2025-10-11 23:49:00,204 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0026709557267038, 'batch_size': 32, 'epochs': 25, 'weight_decay': 8.308774921641045e-05, 'base_channels': 5, 'kernel_size': 11, 'dropout': 0.006923183312818916, 'amp': True, 'grad_clip_norm': 0.8447053548189536, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.3407915606587912, 'label_smoothing': 0.09441805349045114, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}
2025-10-11 23:49:07,423 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9339 | val_loss=0.8578 | val_acc=0.3161 | time=7.2s
2025-10-11 23:49:11,745 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7360 | val_loss=0.6524 | val_acc=0.5124 | time=4.3s
2025-10-11 23:49:16,058 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6190 | val_loss=0.5986 | val_acc=0.5445 | time=4.3s
2025-10-11 23:49:20,389 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5804 | val_loss=0.5532 | val_acc=0.5690 | time=4.3s
2025-10-11 23:49:24,701 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5409 | val_loss=0.5203 | val_acc=0.5841 | time=4.3s
2025-10-11 23:49:29,020 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5138 | val_loss=0.5497 | val_acc=0.5645 | time=4.3s
2025-10-11 23:49:33,326 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4979 | val_loss=0.5125 | val_acc=0.5970 | time=4.3s
2025-10-11 23:49:37,676 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4754 | val_loss=0.4707 | val_acc=0.6100 | time=4.3s
2025-10-11 23:49:42,006 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4659 | val_loss=0.4455 | val_acc=0.6334 | time=4.3s
2025-10-11 23:49:46,328 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4503 | val_loss=0.4400 | val_acc=0.6448 | time=4.3s
2025-10-11 23:49:50,635 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4308 | val_loss=0.4119 | val_acc=0.6659 | time=4.3s
2025-10-11 23:49:54,933 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4095 | val_loss=0.4119 | val_acc=0.6683 | time=4.3s
2025-10-11 23:49:59,241 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3955 | val_loss=0.3829 | val_acc=0.6910 | time=4.3s
2025-10-11 23:50:03,574 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3865 | val_loss=0.3889 | val_acc=0.7059 | time=4.3s
2025-10-11 23:50:07,923 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3768 | val_loss=0.3808 | val_acc=0.7032 | time=4.3s
2025-10-11 23:50:12,259 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3683 | val_loss=0.3576 | val_acc=0.7113 | time=4.3s
2025-10-11 23:50:16,570 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3644 | val_loss=0.3664 | val_acc=0.7117 | time=4.3s
2025-10-11 23:50:20,898 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3552 | val_loss=0.3634 | val_acc=0.7132 | time=4.3s
2025-10-11 23:50:25,229 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3520 | val_loss=0.3654 | val_acc=0.7135 | time=4.3s
2025-10-11 23:50:29,571 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3446 | val_loss=0.3598 | val_acc=0.7081 | time=4.3s
2025-10-11 23:50:33,891 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3406 | val_loss=0.3580 | val_acc=0.7199 | time=4.3s
2025-10-11 23:50:38,209 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3373 | val_loss=0.3504 | val_acc=0.7235 | time=4.3s
2025-10-11 23:50:42,545 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3348 | val_loss=0.3469 | val_acc=0.7242 | time=4.3s
2025-10-11 23:50:46,869 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3331 | val_loss=0.3475 | val_acc=0.7256 | time=4.3s
2025-10-11 23:50:51,197 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3322 | val_loss=0.3470 | val_acc=0.7247 | time=4.3s
2025-10-11 23:50:52,312 - INFO - _models.training_function_executor - Model: 931 parameters, 4.0KB storage
2025-10-11 23:50:52,312 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9339410999256719, 0.7360393844800366, 0.6190219430384559, 0.5804316202521408, 0.5408995050475512, 0.5138038698612517, 0.49790532322844233, 0.47536849637728956, 0.4658759434044653, 0.45034544186587094, 0.43077275818089994, 0.40951715558871593, 0.3954958865866117, 0.38652955587924653, 0.3767872345435027, 0.36832849711617693, 0.36439542099572797, 0.35522308155237337, 0.35199984810605095, 0.34463693317810584, 0.3406402709091602, 0.33732659121528213, 0.3348199996896521, 0.33312838331146455, 0.33219084038318997], 'val_losses': [0.8578365500079853, 0.6523965380711263, 0.5985733868356523, 0.5532471849765191, 0.5203019194929294, 0.5496833299042126, 0.5124864574084734, 0.47069647059094305, 0.4455356870949601, 0.4400116545278267, 0.4118604619867642, 0.41190095424818596, 0.3828959374287941, 0.3889291417582075, 0.3808381980774123, 0.3575939447436919, 0.3664271704561218, 0.36343352987779587, 0.3654084570664267, 0.3598447655998795, 0.35799631705330737, 0.3503716680840407, 0.34693111167107216, 0.3475371872246598, 0.34704120186620585], 'val_acc': [0.3160658032901645, 0.5124256212810641, 0.5444522226111306, 0.5689534476723836, 0.5840917045852293, 0.5644907245362268, 0.5969548477423872, 0.6099929996499825, 0.6333566678333916, 0.6448197409870493, 0.6659082954147707, 0.6682709135456772, 0.6910220511025551, 0.7058977948897445, 0.7031851592579629, 0.7113230661533076, 0.7116730836541827, 0.7132481624081204, 0.7135106755337767, 0.7080854042702135, 0.7198984949247462, 0.7234861743087154, 0.7241862093104655, 0.7255862793139657, 0.7247112355617781], 'best_epoch': 24, 'total_params': 931, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0026709557267038, 'batch_size': 32, 'epochs': 25, 'weight_decay': 8.308774921641045e-05, 'base_channels': 5, 'kernel_size': 11, 'dropout': 0.006923183312818916, 'amp': True, 'grad_clip_norm': 0.8447053548189536, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.3407915606587912, 'label_smoothing': 0.09441805349045114, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}, 'model_parameter_count': 931, 'model_storage_size_kb': 4.0003906250000005, 'model_size_validation': 'PASS'}
2025-10-11 23:50:52,312 - INFO - _models.training_function_executor - BO Objective: base=0.7247, size_penalty=0.0000, final=0.7247
2025-10-11 23:50:52,312 - INFO - _models.training_function_executor - Model: 931 parameters, 4.0KB (PASS 256KB limit)
2025-10-11 23:50:52,312 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 112.110s
2025-10-11 23:50:52,409 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7247
2025-10-11 23:50:52,409 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-11 23:50:52,409 - INFO - bo.run_bo - Recorded observation #14: hparams={'lr': 0.0026709557267038, 'batch_size': np.int64(32), 'epochs': np.int64(25), 'weight_decay': 8.308774921641045e-05, 'base_channels': np.int64(5), 'kernel_size': np.int64(11), 'dropout': 0.006923183312818916, 'amp': np.True_, 'grad_clip_norm': 0.8447053548189536, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.3407915606587912, 'label_smoothing': 0.09441805349045114, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(6)}, value=0.7247
2025-10-11 23:50:52,409 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 14: {'lr': 0.0026709557267038, 'batch_size': np.int64(32), 'epochs': np.int64(25), 'weight_decay': 8.308774921641045e-05, 'base_channels': np.int64(5), 'kernel_size': np.int64(11), 'dropout': 0.006923183312818916, 'amp': np.True_, 'grad_clip_norm': 0.8447053548189536, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.3407915606587912, 'label_smoothing': 0.09441805349045114, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(6)} -> 0.7247
2025-10-11 23:50:52,409 - INFO - bo.run_bo - üîçBO Trial 15: Using RF surrogate + Expected Improvement
2025-10-11 23:50:52,409 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:50:52,409 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:50:52,409 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:50:52,409 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0038754538224044627, 'batch_size': 32, 'epochs': 34, 'weight_decay': 0.00016420718965041788, 'base_channels': 12, 'kernel_size': 13, 'dropout': 0.09728509149485862, 'amp': True, 'grad_clip_norm': 0.14049885334780068, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.7652351727132727, 'label_smoothing': 0.12046340074185254, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}
2025-10-11 23:50:52,411 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0038754538224044627, 'batch_size': 32, 'epochs': 34, 'weight_decay': 0.00016420718965041788, 'base_channels': 12, 'kernel_size': 13, 'dropout': 0.09728509149485862, 'amp': True, 'grad_clip_norm': 0.14049885334780068, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.7652351727132727, 'label_smoothing': 0.12046340074185254, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}
2025-10-11 23:51:01,641 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3285 | val_loss=1.2929 | val_acc=0.5719 | time=9.2s
2025-10-11 23:51:08,010 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.1944 | val_loss=1.1594 | val_acc=0.6106 | time=6.4s
2025-10-11 23:51:14,391 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1386 | val_loss=1.1465 | val_acc=0.6380 | time=6.4s
2025-10-11 23:51:20,783 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1233 | val_loss=1.1144 | val_acc=0.6513 | time=6.4s
2025-10-11 23:51:27,166 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.1184 | val_loss=1.0921 | val_acc=0.7023 | time=6.4s
2025-10-11 23:51:33,554 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1066 | val_loss=1.0776 | val_acc=0.7106 | time=6.4s
2025-10-11 23:51:39,928 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1004 | val_loss=1.0957 | val_acc=0.6702 | time=6.4s
2025-10-11 23:51:46,311 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.0941 | val_loss=1.0794 | val_acc=0.6447 | time=6.4s
2025-10-11 23:51:52,689 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.0843 | val_loss=1.0726 | val_acc=0.6887 | time=6.4s
2025-10-11 23:51:59,079 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.0792 | val_loss=1.1589 | val_acc=0.6104 | time=6.4s
2025-10-11 23:52:05,444 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.0749 | val_loss=1.1364 | val_acc=0.6439 | time=6.4s
2025-10-11 23:52:11,813 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.0766 | val_loss=1.1260 | val_acc=0.6250 | time=6.4s
2025-10-11 23:52:18,074 - INFO - _models.training_function_executor - Epoch 013 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.3s
2025-10-11 23:52:24,210 - INFO - _models.training_function_executor - Epoch 014 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:52:30,337 - INFO - _models.training_function_executor - Epoch 015 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:52:36,467 - INFO - _models.training_function_executor - Epoch 016 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:52:42,606 - INFO - _models.training_function_executor - Epoch 017 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:52:48,740 - INFO - _models.training_function_executor - Epoch 018 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:52:54,874 - INFO - _models.training_function_executor - Epoch 019 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:01,006 - INFO - _models.training_function_executor - Epoch 020 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:07,138 - INFO - _models.training_function_executor - Epoch 021 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:13,288 - INFO - _models.training_function_executor - Epoch 022 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:19,429 - INFO - _models.training_function_executor - Epoch 023 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:25,564 - INFO - _models.training_function_executor - Epoch 024 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:31,699 - INFO - _models.training_function_executor - Epoch 025 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:37,837 - INFO - _models.training_function_executor - Epoch 026 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:43,973 - INFO - _models.training_function_executor - Epoch 027 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:50,108 - INFO - _models.training_function_executor - Epoch 028 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:53:56,258 - INFO - _models.training_function_executor - Epoch 029 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:54:02,396 - INFO - _models.training_function_executor - Epoch 030 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:54:08,526 - INFO - _models.training_function_executor - Epoch 031 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:54:14,664 - INFO - _models.training_function_executor - Epoch 032 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:54:20,802 - INFO - _models.training_function_executor - Epoch 033 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:54:26,942 - INFO - _models.training_function_executor - Epoch 034 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-11 23:54:28,072 - INFO - _models.training_function_executor - Model: 2,443 parameters, 10.5KB storage
2025-10-11 23:54:28,072 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3285373479357292, 1.1944044585658422, 1.1385629142473592, 1.1233038921886762, 1.118395471631271, 1.1066392628857937, 1.1004447386429976, 1.0941057882165475, 1.0842927698074645, 1.0792076218954076, 1.0749014948864264, 1.0766359175978382, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.292858201698218, 1.1593939890075662, 1.1465288638735616, 1.1144136112162522, 1.0920696736381041, 1.0775710191140628, 1.095678903703583, 1.0794358741304728, 1.0725775792279058, 1.1588883449911405, 1.136443832067138, 1.126025558183979, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5719285964298215, 0.6106055302765139, 0.637994399719986, 0.6512950647532376, 0.7023101155057753, 0.7106230311515576, 0.67019600980049, 0.6447322366118305, 0.6886594329716486, 0.6104305215260764, 0.6439446972348617, 0.6249562478123907, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'best_epoch': 6, 'total_params': 2443, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0038754538224044627, 'batch_size': 32, 'epochs': 34, 'weight_decay': 0.00016420718965041788, 'base_channels': 12, 'kernel_size': 13, 'dropout': 0.09728509149485862, 'amp': True, 'grad_clip_norm': 0.14049885334780068, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.7652351727132727, 'label_smoothing': 0.12046340074185254, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}, 'model_parameter_count': 2443, 'model_storage_size_kb': 10.497265625, 'model_size_validation': 'PASS'}
2025-10-11 23:54:28,072 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-11 23:54:28,072 - INFO - _models.training_function_executor - Model: 2,443 parameters, 10.5KB (PASS 256KB limit)
2025-10-11 23:54:28,072 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 215.663s
2025-10-11 23:54:28,170 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-11 23:54:28,170 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-11 23:54:28,170 - INFO - bo.run_bo - Recorded observation #15: hparams={'lr': 0.0038754538224044627, 'batch_size': np.int64(32), 'epochs': np.int64(34), 'weight_decay': 0.00016420718965041788, 'base_channels': np.int64(12), 'kernel_size': np.int64(13), 'dropout': 0.09728509149485862, 'amp': np.True_, 'grad_clip_norm': 0.14049885334780068, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.7652351727132727, 'label_smoothing': 0.12046340074185254, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(5)}, value=0.2325
2025-10-11 23:54:28,170 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 15: {'lr': 0.0038754538224044627, 'batch_size': np.int64(32), 'epochs': np.int64(34), 'weight_decay': 0.00016420718965041788, 'base_channels': np.int64(12), 'kernel_size': np.int64(13), 'dropout': 0.09728509149485862, 'amp': np.True_, 'grad_clip_norm': 0.14049885334780068, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('class_weights'), 'focal_gamma': 2.7652351727132727, 'label_smoothing': 0.12046340074185254, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(5)} -> 0.2325
2025-10-11 23:54:28,171 - INFO - bo.run_bo - üîçBO Trial 16: Using RF surrogate + Expected Improvement
2025-10-11 23:54:28,171 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:54:28,171 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:54:28,171 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:54:28,171 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001279823985017862, 'batch_size': 64, 'epochs': 31, 'weight_decay': 0.0004812436674821566, 'base_channels': 4, 'kernel_size': 12, 'dropout': 0.0647420317902325, 'amp': True, 'grad_clip_norm': 0.6925526476326626, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9381917755320135, 'label_smoothing': 0.024479855377798714, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-11 23:54:28,172 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001279823985017862, 'batch_size': 64, 'epochs': 31, 'weight_decay': 0.0004812436674821566, 'base_channels': 4, 'kernel_size': 12, 'dropout': 0.0647420317902325, 'amp': True, 'grad_clip_norm': 0.6925526476326626, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9381917755320135, 'label_smoothing': 0.024479855377798714, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-11 23:54:35,902 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3533 | val_loss=1.1621 | val_acc=0.5520 | time=7.7s
2025-10-11 23:54:40,356 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.1235 | val_loss=1.1009 | val_acc=0.5728 | time=4.5s
2025-10-11 23:54:44,800 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.0843 | val_loss=1.0822 | val_acc=0.5913 | time=4.4s
2025-10-11 23:54:49,249 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0645 | val_loss=1.0714 | val_acc=0.6030 | time=4.4s
2025-10-11 23:54:53,701 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0327 | val_loss=1.0437 | val_acc=0.6165 | time=4.5s
2025-10-11 23:54:58,141 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0248 | val_loss=1.0100 | val_acc=0.6358 | time=4.4s
2025-10-11 23:55:02,578 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.0134 | val_loss=1.0284 | val_acc=0.6492 | time=4.4s
2025-10-11 23:55:07,025 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.0152 | val_loss=1.0079 | val_acc=0.6440 | time=4.4s
2025-10-11 23:55:11,476 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.0090 | val_loss=1.0081 | val_acc=0.6526 | time=4.5s
2025-10-11 23:55:15,927 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9987 | val_loss=1.0031 | val_acc=0.6566 | time=4.5s
2025-10-11 23:55:20,381 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.0009 | val_loss=0.9749 | val_acc=0.6552 | time=4.5s
2025-10-11 23:55:24,825 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9881 | val_loss=0.9733 | val_acc=0.6658 | time=4.4s
2025-10-11 23:55:29,257 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9725 | val_loss=0.9720 | val_acc=0.6777 | time=4.4s
2025-10-11 23:55:33,694 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.9640 | val_loss=1.0027 | val_acc=0.6621 | time=4.4s
2025-10-11 23:55:38,129 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.9453 | val_loss=0.9540 | val_acc=0.6926 | time=4.4s
2025-10-11 23:55:42,582 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.9364 | val_loss=0.9504 | val_acc=0.6712 | time=4.5s
2025-10-11 23:55:47,027 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.9211 | val_loss=0.9640 | val_acc=0.6709 | time=4.4s
2025-10-11 23:55:51,470 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.9209 | val_loss=0.9192 | val_acc=0.7003 | time=4.4s
2025-10-11 23:55:55,908 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.9145 | val_loss=0.9183 | val_acc=0.7053 | time=4.4s
2025-10-11 23:56:00,350 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.9070 | val_loss=0.9044 | val_acc=0.7088 | time=4.4s
2025-10-11 23:56:04,789 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.9053 | val_loss=0.9478 | val_acc=0.6921 | time=4.4s
2025-10-11 23:56:09,221 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.9026 | val_loss=0.9034 | val_acc=0.7096 | time=4.4s
2025-10-11 23:56:13,669 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8983 | val_loss=0.8922 | val_acc=0.7039 | time=4.4s
2025-10-11 23:56:18,115 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8979 | val_loss=0.9352 | val_acc=0.6713 | time=4.4s
2025-10-11 23:56:22,550 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8929 | val_loss=0.8797 | val_acc=0.7132 | time=4.4s
2025-10-11 23:56:27,008 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8891 | val_loss=0.9185 | val_acc=0.6889 | time=4.5s
2025-10-11 23:56:31,458 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8881 | val_loss=0.8880 | val_acc=0.7076 | time=4.5s
2025-10-11 23:56:35,900 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8872 | val_loss=0.8934 | val_acc=0.7032 | time=4.4s
2025-10-11 23:56:40,351 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8808 | val_loss=0.8830 | val_acc=0.7080 | time=4.5s
2025-10-11 23:56:44,785 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8854 | val_loss=0.8678 | val_acc=0.7241 | time=4.4s
2025-10-11 23:56:49,227 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8740 | val_loss=0.8680 | val_acc=0.7214 | time=4.4s
2025-10-11 23:56:50,344 - INFO - _models.training_function_executor - Model: 859 parameters, 0.9KB storage
2025-10-11 23:56:50,344 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3532654612214414, 1.1235270114211768, 1.0842527726313451, 1.0645218553242983, 1.0327410036033684, 1.0247865469305666, 1.0134413376554743, 1.0152105716558604, 1.0090116998532435, 0.9987184006017404, 1.0008746121313188, 0.9881036174880875, 0.9724614837786535, 0.9640188904075356, 0.945288060845195, 0.9364244907052367, 0.921097760267191, 0.9209299962003747, 0.9144827084941464, 0.9069656252861023, 0.9053204624802916, 0.9025660481486287, 0.8983100274226049, 0.8979063834343757, 0.8928930634385223, 0.8890502741286804, 0.8881115965909891, 0.8872414685629465, 0.8807638161665909, 0.8854440156396453, 0.8739774340516204], 'val_losses': [1.1621078562470122, 1.1009176566614118, 1.0822054410779942, 1.0714087999066828, 1.0436850240110684, 1.0100452233959176, 1.0283993689041564, 1.007900386549241, 1.0080898500687583, 1.003145941475916, 0.9749093012436808, 0.9732874718458293, 0.9719534133399665, 1.0027151314239928, 0.9540427500309225, 0.9503611819038178, 0.9640160069785304, 0.919193423327121, 0.9182837805268484, 0.9043690069427703, 0.9477628213067294, 0.903426474699095, 0.8922490474232082, 0.9352030394463565, 0.879664625868451, 0.9184690424183893, 0.8879991743151702, 0.8933931379344876, 0.8829540690230258, 0.867796134682341, 0.8679714908812965], 'val_acc': [0.551977598879944, 0.5728036401820091, 0.5912670633531677, 0.6029926496324817, 0.6164683234161709, 0.6358067903395169, 0.6491949597479874, 0.6440322016100805, 0.652607630381519, 0.656632831641582, 0.6552327616380819, 0.6658207910395519, 0.6777213860693034, 0.662145607280364, 0.6925971298564928, 0.6711585579278964, 0.6708960448022401, 0.7002975148757438, 0.7052852642632131, 0.7087854392719636, 0.6920721036051802, 0.7095729786489324, 0.703885194259713, 0.6713335666783339, 0.7131606580329016, 0.6889219460973048, 0.7076478823941197, 0.7031851592579629, 0.7079978998949947, 0.7240987049352468, 0.7213860693034652], 'best_epoch': 30, 'total_params': 859, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001279823985017862, 'batch_size': 64, 'epochs': 31, 'weight_decay': 0.0004812436674821566, 'base_channels': 4, 'kernel_size': 12, 'dropout': 0.0647420317902325, 'amp': True, 'grad_clip_norm': 0.6925526476326626, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9381917755320135, 'label_smoothing': 0.024479855377798714, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}, 'model_parameter_count': 859, 'model_storage_size_kb': 0.9227539062500001, 'model_size_validation': 'PASS'}
2025-10-11 23:56:50,344 - INFO - _models.training_function_executor - BO Objective: base=0.7214, size_penalty=0.0000, final=0.7214
2025-10-11 23:56:50,344 - INFO - _models.training_function_executor - Model: 859 parameters, 0.9KB (PASS 256KB limit)
2025-10-11 23:56:50,344 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 142.173s
2025-10-11 23:56:50,442 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7214
2025-10-11 23:56:50,442 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-11 23:56:50,442 - INFO - bo.run_bo - Recorded observation #16: hparams={'lr': 0.001279823985017862, 'batch_size': np.int64(64), 'epochs': np.int64(31), 'weight_decay': 0.0004812436674821566, 'base_channels': np.int64(4), 'kernel_size': np.int64(12), 'dropout': 0.0647420317902325, 'amp': np.True_, 'grad_clip_norm': 0.6925526476326626, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9381917755320135, 'label_smoothing': 0.024479855377798714, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)}, value=0.7214
2025-10-11 23:56:50,442 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 16: {'lr': 0.001279823985017862, 'batch_size': np.int64(64), 'epochs': np.int64(31), 'weight_decay': 0.0004812436674821566, 'base_channels': np.int64(4), 'kernel_size': np.int64(12), 'dropout': 0.0647420317902325, 'amp': np.True_, 'grad_clip_norm': 0.6925526476326626, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9381917755320135, 'label_smoothing': 0.024479855377798714, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)} -> 0.7214
2025-10-11 23:56:50,443 - INFO - bo.run_bo - üîçBO Trial 17: Using RF surrogate + Expected Improvement
2025-10-11 23:56:50,443 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-11 23:56:50,443 - INFO - _models.training_function_executor - Using device: cuda
2025-10-11 23:56:50,443 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-11 23:56:50,443 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003769188749475096, 'batch_size': 32, 'epochs': 48, 'weight_decay': 1.4639244328467286e-06, 'base_channels': 10, 'kernel_size': 13, 'dropout': 0.05133665021502378, 'amp': True, 'grad_clip_norm': 0.7933607786518067, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.93795705787326, 'label_smoothing': 0.11022031758440387, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}
2025-10-11 23:56:50,444 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003769188749475096, 'batch_size': 32, 'epochs': 48, 'weight_decay': 1.4639244328467286e-06, 'base_channels': 10, 'kernel_size': 13, 'dropout': 0.05133665021502378, 'amp': True, 'grad_clip_norm': 0.7933607786518067, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.93795705787326, 'label_smoothing': 0.11022031758440387, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}
2025-10-11 23:56:58,791 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5368 | val_loss=1.4082 | val_acc=0.4983 | time=8.3s
2025-10-11 23:57:04,283 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3473 | val_loss=1.3076 | val_acc=0.5651 | time=5.5s
2025-10-11 23:57:09,771 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2929 | val_loss=1.2440 | val_acc=0.5940 | time=5.5s
2025-10-11 23:57:15,247 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.2179 | val_loss=1.1997 | val_acc=0.6050 | time=5.5s
2025-10-11 23:57:20,730 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.1800 | val_loss=1.1774 | val_acc=0.6024 | time=5.5s
2025-10-11 23:57:26,209 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1514 | val_loss=1.1430 | val_acc=0.6454 | time=5.5s
2025-10-11 23:57:31,689 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1268 | val_loss=1.1091 | val_acc=0.6575 | time=5.5s
2025-10-11 23:57:37,167 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.0931 | val_loss=1.0676 | val_acc=0.6750 | time=5.5s
2025-10-11 23:57:42,651 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.0589 | val_loss=1.1122 | val_acc=0.6472 | time=5.5s
2025-10-11 23:57:48,134 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.0457 | val_loss=1.0533 | val_acc=0.6830 | time=5.5s
2025-10-11 23:57:53,620 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.0346 | val_loss=1.0558 | val_acc=0.6994 | time=5.5s
2025-10-11 23:57:59,094 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.0336 | val_loss=1.0049 | val_acc=0.7182 | time=5.5s
2025-10-11 23:58:04,581 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.0317 | val_loss=1.0527 | val_acc=0.6815 | time=5.5s
2025-10-11 23:58:10,064 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.0244 | val_loss=1.0316 | val_acc=0.7013 | time=5.5s
2025-10-11 23:58:15,540 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.0202 | val_loss=0.9972 | val_acc=0.7263 | time=5.5s
2025-10-11 23:58:21,014 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.0102 | val_loss=1.0138 | val_acc=0.7188 | time=5.5s
2025-10-11 23:58:26,494 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.0081 | val_loss=0.9916 | val_acc=0.7394 | time=5.5s
2025-10-11 23:58:31,976 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.0032 | val_loss=1.0173 | val_acc=0.7061 | time=5.5s
2025-10-11 23:58:37,455 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.9987 | val_loss=0.9968 | val_acc=0.7185 | time=5.5s
2025-10-11 23:58:42,940 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.9936 | val_loss=1.0012 | val_acc=0.7272 | time=5.5s
2025-10-11 23:58:48,417 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.9942 | val_loss=0.9776 | val_acc=0.7321 | time=5.5s
2025-10-11 23:58:53,899 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.9908 | val_loss=1.0155 | val_acc=0.7120 | time=5.5s
2025-10-11 23:58:59,384 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.9861 | val_loss=1.0284 | val_acc=0.6959 | time=5.5s
2025-10-11 23:59:04,866 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.9821 | val_loss=0.9753 | val_acc=0.7326 | time=5.5s
2025-10-11 23:59:10,348 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.9824 | val_loss=0.9721 | val_acc=0.7315 | time=5.5s
2025-10-11 23:59:15,825 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.9754 | val_loss=0.9563 | val_acc=0.7445 | time=5.5s
2025-10-11 23:59:21,309 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.9729 | val_loss=0.9928 | val_acc=0.7202 | time=5.5s
2025-10-11 23:59:26,789 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.9718 | val_loss=0.9579 | val_acc=0.7452 | time=5.5s
2025-10-11 23:59:32,276 - INFO - _models.training_function_executor - Epoch 029 | train_loss=nan | val_loss=0.9684 | val_acc=0.7361 | time=5.5s
2025-10-11 23:59:37,757 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.9638 | val_loss=0.9593 | val_acc=0.7457 | time=5.5s
2025-10-11 23:59:43,247 - INFO - _models.training_function_executor - Epoch 031 | train_loss=nan | val_loss=0.9656 | val_acc=0.7382 | time=5.5s
2025-10-11 23:59:48,732 - INFO - _models.training_function_executor - Epoch 032 | train_loss=nan | val_loss=0.9653 | val_acc=0.7391 | time=5.5s
2025-10-11 23:59:54,215 - INFO - _models.training_function_executor - Epoch 033 | train_loss=nan | val_loss=0.9579 | val_acc=0.7398 | time=5.5s
2025-10-11 23:59:59,700 - INFO - _models.training_function_executor - Epoch 034 | train_loss=nan | val_loss=0.9471 | val_acc=0.7429 | time=5.5s
2025-10-12 00:00:05,182 - INFO - _models.training_function_executor - Epoch 035 | train_loss=nan | val_loss=0.9515 | val_acc=0.7391 | time=5.5s
2025-10-12 00:00:10,665 - INFO - _models.training_function_executor - Epoch 036 | train_loss=nan | val_loss=0.9472 | val_acc=0.7443 | time=5.5s
2025-10-12 00:00:16,146 - INFO - _models.training_function_executor - Epoch 037 | train_loss=nan | val_loss=0.9634 | val_acc=0.7371 | time=5.5s
2025-10-12 00:00:21,630 - INFO - _models.training_function_executor - Epoch 038 | train_loss=nan | val_loss=0.9408 | val_acc=0.7510 | time=5.5s
2025-10-12 00:00:27,117 - INFO - _models.training_function_executor - Epoch 039 | train_loss=nan | val_loss=0.9416 | val_acc=0.7477 | time=5.5s
2025-10-12 00:00:32,603 - INFO - _models.training_function_executor - Epoch 040 | train_loss=nan | val_loss=0.9365 | val_acc=0.7506 | time=5.5s
2025-10-12 00:00:38,085 - INFO - _models.training_function_executor - Epoch 041 | train_loss=nan | val_loss=0.9356 | val_acc=0.7526 | time=5.5s
2025-10-12 00:00:43,570 - INFO - _models.training_function_executor - Epoch 042 | train_loss=nan | val_loss=0.9437 | val_acc=0.7512 | time=5.5s
2025-10-12 00:00:49,050 - INFO - _models.training_function_executor - Epoch 043 | train_loss=nan | val_loss=0.9486 | val_acc=0.7515 | time=5.5s
2025-10-12 00:00:54,547 - INFO - _models.training_function_executor - Epoch 044 | train_loss=nan | val_loss=0.9432 | val_acc=0.7512 | time=5.5s
2025-10-12 00:01:00,035 - INFO - _models.training_function_executor - Epoch 045 | train_loss=nan | val_loss=0.9501 | val_acc=0.7523 | time=5.5s
2025-10-12 00:01:05,520 - INFO - _models.training_function_executor - Epoch 046 | train_loss=nan | val_loss=0.9462 | val_acc=0.7506 | time=5.5s
2025-10-12 00:01:11,009 - INFO - _models.training_function_executor - Epoch 047 | train_loss=nan | val_loss=0.9562 | val_acc=0.7465 | time=5.5s
2025-10-12 00:01:16,492 - INFO - _models.training_function_executor - Epoch 048 | train_loss=nan | val_loss=0.9570 | val_acc=0.7457 | time=5.5s
2025-10-12 00:01:17,617 - INFO - _models.training_function_executor - Model: 1,975 parameters, 8.5KB storage
2025-10-12 00:01:17,617 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5368468302625973, 1.3472879513149247, 1.2929255493126022, 1.217879266401869, 1.1799742408863225, 1.1514462895790458, 1.1268326693935942, 1.0931436618447221, 1.0588555587931394, 1.0457172254067855, 1.0346061516425424, 1.0336278700761814, 1.0317187290495304, 1.0244373363827892, 1.0202141842114667, 1.0102213408414762, 1.0081363135989185, 1.0031777398831532, 0.9986784436887924, 0.993605551601207, 0.9942019009940519, 0.9907916290848467, 0.9861220785001511, 0.9820511221802259, 0.9823971352350304, 0.9753997517766612, 0.9728607251312117, 0.971846404360924, nan, 0.9637748906043462, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.4082400798797607, 1.3076378283553949, 1.243988142333217, 1.199664432243262, 1.1773575266313288, 1.1429826404129326, 1.1090977458314524, 1.0676258559333545, 1.1121668337776673, 1.053258486133714, 1.0558253315240977, 1.0049160464182911, 1.0526912548688536, 1.0315688240794496, 0.997172689138178, 1.013848100294614, 0.9915987020098297, 1.0173430541041177, 0.9967559492787835, 1.0011983950044856, 0.9775685814505849, 1.015492110944993, 1.0284445900157844, 0.9752632829064097, 0.9720533376965443, 0.956304532189609, 0.992838971275191, 0.9579115386781746, 0.9683803359889451, 0.9592537971515229, 0.9656089429415804, 0.9652687943847486, 0.9579424535096025, 0.9470958286823508, 0.9515148056618994, 0.9471739921822894, 0.9634197985326778, 0.9408203546561342, 0.9416058915953397, 0.9365201387658465, 0.935572327348773, 0.9437103539538783, 0.948617140174578, 0.94321451839788, 0.9501318893286103, 0.9462322855794896, 0.9561928948543591, 0.9570408043914667], 'val_acc': [0.49833741687084354, 0.5651032551627582, 0.5939796989849493, 0.6050052502625132, 0.6023801190059503, 0.6454322716135806, 0.6575078753937696, 0.6750087504375218, 0.6471823591179559, 0.6829716485824291, 0.6994224711235562, 0.7182359117955898, 0.6814840742037102, 0.7012600630031501, 0.7262863143157158, 0.7188484424221211, 0.7394119705985299, 0.706072803640182, 0.718498424921246, 0.7271613580679034, 0.7321491074553728, 0.7120231011550577, 0.6959222961148057, 0.7325866293314666, 0.7315365768288414, 0.7444872243612181, 0.7202485124256213, 0.7451872593629681, 0.736086804340217, 0.7457122856142807, 0.7381869093454673, 0.7391494574728736, 0.7398494924746237, 0.7429121456072804, 0.7391494574728736, 0.7443122156107805, 0.7371368568428421, 0.7509625481274064, 0.7477248862443122, 0.7506125306265313, 0.7526251312565628, 0.7512250612530627, 0.7514875743787189, 0.7512250612530627, 0.7522751137556878, 0.7506125306265313, 0.7464998249912496, 0.7457122856142807], 'best_epoch': 41, 'total_params': 1975, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003769188749475096, 'batch_size': 32, 'epochs': 48, 'weight_decay': 1.4639244328467286e-06, 'base_channels': 10, 'kernel_size': 13, 'dropout': 0.05133665021502378, 'amp': True, 'grad_clip_norm': 0.7933607786518067, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.93795705787326, 'label_smoothing': 0.11022031758440387, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}, 'model_parameter_count': 1975, 'model_storage_size_kb': 8.486328125, 'model_size_validation': 'PASS'}
2025-10-12 00:01:17,617 - INFO - _models.training_function_executor - BO Objective: base=0.7457, size_penalty=0.0000, final=0.7457
2025-10-12 00:01:17,617 - INFO - _models.training_function_executor - Model: 1,975 parameters, 8.5KB (PASS 256KB limit)
2025-10-12 00:01:17,617 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 267.174s
2025-10-12 00:01:17,717 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7457
2025-10-12 00:01:17,717 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.097s
2025-10-12 00:01:17,717 - INFO - bo.run_bo - Recorded observation #17: hparams={'lr': 0.003769188749475096, 'batch_size': np.int64(32), 'epochs': np.int64(48), 'weight_decay': 1.4639244328467286e-06, 'base_channels': np.int64(10), 'kernel_size': np.int64(13), 'dropout': 0.05133665021502378, 'amp': np.True_, 'grad_clip_norm': 0.7933607786518067, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.93795705787326, 'label_smoothing': 0.11022031758440387, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(5)}, value=0.7457
2025-10-12 00:01:17,717 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 17: {'lr': 0.003769188749475096, 'batch_size': np.int64(32), 'epochs': np.int64(48), 'weight_decay': 1.4639244328467286e-06, 'base_channels': np.int64(10), 'kernel_size': np.int64(13), 'dropout': 0.05133665021502378, 'amp': np.True_, 'grad_clip_norm': 0.7933607786518067, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.93795705787326, 'label_smoothing': 0.11022031758440387, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(5)} -> 0.7457
2025-10-12 00:01:17,717 - INFO - bo.run_bo - üîçBO Trial 18: Using RF surrogate + Expected Improvement
2025-10-12 00:01:17,717 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:01:17,717 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:01:17,717 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:01:17,717 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0024636587098568427, 'batch_size': 32, 'epochs': 11, 'weight_decay': 4.146851723640572e-06, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.013732259310554232, 'amp': True, 'grad_clip_norm': 0.02694099780430837, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.1736960390852544, 'label_smoothing': 0.07435117485032226, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-12 00:01:17,719 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0024636587098568427, 'batch_size': 32, 'epochs': 11, 'weight_decay': 4.146851723640572e-06, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.013732259310554232, 'amp': True, 'grad_clip_norm': 0.02694099780430837, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.1736960390852544, 'label_smoothing': 0.07435117485032226, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-12 00:01:25,963 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0795 | val_loss=0.8248 | val_acc=0.5666 | time=8.2s
2025-10-12 00:01:31,348 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7850 | val_loss=0.7448 | val_acc=0.6084 | time=5.4s
2025-10-12 00:01:36,732 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.7191 | val_loss=0.6552 | val_acc=0.6383 | time=5.4s
2025-10-12 00:01:42,117 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6578 | val_loss=0.7490 | val_acc=0.6167 | time=5.4s
2025-10-12 00:01:47,503 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5833 | val_loss=0.5667 | val_acc=0.7115 | time=5.4s
2025-10-12 00:01:52,891 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5389 | val_loss=0.6325 | val_acc=0.6502 | time=5.4s
2025-10-12 00:01:58,280 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5174 | val_loss=0.5043 | val_acc=0.7323 | time=5.4s
2025-10-12 00:02:03,662 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4980 | val_loss=0.5079 | val_acc=0.7321 | time=5.4s
2025-10-12 00:02:09,036 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4791 | val_loss=0.4963 | val_acc=0.7379 | time=5.4s
2025-10-12 00:02:14,408 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4688 | val_loss=0.4813 | val_acc=0.7481 | time=5.4s
2025-10-12 00:02:19,800 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4615 | val_loss=0.4790 | val_acc=0.7455 | time=5.4s
2025-10-12 00:02:20,903 - INFO - _models.training_function_executor - Model: 1,851 parameters, 8.0KB storage
2025-10-12 00:02:20,903 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0794966733063578, 0.7850213684636951, 0.7191148896664485, 0.6578368554484852, 0.5832817942383741, 0.5389257684360441, 0.5174082691140572, 0.4979520710700037, 0.4790667032886836, 0.46882812327400963, 0.46154686226721325], 'val_losses': [0.8247658424703769, 0.744827286158194, 0.6552318441135258, 0.7490169350994366, 0.5666681188861085, 0.6324689120220739, 0.5043149300793696, 0.5079232942958117, 0.49628955633613653, 0.4812685612526686, 0.4790100582651586], 'val_acc': [0.5665908295414771, 0.6084179208960449, 0.6382569128456422, 0.6167308365418271, 0.7114980749037452, 0.6501575078753937, 0.7323241162058103, 0.7321491074553728, 0.737924396219811, 0.7480749037451873, 0.7455372768638432], 'best_epoch': 10, 'total_params': 1851, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0024636587098568427, 'batch_size': 32, 'epochs': 11, 'weight_decay': 4.146851723640572e-06, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.013732259310554232, 'amp': True, 'grad_clip_norm': 0.02694099780430837, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.1736960390852544, 'label_smoothing': 0.07435117485032226, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}, 'model_parameter_count': 1851, 'model_storage_size_kb': 7.9535156250000005, 'model_size_validation': 'PASS'}
2025-10-12 00:02:20,903 - INFO - _models.training_function_executor - BO Objective: base=0.7455, size_penalty=0.0000, final=0.7455
2025-10-12 00:02:20,904 - INFO - _models.training_function_executor - Model: 1,851 parameters, 8.0KB (PASS 256KB limit)
2025-10-12 00:02:20,904 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 63.186s
2025-10-12 00:02:21,004 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7455
2025-10-12 00:02:21,004 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.097s
2025-10-12 00:02:21,004 - INFO - bo.run_bo - Recorded observation #18: hparams={'lr': 0.0024636587098568427, 'batch_size': np.int64(32), 'epochs': np.int64(11), 'weight_decay': 4.146851723640572e-06, 'base_channels': np.int64(10), 'kernel_size': np.int64(10), 'dropout': 0.013732259310554232, 'amp': np.True_, 'grad_clip_norm': 0.02694099780430837, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.1736960390852544, 'label_smoothing': 0.07435117485032226, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)}, value=0.7455
2025-10-12 00:02:21,004 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 18: {'lr': 0.0024636587098568427, 'batch_size': np.int64(32), 'epochs': np.int64(11), 'weight_decay': 4.146851723640572e-06, 'base_channels': np.int64(10), 'kernel_size': np.int64(10), 'dropout': 0.013732259310554232, 'amp': np.True_, 'grad_clip_norm': 0.02694099780430837, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.1736960390852544, 'label_smoothing': 0.07435117485032226, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)} -> 0.7455
2025-10-12 00:02:21,004 - INFO - bo.run_bo - üîçBO Trial 19: Using RF surrogate + Expected Improvement
2025-10-12 00:02:21,004 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:02:21,004 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:02:21,004 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:02:21,004 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0035437210011721584, 'batch_size': 32, 'epochs': 11, 'weight_decay': 0.0006262158276921634, 'base_channels': 10, 'kernel_size': 13, 'dropout': 0.04104402212406619, 'amp': True, 'grad_clip_norm': 0.004879171693529361, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.178704734520836, 'label_smoothing': 0.06610280971558621, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:02:21,005 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0035437210011721584, 'batch_size': 32, 'epochs': 11, 'weight_decay': 0.0006262158276921634, 'base_channels': 10, 'kernel_size': 13, 'dropout': 0.04104402212406619, 'amp': True, 'grad_clip_norm': 0.004879171693529361, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.178704734520836, 'label_smoothing': 0.06610280971558621, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:02:29,315 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.6541 | val_loss=0.6067 | val_acc=0.5508 | time=8.3s
2025-10-12 00:02:34,769 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5674 | val_loss=0.5587 | val_acc=0.6175 | time=5.5s
2025-10-12 00:02:40,216 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5657 | val_loss=0.4987 | val_acc=0.6446 | time=5.4s
2025-10-12 00:02:45,665 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4996 | val_loss=0.5245 | val_acc=0.6349 | time=5.4s
2025-10-12 00:02:51,121 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4441 | val_loss=0.4709 | val_acc=0.6656 | time=5.5s
2025-10-12 00:02:56,572 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4096 | val_loss=0.4585 | val_acc=0.6782 | time=5.4s
2025-10-12 00:03:02,033 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3929 | val_loss=0.3676 | val_acc=0.7189 | time=5.5s
2025-10-12 00:03:07,490 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3839 | val_loss=0.3831 | val_acc=0.7058 | time=5.5s
2025-10-12 00:03:12,941 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3789 | val_loss=0.4292 | val_acc=0.6741 | time=5.5s
2025-10-12 00:03:18,397 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3778 | val_loss=0.3507 | val_acc=0.7254 | time=5.5s
2025-10-12 00:03:23,836 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3703 | val_loss=0.3484 | val_acc=0.7273 | time=5.4s
2025-10-12 00:03:24,955 - INFO - _models.training_function_executor - Model: 1,975 parameters, 8.5KB storage
2025-10-12 00:03:24,955 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.654115754023893, 0.567416254042578, 0.5656772308035944, 0.49957573159413377, 0.44407360716621885, 0.4095850010970158, 0.3928937585496502, 0.3839455658401786, 0.37893534237434184, 0.3778011681234361, 0.37028217095649685], 'val_losses': [0.6067495375205685, 0.5586502492927307, 0.498732360631394, 0.5245289922842766, 0.47088411163184896, 0.45854452984959054, 0.36755041853009657, 0.38307570264409374, 0.4291893145142321, 0.35070919948916196, 0.3484257750171523], 'val_acc': [0.5508400420021001, 0.617518375918796, 0.644557227861393, 0.6349317465873293, 0.6655582779138957, 0.678246412320616, 0.7189359467973399, 0.7058102905145257, 0.6741337066853342, 0.7254112705635282, 0.7273363668183409], 'best_epoch': 11, 'total_params': 1975, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0035437210011721584, 'batch_size': 32, 'epochs': 11, 'weight_decay': 0.0006262158276921634, 'base_channels': 10, 'kernel_size': 13, 'dropout': 0.04104402212406619, 'amp': True, 'grad_clip_norm': 0.004879171693529361, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.178704734520836, 'label_smoothing': 0.06610280971558621, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}, 'model_parameter_count': 1975, 'model_storage_size_kb': 8.486328125, 'model_size_validation': 'PASS'}
2025-10-12 00:03:24,955 - INFO - _models.training_function_executor - BO Objective: base=0.7273, size_penalty=0.0000, final=0.7273
2025-10-12 00:03:24,955 - INFO - _models.training_function_executor - Model: 1,975 parameters, 8.5KB (PASS 256KB limit)
2025-10-12 00:03:24,956 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 63.951s
2025-10-12 00:03:25,057 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7273
2025-10-12 00:03:25,057 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.099s
2025-10-12 00:03:25,057 - INFO - bo.run_bo - Recorded observation #19: hparams={'lr': 0.0035437210011721584, 'batch_size': np.int64(32), 'epochs': np.int64(11), 'weight_decay': 0.0006262158276921634, 'base_channels': np.int64(10), 'kernel_size': np.int64(13), 'dropout': 0.04104402212406619, 'amp': np.True_, 'grad_clip_norm': 0.004879171693529361, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.178704734520836, 'label_smoothing': 0.06610280971558621, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}, value=0.7273
2025-10-12 00:03:25,057 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 19: {'lr': 0.0035437210011721584, 'batch_size': np.int64(32), 'epochs': np.int64(11), 'weight_decay': 0.0006262158276921634, 'base_channels': np.int64(10), 'kernel_size': np.int64(13), 'dropout': 0.04104402212406619, 'amp': np.True_, 'grad_clip_norm': 0.004879171693529361, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.178704734520836, 'label_smoothing': 0.06610280971558621, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)} -> 0.7273
2025-10-12 00:03:25,057 - INFO - bo.run_bo - üîçBO Trial 20: Using RF surrogate + Expected Improvement
2025-10-12 00:03:25,057 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:03:25,057 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:03:25,058 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:03:25,058 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0031590507371503334, 'batch_size': 64, 'epochs': 9, 'weight_decay': 7.378363898288828e-06, 'base_channels': 11, 'kernel_size': 13, 'dropout': 0.04674776620636769, 'amp': True, 'grad_clip_norm': 0.13578364718790117, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.759129163429165, 'label_smoothing': 0.0599266367432259, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 6}
2025-10-12 00:03:25,059 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0031590507371503334, 'batch_size': 64, 'epochs': 9, 'weight_decay': 7.378363898288828e-06, 'base_channels': 11, 'kernel_size': 13, 'dropout': 0.04674776620636769, 'amp': True, 'grad_clip_norm': 0.13578364718790117, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.759129163429165, 'label_smoothing': 0.0599266367432259, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 6}
2025-10-12 00:03:33,234 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.6409 | val_loss=1.3701 | val_acc=0.4951 | time=8.2s
2025-10-12 00:03:38,527 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2540 | val_loss=1.2977 | val_acc=0.5214 | time=5.3s
2025-10-12 00:03:43,818 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1647 | val_loss=1.1510 | val_acc=0.5831 | time=5.3s
2025-10-12 00:03:49,104 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1115 | val_loss=1.0744 | val_acc=0.6247 | time=5.3s
2025-10-12 00:03:54,392 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0590 | val_loss=1.0438 | val_acc=0.6528 | time=5.3s
2025-10-12 00:03:59,684 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0130 | val_loss=0.9773 | val_acc=0.6798 | time=5.3s
2025-10-12 00:04:04,987 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9695 | val_loss=0.9589 | val_acc=0.6957 | time=5.3s
2025-10-12 00:04:10,299 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.9407 | val_loss=0.9351 | val_acc=0.7085 | time=5.3s
2025-10-12 00:04:15,608 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9291 | val_loss=0.9364 | val_acc=0.7088 | time=5.3s
2025-10-12 00:04:16,719 - INFO - _models.training_function_executor - Model: 2,203 parameters, 9.5KB storage
2025-10-12 00:04:16,719 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6408729940027624, 1.253977213622807, 1.1646833654050226, 1.1114613134544213, 1.059021000261907, 1.0129635465728652, 0.9694990775801918, 0.9407209133768415, 0.9290714659057298], 'val_losses': [1.37010824613731, 1.2976918640083441, 1.1509637572911864, 1.0743831306196459, 1.043806599505121, 0.977341905319491, 0.958904200759014, 0.9351085777389271, 0.9363884889213733], 'val_acc': [0.4950997549877494, 0.5213510675533777, 0.5831291564578229, 0.6246937346867344, 0.6527826391319566, 0.6798214910745537, 0.6957472873643682, 0.7085229261463073, 0.7087854392719636], 'best_epoch': 9, 'total_params': 2203, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0031590507371503334, 'batch_size': 64, 'epochs': 9, 'weight_decay': 7.378363898288828e-06, 'base_channels': 11, 'kernel_size': 13, 'dropout': 0.04674776620636769, 'amp': True, 'grad_clip_norm': 0.13578364718790117, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.759129163429165, 'label_smoothing': 0.0599266367432259, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 6}, 'model_parameter_count': 2203, 'model_storage_size_kb': 9.466015625, 'model_size_validation': 'PASS'}
2025-10-12 00:04:16,719 - INFO - _models.training_function_executor - BO Objective: base=0.7088, size_penalty=0.0000, final=0.7088
2025-10-12 00:04:16,719 - INFO - _models.training_function_executor - Model: 2,203 parameters, 9.5KB (PASS 256KB limit)
2025-10-12 00:04:16,719 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 51.661s
2025-10-12 00:04:16,827 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7088
2025-10-12 00:04:16,827 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-12 00:04:16,827 - INFO - bo.run_bo - Recorded observation #20: hparams={'lr': 0.0031590507371503334, 'batch_size': np.int64(64), 'epochs': np.int64(9), 'weight_decay': 7.378363898288828e-06, 'base_channels': np.int64(11), 'kernel_size': np.int64(13), 'dropout': 0.04674776620636769, 'amp': np.True_, 'grad_clip_norm': 0.13578364718790117, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.759129163429165, 'label_smoothing': 0.0599266367432259, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(6)}, value=0.7088
2025-10-12 00:04:16,827 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 20: {'lr': 0.0031590507371503334, 'batch_size': np.int64(64), 'epochs': np.int64(9), 'weight_decay': 7.378363898288828e-06, 'base_channels': np.int64(11), 'kernel_size': np.int64(13), 'dropout': 0.04674776620636769, 'amp': np.True_, 'grad_clip_norm': 0.13578364718790117, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.759129163429165, 'label_smoothing': 0.0599266367432259, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(6)} -> 0.7088
2025-10-12 00:04:16,827 - INFO - bo.run_bo - üîçBO Trial 21: Using RF surrogate + Expected Improvement
2025-10-12 00:04:16,827 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:04:16,827 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:04:16,827 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:04:16,827 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004511647764605639, 'batch_size': 64, 'epochs': 37, 'weight_decay': 1.6920115887086694e-06, 'base_channels': 9, 'kernel_size': 12, 'dropout': 0.03565331918242522, 'amp': True, 'grad_clip_norm': 0.19412332353660205, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.96399359721715, 'label_smoothing': 0.12864546606455332, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}
2025-10-12 00:04:16,829 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004511647764605639, 'batch_size': 64, 'epochs': 37, 'weight_decay': 1.6920115887086694e-06, 'base_channels': 9, 'kernel_size': 12, 'dropout': 0.03565331918242522, 'amp': True, 'grad_clip_norm': 0.19412332353660205, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.96399359721715, 'label_smoothing': 0.12864546606455332, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}
2025-10-12 00:04:24,497 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3616 | val_loss=1.2889 | val_acc=0.5560 | time=7.7s
2025-10-12 00:04:29,335 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2610 | val_loss=1.2095 | val_acc=0.5713 | time=4.8s
2025-10-12 00:04:34,172 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1729 | val_loss=1.1605 | val_acc=0.6224 | time=4.8s
2025-10-12 00:04:39,001 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1184 | val_loss=1.1082 | val_acc=0.6905 | time=4.8s
2025-10-12 00:04:43,831 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0809 | val_loss=1.0925 | val_acc=0.6964 | time=4.8s
2025-10-12 00:04:48,657 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0651 | val_loss=1.0545 | val_acc=0.7090 | time=4.8s
2025-10-12 00:04:53,491 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.0549 | val_loss=1.0803 | val_acc=0.6922 | time=4.8s
2025-10-12 00:04:58,328 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.0537 | val_loss=1.0341 | val_acc=0.7252 | time=4.8s
2025-10-12 00:05:03,174 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.0457 | val_loss=1.0739 | val_acc=0.6971 | time=4.8s
2025-10-12 00:05:08,019 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.0412 | val_loss=1.0690 | val_acc=0.7048 | time=4.8s
2025-10-12 00:05:12,854 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.0434 | val_loss=1.0344 | val_acc=0.7217 | time=4.8s
2025-10-12 00:05:17,702 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.0340 | val_loss=1.1461 | val_acc=0.6619 | time=4.8s
2025-10-12 00:05:22,545 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.0340 | val_loss=1.0655 | val_acc=0.7063 | time=4.8s
2025-10-12 00:05:27,399 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.0295 | val_loss=1.0623 | val_acc=0.7142 | time=4.9s
2025-10-12 00:05:32,240 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.0277 | val_loss=1.0711 | val_acc=0.7013 | time=4.8s
2025-10-12 00:05:37,090 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.0274 | val_loss=1.0590 | val_acc=0.7006 | time=4.8s
2025-10-12 00:05:41,927 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.0234 | val_loss=1.0227 | val_acc=0.7298 | time=4.8s
2025-10-12 00:05:46,776 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.0230 | val_loss=1.0156 | val_acc=0.7312 | time=4.8s
2025-10-12 00:05:51,630 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.0195 | val_loss=1.0138 | val_acc=0.7398 | time=4.9s
2025-10-12 00:05:56,463 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0173 | val_loss=1.0182 | val_acc=0.7262 | time=4.8s
2025-10-12 00:06:01,306 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0171 | val_loss=1.0199 | val_acc=0.7233 | time=4.8s
2025-10-12 00:06:06,152 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.0159 | val_loss=1.0298 | val_acc=0.7324 | time=4.8s
2025-10-12 00:06:10,996 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.0132 | val_loss=1.0295 | val_acc=0.7256 | time=4.8s
2025-10-12 00:06:15,844 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.0126 | val_loss=1.0739 | val_acc=0.6989 | time=4.8s
2025-10-12 00:06:20,699 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.0125 | val_loss=1.0244 | val_acc=0.7234 | time=4.9s
2025-10-12 00:06:25,549 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.0126 | val_loss=1.0363 | val_acc=0.7085 | time=4.8s
2025-10-12 00:06:30,395 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.0141 | val_loss=1.0081 | val_acc=0.7305 | time=4.8s
2025-10-12 00:06:35,234 - INFO - _models.training_function_executor - Epoch 028 | train_loss=1.0081 | val_loss=1.0085 | val_acc=0.7406 | time=4.8s
2025-10-12 00:06:40,096 - INFO - _models.training_function_executor - Epoch 029 | train_loss=1.0116 | val_loss=0.9972 | val_acc=0.7386 | time=4.9s
2025-10-12 00:06:44,938 - INFO - _models.training_function_executor - Epoch 030 | train_loss=1.0096 | val_loss=1.0434 | val_acc=0.7128 | time=4.8s
2025-10-12 00:06:49,776 - INFO - _models.training_function_executor - Epoch 031 | train_loss=nan | val_loss=1.0252 | val_acc=0.7207 | time=4.8s
2025-10-12 00:06:54,617 - INFO - _models.training_function_executor - Epoch 032 | train_loss=1.0124 | val_loss=1.0029 | val_acc=0.7321 | time=4.8s
2025-10-12 00:06:59,463 - INFO - _models.training_function_executor - Epoch 033 | train_loss=nan | val_loss=1.1375 | val_acc=0.6710 | time=4.8s
2025-10-12 00:07:04,298 - INFO - _models.training_function_executor - Epoch 034 | train_loss=nan | val_loss=1.1375 | val_acc=0.6710 | time=4.8s
2025-10-12 00:07:09,076 - INFO - _models.training_function_executor - Epoch 035 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.8s
2025-10-12 00:07:13,786 - INFO - _models.training_function_executor - Epoch 036 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.7s
2025-10-12 00:07:18,494 - INFO - _models.training_function_executor - Epoch 037 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.7s
2025-10-12 00:07:19,592 - INFO - _models.training_function_executor - Model: 1,759 parameters, 7.6KB storage
2025-10-12 00:07:19,593 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3615716749137932, 1.2610386711734158, 1.1729479843919928, 1.1183620788834312, 1.0809071653372757, 1.0651436111310146, 1.0549315094114184, 1.0536870213655325, 1.0456670369301642, 1.04123694896698, 1.0434455442261863, 1.0339844587799552, 1.0340162303064253, 1.0295250710907515, 1.0277073415009292, 1.0273550999748122, 1.0233692434284236, 1.0229583474305959, 1.0195227298703227, 1.017308630143012, 1.017149701485267, 1.0158563605555289, 1.0131728990928277, 1.0126325378884802, 1.0125178585519323, 1.0125583980466937, 1.0140549001160202, 1.008090785500053, 1.0115633695275634, 1.009648720284442, nan, 1.012417053759515, nan, nan, nan, nan, nan], 'val_losses': [1.28886391930074, 1.2095387627958585, 1.16045343875885, 1.1082290394346141, 1.09253034611654, 1.054508191580213, 1.080317266826523, 1.0340941631594183, 1.073863626192402, 1.0689864714718398, 1.0344005786506822, 1.1460773861608027, 1.0655301509622754, 1.0623406431528444, 1.071097974337679, 1.0589646783620952, 1.0226555696412838, 1.0155616003041827, 1.013838795310292, 1.0182332962584895, 1.0199204829818043, 1.0298380302317316, 1.0294844071958318, 1.073893195091013, 1.0243527343153287, 1.0363098129879829, 1.0081310635172456, 1.0085278746136075, 0.9972003082323341, 1.0434043327523344, 1.0252124087770558, 1.002920323909994, 1.1375411442538212, 1.1375409161578343, nan, nan, nan], 'val_acc': [0.556002800140007, 0.5713160658032902, 0.6224186209310466, 0.6904970248512425, 0.6964473223661183, 0.7089604480224011, 0.692159607980399, 0.7252362618130906, 0.6971473573678684, 0.7047602380119006, 0.7217360868043402, 0.6618830941547077, 0.7063353167658383, 0.7142107105355268, 0.7013475673783689, 0.7006475323766188, 0.7297864893244662, 0.7311865593279664, 0.7398494924746237, 0.726198809940497, 0.7233111655582779, 0.732411620581029, 0.7255862793139657, 0.6988974448722436, 0.7233986699334967, 0.7085229261463073, 0.7304865243262163, 0.7406370318515926, 0.7386244312215611, 0.7128106405320266, 0.7206860343017151, 0.732061603080154, 0.6709835491774588, 0.6709835491774588, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'best_epoch': 28, 'total_params': 1759, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004511647764605639, 'batch_size': 64, 'epochs': 37, 'weight_decay': 1.6920115887086694e-06, 'base_channels': 9, 'kernel_size': 12, 'dropout': 0.03565331918242522, 'amp': True, 'grad_clip_norm': 0.19412332353660205, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.96399359721715, 'label_smoothing': 0.12864546606455332, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}, 'model_parameter_count': 1759, 'model_storage_size_kb': 7.558203125, 'model_size_validation': 'PASS'}
2025-10-12 00:07:19,593 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-12 00:07:19,593 - INFO - _models.training_function_executor - Model: 1,759 parameters, 7.6KB (PASS 256KB limit)
2025-10-12 00:07:19,593 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 182.765s
2025-10-12 00:07:19,702 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-12 00:07:19,702 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-12 00:07:19,702 - INFO - bo.run_bo - Recorded observation #21: hparams={'lr': 0.004511647764605639, 'batch_size': np.int64(64), 'epochs': np.int64(37), 'weight_decay': 1.6920115887086694e-06, 'base_channels': np.int64(9), 'kernel_size': np.int64(12), 'dropout': 0.03565331918242522, 'amp': np.True_, 'grad_clip_norm': 0.19412332353660205, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.96399359721715, 'label_smoothing': 0.12864546606455332, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(8)}, value=0.2325
2025-10-12 00:07:19,702 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 21: {'lr': 0.004511647764605639, 'batch_size': np.int64(64), 'epochs': np.int64(37), 'weight_decay': 1.6920115887086694e-06, 'base_channels': np.int64(9), 'kernel_size': np.int64(12), 'dropout': 0.03565331918242522, 'amp': np.True_, 'grad_clip_norm': 0.19412332353660205, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.96399359721715, 'label_smoothing': 0.12864546606455332, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(8)} -> 0.2325
2025-10-12 00:07:19,702 - INFO - bo.run_bo - üîçBO Trial 22: Using RF surrogate + Expected Improvement
2025-10-12 00:07:19,702 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:07:19,702 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:07:19,703 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:07:19,703 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0016646172864285482, 'batch_size': 16, 'epochs': 12, 'weight_decay': 5.030548007155996e-06, 'base_channels': 9, 'kernel_size': 10, 'dropout': 0.05021367110979969, 'amp': False, 'grad_clip_norm': 0.6625489392931388, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.928220586700708, 'label_smoothing': 0.18532263972987495, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}
2025-10-12 00:07:19,704 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0016646172864285482, 'batch_size': 16, 'epochs': 12, 'weight_decay': 5.030548007155996e-06, 'base_channels': 9, 'kernel_size': 10, 'dropout': 0.05021367110979969, 'amp': False, 'grad_clip_norm': 0.6625489392931388, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.928220586700708, 'label_smoothing': 0.18532263972987495, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}
2025-10-12 00:07:28,465 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.5635 | val_loss=0.4600 | val_acc=0.5919 | time=8.8s
2025-10-12 00:07:34,372 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.4456 | val_loss=0.3775 | val_acc=0.6674 | time=5.9s
2025-10-12 00:07:40,267 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.3861 | val_loss=0.4123 | val_acc=0.6425 | time=5.9s
2025-10-12 00:07:46,138 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.3560 | val_loss=0.3509 | val_acc=0.6945 | time=5.9s
2025-10-12 00:07:52,021 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3477 | val_loss=0.4140 | val_acc=0.6304 | time=5.9s
2025-10-12 00:07:57,895 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3359 | val_loss=0.3658 | val_acc=0.7150 | time=5.9s
2025-10-12 00:08:03,778 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3370 | val_loss=0.3247 | val_acc=0.7129 | time=5.9s
2025-10-12 00:08:09,682 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3255 | val_loss=0.3476 | val_acc=0.6949 | time=5.9s
2025-10-12 00:08:15,614 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3160 | val_loss=0.3328 | val_acc=0.7064 | time=5.9s
2025-10-12 00:08:21,506 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3180 | val_loss=0.4071 | val_acc=0.6473 | time=5.9s
2025-10-12 00:08:27,376 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3101 | val_loss=0.3211 | val_acc=0.7100 | time=5.9s
2025-10-12 00:08:33,251 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3091 | val_loss=0.2951 | val_acc=0.7282 | time=5.9s
2025-10-12 00:08:33,258 - INFO - _models.training_function_executor - Quantization failed (cannot assign 'torch.fx.graph.Graph' as child module 'graph' (torch.nn.Module or None expected)); returning FP32 CPU model.
2025-10-12 00:08:34,359 - INFO - _models.training_function_executor - Model: 1,643 parameters, 1.8KB storage
2025-10-12 00:08:34,359 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.5634506090583608, 0.4456488797281395, 0.3861416701747689, 0.3560335988874489, 0.3476917841372308, 0.3359087044728472, 0.3369890517761522, 0.3254880272908189, 0.31602843994999064, 0.31798772312802454, 0.3100620134504454, 0.3091314306869284], 'val_losses': [0.45996752464687907, 0.3775146036714941, 0.412301878287242, 0.3508703668634375, 0.41395826039614375, 0.365839626046119, 0.32473802944788566, 0.34759092415337794, 0.33284420339794424, 0.4070848458400973, 0.32108680225023023, 0.2951461061939493], 'val_acc': [0.591879593979699, 0.6673958697934896, 0.6424571228561428, 0.6945222261113055, 0.6303815190759537, 0.7149982499124956, 0.7128981449072453, 0.6948722436121806, 0.706422821141057, 0.6472698634931746, 0.7100105005250262, 0.7282114105705285], 'best_epoch': 12, 'total_params': 1643, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0016646172864285482, 'batch_size': 16, 'epochs': 12, 'weight_decay': 5.030548007155996e-06, 'base_channels': 9, 'kernel_size': 10, 'dropout': 0.05021367110979969, 'amp': False, 'grad_clip_norm': 0.6625489392931388, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.928220586700708, 'label_smoothing': 0.18532263972987495, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}, 'model_parameter_count': 1643, 'model_storage_size_kb': 1.7649414062500002, 'model_size_validation': 'PASS'}
2025-10-12 00:08:34,359 - INFO - _models.training_function_executor - BO Objective: base=0.7282, size_penalty=0.0000, final=0.7282
2025-10-12 00:08:34,359 - INFO - _models.training_function_executor - Model: 1,643 parameters, 1.8KB (PASS 256KB limit)
2025-10-12 00:08:34,359 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 74.657s
2025-10-12 00:08:34,465 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7282
2025-10-12 00:08:34,465 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-12 00:08:34,465 - INFO - bo.run_bo - Recorded observation #22: hparams={'lr': 0.0016646172864285482, 'batch_size': np.int64(16), 'epochs': np.int64(12), 'weight_decay': 5.030548007155996e-06, 'base_channels': np.int64(9), 'kernel_size': np.int64(10), 'dropout': 0.05021367110979969, 'amp': np.False_, 'grad_clip_norm': 0.6625489392931388, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.928220586700708, 'label_smoothing': 0.18532263972987495, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(5)}, value=0.7282
2025-10-12 00:08:34,465 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 22: {'lr': 0.0016646172864285482, 'batch_size': np.int64(16), 'epochs': np.int64(12), 'weight_decay': 5.030548007155996e-06, 'base_channels': np.int64(9), 'kernel_size': np.int64(10), 'dropout': 0.05021367110979969, 'amp': np.False_, 'grad_clip_norm': 0.6625489392931388, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.928220586700708, 'label_smoothing': 0.18532263972987495, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(5)} -> 0.7282
2025-10-12 00:08:34,465 - INFO - bo.run_bo - üîçBO Trial 23: Using RF surrogate + Expected Improvement
2025-10-12 00:08:34,465 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:08:34,465 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:08:34,465 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:08:34,465 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004619337249688971, 'batch_size': 32, 'epochs': 22, 'weight_decay': 1.5235520170519912e-05, 'base_channels': 9, 'kernel_size': 10, 'dropout': 0.019337424855819643, 'amp': True, 'grad_clip_norm': 0.9248327466474622, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7627957674543078, 'label_smoothing': 0.09710758008103548, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}
2025-10-12 00:08:34,467 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004619337249688971, 'batch_size': 32, 'epochs': 22, 'weight_decay': 1.5235520170519912e-05, 'base_channels': 9, 'kernel_size': 10, 'dropout': 0.019337424855819643, 'amp': True, 'grad_clip_norm': 0.9248327466474622, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7627957674543078, 'label_smoothing': 0.09710758008103548, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}
2025-10-12 00:08:42,524 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.7456 | val_loss=0.5679 | val_acc=0.5404 | time=8.1s
2025-10-12 00:08:47,728 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5191 | val_loss=0.4759 | val_acc=0.5799 | time=5.2s
2025-10-12 00:08:52,926 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4491 | val_loss=0.4216 | val_acc=0.6058 | time=5.2s
2025-10-12 00:08:58,114 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.3985 | val_loss=0.4644 | val_acc=0.6076 | time=5.2s
2025-10-12 00:09:03,312 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3656 | val_loss=0.3463 | val_acc=0.6834 | time=5.2s
2025-10-12 00:09:08,505 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3534 | val_loss=0.4422 | val_acc=0.6336 | time=5.2s
2025-10-12 00:09:13,701 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3477 | val_loss=0.3180 | val_acc=0.7206 | time=5.2s
2025-10-12 00:09:18,901 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3328 | val_loss=0.3147 | val_acc=0.6955 | time=5.2s
2025-10-12 00:09:24,105 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3241 | val_loss=0.2980 | val_acc=0.7305 | time=5.2s
2025-10-12 00:09:29,295 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3169 | val_loss=0.3080 | val_acc=0.7122 | time=5.2s
2025-10-12 00:09:34,483 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3068 | val_loss=0.3042 | val_acc=0.7235 | time=5.2s
2025-10-12 00:09:39,678 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.2971 | val_loss=0.2980 | val_acc=0.7243 | time=5.2s
2025-10-12 00:09:44,879 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.2940 | val_loss=0.2956 | val_acc=0.7070 | time=5.2s
2025-10-12 00:09:50,078 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.2863 | val_loss=0.2814 | val_acc=0.7372 | time=5.2s
2025-10-12 00:09:55,266 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.2796 | val_loss=0.2918 | val_acc=0.7375 | time=5.2s
2025-10-12 00:10:00,455 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.2714 | val_loss=0.2746 | val_acc=0.7472 | time=5.2s
2025-10-12 00:10:05,642 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.2659 | val_loss=0.2797 | val_acc=0.7230 | time=5.2s
2025-10-12 00:10:10,846 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.2639 | val_loss=0.2669 | val_acc=0.7511 | time=5.2s
2025-10-12 00:10:16,044 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.2559 | val_loss=0.2627 | val_acc=0.7536 | time=5.2s
2025-10-12 00:10:21,235 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.2513 | val_loss=0.2638 | val_acc=0.7480 | time=5.2s
2025-10-12 00:10:26,426 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.2488 | val_loss=0.2602 | val_acc=0.7536 | time=5.2s
2025-10-12 00:10:31,633 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.2468 | val_loss=0.2610 | val_acc=0.7535 | time=5.2s
2025-10-12 00:10:31,643 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 00:10:32,762 - INFO - _models.training_function_executor - Model: 1,643 parameters, 3.5KB storage
2025-10-12 00:10:32,762 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7456303638249031, 0.5191015361321398, 0.4491189540141608, 0.3984867867220524, 0.3656246174645641, 0.35337960837373705, 0.34769452310592835, 0.33277910291898327, 0.32412842643415285, 0.31692264016855837, 0.30681594711988436, 0.29713421613186536, 0.2940044861477184, 0.28632640112856206, 0.27955070684388267, 0.27144703598519654, 0.26587049194342444, 0.26390761248063505, 0.25594550187642795, 0.2512586613070347, 0.2488364365350708, 0.24678316371915557], 'val_losses': [0.5679139685530902, 0.47587333086815625, 0.42159311236116476, 0.46439690492506136, 0.34630347210809836, 0.44220341213422115, 0.31796712696802015, 0.31471228666145706, 0.2979588022028934, 0.30797109738325273, 0.3041760888179587, 0.29804207544836253, 0.2955672026055152, 0.28141842944828493, 0.29175336251045736, 0.2745652686617228, 0.27967883431087326, 0.26692002868102915, 0.2626802647829722, 0.26382444007062045, 0.26018561643428645, 0.2609995229783671], 'val_acc': [0.5404270213510676, 0.5798914945747288, 0.605792789639482, 0.607630381519076, 0.6834091704585229, 0.6336191809590479, 0.7205985299264963, 0.6954847742387119, 0.7304865243262163, 0.7121981099054953, 0.7234861743087154, 0.7242737136856843, 0.7070353517675884, 0.7372243612180609, 0.7374868743437172, 0.7471998599929996, 0.7230486524326216, 0.7510500525026251, 0.7535876793839692, 0.7479873993699685, 0.7535876793839692, 0.7535001750087504], 'best_epoch': 19, 'total_params': 1643, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004619337249688971, 'batch_size': 32, 'epochs': 22, 'weight_decay': 1.5235520170519912e-05, 'base_channels': 9, 'kernel_size': 10, 'dropout': 0.019337424855819643, 'amp': True, 'grad_clip_norm': 0.9248327466474622, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7627957674543078, 'label_smoothing': 0.09710758008103548, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}, 'model_parameter_count': 1643, 'model_storage_size_kb': 3.5298828125000004, 'model_size_validation': 'PASS'}
2025-10-12 00:10:32,762 - INFO - _models.training_function_executor - BO Objective: base=0.7535, size_penalty=0.0000, final=0.7535
2025-10-12 00:10:32,762 - INFO - _models.training_function_executor - Model: 1,643 parameters, 3.5KB (PASS 256KB limit)
2025-10-12 00:10:32,762 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 118.297s
2025-10-12 00:10:32,866 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7535
2025-10-12 00:10:32,867 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-12 00:10:32,867 - INFO - bo.run_bo - Recorded observation #23: hparams={'lr': 0.004619337249688971, 'batch_size': np.int64(32), 'epochs': np.int64(22), 'weight_decay': 1.5235520170519912e-05, 'base_channels': np.int64(9), 'kernel_size': np.int64(10), 'dropout': 0.019337424855819643, 'amp': np.True_, 'grad_clip_norm': 0.9248327466474622, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7627957674543078, 'label_smoothing': 0.09710758008103548, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(3)}, value=0.7535
2025-10-12 00:10:32,867 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 23: {'lr': 0.004619337249688971, 'batch_size': np.int64(32), 'epochs': np.int64(22), 'weight_decay': 1.5235520170519912e-05, 'base_channels': np.int64(9), 'kernel_size': np.int64(10), 'dropout': 0.019337424855819643, 'amp': np.True_, 'grad_clip_norm': 0.9248327466474622, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7627957674543078, 'label_smoothing': 0.09710758008103548, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(3)} -> 0.7535
2025-10-12 00:10:32,867 - INFO - bo.run_bo - üîçBO Trial 24: Using RF surrogate + Expected Improvement
2025-10-12 00:10:32,867 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:10:32,867 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:10:32,867 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:10:32,867 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002613870873064416, 'batch_size': 16, 'epochs': 15, 'weight_decay': 8.403511485694338e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.04251250152960375, 'amp': True, 'grad_clip_norm': 0.934088748977356, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.9730547560043985, 'label_smoothing': 0.19220023129666966, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}
2025-10-12 00:10:32,868 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002613870873064416, 'batch_size': 16, 'epochs': 15, 'weight_decay': 8.403511485694338e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.04251250152960375, 'amp': True, 'grad_clip_norm': 0.934088748977356, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.9730547560043985, 'label_smoothing': 0.19220023129666966, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}
2025-10-12 00:10:42,174 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8254 | val_loss=0.5695 | val_acc=0.5499 | time=9.3s
2025-10-12 00:10:48,563 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5428 | val_loss=0.4946 | val_acc=0.5914 | time=6.4s
2025-10-12 00:10:54,997 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4779 | val_loss=0.4178 | val_acc=0.6077 | time=6.4s
2025-10-12 00:11:01,390 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4269 | val_loss=0.3808 | val_acc=0.6284 | time=6.4s
2025-10-12 00:11:07,801 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3977 | val_loss=0.3522 | val_acc=0.6712 | time=6.4s
2025-10-12 00:11:14,237 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3531 | val_loss=0.3351 | val_acc=0.6908 | time=6.4s
2025-10-12 00:11:20,666 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3311 | val_loss=0.3010 | val_acc=0.7062 | time=6.4s
2025-10-12 00:11:27,095 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3216 | val_loss=0.3391 | val_acc=0.6924 | time=6.4s
2025-10-12 00:11:33,519 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3047 | val_loss=0.2857 | val_acc=0.7209 | time=6.4s
2025-10-12 00:11:39,938 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.2991 | val_loss=0.2834 | val_acc=0.7260 | time=6.4s
2025-10-12 00:11:46,383 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.2934 | val_loss=0.2848 | val_acc=0.7226 | time=6.4s
2025-10-12 00:11:52,821 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.2854 | val_loss=0.2750 | val_acc=0.7321 | time=6.4s
2025-10-12 00:11:59,277 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.2775 | val_loss=0.2736 | val_acc=0.7368 | time=6.5s
2025-10-12 00:12:05,713 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.2717 | val_loss=0.2711 | val_acc=0.7434 | time=6.4s
2025-10-12 00:12:12,115 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.2701 | val_loss=0.2699 | val_acc=0.7426 | time=6.4s
2025-10-12 00:12:13,245 - INFO - _models.training_function_executor - Model: 1,263 parameters, 5.4KB storage
2025-10-12 00:12:13,245 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8254304873722185, 0.5427551997012511, 0.47790226598990976, 0.4268667140390788, 0.39765496641178416, 0.35311957854369447, 0.3310541813481843, 0.3216316338327326, 0.3046538210782005, 0.299092000147597, 0.2933613148511061, 0.2854292885272245, 0.27749080269633003, 0.2716908946960622, 0.27006931046410576], 'val_losses': [0.5695006369502394, 0.49462995474988763, 0.4177560969874575, 0.3807868850189489, 0.35221062403667225, 0.33510620015692877, 0.30101756732780616, 0.33906395939680245, 0.2857118745523316, 0.2834400316739416, 0.2847832707675187, 0.27495636947296714, 0.27358991700660934, 0.271073491235713, 0.2699049453635316], 'val_acc': [0.5498774938746938, 0.5914420721036052, 0.6077178858942948, 0.6283689184459222, 0.6712460623031151, 0.6908470423521176, 0.7061603080154008, 0.6924221211060553, 0.7209485474273714, 0.7260238011900595, 0.7226111305565278, 0.732061603080154, 0.7367868393419671, 0.7434371718585929, 0.7425621281064053], 'best_epoch': 14, 'total_params': 1263, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002613870873064416, 'batch_size': 16, 'epochs': 15, 'weight_decay': 8.403511485694338e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.04251250152960375, 'amp': True, 'grad_clip_norm': 0.934088748977356, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.9730547560043985, 'label_smoothing': 0.19220023129666966, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}, 'model_parameter_count': 1263, 'model_storage_size_kb': 5.426953125000001, 'model_size_validation': 'PASS'}
2025-10-12 00:12:13,245 - INFO - _models.training_function_executor - BO Objective: base=0.7426, size_penalty=0.0000, final=0.7426
2025-10-12 00:12:13,245 - INFO - _models.training_function_executor - Model: 1,263 parameters, 5.4KB (PASS 256KB limit)
2025-10-12 00:12:13,245 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 100.378s
2025-10-12 00:12:13,348 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7426
2025-10-12 00:12:13,348 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-12 00:12:13,348 - INFO - bo.run_bo - Recorded observation #24: hparams={'lr': 0.002613870873064416, 'batch_size': np.int64(16), 'epochs': np.int64(15), 'weight_decay': 8.403511485694338e-05, 'base_channels': np.int64(7), 'kernel_size': np.int64(10), 'dropout': 0.04251250152960375, 'amp': np.True_, 'grad_clip_norm': 0.934088748977356, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.9730547560043985, 'label_smoothing': 0.19220023129666966, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(5)}, value=0.7426
2025-10-12 00:12:13,348 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 24: {'lr': 0.002613870873064416, 'batch_size': np.int64(16), 'epochs': np.int64(15), 'weight_decay': 8.403511485694338e-05, 'base_channels': np.int64(7), 'kernel_size': np.int64(10), 'dropout': 0.04251250152960375, 'amp': np.True_, 'grad_clip_norm': 0.934088748977356, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.9730547560043985, 'label_smoothing': 0.19220023129666966, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(5)} -> 0.7426
2025-10-12 00:12:13,349 - INFO - bo.run_bo - üîçBO Trial 25: Using RF surrogate + Expected Improvement
2025-10-12 00:12:13,349 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:12:13,349 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:12:13,349 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:12:13,349 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004159617793131237, 'batch_size': 16, 'epochs': 30, 'weight_decay': 7.795525599854901e-06, 'base_channels': 11, 'kernel_size': 10, 'dropout': 0.00723665377744649, 'amp': False, 'grad_clip_norm': 0.8819636140199963, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3621077834767537, 'label_smoothing': 0.15255893624551736, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 2}
2025-10-12 00:12:13,350 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004159617793131237, 'batch_size': 16, 'epochs': 30, 'weight_decay': 7.795525599854901e-06, 'base_channels': 11, 'kernel_size': 10, 'dropout': 0.00723665377744649, 'amp': False, 'grad_clip_norm': 0.8819636140199963, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3621077834767537, 'label_smoothing': 0.15255893624551736, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 2}
2025-10-12 00:12:22,575 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.4977 | val_loss=1.3621 | val_acc=0.5401 | time=9.2s
2025-10-12 00:12:28,962 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3171 | val_loss=1.3118 | val_acc=0.5512 | time=6.4s
2025-10-12 00:12:35,351 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2549 | val_loss=1.2045 | val_acc=0.6301 | time=6.4s
2025-10-12 00:12:41,737 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1963 | val_loss=1.1930 | val_acc=0.6585 | time=6.4s
2025-10-12 00:12:48,137 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.1580 | val_loss=1.1367 | val_acc=0.6665 | time=6.4s
2025-10-12 00:12:54,543 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1470 | val_loss=1.1183 | val_acc=0.7024 | time=6.4s
2025-10-12 00:13:00,928 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1332 | val_loss=1.1400 | val_acc=0.6727 | time=6.4s
2025-10-12 00:13:07,332 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1214 | val_loss=1.1333 | val_acc=0.6773 | time=6.4s
2025-10-12 00:13:13,743 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1147 | val_loss=1.1996 | val_acc=0.6581 | time=6.4s
2025-10-12 00:13:20,141 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1044 | val_loss=1.0840 | val_acc=0.7034 | time=6.4s
2025-10-12 00:13:26,498 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.0931 | val_loss=1.0713 | val_acc=0.7016 | time=6.4s
2025-10-12 00:13:32,871 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.0908 | val_loss=1.1117 | val_acc=0.6933 | time=6.4s
2025-10-12 00:13:39,238 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.0822 | val_loss=1.1158 | val_acc=0.6851 | time=6.4s
2025-10-12 00:13:45,625 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.0771 | val_loss=1.0929 | val_acc=0.6841 | time=6.4s
2025-10-12 00:13:52,032 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.0707 | val_loss=1.0599 | val_acc=0.7239 | time=6.4s
2025-10-12 00:13:58,486 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.0649 | val_loss=1.0779 | val_acc=0.6929 | time=6.5s
2025-10-12 00:14:04,857 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.0592 | val_loss=1.0436 | val_acc=0.7188 | time=6.4s
2025-10-12 00:14:11,283 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.0535 | val_loss=1.0595 | val_acc=0.7040 | time=6.4s
2025-10-12 00:14:17,732 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.0457 | val_loss=1.0599 | val_acc=0.7043 | time=6.4s
2025-10-12 00:14:24,113 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0445 | val_loss=1.0315 | val_acc=0.7339 | time=6.4s
2025-10-12 00:14:30,500 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0362 | val_loss=1.0268 | val_acc=0.7370 | time=6.4s
2025-10-12 00:14:36,890 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.0284 | val_loss=1.0470 | val_acc=0.7301 | time=6.4s
2025-10-12 00:14:43,306 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.0232 | val_loss=1.0304 | val_acc=0.7376 | time=6.4s
2025-10-12 00:14:49,719 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.0187 | val_loss=1.0302 | val_acc=0.7389 | time=6.4s
2025-10-12 00:14:56,098 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.0145 | val_loss=1.0292 | val_acc=0.7386 | time=6.4s
2025-10-12 00:15:02,504 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.0094 | val_loss=1.0189 | val_acc=0.7413 | time=6.4s
2025-10-12 00:15:08,919 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.0058 | val_loss=1.0205 | val_acc=0.7389 | time=6.4s
2025-10-12 00:15:15,293 - INFO - _models.training_function_executor - Epoch 028 | train_loss=1.0036 | val_loss=1.0171 | val_acc=0.7419 | time=6.4s
2025-10-12 00:15:21,682 - INFO - _models.training_function_executor - Epoch 029 | train_loss=1.0017 | val_loss=1.0166 | val_acc=0.7422 | time=6.4s
2025-10-12 00:15:28,105 - INFO - _models.training_function_executor - Epoch 030 | train_loss=1.0001 | val_loss=1.0168 | val_acc=0.7426 | time=6.4s
2025-10-12 00:15:29,229 - INFO - _models.training_function_executor - Model: 2,071 parameters, 8.9KB storage
2025-10-12 00:15:29,229 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.497655096903605, 1.317070376197066, 1.2549038860695239, 1.196253884890132, 1.157984175087899, 1.1470000199350312, 1.1331734379188223, 1.121427426043615, 1.1147385751362402, 1.1044494634872972, 1.093078732782617, 1.0907997957133813, 1.0822415854240741, 1.0770641657327245, 1.0707243674486553, 1.0648627520692402, 1.0591996493855265, 1.0535245053326703, 1.0457461889824085, 1.0445169454735812, 1.0362233033453956, 1.0284015175592744, 1.0232021306668455, 1.0186655983500936, 1.014509590952222, 1.0094030839519814, 1.005827647345359, 1.0036101174346208, 1.0016961924087597, 1.0000888449894534], 'val_losses': [1.3621441950331201, 1.3117955982268272, 1.2045347422152965, 1.1930462979770207, 1.1366947898497948, 1.1182901510825525, 1.1400089234738917, 1.1332926834379877, 1.199606437032873, 1.0840213463856623, 1.0712701113907608, 1.1117258455369856, 1.1158321991667046, 1.0929473171700965, 1.0599316807059975, 1.077881247013599, 1.0436274984499792, 1.0594745400068644, 1.0598973119175517, 1.0314876363827632, 1.0268221761796859, 1.0470469518141312, 1.0304355145334363, 1.03015152065904, 1.0292010716625026, 1.0188531523817903, 1.0205451788602176, 1.017119910917082, 1.0165878458456559, 1.0167560689099184], 'val_acc': [0.5400770038501925, 0.5511900595029752, 0.6301190059502975, 0.658470423521176, 0.666520826041302, 0.702397619880994, 0.6727336366818341, 0.6772838641932096, 0.658120406020301, 0.7034476723836192, 0.7016100805040252, 0.6932971648582429, 0.6850717535876794, 0.684109205460273, 0.7239236961848092, 0.6928596429821491, 0.7187609380469023, 0.7039726986349317, 0.7043227161358068, 0.733899194959748, 0.7370493524676234, 0.7301365068253413, 0.7375743787189359, 0.7388869443472174, 0.7386244312215611, 0.7413370668533427, 0.7388869443472174, 0.7418620931046552, 0.7422121106055303, 0.7426496324816241], 'best_epoch': 30, 'total_params': 2071, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004159617793131237, 'batch_size': 16, 'epochs': 30, 'weight_decay': 7.795525599854901e-06, 'base_channels': 11, 'kernel_size': 10, 'dropout': 0.00723665377744649, 'amp': False, 'grad_clip_norm': 0.8819636140199963, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3621077834767537, 'label_smoothing': 0.15255893624551736, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 2}, 'model_parameter_count': 2071, 'model_storage_size_kb': 8.898828125000001, 'model_size_validation': 'PASS'}
2025-10-12 00:15:29,229 - INFO - _models.training_function_executor - BO Objective: base=0.7426, size_penalty=0.0000, final=0.7426
2025-10-12 00:15:29,229 - INFO - _models.training_function_executor - Model: 2,071 parameters, 8.9KB (PASS 256KB limit)
2025-10-12 00:15:29,229 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 195.881s
2025-10-12 00:15:29,335 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7426
2025-10-12 00:15:29,335 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-12 00:15:29,335 - INFO - bo.run_bo - Recorded observation #25: hparams={'lr': 0.004159617793131237, 'batch_size': np.int64(16), 'epochs': np.int64(30), 'weight_decay': 7.795525599854901e-06, 'base_channels': np.int64(11), 'kernel_size': np.int64(10), 'dropout': 0.00723665377744649, 'amp': np.False_, 'grad_clip_norm': 0.8819636140199963, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3621077834767537, 'label_smoothing': 0.15255893624551736, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(2)}, value=0.7426
2025-10-12 00:15:29,335 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 25: {'lr': 0.004159617793131237, 'batch_size': np.int64(16), 'epochs': np.int64(30), 'weight_decay': 7.795525599854901e-06, 'base_channels': np.int64(11), 'kernel_size': np.int64(10), 'dropout': 0.00723665377744649, 'amp': np.False_, 'grad_clip_norm': 0.8819636140199963, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3621077834767537, 'label_smoothing': 0.15255893624551736, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(2)} -> 0.7426
2025-10-12 00:15:29,336 - INFO - bo.run_bo - üîçBO Trial 26: Using RF surrogate + Expected Improvement
2025-10-12 00:15:29,336 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:15:29,336 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:15:29,336 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:15:29,336 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00459070330685566, 'batch_size': 16, 'epochs': 23, 'weight_decay': 5.341458224423491e-06, 'base_channels': 7, 'kernel_size': 14, 'dropout': 0.060802196152316475, 'amp': True, 'grad_clip_norm': 0.1115082501704078, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.456194356867164, 'label_smoothing': 0.1496536596325378, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}
2025-10-12 00:15:29,337 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00459070330685566, 'batch_size': 16, 'epochs': 23, 'weight_decay': 5.341458224423491e-06, 'base_channels': 7, 'kernel_size': 14, 'dropout': 0.060802196152316475, 'amp': True, 'grad_clip_norm': 0.1115082501704078, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.456194356867164, 'label_smoothing': 0.1496536596325378, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}
2025-10-12 00:15:38,840 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.4998 | val_loss=1.3562 | val_acc=0.5003 | time=9.5s
2025-10-12 00:15:45,493 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3206 | val_loss=1.2623 | val_acc=0.5592 | time=6.7s
2025-10-12 00:15:52,159 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2370 | val_loss=1.1842 | val_acc=0.6140 | time=6.7s
2025-10-12 00:15:58,833 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.2041 | val_loss=1.2628 | val_acc=0.5868 | time=6.7s
2025-10-12 00:16:05,570 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.1860 | val_loss=1.1818 | val_acc=0.6365 | time=6.7s
2025-10-12 00:16:12,272 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1653 | val_loss=1.1711 | val_acc=0.6316 | time=6.7s
2025-10-12 00:16:18,969 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1486 | val_loss=1.1067 | val_acc=0.6920 | time=6.7s
2025-10-12 00:16:25,670 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1340 | val_loss=1.1926 | val_acc=0.6441 | time=6.7s
2025-10-12 00:16:32,362 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1224 | val_loss=1.1838 | val_acc=0.6458 | time=6.7s
2025-10-12 00:16:39,058 - INFO - _models.training_function_executor - Epoch 010 | train_loss=nan | val_loss=1.0974 | val_acc=0.6972 | time=6.7s
2025-10-12 00:16:45,743 - INFO - _models.training_function_executor - Epoch 011 | train_loss=nan | val_loss=1.1237 | val_acc=0.6936 | time=6.7s
2025-10-12 00:16:52,449 - INFO - _models.training_function_executor - Epoch 012 | train_loss=nan | val_loss=1.0964 | val_acc=0.6875 | time=6.7s
2025-10-12 00:16:59,158 - INFO - _models.training_function_executor - Epoch 013 | train_loss=nan | val_loss=1.0857 | val_acc=0.7181 | time=6.7s
2025-10-12 00:17:05,856 - INFO - _models.training_function_executor - Epoch 014 | train_loss=nan | val_loss=1.0861 | val_acc=0.7025 | time=6.7s
2025-10-12 00:17:12,534 - INFO - _models.training_function_executor - Epoch 015 | train_loss=nan | val_loss=25.9092 | val_acc=0.2325 | time=6.7s
2025-10-12 00:17:18,862 - INFO - _models.training_function_executor - Epoch 016 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.3s
2025-10-12 00:17:25,100 - INFO - _models.training_function_executor - Epoch 017 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.2s
2025-10-12 00:17:31,334 - INFO - _models.training_function_executor - Epoch 018 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.2s
2025-10-12 00:17:37,562 - INFO - _models.training_function_executor - Epoch 019 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.2s
2025-10-12 00:17:43,793 - INFO - _models.training_function_executor - Epoch 020 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.2s
2025-10-12 00:17:50,063 - INFO - _models.training_function_executor - Epoch 021 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.3s
2025-10-12 00:17:56,266 - INFO - _models.training_function_executor - Epoch 022 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.2s
2025-10-12 00:18:02,499 - INFO - _models.training_function_executor - Epoch 023 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.2s
2025-10-12 00:18:03,612 - INFO - _models.training_function_executor - Model: 1,463 parameters, 6.3KB storage
2025-10-12 00:18:03,612 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4997885673664482, 1.320600781192052, 1.237022126184129, 1.2040548890589167, 1.1859775954582994, 1.1653333585872323, 1.1486181074353754, 1.1340122966028654, 1.1223553328151923, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [1.3561693354920075, 1.262279456228643, 1.184228004275502, 1.262789205904607, 1.1818474812941118, 1.1711095122190622, 1.106726854414373, 1.192601230761388, 1.1838340084035914, 1.0974073355014509, 1.1237430177368484, 1.0963939679252517, 1.0856533387324192, 1.0860725387826666, 25.90919589729576, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5002625131256563, 0.5591529576478824, 0.6140182009100456, 0.5868043402170109, 0.636506825341267, 0.6316065803290164, 0.6919845992299615, 0.6441197059852992, 0.6457822891144557, 0.6972348617430871, 0.6935596779838992, 0.6875218760938047, 0.7180609030451522, 0.7024851242562128, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'best_epoch': 13, 'total_params': 1463, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00459070330685566, 'batch_size': 16, 'epochs': 23, 'weight_decay': 5.341458224423491e-06, 'base_channels': 7, 'kernel_size': 14, 'dropout': 0.060802196152316475, 'amp': True, 'grad_clip_norm': 0.1115082501704078, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.456194356867164, 'label_smoothing': 0.1496536596325378, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}, 'model_parameter_count': 1463, 'model_storage_size_kb': 6.286328125000001, 'model_size_validation': 'PASS'}
2025-10-12 00:18:03,612 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-12 00:18:03,612 - INFO - _models.training_function_executor - Model: 1,463 parameters, 6.3KB (PASS 256KB limit)
2025-10-12 00:18:03,612 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 154.276s
2025-10-12 00:18:03,718 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-12 00:18:03,718 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-12 00:18:03,718 - INFO - bo.run_bo - Recorded observation #26: hparams={'lr': 0.00459070330685566, 'batch_size': np.int64(16), 'epochs': np.int64(23), 'weight_decay': 5.341458224423491e-06, 'base_channels': np.int64(7), 'kernel_size': np.int64(14), 'dropout': 0.060802196152316475, 'amp': np.True_, 'grad_clip_norm': 0.1115082501704078, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.456194356867164, 'label_smoothing': 0.1496536596325378, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(6)}, value=0.2325
2025-10-12 00:18:03,718 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 26: {'lr': 0.00459070330685566, 'batch_size': np.int64(16), 'epochs': np.int64(23), 'weight_decay': 5.341458224423491e-06, 'base_channels': np.int64(7), 'kernel_size': np.int64(14), 'dropout': 0.060802196152316475, 'amp': np.True_, 'grad_clip_norm': 0.1115082501704078, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.456194356867164, 'label_smoothing': 0.1496536596325378, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(6)} -> 0.2325
2025-10-12 00:18:03,718 - INFO - bo.run_bo - üîçBO Trial 27: Using RF surrogate + Expected Improvement
2025-10-12 00:18:03,718 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:18:03,718 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:18:03,718 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:18:03,718 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004520650382453096, 'batch_size': 16, 'epochs': 16, 'weight_decay': 6.176622042983872e-05, 'base_channels': 4, 'kernel_size': 11, 'dropout': 0.047468191862011476, 'amp': False, 'grad_clip_norm': 0.9671363429342713, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3269206890776626, 'label_smoothing': 0.17896515051016668, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}
2025-10-12 00:18:03,720 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004520650382453096, 'batch_size': 16, 'epochs': 16, 'weight_decay': 6.176622042983872e-05, 'base_channels': 4, 'kernel_size': 11, 'dropout': 0.047468191862011476, 'amp': False, 'grad_clip_norm': 0.9671363429342713, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3269206890776626, 'label_smoothing': 0.17896515051016668, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}
2025-10-12 00:18:11,456 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.4981 | val_loss=1.4451 | val_acc=0.5122 | time=7.7s
2025-10-12 00:18:16,299 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3981 | val_loss=1.3498 | val_acc=0.5464 | time=4.8s
2025-10-12 00:18:21,133 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.3228 | val_loss=1.3366 | val_acc=0.5324 | time=4.8s
2025-10-12 00:18:25,962 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.3000 | val_loss=1.2980 | val_acc=0.5638 | time=4.8s
2025-10-12 00:18:30,797 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.2809 | val_loss=1.2378 | val_acc=0.5990 | time=4.8s
2025-10-12 00:18:35,656 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.2475 | val_loss=1.2504 | val_acc=0.6078 | time=4.9s
2025-10-12 00:18:40,499 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.2285 | val_loss=1.2071 | val_acc=0.6350 | time=4.8s
2025-10-12 00:18:45,332 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.2078 | val_loss=1.2176 | val_acc=0.6460 | time=4.8s
2025-10-12 00:18:50,149 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1942 | val_loss=1.2507 | val_acc=0.6424 | time=4.8s
2025-10-12 00:18:55,007 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1786 | val_loss=1.1791 | val_acc=0.6799 | time=4.9s
2025-10-12 00:18:59,871 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.1672 | val_loss=1.1707 | val_acc=0.6838 | time=4.9s
2025-10-12 00:19:04,687 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.1591 | val_loss=1.1563 | val_acc=0.6878 | time=4.8s
2025-10-12 00:19:09,490 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.1498 | val_loss=1.1564 | val_acc=0.6822 | time=4.8s
2025-10-12 00:19:14,332 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.1416 | val_loss=1.1465 | val_acc=0.6951 | time=4.8s
2025-10-12 00:19:19,220 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.1373 | val_loss=1.1444 | val_acc=0.6936 | time=4.9s
2025-10-12 00:19:24,071 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.1345 | val_loss=1.1454 | val_acc=0.6932 | time=4.9s
2025-10-12 00:19:25,186 - INFO - _models.training_function_executor - Model: 783 parameters, 3.4KB storage
2025-10-12 00:19:25,186 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4980551556436006, 1.3980794833346517, 1.3228260230509017, 1.2999928870483175, 1.2809443968052543, 1.2474516277385, 1.2284773137546896, 1.2078496062300779, 1.1942057182916528, 1.1785809483025764, 1.1671869476691885, 1.1591091198565704, 1.1498424430013663, 1.1416439927454631, 1.137349396474636, 1.134511135969706], 'val_losses': [1.445090129492166, 1.3498099723895947, 1.3365916637273936, 1.2980365787352715, 1.2377802512028835, 1.2503853291898341, 1.2071047576990994, 1.2176180443563662, 1.2507116176865318, 1.1791425979220784, 1.1707155127625366, 1.156321326335827, 1.1563688005600776, 1.1465307492476242, 1.1444353589644798, 1.1454126810694074], 'val_acc': [0.5121631081554078, 0.5463773188659433, 0.5323766188309416, 0.5637906895344768, 0.5989674483724187, 0.6078053902695135, 0.6350192509625481, 0.646044802240112, 0.642369618480924, 0.6799089954497725, 0.6837591879593979, 0.687784389219461, 0.6821841092054602, 0.6951347567378369, 0.6935596779838992, 0.6932096604830241], 'best_epoch': 14, 'total_params': 783, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004520650382453096, 'batch_size': 16, 'epochs': 16, 'weight_decay': 6.176622042983872e-05, 'base_channels': 4, 'kernel_size': 11, 'dropout': 0.047468191862011476, 'amp': False, 'grad_clip_norm': 0.9671363429342713, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3269206890776626, 'label_smoothing': 0.17896515051016668, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 3}, 'model_parameter_count': 783, 'model_storage_size_kb': 3.3644531250000003, 'model_size_validation': 'PASS'}
2025-10-12 00:19:25,186 - INFO - _models.training_function_executor - BO Objective: base=0.6932, size_penalty=0.0000, final=0.6932
2025-10-12 00:19:25,186 - INFO - _models.training_function_executor - Model: 783 parameters, 3.4KB (PASS 256KB limit)
2025-10-12 00:19:25,186 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 81.468s
2025-10-12 00:19:25,297 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6932
2025-10-12 00:19:25,297 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-12 00:19:25,297 - INFO - bo.run_bo - Recorded observation #27: hparams={'lr': 0.004520650382453096, 'batch_size': np.int64(16), 'epochs': np.int64(16), 'weight_decay': 6.176622042983872e-05, 'base_channels': np.int64(4), 'kernel_size': np.int64(11), 'dropout': 0.047468191862011476, 'amp': np.False_, 'grad_clip_norm': 0.9671363429342713, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3269206890776626, 'label_smoothing': 0.17896515051016668, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(3)}, value=0.6932
2025-10-12 00:19:25,297 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 27: {'lr': 0.004520650382453096, 'batch_size': np.int64(16), 'epochs': np.int64(16), 'weight_decay': 6.176622042983872e-05, 'base_channels': np.int64(4), 'kernel_size': np.int64(11), 'dropout': 0.047468191862011476, 'amp': np.False_, 'grad_clip_norm': 0.9671363429342713, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.3269206890776626, 'label_smoothing': 0.17896515051016668, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(3)} -> 0.6932
2025-10-12 00:19:25,298 - INFO - bo.run_bo - üîçBO Trial 28: Using RF surrogate + Expected Improvement
2025-10-12 00:19:25,298 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:19:25,298 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:19:25,298 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:19:25,298 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004826224025421514, 'batch_size': 16, 'epochs': 22, 'weight_decay': 4.079396811941366e-06, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.032642851584492406, 'amp': True, 'grad_clip_norm': 0.8082915442680473, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7537515414400977, 'label_smoothing': 0.12200377642182268, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 1}
2025-10-12 00:19:25,299 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004826224025421514, 'batch_size': 16, 'epochs': 22, 'weight_decay': 4.079396811941366e-06, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.032642851584492406, 'amp': True, 'grad_clip_norm': 0.8082915442680473, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7537515414400977, 'label_smoothing': 0.12200377642182268, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 1}
2025-10-12 00:19:34,548 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.7644 | val_loss=0.6439 | val_acc=0.5760 | time=9.2s
2025-10-12 00:19:40,943 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.6817 | val_loss=0.6092 | val_acc=0.6102 | time=6.4s
2025-10-12 00:19:47,371 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6296 | val_loss=0.5893 | val_acc=0.6255 | time=6.4s
2025-10-12 00:19:53,723 - INFO - _models.training_function_executor - Epoch 004 | train_loss=nan | val_loss=0.5873 | val_acc=0.6369 | time=6.4s
2025-10-12 00:20:00,106 - INFO - _models.training_function_executor - Epoch 005 | train_loss=nan | val_loss=2.7196 | val_acc=0.3599 | time=6.4s
2025-10-12 00:20:06,478 - INFO - _models.training_function_executor - Epoch 006 | train_loss=nan | val_loss=2.7196 | val_acc=0.3599 | time=6.4s
2025-10-12 00:20:12,534 - INFO - _models.training_function_executor - Epoch 007 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:20:18,510 - INFO - _models.training_function_executor - Epoch 008 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.0s
2025-10-12 00:20:24,464 - INFO - _models.training_function_executor - Epoch 009 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.0s
2025-10-12 00:20:30,404 - INFO - _models.training_function_executor - Epoch 010 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=5.9s
2025-10-12 00:20:36,335 - INFO - _models.training_function_executor - Epoch 011 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=5.9s
2025-10-12 00:20:42,275 - INFO - _models.training_function_executor - Epoch 012 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=5.9s
2025-10-12 00:20:48,226 - INFO - _models.training_function_executor - Epoch 013 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.0s
2025-10-12 00:20:54,138 - INFO - _models.training_function_executor - Epoch 014 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=5.9s
2025-10-12 00:21:00,063 - INFO - _models.training_function_executor - Epoch 015 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=5.9s
2025-10-12 00:21:05,982 - INFO - _models.training_function_executor - Epoch 016 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=5.9s
2025-10-12 00:21:11,936 - INFO - _models.training_function_executor - Epoch 017 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.0s
2025-10-12 00:21:17,871 - INFO - _models.training_function_executor - Epoch 018 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=5.9s
2025-10-12 00:21:23,817 - INFO - _models.training_function_executor - Epoch 019 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=5.9s
2025-10-12 00:21:29,768 - INFO - _models.training_function_executor - Epoch 020 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.0s
2025-10-12 00:21:35,750 - INFO - _models.training_function_executor - Epoch 021 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.0s
2025-10-12 00:21:41,708 - INFO - _models.training_function_executor - Epoch 022 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.0s
2025-10-12 00:21:42,810 - INFO - _models.training_function_executor - Model: 1,263 parameters, 5.4KB storage
2025-10-12 00:21:42,810 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7644435712662785, 0.6817136055779782, 0.6295914381095735, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [0.6438596883437017, 0.6092179814835529, 0.5892693769056481, 0.5872916276117305, 2.71959603199592, 2.71959603199592, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5759537976898845, 0.6101680084004201, 0.6254812740637031, 0.6368568428421421, 0.35990549527476373, 0.35990549527476373, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'best_epoch': 4, 'total_params': 1263, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004826224025421514, 'batch_size': 16, 'epochs': 22, 'weight_decay': 4.079396811941366e-06, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.032642851584492406, 'amp': True, 'grad_clip_norm': 0.8082915442680473, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7537515414400977, 'label_smoothing': 0.12200377642182268, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 1}, 'model_parameter_count': 1263, 'model_storage_size_kb': 5.426953125000001, 'model_size_validation': 'PASS'}
2025-10-12 00:21:42,811 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-12 00:21:42,811 - INFO - _models.training_function_executor - Model: 1,263 parameters, 5.4KB (PASS 256KB limit)
2025-10-12 00:21:42,811 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 137.513s
2025-10-12 00:21:42,915 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-12 00:21:42,915 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-12 00:21:42,915 - INFO - bo.run_bo - Recorded observation #28: hparams={'lr': 0.004826224025421514, 'batch_size': np.int64(16), 'epochs': np.int64(22), 'weight_decay': 4.079396811941366e-06, 'base_channels': np.int64(7), 'kernel_size': np.int64(10), 'dropout': 0.032642851584492406, 'amp': np.True_, 'grad_clip_norm': 0.8082915442680473, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7537515414400977, 'label_smoothing': 0.12200377642182268, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(1)}, value=0.2325
2025-10-12 00:21:42,915 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 28: {'lr': 0.004826224025421514, 'batch_size': np.int64(16), 'epochs': np.int64(22), 'weight_decay': 4.079396811941366e-06, 'base_channels': np.int64(7), 'kernel_size': np.int64(10), 'dropout': 0.032642851584492406, 'amp': np.True_, 'grad_clip_norm': 0.8082915442680473, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7537515414400977, 'label_smoothing': 0.12200377642182268, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(1)} -> 0.2325
2025-10-12 00:21:42,916 - INFO - bo.run_bo - üîçBO Trial 29: Using RF surrogate + Expected Improvement
2025-10-12 00:21:42,916 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:21:42,916 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:21:42,916 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:21:42,916 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004304318494211325, 'batch_size': 64, 'epochs': 17, 'weight_decay': 0.00010680219686827239, 'base_channels': 16, 'kernel_size': 12, 'dropout': 0.03031350017716367, 'amp': False, 'grad_clip_norm': 0.7685437689133611, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6263098409956722, 'label_smoothing': 0.1869760195182956, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:21:42,917 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004304318494211325, 'batch_size': 64, 'epochs': 17, 'weight_decay': 0.00010680219686827239, 'base_channels': 16, 'kernel_size': 12, 'dropout': 0.03031350017716367, 'amp': False, 'grad_clip_norm': 0.7685437689133611, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6263098409956722, 'label_smoothing': 0.1869760195182956, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:21:52,077 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9880 | val_loss=0.8184 | val_acc=0.5008 | time=9.2s
2025-10-12 00:21:58,395 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7401 | val_loss=0.6867 | val_acc=0.5482 | time=6.3s
2025-10-12 00:22:04,709 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6826 | val_loss=0.7141 | val_acc=0.5211 | time=6.3s
2025-10-12 00:22:11,020 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6245 | val_loss=0.6059 | val_acc=0.6068 | time=6.3s
2025-10-12 00:22:17,325 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5603 | val_loss=0.5202 | val_acc=0.6527 | time=6.3s
2025-10-12 00:22:23,637 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4834 | val_loss=0.4251 | val_acc=0.7258 | time=6.3s
2025-10-12 00:22:29,961 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4458 | val_loss=0.4563 | val_acc=0.7097 | time=6.3s
2025-10-12 00:22:36,290 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4332 | val_loss=0.4294 | val_acc=0.7159 | time=6.3s
2025-10-12 00:22:42,618 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4190 | val_loss=0.4082 | val_acc=0.7310 | time=6.3s
2025-10-12 00:22:48,947 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4047 | val_loss=0.4134 | val_acc=0.7240 | time=6.3s
2025-10-12 00:22:55,274 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3907 | val_loss=0.3754 | val_acc=0.7464 | time=6.3s
2025-10-12 00:23:01,607 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3772 | val_loss=0.3822 | val_acc=0.7440 | time=6.3s
2025-10-12 00:23:07,941 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3660 | val_loss=0.3776 | val_acc=0.7487 | time=6.3s
2025-10-12 00:23:14,270 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3544 | val_loss=0.3632 | val_acc=0.7501 | time=6.3s
2025-10-12 00:23:20,602 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3463 | val_loss=0.3624 | val_acc=0.7535 | time=6.3s
2025-10-12 00:23:26,938 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3399 | val_loss=0.3578 | val_acc=0.7563 | time=6.3s
2025-10-12 00:23:33,270 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3358 | val_loss=0.3575 | val_acc=0.7565 | time=6.3s
2025-10-12 00:23:34,371 - INFO - _models.training_function_executor - Model: 3,523 parameters, 15.1KB storage
2025-10-12 00:23:34,371 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9879558062219953, 0.7401081916752396, 0.6826070409137885, 0.6245274476238064, 0.5602555075725475, 0.48340216708350014, 0.4458411218819918, 0.4332103962039614, 0.4189633736243615, 0.40469031698637076, 0.3907116197622739, 0.3771970414615178, 0.36600712493999854, 0.3543657998938661, 0.34627059661633486, 0.3398754126750506, 0.33583761493226033], 'val_losses': [0.8184238682246076, 0.6867336920519781, 0.7141345233224624, 0.6059103308443251, 0.5202293395996094, 0.42510220258595555, 0.45631276387409125, 0.42939207557193393, 0.40820173977473595, 0.4133929145735735, 0.3754001049189594, 0.38216731917924723, 0.37763373120870003, 0.3631921022630937, 0.3623974163439021, 0.3578111050681695, 0.3574675285782894], 'val_acc': [0.5007875393769688, 0.5482149107455373, 0.5210885544277214, 0.6067553377668884, 0.6526951347567378, 0.725848792439622, 0.70974798739937, 0.7158732936646832, 0.7310115505775289, 0.724011200560028, 0.7464123206160308, 0.7439621981099055, 0.7486874343717186, 0.7500875043752188, 0.7535001750087504, 0.7563003150157508, 0.7564753237661883], 'best_epoch': 17, 'total_params': 3523, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004304318494211325, 'batch_size': 64, 'epochs': 17, 'weight_decay': 0.00010680219686827239, 'base_channels': 16, 'kernel_size': 12, 'dropout': 0.03031350017716367, 'amp': False, 'grad_clip_norm': 0.7685437689133611, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6263098409956722, 'label_smoothing': 0.1869760195182956, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}, 'model_parameter_count': 3523, 'model_storage_size_kb': 15.137890625, 'model_size_validation': 'PASS'}
2025-10-12 00:23:34,371 - INFO - _models.training_function_executor - BO Objective: base=0.7565, size_penalty=0.0000, final=0.7565
2025-10-12 00:23:34,371 - INFO - _models.training_function_executor - Model: 3,523 parameters, 15.1KB (PASS 256KB limit)
2025-10-12 00:23:34,371 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 111.456s
2025-10-12 00:23:34,489 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7565
2025-10-12 00:23:34,489 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.105s
2025-10-12 00:23:34,489 - INFO - bo.run_bo - Recorded observation #29: hparams={'lr': 0.004304318494211325, 'batch_size': np.int64(64), 'epochs': np.int64(17), 'weight_decay': 0.00010680219686827239, 'base_channels': np.int64(16), 'kernel_size': np.int64(12), 'dropout': 0.03031350017716367, 'amp': np.False_, 'grad_clip_norm': 0.7685437689133611, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6263098409956722, 'label_smoothing': 0.1869760195182956, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}, value=0.7565
2025-10-12 00:23:34,489 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 29: {'lr': 0.004304318494211325, 'batch_size': np.int64(64), 'epochs': np.int64(17), 'weight_decay': 0.00010680219686827239, 'base_channels': np.int64(16), 'kernel_size': np.int64(12), 'dropout': 0.03031350017716367, 'amp': np.False_, 'grad_clip_norm': 0.7685437689133611, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6263098409956722, 'label_smoothing': 0.1869760195182956, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)} -> 0.7565
2025-10-12 00:23:34,490 - INFO - bo.run_bo - üîçBO Trial 30: Using RF surrogate + Expected Improvement
2025-10-12 00:23:34,490 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:23:34,490 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:23:34,490 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:23:34,490 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004397297232479008, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.2710621369165862e-05, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.003950450539863282, 'amp': True, 'grad_clip_norm': 0.81449310801231, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.0788835423435805, 'label_smoothing': 0.03327629703685072, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}
2025-10-12 00:23:34,491 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004397297232479008, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.2710621369165862e-05, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.003950450539863282, 'amp': True, 'grad_clip_norm': 0.81449310801231, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.0788835423435805, 'label_smoothing': 0.03327629703685072, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}
2025-10-12 00:23:42,705 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.6182 | val_loss=0.5280 | val_acc=0.6225 | time=8.2s
2025-10-12 00:23:48,079 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5187 | val_loss=0.4917 | val_acc=0.6376 | time=5.4s
2025-10-12 00:23:53,445 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4829 | val_loss=0.4774 | val_acc=0.6532 | time=5.4s
2025-10-12 00:23:58,821 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4299 | val_loss=0.4046 | val_acc=0.7240 | time=5.4s
2025-10-12 00:24:04,186 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4120 | val_loss=0.3855 | val_acc=0.7237 | time=5.4s
2025-10-12 00:24:09,564 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4048 | val_loss=0.3801 | val_acc=0.7288 | time=5.4s
2025-10-12 00:24:14,933 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4019 | val_loss=0.4179 | val_acc=0.6902 | time=5.4s
2025-10-12 00:24:20,309 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3958 | val_loss=0.4545 | val_acc=0.6712 | time=5.4s
2025-10-12 00:24:25,691 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3877 | val_loss=0.4083 | val_acc=0.7078 | time=5.4s
2025-10-12 00:24:31,066 - INFO - _models.training_function_executor - Epoch 010 | train_loss=nan | val_loss=0.3951 | val_acc=0.6965 | time=5.4s
2025-10-12 00:24:36,435 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3798 | val_loss=0.3678 | val_acc=0.7281 | time=5.4s
2025-10-12 00:24:41,811 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3769 | val_loss=0.4292 | val_acc=0.6806 | time=5.4s
2025-10-12 00:24:47,184 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3771 | val_loss=0.3656 | val_acc=0.7165 | time=5.4s
2025-10-12 00:24:52,549 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3708 | val_loss=0.3868 | val_acc=0.7004 | time=5.4s
2025-10-12 00:24:57,913 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3670 | val_loss=0.4056 | val_acc=0.7132 | time=5.4s
2025-10-12 00:25:03,288 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3658 | val_loss=0.3621 | val_acc=0.7304 | time=5.4s
2025-10-12 00:25:04,394 - INFO - _models.training_function_executor - Model: 1,851 parameters, 8.0KB storage
2025-10-12 00:25:04,395 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.6182295296515844, 0.5186984555194893, 0.4828509297652041, 0.4298847668691479, 0.41202622458098903, 0.4047592055701642, 0.4018998397468603, 0.39581803880512006, 0.38774556656706327, nan, 0.3798244699178833, 0.3768765963379364, 0.37710898114593816, 0.37076427908503484, 0.3669986924126567, 0.3658051895012882], 'val_losses': [0.5279779974475253, 0.4917235292868907, 0.47743920544838775, 0.40459201622275665, 0.3855142139272983, 0.38005894713894617, 0.41785873784865746, 0.4544800246894027, 0.408338882903147, 0.39507451395415727, 0.36781131234748404, 0.42918709628075863, 0.36560538640068896, 0.3868272722849633, 0.4056235542676968, 0.36206834560894935], 'val_acc': [0.6225061253062654, 0.6376443822191109, 0.6532201610080504, 0.724011200560028, 0.7237486874343717, 0.7288239411970598, 0.6902345117255863, 0.6711585579278964, 0.7078228911445572, 0.696534826741337, 0.7281239061953098, 0.6806090304515225, 0.7164858242912145, 0.7003850192509625, 0.7132481624081204, 0.7303990199509975], 'best_epoch': 16, 'total_params': 1851, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004397297232479008, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.2710621369165862e-05, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.003950450539863282, 'amp': True, 'grad_clip_norm': 0.81449310801231, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.0788835423435805, 'label_smoothing': 0.03327629703685072, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 5}, 'model_parameter_count': 1851, 'model_storage_size_kb': 7.9535156250000005, 'model_size_validation': 'PASS'}
2025-10-12 00:25:04,395 - INFO - _models.training_function_executor - BO Objective: base=0.7304, size_penalty=0.0000, final=0.7304
2025-10-12 00:25:04,395 - INFO - _models.training_function_executor - Model: 1,851 parameters, 8.0KB (PASS 256KB limit)
2025-10-12 00:25:04,395 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 89.905s
2025-10-12 00:25:04,504 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7304
2025-10-12 00:25:04,504 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.105s
2025-10-12 00:25:04,504 - INFO - bo.run_bo - Recorded observation #30: hparams={'lr': 0.004397297232479008, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 1.2710621369165862e-05, 'base_channels': np.int64(10), 'kernel_size': np.int64(10), 'dropout': 0.003950450539863282, 'amp': np.True_, 'grad_clip_norm': 0.81449310801231, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.0788835423435805, 'label_smoothing': 0.03327629703685072, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(5)}, value=0.7304
2025-10-12 00:25:04,504 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 30: {'lr': 0.004397297232479008, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 1.2710621369165862e-05, 'base_channels': np.int64(10), 'kernel_size': np.int64(10), 'dropout': 0.003950450539863282, 'amp': np.True_, 'grad_clip_norm': 0.81449310801231, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.0788835423435805, 'label_smoothing': 0.03327629703685072, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(5)} -> 0.7304
2025-10-12 00:25:04,504 - INFO - bo.run_bo - üîçBO Trial 31: Using RF surrogate + Expected Improvement
2025-10-12 00:25:04,504 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:25:04,505 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:25:04,505 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:25:04,505 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00453087281043834, 'batch_size': 32, 'epochs': 17, 'weight_decay': 2.059231473927606e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.015070532731573195, 'amp': False, 'grad_clip_norm': 0.46127299736515737, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4394755223583733, 'label_smoothing': 0.14831117210979483, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-12 00:25:04,506 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00453087281043834, 'batch_size': 32, 'epochs': 17, 'weight_decay': 2.059231473927606e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.015070532731573195, 'amp': False, 'grad_clip_norm': 0.46127299736515737, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4394755223583733, 'label_smoothing': 0.14831117210979483, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-12 00:25:12,071 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.7394 | val_loss=0.6951 | val_acc=0.6022 | time=7.6s
2025-10-12 00:25:16,780 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5788 | val_loss=0.5561 | val_acc=0.6656 | time=4.7s
2025-10-12 00:25:21,480 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5514 | val_loss=0.6113 | val_acc=0.6351 | time=4.7s
2025-10-12 00:25:26,185 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5447 | val_loss=0.5437 | val_acc=0.6918 | time=4.7s
2025-10-12 00:25:30,889 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5271 | val_loss=0.5291 | val_acc=0.6833 | time=4.7s
2025-10-12 00:25:35,592 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5209 | val_loss=0.5370 | val_acc=0.6764 | time=4.7s
2025-10-12 00:25:40,293 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5066 | val_loss=0.4828 | val_acc=0.7020 | time=4.7s
2025-10-12 00:25:45,001 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.5010 | val_loss=0.5167 | val_acc=0.6808 | time=4.7s
2025-10-12 00:25:49,704 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4959 | val_loss=0.5120 | val_acc=0.6746 | time=4.7s
2025-10-12 00:25:54,412 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4874 | val_loss=0.5301 | val_acc=0.6772 | time=4.7s
2025-10-12 00:25:59,113 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4812 | val_loss=0.4569 | val_acc=0.7275 | time=4.7s
2025-10-12 00:26:03,819 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4725 | val_loss=0.4368 | val_acc=0.7395 | time=4.7s
2025-10-12 00:26:08,522 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.4647 | val_loss=0.5338 | val_acc=0.6940 | time=4.7s
2025-10-12 00:26:13,229 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.4682 | val_loss=0.5428 | val_acc=0.6707 | time=4.7s
2025-10-12 00:26:17,939 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.4547 | val_loss=0.4831 | val_acc=0.6955 | time=4.7s
2025-10-12 00:26:22,648 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.4559 | val_loss=0.4268 | val_acc=0.7350 | time=4.7s
2025-10-12 00:26:27,356 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.4578 | val_loss=0.4453 | val_acc=0.7430 | time=4.7s
2025-10-12 00:26:28,473 - INFO - _models.training_function_executor - Model: 1,263 parameters, 5.4KB storage
2025-10-12 00:26:28,474 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7393862880802888, 0.5787564358296637, 0.5513752956253569, 0.5446992204208487, 0.5271327634993094, 0.5209366149569492, 0.5066330335601549, 0.5009958685236932, 0.4959404682721017, 0.48735148795965755, 0.48120813783938604, 0.47250070719555426, 0.4646835466149472, 0.46816763712485576, 0.45471986506767753, 0.45594484805852237, 0.45779593006308217], 'val_losses': [0.6950735991727041, 0.5561283727764418, 0.611304380623988, 0.5436667462384235, 0.5290563295506898, 0.53703415997368, 0.4828488040902761, 0.5166569228112364, 0.5119876826192413, 0.5300622521249275, 0.45687469298946126, 0.4368152663361427, 0.53384796575794, 0.5428039191405201, 0.4830643690331688, 0.42683339901476597, 0.4452580574837477], 'val_acc': [0.6022051102555128, 0.6655582779138957, 0.6351067553377668, 0.691809590479524, 0.6833216660833041, 0.676408820441022, 0.7019600980049002, 0.6807840392019601, 0.674571228561428, 0.6771963598179909, 0.7275113755687784, 0.7394994749737487, 0.693997199859993, 0.6707210360518026, 0.6954847742387119, 0.7350367518375919, 0.7429996499824991], 'best_epoch': 17, 'total_params': 1263, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00453087281043834, 'batch_size': 32, 'epochs': 17, 'weight_decay': 2.059231473927606e-05, 'base_channels': 7, 'kernel_size': 10, 'dropout': 0.015070532731573195, 'amp': False, 'grad_clip_norm': 0.46127299736515737, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4394755223583733, 'label_smoothing': 0.14831117210979483, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}, 'model_parameter_count': 1263, 'model_storage_size_kb': 5.426953125000001, 'model_size_validation': 'PASS'}
2025-10-12 00:26:28,474 - INFO - _models.training_function_executor - BO Objective: base=0.7430, size_penalty=0.0000, final=0.7430
2025-10-12 00:26:28,474 - INFO - _models.training_function_executor - Model: 1,263 parameters, 5.4KB (PASS 256KB limit)
2025-10-12 00:26:28,474 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 83.969s
2025-10-12 00:26:28,708 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7430
2025-10-12 00:26:28,708 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.232s
2025-10-12 00:26:28,709 - INFO - bo.run_bo - Recorded observation #31: hparams={'lr': 0.00453087281043834, 'batch_size': np.int64(32), 'epochs': np.int64(17), 'weight_decay': 2.059231473927606e-05, 'base_channels': np.int64(7), 'kernel_size': np.int64(10), 'dropout': 0.015070532731573195, 'amp': np.False_, 'grad_clip_norm': 0.46127299736515737, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4394755223583733, 'label_smoothing': 0.14831117210979483, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)}, value=0.7430
2025-10-12 00:26:28,709 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 31: {'lr': 0.00453087281043834, 'batch_size': np.int64(32), 'epochs': np.int64(17), 'weight_decay': 2.059231473927606e-05, 'base_channels': np.int64(7), 'kernel_size': np.int64(10), 'dropout': 0.015070532731573195, 'amp': np.False_, 'grad_clip_norm': 0.46127299736515737, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4394755223583733, 'label_smoothing': 0.14831117210979483, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)} -> 0.7430
2025-10-12 00:26:28,709 - INFO - bo.run_bo - üîçBO Trial 32: Using RF surrogate + Expected Improvement
2025-10-12 00:26:28,709 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:26:28,709 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:26:28,709 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:26:28,709 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004572691806905605, 'batch_size': 64, 'epochs': 27, 'weight_decay': 0.0009141371526901707, 'base_channels': 11, 'kernel_size': 3, 'dropout': 0.016070403083131138, 'amp': False, 'grad_clip_norm': 0.47849133708098546, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.7185751605936908, 'label_smoothing': 0.14209538800703972, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 4}
2025-10-12 00:26:28,710 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004572691806905605, 'batch_size': 64, 'epochs': 27, 'weight_decay': 0.0009141371526901707, 'base_channels': 11, 'kernel_size': 3, 'dropout': 0.016070403083131138, 'amp': False, 'grad_clip_norm': 0.47849133708098546, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.7185751605936908, 'label_smoothing': 0.14209538800703972, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 4}
2025-10-12 00:26:36,566 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.7027 | val_loss=1.5611 | val_acc=0.3791 | time=7.9s
2025-10-12 00:26:41,626 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.4366 | val_loss=1.3526 | val_acc=0.5186 | time=5.1s
2025-10-12 00:26:46,685 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.3316 | val_loss=1.3361 | val_acc=0.5411 | time=5.1s
2025-10-12 00:26:51,737 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.3032 | val_loss=1.3343 | val_acc=0.5431 | time=5.1s
2025-10-12 00:26:56,786 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.2784 | val_loss=1.3779 | val_acc=0.5129 | time=5.0s
2025-10-12 00:27:01,847 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.2581 | val_loss=1.2809 | val_acc=0.5660 | time=5.1s
2025-10-12 00:27:06,908 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.2241 | val_loss=1.2223 | val_acc=0.6233 | time=5.1s
2025-10-12 00:27:11,964 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1944 | val_loss=1.1612 | val_acc=0.6629 | time=5.1s
2025-10-12 00:27:17,023 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1664 | val_loss=1.1879 | val_acc=0.6432 | time=5.1s
2025-10-12 00:27:22,080 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1483 | val_loss=1.1719 | val_acc=0.6222 | time=5.1s
2025-10-12 00:27:27,139 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.1378 | val_loss=1.1314 | val_acc=0.6568 | time=5.1s
2025-10-12 00:27:32,199 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.1286 | val_loss=1.1348 | val_acc=0.6546 | time=5.1s
2025-10-12 00:27:37,246 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.1226 | val_loss=1.1175 | val_acc=0.6796 | time=5.0s
2025-10-12 00:27:42,307 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.1147 | val_loss=1.1098 | val_acc=0.6828 | time=5.1s
2025-10-12 00:27:47,367 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.1073 | val_loss=1.0940 | val_acc=0.6859 | time=5.1s
2025-10-12 00:27:52,425 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.1021 | val_loss=1.0963 | val_acc=0.6901 | time=5.1s
2025-10-12 00:27:57,480 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.0935 | val_loss=1.0871 | val_acc=0.6934 | time=5.1s
2025-10-12 00:28:02,544 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.0898 | val_loss=1.0872 | val_acc=0.6906 | time=5.1s
2025-10-12 00:28:07,597 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.0859 | val_loss=1.0877 | val_acc=0.6851 | time=5.1s
2025-10-12 00:28:12,652 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0804 | val_loss=1.0879 | val_acc=0.6957 | time=5.1s
2025-10-12 00:28:17,710 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0754 | val_loss=1.0773 | val_acc=0.6997 | time=5.1s
2025-10-12 00:28:22,768 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.0740 | val_loss=1.0792 | val_acc=0.6969 | time=5.1s
2025-10-12 00:28:27,829 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.0699 | val_loss=1.0795 | val_acc=0.7056 | time=5.1s
2025-10-12 00:28:32,891 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.0668 | val_loss=1.0749 | val_acc=0.7005 | time=5.1s
2025-10-12 00:28:37,949 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.0635 | val_loss=1.0750 | val_acc=0.7018 | time=5.1s
2025-10-12 00:28:43,007 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.0629 | val_loss=1.0737 | val_acc=0.7034 | time=5.1s
2025-10-12 00:28:48,068 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.0613 | val_loss=1.0731 | val_acc=0.7033 | time=5.1s
2025-10-12 00:28:48,072 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 00:28:49,173 - INFO - _models.training_function_executor - Model: 1,543 parameters, 3.3KB storage
2025-10-12 00:28:49,173 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7027155084209842, 1.4365918908085857, 1.3316094326806236, 1.30317338363274, 1.2783886270923215, 1.2580649649346625, 1.2241037672216242, 1.1944269440390847, 1.166381305998022, 1.1482601655113114, 1.1377771497606397, 1.1286293093974773, 1.1225692460586976, 1.1147019043669, 1.107313290676037, 1.1021060200004311, 1.0934919225586044, 1.0898245623895337, 1.0859206758179032, 1.0804230602471145, 1.0753518229597931, 1.0740466057837426, 1.0699219223502632, 1.0668251007586926, 1.063461852490485, 1.0628756272209274, 1.061271283509848], 'val_losses': [1.5611188138663437, 1.3525706323165467, 1.3361011297343164, 1.334265965989182, 1.3779275896828933, 1.2808939165243223, 1.2222707458048558, 1.1611570672615947, 1.1879143848099523, 1.1719154965278156, 1.131437299970808, 1.1347728594721362, 1.1175087054348525, 1.109813022213941, 1.0940331949868016, 1.0962637246654021, 1.087067501504994, 1.0871835860460164, 1.0877257688751434, 1.0878794596181902, 1.0772621888022182, 1.0791688091928067, 1.0794881772062632, 1.0749322518956062, 1.0750219755332564, 1.0737200525885853, 1.0730945994068124], 'val_acc': [0.3790689534476724, 0.5186384319215961, 0.5411270563528177, 0.5430521526076304, 0.5128631431571579, 0.5659782989149458, 0.6232936646832342, 0.6629331466573328, 0.6431571578578928, 0.6222436121806091, 0.6568078403920196, 0.6546202310115505, 0.6795589779488974, 0.6827966398319916, 0.6858592929646482, 0.6900595029751487, 0.6933846692334616, 0.6905845292264613, 0.6850717535876794, 0.6957472873643682, 0.6996849842492124, 0.6968848442422121, 0.7056352817640882, 0.7004725236261813, 0.7017850892544627, 0.7034476723836192, 0.7032726636331816], 'best_epoch': 23, 'total_params': 1543, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004572691806905605, 'batch_size': 64, 'epochs': 27, 'weight_decay': 0.0009141371526901707, 'base_channels': 11, 'kernel_size': 3, 'dropout': 0.016070403083131138, 'amp': False, 'grad_clip_norm': 0.47849133708098546, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.7185751605936908, 'label_smoothing': 0.14209538800703972, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 4}, 'model_parameter_count': 1543, 'model_storage_size_kb': 3.3150390625000004, 'model_size_validation': 'PASS'}
2025-10-12 00:28:49,173 - INFO - _models.training_function_executor - BO Objective: base=0.7033, size_penalty=0.0000, final=0.7033
2025-10-12 00:28:49,173 - INFO - _models.training_function_executor - Model: 1,543 parameters, 3.3KB (PASS 256KB limit)
2025-10-12 00:28:49,173 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 140.464s
2025-10-12 00:28:49,291 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7033
2025-10-12 00:28:49,291 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.109s
2025-10-12 00:28:49,291 - INFO - bo.run_bo - Recorded observation #32: hparams={'lr': 0.004572691806905605, 'batch_size': np.int64(64), 'epochs': np.int64(27), 'weight_decay': 0.0009141371526901707, 'base_channels': np.int64(11), 'kernel_size': np.int64(3), 'dropout': 0.016070403083131138, 'amp': np.False_, 'grad_clip_norm': 0.47849133708098546, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.7185751605936908, 'label_smoothing': 0.14209538800703972, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(4)}, value=0.7033
2025-10-12 00:28:49,291 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 32: {'lr': 0.004572691806905605, 'batch_size': np.int64(64), 'epochs': np.int64(27), 'weight_decay': 0.0009141371526901707, 'base_channels': np.int64(11), 'kernel_size': np.int64(3), 'dropout': 0.016070403083131138, 'amp': np.False_, 'grad_clip_norm': 0.47849133708098546, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 1.7185751605936908, 'label_smoothing': 0.14209538800703972, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(4)} -> 0.7033
2025-10-12 00:28:49,291 - INFO - bo.run_bo - üîçBO Trial 33: Using RF surrogate + Expected Improvement
2025-10-12 00:28:49,291 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:28:49,291 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:28:49,291 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:28:49,291 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003595408067961084, 'batch_size': 64, 'epochs': 25, 'weight_decay': 8.628013963715839e-06, 'base_channels': 12, 'kernel_size': 11, 'dropout': 0.03718313459605959, 'amp': True, 'grad_clip_norm': 0.2673422741373824, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7316900723724369, 'label_smoothing': 0.1354588270015987, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 00:28:49,293 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003595408067961084, 'batch_size': 64, 'epochs': 25, 'weight_decay': 8.628013963715839e-06, 'base_channels': 12, 'kernel_size': 11, 'dropout': 0.03718313459605959, 'amp': True, 'grad_clip_norm': 0.2673422741373824, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7316900723724369, 'label_smoothing': 0.1354588270015987, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 00:28:57,325 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0312 | val_loss=0.8017 | val_acc=0.4984 | time=8.0s
2025-10-12 00:29:02,496 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7101 | val_loss=0.6850 | val_acc=0.5439 | time=5.2s
2025-10-12 00:29:07,673 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6584 | val_loss=0.6662 | val_acc=0.5444 | time=5.2s
2025-10-12 00:29:12,841 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6266 | val_loss=0.6048 | val_acc=0.6196 | time=5.2s
2025-10-12 00:29:18,014 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5893 | val_loss=0.5752 | val_acc=0.6172 | time=5.2s
2025-10-12 00:29:23,187 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5358 | val_loss=0.5127 | val_acc=0.6624 | time=5.2s
2025-10-12 00:29:28,370 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4937 | val_loss=0.4939 | val_acc=0.6751 | time=5.2s
2025-10-12 00:29:33,541 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4575 | val_loss=0.5056 | val_acc=0.6535 | time=5.2s
2025-10-12 00:29:38,705 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4390 | val_loss=0.4541 | val_acc=0.6926 | time=5.2s
2025-10-12 00:29:43,870 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4271 | val_loss=0.4001 | val_acc=0.7260 | time=5.2s
2025-10-12 00:29:49,048 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4110 | val_loss=0.4296 | val_acc=0.7219 | time=5.2s
2025-10-12 00:29:54,225 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3989 | val_loss=0.3891 | val_acc=0.7370 | time=5.2s
2025-10-12 00:29:59,427 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3935 | val_loss=0.4233 | val_acc=0.7258 | time=5.2s
2025-10-12 00:30:04,609 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3809 | val_loss=0.4092 | val_acc=0.7276 | time=5.2s
2025-10-12 00:30:09,794 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3768 | val_loss=0.3811 | val_acc=0.7454 | time=5.2s
2025-10-12 00:30:14,983 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3663 | val_loss=0.3795 | val_acc=0.7464 | time=5.2s
2025-10-12 00:30:20,171 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3617 | val_loss=0.3752 | val_acc=0.7454 | time=5.2s
2025-10-12 00:30:25,360 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3580 | val_loss=0.3767 | val_acc=0.7374 | time=5.2s
2025-10-12 00:30:30,557 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3521 | val_loss=0.3752 | val_acc=0.7489 | time=5.2s
2025-10-12 00:30:35,747 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3496 | val_loss=0.3677 | val_acc=0.7505 | time=5.2s
2025-10-12 00:30:40,927 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3403 | val_loss=0.3642 | val_acc=0.7550 | time=5.2s
2025-10-12 00:30:46,126 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3379 | val_loss=0.3692 | val_acc=0.7541 | time=5.2s
2025-10-12 00:30:51,365 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3325 | val_loss=0.3581 | val_acc=0.7540 | time=5.2s
2025-10-12 00:30:56,582 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3302 | val_loss=0.3586 | val_acc=0.7533 | time=5.2s
2025-10-12 00:31:01,795 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3294 | val_loss=0.3583 | val_acc=0.7553 | time=5.2s
2025-10-12 00:31:01,798 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 00:31:02,912 - INFO - _models.training_function_executor - Model: 2,303 parameters, 4.9KB storage
2025-10-12 00:31:02,912 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0311600728468462, 0.7100703001439155, 0.6583730442540628, 0.6266041761928505, 0.5893386892505459, 0.5357849244471197, 0.49369696557938636, 0.457475357955986, 0.4389741172323694, 0.4271487182462132, 0.4109957381145104, 0.39890292005522265, 0.3935143441795469, 0.38092218927153343, 0.376765887387149, 0.36631308929486706, 0.361670674748354, 0.3579637415759213, 0.35206764121572454, 0.3495814664797349, 0.3402575816724684, 0.3378744070763355, 0.33245026610947986, 0.33018055345628644, 0.3293728256454835], 'val_losses': [0.8016730104078794, 0.6850367891055912, 0.6661734031565363, 0.6048043716553203, 0.5751828461385972, 0.5126525315159526, 0.4938664223228753, 0.5056205888034245, 0.454145748688522, 0.4000965711457769, 0.429570857040043, 0.38908952940775693, 0.42333069893234937, 0.4092146568624667, 0.3810780434635098, 0.3795326858259446, 0.37516883714904997, 0.37670890345919733, 0.3752263938414984, 0.36768800344880065, 0.36419097263386796, 0.3691551802711114, 0.3580603371452353, 0.3586377698782436, 0.3583217959164241], 'val_acc': [0.4984249212460623, 0.543927196359818, 0.5443647182359118, 0.6196184809240463, 0.617168358417921, 0.6624081204060203, 0.6750962548127406, 0.6534826741337066, 0.6925971298564928, 0.7260238011900595, 0.7219110955547777, 0.7370493524676234, 0.7257612880644032, 0.7275988799439972, 0.7454497724886244, 0.7464123206160308, 0.7454497724886244, 0.7373993699684984, 0.7488624431221561, 0.7505250262513126, 0.7549877493874694, 0.7541127056352818, 0.754025201260063, 0.7533251662583129, 0.7553377668883444], 'best_epoch': 25, 'total_params': 2303, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003595408067961084, 'batch_size': 64, 'epochs': 25, 'weight_decay': 8.628013963715839e-06, 'base_channels': 12, 'kernel_size': 11, 'dropout': 0.03718313459605959, 'amp': True, 'grad_clip_norm': 0.2673422741373824, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7316900723724369, 'label_smoothing': 0.1354588270015987, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}, 'model_parameter_count': 2303, 'model_storage_size_kb': 4.9478515625, 'model_size_validation': 'PASS'}
2025-10-12 00:31:02,912 - INFO - _models.training_function_executor - BO Objective: base=0.7553, size_penalty=0.0000, final=0.7553
2025-10-12 00:31:02,912 - INFO - _models.training_function_executor - Model: 2,303 parameters, 4.9KB (PASS 256KB limit)
2025-10-12 00:31:02,912 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 133.621s
2025-10-12 00:31:03,025 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7553
2025-10-12 00:31:03,025 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-12 00:31:03,025 - INFO - bo.run_bo - Recorded observation #33: hparams={'lr': 0.003595408067961084, 'batch_size': np.int64(64), 'epochs': np.int64(25), 'weight_decay': 8.628013963715839e-06, 'base_channels': np.int64(12), 'kernel_size': np.int64(11), 'dropout': 0.03718313459605959, 'amp': np.True_, 'grad_clip_norm': 0.2673422741373824, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7316900723724369, 'label_smoothing': 0.1354588270015987, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)}, value=0.7553
2025-10-12 00:31:03,025 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 33: {'lr': 0.003595408067961084, 'batch_size': np.int64(64), 'epochs': np.int64(25), 'weight_decay': 8.628013963715839e-06, 'base_channels': np.int64(12), 'kernel_size': np.int64(11), 'dropout': 0.03718313459605959, 'amp': np.True_, 'grad_clip_norm': 0.2673422741373824, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.7316900723724369, 'label_smoothing': 0.1354588270015987, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)} -> 0.7553
2025-10-12 00:31:03,026 - INFO - bo.run_bo - üîçBO Trial 34: Using RF surrogate + Expected Improvement
2025-10-12 00:31:03,026 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:31:03,026 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:31:03,026 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:31:03,026 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004218439443446737, 'batch_size': 16, 'epochs': 16, 'weight_decay': 8.69533371840594e-05, 'base_channels': 11, 'kernel_size': 14, 'dropout': 0.043609068363624985, 'amp': True, 'grad_clip_norm': 0.6244304007129833, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.879871549132549, 'label_smoothing': 0.18036567670088255, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}
2025-10-12 00:31:03,027 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004218439443446737, 'batch_size': 16, 'epochs': 16, 'weight_decay': 8.69533371840594e-05, 'base_channels': 11, 'kernel_size': 14, 'dropout': 0.043609068363624985, 'amp': True, 'grad_clip_norm': 0.6244304007129833, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.879871549132549, 'label_smoothing': 0.18036567670088255, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}
2025-10-12 00:31:13,177 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.6364 | val_loss=0.4983 | val_acc=0.5847 | time=10.1s
2025-10-12 00:31:20,405 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5228 | val_loss=0.4563 | val_acc=0.5746 | time=7.2s
2025-10-12 00:31:27,619 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4696 | val_loss=0.3951 | val_acc=0.6491 | time=7.2s
2025-10-12 00:31:34,818 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4233 | val_loss=0.5184 | val_acc=0.5380 | time=7.2s
2025-10-12 00:31:42,002 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3991 | val_loss=0.4806 | val_acc=0.6247 | time=7.2s
2025-10-12 00:31:49,198 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3812 | val_loss=0.4682 | val_acc=0.6031 | time=7.2s
2025-10-12 00:31:56,414 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3519 | val_loss=0.3289 | val_acc=0.7384 | time=7.2s
2025-10-12 00:32:03,612 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3285 | val_loss=0.3154 | val_acc=0.7151 | time=7.2s
2025-10-12 00:32:10,830 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3206 | val_loss=0.3941 | val_acc=0.6841 | time=7.2s
2025-10-12 00:32:18,046 - INFO - _models.training_function_executor - Epoch 010 | train_loss=nan | val_loss=0.3890 | val_acc=0.6387 | time=7.2s
2025-10-12 00:32:24,900 - INFO - _models.training_function_executor - Epoch 011 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:32:31,619 - INFO - _models.training_function_executor - Epoch 012 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.7s
2025-10-12 00:32:38,342 - INFO - _models.training_function_executor - Epoch 013 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.7s
2025-10-12 00:32:45,088 - INFO - _models.training_function_executor - Epoch 014 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.7s
2025-10-12 00:32:51,848 - INFO - _models.training_function_executor - Epoch 015 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.8s
2025-10-12 00:32:58,573 - INFO - _models.training_function_executor - Epoch 016 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.7s
2025-10-12 00:32:59,691 - INFO - _models.training_function_executor - Model: 2,335 parameters, 10.0KB storage
2025-10-12 00:32:59,691 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.6363956517206442, 0.522809234388775, 0.4695882807307449, 0.4232839808978941, 0.399078237729282, 0.38116694700219306, 0.3518600752228388, 0.3285308700350873, 0.32059311492014564, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [0.49833634245645747, 0.4563239818269556, 0.39507561891854226, 0.5184215715298286, 0.4806122054586877, 0.46818362133694696, 0.3288993332404774, 0.31536966716492926, 0.3941259839734831, 0.3889571547091424, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5847042352117606, 0.5746412320616031, 0.6491074553727686, 0.5379768988449423, 0.6246937346867344, 0.6030801540077004, 0.7383619180959048, 0.7150857542877144, 0.684109205460273, 0.638694434721736, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'best_epoch': 7, 'total_params': 2335, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004218439443446737, 'batch_size': 16, 'epochs': 16, 'weight_decay': 8.69533371840594e-05, 'base_channels': 11, 'kernel_size': 14, 'dropout': 0.043609068363624985, 'amp': True, 'grad_clip_norm': 0.6244304007129833, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.879871549132549, 'label_smoothing': 0.18036567670088255, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}, 'model_parameter_count': 2335, 'model_storage_size_kb': 10.033203125, 'model_size_validation': 'PASS'}
2025-10-12 00:32:59,691 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-12 00:32:59,691 - INFO - _models.training_function_executor - Model: 2,335 parameters, 10.0KB (PASS 256KB limit)
2025-10-12 00:32:59,691 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 116.665s
2025-10-12 00:32:59,801 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-12 00:32:59,801 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-12 00:32:59,801 - INFO - bo.run_bo - Recorded observation #34: hparams={'lr': 0.004218439443446737, 'batch_size': np.int64(16), 'epochs': np.int64(16), 'weight_decay': 8.69533371840594e-05, 'base_channels': np.int64(11), 'kernel_size': np.int64(14), 'dropout': 0.043609068363624985, 'amp': np.True_, 'grad_clip_norm': 0.6244304007129833, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.879871549132549, 'label_smoothing': 0.18036567670088255, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(8)}, value=0.2325
2025-10-12 00:32:59,801 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 34: {'lr': 0.004218439443446737, 'batch_size': np.int64(16), 'epochs': np.int64(16), 'weight_decay': 8.69533371840594e-05, 'base_channels': np.int64(11), 'kernel_size': np.int64(14), 'dropout': 0.043609068363624985, 'amp': np.True_, 'grad_clip_norm': 0.6244304007129833, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.879871549132549, 'label_smoothing': 0.18036567670088255, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(8)} -> 0.2325
2025-10-12 00:32:59,802 - INFO - bo.run_bo - üîçBO Trial 35: Using RF surrogate + Expected Improvement
2025-10-12 00:32:59,802 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:32:59,802 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:32:59,802 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:32:59,802 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004059256163827505, 'batch_size': 32, 'epochs': 24, 'weight_decay': 2.790710621045929e-05, 'base_channels': 12, 'kernel_size': 10, 'dropout': 0.03350111729830639, 'amp': False, 'grad_clip_norm': 0.44079175362027767, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7249540962676555, 'label_smoothing': 0.14349036592739597, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:32:59,803 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004059256163827505, 'batch_size': 32, 'epochs': 24, 'weight_decay': 2.790710621045929e-05, 'base_channels': 12, 'kernel_size': 10, 'dropout': 0.03350111729830639, 'amp': False, 'grad_clip_norm': 0.44079175362027767, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7249540962676555, 'label_smoothing': 0.14349036592739597, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:33:08,464 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.7419 | val_loss=0.5474 | val_acc=0.5820 | time=8.7s
2025-10-12 00:33:14,270 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5108 | val_loss=0.5013 | val_acc=0.6069 | time=5.8s
2025-10-12 00:33:20,067 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4702 | val_loss=0.4438 | val_acc=0.6121 | time=5.8s
2025-10-12 00:33:25,865 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4491 | val_loss=0.4454 | val_acc=0.6176 | time=5.8s
2025-10-12 00:33:31,658 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4090 | val_loss=0.4162 | val_acc=0.6218 | time=5.8s
2025-10-12 00:33:37,458 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3728 | val_loss=0.3490 | val_acc=0.6784 | time=5.8s
2025-10-12 00:33:43,246 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3571 | val_loss=0.3588 | val_acc=0.6871 | time=5.8s
2025-10-12 00:33:49,036 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3312 | val_loss=0.3857 | val_acc=0.6525 | time=5.8s
2025-10-12 00:33:54,831 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3303 | val_loss=0.3407 | val_acc=0.6779 | time=5.8s
2025-10-12 00:34:00,620 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3193 | val_loss=0.3286 | val_acc=0.7033 | time=5.8s
2025-10-12 00:34:06,400 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3097 | val_loss=0.2881 | val_acc=0.7260 | time=5.8s
2025-10-12 00:34:12,192 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.2991 | val_loss=0.3398 | val_acc=0.6969 | time=5.8s
2025-10-12 00:34:17,991 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.2921 | val_loss=0.3129 | val_acc=0.7062 | time=5.8s
2025-10-12 00:34:23,790 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.2859 | val_loss=0.2984 | val_acc=0.7244 | time=5.8s
2025-10-12 00:34:29,593 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.2780 | val_loss=0.2866 | val_acc=0.7378 | time=5.8s
2025-10-12 00:34:35,388 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.2724 | val_loss=0.2687 | val_acc=0.7355 | time=5.8s
2025-10-12 00:34:41,191 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.2676 | val_loss=0.2901 | val_acc=0.7210 | time=5.8s
2025-10-12 00:34:46,993 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.2597 | val_loss=0.2581 | val_acc=0.7497 | time=5.8s
2025-10-12 00:34:52,780 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.2544 | val_loss=0.2625 | val_acc=0.7496 | time=5.8s
2025-10-12 00:34:58,589 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.2512 | val_loss=0.2555 | val_acc=0.7507 | time=5.8s
2025-10-12 00:35:04,392 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.2440 | val_loss=0.2596 | val_acc=0.7504 | time=5.8s
2025-10-12 00:35:10,197 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.2409 | val_loss=0.2535 | val_acc=0.7533 | time=5.8s
2025-10-12 00:35:16,000 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.2390 | val_loss=0.2536 | val_acc=0.7560 | time=5.8s
2025-10-12 00:35:21,799 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.2369 | val_loss=0.2538 | val_acc=0.7552 | time=5.8s
2025-10-12 00:35:21,802 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 00:35:22,919 - INFO - _models.training_function_executor - Model: 2,303 parameters, 4.9KB storage
2025-10-12 00:35:22,919 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.741856263078452, 0.5107943784051879, 0.4702311131902472, 0.44909181318097885, 0.40895188925690046, 0.3728200510363215, 0.3570684064583732, 0.33115644924514687, 0.33032486003291117, 0.31933929608513045, 0.30974016224925044, 0.29907993836741587, 0.2921093873799556, 0.28585864218737883, 0.27801069294013203, 0.2723840448752494, 0.26755722193992415, 0.2596575515651052, 0.25435911667480426, 0.25121969521629633, 0.24403854507752196, 0.24092087171518195, 0.2390235703493266, 0.23691607340179682], 'val_losses': [0.5473537189500958, 0.5013342296610998, 0.44379589419458165, 0.4453784218630311, 0.4162239145549982, 0.34903053914368487, 0.35875931132439126, 0.385746771937975, 0.34074001767615364, 0.3286363378416893, 0.28805213190573553, 0.3397586980324717, 0.3129086409326039, 0.2984198474600994, 0.28659722741755694, 0.2686669617766442, 0.29013476971999935, 0.25808124647439357, 0.26247710656561996, 0.2554581718592171, 0.2595585183547445, 0.25348459121734734, 0.25363668868078865, 0.25382413860805875], 'val_acc': [0.581991599579979, 0.6069303465173259, 0.6120931046552328, 0.6176058802940148, 0.6218060903045153, 0.6784214210710535, 0.6870843542177109, 0.6525201260063003, 0.677896394819741, 0.7032726636331816, 0.7260238011900595, 0.6968848442422121, 0.7062478123906195, 0.7244487224361218, 0.7378368918445922, 0.7354742737136857, 0.7210360518025901, 0.7497374868743437, 0.7495624781239062, 0.7507000350017501, 0.750350017500875, 0.7533251662583129, 0.7560378018900945, 0.7551627581379069], 'best_epoch': 23, 'total_params': 2303, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004059256163827505, 'batch_size': 32, 'epochs': 24, 'weight_decay': 2.790710621045929e-05, 'base_channels': 12, 'kernel_size': 10, 'dropout': 0.03350111729830639, 'amp': False, 'grad_clip_norm': 0.44079175362027767, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7249540962676555, 'label_smoothing': 0.14349036592739597, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}, 'model_parameter_count': 2303, 'model_storage_size_kb': 4.9478515625, 'model_size_validation': 'PASS'}
2025-10-12 00:35:22,919 - INFO - _models.training_function_executor - BO Objective: base=0.7552, size_penalty=0.0000, final=0.7552
2025-10-12 00:35:22,919 - INFO - _models.training_function_executor - Model: 2,303 parameters, 4.9KB (PASS 256KB limit)
2025-10-12 00:35:22,919 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 143.117s
2025-10-12 00:35:23,032 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7552
2025-10-12 00:35:23,033 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-12 00:35:23,033 - INFO - bo.run_bo - Recorded observation #35: hparams={'lr': 0.004059256163827505, 'batch_size': np.int64(32), 'epochs': np.int64(24), 'weight_decay': 2.790710621045929e-05, 'base_channels': np.int64(12), 'kernel_size': np.int64(10), 'dropout': 0.03350111729830639, 'amp': np.False_, 'grad_clip_norm': 0.44079175362027767, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7249540962676555, 'label_smoothing': 0.14349036592739597, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}, value=0.7552
2025-10-12 00:35:23,033 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 35: {'lr': 0.004059256163827505, 'batch_size': np.int64(32), 'epochs': np.int64(24), 'weight_decay': 2.790710621045929e-05, 'base_channels': np.int64(12), 'kernel_size': np.int64(10), 'dropout': 0.03350111729830639, 'amp': np.False_, 'grad_clip_norm': 0.44079175362027767, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.7249540962676555, 'label_smoothing': 0.14349036592739597, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)} -> 0.7552
2025-10-12 00:35:23,033 - INFO - bo.run_bo - üîçBO Trial 36: Using RF surrogate + Expected Improvement
2025-10-12 00:35:23,033 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:35:23,033 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:35:23,033 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:35:23,033 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0028695212619881216, 'batch_size': 32, 'epochs': 26, 'weight_decay': 6.350866270543147e-05, 'base_channels': 15, 'kernel_size': 11, 'dropout': 0.03457966500983455, 'amp': True, 'grad_clip_norm': 0.6604926434044506, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.908128162016011, 'label_smoothing': 0.15948712452462477, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-12 00:35:23,035 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0028695212619881216, 'batch_size': 32, 'epochs': 26, 'weight_decay': 6.350866270543147e-05, 'base_channels': 15, 'kernel_size': 11, 'dropout': 0.03457966500983455, 'amp': True, 'grad_clip_norm': 0.6604926434044506, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.908128162016011, 'label_smoothing': 0.15948712452462477, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-12 00:35:32,283 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.7505 | val_loss=0.5719 | val_acc=0.5672 | time=9.2s
2025-10-12 00:35:38,667 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5298 | val_loss=0.4998 | val_acc=0.5933 | time=6.4s
2025-10-12 00:35:45,042 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4691 | val_loss=0.4599 | val_acc=0.5931 | time=6.4s
2025-10-12 00:35:51,419 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4329 | val_loss=0.4151 | val_acc=0.6115 | time=6.4s
2025-10-12 00:35:57,799 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4046 | val_loss=0.3613 | val_acc=0.6803 | time=6.4s
2025-10-12 00:36:04,170 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3592 | val_loss=0.3248 | val_acc=0.7146 | time=6.4s
2025-10-12 00:36:10,547 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3410 | val_loss=0.3189 | val_acc=0.6829 | time=6.4s
2025-10-12 00:36:16,923 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3310 | val_loss=0.3379 | val_acc=0.6835 | time=6.4s
2025-10-12 00:36:23,305 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3157 | val_loss=0.3111 | val_acc=0.7188 | time=6.4s
2025-10-12 00:36:29,694 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3049 | val_loss=0.2706 | val_acc=0.7332 | time=6.4s
2025-10-12 00:36:36,069 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.2979 | val_loss=0.2757 | val_acc=0.7388 | time=6.4s
2025-10-12 00:36:42,455 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.2863 | val_loss=0.2713 | val_acc=0.7293 | time=6.4s
2025-10-12 00:36:48,835 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.2878 | val_loss=0.2750 | val_acc=0.7206 | time=6.4s
2025-10-12 00:36:55,222 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.2784 | val_loss=0.2978 | val_acc=0.7135 | time=6.4s
2025-10-12 00:37:01,611 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.2723 | val_loss=0.2713 | val_acc=0.7370 | time=6.4s
2025-10-12 00:37:07,990 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.2672 | val_loss=0.3346 | val_acc=0.7391 | time=6.4s
2025-10-12 00:37:14,360 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.2673 | val_loss=0.2578 | val_acc=0.7467 | time=6.4s
2025-10-12 00:37:20,724 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.2536 | val_loss=0.2589 | val_acc=0.7366 | time=6.4s
2025-10-12 00:37:27,096 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.2495 | val_loss=0.3147 | val_acc=0.7452 | time=6.4s
2025-10-12 00:37:33,467 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.2484 | val_loss=0.2898 | val_acc=0.7399 | time=6.4s
2025-10-12 00:37:39,849 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.2575 | val_loss=0.2406 | val_acc=0.7544 | time=6.4s
2025-10-12 00:37:46,227 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.2365 | val_loss=0.2417 | val_acc=0.7589 | time=6.4s
2025-10-12 00:37:52,605 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.2321 | val_loss=0.2498 | val_acc=0.7585 | time=6.4s
2025-10-12 00:37:58,990 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.2310 | val_loss=0.2364 | val_acc=0.7582 | time=6.4s
2025-10-12 00:38:05,372 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.2276 | val_loss=0.2435 | val_acc=0.7595 | time=6.4s
2025-10-12 00:38:11,756 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.2262 | val_loss=0.2462 | val_acc=0.7591 | time=6.4s
2025-10-12 00:38:11,762 - INFO - _models.training_function_executor - Quantization failed (cannot assign 'torch.fx.graph.Graph' as child module 'graph' (torch.nn.Module or None expected)); returning FP32 CPU model.
2025-10-12 00:38:12,902 - INFO - _models.training_function_executor - Model: 3,071 parameters, 3.3KB storage
2025-10-12 00:38:12,902 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7505289062158973, 0.5297584299485611, 0.4690950400996992, 0.4329291000555578, 0.40457510284980414, 0.35916898268724007, 0.3409969593372856, 0.3309531117430344, 0.31568575869434945, 0.30490118833982166, 0.2979155980087061, 0.2863460367609355, 0.28781044321295013, 0.2783724606829644, 0.27234790029957046, 0.2672268547889359, 0.2672930117031759, 0.2536350275677263, 0.2495452872861341, 0.2484095943733226, 0.2574794040047847, 0.23646750860307247, 0.23212485964050902, 0.23102185448685086, 0.227628682340522, 0.22618722108546632], 'val_losses': [0.5719308193835466, 0.4997829870222001, 0.4598668169792138, 0.41513068582758555, 0.3612565786978386, 0.3247900650987412, 0.3189062317156925, 0.3378645582696912, 0.31113504327042807, 0.2705548607104317, 0.2756920433993446, 0.27126370366225694, 0.27504465624939795, 0.29784952133227993, 0.2712630387499679, 0.33457088068793606, 0.25777096030765406, 0.25892803441296075, 0.31473554758219746, 0.28981439599652864, 0.240587397858334, 0.24171408311614778, 0.2497874591707684, 0.23639327345946648, 0.24353795237422987, 0.2461558865206368], 'val_acc': [0.5672033601680084, 0.5932796639831992, 0.5931046552327617, 0.6114805740287015, 0.6802590129506475, 0.7145607280364018, 0.6828841442072103, 0.6834966748337417, 0.7187609380469023, 0.7331991599579979, 0.7387994399719986, 0.7293489674483724, 0.7205985299264963, 0.7135106755337767, 0.7370493524676234, 0.7390619530976549, 0.7466748337416871, 0.7366118305915296, 0.7451872593629681, 0.7399369968498425, 0.754375218760938, 0.7589254462723136, 0.7584879243962198, 0.7582254112705635, 0.759537976898845, 0.7591004550227511], 'best_epoch': 25, 'total_params': 3071, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0028695212619881216, 'batch_size': 32, 'epochs': 26, 'weight_decay': 6.350866270543147e-05, 'base_channels': 15, 'kernel_size': 11, 'dropout': 0.03457966500983455, 'amp': True, 'grad_clip_norm': 0.6604926434044506, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.908128162016011, 'label_smoothing': 0.15948712452462477, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}, 'model_parameter_count': 3071, 'model_storage_size_kb': 3.2989257812500004, 'model_size_validation': 'PASS'}
2025-10-12 00:38:12,902 - INFO - _models.training_function_executor - BO Objective: base=0.7591, size_penalty=0.0000, final=0.7591
2025-10-12 00:38:12,902 - INFO - _models.training_function_executor - Model: 3,071 parameters, 3.3KB (PASS 256KB limit)
2025-10-12 00:38:12,902 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 169.869s
2025-10-12 00:38:13,014 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7591
2025-10-12 00:38:13,015 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.109s
2025-10-12 00:38:13,015 - INFO - bo.run_bo - Recorded observation #36: hparams={'lr': 0.0028695212619881216, 'batch_size': np.int64(32), 'epochs': np.int64(26), 'weight_decay': 6.350866270543147e-05, 'base_channels': np.int64(15), 'kernel_size': np.int64(11), 'dropout': 0.03457966500983455, 'amp': np.True_, 'grad_clip_norm': 0.6604926434044506, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.908128162016011, 'label_smoothing': 0.15948712452462477, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)}, value=0.7591
2025-10-12 00:38:13,015 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 36: {'lr': 0.0028695212619881216, 'batch_size': np.int64(32), 'epochs': np.int64(26), 'weight_decay': 6.350866270543147e-05, 'base_channels': np.int64(15), 'kernel_size': np.int64(11), 'dropout': 0.03457966500983455, 'amp': np.True_, 'grad_clip_norm': 0.6604926434044506, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.908128162016011, 'label_smoothing': 0.15948712452462477, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)} -> 0.7591
2025-10-12 00:38:13,015 - INFO - bo.run_bo - üîçBO Trial 37: Using RF surrogate + Expected Improvement
2025-10-12 00:38:13,015 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:38:13,015 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:38:13,015 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:38:13,015 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004768491477271673, 'batch_size': 16, 'epochs': 17, 'weight_decay': 0.0004950458218850326, 'base_channels': 14, 'kernel_size': 10, 'dropout': 0.031302721726208564, 'amp': True, 'grad_clip_norm': 0.9021512517588499, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6512869555964764, 'label_smoothing': 0.18124996633813786, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}
2025-10-12 00:38:13,017 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004768491477271673, 'batch_size': 16, 'epochs': 17, 'weight_decay': 0.0004950458218850326, 'base_channels': 14, 'kernel_size': 10, 'dropout': 0.031302721726208564, 'amp': True, 'grad_clip_norm': 0.9021512517588499, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6512869555964764, 'label_smoothing': 0.18124996633813786, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}
2025-10-12 00:38:23,191 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8696 | val_loss=0.7051 | val_acc=0.5699 | time=10.2s
2025-10-12 00:38:30,515 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.6767 | val_loss=0.6083 | val_acc=0.6067 | time=7.3s
2025-10-12 00:38:37,843 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5807 | val_loss=0.4733 | val_acc=0.6946 | time=7.3s
2025-10-12 00:38:45,158 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5271 | val_loss=0.7078 | val_acc=0.6363 | time=7.3s
2025-10-12 00:38:52,460 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5032 | val_loss=0.4406 | val_acc=0.7286 | time=7.3s
2025-10-12 00:38:59,782 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4843 | val_loss=0.4571 | val_acc=0.7010 | time=7.3s
2025-10-12 00:39:07,079 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4647 | val_loss=0.4212 | val_acc=0.7234 | time=7.3s
2025-10-12 00:39:14,406 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4500 | val_loss=0.4649 | val_acc=0.7156 | time=7.3s
2025-10-12 00:39:21,724 - INFO - _models.training_function_executor - Epoch 009 | train_loss=nan | val_loss=0.4177 | val_acc=0.7409 | time=7.3s
2025-10-12 00:39:29,025 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4202 | val_loss=0.4117 | val_acc=0.7371 | time=7.3s
2025-10-12 00:39:36,341 - INFO - _models.training_function_executor - Epoch 011 | train_loss=nan | val_loss=0.4461 | val_acc=0.7357 | time=7.3s
2025-10-12 00:39:43,636 - INFO - _models.training_function_executor - Epoch 012 | train_loss=nan | val_loss=0.4083 | val_acc=0.7517 | time=7.3s
2025-10-12 00:39:50,941 - INFO - _models.training_function_executor - Epoch 013 | train_loss=nan | val_loss=0.3982 | val_acc=0.7372 | time=7.3s
2025-10-12 00:39:58,287 - INFO - _models.training_function_executor - Epoch 014 | train_loss=nan | val_loss=0.3764 | val_acc=0.7539 | time=7.3s
2025-10-12 00:40:05,639 - INFO - _models.training_function_executor - Epoch 015 | train_loss=nan | val_loss=0.3737 | val_acc=0.7560 | time=7.4s
2025-10-12 00:40:12,962 - INFO - _models.training_function_executor - Epoch 016 | train_loss=nan | val_loss=0.3723 | val_acc=0.7624 | time=7.3s
2025-10-12 00:40:20,291 - INFO - _models.training_function_executor - Epoch 017 | train_loss=nan | val_loss=0.3756 | val_acc=0.7618 | time=7.3s
2025-10-12 00:40:20,294 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 00:40:21,402 - INFO - _models.training_function_executor - Model: 2,803 parameters, 6.0KB storage
2025-10-12 00:40:21,402 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8696044929948853, 0.6766926432285937, 0.5806841034472177, 0.5270982543446612, 0.5031657875781194, 0.4843155895553772, 0.46469427409979863, 0.449980442014177, nan, 0.42023615373998074, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [0.7050643922148885, 0.6083246029548711, 0.47326793791530847, 0.7078329918684659, 0.4405529286686357, 0.45712800340635795, 0.42117203758521515, 0.4649059456597258, 0.4177182930853817, 0.41169163903573175, 0.44607856962439063, 0.4083016109372769, 0.39816319585054905, 0.37644711201945386, 0.37372194591102065, 0.3723452693828336, 0.37557546002985714], 'val_acc': [0.56991599579979, 0.6066678333916696, 0.6946097304865243, 0.6363318165908295, 0.7285614280714036, 0.7009975498774939, 0.7233986699334967, 0.7156107805390269, 0.7408995449772489, 0.7371368568428421, 0.735736786839342, 0.7516625831291565, 0.7372243612180609, 0.7538501925096255, 0.7560378018900945, 0.7624256212810641, 0.7618130906545327], 'best_epoch': 16, 'total_params': 2803, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004768491477271673, 'batch_size': 16, 'epochs': 17, 'weight_decay': 0.0004950458218850326, 'base_channels': 14, 'kernel_size': 10, 'dropout': 0.031302721726208564, 'amp': True, 'grad_clip_norm': 0.9021512517588499, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6512869555964764, 'label_smoothing': 0.18124996633813786, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}, 'model_parameter_count': 2803, 'model_storage_size_kb': 6.0220703125, 'model_size_validation': 'PASS'}
2025-10-12 00:40:21,402 - INFO - _models.training_function_executor - BO Objective: base=0.7618, size_penalty=0.0000, final=0.7618
2025-10-12 00:40:21,402 - INFO - _models.training_function_executor - Model: 2,803 parameters, 6.0KB (PASS 256KB limit)
2025-10-12 00:40:21,402 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 128.387s
2025-10-12 00:40:21,513 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7618
2025-10-12 00:40:21,513 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.109s
2025-10-12 00:40:21,513 - INFO - bo.run_bo - Recorded observation #37: hparams={'lr': 0.004768491477271673, 'batch_size': np.int64(16), 'epochs': np.int64(17), 'weight_decay': 0.0004950458218850326, 'base_channels': np.int64(14), 'kernel_size': np.int64(10), 'dropout': 0.031302721726208564, 'amp': np.True_, 'grad_clip_norm': 0.9021512517588499, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6512869555964764, 'label_smoothing': 0.18124996633813786, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(5)}, value=0.7618
2025-10-12 00:40:21,513 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 37: {'lr': 0.004768491477271673, 'batch_size': np.int64(16), 'epochs': np.int64(17), 'weight_decay': 0.0004950458218850326, 'base_channels': np.int64(14), 'kernel_size': np.int64(10), 'dropout': 0.031302721726208564, 'amp': np.True_, 'grad_clip_norm': 0.9021512517588499, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6512869555964764, 'label_smoothing': 0.18124996633813786, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(5)} -> 0.7618
2025-10-12 00:40:21,513 - INFO - bo.run_bo - üîçBO Trial 38: Using RF surrogate + Expected Improvement
2025-10-12 00:40:21,513 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:40:21,513 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:40:21,513 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:40:21,513 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003909924237406688, 'batch_size': 16, 'epochs': 41, 'weight_decay': 1.4872337209221627e-05, 'base_channels': 16, 'kernel_size': 10, 'dropout': 0.009781176842976292, 'amp': False, 'grad_clip_norm': 0.2753273495460478, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.382692692661525, 'label_smoothing': 0.18947983872452515, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:40:21,515 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003909924237406688, 'batch_size': 16, 'epochs': 41, 'weight_decay': 1.4872337209221627e-05, 'base_channels': 16, 'kernel_size': 10, 'dropout': 0.009781176842976292, 'amp': False, 'grad_clip_norm': 0.2753273495460478, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.382692692661525, 'label_smoothing': 0.18947983872452515, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:40:32,051 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8100 | val_loss=0.6097 | val_acc=0.5613 | time=10.5s
2025-10-12 00:40:39,726 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5739 | val_loss=0.6970 | val_acc=0.5287 | time=7.7s
2025-10-12 00:40:47,410 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5401 | val_loss=0.5233 | val_acc=0.6129 | time=7.7s
2025-10-12 00:40:55,088 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5143 | val_loss=0.4637 | val_acc=0.6510 | time=7.7s
2025-10-12 00:41:02,753 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4564 | val_loss=0.4717 | val_acc=0.6516 | time=7.7s
2025-10-12 00:41:10,431 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3988 | val_loss=0.3577 | val_acc=0.6987 | time=7.7s
2025-10-12 00:41:18,119 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3833 | val_loss=0.3284 | val_acc=0.7294 | time=7.7s
2025-10-12 00:41:25,818 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3708 | val_loss=0.3743 | val_acc=0.7279 | time=7.7s
2025-10-12 00:41:33,485 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3717 | val_loss=0.3609 | val_acc=0.7124 | time=7.7s
2025-10-12 00:41:41,169 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3765 | val_loss=0.3325 | val_acc=0.7363 | time=7.7s
2025-10-12 00:41:48,842 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3605 | val_loss=0.4311 | val_acc=0.6885 | time=7.7s
2025-10-12 00:41:56,527 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3593 | val_loss=0.3113 | val_acc=0.7348 | time=7.7s
2025-10-12 00:42:04,215 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3627 | val_loss=0.3084 | val_acc=0.7406 | time=7.7s
2025-10-12 00:42:11,895 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3490 | val_loss=0.3306 | val_acc=0.7276 | time=7.7s
2025-10-12 00:42:19,581 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3465 | val_loss=0.4355 | val_acc=0.6824 | time=7.7s
2025-10-12 00:42:27,268 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3484 | val_loss=0.3444 | val_acc=0.7126 | time=7.7s
2025-10-12 00:42:34,960 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3411 | val_loss=0.3155 | val_acc=0.7502 | time=7.7s
2025-10-12 00:42:42,629 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3413 | val_loss=0.3211 | val_acc=0.7412 | time=7.7s
2025-10-12 00:42:50,297 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3323 | val_loss=0.3062 | val_acc=0.7502 | time=7.7s
2025-10-12 00:42:57,978 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3292 | val_loss=0.2989 | val_acc=0.7528 | time=7.7s
2025-10-12 00:43:05,667 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3323 | val_loss=0.3847 | val_acc=0.7212 | time=7.7s
2025-10-12 00:43:13,343 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3230 | val_loss=0.3002 | val_acc=0.7522 | time=7.7s
2025-10-12 00:43:21,049 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3160 | val_loss=0.2913 | val_acc=0.7481 | time=7.7s
2025-10-12 00:43:28,744 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3159 | val_loss=0.3451 | val_acc=0.7345 | time=7.7s
2025-10-12 00:43:36,423 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3118 | val_loss=0.4204 | val_acc=0.6940 | time=7.7s
2025-10-12 00:43:44,091 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.3110 | val_loss=0.3263 | val_acc=0.7477 | time=7.7s
2025-10-12 00:43:51,771 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.3049 | val_loss=0.3057 | val_acc=0.7629 | time=7.7s
2025-10-12 00:43:59,459 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.3004 | val_loss=0.3523 | val_acc=0.7347 | time=7.7s
2025-10-12 00:44:07,152 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.2918 | val_loss=0.3178 | val_acc=0.7546 | time=7.7s
2025-10-12 00:44:14,819 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.2951 | val_loss=0.3336 | val_acc=0.7635 | time=7.7s
2025-10-12 00:44:22,501 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.2885 | val_loss=0.3202 | val_acc=0.7564 | time=7.7s
2025-10-12 00:44:30,191 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.2792 | val_loss=0.3394 | val_acc=0.7645 | time=7.7s
2025-10-12 00:44:37,886 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.2715 | val_loss=0.3032 | val_acc=0.7696 | time=7.7s
2025-10-12 00:44:45,562 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.2646 | val_loss=0.3047 | val_acc=0.7653 | time=7.7s
2025-10-12 00:44:53,253 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.2630 | val_loss=0.3114 | val_acc=0.7645 | time=7.7s
2025-10-12 00:45:00,958 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.2586 | val_loss=0.3210 | val_acc=0.7681 | time=7.7s
2025-10-12 00:45:08,659 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.2550 | val_loss=0.3111 | val_acc=0.7679 | time=7.7s
2025-10-12 00:45:16,349 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.2541 | val_loss=0.3015 | val_acc=0.7665 | time=7.7s
2025-10-12 00:45:24,043 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.2505 | val_loss=0.3043 | val_acc=0.7677 | time=7.7s
2025-10-12 00:45:31,750 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.2494 | val_loss=0.3055 | val_acc=0.7696 | time=7.7s
2025-10-12 00:45:39,468 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.2474 | val_loss=0.3065 | val_acc=0.7680 | time=7.7s
2025-10-12 00:45:40,608 - INFO - _models.training_function_executor - Model: 3,351 parameters, 14.4KB storage
2025-10-12 00:45:40,608 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8100304423636142, 0.5739462310914439, 0.5400519503302035, 0.5143237056319514, 0.45641167007587485, 0.3988222226664805, 0.38330206723272864, 0.37075806019119045, 0.37173367535130186, 0.3764525309914386, 0.3605437359525204, 0.3592826395765296, 0.3627372956595139, 0.3489564798660198, 0.34648371613031925, 0.3483569830679522, 0.3411261178761731, 0.34130303274825774, 0.33229974037936655, 0.3291967697532852, 0.3322915779840688, 0.32304576097077786, 0.3160084643084028, 0.31590429308805007, 0.31184520292212214, 0.31096679223443835, 0.3048929230635676, 0.3004348699706269, 0.2917990158639632, 0.295104316972968, 0.2884508003110746, 0.2792301153076965, 0.27146408716813225, 0.2645636221421977, 0.2629702089769693, 0.25859428967043135, 0.2549676508771495, 0.25407476667516876, 0.250474089772255, 0.24944791348965947, 0.24735258831090035], 'val_losses': [0.6096868575036108, 0.69702063548815, 0.5233183366643799, 0.4636667033800712, 0.47174721601959707, 0.3576648832149022, 0.32839813898284953, 0.3742643288512538, 0.3609013075907747, 0.3325266414797389, 0.431122502945103, 0.31131798865703436, 0.3083718093020933, 0.33063475321327057, 0.43554629013723845, 0.34442469671472803, 0.3154748176100788, 0.321133614839478, 0.3061826699055158, 0.2988693366830166, 0.38467689090883816, 0.30023833776895814, 0.2913184172519437, 0.3450826082873594, 0.42042550786391836, 0.3262774107131091, 0.3057153379114775, 0.35230817833876277, 0.317760270484886, 0.3336179960779585, 0.32017758630893445, 0.33939487805420704, 0.30324246013810585, 0.30472145825103447, 0.31138020688212004, 0.3209909036547154, 0.3110951518418489, 0.3015251661201457, 0.30427820215692053, 0.3054549096087059, 0.3064775189997016], 'val_acc': [0.5613405670283514, 0.5287014350717536, 0.6128806440322017, 0.6510325516275813, 0.6515575778788939, 0.6987224361218061, 0.7294364718235912, 0.7279488974448722, 0.7123731186559328, 0.7362618130906545, 0.688484424221211, 0.7347742387119356, 0.7406370318515926, 0.7275988799439972, 0.6823591179558978, 0.7126356317815891, 0.7501750087504375, 0.7411620581029051, 0.7501750087504375, 0.7528001400070004, 0.7212110605530276, 0.752187609380469, 0.7480749037451873, 0.7345117255862793, 0.693997199859993, 0.7477248862443122, 0.7628631431571579, 0.7346867343367168, 0.7545502275113756, 0.7634756737836892, 0.7563878193909696, 0.7645257262863143, 0.7696009800490025, 0.7653132656632832, 0.7645257262863143, 0.7681134056702835, 0.7678508925446272, 0.7665383269163458, 0.7676758837941897, 0.7696009800490025, 0.7680259012950648], 'best_epoch': 33, 'total_params': 3351, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003909924237406688, 'batch_size': 16, 'epochs': 41, 'weight_decay': 1.4872337209221627e-05, 'base_channels': 16, 'kernel_size': 10, 'dropout': 0.009781176842976292, 'amp': False, 'grad_clip_norm': 0.2753273495460478, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.382692692661525, 'label_smoothing': 0.18947983872452515, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}, 'model_parameter_count': 3351, 'model_storage_size_kb': 14.398828125000001, 'model_size_validation': 'PASS'}
2025-10-12 00:45:40,608 - INFO - _models.training_function_executor - BO Objective: base=0.7680, size_penalty=0.0000, final=0.7680
2025-10-12 00:45:40,608 - INFO - _models.training_function_executor - Model: 3,351 parameters, 14.4KB (PASS 256KB limit)
2025-10-12 00:45:40,608 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 319.095s
2025-10-12 00:45:40,721 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7680
2025-10-12 00:45:40,721 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-12 00:45:40,721 - INFO - bo.run_bo - Recorded observation #38: hparams={'lr': 0.003909924237406688, 'batch_size': np.int64(16), 'epochs': np.int64(41), 'weight_decay': 1.4872337209221627e-05, 'base_channels': np.int64(16), 'kernel_size': np.int64(10), 'dropout': 0.009781176842976292, 'amp': np.False_, 'grad_clip_norm': 0.2753273495460478, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.382692692661525, 'label_smoothing': 0.18947983872452515, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}, value=0.7680
2025-10-12 00:45:40,721 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 38: {'lr': 0.003909924237406688, 'batch_size': np.int64(16), 'epochs': np.int64(41), 'weight_decay': 1.4872337209221627e-05, 'base_channels': np.int64(16), 'kernel_size': np.int64(10), 'dropout': 0.009781176842976292, 'amp': np.False_, 'grad_clip_norm': 0.2753273495460478, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.382692692661525, 'label_smoothing': 0.18947983872452515, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)} -> 0.7680
2025-10-12 00:45:40,722 - INFO - bo.run_bo - üîçBO Trial 39: Using RF surrogate + Expected Improvement
2025-10-12 00:45:40,722 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:45:40,722 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:45:40,722 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:45:40,722 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.002777939452942935, 'batch_size': 16, 'epochs': 21, 'weight_decay': 0.0007620741492848552, 'base_channels': 9, 'kernel_size': 4, 'dropout': 0.02999368700276323, 'amp': False, 'grad_clip_norm': 0.41251367617817014, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.831729908978953, 'label_smoothing': 0.16076340988859558, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 00:45:40,723 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.002777939452942935, 'batch_size': 16, 'epochs': 21, 'weight_decay': 0.0007620741492848552, 'base_channels': 9, 'kernel_size': 4, 'dropout': 0.02999368700276323, 'amp': False, 'grad_clip_norm': 0.41251367617817014, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.831729908978953, 'label_smoothing': 0.16076340988859558, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 00:45:49,316 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.7964 | val_loss=0.6746 | val_acc=0.4777 | time=8.6s
2025-10-12 00:45:55,065 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.6286 | val_loss=0.5966 | val_acc=0.5581 | time=5.7s
2025-10-12 00:46:00,800 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5637 | val_loss=0.5207 | val_acc=0.5858 | time=5.7s
2025-10-12 00:46:06,529 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5082 | val_loss=0.4963 | val_acc=0.6126 | time=5.7s
2025-10-12 00:46:12,266 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4421 | val_loss=0.3727 | val_acc=0.6738 | time=5.7s
2025-10-12 00:46:17,977 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3885 | val_loss=0.3661 | val_acc=0.6882 | time=5.7s
2025-10-12 00:46:23,663 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3656 | val_loss=0.3346 | val_acc=0.7086 | time=5.7s
2025-10-12 00:46:29,357 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3530 | val_loss=0.3431 | val_acc=0.6727 | time=5.7s
2025-10-12 00:46:35,062 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3450 | val_loss=0.3408 | val_acc=0.6954 | time=5.7s
2025-10-12 00:46:40,793 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3359 | val_loss=0.3120 | val_acc=0.7253 | time=5.7s
2025-10-12 00:46:46,497 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3311 | val_loss=0.2949 | val_acc=0.7174 | time=5.7s
2025-10-12 00:46:52,205 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3208 | val_loss=0.3554 | val_acc=0.6695 | time=5.7s
2025-10-12 00:46:57,935 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3160 | val_loss=0.2917 | val_acc=0.7200 | time=5.7s
2025-10-12 00:47:03,638 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3058 | val_loss=0.2795 | val_acc=0.7386 | time=5.7s
2025-10-12 00:47:09,343 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3016 | val_loss=0.3077 | val_acc=0.7244 | time=5.7s
2025-10-12 00:47:15,052 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3004 | val_loss=0.2922 | val_acc=0.7358 | time=5.7s
2025-10-12 00:47:20,704 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.2930 | val_loss=0.2878 | val_acc=0.7436 | time=5.7s
2025-10-12 00:47:26,400 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.2909 | val_loss=0.2800 | val_acc=0.7400 | time=5.7s
2025-10-12 00:47:32,103 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.2887 | val_loss=0.2812 | val_acc=0.7454 | time=5.7s
2025-10-12 00:47:37,809 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.2850 | val_loss=0.2870 | val_acc=0.7405 | time=5.7s
2025-10-12 00:47:43,538 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.2845 | val_loss=0.2836 | val_acc=0.7437 | time=5.7s
2025-10-12 00:47:44,649 - INFO - _models.training_function_executor - Model: 1,295 parameters, 5.6KB storage
2025-10-12 00:47:44,649 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7964054852421567, 0.6285860305655282, 0.5637247891099795, 0.5081803485370409, 0.44208959421996347, 0.38849379667033673, 0.36555880776518157, 0.3529561331804019, 0.3450327428161451, 0.33587858618338456, 0.3311130252240065, 0.32075345486214746, 0.31601062258995616, 0.30583224784665, 0.3015962293163583, 0.3004334786398963, 0.2929684696487605, 0.2908807965461654, 0.2887060702933239, 0.285022021465898, 0.28449173737806294], 'val_losses': [0.6746352152390913, 0.5965859772025288, 0.5207488935310524, 0.49632741456682034, 0.37271744209778057, 0.36610592216044874, 0.3346081826236698, 0.34314933605752623, 0.3408498009914285, 0.3119891522543414, 0.29487336122176866, 0.3553922083723795, 0.29172590067023996, 0.2795123174369752, 0.3077106023845556, 0.2922365497771677, 0.2877601404446405, 0.2800277915972096, 0.2811637603788526, 0.2869622971315484, 0.28362909761758953], 'val_acc': [0.47768638431921595, 0.5581029051452573, 0.5858417920896045, 0.6126181309065454, 0.6737836891844592, 0.6882219110955548, 0.7086104305215261, 0.6727336366818341, 0.6953972698634932, 0.7253237661883094, 0.7173608680434022, 0.6694959747987399, 0.719985999299965, 0.7386244312215611, 0.7244487224361218, 0.7358242912145607, 0.7436121806090304, 0.7400245012250612, 0.7453622681134057, 0.7405495274763738, 0.7436996849842492], 'best_epoch': 19, 'total_params': 1295, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.002777939452942935, 'batch_size': 16, 'epochs': 21, 'weight_decay': 0.0007620741492848552, 'base_channels': 9, 'kernel_size': 4, 'dropout': 0.02999368700276323, 'amp': False, 'grad_clip_norm': 0.41251367617817014, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.831729908978953, 'label_smoothing': 0.16076340988859558, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}, 'model_parameter_count': 1295, 'model_storage_size_kb': 5.564453125000001, 'model_size_validation': 'PASS'}
2025-10-12 00:47:44,650 - INFO - _models.training_function_executor - BO Objective: base=0.7437, size_penalty=0.0000, final=0.7437
2025-10-12 00:47:44,650 - INFO - _models.training_function_executor - Model: 1,295 parameters, 5.6KB (PASS 256KB limit)
2025-10-12 00:47:44,650 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 123.928s
2025-10-12 00:47:44,760 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7437
2025-10-12 00:47:44,760 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.109s
2025-10-12 00:47:44,760 - INFO - bo.run_bo - Recorded observation #39: hparams={'lr': 0.002777939452942935, 'batch_size': np.int64(16), 'epochs': np.int64(21), 'weight_decay': 0.0007620741492848552, 'base_channels': np.int64(9), 'kernel_size': np.int64(4), 'dropout': 0.02999368700276323, 'amp': np.False_, 'grad_clip_norm': 0.41251367617817014, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.831729908978953, 'label_smoothing': 0.16076340988859558, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)}, value=0.7437
2025-10-12 00:47:44,761 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 39: {'lr': 0.002777939452942935, 'batch_size': np.int64(16), 'epochs': np.int64(21), 'weight_decay': 0.0007620741492848552, 'base_channels': np.int64(9), 'kernel_size': np.int64(4), 'dropout': 0.02999368700276323, 'amp': np.False_, 'grad_clip_norm': 0.41251367617817014, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.831729908978953, 'label_smoothing': 0.16076340988859558, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)} -> 0.7437
2025-10-12 00:47:44,761 - INFO - bo.run_bo - üîçBO Trial 40: Using RF surrogate + Expected Improvement
2025-10-12 00:47:44,761 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:47:44,761 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:47:44,761 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:47:44,761 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004329593077279012, 'batch_size': 16, 'epochs': 40, 'weight_decay': 2.5002452326309026e-05, 'base_channels': 9, 'kernel_size': 4, 'dropout': 0.03579067701114764, 'amp': True, 'grad_clip_norm': 0.15357312523895864, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.91577572178398, 'label_smoothing': 0.14922065463334322, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 00:47:44,763 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004329593077279012, 'batch_size': 16, 'epochs': 40, 'weight_decay': 2.5002452326309026e-05, 'base_channels': 9, 'kernel_size': 4, 'dropout': 0.03579067701114764, 'amp': True, 'grad_clip_norm': 0.15357312523895864, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.91577572178398, 'label_smoothing': 0.14922065463334322, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 00:47:54,185 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8664 | val_loss=0.7620 | val_acc=0.5244 | time=9.4s
2025-10-12 00:48:00,758 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7255 | val_loss=0.7431 | val_acc=0.5402 | time=6.6s
2025-10-12 00:48:07,293 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6569 | val_loss=0.6270 | val_acc=0.5806 | time=6.5s
2025-10-12 00:48:13,811 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6201 | val_loss=0.5541 | val_acc=0.6343 | time=6.5s
2025-10-12 00:48:20,340 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5625 | val_loss=0.5508 | val_acc=0.6366 | time=6.5s
2025-10-12 00:48:26,909 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5080 | val_loss=0.4609 | val_acc=0.7042 | time=6.6s
2025-10-12 00:48:33,443 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4879 | val_loss=0.5061 | val_acc=0.6821 | time=6.5s
2025-10-12 00:48:40,004 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4685 | val_loss=0.5055 | val_acc=0.6445 | time=6.6s
2025-10-12 00:48:46,554 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4653 | val_loss=0.4666 | val_acc=0.6705 | time=6.5s
2025-10-12 00:48:53,064 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4570 | val_loss=0.6369 | val_acc=0.5818 | time=6.5s
2025-10-12 00:48:59,623 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4620 | val_loss=0.4294 | val_acc=0.7063 | time=6.6s
2025-10-12 00:49:06,131 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4574 | val_loss=0.4195 | val_acc=0.7043 | time=6.5s
2025-10-12 00:49:12,656 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.4526 | val_loss=0.4506 | val_acc=0.7062 | time=6.5s
2025-10-12 00:49:19,202 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.4415 | val_loss=0.5651 | val_acc=0.6808 | time=6.5s
2025-10-12 00:49:25,732 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.4473 | val_loss=0.4054 | val_acc=0.7258 | time=6.5s
2025-10-12 00:49:32,305 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.4413 | val_loss=0.4360 | val_acc=0.6949 | time=6.6s
2025-10-12 00:49:38,880 - INFO - _models.training_function_executor - Epoch 017 | train_loss=nan | val_loss=0.4252 | val_acc=0.7162 | time=6.6s
2025-10-12 00:49:45,438 - INFO - _models.training_function_executor - Epoch 018 | train_loss=nan | val_loss=0.4605 | val_acc=0.6929 | time=6.6s
2025-10-12 00:49:52,014 - INFO - _models.training_function_executor - Epoch 019 | train_loss=nan | val_loss=0.3945 | val_acc=0.7227 | time=6.6s
2025-10-12 00:49:58,602 - INFO - _models.training_function_executor - Epoch 020 | train_loss=nan | val_loss=0.5134 | val_acc=0.6885 | time=6.6s
2025-10-12 00:50:05,163 - INFO - _models.training_function_executor - Epoch 021 | train_loss=nan | val_loss=0.3806 | val_acc=0.7363 | time=6.6s
2025-10-12 00:50:11,709 - INFO - _models.training_function_executor - Epoch 022 | train_loss=nan | val_loss=0.4304 | val_acc=0.7223 | time=6.5s
2025-10-12 00:50:18,241 - INFO - _models.training_function_executor - Epoch 023 | train_loss=nan | val_loss=0.4184 | val_acc=0.7353 | time=6.5s
2025-10-12 00:50:24,792 - INFO - _models.training_function_executor - Epoch 024 | train_loss=nan | val_loss=0.4068 | val_acc=0.7297 | time=6.5s
2025-10-12 00:50:31,309 - INFO - _models.training_function_executor - Epoch 025 | train_loss=nan | val_loss=0.4068 | val_acc=0.7243 | time=6.5s
2025-10-12 00:50:37,848 - INFO - _models.training_function_executor - Epoch 026 | train_loss=nan | val_loss=0.9368 | val_acc=0.6843 | time=6.5s
2025-10-12 00:50:44,380 - INFO - _models.training_function_executor - Epoch 027 | train_loss=nan | val_loss=0.9329 | val_acc=0.6846 | time=6.5s
2025-10-12 00:50:50,910 - INFO - _models.training_function_executor - Epoch 028 | train_loss=nan | val_loss=0.9290 | val_acc=0.6852 | time=6.5s
2025-10-12 00:50:57,322 - INFO - _models.training_function_executor - Epoch 029 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.4s
2025-10-12 00:51:03,413 - INFO - _models.training_function_executor - Epoch 030 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:51:09,485 - INFO - _models.training_function_executor - Epoch 031 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:51:15,560 - INFO - _models.training_function_executor - Epoch 032 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:51:21,647 - INFO - _models.training_function_executor - Epoch 033 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:51:27,732 - INFO - _models.training_function_executor - Epoch 034 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:51:33,768 - INFO - _models.training_function_executor - Epoch 035 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.0s
2025-10-12 00:51:39,843 - INFO - _models.training_function_executor - Epoch 036 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:51:45,960 - INFO - _models.training_function_executor - Epoch 037 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:51:52,056 - INFO - _models.training_function_executor - Epoch 038 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:51:58,109 - INFO - _models.training_function_executor - Epoch 039 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:52:04,200 - INFO - _models.training_function_executor - Epoch 040 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.1s
2025-10-12 00:52:05,325 - INFO - _models.training_function_executor - Model: 1,295 parameters, 5.6KB storage
2025-10-12 00:52:05,325 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8664286602386279, 0.7254809848820784, 0.6569012365413789, 0.6201105791662054, 0.5625293048337953, 0.5079525255206627, 0.48791645796650723, 0.4684971208844854, 0.46528746798050374, 0.45696743816857077, 0.4620378885260403, 0.4573560933946603, 0.4526066375589262, 0.4414656494747708, 0.44730879532256074, 0.44125753939986273, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [0.7620366515396358, 0.7430813275433921, 0.6270485924882488, 0.5540680677949131, 0.5507574362146271, 0.46086812352800705, 0.506132068469391, 0.5054848097837888, 0.4665893827701782, 0.6369493083311961, 0.42939601312358894, 0.41947677821129353, 0.45062662104626633, 0.5650970616436505, 0.40538332704063895, 0.43597739780699457, 0.4251718544564047, 0.4604765395288701, 0.39454517325946503, 0.5134194609481137, 0.38059781406309223, 0.4303757743818777, 0.4184417494996028, 0.40677375774700325, 0.4068155567285481, 0.9368392363920078, 0.9328960934406394, 0.928975749172114, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5244137206860343, 0.5401645082254113, 0.5805915295764789, 0.634319215960798, 0.6365943297164858, 0.704235211760588, 0.6820966048302415, 0.6444697234861743, 0.670546027301365, 0.5818165908295415, 0.7063353167658383, 0.7043227161358068, 0.7062478123906195, 0.6807840392019601, 0.7257612880644032, 0.6948722436121806, 0.7162233111655583, 0.6929471473573678, 0.7226986349317466, 0.688484424221211, 0.7362618130906545, 0.7223486174308715, 0.7352992649632482, 0.7296989849492475, 0.7242737136856843, 0.6842842142107105, 0.6846342317115856, 0.6852467623381169, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'best_epoch': 21, 'total_params': 1295, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004329593077279012, 'batch_size': 16, 'epochs': 40, 'weight_decay': 2.5002452326309026e-05, 'base_channels': 9, 'kernel_size': 4, 'dropout': 0.03579067701114764, 'amp': True, 'grad_clip_norm': 0.15357312523895864, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.91577572178398, 'label_smoothing': 0.14922065463334322, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}, 'model_parameter_count': 1295, 'model_storage_size_kb': 5.564453125000001, 'model_size_validation': 'PASS'}
2025-10-12 00:52:05,325 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-12 00:52:05,325 - INFO - _models.training_function_executor - Model: 1,295 parameters, 5.6KB (PASS 256KB limit)
2025-10-12 00:52:05,325 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 260.564s
2025-10-12 00:52:05,437 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-12 00:52:05,437 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-12 00:52:05,437 - INFO - bo.run_bo - Recorded observation #40: hparams={'lr': 0.004329593077279012, 'batch_size': np.int64(16), 'epochs': np.int64(40), 'weight_decay': 2.5002452326309026e-05, 'base_channels': np.int64(9), 'kernel_size': np.int64(4), 'dropout': 0.03579067701114764, 'amp': np.True_, 'grad_clip_norm': 0.15357312523895864, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.91577572178398, 'label_smoothing': 0.14922065463334322, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)}, value=0.2325
2025-10-12 00:52:05,437 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 40: {'lr': 0.004329593077279012, 'batch_size': np.int64(16), 'epochs': np.int64(40), 'weight_decay': 2.5002452326309026e-05, 'base_channels': np.int64(9), 'kernel_size': np.int64(4), 'dropout': 0.03579067701114764, 'amp': np.True_, 'grad_clip_norm': 0.15357312523895864, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.91577572178398, 'label_smoothing': 0.14922065463334322, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)} -> 0.2325
2025-10-12 00:52:05,438 - INFO - bo.run_bo - üîçBO Trial 41: Using RF surrogate + Expected Improvement
2025-10-12 00:52:05,438 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:52:05,438 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:52:05,438 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:52:05,438 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004776273729444448, 'batch_size': 16, 'epochs': 27, 'weight_decay': 2.55460657271713e-05, 'base_channels': 14, 'kernel_size': 12, 'dropout': 0.013972107223204591, 'amp': True, 'grad_clip_norm': 0.45990714261334575, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.96271343298874, 'label_smoothing': 0.18064199564881186, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}
2025-10-12 00:52:05,439 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004776273729444448, 'batch_size': 16, 'epochs': 27, 'weight_decay': 2.55460657271713e-05, 'base_channels': 14, 'kernel_size': 12, 'dropout': 0.013972107223204591, 'amp': True, 'grad_clip_norm': 0.45990714261334575, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.96271343298874, 'label_smoothing': 0.18064199564881186, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}
2025-10-12 00:52:15,657 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.6371 | val_loss=0.5043 | val_acc=0.5783 | time=10.2s
2025-10-12 00:52:23,028 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.4796 | val_loss=0.4445 | val_acc=0.5921 | time=7.4s
2025-10-12 00:52:30,406 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4093 | val_loss=0.4452 | val_acc=0.5820 | time=7.4s
2025-10-12 00:52:37,801 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.3647 | val_loss=0.3609 | val_acc=0.6841 | time=7.4s
2025-10-12 00:52:45,186 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3491 | val_loss=0.3401 | val_acc=0.6743 | time=7.4s
2025-10-12 00:52:52,575 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3446 | val_loss=0.3556 | val_acc=0.7032 | time=7.4s
2025-10-12 00:53:00,001 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3466 | val_loss=0.3028 | val_acc=0.7188 | time=7.4s
2025-10-12 00:53:07,427 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3332 | val_loss=0.3039 | val_acc=0.7047 | time=7.4s
2025-10-12 00:53:14,856 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3237 | val_loss=0.3409 | val_acc=0.6811 | time=7.4s
2025-10-12 00:53:22,287 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3192 | val_loss=0.3948 | val_acc=0.6791 | time=7.4s
2025-10-12 00:53:29,701 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3160 | val_loss=0.3438 | val_acc=0.7071 | time=7.4s
2025-10-12 00:53:37,095 - INFO - _models.training_function_executor - Epoch 012 | train_loss=nan | val_loss=0.3163 | val_acc=0.7468 | time=7.4s
2025-10-12 00:53:44,473 - INFO - _models.training_function_executor - Epoch 013 | train_loss=nan | val_loss=7.9448 | val_acc=0.5219 | time=7.4s
2025-10-12 00:53:51,642 - INFO - _models.training_function_executor - Epoch 014 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=7.2s
2025-10-12 00:53:58,585 - INFO - _models.training_function_executor - Epoch 015 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:54:05,551 - INFO - _models.training_function_executor - Epoch 016 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=7.0s
2025-10-12 00:54:12,479 - INFO - _models.training_function_executor - Epoch 017 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:54:19,434 - INFO - _models.training_function_executor - Epoch 018 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=7.0s
2025-10-12 00:54:26,369 - INFO - _models.training_function_executor - Epoch 019 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:54:33,308 - INFO - _models.training_function_executor - Epoch 020 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:54:40,237 - INFO - _models.training_function_executor - Epoch 021 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:54:47,161 - INFO - _models.training_function_executor - Epoch 022 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:54:54,121 - INFO - _models.training_function_executor - Epoch 023 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=7.0s
2025-10-12 00:55:01,063 - INFO - _models.training_function_executor - Epoch 024 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:55:08,022 - INFO - _models.training_function_executor - Epoch 025 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=7.0s
2025-10-12 00:55:14,942 - INFO - _models.training_function_executor - Epoch 026 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=6.9s
2025-10-12 00:55:21,906 - INFO - _models.training_function_executor - Epoch 027 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=7.0s
2025-10-12 00:55:21,909 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 00:55:23,031 - INFO - _models.training_function_executor - Model: 2,959 parameters, 6.4KB storage
2025-10-12 00:55:23,031 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.6371344356664962, 0.4796377091760146, 0.40928801798741216, 0.3646967985436169, 0.3490761712136117, 0.344610311595562, 0.34662635101538086, 0.3331547855397267, 0.3237036981971626, 0.31922543987874324, 0.3160325803689327, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [0.5043141673911702, 0.4444805185277979, 0.44518047608695666, 0.36093803724417317, 0.34007637671136354, 0.35558103258376356, 0.30276561359112913, 0.303860921959777, 0.34087840178004514, 0.394755901140975, 0.3438484691448145, 0.3163036288081349, 7.944828395618425, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5783164158207911, 0.5921421071053553, 0.581991599579979, 0.684109205460273, 0.6743087154357718, 0.7031851592579629, 0.7187609380469023, 0.7046727336366818, 0.6811340567028351, 0.6791214560728036, 0.7071228561428071, 0.7467623381169058, 0.5218760938046902, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'best_epoch': 12, 'total_params': 2959, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004776273729444448, 'batch_size': 16, 'epochs': 27, 'weight_decay': 2.55460657271713e-05, 'base_channels': 14, 'kernel_size': 12, 'dropout': 0.013972107223204591, 'amp': True, 'grad_clip_norm': 0.45990714261334575, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.96271343298874, 'label_smoothing': 0.18064199564881186, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': 8}, 'model_parameter_count': 2959, 'model_storage_size_kb': 6.3572265625, 'model_size_validation': 'PASS'}
2025-10-12 00:55:23,031 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-12 00:55:23,031 - INFO - _models.training_function_executor - Model: 2,959 parameters, 6.4KB (PASS 256KB limit)
2025-10-12 00:55:23,031 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 197.594s
2025-10-12 00:55:23,144 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-12 00:55:23,144 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-12 00:55:23,144 - INFO - bo.run_bo - Recorded observation #41: hparams={'lr': 0.004776273729444448, 'batch_size': np.int64(16), 'epochs': np.int64(27), 'weight_decay': 2.55460657271713e-05, 'base_channels': np.int64(14), 'kernel_size': np.int64(12), 'dropout': 0.013972107223204591, 'amp': np.True_, 'grad_clip_norm': 0.45990714261334575, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.96271343298874, 'label_smoothing': 0.18064199564881186, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(8)}, value=0.2325
2025-10-12 00:55:23,144 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 41: {'lr': 0.004776273729444448, 'batch_size': np.int64(16), 'epochs': np.int64(27), 'weight_decay': 2.55460657271713e-05, 'base_channels': np.int64(14), 'kernel_size': np.int64(12), 'dropout': 0.013972107223204591, 'amp': np.True_, 'grad_clip_norm': 0.45990714261334575, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.96271343298874, 'label_smoothing': 0.18064199564881186, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('fbgemm'), 'calibration_batches': np.int64(8)} -> 0.2325
2025-10-12 00:55:23,145 - INFO - bo.run_bo - üîçBO Trial 42: Using RF surrogate + Expected Improvement
2025-10-12 00:55:23,145 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:55:23,145 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:55:23,145 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:55:23,145 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004289471111230987, 'batch_size': 64, 'epochs': 5, 'weight_decay': 0.00012890234263161085, 'base_channels': 16, 'kernel_size': 8, 'dropout': 0.031721033473951894, 'amp': True, 'grad_clip_norm': 0.8577862073927826, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.997277043011827, 'label_smoothing': 0.16477390402018768, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 00:55:23,147 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004289471111230987, 'batch_size': 64, 'epochs': 5, 'weight_decay': 0.00012890234263161085, 'base_channels': 16, 'kernel_size': 8, 'dropout': 0.031721033473951894, 'amp': True, 'grad_clip_norm': 0.8577862073927826, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.997277043011827, 'label_smoothing': 0.16477390402018768, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 00:55:31,593 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.5318 | val_loss=0.4117 | val_acc=0.5850 | time=8.4s
2025-10-12 00:55:37,160 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.3853 | val_loss=0.3700 | val_acc=0.6602 | time=5.6s
2025-10-12 00:55:42,726 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.3365 | val_loss=0.3163 | val_acc=0.6865 | time=5.6s
2025-10-12 00:55:48,283 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.3144 | val_loss=0.3028 | val_acc=0.7059 | time=5.6s
2025-10-12 00:55:53,859 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3006 | val_loss=0.2838 | val_acc=0.7169 | time=5.6s
2025-10-12 00:55:54,970 - INFO - _models.training_function_executor - Model: 3,179 parameters, 13.7KB storage
2025-10-12 00:55:54,970 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.5318078779674077, 0.3853483248840679, 0.336465059648027, 0.31435226547968137, 0.30056140591631403], 'val_losses': [0.4116592884230214, 0.3700162164825301, 0.31632116470257, 0.30282619104372055, 0.2838401204214416], 'val_acc': [0.5849667483374169, 0.6602205110255512, 0.6864718235911795, 0.7058977948897445, 0.7169233461673084], 'best_epoch': 5, 'total_params': 3179, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004289471111230987, 'batch_size': 64, 'epochs': 5, 'weight_decay': 0.00012890234263161085, 'base_channels': 16, 'kernel_size': 8, 'dropout': 0.031721033473951894, 'amp': True, 'grad_clip_norm': 0.8577862073927826, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.997277043011827, 'label_smoothing': 0.16477390402018768, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}, 'model_parameter_count': 3179, 'model_storage_size_kb': 13.659765625, 'model_size_validation': 'PASS'}
2025-10-12 00:55:54,970 - INFO - _models.training_function_executor - BO Objective: base=0.7169, size_penalty=0.0000, final=0.7169
2025-10-12 00:55:54,970 - INFO - _models.training_function_executor - Model: 3,179 parameters, 13.7KB (PASS 256KB limit)
2025-10-12 00:55:54,971 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 31.826s
2025-10-12 00:55:55,091 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7169
2025-10-12 00:55:55,092 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.113s
2025-10-12 00:55:55,092 - INFO - bo.run_bo - Recorded observation #42: hparams={'lr': 0.004289471111230987, 'batch_size': np.int64(64), 'epochs': np.int64(5), 'weight_decay': 0.00012890234263161085, 'base_channels': np.int64(16), 'kernel_size': np.int64(8), 'dropout': 0.031721033473951894, 'amp': np.True_, 'grad_clip_norm': 0.8577862073927826, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.997277043011827, 'label_smoothing': 0.16477390402018768, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)}, value=0.7169
2025-10-12 00:55:55,092 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 42: {'lr': 0.004289471111230987, 'batch_size': np.int64(64), 'epochs': np.int64(5), 'weight_decay': 0.00012890234263161085, 'base_channels': np.int64(16), 'kernel_size': np.int64(8), 'dropout': 0.031721033473951894, 'amp': np.True_, 'grad_clip_norm': 0.8577862073927826, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.997277043011827, 'label_smoothing': 0.16477390402018768, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)} -> 0.7169
2025-10-12 00:55:55,092 - INFO - bo.run_bo - üîçBO Trial 43: Using RF surrogate + Expected Improvement
2025-10-12 00:55:55,092 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 00:55:55,092 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:55:55,092 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:55:55,092 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004998990518282603, 'batch_size': 16, 'epochs': 22, 'weight_decay': 1.2943422409501118e-05, 'base_channels': 13, 'kernel_size': 7, 'dropout': 0.039239464313639144, 'amp': False, 'grad_clip_norm': 0.6600939663900319, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.3115226488172054, 'label_smoothing': 0.16657469400896258, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}
2025-10-12 00:55:55,094 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004998990518282603, 'batch_size': 16, 'epochs': 22, 'weight_decay': 1.2943422409501118e-05, 'base_channels': 13, 'kernel_size': 7, 'dropout': 0.039239464313639144, 'amp': False, 'grad_clip_norm': 0.6600939663900319, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.3115226488172054, 'label_smoothing': 0.16657469400896258, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}
2025-10-12 00:56:04,596 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0115 | val_loss=0.9061 | val_acc=0.5120 | time=9.5s
2025-10-12 00:56:11,229 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7568 | val_loss=0.6726 | val_acc=0.6141 | time=6.6s
2025-10-12 00:56:17,827 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6655 | val_loss=0.6005 | val_acc=0.6521 | time=6.6s
2025-10-12 00:56:24,401 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5861 | val_loss=0.5240 | val_acc=0.6831 | time=6.6s
2025-10-12 00:56:30,978 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5627 | val_loss=0.4944 | val_acc=0.7122 | time=6.6s
2025-10-12 00:56:37,548 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5551 | val_loss=0.5630 | val_acc=0.6738 | time=6.6s
2025-10-12 00:56:44,137 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5479 | val_loss=0.4869 | val_acc=0.7237 | time=6.6s
2025-10-12 00:56:50,728 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.5255 | val_loss=0.5566 | val_acc=0.7007 | time=6.6s
2025-10-12 00:56:57,332 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.5123 | val_loss=0.4775 | val_acc=0.7188 | time=6.6s
2025-10-12 00:57:03,923 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.5030 | val_loss=0.5020 | val_acc=0.7020 | time=6.6s
2025-10-12 00:57:10,496 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4911 | val_loss=0.4862 | val_acc=0.7114 | time=6.6s
2025-10-12 00:57:17,064 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4816 | val_loss=0.4576 | val_acc=0.7230 | time=6.6s
2025-10-12 00:57:23,631 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.4732 | val_loss=0.4681 | val_acc=0.7156 | time=6.6s
2025-10-12 00:57:30,202 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.4581 | val_loss=0.4416 | val_acc=0.7386 | time=6.6s
2025-10-12 00:57:36,786 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.4515 | val_loss=0.4531 | val_acc=0.7343 | time=6.6s
2025-10-12 00:57:43,370 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.4399 | val_loss=0.4225 | val_acc=0.7402 | time=6.6s
2025-10-12 00:57:49,948 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.4283 | val_loss=0.4335 | val_acc=0.7376 | time=6.6s
2025-10-12 00:57:56,508 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.4179 | val_loss=0.4163 | val_acc=0.7480 | time=6.6s
2025-10-12 00:58:03,097 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.4084 | val_loss=0.4196 | val_acc=0.7474 | time=6.6s
2025-10-12 00:58:09,686 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.4015 | val_loss=0.4089 | val_acc=0.7576 | time=6.6s
2025-10-12 00:58:16,271 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3955 | val_loss=0.4102 | val_acc=0.7588 | time=6.6s
2025-10-12 00:58:22,855 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3921 | val_loss=0.4076 | val_acc=0.7588 | time=6.6s
2025-10-12 00:58:22,858 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 00:58:23,988 - INFO - _models.training_function_executor - Model: 2,251 parameters, 4.8KB storage
2025-10-12 00:58:23,988 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0115252208430157, 0.7568468541887452, 0.6654935695718626, 0.5861025973215652, 0.5626775054746798, 0.5550609658432144, 0.5478768623272647, 0.5254536204334735, 0.5122933959328277, 0.502982477985106, 0.4910644702000513, 0.4815660564781101, 0.4731508079821053, 0.4581079933535481, 0.4515009580084211, 0.4399370803730155, 0.428332536635509, 0.41786031686304165, 0.4083719985493735, 0.4015233518257815, 0.39551652925422154, 0.39209669236045513], 'val_losses': [0.9060840609190347, 0.6726021941725191, 0.6004529325695305, 0.5239712932935128, 0.4944326057717517, 0.5629815816879272, 0.4868906775971393, 0.5566334013755505, 0.4775384224378146, 0.501988052967545, 0.48624368745547075, 0.45760643837022613, 0.4681189323221887, 0.44163577974467844, 0.45314981923861936, 0.4225489305553736, 0.43350472013120883, 0.4162795583059738, 0.4195764834751616, 0.40893882818363764, 0.4102172855522249, 0.40760461056565905], 'val_acc': [0.5119880994049703, 0.6141057052852643, 0.6520826041302065, 0.6831466573328666, 0.7121981099054953, 0.6737836891844592, 0.723661183059153, 0.7007350367518376, 0.7187609380469023, 0.702047602380119, 0.7114105705285264, 0.7230486524326216, 0.7156107805390269, 0.7386244312215611, 0.7343367168358418, 0.7401995099754988, 0.7375743787189359, 0.7479873993699685, 0.7473748687434372, 0.7576128806440322, 0.7588379418970949, 0.7588379418970949], 'best_epoch': 21, 'total_params': 2251, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004998990518282603, 'batch_size': 16, 'epochs': 22, 'weight_decay': 1.2943422409501118e-05, 'base_channels': 13, 'kernel_size': 7, 'dropout': 0.039239464313639144, 'amp': False, 'grad_clip_norm': 0.6600939663900319, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.3115226488172054, 'label_smoothing': 0.16657469400896258, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 5}, 'model_parameter_count': 2251, 'model_storage_size_kb': 4.836132812500001, 'model_size_validation': 'PASS'}
2025-10-12 00:58:23,988 - INFO - _models.training_function_executor - BO Objective: base=0.7588, size_penalty=0.0000, final=0.7588
2025-10-12 00:58:23,988 - INFO - _models.training_function_executor - Model: 2,251 parameters, 4.8KB (PASS 256KB limit)
2025-10-12 00:58:23,988 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 148.896s
2025-10-12 00:58:24,105 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7588
2025-10-12 00:58:24,105 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.115s
2025-10-12 00:58:24,105 - INFO - bo.run_bo - Recorded observation #43: hparams={'lr': 0.004998990518282603, 'batch_size': np.int64(16), 'epochs': np.int64(22), 'weight_decay': 1.2943422409501118e-05, 'base_channels': np.int64(13), 'kernel_size': np.int64(7), 'dropout': 0.039239464313639144, 'amp': np.False_, 'grad_clip_norm': 0.6600939663900319, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.3115226488172054, 'label_smoothing': 0.16657469400896258, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(5)}, value=0.7588
2025-10-12 00:58:24,105 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 43: {'lr': 0.004998990518282603, 'batch_size': np.int64(16), 'epochs': np.int64(22), 'weight_decay': 1.2943422409501118e-05, 'base_channels': np.int64(13), 'kernel_size': np.int64(7), 'dropout': 0.039239464313639144, 'amp': np.False_, 'grad_clip_norm': 0.6600939663900319, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.3115226488172054, 'label_smoothing': 0.16657469400896258, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(5)} -> 0.7588
2025-10-12 00:58:24,106 - INFO - bo.run_bo - üîçBO Trial 44: Using RF surrogate + Expected Improvement
2025-10-12 00:58:24,106 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 00:58:24,106 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 00:58:24,106 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 00:58:24,106 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003232909661827045, 'batch_size': 16, 'epochs': 45, 'weight_decay': 0.0005378987664663762, 'base_channels': 15, 'kernel_size': 6, 'dropout': 0.013939570639630375, 'amp': False, 'grad_clip_norm': 0.5002129905550226, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9668364054999152, 'label_smoothing': 0.19595060741897494, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:58:24,108 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003232909661827045, 'batch_size': 16, 'epochs': 45, 'weight_decay': 0.0005378987664663762, 'base_channels': 15, 'kernel_size': 6, 'dropout': 0.013939570639630375, 'amp': False, 'grad_clip_norm': 0.5002129905550226, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9668364054999152, 'label_smoothing': 0.19595060741897494, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 00:58:34,217 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.4906 | val_loss=1.4022 | val_acc=0.5419 | time=10.1s
2025-10-12 00:58:41,423 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3753 | val_loss=1.3663 | val_acc=0.5659 | time=7.2s
2025-10-12 00:58:48,639 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.3439 | val_loss=1.3164 | val_acc=0.5733 | time=7.2s
2025-10-12 00:58:55,855 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.2996 | val_loss=1.2879 | val_acc=0.6058 | time=7.2s
2025-10-12 00:59:03,089 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.2743 | val_loss=1.2395 | val_acc=0.6278 | time=7.2s
2025-10-12 00:59:10,305 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.2251 | val_loss=1.2051 | val_acc=0.6636 | time=7.2s
2025-10-12 00:59:17,511 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1934 | val_loss=1.1758 | val_acc=0.6861 | time=7.2s
2025-10-12 00:59:24,733 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1784 | val_loss=1.1535 | val_acc=0.7118 | time=7.2s
2025-10-12 00:59:31,989 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1670 | val_loss=1.1505 | val_acc=0.7048 | time=7.3s
2025-10-12 00:59:39,232 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1632 | val_loss=1.1727 | val_acc=0.6965 | time=7.2s
2025-10-12 00:59:46,473 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.1541 | val_loss=1.1425 | val_acc=0.7198 | time=7.2s
2025-10-12 00:59:53,704 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.1475 | val_loss=1.1360 | val_acc=0.7189 | time=7.2s
2025-10-12 01:00:00,964 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.1439 | val_loss=1.1193 | val_acc=0.7251 | time=7.3s
2025-10-12 01:00:08,193 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.1364 | val_loss=1.1463 | val_acc=0.7139 | time=7.2s
2025-10-12 01:00:15,429 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.1326 | val_loss=1.1269 | val_acc=0.7193 | time=7.2s
2025-10-12 01:00:22,666 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.1273 | val_loss=1.1192 | val_acc=0.7192 | time=7.2s
2025-10-12 01:00:29,888 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.1207 | val_loss=1.1153 | val_acc=0.7197 | time=7.2s
2025-10-12 01:00:37,116 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.1204 | val_loss=1.1159 | val_acc=0.7268 | time=7.2s
2025-10-12 01:00:44,335 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.1180 | val_loss=1.1161 | val_acc=0.7238 | time=7.2s
2025-10-12 01:00:51,572 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.1136 | val_loss=1.1217 | val_acc=0.7200 | time=7.2s
2025-10-12 01:00:58,801 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.1103 | val_loss=1.1107 | val_acc=0.7182 | time=7.2s
2025-10-12 01:01:06,021 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.1073 | val_loss=1.1164 | val_acc=0.7293 | time=7.2s
2025-10-12 01:01:13,263 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.1042 | val_loss=1.1173 | val_acc=0.7153 | time=7.2s
2025-10-12 01:01:20,477 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.1016 | val_loss=1.1040 | val_acc=0.7265 | time=7.2s
2025-10-12 01:01:27,710 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.0996 | val_loss=1.0989 | val_acc=0.7295 | time=7.2s
2025-10-12 01:01:34,941 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.0970 | val_loss=1.0993 | val_acc=0.7307 | time=7.2s
2025-10-12 01:01:42,165 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.0925 | val_loss=1.1047 | val_acc=0.7300 | time=7.2s
2025-10-12 01:01:49,404 - INFO - _models.training_function_executor - Epoch 028 | train_loss=1.0907 | val_loss=1.0962 | val_acc=0.7252 | time=7.2s
2025-10-12 01:01:56,640 - INFO - _models.training_function_executor - Epoch 029 | train_loss=1.0866 | val_loss=1.0965 | val_acc=0.7308 | time=7.2s
2025-10-12 01:02:03,881 - INFO - _models.training_function_executor - Epoch 030 | train_loss=1.0844 | val_loss=1.0927 | val_acc=0.7327 | time=7.2s
2025-10-12 01:02:11,133 - INFO - _models.training_function_executor - Epoch 031 | train_loss=1.0827 | val_loss=1.0884 | val_acc=0.7357 | time=7.3s
2025-10-12 01:02:18,400 - INFO - _models.training_function_executor - Epoch 032 | train_loss=1.0802 | val_loss=1.0913 | val_acc=0.7384 | time=7.3s
2025-10-12 01:02:25,639 - INFO - _models.training_function_executor - Epoch 033 | train_loss=1.0752 | val_loss=1.0909 | val_acc=0.7383 | time=7.2s
2025-10-12 01:02:32,917 - INFO - _models.training_function_executor - Epoch 034 | train_loss=1.0745 | val_loss=1.0843 | val_acc=0.7434 | time=7.3s
2025-10-12 01:02:40,127 - INFO - _models.training_function_executor - Epoch 035 | train_loss=1.0711 | val_loss=1.0870 | val_acc=0.7356 | time=7.2s
2025-10-12 01:02:47,352 - INFO - _models.training_function_executor - Epoch 036 | train_loss=1.0684 | val_loss=1.0855 | val_acc=0.7465 | time=7.2s
2025-10-12 01:02:54,584 - INFO - _models.training_function_executor - Epoch 037 | train_loss=1.0664 | val_loss=1.0915 | val_acc=0.7412 | time=7.2s
2025-10-12 01:03:01,833 - INFO - _models.training_function_executor - Epoch 038 | train_loss=1.0635 | val_loss=1.0832 | val_acc=0.7413 | time=7.2s
2025-10-12 01:03:09,056 - INFO - _models.training_function_executor - Epoch 039 | train_loss=1.0608 | val_loss=1.0812 | val_acc=0.7423 | time=7.2s
2025-10-12 01:03:16,277 - INFO - _models.training_function_executor - Epoch 040 | train_loss=1.0601 | val_loss=1.0804 | val_acc=0.7446 | time=7.2s
2025-10-12 01:03:23,510 - INFO - _models.training_function_executor - Epoch 041 | train_loss=1.0585 | val_loss=1.0820 | val_acc=0.7441 | time=7.2s
2025-10-12 01:03:30,730 - INFO - _models.training_function_executor - Epoch 042 | train_loss=1.0572 | val_loss=1.0805 | val_acc=0.7456 | time=7.2s
2025-10-12 01:03:37,929 - INFO - _models.training_function_executor - Epoch 043 | train_loss=1.0560 | val_loss=1.0797 | val_acc=0.7462 | time=7.2s
2025-10-12 01:03:45,141 - INFO - _models.training_function_executor - Epoch 044 | train_loss=1.0556 | val_loss=1.0799 | val_acc=0.7454 | time=7.2s
2025-10-12 01:03:52,384 - INFO - _models.training_function_executor - Epoch 045 | train_loss=1.0547 | val_loss=1.0796 | val_acc=0.7454 | time=7.2s
2025-10-12 01:03:53,510 - INFO - _models.training_function_executor - Model: 2,743 parameters, 11.8KB storage
2025-10-12 01:03:53,510 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4905823056081144, 1.3752751464313004, 1.3439052893558832, 1.2995887580433634, 1.2743152395219373, 1.2250560115883307, 1.1934480107786107, 1.1783960393812842, 1.167045941835189, 1.1632327731773076, 1.154126831564738, 1.147498627914012, 1.1438750918194427, 1.1363856507257268, 1.1325866770485626, 1.1272557985753415, 1.1207349981133405, 1.1203850567820692, 1.1180322978060104, 1.113622684202538, 1.1102800164808542, 1.1073381671297997, 1.1041965222375394, 1.1015514269716304, 1.09956018568796, 1.0969756223290044, 1.092483530313267, 1.0907008374409113, 1.086645366492954, 1.084422352162115, 1.0826829763029604, 1.080195454771718, 1.0752328590659108, 1.0745094766306384, 1.0710875286812294, 1.0684173286983423, 1.0663973360074999, 1.0635355726421651, 1.0608035298673932, 1.060108420353984, 1.0585193920269018, 1.0572075651248602, 1.0559861612019523, 1.055578738357122, 1.0547329995195724], 'val_losses': [1.402247846543372, 1.3662621333048894, 1.3164414000677895, 1.28792137132658, 1.239502881373559, 1.205116275890724, 1.1757913767041026, 1.1534976354012123, 1.1505020143268825, 1.1727366728382511, 1.1425377413943096, 1.1359667754673457, 1.1193152325136677, 1.146311203499774, 1.1269100232557816, 1.1191891410134056, 1.115303986305957, 1.1158851153367049, 1.11607654253086, 1.1216526954324095, 1.1106643857655825, 1.1164396182640448, 1.1172610197033916, 1.1039993557063017, 1.0989246496787437, 1.0993126009727692, 1.1046878822199948, 1.0962188478116388, 1.096470014448766, 1.0927388085351957, 1.0884064800255782, 1.091280290130135, 1.090923861440245, 1.0842726980889594, 1.086996999070361, 1.0855281484710586, 1.0914532307978277, 1.0832132923853148, 1.081239469151397, 1.0804313829728773, 1.081952368379473, 1.0805460760643433, 1.0797265171171069, 1.0798825769991307, 1.0796019961783936], 'val_acc': [0.5419145957297865, 0.565890794539727, 0.5733286664333217, 0.605792789639482, 0.6277563878193909, 0.6636331816590829, 0.6861218060903045, 0.7118480924046202, 0.7047602380119006, 0.696534826741337, 0.7198109905495275, 0.7189359467973399, 0.7250612530626531, 0.7138606930346517, 0.7192859642982149, 0.7191984599229961, 0.7197234861743087, 0.7268113405670283, 0.7238361918095905, 0.719985999299965, 0.7182359117955898, 0.7292614630731536, 0.7152607630381519, 0.7265488274413721, 0.7295239761988099, 0.7307490374518726, 0.7299614980749037, 0.7252362618130906, 0.7308365418270913, 0.7326741337066853, 0.735736786839342, 0.7383619180959048, 0.738274413720686, 0.7434371718585929, 0.7356492824641232, 0.7464998249912496, 0.7411620581029051, 0.7413370668533427, 0.742299614980749, 0.7445747287364368, 0.744137206860343, 0.745624781239062, 0.7462373118655933, 0.7453622681134057, 0.7454497724886244], 'best_epoch': 36, 'total_params': 2743, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003232909661827045, 'batch_size': 16, 'epochs': 45, 'weight_decay': 0.0005378987664663762, 'base_channels': 15, 'kernel_size': 6, 'dropout': 0.013939570639630375, 'amp': False, 'grad_clip_norm': 0.5002129905550226, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9668364054999152, 'label_smoothing': 0.19595060741897494, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}, 'model_parameter_count': 2743, 'model_storage_size_kb': 11.786328125, 'model_size_validation': 'PASS'}
2025-10-12 01:03:53,510 - INFO - _models.training_function_executor - BO Objective: base=0.7454, size_penalty=0.0000, final=0.7454
2025-10-12 01:03:53,510 - INFO - _models.training_function_executor - Model: 2,743 parameters, 11.8KB (PASS 256KB limit)
2025-10-12 01:03:53,510 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 329.404s
2025-10-12 01:03:53,627 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7454
2025-10-12 01:03:53,627 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.114s
2025-10-12 01:03:53,628 - INFO - bo.run_bo - Recorded observation #44: hparams={'lr': 0.003232909661827045, 'batch_size': np.int64(16), 'epochs': np.int64(45), 'weight_decay': 0.0005378987664663762, 'base_channels': np.int64(15), 'kernel_size': np.int64(6), 'dropout': 0.013939570639630375, 'amp': np.False_, 'grad_clip_norm': 0.5002129905550226, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9668364054999152, 'label_smoothing': 0.19595060741897494, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}, value=0.7454
2025-10-12 01:03:53,628 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 44: {'lr': 0.003232909661827045, 'batch_size': np.int64(16), 'epochs': np.int64(45), 'weight_decay': 0.0005378987664663762, 'base_channels': np.int64(15), 'kernel_size': np.int64(6), 'dropout': 0.013939570639630375, 'amp': np.False_, 'grad_clip_norm': 0.5002129905550226, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('none'), 'focal_gamma': 2.9668364054999152, 'label_smoothing': 0.19595060741897494, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)} -> 0.7454
2025-10-12 01:03:53,628 - INFO - bo.run_bo - üîçBO Trial 45: Using RF surrogate + Expected Improvement
2025-10-12 01:03:53,628 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 01:03:53,628 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:03:53,628 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 01:03:53,628 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0039044050208702054, 'batch_size': 64, 'epochs': 43, 'weight_decay': 5.078220218869848e-05, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.03770567663736399, 'amp': False, 'grad_clip_norm': 0.40972236813975604, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4998540547908998, 'label_smoothing': 0.15802297517856365, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 01:03:53,630 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0039044050208702054, 'batch_size': 64, 'epochs': 43, 'weight_decay': 5.078220218869848e-05, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.03770567663736399, 'amp': False, 'grad_clip_norm': 0.40972236813975604, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4998540547908998, 'label_smoothing': 0.15802297517856365, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 01:04:01,690 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0428 | val_loss=0.8558 | val_acc=0.4955 | time=8.1s
2025-10-12 01:04:06,901 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.8067 | val_loss=0.7828 | val_acc=0.5357 | time=5.2s
2025-10-12 01:04:12,115 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.7508 | val_loss=0.7245 | val_acc=0.5574 | time=5.2s
2025-10-12 01:04:17,329 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.7278 | val_loss=0.6926 | val_acc=0.5739 | time=5.2s
2025-10-12 01:04:22,546 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.6872 | val_loss=0.6580 | val_acc=0.5745 | time=5.2s
2025-10-12 01:04:27,758 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.6568 | val_loss=0.6195 | val_acc=0.6160 | time=5.2s
2025-10-12 01:04:32,968 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.6249 | val_loss=0.5884 | val_acc=0.6435 | time=5.2s
2025-10-12 01:04:38,179 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.6111 | val_loss=0.5644 | val_acc=0.6593 | time=5.2s
2025-10-12 01:04:43,388 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.5436 | val_loss=0.5905 | val_acc=0.6368 | time=5.2s
2025-10-12 01:04:48,596 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.5093 | val_loss=0.4993 | val_acc=0.6833 | time=5.2s
2025-10-12 01:04:53,808 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4971 | val_loss=0.4679 | val_acc=0.7101 | time=5.2s
2025-10-12 01:04:59,019 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4947 | val_loss=0.4753 | val_acc=0.7033 | time=5.2s
2025-10-12 01:05:04,238 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.4779 | val_loss=0.4888 | val_acc=0.6976 | time=5.2s
2025-10-12 01:05:09,452 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.4717 | val_loss=0.4597 | val_acc=0.7211 | time=5.2s
2025-10-12 01:05:14,667 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.4646 | val_loss=0.4764 | val_acc=0.7071 | time=5.2s
2025-10-12 01:05:19,879 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.4573 | val_loss=0.5559 | val_acc=0.6890 | time=5.2s
2025-10-12 01:05:25,091 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.4589 | val_loss=0.5253 | val_acc=0.6889 | time=5.2s
2025-10-12 01:05:30,301 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.4489 | val_loss=0.4269 | val_acc=0.7444 | time=5.2s
2025-10-12 01:05:35,507 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.4441 | val_loss=0.4260 | val_acc=0.7373 | time=5.2s
2025-10-12 01:05:40,722 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.4362 | val_loss=0.4364 | val_acc=0.7408 | time=5.2s
2025-10-12 01:05:45,931 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.4269 | val_loss=0.4187 | val_acc=0.7447 | time=5.2s
2025-10-12 01:05:51,135 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.4221 | val_loss=0.4542 | val_acc=0.7152 | time=5.2s
2025-10-12 01:05:56,349 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.4217 | val_loss=0.4236 | val_acc=0.7317 | time=5.2s
2025-10-12 01:06:01,566 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.4137 | val_loss=0.4140 | val_acc=0.7399 | time=5.2s
2025-10-12 01:06:06,777 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.4091 | val_loss=0.4102 | val_acc=0.7469 | time=5.2s
2025-10-12 01:06:11,984 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.4030 | val_loss=0.4156 | val_acc=0.7475 | time=5.2s
2025-10-12 01:06:17,189 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.3973 | val_loss=0.4066 | val_acc=0.7411 | time=5.2s
2025-10-12 01:06:22,397 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.3976 | val_loss=0.3993 | val_acc=0.7537 | time=5.2s
2025-10-12 01:06:27,615 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.3894 | val_loss=0.4001 | val_acc=0.7461 | time=5.2s
2025-10-12 01:06:32,827 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.3832 | val_loss=0.4024 | val_acc=0.7553 | time=5.2s
2025-10-12 01:06:38,041 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.3830 | val_loss=0.3937 | val_acc=0.7554 | time=5.2s
2025-10-12 01:06:43,259 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.3772 | val_loss=0.3897 | val_acc=0.7573 | time=5.2s
2025-10-12 01:06:48,472 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.3743 | val_loss=0.3824 | val_acc=0.7593 | time=5.2s
2025-10-12 01:06:53,683 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.3680 | val_loss=0.3867 | val_acc=0.7567 | time=5.2s
2025-10-12 01:06:58,899 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.3658 | val_loss=0.3903 | val_acc=0.7546 | time=5.2s
2025-10-12 01:07:04,109 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.3633 | val_loss=0.3847 | val_acc=0.7588 | time=5.2s
2025-10-12 01:07:09,323 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.3586 | val_loss=0.3831 | val_acc=0.7588 | time=5.2s
2025-10-12 01:07:14,537 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.3562 | val_loss=0.3825 | val_acc=0.7602 | time=5.2s
2025-10-12 01:07:19,747 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.3546 | val_loss=0.3807 | val_acc=0.7609 | time=5.2s
2025-10-12 01:07:24,955 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.3525 | val_loss=0.3803 | val_acc=0.7620 | time=5.2s
2025-10-12 01:07:30,171 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.3513 | val_loss=0.3814 | val_acc=0.7605 | time=5.2s
2025-10-12 01:07:35,383 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.3513 | val_loss=0.3803 | val_acc=0.7611 | time=5.2s
2025-10-12 01:07:40,590 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.3502 | val_loss=0.3802 | val_acc=0.7609 | time=5.2s
2025-10-12 01:07:41,695 - INFO - _models.training_function_executor - Model: 1,851 parameters, 8.0KB storage
2025-10-12 01:07:41,695 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0428062050492612, 0.806737666530209, 0.7508033014677621, 0.7277549742818712, 0.6872040213821651, 0.6567590986098443, 0.6249266873289655, 0.6111332387774141, 0.5435512218441997, 0.5092969731017426, 0.49708283439382805, 0.49474292868500824, 0.4778535082832083, 0.47174799561083736, 0.46457858073127856, 0.45731198612626617, 0.4588858027141411, 0.44885505517045937, 0.44406631184624623, 0.43624477334372647, 0.426925638297221, 0.4220844276093103, 0.4216553871448223, 0.4136727709870238, 0.4090821267007948, 0.40299312316037555, 0.3972838899055561, 0.39757169109958035, 0.38939042153891984, 0.38320295766933815, 0.3829650254307927, 0.3771665498718515, 0.37426097482651266, 0.36800619276253493, 0.3658138237216256, 0.36333106985458963, 0.35862862719939304, 0.35616632593678427, 0.35459632158696236, 0.35248690443439085, 0.3513231276632189, 0.35133534484393114, 0.35020647897170143], 'val_losses': [0.8557701660268133, 0.7827910361343255, 0.7244766604300984, 0.6926284006188036, 0.6579878889648608, 0.6194963788187038, 0.588399760216974, 0.5644174353037467, 0.5904689078224438, 0.4993400432211061, 0.4678503403117537, 0.4752644578504829, 0.48880866253176214, 0.4597398462242254, 0.476425547839543, 0.5559331892921938, 0.525336273555649, 0.4268697818231316, 0.42597205712142605, 0.4363519059879154, 0.4186895829339267, 0.4541978081844372, 0.4236208791506357, 0.4140447100114556, 0.41019494773289344, 0.4156437032549075, 0.4065824563942808, 0.39932414439803393, 0.40010908778819293, 0.4024301128014506, 0.39368444073466613, 0.3897376958717847, 0.3823529113937357, 0.38674722378813353, 0.3903188634684632, 0.38468939906725, 0.3831208379907981, 0.3825169659360161, 0.38071795332365194, 0.3803359369991878, 0.3813962562623637, 0.3802669140713175, 0.3802176152028185], 'val_acc': [0.4955372768638432, 0.5357017850892545, 0.5574028701435072, 0.5738536926846343, 0.5744662233111656, 0.616030801540077, 0.6435071753587679, 0.6593454672733636, 0.6367693384669233, 0.6833216660833041, 0.710098004900245, 0.7032726636331816, 0.6975848792439622, 0.7211235561778089, 0.7071228561428071, 0.6890094504725236, 0.6889219460973048, 0.7443997199859993, 0.7373118655932797, 0.7408120406020301, 0.7447497374868743, 0.7151732586629331, 0.731711585579279, 0.7399369968498425, 0.7469373468673434, 0.7475498774938747, 0.7410745537276864, 0.753675183759188, 0.7460623031151558, 0.7553377668883444, 0.7554252712635632, 0.7572628631431572, 0.7592754637731887, 0.7566503325166258, 0.7545502275113756, 0.7588379418970949, 0.7588379418970949, 0.7601505075253763, 0.7608505425271264, 0.7619880994049703, 0.7605005250262513, 0.7611130556527826, 0.7609380469023451], 'best_epoch': 40, 'total_params': 1851, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0039044050208702054, 'batch_size': 64, 'epochs': 43, 'weight_decay': 5.078220218869848e-05, 'base_channels': 10, 'kernel_size': 10, 'dropout': 0.03770567663736399, 'amp': False, 'grad_clip_norm': 0.40972236813975604, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4998540547908998, 'label_smoothing': 0.15802297517856365, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}, 'model_parameter_count': 1851, 'model_storage_size_kb': 7.9535156250000005, 'model_size_validation': 'PASS'}
2025-10-12 01:07:41,696 - INFO - _models.training_function_executor - BO Objective: base=0.7609, size_penalty=0.0000, final=0.7609
2025-10-12 01:07:41,696 - INFO - _models.training_function_executor - Model: 1,851 parameters, 8.0KB (PASS 256KB limit)
2025-10-12 01:07:41,696 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 228.067s
2025-10-12 01:07:41,831 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7609
2025-10-12 01:07:41,832 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.126s
2025-10-12 01:07:41,832 - INFO - bo.run_bo - Recorded observation #45: hparams={'lr': 0.0039044050208702054, 'batch_size': np.int64(64), 'epochs': np.int64(43), 'weight_decay': 5.078220218869848e-05, 'base_channels': np.int64(10), 'kernel_size': np.int64(10), 'dropout': 0.03770567663736399, 'amp': np.False_, 'grad_clip_norm': 0.40972236813975604, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4998540547908998, 'label_smoothing': 0.15802297517856365, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}, value=0.7609
2025-10-12 01:07:41,832 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 45: {'lr': 0.0039044050208702054, 'batch_size': np.int64(64), 'epochs': np.int64(43), 'weight_decay': 5.078220218869848e-05, 'base_channels': np.int64(10), 'kernel_size': np.int64(10), 'dropout': 0.03770567663736399, 'amp': np.False_, 'grad_clip_norm': 0.40972236813975604, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.4998540547908998, 'label_smoothing': 0.15802297517856365, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)} -> 0.7609
2025-10-12 01:07:41,832 - INFO - bo.run_bo - üîçBO Trial 46: Using RF surrogate + Expected Improvement
2025-10-12 01:07:41,832 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 01:07:41,833 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:07:41,833 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 01:07:41,833 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004154534820803335, 'batch_size': 32, 'epochs': 28, 'weight_decay': 9.323691363076123e-06, 'base_channels': 9, 'kernel_size': 15, 'dropout': 0.021731555190373657, 'amp': False, 'grad_clip_norm': 0.791202369585964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.228698979961901, 'label_smoothing': 0.0817414012880943, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 01:07:41,834 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004154534820803335, 'batch_size': 32, 'epochs': 28, 'weight_decay': 9.323691363076123e-06, 'base_channels': 9, 'kernel_size': 15, 'dropout': 0.021731555190373657, 'amp': False, 'grad_clip_norm': 0.791202369585964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.228698979961901, 'label_smoothing': 0.0817414012880943, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}
2025-10-12 01:07:50,360 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9470 | val_loss=0.6787 | val_acc=0.5311 | time=8.5s
2025-10-12 01:07:55,968 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.6214 | val_loss=0.5838 | val_acc=0.5678 | time=5.6s
2025-10-12 01:08:01,577 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5698 | val_loss=0.5513 | val_acc=0.6000 | time=5.6s
2025-10-12 01:08:07,175 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5188 | val_loss=0.4931 | val_acc=0.6421 | time=5.6s
2025-10-12 01:08:12,780 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4665 | val_loss=0.4072 | val_acc=0.6773 | time=5.6s
2025-10-12 01:08:18,396 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4397 | val_loss=0.4291 | val_acc=0.6833 | time=5.6s
2025-10-12 01:08:24,004 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4196 | val_loss=0.4008 | val_acc=0.6840 | time=5.6s
2025-10-12 01:08:29,617 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4084 | val_loss=0.5174 | val_acc=0.6384 | time=5.6s
2025-10-12 01:08:35,239 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3992 | val_loss=0.4161 | val_acc=0.6738 | time=5.6s
2025-10-12 01:08:40,852 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3853 | val_loss=0.3547 | val_acc=0.7340 | time=5.6s
2025-10-12 01:08:46,466 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3764 | val_loss=0.3934 | val_acc=0.7087 | time=5.6s
2025-10-12 01:08:52,073 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3684 | val_loss=0.4168 | val_acc=0.7002 | time=5.6s
2025-10-12 01:08:57,676 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3685 | val_loss=0.3818 | val_acc=0.7197 | time=5.6s
2025-10-12 01:09:03,284 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3557 | val_loss=0.3783 | val_acc=0.7035 | time=5.6s
2025-10-12 01:09:08,901 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3484 | val_loss=0.3485 | val_acc=0.7320 | time=5.6s
2025-10-12 01:09:14,509 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3464 | val_loss=0.3649 | val_acc=0.7145 | time=5.6s
2025-10-12 01:09:20,117 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3388 | val_loss=0.3678 | val_acc=0.7173 | time=5.6s
2025-10-12 01:09:25,726 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3331 | val_loss=0.3456 | val_acc=0.7313 | time=5.6s
2025-10-12 01:09:31,333 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3234 | val_loss=0.3391 | val_acc=0.7397 | time=5.6s
2025-10-12 01:09:36,939 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3221 | val_loss=0.3385 | val_acc=0.7265 | time=5.6s
2025-10-12 01:09:42,550 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3145 | val_loss=0.3134 | val_acc=0.7491 | time=5.6s
2025-10-12 01:09:48,161 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3094 | val_loss=0.3175 | val_acc=0.7454 | time=5.6s
2025-10-12 01:09:53,776 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3003 | val_loss=0.3201 | val_acc=0.7485 | time=5.6s
2025-10-12 01:09:59,386 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.2968 | val_loss=0.3077 | val_acc=0.7556 | time=5.6s
2025-10-12 01:10:04,991 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.2934 | val_loss=0.3058 | val_acc=0.7536 | time=5.6s
2025-10-12 01:10:10,605 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.2891 | val_loss=0.3021 | val_acc=0.7560 | time=5.6s
2025-10-12 01:10:16,218 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.2875 | val_loss=0.3036 | val_acc=0.7548 | time=5.6s
2025-10-12 01:10:21,823 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.2855 | val_loss=0.3030 | val_acc=0.7562 | time=5.6s
2025-10-12 01:10:21,827 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 01:10:22,966 - INFO - _models.training_function_executor - Model: 1,875 parameters, 4.0KB storage
2025-10-12 01:10:22,966 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9469784607079749, 0.6214246366139139, 0.5697979960327302, 0.5188225618791046, 0.46648196898989946, 0.4397303633146807, 0.4196433211912051, 0.40836058100300954, 0.3991511667510944, 0.3852752632949634, 0.3763928695355703, 0.3683988266084226, 0.3685442775675598, 0.35570034435823134, 0.3483505124256192, 0.3463927383832451, 0.33879311239389875, 0.333078208453093, 0.32339930118819565, 0.32209531418546417, 0.3144568804315206, 0.30942732065999484, 0.3003341555021875, 0.2967985755887125, 0.2933593009780386, 0.2891195241734646, 0.28748063525175865, 0.2855034662427562], 'val_losses': [0.6787252384524106, 0.5837626048473007, 0.5512531294836013, 0.4931251501570867, 0.4071795440086439, 0.42906487046340325, 0.4007546941245068, 0.5173936537024695, 0.41614707846548304, 0.35466349788800966, 0.39335410821371236, 0.41684052258646687, 0.38181847562836535, 0.37825799408738175, 0.34847880437886913, 0.36494903815858193, 0.36782482753419343, 0.34562488641152833, 0.3391212395616084, 0.3385402894469613, 0.3134012759855673, 0.31753988114482196, 0.3200628192231642, 0.3076582880035126, 0.3057515593922005, 0.3020588426158748, 0.3036215397732218, 0.30298788654071657], 'val_acc': [0.5310640532026601, 0.5678158907945398, 0.6000175008750438, 0.6421071053552677, 0.6772838641932096, 0.6833216660833041, 0.6840217010850542, 0.6384319215960798, 0.6737836891844592, 0.7339866993349667, 0.7086979348967448, 0.700210010500525, 0.7197234861743087, 0.7035351767588379, 0.7319740987049352, 0.714473223661183, 0.7172733636681834, 0.7312740637031852, 0.7396744837241862, 0.7264613230661533, 0.7491249562478124, 0.7454497724886244, 0.7485124256212811, 0.7556002800140007, 0.7535876793839692, 0.7559502975148757, 0.7548127406370319, 0.756212810640532], 'best_epoch': 28, 'total_params': 1875, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004154534820803335, 'batch_size': 32, 'epochs': 28, 'weight_decay': 9.323691363076123e-06, 'base_channels': 9, 'kernel_size': 15, 'dropout': 0.021731555190373657, 'amp': False, 'grad_clip_norm': 0.791202369585964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.228698979961901, 'label_smoothing': 0.0817414012880943, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 7}, 'model_parameter_count': 1875, 'model_storage_size_kb': 4.0283203125, 'model_size_validation': 'PASS'}
2025-10-12 01:10:22,966 - INFO - _models.training_function_executor - BO Objective: base=0.7562, size_penalty=0.0000, final=0.7562
2025-10-12 01:10:22,966 - INFO - _models.training_function_executor - Model: 1,875 parameters, 4.0KB (PASS 256KB limit)
2025-10-12 01:10:22,966 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 161.133s
2025-10-12 01:10:23,081 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7562
2025-10-12 01:10:23,081 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.112s
2025-10-12 01:10:23,081 - INFO - bo.run_bo - Recorded observation #46: hparams={'lr': 0.004154534820803335, 'batch_size': np.int64(32), 'epochs': np.int64(28), 'weight_decay': 9.323691363076123e-06, 'base_channels': np.int64(9), 'kernel_size': np.int64(15), 'dropout': 0.021731555190373657, 'amp': np.False_, 'grad_clip_norm': 0.791202369585964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.228698979961901, 'label_smoothing': 0.0817414012880943, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)}, value=0.7562
2025-10-12 01:10:23,081 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 46: {'lr': 0.004154534820803335, 'batch_size': np.int64(32), 'epochs': np.int64(28), 'weight_decay': 9.323691363076123e-06, 'base_channels': np.int64(9), 'kernel_size': np.int64(15), 'dropout': 0.021731555190373657, 'amp': np.False_, 'grad_clip_norm': 0.791202369585964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.228698979961901, 'label_smoothing': 0.0817414012880943, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(7)} -> 0.7562
2025-10-12 01:10:23,082 - INFO - bo.run_bo - üîçBO Trial 47: Using RF surrogate + Expected Improvement
2025-10-12 01:10:23,082 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-12 01:10:23,082 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:10:23,082 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 01:10:23,082 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004517665937421365, 'batch_size': 32, 'epochs': 29, 'weight_decay': 1.8343973326814637e-05, 'base_channels': 5, 'kernel_size': 13, 'dropout': 0.00699672084603763, 'amp': True, 'grad_clip_norm': 0.22544877728976004, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8503863946585484, 'label_smoothing': 0.03350775619231317, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 01:10:23,084 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004517665937421365, 'batch_size': 32, 'epochs': 29, 'weight_decay': 1.8343973326814637e-05, 'base_channels': 5, 'kernel_size': 13, 'dropout': 0.00699672084603763, 'amp': True, 'grad_clip_norm': 0.22544877728976004, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8503863946585484, 'label_smoothing': 0.03350775619231317, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}
2025-10-12 01:10:30,394 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.5229 | val_loss=0.4901 | val_acc=0.5837 | time=7.3s
2025-10-12 01:10:34,792 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.4401 | val_loss=0.4275 | val_acc=0.6166 | time=4.4s
2025-10-12 01:10:39,196 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4095 | val_loss=0.3925 | val_acc=0.6312 | time=4.4s
2025-10-12 01:10:43,597 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.3862 | val_loss=0.3738 | val_acc=0.6599 | time=4.4s
2025-10-12 01:10:47,997 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3670 | val_loss=0.3540 | val_acc=0.6648 | time=4.4s
2025-10-12 01:10:52,390 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3578 | val_loss=0.3502 | val_acc=0.6738 | time=4.4s
2025-10-12 01:10:56,804 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3451 | val_loss=0.3711 | val_acc=0.6536 | time=4.4s
2025-10-12 01:11:01,225 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3317 | val_loss=0.3314 | val_acc=0.6981 | time=4.4s
2025-10-12 01:11:05,629 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3258 | val_loss=0.3719 | val_acc=0.6839 | time=4.4s
2025-10-12 01:11:10,032 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3221 | val_loss=0.3168 | val_acc=0.7090 | time=4.4s
2025-10-12 01:11:14,436 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3162 | val_loss=0.3155 | val_acc=0.6877 | time=4.4s
2025-10-12 01:11:18,831 - INFO - _models.training_function_executor - Epoch 012 | train_loss=nan | val_loss=0.3126 | val_acc=0.6998 | time=4.4s
2025-10-12 01:11:23,270 - INFO - _models.training_function_executor - Epoch 013 | train_loss=nan | val_loss=0.3508 | val_acc=0.7044 | time=4.4s
2025-10-12 01:11:27,705 - INFO - _models.training_function_executor - Epoch 014 | train_loss=nan | val_loss=0.3107 | val_acc=0.7146 | time=4.4s
2025-10-12 01:11:32,125 - INFO - _models.training_function_executor - Epoch 015 | train_loss=nan | val_loss=0.3273 | val_acc=0.7134 | time=4.4s
2025-10-12 01:11:36,551 - INFO - _models.training_function_executor - Epoch 016 | train_loss=nan | val_loss=0.3152 | val_acc=0.7261 | time=4.4s
2025-10-12 01:11:40,938 - INFO - _models.training_function_executor - Epoch 017 | train_loss=nan | val_loss=0.3828 | val_acc=0.6060 | time=4.4s
2025-10-12 01:11:45,212 - INFO - _models.training_function_executor - Epoch 018 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.3s
2025-10-12 01:11:49,379 - INFO - _models.training_function_executor - Epoch 019 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:11:53,529 - INFO - _models.training_function_executor - Epoch 020 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:11:57,693 - INFO - _models.training_function_executor - Epoch 021 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:01,853 - INFO - _models.training_function_executor - Epoch 022 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:06,032 - INFO - _models.training_function_executor - Epoch 023 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:10,217 - INFO - _models.training_function_executor - Epoch 024 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:14,369 - INFO - _models.training_function_executor - Epoch 025 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:18,539 - INFO - _models.training_function_executor - Epoch 026 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:22,723 - INFO - _models.training_function_executor - Epoch 027 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:26,904 - INFO - _models.training_function_executor - Epoch 028 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:31,085 - INFO - _models.training_function_executor - Epoch 029 | train_loss=nan | val_loss=nan | val_acc=0.2325 | time=4.2s
2025-10-12 01:12:32,268 - INFO - _models.training_function_executor - Model: 1,015 parameters, 4.4KB storage
2025-10-12 01:12:32,268 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.522887002491634, 0.44012620966904975, 0.40953481002359476, 0.38621831044523425, 0.36703292320060765, 0.3578011493548553, 0.3451043705972781, 0.33170683233053055, 0.32582659464123537, 0.3221382429814155, 0.31622206617310966, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_losses': [0.4900760952404091, 0.4275078134163798, 0.39252649767938275, 0.373751957135993, 0.3539903477750011, 0.35017499015484443, 0.37109013815415637, 0.3314070629174483, 0.3719276394799102, 0.316825084846113, 0.31551944530001896, 0.31262244367399694, 0.3508100737323308, 0.3106886106205053, 0.3273461446915259, 0.31521627642006184, 0.3827877633648212, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_acc': [0.5837416870843543, 0.6166433321666084, 0.6311690584529226, 0.6598704935246762, 0.6647707385369268, 0.6737836891844592, 0.6535701785089254, 0.6981099054952747, 0.6839341967098355, 0.7090479523976199, 0.6876968848442422, 0.6997724886244312, 0.7044102205110255, 0.7145607280364018, 0.7134231711585579, 0.7261113055652783, 0.6059677983899195, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478, 0.2324991249562478], 'best_epoch': 16, 'total_params': 1015, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004517665937421365, 'batch_size': 32, 'epochs': 29, 'weight_decay': 1.8343973326814637e-05, 'base_channels': 5, 'kernel_size': 13, 'dropout': 0.00699672084603763, 'amp': True, 'grad_clip_norm': 0.22544877728976004, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8503863946585484, 'label_smoothing': 0.03350775619231317, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 8}, 'model_parameter_count': 1015, 'model_storage_size_kb': 4.361328125, 'model_size_validation': 'PASS'}
2025-10-12 01:12:32,268 - INFO - _models.training_function_executor - BO Objective: base=0.2325, size_penalty=0.0000, final=0.2325
2025-10-12 01:12:32,268 - INFO - _models.training_function_executor - Model: 1,015 parameters, 4.4KB (PASS 256KB limit)
2025-10-12 01:12:32,268 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 129.186s
2025-10-12 01:12:32,385 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2325
2025-10-12 01:12:32,385 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.114s
2025-10-12 01:12:32,385 - INFO - bo.run_bo - Recorded observation #47: hparams={'lr': 0.004517665937421365, 'batch_size': np.int64(32), 'epochs': np.int64(29), 'weight_decay': 1.8343973326814637e-05, 'base_channels': np.int64(5), 'kernel_size': np.int64(13), 'dropout': 0.00699672084603763, 'amp': np.True_, 'grad_clip_norm': 0.22544877728976004, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8503863946585484, 'label_smoothing': 0.03350775619231317, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}, value=0.2325
2025-10-12 01:12:32,385 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 47: {'lr': 0.004517665937421365, 'batch_size': np.int64(32), 'epochs': np.int64(29), 'weight_decay': 1.8343973326814637e-05, 'base_channels': np.int64(5), 'kernel_size': np.int64(13), 'dropout': 0.00699672084603763, 'amp': np.True_, 'grad_clip_norm': 0.22544877728976004, 'scheduler': np.str_('none'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8503863946585484, 'label_smoothing': 0.03350775619231317, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)} -> 0.2325
2025-10-12 01:12:32,385 - INFO - bo.run_bo - üîçBO Trial 48: Using RF surrogate + Expected Improvement
2025-10-12 01:12:32,385 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 01:12:32,385 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:12:32,385 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 01:12:32,386 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0047652735664032815, 'batch_size': 16, 'epochs': 24, 'weight_decay': 7.0267725732654226e-06, 'base_channels': 12, 'kernel_size': 4, 'dropout': 0.02065857207574259, 'amp': True, 'grad_clip_norm': 0.3413829004373166, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6238408389171264, 'label_smoothing': 0.022755311006000083, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}
2025-10-12 01:12:32,387 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0047652735664032815, 'batch_size': 16, 'epochs': 24, 'weight_decay': 7.0267725732654226e-06, 'base_channels': 12, 'kernel_size': 4, 'dropout': 0.02065857207574259, 'amp': True, 'grad_clip_norm': 0.3413829004373166, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6238408389171264, 'label_smoothing': 0.022755311006000083, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}
2025-10-12 01:12:42,018 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9747 | val_loss=0.7974 | val_acc=0.5401 | time=9.6s
2025-10-12 01:12:48,774 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7257 | val_loss=0.7368 | val_acc=0.5457 | time=6.8s
2025-10-12 01:12:55,623 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6481 | val_loss=0.6509 | val_acc=0.6021 | time=6.8s
2025-10-12 01:13:02,376 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6248 | val_loss=0.5882 | val_acc=0.6088 | time=6.8s
2025-10-12 01:13:09,112 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5917 | val_loss=0.5400 | val_acc=0.6392 | time=6.7s
2025-10-12 01:13:15,835 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5680 | val_loss=0.5605 | val_acc=0.6653 | time=6.7s
2025-10-12 01:13:22,616 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5253 | val_loss=0.4638 | val_acc=0.6982 | time=6.8s
2025-10-12 01:13:29,443 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4997 | val_loss=0.4826 | val_acc=0.6948 | time=6.8s
2025-10-12 01:13:36,266 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4906 | val_loss=0.5527 | val_acc=0.6877 | time=6.8s
2025-10-12 01:13:43,042 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4750 | val_loss=0.4357 | val_acc=0.7142 | time=6.8s
2025-10-12 01:13:49,785 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4648 | val_loss=0.4347 | val_acc=0.7209 | time=6.7s
2025-10-12 01:13:56,537 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4555 | val_loss=0.4690 | val_acc=0.7155 | time=6.8s
2025-10-12 01:14:03,279 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.4437 | val_loss=0.4481 | val_acc=0.7080 | time=6.7s
2025-10-12 01:14:10,038 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.4307 | val_loss=0.4757 | val_acc=0.7048 | time=6.8s
2025-10-12 01:14:16,820 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.4184 | val_loss=0.4190 | val_acc=0.7344 | time=6.8s
2025-10-12 01:14:23,568 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.4117 | val_loss=0.4158 | val_acc=0.7230 | time=6.7s
2025-10-12 01:14:30,323 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.4038 | val_loss=0.4018 | val_acc=0.7403 | time=6.8s
2025-10-12 01:14:37,097 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3947 | val_loss=0.3912 | val_acc=0.7483 | time=6.8s
2025-10-12 01:14:43,868 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3864 | val_loss=0.3863 | val_acc=0.7536 | time=6.8s
2025-10-12 01:14:50,641 - INFO - _models.training_function_executor - Epoch 020 | train_loss=nan | val_loss=0.3834 | val_acc=0.7543 | time=6.8s
2025-10-12 01:14:57,442 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3700 | val_loss=0.3769 | val_acc=0.7584 | time=6.8s
2025-10-12 01:15:04,193 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3670 | val_loss=0.3808 | val_acc=0.7527 | time=6.8s
2025-10-12 01:15:10,910 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3645 | val_loss=0.3771 | val_acc=0.7571 | time=6.7s
2025-10-12 01:15:17,657 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3582 | val_loss=0.3778 | val_acc=0.7569 | time=6.7s
2025-10-12 01:15:18,795 - INFO - _models.training_function_executor - Model: 1,883 parameters, 8.1KB storage
2025-10-12 01:15:18,795 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9747177607787002, 0.7257167670509387, 0.6481043588178409, 0.6247835453934798, 0.5917209096365055, 0.5680246890832545, 0.5253009545999179, 0.49972779741383616, 0.4905838328702157, 0.4750283690085351, 0.46484635131792834, 0.45552755562776986, 0.4436745980169688, 0.4307338943809928, 0.41837605318699345, 0.4116993726087401, 0.40379193431437327, 0.3947452727456192, 0.38641191919888074, nan, 0.3699523229797403, 0.3669778143150597, 0.36451699511768376, 0.35818448681534276], 'val_losses': [0.7973845398509419, 0.7367976371224944, 0.6509362440426033, 0.5881598211460181, 0.5399816710423756, 0.5604691522000553, 0.46384589995641806, 0.4826240409921099, 0.5527191121469844, 0.43573928630643793, 0.4347029733386907, 0.4689622482011368, 0.4480536956782941, 0.47571878119573724, 0.4189906783401966, 0.41575354996261066, 0.4018342064185576, 0.39115875419620033, 0.38626061624267716, 0.3834435303154942, 0.3768538264284184, 0.3808405357693042, 0.3770538576937222, 0.3778221281518886], 'val_acc': [0.5400770038501925, 0.5456772838641932, 0.6021176058802941, 0.6087679383969199, 0.6392194609730486, 0.6652957647882394, 0.6981974098704935, 0.6947847392369618, 0.6876968848442422, 0.7142107105355268, 0.7209485474273714, 0.7155232761638082, 0.7079978998949947, 0.7047602380119006, 0.7344242212110605, 0.7229611480574029, 0.7402870143507175, 0.7483374168708435, 0.7535876793839692, 0.7542877143857193, 0.758400420021001, 0.7527126356317816, 0.7570878543927196, 0.7569128456422821], 'best_epoch': 21, 'total_params': 1883, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0047652735664032815, 'batch_size': 16, 'epochs': 24, 'weight_decay': 7.0267725732654226e-06, 'base_channels': 12, 'kernel_size': 4, 'dropout': 0.02065857207574259, 'amp': True, 'grad_clip_norm': 0.3413829004373166, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6238408389171264, 'label_smoothing': 0.022755311006000083, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 6}, 'model_parameter_count': 1883, 'model_storage_size_kb': 8.091015625, 'model_size_validation': 'PASS'}
2025-10-12 01:15:18,795 - INFO - _models.training_function_executor - BO Objective: base=0.7569, size_penalty=0.0000, final=0.7569
2025-10-12 01:15:18,795 - INFO - _models.training_function_executor - Model: 1,883 parameters, 8.1KB (PASS 256KB limit)
2025-10-12 01:15:18,795 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 166.410s
2025-10-12 01:15:19,061 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7569
2025-10-12 01:15:19,062 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.264s
2025-10-12 01:15:19,062 - INFO - bo.run_bo - Recorded observation #48: hparams={'lr': 0.0047652735664032815, 'batch_size': np.int64(16), 'epochs': np.int64(24), 'weight_decay': 7.0267725732654226e-06, 'base_channels': np.int64(12), 'kernel_size': np.int64(4), 'dropout': 0.02065857207574259, 'amp': np.True_, 'grad_clip_norm': 0.3413829004373166, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6238408389171264, 'label_smoothing': 0.022755311006000083, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(6)}, value=0.7569
2025-10-12 01:15:19,062 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 48: {'lr': 0.0047652735664032815, 'batch_size': np.int64(16), 'epochs': np.int64(24), 'weight_decay': 7.0267725732654226e-06, 'base_channels': np.int64(12), 'kernel_size': np.int64(4), 'dropout': 0.02065857207574259, 'amp': np.True_, 'grad_clip_norm': 0.3413829004373166, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 1.6238408389171264, 'label_smoothing': 0.022755311006000083, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(6)} -> 0.7569
2025-10-12 01:15:19,062 - INFO - bo.run_bo - üîçBO Trial 49: Using RF surrogate + Expected Improvement
2025-10-12 01:15:19,062 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 01:15:19,062 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:15:19,062 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 01:15:19,062 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004834717551434, 'batch_size': 16, 'epochs': 23, 'weight_decay': 0.0005009231437921103, 'base_channels': 13, 'kernel_size': 11, 'dropout': 0.027153726108088787, 'amp': False, 'grad_clip_norm': 0.9236585501355482, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.5224890972552743, 'label_smoothing': 0.1872498406241752, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 2}
2025-10-12 01:15:19,064 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004834717551434, 'batch_size': 16, 'epochs': 23, 'weight_decay': 0.0005009231437921103, 'base_channels': 13, 'kernel_size': 11, 'dropout': 0.027153726108088787, 'amp': False, 'grad_clip_norm': 0.9236585501355482, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.5224890972552743, 'label_smoothing': 0.1872498406241752, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 2}
2025-10-12 01:15:28,731 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.6696 | val_loss=0.5659 | val_acc=0.5732 | time=9.7s
2025-10-12 01:15:35,583 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5547 | val_loss=0.4977 | val_acc=0.6010 | time=6.9s
2025-10-12 01:15:42,422 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4880 | val_loss=0.4508 | val_acc=0.6358 | time=6.8s
2025-10-12 01:15:49,280 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4187 | val_loss=0.3746 | val_acc=0.6981 | time=6.9s
2025-10-12 01:15:56,119 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3902 | val_loss=0.3328 | val_acc=0.7027 | time=6.8s
2025-10-12 01:16:02,962 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3815 | val_loss=0.3738 | val_acc=0.6892 | time=6.8s
2025-10-12 01:16:09,832 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3693 | val_loss=0.3585 | val_acc=0.6956 | time=6.9s
2025-10-12 01:16:16,696 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3609 | val_loss=0.3827 | val_acc=0.6985 | time=6.9s
2025-10-12 01:16:23,549 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3539 | val_loss=0.3221 | val_acc=0.7221 | time=6.9s
2025-10-12 01:16:30,408 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3540 | val_loss=0.3414 | val_acc=0.7210 | time=6.9s
2025-10-12 01:16:37,230 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3423 | val_loss=0.3264 | val_acc=0.7348 | time=6.8s
2025-10-12 01:16:44,065 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3346 | val_loss=0.2986 | val_acc=0.7282 | time=6.8s
2025-10-12 01:16:50,939 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3243 | val_loss=0.3477 | val_acc=0.7282 | time=6.9s
2025-10-12 01:16:57,767 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3185 | val_loss=0.3062 | val_acc=0.7412 | time=6.8s
2025-10-12 01:17:04,611 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3151 | val_loss=0.2999 | val_acc=0.7477 | time=6.8s
2025-10-12 01:17:11,443 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3058 | val_loss=0.2880 | val_acc=0.7419 | time=6.8s
2025-10-12 01:17:18,274 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.2947 | val_loss=0.2839 | val_acc=0.7536 | time=6.8s
2025-10-12 01:17:25,107 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.2906 | val_loss=0.2917 | val_acc=0.7538 | time=6.8s
2025-10-12 01:17:31,923 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.2809 | val_loss=0.2944 | val_acc=0.7489 | time=6.8s
2025-10-12 01:17:38,757 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.2784 | val_loss=0.2858 | val_acc=0.7556 | time=6.8s
2025-10-12 01:17:45,577 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.2710 | val_loss=0.2816 | val_acc=0.7582 | time=6.8s
2025-10-12 01:17:52,412 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.2685 | val_loss=0.2797 | val_acc=0.7609 | time=6.8s
2025-10-12 01:17:59,256 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.2665 | val_loss=0.2805 | val_acc=0.7616 | time=6.8s
2025-10-12 01:17:59,260 - INFO - _models.training_function_executor - Quantization failed (quantized::linear_prepack_fp16 is currently not supported by QNNPACK); returning FP32 CPU model.
2025-10-12 01:18:00,425 - INFO - _models.training_function_executor - Model: 2,547 parameters, 5.5KB storage
2025-10-12 01:18:00,426 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.6695516953622289, 0.5547245147712672, 0.4880482519099585, 0.4187190528981202, 0.39022875092545506, 0.38151102062962794, 0.36934902263550357, 0.3609456945566665, 0.3539265663039342, 0.35399277166241444, 0.34234907991446145, 0.3345694123973661, 0.3242698510405293, 0.31852611286861, 0.3150820930579356, 0.30581046813381146, 0.29474622898043706, 0.29058870835256484, 0.2808886366020425, 0.2783988270984221, 0.27103820758896835, 0.26851681718067516, 0.2665287839639299], 'val_losses': [0.5659036355418758, 0.49765171058528074, 0.4507699464167748, 0.37461564379346957, 0.3328168017229625, 0.3737670905523367, 0.3585180708370009, 0.38270574704958843, 0.3220987140142417, 0.34141340174458246, 0.32637199545344275, 0.2986289151586019, 0.34773483289392676, 0.3062085520971071, 0.2998622720058148, 0.28796481942380225, 0.2838624497940699, 0.29168494885618035, 0.2943838242102753, 0.2858318724754182, 0.2816152122757443, 0.27974530810399073, 0.28050094707966683], 'val_acc': [0.5731536576828842, 0.6009800490024502, 0.6358067903395169, 0.6981099054952747, 0.7027476373818691, 0.6891844592229611, 0.6955722786139307, 0.6985474273713685, 0.7220861043052152, 0.7210360518025901, 0.7347742387119356, 0.7282114105705285, 0.7282114105705285, 0.7411620581029051, 0.7477248862443122, 0.741949597479874, 0.7535876793839692, 0.7537626881344067, 0.7488624431221561, 0.7556002800140007, 0.7582254112705635, 0.7609380469023451, 0.7615505775288764], 'best_epoch': 23, 'total_params': 2547, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004834717551434, 'batch_size': 16, 'epochs': 23, 'weight_decay': 0.0005009231437921103, 'base_channels': 13, 'kernel_size': 11, 'dropout': 0.027153726108088787, 'amp': False, 'grad_clip_norm': 0.9236585501355482, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.5224890972552743, 'label_smoothing': 0.1872498406241752, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 2}, 'model_parameter_count': 2547, 'model_storage_size_kb': 5.4720703125000005, 'model_size_validation': 'PASS'}
2025-10-12 01:18:00,426 - INFO - _models.training_function_executor - BO Objective: base=0.7616, size_penalty=0.0000, final=0.7616
2025-10-12 01:18:00,426 - INFO - _models.training_function_executor - Model: 2,547 parameters, 5.5KB (PASS 256KB limit)
2025-10-12 01:18:00,426 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 161.363s
2025-10-12 01:18:00,543 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7616
2025-10-12 01:18:00,543 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.115s
2025-10-12 01:18:00,543 - INFO - bo.run_bo - Recorded observation #49: hparams={'lr': 0.004834717551434, 'batch_size': np.int64(16), 'epochs': np.int64(23), 'weight_decay': 0.0005009231437921103, 'base_channels': np.int64(13), 'kernel_size': np.int64(11), 'dropout': 0.027153726108088787, 'amp': np.False_, 'grad_clip_norm': 0.9236585501355482, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.5224890972552743, 'label_smoothing': 0.1872498406241752, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(2)}, value=0.7616
2025-10-12 01:18:00,543 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 49: {'lr': 0.004834717551434, 'batch_size': np.int64(16), 'epochs': np.int64(23), 'weight_decay': 0.0005009231437921103, 'base_channels': np.int64(13), 'kernel_size': np.int64(11), 'dropout': 0.027153726108088787, 'amp': np.False_, 'grad_clip_norm': 0.9236585501355482, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.5224890972552743, 'label_smoothing': 0.1872498406241752, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(2)} -> 0.7616
2025-10-12 01:18:00,544 - INFO - bo.run_bo - üîçBO Trial 50: Using RF surrogate + Expected Improvement
2025-10-12 01:18:00,544 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-12 01:18:00,544 - INFO - _models.training_function_executor - Using device: cuda
2025-10-12 01:18:00,544 - INFO - _models.training_function_executor - Executing training function: ST-USleepNet-Tiny-1D-Graph
2025-10-12 01:18:00,544 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004262079822912969, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.0009205383238064e-05, 'base_channels': 15, 'kernel_size': 10, 'dropout': 0.018499689611800055, 'amp': True, 'grad_clip_norm': 0.3380664532579964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8238865830969253, 'label_smoothing': 0.07397514971936985, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-12 01:18:00,545 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004262079822912969, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.0009205383238064e-05, 'base_channels': 15, 'kernel_size': 10, 'dropout': 0.018499689611800055, 'amp': True, 'grad_clip_norm': 0.3380664532579964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8238865830969253, 'label_smoothing': 0.07397514971936985, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}
2025-10-12 01:18:09,247 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.1213 | val_loss=0.7404 | val_acc=0.4401 | time=8.7s
2025-10-12 01:18:15,082 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.6259 | val_loss=0.5553 | val_acc=0.5464 | time=5.8s
2025-10-12 01:18:20,921 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5092 | val_loss=0.4799 | val_acc=0.5760 | time=5.8s
2025-10-12 01:18:26,763 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4762 | val_loss=0.4444 | val_acc=0.5950 | time=5.8s
2025-10-12 01:18:32,600 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4392 | val_loss=0.4195 | val_acc=0.6401 | time=5.8s
2025-10-12 01:18:38,436 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3969 | val_loss=0.3615 | val_acc=0.6493 | time=5.8s
2025-10-12 01:18:44,277 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3726 | val_loss=0.3540 | val_acc=0.6801 | time=5.8s
2025-10-12 01:18:50,124 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3512 | val_loss=0.3174 | val_acc=0.7048 | time=5.8s
2025-10-12 01:18:55,968 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3375 | val_loss=0.3391 | val_acc=0.6851 | time=5.8s
2025-10-12 01:19:01,802 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3290 | val_loss=0.2923 | val_acc=0.7202 | time=5.8s
2025-10-12 01:19:07,646 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3166 | val_loss=0.2846 | val_acc=0.7215 | time=5.8s
2025-10-12 01:19:13,497 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3069 | val_loss=0.5896 | val_acc=0.5427 | time=5.8s
2025-10-12 01:19:19,334 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3032 | val_loss=0.2872 | val_acc=0.7050 | time=5.8s
2025-10-12 01:19:25,161 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.2884 | val_loss=0.2850 | val_acc=0.7161 | time=5.8s
2025-10-12 01:19:31,000 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.2910 | val_loss=0.2694 | val_acc=0.7366 | time=5.8s
2025-10-12 01:19:36,831 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.2856 | val_loss=0.2713 | val_acc=0.7192 | time=5.8s
2025-10-12 01:19:42,665 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.2839 | val_loss=0.2688 | val_acc=0.7198 | time=5.8s
2025-10-12 01:19:48,498 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.2784 | val_loss=0.2586 | val_acc=0.7398 | time=5.8s
2025-10-12 01:19:54,345 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.2745 | val_loss=0.3265 | val_acc=0.6849 | time=5.8s
2025-10-12 01:20:00,194 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.2707 | val_loss=0.3115 | val_acc=0.7103 | time=5.8s
2025-10-12 01:20:06,032 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.2707 | val_loss=0.2712 | val_acc=0.7408 | time=5.8s
2025-10-12 01:20:11,871 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.2623 | val_loss=0.3006 | val_acc=0.7308 | time=5.8s
2025-10-12 01:20:17,713 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.2580 | val_loss=0.3005 | val_acc=0.7095 | time=5.8s
2025-10-12 01:20:23,548 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.2563 | val_loss=0.2640 | val_acc=0.7327 | time=5.8s
2025-10-12 01:20:29,383 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.2549 | val_loss=0.2675 | val_acc=0.7391 | time=5.8s
2025-10-12 01:20:35,221 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.2497 | val_loss=0.2524 | val_acc=0.7380 | time=5.8s
2025-10-12 01:20:41,055 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.2480 | val_loss=0.2464 | val_acc=0.7461 | time=5.8s
2025-10-12 01:20:46,895 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.2450 | val_loss=0.2504 | val_acc=0.7524 | time=5.8s
2025-10-12 01:20:52,733 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.2431 | val_loss=0.2467 | val_acc=0.7545 | time=5.8s
2025-10-12 01:20:58,571 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.2390 | val_loss=0.2458 | val_acc=0.7462 | time=5.8s
2025-10-12 01:21:04,415 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.2361 | val_loss=0.2530 | val_acc=0.7467 | time=5.8s
2025-10-12 01:21:10,256 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.2363 | val_loss=0.2437 | val_acc=0.7525 | time=5.8s
2025-10-12 01:21:16,100 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.2304 | val_loss=0.2464 | val_acc=0.7477 | time=5.8s
2025-10-12 01:21:21,930 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.2273 | val_loss=0.2496 | val_acc=0.7593 | time=5.8s
2025-10-12 01:21:27,764 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.2243 | val_loss=0.2426 | val_acc=0.7553 | time=5.8s
2025-10-12 01:21:33,611 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.2226 | val_loss=0.2372 | val_acc=0.7564 | time=5.8s
2025-10-12 01:21:39,449 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.2203 | val_loss=0.2421 | val_acc=0.7556 | time=5.8s
2025-10-12 01:21:45,294 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.2172 | val_loss=0.2353 | val_acc=0.7562 | time=5.8s
2025-10-12 01:21:51,134 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.2152 | val_loss=0.2370 | val_acc=0.7588 | time=5.8s
2025-10-12 01:21:56,976 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.2127 | val_loss=0.2353 | val_acc=0.7633 | time=5.8s
2025-10-12 01:22:02,811 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.2121 | val_loss=0.2357 | val_acc=0.7584 | time=5.8s
2025-10-12 01:22:08,643 - INFO - _models.training_function_executor - Epoch 042 | train_loss=nan | val_loss=0.2334 | val_acc=0.7624 | time=5.8s
2025-10-12 01:22:14,472 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.2090 | val_loss=0.2345 | val_acc=0.7608 | time=5.8s
2025-10-12 01:22:20,309 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.2081 | val_loss=0.2337 | val_acc=0.7613 | time=5.8s
2025-10-12 01:22:26,136 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.2076 | val_loss=0.2335 | val_acc=0.7620 | time=5.8s
2025-10-12 01:22:31,978 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.2066 | val_loss=0.2336 | val_acc=0.7619 | time=5.8s
2025-10-12 01:22:31,985 - INFO - _models.training_function_executor - Quantization failed (cannot assign 'torch.fx.graph.Graph' as child module 'graph' (torch.nn.Module or None expected)); returning FP32 CPU model.
2025-10-12 01:22:33,141 - INFO - _models.training_function_executor - Model: 3,071 parameters, 3.3KB storage
2025-10-12 01:22:33,141 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1213276061144741, 0.6259423746929302, 0.5092486661630911, 0.47619178424348363, 0.43922128468960314, 0.396941480353162, 0.37262270731942637, 0.35122710207959157, 0.33745444475354014, 0.3289850831657023, 0.31656485695938963, 0.30693149593743413, 0.30324476821856067, 0.2883661995400916, 0.29095635335970593, 0.28562570212187466, 0.2839115391869645, 0.27839978891652783, 0.2744700137135032, 0.2706835436341646, 0.27069392607553855, 0.26234907739229135, 0.25804724617229474, 0.2563224085977861, 0.2548508027425179, 0.2497029040243242, 0.24798395629529352, 0.24502604397443625, 0.24309074505642578, 0.2390282383123478, 0.23605440929011032, 0.23628842163752842, 0.23042556121424362, 0.22732023842684873, 0.22427288058337633, 0.2226187043152489, 0.22028528224755, 0.2172497023339872, 0.2152196334375368, 0.21268951917861725, 0.21212389637957085, nan, 0.20902896527643805, 0.20812896298361824, 0.20760009407580315, 0.2065930289613617], 'val_losses': [0.7404371443407496, 0.5553099323251394, 0.4798795953809216, 0.4443937441823203, 0.4194848000503785, 0.3615048445303347, 0.35400819645247644, 0.3174379582844633, 0.3390844251190484, 0.2923449862269716, 0.28456486761569977, 0.5895688485499867, 0.28718075306055935, 0.2849764101332126, 0.2694246141271218, 0.2713423728443391, 0.26884643433813277, 0.25855800709244925, 0.3265438643414215, 0.31153987156612245, 0.27118025778392174, 0.300629762880629, 0.3005032264653531, 0.26398972376098845, 0.26745717385627704, 0.2524037466035875, 0.24637573574508367, 0.2503661245274144, 0.24672387652723482, 0.24579914675911047, 0.2529746532107199, 0.2437454158200898, 0.24642879420152589, 0.24964017058883967, 0.24256296447535466, 0.23719900267916685, 0.24205533531624512, 0.2352692286312247, 0.23701490499287345, 0.23525931049325613, 0.23566566524225907, 0.23335569102171413, 0.23446323518646495, 0.2337264065635937, 0.2334924406429243, 0.2336456073063046], 'val_acc': [0.4401470073503675, 0.5463773188659433, 0.5759537976898845, 0.5950297514875744, 0.6400945047252362, 0.6492824641232061, 0.68008400420021, 0.7047602380119006, 0.6850717535876794, 0.7201610080504025, 0.7214735736786839, 0.5427021351067554, 0.7050227511375569, 0.7161358067903395, 0.7366118305915296, 0.7191984599229961, 0.7198109905495275, 0.7398494924746237, 0.6848967448372418, 0.7102730136506825, 0.7408120406020301, 0.7308365418270913, 0.7094854742737137, 0.7326741337066853, 0.7390619530976549, 0.7380119005950297, 0.7460623031151558, 0.7523626181309065, 0.7544627231361568, 0.7462373118655933, 0.7466748337416871, 0.7524501225061253, 0.7477248862443122, 0.7592754637731887, 0.7552502625131257, 0.7563878193909696, 0.7556002800140007, 0.756212810640532, 0.7587504375218761, 0.7633006650332517, 0.758400420021001, 0.7624256212810641, 0.7607630381519076, 0.7612880644032202, 0.7619880994049703, 0.7619005950297515], 'best_epoch': 40, 'total_params': 3071, 'model_name': 'ST-USleepNet-Tiny-1D-Graph', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004262079822912969, 'batch_size': 64, 'epochs': 46, 'weight_decay': 1.0009205383238064e-05, 'base_channels': 15, 'kernel_size': 10, 'dropout': 0.018499689611800055, 'amp': True, 'grad_clip_norm': 0.3380664532579964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8238865830969253, 'label_smoothing': 0.07397514971936985, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': 4}, 'model_parameter_count': 3071, 'model_storage_size_kb': 3.2989257812500004, 'model_size_validation': 'PASS'}
2025-10-12 01:22:33,141 - INFO - _models.training_function_executor - BO Objective: base=0.7619, size_penalty=0.0000, final=0.7619
2025-10-12 01:22:33,141 - INFO - _models.training_function_executor - Model: 3,071 parameters, 3.3KB (PASS 256KB limit)
2025-10-12 01:22:33,141 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 272.598s
2025-10-12 01:22:33,268 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7619
2025-10-12 01:22:33,268 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.119s
2025-10-12 01:22:33,268 - INFO - bo.run_bo - Recorded observation #50: hparams={'lr': 0.004262079822912969, 'batch_size': np.int64(64), 'epochs': np.int64(46), 'weight_decay': 1.0009205383238064e-05, 'base_channels': np.int64(15), 'kernel_size': np.int64(10), 'dropout': 0.018499689611800055, 'amp': np.True_, 'grad_clip_norm': 0.3380664532579964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8238865830969253, 'label_smoothing': 0.07397514971936985, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)}, value=0.7619
2025-10-12 01:22:33,268 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 50: {'lr': 0.004262079822912969, 'batch_size': np.int64(64), 'epochs': np.int64(46), 'weight_decay': 1.0009205383238064e-05, 'base_channels': np.int64(15), 'kernel_size': np.int64(10), 'dropout': 0.018499689611800055, 'amp': np.True_, 'grad_clip_norm': 0.3380664532579964, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.8238865830969253, 'label_smoothing': 0.07397514971936985, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(4)} -> 0.7619
2025-10-12 01:22:33,269 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.7680
2025-10-12 01:22:33,269 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.003909924237406688, 'batch_size': np.int64(16), 'epochs': np.int64(41), 'weight_decay': 1.4872337209221627e-05, 'base_channels': np.int64(16), 'kernel_size': np.int64(10), 'dropout': 0.009781176842976292, 'amp': np.False_, 'grad_clip_norm': 0.2753273495460478, 'scheduler': np.str_('onecycle'), 'imbalance_mode': np.str_('focal'), 'focal_gamma': 2.382692692661525, 'label_smoothing': 0.18947983872452515, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_, 'quant_backend': np.str_('qnnpack'), 'calibration_batches': np.int64(8)}
2025-10-12 01:22:33,281 - INFO - visualization - Generating BO visualization charts with 50 trials...
2025-10-12 01:22:34,570 - INFO - visualization - BO summary saved to: charts/20251012_012233_BO_ST-USleepNet-Tiny-1D-Graph/bo_summary.txt
2025-10-12 01:22:34,573 - ERROR - evaluation.code_generation_pipeline_orchestrator - Failed to generate BO charts: Object of type int64 is not JSON serializable
2025-10-12 01:22:34,631 - INFO - evaluation.code_generation_pipeline_orchestrator - üöÄ STEP 4: Final Training Execution
2025-10-12 01:22:34,631 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (57140, 6, 6000), Val: (14286, 6, 6000), Test: (17857, 6, 6000)
