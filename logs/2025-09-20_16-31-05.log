2025-09-20 16:31:07,021 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti Laptop GPU
2025-09-20 16:31:07,395 - INFO - __main__ - Logging system initialized successfully
2025-09-20 16:31:07,396 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-09-20 16:31:07,396 - INFO - __main__ - Starting real data processing from data/ directory
2025-09-20 16:31:07,397 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'X.npy', 'y.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-09-20 16:31:07,397 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-09-20 16:31:07,397 - INFO - __main__ - Attempting to load: X.npy
2025-09-20 16:31:07,528 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-09-20 16:31:07,619 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (62352, 1000, 2), device: cuda
2025-09-20 16:31:07,620 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-09-20 16:31:07,620 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-09-20 16:31:07,620 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-09-20 16:31:07,622 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-20 16:31:07,622 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-09-20 16:31:07,622 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-09-20 16:31:07,622 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-09-20 16:31:07,622 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-09-20 16:31:07,623 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-09-20 16:31:07,623 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-09-20 16:31:07,623 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-09-20 16:31:07,623 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-09-20 16:31:07,840 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-09-20 16:31:07,840 - INFO - class_balancing - Class imbalance analysis:
2025-09-20 16:31:07,840 - INFO - class_balancing -   Strategy: severe_imbalance
2025-09-20 16:31:07,840 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-09-20 16:31:07,840 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-09-20 16:31:07,840 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-09-20 16:31:07,841 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-09-20 16:31:07,841 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-09-20 16:31:07,841 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-09-20 16:31:07,841 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-09-20 16:31:08,587 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-09-20 16:31:08,596 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-09-20 16:31:08,597 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-09-20 16:31:08,597 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-09-20 16:31:08,597 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-09-20 16:31:08,597 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-09-20 16:31:08,597 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-09-20 16:31:08,597 - INFO - _models.ai_code_generator - Prompt length: 2552 characters
2025-09-20 16:31:08,597 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-09-20 16:31:08,597 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-09-20 16:31:08,597 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-09-20 16:32:33,568 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-09-20 16:32:33,609 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-09-20 16:32:33,609 - INFO - _models.ai_code_generator - AI generated training function: LightMLP-Arrhythmia-PTQ
2025-09-20 16:32:33,609 - INFO - _models.ai_code_generator - Confidence: 0.90
2025-09-20 16:32:33,609 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: LightMLP-Arrhythmia-PTQ
2025-09-20 16:32:33,609 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'hidden_dim1', 'hidden_dim2', 'hidden_dim3', 'dropout', 'weight_decay', 'grad_clip_norm', 'use_scheduler', 'step_size', 'gamma', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_batches', 'seed']
2025-09-20 16:32:33,609 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.90
2025-09-20 16:32:33,612 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-09-20 16:32:33,615 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions\training_function_torch_tensor_LightMLP-Arrhythmia-PTQ_1758403953.json
2025-09-20 16:32:33,615 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions\training_function_torch_tensor_LightMLP-Arrhythmia-PTQ_1758403953.json
2025-09-20 16:32:33,615 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-09-20 16:32:33,615 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: LightMLP-Arrhythmia-PTQ
2025-09-20 16:32:33,615 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-09-20 16:32:33,615 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-09-20 16:32:33,615 - WARNING - package_installer - Could not parse code for imports due to syntax error: unexpected character after line continuation character (<unknown>, line 1)
2025-09-20 16:32:33,616 - INFO - package_installer - Extracted imports from code: set()
2025-09-20 16:32:33,616 - INFO - package_installer - ‚úÖ No external packages required
2025-09-20 16:32:33,616 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-09-20 16:32:33,698 - INFO - data_splitting - Created BO subset: 5000 samples
2025-09-20 16:32:33,698 - INFO - data_splitting - BO subset class distribution: [3600  766   96  100  438]
2025-09-20 16:32:33,698 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 5000 samples (using bo_sample_num=5000)
2025-09-20 16:32:33,698 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'hidden_dim1', 'hidden_dim2', 'hidden_dim3', 'dropout', 'weight_decay', 'grad_clip_norm', 'use_scheduler', 'step_size', 'gamma', 'quantization_bits', 'quantize_weights', 'quantize_activations', 'calibration_batches', 'seed']
2025-09-20 16:32:33,699 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti Laptop GPU
2025-09-20 16:32:33,783 - INFO - data_splitting - Created BO subset: 5000 samples
2025-09-20 16:32:33,784 - INFO - data_splitting - BO subset class distribution: [3600  766   96  100  438]
2025-09-20 16:32:33,784 - INFO - _models.training_function_executor - Using BO subset for optimization: 5000 samples (bo_sample_num=5000)
2025-09-20 16:32:33,794 - INFO - _models.training_function_executor - BO splits - Train: 4000, Val: 1000
2025-09-20 16:32:34,068 - INFO - bo.run_bo - Converted GPT search space: 17 parameters
2025-09-20 16:32:34,068 - INFO - bo.run_bo - Using GPT-generated search space
2025-09-20 16:32:34,069 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-09-20 16:32:34,070 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-09-20 16:32:34,070 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-20 16:32:34,070 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 16:32:34,070 - INFO - _models.training_function_executor - Executing training function: LightMLP-Arrhythmia-PTQ
2025-09-20 16:32:34,070 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': 76, 'hidden_dim1': 76, 'hidden_dim2': 36, 'hidden_dim3': 46, 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': 12, 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 6, 'seed': 3344769}
2025-09-20 16:32:34,072 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': 76, 'hidden_dim1': 76, 'hidden_dim2': 36, 'hidden_dim3': 46, 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': 12, 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 6, 'seed': 3344769}
2025-09-20 16:32:52,052 - INFO - _models.training_function_executor - Model parameter count: 156,785
2025-09-20 16:32:52,052 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0682484731674193, 0.909706695318222, 0.8530737676620483, 0.8224844534397125, 0.8261524636745453, 0.8150945601463317, 0.8128508415222168, 0.784170883178711, 0.7804885351657868, 0.7726649448871613, 0.7572955925464631, 0.7577561802864075, 0.7406702597141266, 0.7431824653148651, 0.7252018775939941, 0.7078662006855011, 0.6942144448757172, 0.7002660119533539, 0.6954471848011017, 0.7058368813991547, 0.6904045503139495, 0.7036382095813751, 0.6968603492975235, 0.6740532550811767, 0.6882075223922729, 0.6849905946254731, 0.6528615520000458, 0.6568868463039398, 0.6549739167690277, 0.6349215871095657, 0.6381072580814362, 0.6309191305637359, 0.6379634870290756, 0.6310428667068482, 0.629674256324768, 0.6473388392925262, 0.6117134492397308, 0.6076911065578461, 0.5956524695158005, 0.6025842554569244, 0.5850030033588409, 0.5874548283815384, 0.5692977548837662, 0.5775593081712723, 0.567509644985199, 0.5728851450681687, 0.5699870128631592, 0.5599677498340607, 0.5597787573337555, 0.5539999952316285, 0.5553346534967423, 0.5466565738916397, 0.5467076836824417, 0.5256738164424897, 0.5302993767261505, 0.5337884246110917, 0.542062377333641, 0.5218618903160095, 0.5100338181257248, 0.531488790154457, 0.5229829597473145, 0.5125900346040726, 0.5138150498867035, 0.5132235187292099, 0.5035321964025498, 0.5234296309947968, 0.49926701867580414, 0.5083463793992996, 0.508745877623558, 0.49888800585269927, 0.48942290818691253, 0.49264698469638823, 0.4961598641872406, 0.5129330310821533, 0.48018178510665893, 0.4905752658843994], 'val_losses': [0.8214086461067199, 0.8107976641654968, 0.7440131015777588, 0.7495807409286499, 0.7573290510177613, 0.733795684337616, 0.7320515871047973, 0.7084641966819764, 0.739519492149353, 0.7249019298553466, 0.7029472532272338, 0.6948770895004273, 0.7287000412940979, 0.7283016481399536, 0.6893439483642578, 0.6876684150695801, 0.6795024404525757, 0.6854659261703491, 0.6917483215332031, 0.6993417239189148, 0.7020963177680969, 0.7428040781021118, 0.6879987983703614, 0.6839779462814332, 0.6623065075874328, 0.7140251860618592, 0.6779627871513366, 0.6729112000465393, 0.6830520219802857, 0.699315857887268, 0.6865231518745423, 0.6837679643630982, 0.7196575260162353, 0.7033125162124634, 0.696944845199585, 0.6864412279129029, 0.6778332295417786, 0.6891568970680236, 0.7064377069473267, 0.7187585215568543, 0.7620279731750488, 0.7865251569747925, 0.8196339268684387, 0.8107172746658325, 0.7692254190444946, 0.8641059942245484, 0.8953018779754639, 0.9135840702056884, 0.9475586414337158, 0.9764939556121827, 0.9155655002593994, 0.9323516340255738, 0.9209983959197998, 0.9766628265380859, 0.935755407333374, 0.9705657014846801, 0.9516960229873658, 1.0517469921112061, 1.0908718347549438, 0.9919021739959717, 1.0096918420791625, 1.1000868806838988, 1.1759325876235962, 1.3089286766052246, 1.087736029624939, 1.1208888072967529, 1.1119585189819337, 1.022885524749756, 1.0726864709854127, 1.1136267929077148, 1.2058558082580566, 1.3064999341964723, 1.3281718578338624, 1.2328129873275757, 1.2015940313339233, 1.2337972145080567], 'val_acc': [0.753, 0.74, 0.756, 0.759, 0.766, 0.772, 0.767, 0.775, 0.77, 0.772, 0.777, 0.778, 0.777, 0.775, 0.778, 0.782, 0.781, 0.783, 0.781, 0.78, 0.779, 0.777, 0.776, 0.78, 0.785, 0.783, 0.796, 0.795, 0.788, 0.791, 0.79, 0.792, 0.788, 0.797, 0.798, 0.795, 0.792, 0.793, 0.789, 0.791, 0.791, 0.792, 0.795, 0.791, 0.799, 0.797, 0.79, 0.785, 0.79, 0.789, 0.792, 0.792, 0.796, 0.79, 0.8, 0.8, 0.793, 0.793, 0.796, 0.8, 0.794, 0.789, 0.793, 0.78, 0.792, 0.79, 0.792, 0.79, 0.787, 0.788, 0.793, 0.787, 0.788, 0.791, 0.791, 0.792], 'param_count_before': 156785, 'param_count_after': 156785, 'config': {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': 76, 'hidden_dim1': 76, 'hidden_dim2': 36, 'hidden_dim3': 46, 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': 12, 'gamma': 0.7301845942384806, 'seed': 3344769, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 6}, 'model_name': 'LightMLP-Arrhythmia-PTQ', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': 76, 'hidden_dim1': 76, 'hidden_dim2': 36, 'hidden_dim3': 46, 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': 12, 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 6, 'seed': 3344769}, 'model_parameter_count': 156785, 'model_size_validation': 'PASS'}
2025-09-20 16:32:52,052 - INFO - _models.training_function_executor - BO Objective: base=0.7920, size_penalty=0.0000, final=0.7920
2025-09-20 16:32:52,053 - INFO - _models.training_function_executor - Model size: 156,785 parameters (PASS 256K limit)
2025-09-20 16:32:52,053 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 17.983s
2025-09-20 16:32:52,053 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7920
2025-09-20 16:32:52,053 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-09-20 16:32:52,053 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': np.int64(76), 'hidden_dim1': np.int64(76), 'hidden_dim2': np.int64(36), 'hidden_dim3': np.int64(46), 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': np.int64(12), 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(6), 'seed': np.int64(3344769)}, value=0.7920
2025-09-20 16:32:52,053 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': np.int64(76), 'hidden_dim1': np.int64(76), 'hidden_dim2': np.int64(36), 'hidden_dim3': np.int64(46), 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': np.int64(12), 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(6), 'seed': np.int64(3344769)} -> 0.7920
2025-09-20 16:32:52,053 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-09-20 16:32:52,053 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-09-20 16:32:52,055 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 16:32:52,055 - INFO - _models.training_function_executor - Executing training function: LightMLP-Arrhythmia-PTQ
2025-09-20 16:32:52,055 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 8.111941985431925e-06, 'batch_size': 32, 'epochs': 80, 'hidden_dim1': 73, 'hidden_dim2': 37, 'hidden_dim3': 51, 'dropout': 0.01153121252070788, 'weight_decay': 1.4081468939305824e-05, 'grad_clip_norm': 1.9993048585762778, 'use_scheduler': True, 'step_size': 16, 'gamma': 0.42606204053138563, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_batches': 20, 'seed': 396917567}
2025-09-20 16:32:52,056 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 8.111941985431925e-06, 'batch_size': 32, 'epochs': 80, 'hidden_dim1': 73, 'hidden_dim2': 37, 'hidden_dim3': 51, 'dropout': 0.01153121252070788, 'weight_decay': 1.4081468939305824e-05, 'grad_clip_norm': 1.9993048585762778, 'use_scheduler': True, 'step_size': 16, 'gamma': 0.42606204053138563, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_batches': 20, 'seed': 396917567}
2025-09-20 16:33:09,458 - INFO - _models.training_function_executor - Model parameter count: 151,009
2025-09-20 16:33:09,458 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5000641908645629, 1.4004330711364745, 1.302610276222229, 1.2028470191955567, 1.1239429721832275, 1.0722632031440735, 1.0375000329017638, 1.0162001657485962, 0.999716203212738, 0.9900057563781738, 0.9746674242019653, 0.9686337027549744, 0.9620239701271057, 0.950623437166214, 0.9460561804771423, 0.9384213151931763, 0.9339564595222473, 0.9314641356468201, 0.9303051218986511, 0.9275353012084961, 0.9250294175148011, 0.9210573382377625, 0.9228106555938721, 0.9173535981178284, 0.9151195321083069, 0.9146891093254089, 0.9121170964241028, 0.9075819392204285, 0.9072549324035645, 0.906022376537323, 0.9006632876396179, 0.8988274269104004, 0.8975286674499512, 0.8985780487060547, 0.8987935252189636, 0.8935762338638306, 0.8964733157157898, 0.8960233120918274, 0.8942760529518128, 0.8942059278488159, 0.8922912955284119, 0.8906847023963929, 0.891237380027771, 0.8895377998352051, 0.8886627588272095, 0.8903357629776001, 0.8863251571655273, 0.8876424608230591, 0.8884529175758362, 0.8850255403518676, 0.8867724795341492, 0.8816174354553222, 0.8847878799438477, 0.88503178358078, 0.8844011435508728, 0.8844369220733642, 0.8810694417953491, 0.8838582019805908, 0.8828566284179687, 0.8814647250175476, 0.8839889912605285, 0.8809556488990784, 0.8801562995910645, 0.8814346632957458, 0.8794217672348023, 0.8827207159996032, 0.8794292612075806, 0.8796769232749939, 0.8794286079406738, 0.8798057079315186, 0.8813387913703918, 0.8790588598251343, 0.880240083694458, 0.8798715224266053, 0.8829588084220886, 0.8794109146595002, 0.880182119846344, 0.8763852505683899, 0.8790357336997986, 0.8790583925247193], 'val_losses': [1.4455970020294189, 1.3387432727813722, 1.2348065872192382, 1.1414878187179565, 1.0757455387115478, 1.0340342082977294, 1.0064161081314087, 0.9886353006362915, 0.9751973285675049, 0.9646575841903686, 0.9555304889678955, 0.9478146114349365, 0.9406308469772339, 0.9341755857467652, 0.9284840927124024, 0.9225086107254028, 0.9202662963867188, 0.9179982595443725, 0.9159058923721314, 0.9138766803741455, 0.9117925710678101, 0.9099267053604126, 0.9080946369171142, 0.9061956195831299, 0.90423055934906, 0.9024987173080444, 0.9007316608428955, 0.8988498620986939, 0.8971732482910156, 0.8954889993667603, 0.8938256006240844, 0.8922258224487305, 0.891538779258728, 0.8908094367980957, 0.8901152019500732, 0.8894289531707764, 0.8887253160476685, 0.8880108413696289, 0.8873100919723511, 0.8866285810470581, 0.8859235258102417, 0.885293436050415, 0.8845986423492431, 0.8838812551498413, 0.8832577629089355, 0.8825447797775269, 0.8818487586975098, 0.8811765213012696, 0.8808886041641235, 0.880591721534729, 0.8803039989471435, 0.880008246421814, 0.8797237033843994, 0.8794264373779297, 0.8791304531097413, 0.8788528127670288, 0.8785818243026733, 0.8782856492996216, 0.8779841728210449, 0.8776908674240113, 0.8774270524978638, 0.8771083927154542, 0.8768558731079101, 0.8765677309036255, 0.8764390897750854, 0.8763218183517456, 0.8762063837051391, 0.8760836410522461, 0.8759754304885864, 0.8758545017242432, 0.8757375144958496, 0.8756208610534668, 0.8755015420913697, 0.8753874435424804, 0.8752689819335937, 0.8751457319259643, 0.8750287532806397, 0.8749064626693726, 0.8747824916839599, 0.8746570529937744], 'val_acc': [0.719, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.721, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.722, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.723, 0.724, 0.724, 0.726, 0.726, 0.727, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.728, 0.729, 0.729, 0.729], 'param_count_before': 151009, 'param_count_after': 151009, 'config': {'lr': 8.111941985431925e-06, 'batch_size': 32, 'epochs': 80, 'hidden_dim1': 73, 'hidden_dim2': 37, 'hidden_dim3': 51, 'dropout': 0.01153121252070788, 'weight_decay': 1.4081468939305824e-05, 'grad_clip_norm': 1.9993048585762778, 'use_scheduler': True, 'step_size': 16, 'gamma': 0.42606204053138563, 'seed': 396917567, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_batches': 20}, 'model_name': 'LightMLP-Arrhythmia-PTQ', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 8.111941985431925e-06, 'batch_size': 32, 'epochs': 80, 'hidden_dim1': 73, 'hidden_dim2': 37, 'hidden_dim3': 51, 'dropout': 0.01153121252070788, 'weight_decay': 1.4081468939305824e-05, 'grad_clip_norm': 1.9993048585762778, 'use_scheduler': True, 'step_size': 16, 'gamma': 0.42606204053138563, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_batches': 20, 'seed': 396917567}, 'model_parameter_count': 151009, 'model_size_validation': 'PASS'}
2025-09-20 16:33:09,458 - INFO - _models.training_function_executor - BO Objective: base=0.7290, size_penalty=0.0000, final=0.7290
2025-09-20 16:33:09,458 - INFO - _models.training_function_executor - Model size: 151,009 parameters (PASS 256K limit)
2025-09-20 16:33:09,458 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 17.403s
2025-09-20 16:33:09,458 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7290
2025-09-20 16:33:09,458 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-09-20 16:33:09,458 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 8.111941985431925e-06, 'batch_size': 32, 'epochs': np.int64(80), 'hidden_dim1': np.int64(73), 'hidden_dim2': np.int64(37), 'hidden_dim3': np.int64(51), 'dropout': 0.01153121252070788, 'weight_decay': 1.4081468939305824e-05, 'grad_clip_norm': 1.9993048585762778, 'use_scheduler': True, 'step_size': np.int64(16), 'gamma': 0.42606204053138563, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_batches': np.int64(20), 'seed': np.int64(396917567)}, value=0.7290
2025-09-20 16:33:09,458 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 8.111941985431925e-06, 'batch_size': 32, 'epochs': np.int64(80), 'hidden_dim1': np.int64(73), 'hidden_dim2': np.int64(37), 'hidden_dim3': np.int64(51), 'dropout': 0.01153121252070788, 'weight_decay': 1.4081468939305824e-05, 'grad_clip_norm': 1.9993048585762778, 'use_scheduler': True, 'step_size': np.int64(16), 'gamma': 0.42606204053138563, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True, 'calibration_batches': np.int64(20), 'seed': np.int64(396917567)} -> 0.7290
2025-09-20 16:33:09,459 - INFO - bo.run_bo - üîçBO Trial 3: Initial random exploration
2025-09-20 16:33:09,459 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-09-20 16:33:09,459 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 16:33:09,459 - INFO - _models.training_function_executor - Executing training function: LightMLP-Arrhythmia-PTQ
2025-09-20 16:33:09,459 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00021568228019263973, 'batch_size': 256, 'epochs': 11, 'hidden_dim1': 36, 'hidden_dim2': 88, 'hidden_dim3': 46, 'dropout': 0.006632480579933266, 'weight_decay': 0.0044999794874720144, 'grad_clip_norm': 2.816441089227697, 'use_scheduler': True, 'step_size': 14, 'gamma': 0.18692818146568166, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 8, 'seed': 147697582}
2025-09-20 16:33:09,462 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00021568228019263973, 'batch_size': 256, 'epochs': 11, 'hidden_dim1': 36, 'hidden_dim2': 88, 'hidden_dim3': 46, 'dropout': 0.006632480579933266, 'weight_decay': 0.0044999794874720144, 'grad_clip_norm': 2.816441089227697, 'use_scheduler': True, 'step_size': 14, 'gamma': 0.18692818146568166, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 8, 'seed': 147697582}
2025-09-20 16:33:10,115 - INFO - _models.training_function_executor - Model parameter count: 79,621
2025-09-20 16:33:10,116 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5250810642242432, 1.2154316835403443, 1.0237889752388, 0.9697314686775208, 0.9420342745780945, 0.9229577836990357, 0.9017657322883605, 0.8779049029350281, 0.8549957227706909, 0.8267053298950195, 0.805099395275116], 'val_losses': [1.368368369102478, 1.052441556930542, 0.9717465114593505, 0.9362255969047546, 0.9176436939239502, 0.8984871249198914, 0.8828331871032715, 0.8609846367835998, 0.840715325832367, 0.8212215847969055, 0.8031313524246216], 'val_acc': [0.72, 0.72, 0.72, 0.72, 0.72, 0.721, 0.737, 0.752, 0.763, 0.766, 0.769], 'param_count_before': 79621, 'param_count_after': 79621, 'config': {'lr': 0.00021568228019263973, 'batch_size': 256, 'epochs': 11, 'hidden_dim1': 36, 'hidden_dim2': 88, 'hidden_dim3': 46, 'dropout': 0.006632480579933266, 'weight_decay': 0.0044999794874720144, 'grad_clip_norm': 2.816441089227697, 'use_scheduler': True, 'step_size': 14, 'gamma': 0.18692818146568166, 'seed': 147697582, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 8}, 'model_name': 'LightMLP-Arrhythmia-PTQ', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00021568228019263973, 'batch_size': 256, 'epochs': 11, 'hidden_dim1': 36, 'hidden_dim2': 88, 'hidden_dim3': 46, 'dropout': 0.006632480579933266, 'weight_decay': 0.0044999794874720144, 'grad_clip_norm': 2.816441089227697, 'use_scheduler': True, 'step_size': 14, 'gamma': 0.18692818146568166, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': 8, 'seed': 147697582}, 'model_parameter_count': 79621, 'model_size_validation': 'PASS'}
2025-09-20 16:33:10,116 - INFO - _models.training_function_executor - BO Objective: base=0.7690, size_penalty=0.0000, final=0.7690
2025-09-20 16:33:10,116 - INFO - _models.training_function_executor - Model size: 79,621 parameters (PASS 256K limit)
2025-09-20 16:33:10,116 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 0.657s
2025-09-20 16:33:10,265 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7690
2025-09-20 16:33:10,265 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.149s
2025-09-20 16:33:10,265 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 0.00021568228019263973, 'batch_size': 256, 'epochs': np.int64(11), 'hidden_dim1': np.int64(36), 'hidden_dim2': np.int64(88), 'hidden_dim3': np.int64(46), 'dropout': 0.006632480579933266, 'weight_decay': 0.0044999794874720144, 'grad_clip_norm': 2.816441089227697, 'use_scheduler': True, 'step_size': np.int64(14), 'gamma': 0.18692818146568166, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': np.int64(8), 'seed': np.int64(147697582)}, value=0.7690
2025-09-20 16:33:10,265 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 0.00021568228019263973, 'batch_size': 256, 'epochs': np.int64(11), 'hidden_dim1': np.int64(36), 'hidden_dim2': np.int64(88), 'hidden_dim3': np.int64(46), 'dropout': 0.006632480579933266, 'weight_decay': 0.0044999794874720144, 'grad_clip_norm': 2.816441089227697, 'use_scheduler': True, 'step_size': np.int64(14), 'gamma': 0.18692818146568166, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True, 'calibration_batches': np.int64(8), 'seed': np.int64(147697582)} -> 0.7690
2025-09-20 16:33:10,265 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.7920
2025-09-20 16:33:10,265 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': np.int64(76), 'hidden_dim1': np.int64(76), 'hidden_dim2': np.int64(36), 'hidden_dim3': np.int64(46), 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': np.int64(12), 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(6), 'seed': np.int64(3344769)}
2025-09-20 16:33:10,267 - INFO - visualization - Generating BO visualization charts with 3 trials...
2025-09-20 16:33:12,136 - INFO - visualization - BO summary saved to: charts\BO_LightMLP-Arrhythmia-PTQ_20250920_163310\bo_summary.txt
2025-09-20 16:33:12,136 - INFO - visualization - BO charts saved to: charts\BO_LightMLP-Arrhythmia-PTQ_20250920_163310
2025-09-20 16:33:12,136 - INFO - evaluation.code_generation_pipeline_orchestrator - üìä BO charts saved to: charts\BO_LightMLP-Arrhythmia-PTQ_20250920_163310
2025-09-20 16:33:12,149 - INFO - evaluation.code_generation_pipeline_orchestrator - üöÄ STEP 4: Final Training Execution
2025-09-20 16:33:12,149 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (39904, 1000, 2), Val: (9977, 1000, 2), Test: (12471, 1000, 2)
2025-09-20 16:33:12,324 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-20 16:33:12,332 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-20 16:33:12,342 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-09-20 16:33:12,351 - INFO - _models.training_function_executor - Loaded training function: LightMLP-Arrhythmia-PTQ
2025-09-20 16:33:12,352 - INFO - _models.training_function_executor - Reasoning: No reasoning provided
2025-09-20 16:33:12,352 - INFO - evaluation.code_generation_pipeline_orchestrator - Executing final training with optimized params: {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': np.int64(76), 'hidden_dim1': np.int64(76), 'hidden_dim2': np.int64(36), 'hidden_dim3': np.int64(46), 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': np.int64(12), 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(6), 'seed': np.int64(3344769)}
2025-09-20 16:33:12,352 - INFO - _models.training_function_executor - Using device: cuda
2025-09-20 16:33:12,443 - INFO - _models.training_function_executor - Executing training function: LightMLP-Arrhythmia-PTQ
2025-09-20 16:33:12,443 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': np.int64(76), 'hidden_dim1': np.int64(76), 'hidden_dim2': np.int64(36), 'hidden_dim3': np.int64(46), 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': np.int64(12), 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': np.int64(6), 'seed': np.int64(3344769)}
2025-09-20 16:33:12,445 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': 76, 'hidden_dim1': 76, 'hidden_dim2': 36, 'hidden_dim3': 46, 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': 12, 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 6, 'seed': 3344769}
2025-09-20 16:35:52,407 - INFO - _models.training_function_executor - Model parameter count: 156,785
2025-09-20 16:35:52,407 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8226876899827071, 0.7613769221420563, 0.7623802204560354, 0.7517248709247699, 0.7481736473637576, 0.7587551945863769, 0.7938427668312787, 0.823074891482149, 0.8066751548502096, 0.843821386241301, 0.8089888315250516, 0.7990982047825119, 0.8189064320460643, 0.8328226282296414, 0.8302076602565257, 0.8464772683817, 0.8574355395918574, 0.8643719656236093, 0.886547008106588, 0.8702273420696748, 0.8544565331199787, 0.8909008871247124, 0.8900791740025533, 0.8823770151773069, 0.8598364570089216, 0.8642085308347975, 0.8625412826884147, 0.8986937456735153, 0.876452901813634, 0.8757385799859941, 0.8775580916867413, 0.9056729363410494, 0.8966193282087994, 0.8872955710341095, 0.8888855085147316, 0.888947656872565, 0.8949251861551234, 0.8899887973485991, 0.8795575275598952, 0.853635854212494, 0.8456315144884557, 0.8346522905488156, 0.8164261216006474, 0.8147977721050632, 0.7902253621706699, 0.7883034641731235, 0.7735425190105377, 0.7685351108634768, 0.7566407239953327, 0.7440877853151121, 0.7436232112509399, 0.7358687081476547, 0.7203767738561202, 0.7305427880744123, 0.7136572753321963, 0.7157267440340475, 0.7154073905447721, 0.7017828725583093, 0.6866784299624473, 0.6697732658389098, 0.6456330857854321, 0.6249186711351491, 0.621804859247223, 0.6119589042979043, 0.5987750167189929, 0.5969346643880357, 0.5877249999914346, 0.5796279071351482, 0.575508910472525, 0.5728346037334122, 0.5661259070696024, 0.5576358424871563, 0.540276983126986, 0.5428805134969419, 0.5419053760713449, 0.5324141796627518], 'val_losses': [0.6855733582810265, 0.6922095453761868, 0.7229607112842368, 0.7061021469351977, 0.7114536203290915, 0.8227664110798437, 0.7377204545886983, 0.7679819004311284, 0.7687198801091789, 0.7782792250295434, 0.7362972277790604, 0.7764501760798609, 0.7857915971768312, 0.7853860153969823, 0.8117547461058628, 0.8252819652570277, 0.8368474076180632, 0.8406736541453925, 0.8312005281173551, 0.8332232213980977, 0.8507294073675514, 0.869597855288865, 0.8703677266898896, 0.8653443628828571, 0.8262481917488536, 0.8241081946811636, 0.8049003676743501, 0.8547085137134015, 0.8658939906049374, 0.8627721884631318, 0.8604882611197963, 0.8783613266000483, 0.8752813280506961, 0.8663726253058828, 0.8800421315873088, 0.8814580032602513, 0.877554700407342, 0.9220940453669011, 0.8427708955175284, 0.8203281483430834, 0.7997179823551673, 0.7885903055997414, 0.7694556780791992, 0.7581659558302799, 0.7352664769741317, 0.7318985484532248, 0.7223836759282124, 0.7284355298889965, 0.7125123255630647, 0.7053364098305046, 0.7131773347162562, 0.702933715450103, 0.6945224477758003, 0.6967249854038506, 0.6965947619502024, 0.6921666117210098, 0.69104892619748, 0.6800260108064718, 0.633772311175265, 0.6183649211318433, 0.605682622323572, 0.5968565409720225, 0.5822061554659366, 0.5779274061428255, 0.5659063080096276, 0.5724719118991906, 0.576261110149023, 0.5627996737145464, 0.5634054547920487, 0.5426585352754167, 0.5524142972719481, 0.5346883821370332, 0.5440984962100529, 0.5204398194259807, 0.5273229186277035, 0.5099622782185738], 'val_acc': [0.7820988273027965, 0.7802946777588453, 0.7748822291269921, 0.7829006715445525, 0.7807958304099428, 0.761752029668237, 0.772476696401724, 0.7667635561792122, 0.7682670141325048, 0.7642577929237245, 0.7750826901874311, 0.773078079583041, 0.7641575623935051, 0.7633557181517491, 0.7568407336874812, 0.7502255186929939, 0.7461160669539942, 0.7447128395309212, 0.7473188333166283, 0.7470181417259697, 0.7388994687781898, 0.731983562193044, 0.720056129096923, 0.7343890949183122, 0.752029668236945, 0.752430590357823, 0.7582439611105543, 0.7387992382479703, 0.7335872506765561, 0.7364939360529217, 0.7357923223413851, 0.720056129096923, 0.720056129096923, 0.720056129096923, 0.720056129096923, 0.720056129096923, 0.720056129096923, 0.7310814874210685, 0.7392001603688484, 0.7488222912699208, 0.7540342788413351, 0.7587451137616518, 0.7643580234539441, 0.7684674751929438, 0.7752831512478701, 0.7747819985967725, 0.7784905282148943, 0.7773879923824797, 0.7811967525308209, 0.782599979953894, 0.7820988273027965, 0.7833015936654305, 0.7843038989676255, 0.784003207376967, 0.7850055126791621, 0.7852059737396011, 0.7875112759346496, 0.792923724566503, 0.8118672947779894, 0.814974441214794, 0.825097724766964, 0.8314122481707928, 0.8334168587751829, 0.8380274631652801, 0.8379272326350606, 0.8374260799839631, 0.8399318432394507, 0.8387290768768166, 0.8421369149042799, 0.8454445224015235, 0.8436403728575724, 0.8488523604289867, 0.8444422170993284, 0.8499548962614012, 0.8490528214894256, 0.8553673448932545], 'param_count_before': 156785, 'param_count_after': 156785, 'config': {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': 76, 'hidden_dim1': 76, 'hidden_dim2': 36, 'hidden_dim3': 46, 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': 12, 'gamma': 0.7301845942384806, 'seed': 3344769, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 6}, 'model_name': 'LightMLP-Arrhythmia-PTQ', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.009609812947036413, 'batch_size': 32, 'epochs': 76, 'hidden_dim1': 76, 'hidden_dim2': 36, 'hidden_dim3': 46, 'dropout': 0.22291637642679563, 'weight_decay': 3.9796923010559875e-08, 'grad_clip_norm': 2.296244459829336, 'use_scheduler': True, 'step_size': 12, 'gamma': 0.7301845942384806, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False, 'calibration_batches': 6, 'seed': 3344769}, 'model_parameter_count': 156785, 'model_size_validation': 'PASS'}
2025-09-20 16:35:52,410 - ERROR - __main__ - Unhandled exception: RuntimeError: mat1 and mat2 shapes cannot be multiplied (64000x2 and 2000x76)
Traceback (most recent call last):
  File "D:\_A\GPT_research\ml_pipeline\main.py", line 484, in <module>
    processed_real_data = process_real_data()
  File "D:\_A\GPT_research\ml_pipeline\main.py", line 342, in process_real_data
    result = process_data_with_ai_enhanced_evaluation(
  File "D:\_A\GPT_research\ml_pipeline\main.py", line 136, in process_data_with_ai_enhanced_evaluation
    result = train_with_iterative_selection(data, labels, device=device, **kwargs)
  File "D:\_A\GPT_research\ml_pipeline\main.py", line 85, in train_with_iterative_selection
    best_model, pipeline_results = orchestrator.run_complete_pipeline(
  File "D:\_A\GPT_research\ml_pipeline\evaluation\code_generation_pipeline_orchestrator.py", line 98, in run_complete_pipeline
    final_model, training_results = self._execute_final_training(
  File "D:\_A\GPT_research\ml_pipeline\evaluation\code_generation_pipeline_orchestrator.py", line 474, in _execute_final_training
    final_metrics = evaluate_model(trained_model, test_loader, eval_device)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "D:\_A\GPT_research\ml_pipeline\evaluation\evaluate.py", line 28, in evaluate_model
    logits = model(X) if lengths is None else model(X, lengths=lengths)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "<string>", line 86, in forward
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\nn\modules\container.py", line 250, in forward
    input = module(input)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\22447\.conda\envs\GPT\lib\site-packages\torch\nn\modules\linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64000x2 and 2000x76)

