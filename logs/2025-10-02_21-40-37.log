2025-10-02 21:40:37,870 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-02 21:40:37,979 - INFO - __main__ - Logging system initialized successfully
2025-10-02 21:40:37,979 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-10-02 21:40:37,979 - INFO - __main__ - Starting real data processing from data/dataset1/ directory
2025-10-02 21:40:37,979 - INFO - __main__ - Found 5 data files: ['mitdb_ecg_sample.csv', 'X.npy', 'y.npy', 'mitdb_ecg_data.npz', 'mitdb_metadata.json']
2025-10-02 21:40:37,979 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-10-02 21:40:37,979 - INFO - __main__ - Attempting to load: X.npy
2025-10-02 21:40:38,021 - INFO - __main__ - Successfully loaded NPY data: X(62352, 1000, 2), y(62352,)
2025-10-02 21:40:38,059 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (62352, 1000, 2), device: cuda
2025-10-02 21:40:38,059 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-10-02 21:40:38,059 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-10-02 21:40:38,060 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-10-02 21:40:38,061 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-02 21:40:38,061 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (62352, 1000, 2), 'dtype': 'float32', 'feature_count': 2, 'sample_count': 62352, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-10-02 21:40:38,062 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-10-02 21:40:38,062 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-10-02 21:40:38,062 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-10-02 21:40:38,062 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-10-02 21:40:38,062 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-10-02 21:40:38,062 - INFO - data_splitting - Input data shape: X=(62352, 1000, 2), y=(62352,)
2025-10-02 21:40:38,062 - INFO - data_splitting - Class distribution: [44897  9551  1201  1239  5464]
2025-10-02 21:40:38,158 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.27775728256708315), np.int64(1): np.float64(1.3057591623036648), np.int64(2): np.float64(10.37815344603381), np.int64(3): np.float64(10.0640605296343), np.int64(4): np.float64(2.282184729768373)}
2025-10-02 21:40:38,159 - INFO - class_balancing - Class imbalance analysis:
2025-10-02 21:40:38,159 - INFO - class_balancing -   Strategy: severe_imbalance
2025-10-02 21:40:38,159 - INFO - class_balancing -   Imbalance ratio: 37.36
2025-10-02 21:40:38,159 - INFO - class_balancing -   Recommendations: Use weighted loss + weighted sampling, Consider Focal Loss, Evaluate with balanced metrics
2025-10-02 21:40:38,159 - INFO - data_splitting - Final splits - Train: 39904, Val: 9977, Test: 12471
2025-10-02 21:40:38,159 - INFO - data_splitting - Train class distribution: [28733  6112   769   793  3497]
2025-10-02 21:40:38,159 - INFO - data_splitting - Val class distribution: [7184 1529  192  198  874]
2025-10-02 21:40:38,159 - INFO - data_splitting - Test class distribution: [8980 1910  240  248 1093]
2025-10-02 21:40:38,159 - INFO - data_splitting - Recommended balancing strategy: severe_imbalance
2025-10-02 21:40:38,329 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 2]), std shape: torch.Size([1, 2])
2025-10-02 21:40:38,330 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-10-02 21:40:38,330 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-10-02 21:40:38,330 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-10-02 21:40:38,330 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-10-02 21:40:38,330 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-10-02 21:40:38,330 - INFO - _models.ai_code_generator - Conducting literature review before code generation...
2025-10-02 21:42:54,540 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-02 21:42:54,564 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-10-02 21:42:54,564 - INFO - _models.ai_code_generator - Prompt length: 4253 characters
2025-10-02 21:42:54,564 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-10-02 21:42:54,564 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-10-02 21:42:54,564 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-10-02 21:45:20,810 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-02 21:45:20,811 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-10-02 21:45:20,811 - INFO - _models.ai_code_generator - AI generated training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:45:20,811 - INFO - _models.ai_code_generator - Confidence: 0.86
2025-10-02 21:45:20,811 - INFO - _models.ai_code_generator - Literature review informed code generation (confidence: 0.78)
2025-10-02 21:45:20,811 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:45:20,811 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['epochs', 'batch_size', 'lr', 'weight_decay', 'stem_channels', 'nhead', 'd_model_factor', 'num_layers', 'ff_factor', 'dropout', 'use_focal_loss', 'focal_gamma', 'label_smoothing', 'grad_clip_norm', 'sched_step', 'sched_gamma', 'quantization_bits', 'quantize_weights', 'quantize_activations']
2025-10-02 21:45:20,811 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.86
2025-10-02 21:45:20,812 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-10-02 21:45:20,812 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions/training_function_torch_tensor_Two‚ÄëLead_CAT‚ÄëNet__1D_CNN_+_SE_Channel_Attention_+_Transformer_Encoder_1759459520.json
2025-10-02 21:45:20,812 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_torch_tensor_Two‚ÄëLead_CAT‚ÄëNet__1D_CNN_+_SE_Channel_Attention_+_Transformer_Encoder_1759459520.json
2025-10-02 21:45:20,812 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-10-02 21:45:20,812 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:45:20,812 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-10-02 21:45:20,813 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-10-02 21:45:20,815 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-10-02 21:45:20,815 - INFO - package_installer - Available packages: {'torch'}
2025-10-02 21:45:20,815 - INFO - package_installer - Missing packages: set()
2025-10-02 21:45:20,815 - INFO - package_installer - ‚úÖ All required packages are already available
2025-10-02 21:45:20,815 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-10-02 21:45:20,815 - INFO - data_splitting - Using all 39904 training samples for BO
2025-10-02 21:45:20,815 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 39904 samples (using bo_sample_num=70000)
2025-10-02 21:45:20,815 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['epochs', 'batch_size', 'lr', 'weight_decay', 'stem_channels', 'nhead', 'd_model_factor', 'num_layers', 'ff_factor', 'dropout', 'use_focal_loss', 'focal_gamma', 'label_smoothing', 'grad_clip_norm', 'sched_step', 'sched_gamma', 'quantization_bits', 'quantize_weights', 'quantize_activations']
2025-10-02 21:45:20,815 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-02 21:45:20,815 - INFO - data_splitting - Using all 39904 training samples for BO
2025-10-02 21:45:20,815 - INFO - _models.training_function_executor - Using BO subset for optimization: 39904 samples (bo_sample_num=70000)
2025-10-02 21:45:20,848 - INFO - _models.training_function_executor - BO splits - Train: 31923, Val: 7981
2025-10-02 21:45:20,977 - INFO - bo.run_bo - Converted GPT search space: 19 parameters
2025-10-02 21:45:20,977 - INFO - bo.run_bo - Using GPT-generated search space
2025-10-02 21:45:20,977 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-10-02 21:45:20,978 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-10-02 21:45:20,978 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 21:45:20,978 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:45:20,978 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:45:20,978 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 33, 'batch_size': 32, 'lr': 0.0007656911415245034, 'weight_decay': 2.4400607090817545e-05, 'stem_channels': 18, 'nhead': 2, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.21242177333881368, 'use_focal_loss': True, 'focal_gamma': 2.9398197043239893, 'label_smoothing': 0.0832442640800422, 'grad_clip_norm': 0.2123391106782762, 'sched_step': 4, 'sched_gamma': 0.6495585435686677, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 21:45:20,979 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 33, 'batch_size': 32, 'lr': 0.0007656911415245034, 'weight_decay': 2.4400607090817545e-05, 'stem_channels': 18, 'nhead': 2, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.21242177333881368, 'use_focal_loss': True, 'focal_gamma': 2.9398197043239893, 'label_smoothing': 0.0832442640800422, 'grad_clip_norm': 0.2123391106782762, 'sched_step': 4, 'sched_gamma': 0.6495585435686677, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 21:45:20,981 - ERROR - _models.training_function_executor - Training execution failed: Unsupported nonlinearity gelu
2025-10-02 21:45:20,982 - INFO - _models.ai_code_generator - Starting debug attempts (max: 4)
2025-10-02 21:45:20,982 - INFO - _models.ai_code_generator - Calling GPT to debug training error (attempt 1/4)
2025-10-02 21:45:20,982 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-10-02 21:45:20,982 - INFO - _models.ai_code_generator - Prompt length: 18051 characters
2025-10-02 21:45:20,982 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-10-02 21:45:20,982 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-10-02 21:45:20,982 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-10-02 21:47:19,795 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-02 21:47:19,796 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-10-02 21:47:19,797 - INFO - _models.ai_code_generator - Saved GPT debug response to: gpt_debug_responses/gpt_debug_training_error_20251002_214719_attempt1.txt
2025-10-02 21:47:19,797 - INFO - _models.ai_code_generator - GPT suggested correction: {"training_code": "def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import math\n    import io\n    import copy\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torch.utils.data import Dataset, DataLoader\n    from torch.ao.quantization import get_default_qconfig, prepare, convert, quantize_dynamic\n\n    # Robust device handling (string or torch.device)\n    device = torch.device(device)\n    if device.type != 'cuda':\n        raise ValueError(\"This function requires a CUDA device; pass device='cuda' or torch.device('cuda').\")\n\n    # Defaults and hyperparams\n    num_classes = 5\n    seq_len = 1000\n\n    epochs = int(hyperparams.get('epochs', 10))\n    batch_size = int(hyperparams.get('batch_size', 128))\n    lr = float(hyperparams.get('lr', 1e-3))\n    weight_decay = float(hyperparams.get('weight_decay', 1e-4))\n\n    stem_channels = int(hyperparams.get('stem_channels', 12))\n    nhead = int(hyperparams.get('nhead', 2))\n    d_model_factor = int(hyperparams.get('d_model_factor', 12))\n    d_model = nhead * d_model_factor  # ensure divisibility\n    num_layers = int(hyperparams.get('num_layers', 1))\n    ff_factor = int(hyperparams.get('ff_factor', 2))\n    dropout = float(hyperparams.get('dropout', 0.1))\n\n    use_focal_loss = bool(hyperparams.get('use_focal_loss', True))\n    focal_gamma = float(hyperparams.get('focal_gamma', 2.0))\n    label_smoothing = float(hyperparams.get('label_smoothing', 0.0))\n    grad_clip_norm = float(hyperparams.get('grad_clip_norm', 0.5))\n\n    sched_step = int(hyperparams.get('sched_step', 0))  # 0 disables scheduler\n    sched_gamma = float(hyperparams.get('sched_gamma', 0.9))\n\n    # Quantization params\n    quantization_bits = int(hyperparams.get('quantization_bits', 8))  # {8,16,32}\n    quantize_weights = bool(hyperparams.get('quantize_weights', True))\n    quantize_activations = bool(hyperparams.get('quantize_activations', True))\n\n    # Dataset wrapper ensuring shape [C=2, T=1000]\n    class ECGDataset(Dataset):\n        def __init__(self, X, y):\n            assert isinstance(X, torch.Tensor), 'X must be a torch.Tensor'\n            assert isinstance(y, torch.Tensor), 'y must be a torch.Tensor'\n            assert X.dim() == 3, 'X must be [N, T, C] or [N, C, T]'\n            self.X = X\n            self.y = y\n        def __len__(self):\n            return self.X.shape[0]\n        def __getitem__(self, idx):\n            x = self.X[idx]\n            # Normalize input to [C=2, T=1000]\n            if x.dim() == 2:\n                if x.shape == (2, seq_len):\n                    x_ct = x\n                elif x.shape == (seq_len, 2):\n                    x_ct = x.transpose(0,1)\n                else:\n                    # Try to infer channels-last\n                    if x.shape[-1] == 2:\n                        x_ct = x.transpose(0,1)\n                    elif x.shape[0] == 2:\n                        x_ct = x\n                    else:\n                        raise ValueError(f'Unsupported sample shape {tuple(x.shape)}; expected (2,{seq_len}) or ({seq_len},2).')\n            else:\n                raise ValueError(f'Unsupported sample rank {x.dim()}')\n            x_ct = x_ct.to(dtype=torch.float32)\n            y_i = self.y[idx].to(dtype=torch.long)\n            return x_ct, y_i\n\n    train_ds = ECGDataset(X_train, y_train)\n    val_ds = ECGDataset(X_val, y_val)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n\n    # Helper: output length of conv1d\n    def conv1d_out_len(L, kernel_size, stride=1, padding=0, dilation=1):\n        return math.floor((L + 2*padding - dilation*(kernel_size - 1) - 1) / stride + 1)\n\n    # SE Block for channel attention\n    class SEBlock(nn.Module):\n        def __init__(self, channels, reduction=4):\n            super().__init__()\n            hidden = max(channels // reduction, 1)\n            self.avg = nn.AdaptiveAvgPool1d(1)\n            self.fc1 = nn.Conv1d(channels, hidden, kernel_size=1, bias=True)\n            self.fc2 = nn.Conv1d(hidden, channels, kernel_size=1, bias=True)\n        def forward(self, x):  # x: [B, C, T]\n            s = self.avg(x)\n            s = F.gelu(self.fc1(s))\n            s = torch.sigmoid(self.fc2(s))\n            return x * s\n\n    # Model: Two-Lead CAT-Net (Conv -> SE -> Transformer)\n    class TwoLeadCATNet(nn.Module):\n        def __init__(self, seq_len=1000, stem_channels=12, d_model=24, nhead=2, num_layers=1, ff_factor=2, dropout=0.1, num_classes=5):\n            super().__init__()\n            self.seq_len = seq_len\n            self.conv1 = nn.Conv1d(2, stem_channels, kernel_size=7, stride=2, padding=3, bias=True)\n            self.conv2 = nn.Conv1d(stem_channels, stem_channels, kernel_size=5, stride=2, padding=2, bias=True)\n            self.se = SEBlock(stem_channels, reduction=4)\n            self.proj = nn.Conv1d(stem_channels, d_model, kernel_size=1, bias=True)\n            # Compute output length after convs\n            L1 = conv1d_out_len(seq_len, 7, stride=2, padding=3)\n            L2 = conv1d_out_len(L1, 5, stride=2, padding=2)\n            self.time_len = L2\n            self.pos_emb = nn.Parameter(torch.zeros(1, self.time_len, d_model))\n            encoder_layer = nn.TransformerEncoderLayer(\n                d_model=d_model,\n                nhead=nhead,\n                dim_feedforward=max(d_model * ff_factor, 1),\n                dropout=dropout,\n                activation='gelu',\n                batch_first=True,\n                norm_first=True,\n            )\n            self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n            self.norm = nn.LayerNorm(d_model)\n            self.head = nn.Linear(d_model, num_classes)\n            self.dropout = nn.Dropout(dropout)\n            self._init_weights()\n        def _init_weights(self):\n            for m in self.modules():\n                if isinstance(m, nn.Conv1d):\n                    # Use 'relu' gain for Kaiming init; 'gelu' is not supported\n                    nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n                    if m.bias is not None:\n                        nn.init.zeros_(m.bias)\n                elif isinstance(m, nn.Linear):\n                    nn.init.trunc_normal_(m.weight, std=0.02)\n                    if m.bias is not None:\n                        nn.init.zeros_(m.bias)\n                elif isinstance(m, nn.LayerNorm):\n                    nn.init.ones_(m.weight)\n                    nn.init.zeros_(m.bias)\n            nn.init.trunc_normal_(self.pos_emb, std=0.02)\n        def forward(self, x):  # x: [B, 2, T]\n            x = F.gelu(self.conv1(x))\n            x = F.gelu(self.conv2(x))\n            x = self.se(x)\n            x = self.proj(x)  # [B, d_model, L]\n            x = x.transpose(1, 2)  # [B, L, d_model]\n            x = x + self.pos_emb\n            x = self.encoder(x)\n            x = self.norm(x)\n            x = self.dropout(x)\n            x = x.mean(dim=1)  # global average pooling over time\n            logits = self.head(x)\n            return logits\n\n    # Losses\n    class FocalLoss(nn.Module):\n        def __init__(self, weight=None, gamma=2.0, reduction='mean'):\n            super().__init__()\n            self.register_buffer('weight', weight if weight is not None else None)\n            self.gamma = gamma\n            self.reduction = reduction\n        def forward(self, logits, target):\n            ce = F.cross_entropy(logits, target, weight=self.weight, reduction='none')\n            pt = torch.exp(-ce)\n            loss = (1 - pt) ** self.gamma * ce\n            if self.reduction == 'mean':\n                return loss.mean()\n            elif self.reduction == 'sum':\n                return loss.sum()\n            else:\n                return loss\n\n    # Compute class weights from training labels (CPU), then move to device for loss\n    with torch.no_grad():\n        y_cpu = y_train.detach().to('cpu').view(-1).long()\n        counts = torch.bincount(y_cpu, minlength=num_classes).to(torch.float32)\n        eps = 1e-6\n        inv_freq = 1.0 / (counts + eps)\n        class_weights = (num_classes * inv_freq) / (inv_freq.sum())  # normalized\n    class_weights = class_weights.to(device)\n\n    # Build model and optimizer\n    model = TwoLeadCATNet(seq_len=seq_len, stem_channels=stem_channels, d_model=d_model, nhead=nhead, num_layers=num_layers, ff_factor=ff_factor, dropout=dropout, num_classes=num_classes).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = None\n    if sched_step and sched_step > 0:\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=sched_step, gamma=sched_gamma)\n\n    if use_focal_loss:\n        criterion = FocalLoss(weight=class_weights, gamma=focal_gamma)\n    else:\n        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=label_smoothing)\n    criterion = criterion.to(device)\n\n    train_losses, val_losses, val_accs = [], [], []\n    best_state = copy.deepcopy(model.state_dict())\n    best_acc = -1.0\n\n    def evaluate(model, loader):\n        model.eval()\n        total_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for xb, yb in loader:\n                xb = xb.to(device, non_blocking=False)\n                yb = yb.to(device, non_blocking=False)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                total_loss += loss.detach().item() * xb.size(0)\n                preds = logits.argmax(dim=1)\n                correct += (preds == yb).sum().item()\n                total += xb.size(0)\n        return total_loss / max(total, 1), (correct / max(total, 1))\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running = 0.0\n        seen = 0\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=False)\n            yb = yb.to(device, non_blocking=False)\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            loss.backward()\n            if grad_clip_norm and grad_clip_norm > 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n            optimizer.step()\n            running += loss.detach().item() * xb.size(0)\n            seen += xb.size(0)\n        if scheduler is not None:\n            scheduler.step()\n        train_loss = running / max(seen, 1)\n        val_loss, val_acc = evaluate(model, val_loader)\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n        print(f\"Epoch {epoch:03d} | train_loss={train_loss:.5f} | val_loss={val_loss:.5f} | val_acc={val_acc:.4f}\")\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_state = copy.deepcopy(model.state_dict())\n\n    # Load best weights before quantization\n    model.load_state_dict(best_state)\n    model.eval()\n\n    # Move to CPU for post-training quantization\n    model_cpu = copy.deepcopy(model).to('cpu')\n\n    # Quantization logic\n    def static_calibrate_and_convert(m_float, loader, max_batches=10):\n        # Choose backend\n        backend = 'fbgemm' if 'fbgemm' in torch.backends.quantized.supported_engines else 'qnnpack'\n        torch.backends.quantized.engine = backend\n        m_float.qconfig = get_default_qconfig(backend)\n        m_prep = prepare(m_float, inplace=False)\n        m_prep.eval()\n        seen_batches = 0\n        with torch.inference_mode():\n            for xb, _ in loader:\n                # For calibration we only need activations; keep CPU\n                xb = xb.to('cpu', dtype=torch.float32)\n                m_prep(xb)\n                seen_batches += 1\n                if seen_batches >= max_batches:\n                    break\n        m_quant = convert(m_prep, inplace=False)\n        return m_quant\n\n    quantized_model = model_cpu\n    if quantize_weights:\n        if quantization_bits == 8:\n            if quantize_activations:\n                # Static PTQ (Linear layers will be quantized; conv stays float)\n                calib_loader = DataLoader(train_ds, batch_size=min(256, batch_size), shuffle=False, num_workers=0, pin_memory=False)\n                quantized_model = static_calibrate_and_convert(model_cpu, calib_loader, max_batches=10)\n            else:\n                # Dynamic quantization (weight-only)\n                quantized_model = quantize_dynamic(model_cpu, {nn.Linear}, dtype=torch.qint8)\n        elif quantization_bits == 16:\n            # Weight cast to FP16 (simple weight-size reduction)\n            quantized_model = copy.deepcopy(model_cpu).half()\n        elif quantization_bits == 32:\n            quantized_model = model_cpu\n        else:\n            raise ValueError('quantization_bits must be one of {8,16,32}')\n    else:\n        # No weight quantization\n        if quantization_bits == 16:\n            quantized_model = copy.deepcopy(model_cpu).half()\n        else:\n            quantized_model = model_cpu\n\n    # Compute serialized size (approximate storage footprint)\n    def serialized_size_bytes(m):\n        buf = io.BytesIO()\n        torch.save(m.state_dict(), buf)\n        return len(buf.getvalue())\n\n    model_size_bytes = serialized_size_bytes(quantized_model)\n    print(f'Quantized model serialized size: {model_size_bytes} bytes')\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs,\n        'best_val_acc': best_acc,\n        'model_size_bytes': int(model_size_bytes),\n        'config_used': {\n            'epochs': epochs,\n            'batch_size': batch_size,\n            'lr': lr,\n            'weight_decay': weight_decay,\n            'stem_channels': stem_channels,\n            'nhead': nhead,\n            'd_model': d_model,\n            'num_layers': num_layers,\n            'ff_factor': ff_factor,\n            'dropout': dropout,\n            'use_focal_loss': use_focal_loss,\n            'focal_gamma': focal_gamma,\n            'label_smoothing': label_smoothing,\n            'grad_clip_norm': grad_clip_norm,\n            'sched_step': sched_step,\n            'sched_gamma': sched_gamma,\n            'quantization_bits': quantization_bits,\n            'quantize_weights': quantize_weights,\n            'quantize_activations': quantize_activations\n        }\n    }\n\n    return quantized_model, metrics\n"}
2025-10-02 21:47:19,797 - INFO - _models.ai_code_generator - Debug successful on attempt 1
2025-10-02 21:47:19,797 - INFO - _models.training_function_executor - GPT suggested corrections: {"training_code": "def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import math\n    import io\n    import copy\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torch.utils.data import Dataset, DataLoader\n    from torch.ao.quantization import get_default_qconfig, prepare, convert, quantize_dynamic\n\n    # Robust device handling (string or torch.device)\n    device = torch.device(device)\n    if device.type != 'cuda':\n        raise ValueError(\"This function requires a CUDA device; pass device='cuda' or torch.device('cuda').\")\n\n    # Defaults and hyperparams\n    num_classes = 5\n    seq_len = 1000\n\n    epochs = int(hyperparams.get('epochs', 10))\n    batch_size = int(hyperparams.get('batch_size', 128))\n    lr = float(hyperparams.get('lr', 1e-3))\n    weight_decay = float(hyperparams.get('weight_decay', 1e-4))\n\n    stem_channels = int(hyperparams.get('stem_channels', 12))\n    nhead = int(hyperparams.get('nhead', 2))\n    d_model_factor = int(hyperparams.get('d_model_factor', 12))\n    d_model = nhead * d_model_factor  # ensure divisibility\n    num_layers = int(hyperparams.get('num_layers', 1))\n    ff_factor = int(hyperparams.get('ff_factor', 2))\n    dropout = float(hyperparams.get('dropout', 0.1))\n\n    use_focal_loss = bool(hyperparams.get('use_focal_loss', True))\n    focal_gamma = float(hyperparams.get('focal_gamma', 2.0))\n    label_smoothing = float(hyperparams.get('label_smoothing', 0.0))\n    grad_clip_norm = float(hyperparams.get('grad_clip_norm', 0.5))\n\n    sched_step = int(hyperparams.get('sched_step', 0))  # 0 disables scheduler\n    sched_gamma = float(hyperparams.get('sched_gamma', 0.9))\n\n    # Quantization params\n    quantization_bits = int(hyperparams.get('quantization_bits', 8))  # {8,16,32}\n    quantize_weights = bool(hyperparams.get('quantize_weights', True))\n    quantize_activations = bool(hyperparams.get('quantize_activations', True))\n\n    # Dataset wrapper ensuring shape [C=2, T=1000]\n    class ECGDataset(Dataset):\n        def __init__(self, X, y):\n            assert isinstance(X, torch.Tensor), 'X must be a torch.Tensor'\n            assert isinstance(y, torch.Tensor), 'y must be a torch.Tensor'\n            assert X.dim() == 3, 'X must be [N, T, C] or [N, C, T]'\n            self.X = X\n            self.y = y\n        def __len__(self):\n            return self.X.shape[0]\n        def __getitem__(self, idx):\n            x = self.X[idx]\n            # Normalize input to [C=2, T=1000]\n            if x.dim() == 2:\n                if x.shape == (2, seq_len):\n                    x_ct = x\n                elif x.shape == (seq_len, 2):\n                    x_ct = x.transpose(0,1)\n                else:\n                    # Try to infer channels-last\n                    if x.shape[-1] == 2:\n                        x_ct = x.transpose(0,1)\n                    elif x.shape[0] == 2:\n                        x_ct = x\n                    else:\n                        raise ValueError(f'Unsupported sample shape {tuple(x.shape)}; expected (2,{seq_len}) or ({seq_len},2).')\n            else:\n                raise ValueError(f'Unsupported sample rank {x.dim()}')\n            x_ct = x_ct.to(dtype=torch.float32)\n            y_i = self.y[idx].to(dtype=torch.long)\n            return x_ct, y_i\n\n    train_ds = ECGDataset(X_train, y_train)\n    val_ds = ECGDataset(X_val, y_val)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n\n    # Helper: output length of conv1d\n    def conv1d_out_len(L, kernel_size, stride=1, padding=0, dilation=1):\n        return math.floor((L + 2*padding - dilation*(kernel_size - 1) - 1) / stride + 1)\n\n    # SE Block for channel attention\n    class SEBlock(nn.Module):\n        def __init__(self, channels, reduction=4):\n            super().__init__()\n            hidden = max(channels // reduction, 1)\n            self.avg = nn.AdaptiveAvgPool1d(1)\n            self.fc1 = nn.Conv1d(channels, hidden, kernel_size=1, bias=True)\n            self.fc2 = nn.Conv1d(hidden, channels, kernel_size=1, bias=True)\n        def forward(self, x):  # x: [B, C, T]\n            s = self.avg(x)\n            s = F.gelu(self.fc1(s))\n            s = torch.sigmoid(self.fc2(s))\n            return x * s\n\n    # Model: Two-Lead CAT-Net (Conv -> SE -> Transformer)\n    class TwoLeadCATNet(nn.Module):\n        def __init__(self, seq_len=1000, stem_channels=12, d_model=24, nhead=2, num_layers=1, ff_factor=2, dropout=0.1, num_classes=5):\n            super().__init__()\n            self.seq_len = seq_len\n            self.conv1 = nn.Conv1d(2, stem_channels, kernel_size=7, stride=2, padding=3, bias=True)\n            self.conv2 = nn.Conv1d(stem_channels, stem_channels, kernel_size=5, stride=2, padding=2, bias=True)\n            self.se = SEBlock(stem_channels, reduction=4)\n            self.proj = nn.Conv1d(stem_channels, d_model, kernel_size=1, bias=True)\n            # Compute output length after convs\n            L1 = conv1d_out_len(seq_len, 7, stride=2, padding=3)\n            L2 = conv1d_out_len(L1, 5, stride=2, padding=2)\n            self.time_len = L2\n            self.pos_emb = nn.Parameter(torch.zeros(1, self.time_len, d_model))\n            encoder_layer = nn.TransformerEncoderLayer(\n                d_model=d_model,\n                nhead=nhead,\n                dim_feedforward=max(d_model * ff_factor, 1),\n                dropout=dropout,\n                activation='gelu',\n                batch_first=True,\n                norm_first=True,\n            )\n            self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n            self.norm = nn.LayerNorm(d_model)\n            self.head = nn.Linear(d_model, num_classes)\n            self.dropout = nn.Dropout(dropout)\n            self._init_weights()\n        def _init_weights(self):\n            for m in self.modules():\n                if isinstance(m, nn.Conv1d):\n                    # Use 'relu' gain for Kaiming init; 'gelu' is not supported\n                    nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n                    if m.bias is not None:\n                        nn.init.zeros_(m.bias)\n                elif isinstance(m, nn.Linear):\n                    nn.init.trunc_normal_(m.weight, std=0.02)\n                    if m.bias is not None:\n                        nn.init.zeros_(m.bias)\n                elif isinstance(m, nn.LayerNorm):\n                    nn.init.ones_(m.weight)\n                    nn.init.zeros_(m.bias)\n            nn.init.trunc_normal_(self.pos_emb, std=0.02)\n        def forward(self, x):  # x: [B, 2, T]\n            x = F.gelu(self.conv1(x))\n            x = F.gelu(self.conv2(x))\n            x = self.se(x)\n            x = self.proj(x)  # [B, d_model, L]\n            x = x.transpose(1, 2)  # [B, L, d_model]\n            x = x + self.pos_emb\n            x = self.encoder(x)\n            x = self.norm(x)\n            x = self.dropout(x)\n            x = x.mean(dim=1)  # global average pooling over time\n            logits = self.head(x)\n            return logits\n\n    # Losses\n    class FocalLoss(nn.Module):\n        def __init__(self, weight=None, gamma=2.0, reduction='mean'):\n            super().__init__()\n            self.register_buffer('weight', weight if weight is not None else None)\n            self.gamma = gamma\n            self.reduction = reduction\n        def forward(self, logits, target):\n            ce = F.cross_entropy(logits, target, weight=self.weight, reduction='none')\n            pt = torch.exp(-ce)\n            loss = (1 - pt) ** self.gamma * ce\n            if self.reduction == 'mean':\n                return loss.mean()\n            elif self.reduction == 'sum':\n                return loss.sum()\n            else:\n                return loss\n\n    # Compute class weights from training labels (CPU), then move to device for loss\n    with torch.no_grad():\n        y_cpu = y_train.detach().to('cpu').view(-1).long()\n        counts = torch.bincount(y_cpu, minlength=num_classes).to(torch.float32)\n        eps = 1e-6\n        inv_freq = 1.0 / (counts + eps)\n        class_weights = (num_classes * inv_freq) / (inv_freq.sum())  # normalized\n    class_weights = class_weights.to(device)\n\n    # Build model and optimizer\n    model = TwoLeadCATNet(seq_len=seq_len, stem_channels=stem_channels, d_model=d_model, nhead=nhead, num_layers=num_layers, ff_factor=ff_factor, dropout=dropout, num_classes=num_classes).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = None\n    if sched_step and sched_step > 0:\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=sched_step, gamma=sched_gamma)\n\n    if use_focal_loss:\n        criterion = FocalLoss(weight=class_weights, gamma=focal_gamma)\n    else:\n        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=label_smoothing)\n    criterion = criterion.to(device)\n\n    train_losses, val_losses, val_accs = [], [], []\n    best_state = copy.deepcopy(model.state_dict())\n    best_acc = -1.0\n\n    def evaluate(model, loader):\n        model.eval()\n        total_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for xb, yb in loader:\n                xb = xb.to(device, non_blocking=False)\n                yb = yb.to(device, non_blocking=False)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                total_loss += loss.detach().item() * xb.size(0)\n                preds = logits.argmax(dim=1)\n                correct += (preds == yb).sum().item()\n                total += xb.size(0)\n        return total_loss / max(total, 1), (correct / max(total, 1))\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running = 0.0\n        seen = 0\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=False)\n            yb = yb.to(device, non_blocking=False)\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            loss.backward()\n            if grad_clip_norm and grad_clip_norm > 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n            optimizer.step()\n            running += loss.detach().item() * xb.size(0)\n            seen += xb.size(0)\n        if scheduler is not None:\n            scheduler.step()\n        train_loss = running / max(seen, 1)\n        val_loss, val_acc = evaluate(model, val_loader)\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n        print(f\"Epoch {epoch:03d} | train_loss={train_loss:.5f} | val_loss={val_loss:.5f} | val_acc={val_acc:.4f}\")\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_state = copy.deepcopy(model.state_dict())\n\n    # Load best weights before quantization\n    model.load_state_dict(best_state)\n    model.eval()\n\n    # Move to CPU for post-training quantization\n    model_cpu = copy.deepcopy(model).to('cpu')\n\n    # Quantization logic\n    def static_calibrate_and_convert(m_float, loader, max_batches=10):\n        # Choose backend\n        backend = 'fbgemm' if 'fbgemm' in torch.backends.quantized.supported_engines else 'qnnpack'\n        torch.backends.quantized.engine = backend\n        m_float.qconfig = get_default_qconfig(backend)\n        m_prep = prepare(m_float, inplace=False)\n        m_prep.eval()\n        seen_batches = 0\n        with torch.inference_mode():\n            for xb, _ in loader:\n                # For calibration we only need activations; keep CPU\n                xb = xb.to('cpu', dtype=torch.float32)\n                m_prep(xb)\n                seen_batches += 1\n                if seen_batches >= max_batches:\n                    break\n        m_quant = convert(m_prep, inplace=False)\n        return m_quant\n\n    quantized_model = model_cpu\n    if quantize_weights:\n        if quantization_bits == 8:\n            if quantize_activations:\n                # Static PTQ (Linear layers will be quantized; conv stays float)\n                calib_loader = DataLoader(train_ds, batch_size=min(256, batch_size), shuffle=False, num_workers=0, pin_memory=False)\n                quantized_model = static_calibrate_and_convert(model_cpu, calib_loader, max_batches=10)\n            else:\n                # Dynamic quantization (weight-only)\n                quantized_model = quantize_dynamic(model_cpu, {nn.Linear}, dtype=torch.qint8)\n        elif quantization_bits == 16:\n            # Weight cast to FP16 (simple weight-size reduction)\n            quantized_model = copy.deepcopy(model_cpu).half()\n        elif quantization_bits == 32:\n            quantized_model = model_cpu\n        else:\n            raise ValueError('quantization_bits must be one of {8,16,32}')\n    else:\n        # No weight quantization\n        if quantization_bits == 16:\n            quantized_model = copy.deepcopy(model_cpu).half()\n        else:\n            quantized_model = model_cpu\n\n    # Compute serialized size (approximate storage footprint)\n    def serialized_size_bytes(m):\n        buf = io.BytesIO()\n        torch.save(m.state_dict(), buf)\n        return len(buf.getvalue())\n\n    model_size_bytes = serialized_size_bytes(quantized_model)\n    print(f'Quantized model serialized size: {model_size_bytes} bytes')\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs,\n        'best_val_acc': best_acc,\n        'model_size_bytes': int(model_size_bytes),\n        'config_used': {\n            'epochs': epochs,\n            'batch_size': batch_size,\n            'lr': lr,\n            'weight_decay': weight_decay,\n            'stem_channels': stem_channels,\n            'nhead': nhead,\n            'd_model': d_model,\n            'num_layers': num_layers,\n            'ff_factor': ff_factor,\n            'dropout': dropout,\n            'use_focal_loss': use_focal_loss,\n            'focal_gamma': focal_gamma,\n            'label_smoothing': label_smoothing,\n            'grad_clip_norm': grad_clip_norm,\n            'sched_step': sched_step,\n            'sched_gamma': sched_gamma,\n            'quantization_bits': quantization_bits,\n            'quantize_weights': quantize_weights,\n            'quantize_activations': quantize_activations\n        }\n    }\n\n    return quantized_model, metrics\n"}
2025-10-02 21:47:19,797 - INFO - _models.training_function_executor - Stored corrections for BO process
2025-10-02 21:47:19,797 - ERROR - _models.training_function_executor - BO training objective failed: Unsupported nonlinearity gelu
2025-10-02 21:47:19,797 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) FAILED took 118.819s
2025-10-02 21:47:19,797 - ERROR - evaluation.code_generation_pipeline_orchestrator - BO Trial 1 FAILED with error: Unsupported nonlinearity gelu
2025-10-02 21:47:19,797 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚è≥ Waiting for GPT to finish debugging...
2025-10-02 21:47:22,800 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ GPT provided fixes after 3s - requesting BO restart
2025-10-02 21:47:22,800 - INFO - evaluation.code_generation_pipeline_orchestrator - üîß Applying GPT fixes to original JSON file
2025-10-02 21:47:22,801 - INFO - evaluation.code_generation_pipeline_orchestrator - Applying fixes to: generated_training_functions/training_function_torch_tensor_Two‚ÄëLead_CAT‚ÄëNet__1D_CNN_+_SE_Channel_Attention_+_Transformer_Encoder_1759459520.json
2025-10-02 21:47:22,801 - INFO - _models.training_function_executor - Loaded training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:47:22,801 - INFO - _models.training_function_executor - Reasoning: No reasoning provided
2025-10-02 21:47:22,801 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Updated training_code with GPT fix
2025-10-02 21:47:22,801 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ Saved GPT fixes back to: generated_training_functions/training_function_torch_tensor_Two‚ÄëLead_CAT‚ÄëNet__1D_CNN_+_SE_Channel_Attention_+_Transformer_Encoder_1759459520.json
2025-10-02 21:47:22,801 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Reloaded fixed training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:47:22,801 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ Applied GPT fixes, restarting BO from trial 0
2025-10-02 21:47:22,801 - INFO - evaluation.code_generation_pipeline_orchestrator - üîÑ BO Restart attempt 1/4
2025-10-02 21:47:22,801 - INFO - evaluation.code_generation_pipeline_orchestrator - Session 1: üì¶ Installing dependencies for GPT-generated training code...
2025-10-02 21:47:22,801 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-10-02 21:47:22,804 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-10-02 21:47:22,804 - INFO - package_installer - Available packages: {'torch'}
2025-10-02 21:47:22,804 - INFO - package_installer - Missing packages: set()
2025-10-02 21:47:22,804 - INFO - package_installer - ‚úÖ All required packages are already available
2025-10-02 21:47:22,804 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-10-02 21:47:22,804 - INFO - data_splitting - Using all 39904 training samples for BO
2025-10-02 21:47:22,804 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 39904 samples (using bo_sample_num=70000)
2025-10-02 21:47:22,804 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['epochs', 'batch_size', 'lr', 'weight_decay', 'stem_channels', 'nhead', 'd_model_factor', 'num_layers', 'ff_factor', 'dropout', 'use_focal_loss', 'focal_gamma', 'label_smoothing', 'grad_clip_norm', 'sched_step', 'sched_gamma', 'quantization_bits', 'quantize_weights', 'quantize_activations']
2025-10-02 21:47:22,804 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-02 21:47:22,804 - INFO - data_splitting - Using all 39904 training samples for BO
2025-10-02 21:47:22,804 - INFO - _models.training_function_executor - Using BO subset for optimization: 39904 samples (bo_sample_num=70000)
2025-10-02 21:47:22,838 - INFO - _models.training_function_executor - BO splits - Train: 31923, Val: 7981
2025-10-02 21:47:22,872 - INFO - bo.run_bo - Converted GPT search space: 19 parameters
2025-10-02 21:47:22,872 - INFO - bo.run_bo - Using GPT-generated search space
2025-10-02 21:47:22,873 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-10-02 21:47:22,873 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-10-02 21:47:22,873 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 21:47:22,874 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:47:22,874 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:47:22,874 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 33, 'batch_size': 32, 'lr': 0.0007656911415245034, 'weight_decay': 2.4400607090817545e-05, 'stem_channels': 18, 'nhead': 2, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.21242177333881368, 'use_focal_loss': True, 'focal_gamma': 2.9398197043239893, 'label_smoothing': 0.0832442640800422, 'grad_clip_norm': 0.2123391106782762, 'sched_step': 4, 'sched_gamma': 0.6495585435686677, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 21:47:22,875 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 33, 'batch_size': 32, 'lr': 0.0007656911415245034, 'weight_decay': 2.4400607090817545e-05, 'stem_channels': 18, 'nhead': 2, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.21242177333881368, 'use_focal_loss': True, 'focal_gamma': 2.9398197043239893, 'label_smoothing': 0.0832442640800422, 'grad_clip_norm': 0.2123391106782762, 'sched_step': 4, 'sched_gamma': 0.6495585435686677, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 21:49:33,825 - INFO - _models.training_function_executor - Model: 23,151 parameters, 49.7KB storage
2025-10-02 21:49:33,825 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.035473254279466356, 0.014476493626613981, 0.009968067734350172, 0.007616926127019491, 0.005061869382974878, 0.004281469241395192, 0.004112426317096934, 0.00428161027477499, 0.0026307553384009234, 0.0023459641976606035, 0.0022727145451545425, 0.0018521651219911821, 0.001361212345498831, 0.0013504803885701438, 0.0012767402238744849, 0.0010397826128659294, 0.0008400481462068043, 0.0008642469655641466, 0.0006795983575065859, 0.0006876756719389772, 0.0005734742881931999, 0.0004668106092548515, 0.0004683406281095076, 0.0003857810583926904, 0.0003083449512707601, 0.0002863812829209642, 0.00030814920152769955, 0.00036838886579033486, 0.00025229279879957547, 0.00025619172226336035, 0.00022222756007073127, 0.00021425790974020857, 0.0002239657439245798], 'val_losses': [0.017494728285788953, 0.018613160149433636, 0.014432957154591195, 0.014566383792383602, 0.0167091965933011, 0.018911872380361187, 0.016525985617290954, 0.01376101092043683, 0.01503839024352282, 0.01787947200252941, 0.017681272449015045, 0.01602092179761612, 0.016801007732757386, 0.01835316935708881, 0.022852676411317687, 0.019946928243757846, 0.02321530852270545, 0.020542534205836405, 0.021007122359028636, 0.023054215738754272, 0.023641911375431687, 0.024033155195388647, 0.025237600846362417, 0.026046749400484306, 0.025511988823882285, 0.02578823209183365, 0.026432891733103765, 0.02820199159331771, 0.026873235967453807, 0.027716730923143675, 0.027891222629703716, 0.02825853868624292, 0.028317307136667448], 'val_acc': [0.18518982583636137, 0.20436035584513218, 0.21626362611201605, 0.2631249216890114, 0.277784738754542, 0.2903144969302092, 0.32088710687883726, 0.2814183686254855, 0.3030948502693898, 0.35308858539030197, 0.36361358225786244, 0.3241448440045107, 0.3745144718706929, 0.3772710186693397, 0.4391680240571357, 0.3651171532389425, 0.39807041724094727, 0.3727603057260995, 0.4177421375767448, 0.4428016539280792, 0.43954391680240573, 0.4308983836611953, 0.4490665330159128, 0.46184688635509336, 0.4529507580503696, 0.4694900388422503, 0.43891742889362234, 0.46598170655306353, 0.47299837113143717, 0.4770078937476507, 0.4644781355719835, 0.48151860669089086, 0.4857787244706177], 'best_val_acc': 0.4857787244706177, 'model_size_bytes': 58734, 'config_used': {'epochs': 33, 'batch_size': 32, 'lr': 0.0007656911415245034, 'weight_decay': 2.4400607090817545e-05, 'stem_channels': 18, 'nhead': 2, 'd_model': 24, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.21242177333881368, 'use_focal_loss': True, 'focal_gamma': 2.9398197043239893, 'label_smoothing': 0.0832442640800422, 'grad_clip_norm': 0.2123391106782762, 'sched_step': 4, 'sched_gamma': 0.6495585435686677, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 33, 'batch_size': 32, 'lr': 0.0007656911415245034, 'weight_decay': 2.4400607090817545e-05, 'stem_channels': 18, 'nhead': 2, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.21242177333881368, 'use_focal_loss': True, 'focal_gamma': 2.9398197043239893, 'label_smoothing': 0.0832442640800422, 'grad_clip_norm': 0.2123391106782762, 'sched_step': 4, 'sched_gamma': 0.6495585435686677, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 23151, 'model_storage_size_kb': 49.738476562500004, 'model_size_validation': 'PASS'}
2025-10-02 21:49:33,825 - INFO - _models.training_function_executor - BO Objective: base=0.4858, size_penalty=0.0000, final=0.4858
2025-10-02 21:49:33,825 - INFO - _models.training_function_executor - Model: 23,151 parameters, 49.7KB (PASS 256KB limit)
2025-10-02 21:49:33,825 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 130.952s
2025-10-02 21:49:33,825 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.4858
2025-10-02 21:49:33,825 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-02 21:49:33,825 - INFO - bo.run_bo - Recorded observation #1: hparams={'epochs': np.int64(33), 'batch_size': 32, 'lr': 0.0007656911415245034, 'weight_decay': 2.4400607090817545e-05, 'stem_channels': np.int64(18), 'nhead': 2, 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.21242177333881368, 'use_focal_loss': True, 'focal_gamma': 2.9398197043239893, 'label_smoothing': 0.0832442640800422, 'grad_clip_norm': 0.2123391106782762, 'sched_step': np.int64(4), 'sched_gamma': 0.6495585435686677, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, value=0.4858
2025-10-02 21:49:33,825 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'epochs': np.int64(33), 'batch_size': 32, 'lr': 0.0007656911415245034, 'weight_decay': 2.4400607090817545e-05, 'stem_channels': np.int64(18), 'nhead': 2, 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.21242177333881368, 'use_focal_loss': True, 'focal_gamma': 2.9398197043239893, 'label_smoothing': 0.0832442640800422, 'grad_clip_norm': 0.2123391106782762, 'sched_step': np.int64(4), 'sched_gamma': 0.6495585435686677, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True} -> 0.4858
2025-10-02 21:49:33,826 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-10-02 21:49:33,826 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 21:49:33,826 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:49:33,826 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:49:33,826 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 31, 'batch_size': 128, 'lr': 3.280829084730051e-06, 'weight_decay': 1.4742753159914664e-06, 'stem_channels': 23, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.2949692657420365, 'use_focal_loss': True, 'focal_gamma': 2.7198808134726415, 'label_smoothing': 0.06803075385877798, 'grad_clip_norm': 0.4504992519695431, 'sched_step': 1, 'sched_gamma': 0.9445081281554667, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 21:49:33,827 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 31, 'batch_size': 128, 'lr': 3.280829084730051e-06, 'weight_decay': 1.4742753159914664e-06, 'stem_channels': 23, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.2949692657420365, 'use_focal_loss': True, 'focal_gamma': 2.7198808134726415, 'label_smoothing': 0.06803075385877798, 'grad_clip_norm': 0.4504992519695431, 'sched_step': 1, 'sched_gamma': 0.9445081281554667, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 21:51:06,555 - INFO - _models.training_function_executor - Model: 8,326 parameters, 35.8KB storage
2025-10-02 21:51:06,556 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.1371863847212461, 0.13649424372039426, 0.1358246122823937, 0.1351942010299718, 0.13459987066403983, 0.1340467346401489, 0.13351131448184317, 0.1330062386508656, 0.13257018372048204, 0.13211131228686418, 0.13169586905187972, 0.1313233080221773, 0.1309330621560676, 0.13060660703911225, 0.13026237230384663, 0.12998380786771818, 0.12968665665141085, 0.12943078724243415, 0.1291916226363158, 0.12895903903251715, 0.12873402496724148, 0.12853673780949923, 0.12833797993286694, 0.128149958295963, 0.12798309930657786, 0.1278266784424408, 0.12768521317030312, 0.12753184299835627, 0.12742252964870085, 0.12728449512188236, 0.12717306634553993], 'val_losses': [0.13709489438393865, 0.13641684500122708, 0.13576944230518542, 0.1351549629786699, 0.13457939372655967, 0.13402720848853397, 0.13351985559081236, 0.13303762814035885, 0.13258275709665407, 0.13215496440232175, 0.13175144648491446, 0.13137347226881463, 0.13101578372918174, 0.1306853806468112, 0.1303716038417105, 0.1300748883611318, 0.12980033981298394, 0.12954497819631272, 0.12930144099739205, 0.1290756251834274, 0.1288599624119857, 0.12866072026998002, 0.12846918388815612, 0.12829259353321218, 0.12812602325906103, 0.12796878094704747, 0.1278222603642889, 0.12768610329361968, 0.12755621476207418, 0.1274352078232109, 0.12732055316968693], 'val_acc': [0.15035709810800651, 0.08833479513845383, 0.08595414108507705, 0.08382408219521363, 0.08106753539656684, 0.058263375516852525, 0.03834106001754166, 0.03533391805538153, 0.03370504949254479, 0.03295326400200476, 0.030572609948627993, 0.02881844380403458, 0.027690765568224533, 0.025435409096604435, 0.024057135697281042, 0.022428267134444305, 0.0215511840621476, 0.02092469615336424, 0.019797017917554192, 0.01967172033579752, 0.019546422754040848, 0.019421125172284174, 0.019295827590527503, 0.019295827590527503, 0.019295827590527503, 0.019295827590527503, 0.019295827590527503, 0.019295827590527503, 0.019295827590527503, 0.019421125172284174, 0.019421125172284174], 'best_val_acc': 0.15035709810800651, 'model_size_bytes': 45486, 'config_used': {'epochs': 31, 'batch_size': 128, 'lr': 3.280829084730051e-06, 'weight_decay': 1.4742753159914664e-06, 'stem_channels': 23, 'nhead': 1, 'd_model': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.2949692657420365, 'use_focal_loss': True, 'focal_gamma': 2.7198808134726415, 'label_smoothing': 0.06803075385877798, 'grad_clip_norm': 0.4504992519695431, 'sched_step': 1, 'sched_gamma': 0.9445081281554667, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 31, 'batch_size': 128, 'lr': 3.280829084730051e-06, 'weight_decay': 1.4742753159914664e-06, 'stem_channels': 23, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.2949692657420365, 'use_focal_loss': True, 'focal_gamma': 2.7198808134726415, 'label_smoothing': 0.06803075385877798, 'grad_clip_norm': 0.4504992519695431, 'sched_step': 1, 'sched_gamma': 0.9445081281554667, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 8326, 'model_storage_size_kb': 35.77578125, 'model_size_validation': 'PASS'}
2025-10-02 21:51:06,556 - INFO - _models.training_function_executor - BO Objective: base=0.0194, size_penalty=0.0000, final=0.0194
2025-10-02 21:51:06,556 - INFO - _models.training_function_executor - Model: 8,326 parameters, 35.8KB (PASS 256KB limit)
2025-10-02 21:51:06,556 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 92.730s
2025-10-02 21:51:06,556 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0194
2025-10-02 21:51:06,556 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-02 21:51:06,556 - INFO - bo.run_bo - Recorded observation #2: hparams={'epochs': np.int64(31), 'batch_size': 128, 'lr': 3.280829084730051e-06, 'weight_decay': 1.4742753159914664e-06, 'stem_channels': np.int64(23), 'nhead': 1, 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.2949692657420365, 'use_focal_loss': True, 'focal_gamma': 2.7198808134726415, 'label_smoothing': 0.06803075385877798, 'grad_clip_norm': 0.4504992519695431, 'sched_step': np.int64(1), 'sched_gamma': 0.9445081281554667, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, value=0.0194
2025-10-02 21:51:06,556 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'epochs': np.int64(31), 'batch_size': 128, 'lr': 3.280829084730051e-06, 'weight_decay': 1.4742753159914664e-06, 'stem_channels': np.int64(23), 'nhead': 1, 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.2949692657420365, 'use_focal_loss': True, 'focal_gamma': 2.7198808134726415, 'label_smoothing': 0.06803075385877798, 'grad_clip_norm': 0.4504992519695431, 'sched_step': np.int64(1), 'sched_gamma': 0.9445081281554667, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True} -> 0.0194
2025-10-02 21:51:06,557 - INFO - bo.run_bo - üîçBO Trial 3: Initial random exploration
2025-10-02 21:51:06,557 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 21:51:06,557 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:51:06,557 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:51:06,557 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 6, 'batch_size': 128, 'lr': 4.247279795369717e-05, 'weight_decay': 3.077180271250685e-07, 'stem_channels': 15, 'nhead': 1, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.1987566853061946, 'use_focal_loss': True, 'focal_gamma': 2.0401360423556216, 'label_smoothing': 0.05467102793432797, 'grad_clip_norm': 0.18485445552552707, 'sched_step': 1, 'sched_gamma': 0.7898682127913921, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 21:51:06,558 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 6, 'batch_size': 128, 'lr': 4.247279795369717e-05, 'weight_decay': 3.077180271250685e-07, 'stem_channels': 15, 'nhead': 1, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.1987566853061946, 'use_focal_loss': True, 'focal_gamma': 2.0401360423556216, 'label_smoothing': 0.05467102793432797, 'grad_clip_norm': 0.18485445552552707, 'sched_step': 1, 'sched_gamma': 0.7898682127913921, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 21:51:17,388 - INFO - _models.training_function_executor - Model: 4,862 parameters, 20.9KB storage
2025-10-02 21:51:17,388 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.1452171466678649, 0.13977035884383224, 0.13588639963803925, 0.13300302544578896, 0.13076896745648198, 0.12907139526832576], 'val_losses': [0.14232326424699904, 0.1378352077029736, 0.13448818220329037, 0.1319874957952564, 0.13010805465823397, 0.12862968779731598], 'val_acc': [0.030196717203357974, 0.02568600426011778, 0.02518481393309109, 0.024683623606064402, 0.024433028442551057, 0.024057135697281042], 'best_val_acc': 0.030196717203357974, 'model_size_bytes': 31982, 'config_used': {'epochs': 6, 'batch_size': 128, 'lr': 4.247279795369717e-05, 'weight_decay': 3.077180271250685e-07, 'stem_channels': 15, 'nhead': 1, 'd_model': 8, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.1987566853061946, 'use_focal_loss': True, 'focal_gamma': 2.0401360423556216, 'label_smoothing': 0.05467102793432797, 'grad_clip_norm': 0.18485445552552707, 'sched_step': 1, 'sched_gamma': 0.7898682127913921, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 6, 'batch_size': 128, 'lr': 4.247279795369717e-05, 'weight_decay': 3.077180271250685e-07, 'stem_channels': 15, 'nhead': 1, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.1987566853061946, 'use_focal_loss': True, 'focal_gamma': 2.0401360423556216, 'label_smoothing': 0.05467102793432797, 'grad_clip_norm': 0.18485445552552707, 'sched_step': 1, 'sched_gamma': 0.7898682127913921, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 4862, 'model_storage_size_kb': 20.891406250000003, 'model_size_validation': 'PASS'}
2025-10-02 21:51:17,388 - INFO - _models.training_function_executor - BO Objective: base=0.0241, size_penalty=0.0000, final=0.0241
2025-10-02 21:51:17,388 - INFO - _models.training_function_executor - Model: 4,862 parameters, 20.9KB (PASS 256KB limit)
2025-10-02 21:51:17,388 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 10.831s
2025-10-02 21:51:17,465 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0241
2025-10-02 21:51:17,465 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.077s
2025-10-02 21:51:17,465 - INFO - bo.run_bo - Recorded observation #3: hparams={'epochs': np.int64(6), 'batch_size': 128, 'lr': 4.247279795369717e-05, 'weight_decay': 3.077180271250685e-07, 'stem_channels': np.int64(15), 'nhead': 1, 'd_model_factor': np.int64(8), 'num_layers': np.int64(2), 'ff_factor': np.int64(2), 'dropout': 0.1987566853061946, 'use_focal_loss': True, 'focal_gamma': 2.0401360423556216, 'label_smoothing': 0.05467102793432797, 'grad_clip_norm': 0.18485445552552707, 'sched_step': np.int64(1), 'sched_gamma': 0.7898682127913921, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, value=0.0241
2025-10-02 21:51:17,465 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'epochs': np.int64(6), 'batch_size': 128, 'lr': 4.247279795369717e-05, 'weight_decay': 3.077180271250685e-07, 'stem_channels': np.int64(15), 'nhead': 1, 'd_model_factor': np.int64(8), 'num_layers': np.int64(2), 'ff_factor': np.int64(2), 'dropout': 0.1987566853061946, 'use_focal_loss': True, 'focal_gamma': 2.0401360423556216, 'label_smoothing': 0.05467102793432797, 'grad_clip_norm': 0.18485445552552707, 'sched_step': np.int64(1), 'sched_gamma': 0.7898682127913921, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False} -> 0.0241
2025-10-02 21:51:17,465 - INFO - bo.run_bo - üîçBO Trial 4: Using RF surrogate + Expected Improvement
2025-10-02 21:51:17,465 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 21:51:17,465 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:51:17,466 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:51:17,466 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 19, 'batch_size': 128, 'lr': 2.5520059392378158e-05, 'weight_decay': 0.0008542276130073288, 'stem_channels': 24, 'nhead': 2, 'd_model_factor': 10, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.19958239308802037, 'use_focal_loss': False, 'focal_gamma': 2.1918648615145906, 'label_smoothing': 0.04716837914962074, 'grad_clip_norm': 0.0921359925473836, 'sched_step': 4, 'sched_gamma': 0.4378790957290981, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 21:51:17,467 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 19, 'batch_size': 128, 'lr': 2.5520059392378158e-05, 'weight_decay': 0.0008542276130073288, 'stem_channels': 24, 'nhead': 2, 'd_model_factor': 10, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.19958239308802037, 'use_focal_loss': False, 'focal_gamma': 2.1918648615145906, 'label_smoothing': 0.04716837914962074, 'grad_clip_norm': 0.0921359925473836, 'sched_step': 4, 'sched_gamma': 0.4378790957290981, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 21:51:53,919 - INFO - _models.training_function_executor - Model: 11,827 parameters, 50.8KB storage
2025-10-02 21:51:53,919 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.912262299352618, 1.8848378585999097, 1.8631822223468848, 1.8399662619503736, 1.8210142311646416, 1.8073231792314024, 1.7952641679040957, 1.781873797711635, 1.7699330295830955, 1.7647234124803932, 1.7611858534289382, 1.7582784048078413, 1.7536792859238566, 1.752198947512991, 1.7480833211817606, 1.7452464599237143, 1.7446391524831795, 1.7459528976427345, 1.743048327603152], 'val_losses': [1.8904774334776926, 1.8664338843533606, 1.8462931079503633, 1.8192878241318537, 1.805938576250921, 1.7928897847270118, 1.78042677550847, 1.767946544109976, 1.7627651094867538, 1.757558878106501, 1.7525133953374097, 1.7475403265731404, 1.74537024287678, 1.7432176174787095, 1.7411165751993858, 1.7389511658036758, 1.7380099090444252, 1.7370803558711434, 1.736117486113699], 'val_acc': [0.19032702668838491, 0.08708181932088711, 0.12216514221275529, 0.22616213507079314, 0.25623355469239445, 0.26638265881468487, 0.2752787871194086, 0.27966420248089213, 0.2810424758802155, 0.28204485653426886, 0.28304723718832225, 0.2831725347700789, 0.283924320260619, 0.28442551058764565, 0.2845508081694023, 0.28505199849642904, 0.2851772960781857, 0.28542789124169904, 0.2859290815687257], 'best_val_acc': 0.2859290815687257, 'model_size_bytes': 56018, 'config_used': {'epochs': 19, 'batch_size': 128, 'lr': 2.5520059392378158e-05, 'weight_decay': 0.0008542276130073288, 'stem_channels': 24, 'nhead': 2, 'd_model': 20, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.19958239308802037, 'use_focal_loss': False, 'focal_gamma': 2.1918648615145906, 'label_smoothing': 0.04716837914962074, 'grad_clip_norm': 0.0921359925473836, 'sched_step': 4, 'sched_gamma': 0.4378790957290981, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 19, 'batch_size': 128, 'lr': 2.5520059392378158e-05, 'weight_decay': 0.0008542276130073288, 'stem_channels': 24, 'nhead': 2, 'd_model_factor': 10, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.19958239308802037, 'use_focal_loss': False, 'focal_gamma': 2.1918648615145906, 'label_smoothing': 0.04716837914962074, 'grad_clip_norm': 0.0921359925473836, 'sched_step': 4, 'sched_gamma': 0.4378790957290981, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 11827, 'model_storage_size_kb': 50.819140625, 'model_size_validation': 'PASS'}
2025-10-02 21:51:53,919 - INFO - _models.training_function_executor - BO Objective: base=0.2859, size_penalty=0.0000, final=0.2859
2025-10-02 21:51:53,920 - INFO - _models.training_function_executor - Model: 11,827 parameters, 50.8KB (PASS 256KB limit)
2025-10-02 21:51:53,920 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 36.454s
2025-10-02 21:51:53,995 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2859
2025-10-02 21:51:53,995 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.075s
2025-10-02 21:51:53,995 - INFO - bo.run_bo - Recorded observation #4: hparams={'epochs': np.int64(19), 'batch_size': np.int64(128), 'lr': 2.5520059392378158e-05, 'weight_decay': 0.0008542276130073288, 'stem_channels': np.int64(24), 'nhead': np.int64(2), 'd_model_factor': np.int64(10), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.19958239308802037, 'use_focal_loss': np.False_, 'focal_gamma': 2.1918648615145906, 'label_smoothing': 0.04716837914962074, 'grad_clip_norm': 0.0921359925473836, 'sched_step': np.int64(4), 'sched_gamma': 0.4378790957290981, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.2859
2025-10-02 21:51:53,995 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'epochs': np.int64(19), 'batch_size': np.int64(128), 'lr': 2.5520059392378158e-05, 'weight_decay': 0.0008542276130073288, 'stem_channels': np.int64(24), 'nhead': np.int64(2), 'd_model_factor': np.int64(10), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.19958239308802037, 'use_focal_loss': np.False_, 'focal_gamma': 2.1918648615145906, 'label_smoothing': 0.04716837914962074, 'grad_clip_norm': 0.0921359925473836, 'sched_step': np.int64(4), 'sched_gamma': 0.4378790957290981, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.2859
2025-10-02 21:51:53,995 - INFO - bo.run_bo - üîçBO Trial 5: Using RF surrogate + Expected Improvement
2025-10-02 21:51:53,995 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 21:51:53,995 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:51:53,995 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:51:53,995 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 26, 'batch_size': 32, 'lr': 0.00012510240821736509, 'weight_decay': 0.0005492195612598836, 'stem_channels': 11, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.011136633494271022, 'use_focal_loss': False, 'focal_gamma': 1.1300306867597032, 'label_smoothing': 0.03483442253578129, 'grad_clip_norm': 0.3071997232381571, 'sched_step': 2, 'sched_gamma': 0.7217757887145042, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 21:51:53,996 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 26, 'batch_size': 32, 'lr': 0.00012510240821736509, 'weight_decay': 0.0005492195612598836, 'stem_channels': 11, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.011136633494271022, 'use_focal_loss': False, 'focal_gamma': 1.1300306867597032, 'label_smoothing': 0.03483442253578129, 'grad_clip_norm': 0.3071997232381571, 'sched_step': 2, 'sched_gamma': 0.7217757887145042, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 21:53:18,905 - INFO - _models.training_function_executor - Model: 14,613 parameters, 62.8KB storage
2025-10-02 21:53:18,905 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6870629849097964, 1.4066093430813216, 1.2529660327741572, 1.147343375119478, 1.0855520296017636, 1.057887438443491, 1.0293678181984667, 1.0120954523669692, 1.000172226526002, 0.9927918143735899, 0.9828559694290012, 0.9772502624558741, 0.9663195920999541, 0.9657617846486174, 0.9665178173344091, 0.9563312486882565, 0.9600593307257796, 0.9551764567801369, 0.9525089214548889, 0.9524698709368359, 0.9548295825524717, 0.9512838850201205, 0.9493418582656892, 0.9511064040094368, 0.9419790788562145, 0.9466071121712748], 'val_losses': [1.509444596758165, 1.309917261630069, 1.1966403901554592, 1.1117128700320396, 1.089673725185411, 1.0649743826970945, 1.0504309237862184, 1.0353850541355585, 1.0225785031322847, 1.0190930845235289, 1.0125017783468848, 1.0072552626062166, 1.0026899913605734, 1.0002861478217875, 0.9967571710557391, 0.9962345374107002, 0.9934247856883384, 0.9931562416775456, 0.9911119478744547, 0.9903932189063132, 0.9884117954342814, 0.9885720330780722, 0.9867989619622746, 0.9870832463939482, 0.9865148216243257, 0.9865752007336623], 'val_acc': [0.40120285678486406, 0.492168901140208, 0.5807542914421752, 0.6593158752036086, 0.6664578373637389, 0.7172033579751911, 0.7566720962285428, 0.7591780478636763, 0.7668212003508332, 0.7952637514095978, 0.7911289312116276, 0.7754667334920436, 0.7922566094474377, 0.8041598797143216, 0.7827339932339306, 0.7938854780102744, 0.8061646410224282, 0.8057887482771583, 0.8091717829845884, 0.8092970805663451, 0.8002756546798647, 0.8071670216764817, 0.8059140458589149, 0.8075429144217516, 0.8054128555318882, 0.8076682120035084], 'best_val_acc': 0.8092970805663451, 'model_size_bytes': 66706, 'config_used': {'epochs': 26, 'batch_size': 32, 'lr': 0.00012510240821736509, 'weight_decay': 0.0005492195612598836, 'stem_channels': 11, 'nhead': 2, 'd_model': 30, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.011136633494271022, 'use_focal_loss': False, 'focal_gamma': 1.1300306867597032, 'label_smoothing': 0.03483442253578129, 'grad_clip_norm': 0.3071997232381571, 'sched_step': 2, 'sched_gamma': 0.7217757887145042, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 26, 'batch_size': 32, 'lr': 0.00012510240821736509, 'weight_decay': 0.0005492195612598836, 'stem_channels': 11, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.011136633494271022, 'use_focal_loss': False, 'focal_gamma': 1.1300306867597032, 'label_smoothing': 0.03483442253578129, 'grad_clip_norm': 0.3071997232381571, 'sched_step': 2, 'sched_gamma': 0.7217757887145042, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 14613, 'model_storage_size_kb': 62.790234375000004, 'model_size_validation': 'PASS'}
2025-10-02 21:53:18,905 - INFO - _models.training_function_executor - BO Objective: base=0.8077, size_penalty=0.0000, final=0.8077
2025-10-02 21:53:18,905 - INFO - _models.training_function_executor - Model: 14,613 parameters, 62.8KB (PASS 256KB limit)
2025-10-02 21:53:18,905 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 84.910s
2025-10-02 21:53:18,980 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8077
2025-10-02 21:53:18,980 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.075s
2025-10-02 21:53:18,980 - INFO - bo.run_bo - Recorded observation #5: hparams={'epochs': np.int64(26), 'batch_size': np.int64(32), 'lr': 0.00012510240821736509, 'weight_decay': 0.0005492195612598836, 'stem_channels': np.int64(11), 'nhead': np.int64(2), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.011136633494271022, 'use_focal_loss': np.False_, 'focal_gamma': 1.1300306867597032, 'label_smoothing': 0.03483442253578129, 'grad_clip_norm': 0.3071997232381571, 'sched_step': np.int64(2), 'sched_gamma': 0.7217757887145042, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8077
2025-10-02 21:53:18,981 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'epochs': np.int64(26), 'batch_size': np.int64(32), 'lr': 0.00012510240821736509, 'weight_decay': 0.0005492195612598836, 'stem_channels': np.int64(11), 'nhead': np.int64(2), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.011136633494271022, 'use_focal_loss': np.False_, 'focal_gamma': 1.1300306867597032, 'label_smoothing': 0.03483442253578129, 'grad_clip_norm': 0.3071997232381571, 'sched_step': np.int64(2), 'sched_gamma': 0.7217757887145042, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8077
2025-10-02 21:53:18,981 - INFO - bo.run_bo - üîçBO Trial 6: Using RF surrogate + Expected Improvement
2025-10-02 21:53:18,981 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 21:53:18,981 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:53:18,981 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:53:18,981 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 36, 'batch_size': 128, 'lr': 1.68496446999761e-05, 'weight_decay': 3.848179299164583e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.18225991433045485, 'use_focal_loss': True, 'focal_gamma': 2.5849058802335945, 'label_smoothing': 0.012436545276749924, 'grad_clip_norm': 0.16558179466562942, 'sched_step': 10, 'sched_gamma': 0.6088566001267497, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 21:53:18,982 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 36, 'batch_size': 128, 'lr': 1.68496446999761e-05, 'weight_decay': 3.848179299164583e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.18225991433045485, 'use_focal_loss': True, 'focal_gamma': 2.5849058802335945, 'label_smoothing': 0.012436545276749924, 'grad_clip_norm': 0.16558179466562942, 'sched_step': 10, 'sched_gamma': 0.6088566001267497, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 21:56:32,484 - INFO - _models.training_function_executor - Model: 27,825 parameters, 119.6KB storage
2025-10-02 21:56:32,484 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.13310550707783764, 0.11666339941452802, 0.10668466994421331, 0.09842928822465033, 0.08901678780092914, 0.08013281884172564, 0.07273168099770304, 0.06641782082530227, 0.06109841015591671, 0.05633162746562841, 0.05300308120471771, 0.05106197311751669, 0.049403881797387826, 0.047940926271276704, 0.04658909441657997, 0.04542928965377686, 0.04449009922917505, 0.04360566534263237, 0.042728779750958956, 0.04176782586593748, 0.041098770726600155, 0.04074281820973076, 0.04021681503431879, 0.03974341856464461, 0.03938426344938413, 0.03891980060254075, 0.03852301125293568, 0.03808453042478259, 0.03763054870967587, 0.037205105534891314, 0.03683165005768439, 0.03659370123893811, 0.03636923730826747, 0.036064451839923635, 0.03576889138477277, 0.03559129464377353], 'val_losses': [0.12209765027702982, 0.10976772135070632, 0.10094523103388423, 0.09194907812849051, 0.08192341197214394, 0.07362915375843493, 0.06683805358267424, 0.06154067739713626, 0.05689824616370561, 0.052848341513148316, 0.05091806726576638, 0.04931453701942812, 0.04789983009684506, 0.046619984114867244, 0.045556063282440856, 0.04465383373045926, 0.04380477276345853, 0.0429799830074945, 0.04225539583668473, 0.0415332843875705, 0.04143923041715895, 0.04082625118245171, 0.04042886015199999, 0.04022377836912994, 0.039895740180251715, 0.039451525590603415, 0.039131828985199034, 0.03871132623798218, 0.03834430519722485, 0.03796274775480241, 0.037799188832787066, 0.03756593987849807, 0.037355506508051604, 0.03724072263792555, 0.03714820308861219, 0.03683226041858947], 'val_acc': [0.021801779225660945, 0.024683623606064402, 0.02681368249592783, 0.03320385916551811, 0.03483272772835484, 0.03608570354592156, 0.036211001127678236, 0.03608570354592156, 0.04184939230672848, 0.05350206741009898, 0.05475504322766571, 0.055130935972935724, 0.05713569728104247, 0.0592657561709059, 0.06314998120536273, 0.06477884976819948, 0.06828718205738629, 0.06903896754792632, 0.07091843127427641, 0.07204610951008646, 0.07380027565467986, 0.07342438290940985, 0.07492795389048991, 0.07680741761684, 0.07743390552562336, 0.07843628617967673, 0.0808169402330535, 0.08169402330535021, 0.08419997494048365, 0.08670592657561708, 0.08808419997494048, 0.08996366370129057, 0.09008896128304723, 0.0907154491918306, 0.09272021049993735, 0.0938478887357474], 'best_val_acc': 0.0938478887357474, 'model_size_bytes': 123950, 'config_used': {'epochs': 36, 'batch_size': 128, 'lr': 1.68496446999761e-05, 'weight_decay': 3.848179299164583e-07, 'stem_channels': 16, 'nhead': 4, 'd_model': 36, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.18225991433045485, 'use_focal_loss': True, 'focal_gamma': 2.5849058802335945, 'label_smoothing': 0.012436545276749924, 'grad_clip_norm': 0.16558179466562942, 'sched_step': 10, 'sched_gamma': 0.6088566001267497, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 36, 'batch_size': 128, 'lr': 1.68496446999761e-05, 'weight_decay': 3.848179299164583e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.18225991433045485, 'use_focal_loss': True, 'focal_gamma': 2.5849058802335945, 'label_smoothing': 0.012436545276749924, 'grad_clip_norm': 0.16558179466562942, 'sched_step': 10, 'sched_gamma': 0.6088566001267497, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 27825, 'model_storage_size_kb': 119.56054687500001, 'model_size_validation': 'PASS'}
2025-10-02 21:56:32,484 - INFO - _models.training_function_executor - BO Objective: base=0.0938, size_penalty=0.0000, final=0.0938
2025-10-02 21:56:32,484 - INFO - _models.training_function_executor - Model: 27,825 parameters, 119.6KB (PASS 256KB limit)
2025-10-02 21:56:32,484 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 193.504s
2025-10-02 21:56:32,560 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0938
2025-10-02 21:56:32,560 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.076s
2025-10-02 21:56:32,560 - INFO - bo.run_bo - Recorded observation #6: hparams={'epochs': np.int64(36), 'batch_size': np.int64(128), 'lr': 1.68496446999761e-05, 'weight_decay': 3.848179299164583e-07, 'stem_channels': np.int64(16), 'nhead': np.int64(4), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.18225991433045485, 'use_focal_loss': np.True_, 'focal_gamma': 2.5849058802335945, 'label_smoothing': 0.012436545276749924, 'grad_clip_norm': 0.16558179466562942, 'sched_step': np.int64(10), 'sched_gamma': 0.6088566001267497, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.0938
2025-10-02 21:56:32,560 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'epochs': np.int64(36), 'batch_size': np.int64(128), 'lr': 1.68496446999761e-05, 'weight_decay': 3.848179299164583e-07, 'stem_channels': np.int64(16), 'nhead': np.int64(4), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.18225991433045485, 'use_focal_loss': np.True_, 'focal_gamma': 2.5849058802335945, 'label_smoothing': 0.012436545276749924, 'grad_clip_norm': 0.16558179466562942, 'sched_step': np.int64(10), 'sched_gamma': 0.6088566001267497, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.0938
2025-10-02 21:56:32,561 - INFO - bo.run_bo - üîçBO Trial 7: Using RF surrogate + Expected Improvement
2025-10-02 21:56:32,561 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 21:56:32,561 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:56:32,561 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:56:32,561 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 9, 'batch_size': 32, 'lr': 7.049908488458588e-06, 'weight_decay': 1.4680908713399001e-05, 'stem_channels': 12, 'nhead': 2, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.13416001409226966, 'use_focal_loss': True, 'focal_gamma': 1.2747082304791457, 'label_smoothing': 0.05738889024160822, 'grad_clip_norm': 0.07317477953299013, 'sched_step': 2, 'sched_gamma': 0.9357163686132282, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 21:56:32,562 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 9, 'batch_size': 32, 'lr': 7.049908488458588e-06, 'weight_decay': 1.4680908713399001e-05, 'stem_channels': 12, 'nhead': 2, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.13416001409226966, 'use_focal_loss': True, 'focal_gamma': 1.2747082304791457, 'label_smoothing': 0.05738889024160822, 'grad_clip_norm': 0.07317477953299013, 'sched_step': 2, 'sched_gamma': 0.9357163686132282, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 21:57:16,782 - INFO - _models.training_function_executor - Model: 11,053 parameters, 11.9KB storage
2025-10-02 21:57:16,782 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.170527836903792, 0.16357512702905821, 0.15854907626321682, 0.15440770610315072, 0.15107158064016948, 0.14765408391915574, 0.1450155428385956, 0.14209684569609066, 0.13859958180571486], 'val_losses': [0.16617803237496753, 0.16020808454060104, 0.1555351594404878, 0.15181578829456968, 0.14830867904045278, 0.14547428117742695, 0.14227196317394342, 0.1386168541538657, 0.1353766676325567], 'val_acc': [0.11777972685127178, 0.1333166269890991, 0.13507079313369252, 0.13594787620598922, 0.13406841247963913, 0.13356722215261246, 0.13456960280666583, 0.13532138829720586, 0.13720085202355595], 'best_val_acc': 0.13720085202355595, 'model_size_bytes': 69200, 'config_used': {'epochs': 9, 'batch_size': 32, 'lr': 7.049908488458588e-06, 'weight_decay': 1.4680908713399001e-05, 'stem_channels': 12, 'nhead': 2, 'd_model': 22, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.13416001409226966, 'use_focal_loss': True, 'focal_gamma': 1.2747082304791457, 'label_smoothing': 0.05738889024160822, 'grad_clip_norm': 0.07317477953299013, 'sched_step': 2, 'sched_gamma': 0.9357163686132282, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 9, 'batch_size': 32, 'lr': 7.049908488458588e-06, 'weight_decay': 1.4680908713399001e-05, 'stem_channels': 12, 'nhead': 2, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.13416001409226966, 'use_focal_loss': True, 'focal_gamma': 1.2747082304791457, 'label_smoothing': 0.05738889024160822, 'grad_clip_norm': 0.07317477953299013, 'sched_step': 2, 'sched_gamma': 0.9357163686132282, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 11053, 'model_storage_size_kb': 11.873339843750001, 'model_size_validation': 'PASS'}
2025-10-02 21:57:16,783 - INFO - _models.training_function_executor - BO Objective: base=0.1372, size_penalty=0.0000, final=0.1372
2025-10-02 21:57:16,783 - INFO - _models.training_function_executor - Model: 11,053 parameters, 11.9KB (PASS 256KB limit)
2025-10-02 21:57:16,783 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 44.222s
2025-10-02 21:57:16,860 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1372
2025-10-02 21:57:16,860 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.077s
2025-10-02 21:57:16,860 - INFO - bo.run_bo - Recorded observation #7: hparams={'epochs': np.int64(9), 'batch_size': np.int64(32), 'lr': 7.049908488458588e-06, 'weight_decay': 1.4680908713399001e-05, 'stem_channels': np.int64(12), 'nhead': np.int64(2), 'd_model_factor': np.int64(11), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.13416001409226966, 'use_focal_loss': np.True_, 'focal_gamma': 1.2747082304791457, 'label_smoothing': 0.05738889024160822, 'grad_clip_norm': 0.07317477953299013, 'sched_step': np.int64(2), 'sched_gamma': 0.9357163686132282, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.1372
2025-10-02 21:57:16,860 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'epochs': np.int64(9), 'batch_size': np.int64(32), 'lr': 7.049908488458588e-06, 'weight_decay': 1.4680908713399001e-05, 'stem_channels': np.int64(12), 'nhead': np.int64(2), 'd_model_factor': np.int64(11), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.13416001409226966, 'use_focal_loss': np.True_, 'focal_gamma': 1.2747082304791457, 'label_smoothing': 0.05738889024160822, 'grad_clip_norm': 0.07317477953299013, 'sched_step': np.int64(2), 'sched_gamma': 0.9357163686132282, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.1372
2025-10-02 21:57:16,860 - INFO - bo.run_bo - üîçBO Trial 8: Using RF surrogate + Expected Improvement
2025-10-02 21:57:16,860 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 21:57:16,860 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:57:16,860 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:57:16,860 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 37, 'batch_size': 32, 'lr': 3.932807868899979e-06, 'weight_decay': 0.00014116073741203027, 'stem_channels': 24, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.21827708632183446, 'use_focal_loss': False, 'focal_gamma': 2.00974747976075, 'label_smoothing': 0.07526374632243858, 'grad_clip_norm': 0.692956626195452, 'sched_step': 3, 'sched_gamma': 0.47148009804655955, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 21:57:16,862 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 37, 'batch_size': 32, 'lr': 3.932807868899979e-06, 'weight_decay': 0.00014116073741203027, 'stem_channels': 24, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.21827708632183446, 'use_focal_loss': False, 'focal_gamma': 2.00974747976075, 'label_smoothing': 0.07526374632243858, 'grad_clip_norm': 0.692956626195452, 'sched_step': 3, 'sched_gamma': 0.47148009804655955, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 21:59:17,435 - INFO - _models.training_function_executor - Model: 17,747 parameters, 38.1KB storage
2025-10-02 21:59:17,435 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [2.1471584448930754, 2.1235290848999337, 2.1130094521177805, 2.1098687837764896, 2.1051390537682235, 2.1015844611421333, 2.0995963180520363, 2.0975899800125624, 2.102156886270843, 2.1029645184192263, 2.0987416995489196, 2.099879502533141, 2.095514593971921, 2.0970752521165124, 2.098247729652385, 2.091452273215521, 2.0962601678770176, 2.0926055701772355, 2.0890085316576674, 2.094021360180273, 2.0938062905047885, 2.0923943256363176, 2.0906904341153356, 2.095374696838696, 2.0942154793879277, 2.094549197834416, 2.087757517034292, 2.0957279585658264, 2.0898967956356196, 2.0975597678496607, 2.0893478868778637, 2.0955691038395265, 2.096483568580132, 2.093541229226418, 2.093512044956566, 2.0922411750164547, 2.0889071236239882], 'val_losses': [2.131156823760868, 2.1183805681980727, 2.1081821339244815, 2.1040379494716164, 2.1000133932510603, 2.096276037108404, 2.0945824652204474, 2.092923840758287, 2.091293516082582, 2.0905391066135013, 2.0897765695533423, 2.089007437849027, 2.0886520820219046, 2.088295216907491, 2.087941416551738, 2.0877732474199586, 2.0876075462983703, 2.0874418379175768, 2.0873639094562195, 2.087287181213287, 2.0872094573539655, 2.0871736761352917, 2.087138679806951, 2.087103586151492, 2.087088154605301, 2.087072435827605, 2.0870567597388145, 2.0870499466015513, 2.087043075569888, 2.087036399700307, 2.087034073916761, 2.0870317038610278, 2.0870294087573322, 2.0870287466461446, 2.087028104430556, 2.0870274413634236, 2.087027258479256], 'val_acc': [0.02167648164390427, 0.02205237438917429, 0.0507455206114522, 0.13707555444179928, 0.2061145219897256, 0.22741511088835986, 0.2339305851397068, 0.23242701415862674, 0.23029695526876331, 0.23017165768700665, 0.2290439794511966, 0.22829219396065656, 0.2276657060518732, 0.22691392056133317, 0.22653802781606314, 0.22616213507079314, 0.22566094474376644, 0.22503445683498308, 0.22503445683498308, 0.22503445683498308, 0.2249091592532264, 0.2249091592532264, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974, 0.22478386167146974], 'best_val_acc': 0.2339305851397068, 'model_size_bytes': 43730, 'config_used': {'epochs': 37, 'batch_size': 32, 'lr': 3.932807868899979e-06, 'weight_decay': 0.00014116073741203027, 'stem_channels': 24, 'nhead': 2, 'd_model': 30, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.21827708632183446, 'use_focal_loss': False, 'focal_gamma': 2.00974747976075, 'label_smoothing': 0.07526374632243858, 'grad_clip_norm': 0.692956626195452, 'sched_step': 3, 'sched_gamma': 0.47148009804655955, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 37, 'batch_size': 32, 'lr': 3.932807868899979e-06, 'weight_decay': 0.00014116073741203027, 'stem_channels': 24, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.21827708632183446, 'use_focal_loss': False, 'focal_gamma': 2.00974747976075, 'label_smoothing': 0.07526374632243858, 'grad_clip_norm': 0.692956626195452, 'sched_step': 3, 'sched_gamma': 0.47148009804655955, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 17747, 'model_storage_size_kb': 38.1283203125, 'model_size_validation': 'PASS'}
2025-10-02 21:59:17,435 - INFO - _models.training_function_executor - BO Objective: base=0.2248, size_penalty=0.0000, final=0.2248
2025-10-02 21:59:17,435 - INFO - _models.training_function_executor - Model: 17,747 parameters, 38.1KB (PASS 256KB limit)
2025-10-02 21:59:17,435 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 120.575s
2025-10-02 21:59:17,515 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.2248
2025-10-02 21:59:17,515 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.080s
2025-10-02 21:59:17,515 - INFO - bo.run_bo - Recorded observation #8: hparams={'epochs': np.int64(37), 'batch_size': np.int64(32), 'lr': 3.932807868899979e-06, 'weight_decay': 0.00014116073741203027, 'stem_channels': np.int64(24), 'nhead': np.int64(2), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.21827708632183446, 'use_focal_loss': np.False_, 'focal_gamma': 2.00974747976075, 'label_smoothing': 0.07526374632243858, 'grad_clip_norm': 0.692956626195452, 'sched_step': np.int64(3), 'sched_gamma': 0.47148009804655955, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.2248
2025-10-02 21:59:17,515 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'epochs': np.int64(37), 'batch_size': np.int64(32), 'lr': 3.932807868899979e-06, 'weight_decay': 0.00014116073741203027, 'stem_channels': np.int64(24), 'nhead': np.int64(2), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.21827708632183446, 'use_focal_loss': np.False_, 'focal_gamma': 2.00974747976075, 'label_smoothing': 0.07526374632243858, 'grad_clip_norm': 0.692956626195452, 'sched_step': np.int64(3), 'sched_gamma': 0.47148009804655955, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.2248
2025-10-02 21:59:17,515 - INFO - bo.run_bo - üîçBO Trial 9: Using RF surrogate + Expected Improvement
2025-10-02 21:59:17,515 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 21:59:17,515 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 21:59:17,515 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 21:59:17,515 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 42, 'batch_size': 32, 'lr': 0.001223792903418524, 'weight_decay': 7.458619331096148e-05, 'stem_channels': 9, 'nhead': 2, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.0885886194053661, 'use_focal_loss': False, 'focal_gamma': 2.4659871202015307, 'label_smoothing': 0.0679107159350344, 'grad_clip_norm': 0.9031846725471844, 'sched_step': 1, 'sched_gamma': 0.3087572036740698, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 21:59:17,516 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 42, 'batch_size': 32, 'lr': 0.001223792903418524, 'weight_decay': 7.458619331096148e-05, 'stem_channels': 9, 'nhead': 2, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.0885886194053661, 'use_focal_loss': False, 'focal_gamma': 2.4659871202015307, 'label_smoothing': 0.0679107159350344, 'grad_clip_norm': 0.9031846725471844, 'sched_step': 1, 'sched_gamma': 0.3087572036740698, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:01:10,044 - INFO - _models.training_function_executor - Model: 17,689 parameters, 76.0KB storage
2025-10-02 22:01:10,044 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5736853420049166, 1.3365861714358647, 1.2871365941743766, 1.2874155221336285, 1.2736043059033857, 1.2646299793625917, 1.264462538333561, 1.266289168355967, 1.267987841020994, 1.2717236835242656, 1.2674510157582934, 1.2643193582676933, 1.2760602132317282, 1.2705295625472508, 1.271969120581564, 1.2655388761185855, 1.2666231434704407, 1.2699821112549732, 1.269414262393623, 1.2724592891234008, 1.2637023318550646, 1.2654928449206762, 1.268769139152823, 1.275343249492641, 1.2700958861835066, 1.2693384072686729, 1.2724241412522794, 1.2621226636433525, 1.2688848399109205, 1.2736021187099842, 1.2721790251933374, 1.2744075908691659, 1.2785505155264851, 1.270256627746062, 1.2724495250449885, 1.2657436183254525, 1.2637560022817207, 1.2713374770255637, 1.2771708445004852, 1.2716074361503302, 1.2709963887204534, 1.2632213345529353], 'val_losses': [1.3923673106978494, 1.3312924083739113, 1.3032251063810376, 1.2941965005882043, 1.297011920465083, 1.2953582619115114, 1.2950846958602524, 1.2951143219602121, 1.2951125483840886, 1.2951122879787818, 1.295111097499043, 1.2951109837565622, 1.2951109689394196, 1.295110972240416, 1.2951109686556235, 1.2951109715234574, 1.2951109700895405, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543, 1.2951109698505543], 'val_acc': [0.5476757298584137, 0.7918807167021676, 0.7784738754542038, 0.761558701917053, 0.7864929206866308, 0.7778473875454204, 0.7769703044731237, 0.7774714948001503, 0.7777220899636637, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204, 0.7778473875454204], 'best_val_acc': 0.7918807167021676, 'model_size_bytes': 79826, 'config_used': {'epochs': 42, 'batch_size': 32, 'lr': 0.001223792903418524, 'weight_decay': 7.458619331096148e-05, 'stem_channels': 9, 'nhead': 2, 'd_model': 32, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.0885886194053661, 'use_focal_loss': False, 'focal_gamma': 2.4659871202015307, 'label_smoothing': 0.0679107159350344, 'grad_clip_norm': 0.9031846725471844, 'sched_step': 1, 'sched_gamma': 0.3087572036740698, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 42, 'batch_size': 32, 'lr': 0.001223792903418524, 'weight_decay': 7.458619331096148e-05, 'stem_channels': 9, 'nhead': 2, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.0885886194053661, 'use_focal_loss': False, 'focal_gamma': 2.4659871202015307, 'label_smoothing': 0.0679107159350344, 'grad_clip_norm': 0.9031846725471844, 'sched_step': 1, 'sched_gamma': 0.3087572036740698, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 17689, 'model_storage_size_kb': 76.007421875, 'model_size_validation': 'PASS'}
2025-10-02 22:01:10,044 - INFO - _models.training_function_executor - BO Objective: base=0.7778, size_penalty=0.0000, final=0.7778
2025-10-02 22:01:10,044 - INFO - _models.training_function_executor - Model: 17,689 parameters, 76.0KB (PASS 256KB limit)
2025-10-02 22:01:10,044 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 112.529s
2025-10-02 22:01:10,126 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7778
2025-10-02 22:01:10,126 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.082s
2025-10-02 22:01:10,126 - INFO - bo.run_bo - Recorded observation #9: hparams={'epochs': np.int64(42), 'batch_size': np.int64(32), 'lr': 0.001223792903418524, 'weight_decay': 7.458619331096148e-05, 'stem_channels': np.int64(9), 'nhead': np.int64(2), 'd_model_factor': np.int64(16), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.0885886194053661, 'use_focal_loss': np.False_, 'focal_gamma': 2.4659871202015307, 'label_smoothing': 0.0679107159350344, 'grad_clip_norm': 0.9031846725471844, 'sched_step': np.int64(1), 'sched_gamma': 0.3087572036740698, 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7778
2025-10-02 22:01:10,126 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'epochs': np.int64(42), 'batch_size': np.int64(32), 'lr': 0.001223792903418524, 'weight_decay': 7.458619331096148e-05, 'stem_channels': np.int64(9), 'nhead': np.int64(2), 'd_model_factor': np.int64(16), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.0885886194053661, 'use_focal_loss': np.False_, 'focal_gamma': 2.4659871202015307, 'label_smoothing': 0.0679107159350344, 'grad_clip_norm': 0.9031846725471844, 'sched_step': np.int64(1), 'sched_gamma': 0.3087572036740698, 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7778
2025-10-02 22:01:10,127 - INFO - bo.run_bo - üîçBO Trial 10: Using RF surrogate + Expected Improvement
2025-10-02 22:01:10,127 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:01:10,127 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:01:10,127 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:01:10,127 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 6, 'batch_size': 32, 'lr': 0.002323827412403052, 'weight_decay': 9.388822614873797e-05, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.119248604885643, 'use_focal_loss': False, 'focal_gamma': 2.503365369327799, 'label_smoothing': 0.04592515534730285, 'grad_clip_norm': 0.33205061584409207, 'sched_step': 8, 'sched_gamma': 0.4054481149541387, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:01:10,128 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 6, 'batch_size': 32, 'lr': 0.002323827412403052, 'weight_decay': 9.388822614873797e-05, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.119248604885643, 'use_focal_loss': False, 'focal_gamma': 2.503365369327799, 'label_smoothing': 0.04592515534730285, 'grad_clip_norm': 0.33205061584409207, 'sched_step': 8, 'sched_gamma': 0.4054481149541387, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:01:34,025 - INFO - _models.training_function_executor - Model: 59,787 parameters, 256.9KB storage
2025-10-02 22:01:34,025 - WARNING - _models.training_function_executor - Model storage 256.9KB exceeds 256KB limit!
2025-10-02 22:01:34,025 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3309622283709757, 1.1223400572623927, 1.0530422034950866, 1.0312010179063236, 0.99903791396573, 0.9798223825750227], 'val_losses': [1.1828616325784456, 1.0997389529137038, 1.0637492067069132, 1.0333585190065013, 0.994274135670138, 0.9797392626810068], 'val_acc': [0.7452700162886856, 0.7922566094474377, 0.8269640395940359, 0.8348577872447062, 0.8373637388798396, 0.8851021175291317], 'best_val_acc': 0.8851021175291317, 'model_size_bytes': 248146, 'config_used': {'epochs': 6, 'batch_size': 32, 'lr': 0.002323827412403052, 'weight_decay': 9.388822614873797e-05, 'stem_channels': 11, 'nhead': 4, 'd_model': 64, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.119248604885643, 'use_focal_loss': False, 'focal_gamma': 2.503365369327799, 'label_smoothing': 0.04592515534730285, 'grad_clip_norm': 0.33205061584409207, 'sched_step': 8, 'sched_gamma': 0.4054481149541387, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 6, 'batch_size': 32, 'lr': 0.002323827412403052, 'weight_decay': 9.388822614873797e-05, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.119248604885643, 'use_focal_loss': False, 'focal_gamma': 2.503365369327799, 'label_smoothing': 0.04592515534730285, 'grad_clip_norm': 0.33205061584409207, 'sched_step': 8, 'sched_gamma': 0.4054481149541387, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 59787, 'model_storage_size_kb': 256.89726562500005, 'model_size_validation': 'FAIL'}
2025-10-02 22:01:34,025 - INFO - _models.training_function_executor - BO Objective: base=0.8851, size_penalty=0.0018, final=0.8833
2025-10-02 22:01:34,025 - INFO - _models.training_function_executor - Model: 59,787 parameters, 256.9KB (FAIL 256KB limit)
2025-10-02 22:01:34,025 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 23.898s
2025-10-02 22:01:34,109 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8833
2025-10-02 22:01:34,109 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.084s
2025-10-02 22:01:34,109 - INFO - bo.run_bo - Recorded observation #10: hparams={'epochs': np.int64(6), 'batch_size': np.int64(32), 'lr': 0.002323827412403052, 'weight_decay': 9.388822614873797e-05, 'stem_channels': np.int64(11), 'nhead': np.int64(4), 'd_model_factor': np.int64(16), 'num_layers': np.int64(1), 'ff_factor': np.int64(3), 'dropout': 0.119248604885643, 'use_focal_loss': np.False_, 'focal_gamma': 2.503365369327799, 'label_smoothing': 0.04592515534730285, 'grad_clip_norm': 0.33205061584409207, 'sched_step': np.int64(8), 'sched_gamma': 0.4054481149541387, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.8833
2025-10-02 22:01:34,109 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'epochs': np.int64(6), 'batch_size': np.int64(32), 'lr': 0.002323827412403052, 'weight_decay': 9.388822614873797e-05, 'stem_channels': np.int64(11), 'nhead': np.int64(4), 'd_model_factor': np.int64(16), 'num_layers': np.int64(1), 'ff_factor': np.int64(3), 'dropout': 0.119248604885643, 'use_focal_loss': np.False_, 'focal_gamma': 2.503365369327799, 'label_smoothing': 0.04592515534730285, 'grad_clip_norm': 0.33205061584409207, 'sched_step': np.int64(8), 'sched_gamma': 0.4054481149541387, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.8833
2025-10-02 22:01:34,110 - INFO - bo.run_bo - üîçBO Trial 11: Using RF surrogate + Expected Improvement
2025-10-02 22:01:34,110 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:01:34,110 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:01:34,110 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:01:34,110 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 18, 'batch_size': 64, 'lr': 0.0038874697300485235, 'weight_decay': 1.0659140731250364e-06, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.015325650701430818, 'use_focal_loss': False, 'focal_gamma': 1.098873915705981, 'label_smoothing': 0.028150696524633107, 'grad_clip_norm': 0.441669947893361, 'sched_step': 1, 'sched_gamma': 0.3628458461152628, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:01:34,111 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 18, 'batch_size': 64, 'lr': 0.0038874697300485235, 'weight_decay': 1.0659140731250364e-06, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.015325650701430818, 'use_focal_loss': False, 'focal_gamma': 1.098873915705981, 'label_smoothing': 0.028150696524633107, 'grad_clip_norm': 0.441669947893361, 'sched_step': 1, 'sched_gamma': 0.3628458461152628, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:02:41,850 - INFO - _models.training_function_executor - Model: 60,777 parameters, 261.2KB storage
2025-10-02 22:02:41,850 - WARNING - _models.training_function_executor - Model storage 261.2KB exceeds 256KB limit!
2025-10-02 22:02:41,850 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2115627113665883, 0.9146569517756437, 0.8313968328740577, 0.7992786431814448, 0.7814271640938909, 0.7777660732463768, 0.7769283721819149, 0.7725490711911095, 0.7764234306579043, 0.7768340805074055, 0.7739377681729459, 0.7753766397427889, 0.7779877920353603, 0.7753024635874933, 0.7708523103409093, 0.7739853978145841, 0.7760446417456047, 0.7738461591798373], 'val_losses': [1.040966899752572, 0.8840170279434638, 0.8416568209631762, 0.8235385926978778, 0.8249396404337576, 0.8249721230607391, 0.8255747872297514, 0.8252331129800495, 0.8251310352573508, 0.8250884897591491, 0.8250765631468041, 0.8250718766205174, 0.8250719185401856, 0.8250719839551816, 0.8250718048201096, 0.8250718024302479, 0.8250718035803688, 0.825071802385438], 'val_acc': [0.7372509710562586, 0.7868688134319007, 0.792507204610951, 0.8188196967798521, 0.8362360606440296, 0.8347324896629496, 0.8357348703170029, 0.8353589775717328, 0.8349830848264629, 0.8347324896629496, 0.8347324896629496, 0.8347324896629496, 0.8347324896629496, 0.8347324896629496, 0.8347324896629496, 0.8347324896629496, 0.8347324896629496, 0.8347324896629496], 'best_val_acc': 0.8362360606440296, 'model_size_bytes': 129938, 'config_used': {'epochs': 18, 'batch_size': 64, 'lr': 0.0038874697300485235, 'weight_decay': 1.0659140731250364e-06, 'stem_channels': 10, 'nhead': 4, 'd_model': 60, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.015325650701430818, 'use_focal_loss': False, 'focal_gamma': 1.098873915705981, 'label_smoothing': 0.028150696524633107, 'grad_clip_norm': 0.441669947893361, 'sched_step': 1, 'sched_gamma': 0.3628458461152628, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 18, 'batch_size': 64, 'lr': 0.0038874697300485235, 'weight_decay': 1.0659140731250364e-06, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.015325650701430818, 'use_focal_loss': False, 'focal_gamma': 1.098873915705981, 'label_smoothing': 0.028150696524633107, 'grad_clip_norm': 0.441669947893361, 'sched_step': 1, 'sched_gamma': 0.3628458461152628, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 60777, 'model_storage_size_kb': 261.15117187500005, 'model_size_validation': 'FAIL'}
2025-10-02 22:02:41,850 - INFO - _models.training_function_executor - BO Objective: base=0.8347, size_penalty=0.0101, final=0.8247
2025-10-02 22:02:41,851 - INFO - _models.training_function_executor - Model: 60,777 parameters, 261.2KB (FAIL 256KB limit)
2025-10-02 22:02:41,851 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 67.741s
2025-10-02 22:02:41,935 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8247
2025-10-02 22:02:41,935 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.084s
2025-10-02 22:02:41,935 - INFO - bo.run_bo - Recorded observation #11: hparams={'epochs': np.int64(18), 'batch_size': np.int64(64), 'lr': 0.0038874697300485235, 'weight_decay': 1.0659140731250364e-06, 'stem_channels': np.int64(10), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(4), 'dropout': 0.015325650701430818, 'use_focal_loss': np.False_, 'focal_gamma': 1.098873915705981, 'label_smoothing': 0.028150696524633107, 'grad_clip_norm': 0.441669947893361, 'sched_step': np.int64(1), 'sched_gamma': 0.3628458461152628, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.8247
2025-10-02 22:02:41,935 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 11: {'epochs': np.int64(18), 'batch_size': np.int64(64), 'lr': 0.0038874697300485235, 'weight_decay': 1.0659140731250364e-06, 'stem_channels': np.int64(10), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(4), 'dropout': 0.015325650701430818, 'use_focal_loss': np.False_, 'focal_gamma': 1.098873915705981, 'label_smoothing': 0.028150696524633107, 'grad_clip_norm': 0.441669947893361, 'sched_step': np.int64(1), 'sched_gamma': 0.3628458461152628, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.8247
2025-10-02 22:02:41,935 - INFO - bo.run_bo - üîçBO Trial 12: Using RF surrogate + Expected Improvement
2025-10-02 22:02:41,935 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:02:41,935 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:02:41,935 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:02:41,935 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 19, 'batch_size': 256, 'lr': 0.0002303309568936383, 'weight_decay': 4.149472921482775e-07, 'stem_channels': 10, 'nhead': 2, 'd_model_factor': 8, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.11342733374628747, 'use_focal_loss': True, 'focal_gamma': 1.419774803991432, 'label_smoothing': 0.010102988902687729, 'grad_clip_norm': 0.431231731837049, 'sched_step': 8, 'sched_gamma': 0.34895053399933124, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:02:41,936 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 19, 'batch_size': 256, 'lr': 0.0002303309568936383, 'weight_decay': 4.149472921482775e-07, 'stem_channels': 10, 'nhead': 2, 'd_model_factor': 8, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.11342733374628747, 'use_focal_loss': True, 'focal_gamma': 1.419774803991432, 'label_smoothing': 0.010102988902687729, 'grad_clip_norm': 0.431231731837049, 'sched_step': 8, 'sched_gamma': 0.34895053399933124, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:03:11,575 - INFO - _models.training_function_executor - Model: 7,757 parameters, 33.3KB storage
2025-10-02 22:03:11,575 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.1554614592465983, 0.12470983495200087, 0.10030213261376578, 0.0867877411454635, 0.07530361052711174, 0.06835333326110803, 0.06364010266556598, 0.060671784960804054, 0.05775121728956832, 0.0567464093731584, 0.05588675805944621, 0.05488153035476109, 0.05377989595789952, 0.052671924046956184, 0.0516738159475767, 0.050291360330853144, 0.04911858960262622, 0.04859305307499221, 0.04819241268200575], 'val_losses': [0.1413271094744381, 0.10913894291140504, 0.09381780953107659, 0.07992852886849561, 0.07022016065711217, 0.06551544455342978, 0.06101941214770531, 0.058724673137922005, 0.057367089726455586, 0.056521793669412915, 0.05549898445246819, 0.05500886455699176, 0.054052493554469845, 0.05288652922524507, 0.052105136903472196, 0.05119590588869001, 0.051150084225921356, 0.050649689810831074, 0.050438193900748954], 'val_acc': [0.03357975191078812, 0.03658689387294825, 0.03633629870943491, 0.05914045858914923, 0.08507705801278036, 0.09710562586142088, 0.12692645031950883, 0.12354341561207868, 0.13857912542287934, 0.14572108758300964, 0.14534519483773964, 0.1405838867309861, 0.1473499561458464, 0.15599548928705675, 0.15612078686881342, 0.16326274902894375, 0.16050620223029696, 0.16313745144718708, 0.16338804661070042], 'best_val_acc': 0.16338804661070042, 'model_size_bytes': 24210, 'config_used': {'epochs': 19, 'batch_size': 256, 'lr': 0.0002303309568936383, 'weight_decay': 4.149472921482775e-07, 'stem_channels': 10, 'nhead': 2, 'd_model': 16, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.11342733374628747, 'use_focal_loss': True, 'focal_gamma': 1.419774803991432, 'label_smoothing': 0.010102988902687729, 'grad_clip_norm': 0.431231731837049, 'sched_step': 8, 'sched_gamma': 0.34895053399933124, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 19, 'batch_size': 256, 'lr': 0.0002303309568936383, 'weight_decay': 4.149472921482775e-07, 'stem_channels': 10, 'nhead': 2, 'd_model_factor': 8, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.11342733374628747, 'use_focal_loss': True, 'focal_gamma': 1.419774803991432, 'label_smoothing': 0.010102988902687729, 'grad_clip_norm': 0.431231731837049, 'sched_step': 8, 'sched_gamma': 0.34895053399933124, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 7757, 'model_storage_size_kb': 33.330859375, 'model_size_validation': 'PASS'}
2025-10-02 22:03:11,576 - INFO - _models.training_function_executor - BO Objective: base=0.1634, size_penalty=0.0000, final=0.1634
2025-10-02 22:03:11,576 - INFO - _models.training_function_executor - Model: 7,757 parameters, 33.3KB (PASS 256KB limit)
2025-10-02 22:03:11,576 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 29.640s
2025-10-02 22:03:11,779 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.1634
2025-10-02 22:03:11,779 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.203s
2025-10-02 22:03:11,779 - INFO - bo.run_bo - Recorded observation #12: hparams={'epochs': np.int64(19), 'batch_size': np.int64(256), 'lr': 0.0002303309568936383, 'weight_decay': 4.149472921482775e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(2), 'd_model_factor': np.int64(8), 'num_layers': np.int64(1), 'ff_factor': np.int64(3), 'dropout': 0.11342733374628747, 'use_focal_loss': np.True_, 'focal_gamma': 1.419774803991432, 'label_smoothing': 0.010102988902687729, 'grad_clip_norm': 0.431231731837049, 'sched_step': np.int64(8), 'sched_gamma': 0.34895053399933124, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.1634
2025-10-02 22:03:11,779 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 12: {'epochs': np.int64(19), 'batch_size': np.int64(256), 'lr': 0.0002303309568936383, 'weight_decay': 4.149472921482775e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(2), 'd_model_factor': np.int64(8), 'num_layers': np.int64(1), 'ff_factor': np.int64(3), 'dropout': 0.11342733374628747, 'use_focal_loss': np.True_, 'focal_gamma': 1.419774803991432, 'label_smoothing': 0.010102988902687729, 'grad_clip_norm': 0.431231731837049, 'sched_step': np.int64(8), 'sched_gamma': 0.34895053399933124, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.1634
2025-10-02 22:03:11,779 - INFO - bo.run_bo - üîçBO Trial 13: Using RF surrogate + Expected Improvement
2025-10-02 22:03:11,779 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:03:11,779 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:03:11,779 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:03:11,779 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 28, 'batch_size': 128, 'lr': 0.0015727700792178977, 'weight_decay': 3.93621321388681e-06, 'stem_channels': 11, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.026931585581082135, 'use_focal_loss': False, 'focal_gamma': 1.1413789988777077, 'label_smoothing': 0.034559026344925345, 'grad_clip_norm': 0.3113220844828453, 'sched_step': 3, 'sched_gamma': 0.8039019792315392, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:03:11,781 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 28, 'batch_size': 128, 'lr': 0.0015727700792178977, 'weight_decay': 3.93621321388681e-06, 'stem_channels': 11, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.026931585581082135, 'use_focal_loss': False, 'focal_gamma': 1.1413789988777077, 'label_smoothing': 0.034559026344925345, 'grad_clip_norm': 0.3113220844828453, 'sched_step': 3, 'sched_gamma': 0.8039019792315392, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:04:04,233 - INFO - _models.training_function_executor - Model: 6,331 parameters, 27.2KB storage
2025-10-02 22:04:04,234 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5227450883556934, 1.2036357143747325, 1.054273157291453, 0.9725515887361084, 0.9332853146552054, 0.9040171586678888, 0.8817237367965493, 0.8631187278002616, 0.8529984158381885, 0.8343150823579278, 0.8246445125406205, 0.814305405354166, 0.8032394886031783, 0.7939315954627569, 0.7902020315469269, 0.778512023211728, 0.7772159601473007, 0.777387941167068, 0.7657604115434193, 0.7633075118344951, 0.7599673672240431, 0.7546896373210267, 0.7517523050524816, 0.7522357389024187, 0.7475930917282823, 0.7481035474017163, 0.7449052704122585, 0.7360647619003992], 'val_losses': [1.2716198245201356, 1.1273450236349771, 0.9931882959367517, 0.9403815918915135, 0.9377707006817487, 0.9188754952591682, 0.8995473318239783, 0.8865442073758929, 0.8955207095978448, 0.872785090683188, 0.8673082585472792, 0.8534416662333768, 0.8478949557657962, 0.8480700466241802, 0.8433427153755707, 0.8498141802338606, 0.8394724813384111, 0.8390418262861677, 0.8400059070910985, 0.8439830208523742, 0.8407298904838844, 0.8422204193174503, 0.8387624150663222, 0.8400883709274577, 0.8430055207648144, 0.8348781803529255, 0.8359552129231185, 0.8353313506060324], 'val_acc': [0.5271269264503196, 0.5996742262874326, 0.6885102117529132, 0.7453953138704423, 0.7242200225535648, 0.7441423380528756, 0.7737125673474502, 0.785239944869064, 0.6921438416238567, 0.8106753539656685, 0.8087958902393184, 0.8220774339055257, 0.8244580879589024, 0.8129307104372886, 0.8277158250845759, 0.8453827841122666, 0.8458839744392933, 0.8097982708933718, 0.8091717829845884, 0.859792006014284, 0.8604184939230672, 0.8406214760055131, 0.8247086831224157, 0.8254604686129557, 0.8341060017541662, 0.8435033203859166, 0.855155995489287, 0.8614208745771207], 'best_val_acc': 0.8614208745771207, 'model_size_bytes': 21266, 'config_used': {'epochs': 28, 'batch_size': 128, 'lr': 0.0015727700792178977, 'weight_decay': 3.93621321388681e-06, 'stem_channels': 11, 'nhead': 1, 'd_model': 14, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.026931585581082135, 'use_focal_loss': False, 'focal_gamma': 1.1413789988777077, 'label_smoothing': 0.034559026344925345, 'grad_clip_norm': 0.3113220844828453, 'sched_step': 3, 'sched_gamma': 0.8039019792315392, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 28, 'batch_size': 128, 'lr': 0.0015727700792178977, 'weight_decay': 3.93621321388681e-06, 'stem_channels': 11, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.026931585581082135, 'use_focal_loss': False, 'focal_gamma': 1.1413789988777077, 'label_smoothing': 0.034559026344925345, 'grad_clip_norm': 0.3113220844828453, 'sched_step': 3, 'sched_gamma': 0.8039019792315392, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 6331, 'model_storage_size_kb': 27.203515625, 'model_size_validation': 'PASS'}
2025-10-02 22:04:04,234 - INFO - _models.training_function_executor - BO Objective: base=0.8614, size_penalty=0.0000, final=0.8614
2025-10-02 22:04:04,234 - INFO - _models.training_function_executor - Model: 6,331 parameters, 27.2KB (PASS 256KB limit)
2025-10-02 22:04:04,234 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 52.454s
2025-10-02 22:04:04,325 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8614
2025-10-02 22:04:04,326 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.092s
2025-10-02 22:04:04,326 - INFO - bo.run_bo - Recorded observation #13: hparams={'epochs': np.int64(28), 'batch_size': np.int64(128), 'lr': 0.0015727700792178977, 'weight_decay': 3.93621321388681e-06, 'stem_channels': np.int64(11), 'nhead': np.int64(1), 'd_model_factor': np.int64(14), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.026931585581082135, 'use_focal_loss': np.False_, 'focal_gamma': 1.1413789988777077, 'label_smoothing': 0.034559026344925345, 'grad_clip_norm': 0.3113220844828453, 'sched_step': np.int64(3), 'sched_gamma': 0.8039019792315392, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.8614
2025-10-02 22:04:04,326 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 13: {'epochs': np.int64(28), 'batch_size': np.int64(128), 'lr': 0.0015727700792178977, 'weight_decay': 3.93621321388681e-06, 'stem_channels': np.int64(11), 'nhead': np.int64(1), 'd_model_factor': np.int64(14), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.026931585581082135, 'use_focal_loss': np.False_, 'focal_gamma': 1.1413789988777077, 'label_smoothing': 0.034559026344925345, 'grad_clip_norm': 0.3113220844828453, 'sched_step': np.int64(3), 'sched_gamma': 0.8039019792315392, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.8614
2025-10-02 22:04:04,326 - INFO - bo.run_bo - üîçBO Trial 14: Using RF surrogate + Expected Improvement
2025-10-02 22:04:04,326 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:04:04,326 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:04:04,326 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:04:04,326 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 48, 'batch_size': 128, 'lr': 0.0010867825849791627, 'weight_decay': 5.960803295682008e-07, 'stem_channels': 10, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.06592550177919701, 'use_focal_loss': True, 'focal_gamma': 1.7128866799641864, 'label_smoothing': 0.044981034967549446, 'grad_clip_norm': 0.12115593081273127, 'sched_step': 5, 'sched_gamma': 0.976617710514731, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:04:04,327 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 48, 'batch_size': 128, 'lr': 0.0010867825849791627, 'weight_decay': 5.960803295682008e-07, 'stem_channels': 10, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.06592550177919701, 'use_focal_loss': True, 'focal_gamma': 1.7128866799641864, 'label_smoothing': 0.044981034967549446, 'grad_clip_norm': 0.12115593081273127, 'sched_step': 5, 'sched_gamma': 0.976617710514731, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:07:35,714 - INFO - _models.training_function_executor - Model: 27,477 parameters, 118.1KB storage
2025-10-02 22:07:35,714 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.07224688898864541, 0.03471397753671072, 0.02621606114262459, 0.02235850851458983, 0.01962375493788266, 0.016389923730291966, 0.015275632718113413, 0.013182107148811567, 0.011822775265724316, 0.011991693703148176, 0.010536589824335755, 0.010185904722792996, 0.008937767519051015, 0.009103206181269138, 0.007412987740843295, 0.007183216271422649, 0.005916876828665157, 0.006209201180516936, 0.005529042731735873, 0.005391824247922463, 0.005431402122689943, 0.0041180032152357895, 0.004261706494168579, 0.003994350946469459, 0.0036281814288867376, 0.003054694145211239, 0.003220499212075335, 0.0033168484683315175, 0.003912684012716004, 0.002673321124352964, 0.003285189770089521, 0.0023088574769667444, 0.0030084831413285293, 0.0021997433560360523, 0.0029168392087574203, 0.0030519672242632365, 0.0017713228788439114, 0.0020827824226199837, 0.00197390879482276, 0.0022255245579205726, 0.0016830399654371821, 0.0021396482271665673, 0.002204488824815325, 0.0014996517677276933, 0.001958019510549865, 0.001125378991588257, 0.0008926895264039323, 0.001252625812131276], 'val_losses': [0.03837334032545874, 0.03018174976166004, 0.02334325864505923, 0.033033551076349386, 0.023191266479977702, 0.02582461912291844, 0.024533336879441633, 0.032678133040006566, 0.040564523438497486, 0.0314434551744869, 0.04292469751591589, 0.041418880023050095, 0.04435380672215748, 0.031648959500544534, 0.043099258210318174, 0.05181198296822256, 0.043391680008164776, 0.054099114991462166, 0.057523034505061583, 0.05151737384874336, 0.048358050068004164, 0.05006433608328515, 0.05197576533962411, 0.046258123841964274, 0.05205331987117544, 0.060712964322883346, 0.06229056784263038, 0.05861278495354217, 0.06064002963394214, 0.06525211886286571, 0.06659808379731341, 0.07732880466893388, 0.07077280905290499, 0.06599020671816849, 0.054913820794778516, 0.08048478149875575, 0.07063314786453681, 0.09365527617585583, 0.10071091208074374, 0.07492213718366271, 0.0768262065117139, 0.08117500556215818, 0.09229330102661143, 0.09297204530152473, 0.07519621865481023, 0.08872434775167772, 0.08219287601528184, 0.07900043125309274], 'val_acc': [0.20862047362485903, 0.23192582383160004, 0.28492670091467237, 0.2764064653552186, 0.2891868186943992, 0.3133692519734369, 0.3519609071544919, 0.3332915674727478, 0.3797769703044731, 0.4158626738503947, 0.39042726475379025, 0.3911790502443303, 0.4235058263375517, 0.40709184312742763, 0.45683498308482645, 0.4518230798145596, 0.5114647287307355, 0.5462974564590903, 0.4197468988848515, 0.5914045858914923, 0.6060644029570229, 0.53877960155369, 0.5157248465104624, 0.6199724345320136, 0.5820072672597418, 0.6088209497556697, 0.6544292695150984, 0.5900263124921689, 0.6284926700914673, 0.6524245082069916, 0.668713193835359, 0.6783611076306227, 0.661445934093472, 0.5896504197468989, 0.6769828342312993, 0.6596917679488786, 0.6856283673725098, 0.675604560831976, 0.6677108131813057, 0.708808419997494, 0.7123167522866809, 0.7139456208495176, 0.7083072296704673, 0.6489161759178048, 0.6821200350833229, 0.7755920310738003, 0.7873700037589274, 0.7163262749028944], 'best_val_acc': 0.7873700037589274, 'model_size_bytes': 121774, 'config_used': {'epochs': 48, 'batch_size': 128, 'lr': 0.0010867825849791627, 'weight_decay': 5.960803295682008e-07, 'stem_channels': 10, 'nhead': 2, 'd_model': 30, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.06592550177919701, 'use_focal_loss': True, 'focal_gamma': 1.7128866799641864, 'label_smoothing': 0.044981034967549446, 'grad_clip_norm': 0.12115593081273127, 'sched_step': 5, 'sched_gamma': 0.976617710514731, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 48, 'batch_size': 128, 'lr': 0.0010867825849791627, 'weight_decay': 5.960803295682008e-07, 'stem_channels': 10, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.06592550177919701, 'use_focal_loss': True, 'focal_gamma': 1.7128866799641864, 'label_smoothing': 0.044981034967549446, 'grad_clip_norm': 0.12115593081273127, 'sched_step': 5, 'sched_gamma': 0.976617710514731, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 27477, 'model_storage_size_kb': 118.065234375, 'model_size_validation': 'PASS'}
2025-10-02 22:07:35,714 - INFO - _models.training_function_executor - BO Objective: base=0.7163, size_penalty=0.0000, final=0.7163
2025-10-02 22:07:35,714 - INFO - _models.training_function_executor - Model: 27,477 parameters, 118.1KB (PASS 256KB limit)
2025-10-02 22:07:35,714 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 211.388s
2025-10-02 22:07:35,803 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7163
2025-10-02 22:07:35,803 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.089s
2025-10-02 22:07:35,803 - INFO - bo.run_bo - Recorded observation #14: hparams={'epochs': np.int64(48), 'batch_size': np.int64(128), 'lr': 0.0010867825849791627, 'weight_decay': 5.960803295682008e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(2), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.06592550177919701, 'use_focal_loss': np.True_, 'focal_gamma': 1.7128866799641864, 'label_smoothing': 0.044981034967549446, 'grad_clip_norm': 0.12115593081273127, 'sched_step': np.int64(5), 'sched_gamma': 0.976617710514731, 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7163
2025-10-02 22:07:35,803 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 14: {'epochs': np.int64(48), 'batch_size': np.int64(128), 'lr': 0.0010867825849791627, 'weight_decay': 5.960803295682008e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(2), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.06592550177919701, 'use_focal_loss': np.True_, 'focal_gamma': 1.7128866799641864, 'label_smoothing': 0.044981034967549446, 'grad_clip_norm': 0.12115593081273127, 'sched_step': np.int64(5), 'sched_gamma': 0.976617710514731, 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7163
2025-10-02 22:07:35,803 - INFO - bo.run_bo - üîçBO Trial 15: Using RF surrogate + Expected Improvement
2025-10-02 22:07:35,803 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:07:35,804 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:07:35,804 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:07:35,804 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 12, 'batch_size': 128, 'lr': 0.0018061599094632258, 'weight_decay': 2.3844478898615256e-06, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 13, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.0178507310154205, 'use_focal_loss': False, 'focal_gamma': 2.446905290488739, 'label_smoothing': 0.07681350333785256, 'grad_clip_norm': 0.7377497894191393, 'sched_step': 3, 'sched_gamma': 0.3136038123306479, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:07:35,805 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 12, 'batch_size': 128, 'lr': 0.0018061599094632258, 'weight_decay': 2.3844478898615256e-06, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 13, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.0178507310154205, 'use_focal_loss': False, 'focal_gamma': 2.446905290488739, 'label_smoothing': 0.07681350333785256, 'grad_clip_norm': 0.7377497894191393, 'sched_step': 3, 'sched_gamma': 0.3136038123306479, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:08:14,275 - INFO - _models.training_function_executor - Model: 26,011 parameters, 27.9KB storage
2025-10-02 22:08:14,275 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5804459105920243, 1.3033020737901373, 1.2521530788046291, 1.1911234878244226, 1.1676547371817985, 1.1579113161377532, 1.1353248652892651, 1.1314241667123635, 1.1260930226343047, 1.1168708915725087, 1.118042496254998, 1.1169913679728236], 'val_losses': [1.3517904480273466, 1.2727023195374985, 1.271610279755998, 1.2020242231380012, 1.1967415354661424, 1.1841451598056172, 1.1807664374841542, 1.1786734669478283, 1.1823273055342232, 1.1771702228848937, 1.1783861650618197, 1.1803104607566917], 'val_acc': [0.5729858413732615, 0.7388798396190953, 0.5333918055381531, 0.7460218017792256, 0.8269640395940359, 0.6994111013657437, 0.784488159378524, 0.8278411226663326, 0.815060769327152, 0.8004009522616213, 0.7753414359102869, 0.8141836862548553], 'best_val_acc': 0.8278411226663326, 'model_size_bytes': 121280, 'config_used': {'epochs': 12, 'batch_size': 128, 'lr': 0.0018061599094632258, 'weight_decay': 2.3844478898615256e-06, 'stem_channels': 12, 'nhead': 4, 'd_model': 52, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.0178507310154205, 'use_focal_loss': False, 'focal_gamma': 2.446905290488739, 'label_smoothing': 0.07681350333785256, 'grad_clip_norm': 0.7377497894191393, 'sched_step': 3, 'sched_gamma': 0.3136038123306479, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 12, 'batch_size': 128, 'lr': 0.0018061599094632258, 'weight_decay': 2.3844478898615256e-06, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 13, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.0178507310154205, 'use_focal_loss': False, 'focal_gamma': 2.446905290488739, 'label_smoothing': 0.07681350333785256, 'grad_clip_norm': 0.7377497894191393, 'sched_step': 3, 'sched_gamma': 0.3136038123306479, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 26011, 'model_storage_size_kb': 27.941503906250002, 'model_size_validation': 'PASS'}
2025-10-02 22:08:14,275 - INFO - _models.training_function_executor - BO Objective: base=0.8142, size_penalty=0.0000, final=0.8142
2025-10-02 22:08:14,275 - INFO - _models.training_function_executor - Model: 26,011 parameters, 27.9KB (PASS 256KB limit)
2025-10-02 22:08:14,275 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 38.472s
2025-10-02 22:08:14,363 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8142
2025-10-02 22:08:14,363 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.088s
2025-10-02 22:08:14,364 - INFO - bo.run_bo - Recorded observation #15: hparams={'epochs': np.int64(12), 'batch_size': np.int64(128), 'lr': 0.0018061599094632258, 'weight_decay': 2.3844478898615256e-06, 'stem_channels': np.int64(12), 'nhead': np.int64(4), 'd_model_factor': np.int64(13), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.0178507310154205, 'use_focal_loss': np.False_, 'focal_gamma': 2.446905290488739, 'label_smoothing': 0.07681350333785256, 'grad_clip_norm': 0.7377497894191393, 'sched_step': np.int64(3), 'sched_gamma': 0.3136038123306479, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8142
2025-10-02 22:08:14,364 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 15: {'epochs': np.int64(12), 'batch_size': np.int64(128), 'lr': 0.0018061599094632258, 'weight_decay': 2.3844478898615256e-06, 'stem_channels': np.int64(12), 'nhead': np.int64(4), 'd_model_factor': np.int64(13), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.0178507310154205, 'use_focal_loss': np.False_, 'focal_gamma': 2.446905290488739, 'label_smoothing': 0.07681350333785256, 'grad_clip_norm': 0.7377497894191393, 'sched_step': np.int64(3), 'sched_gamma': 0.3136038123306479, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8142
2025-10-02 22:08:14,364 - INFO - bo.run_bo - üîçBO Trial 16: Using RF surrogate + Expected Improvement
2025-10-02 22:08:14,364 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:08:14,364 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:08:14,364 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:08:14,364 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 8, 'batch_size': 32, 'lr': 0.00099863797087451, 'weight_decay': 1.0028157115714436e-07, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.10691598190738263, 'use_focal_loss': True, 'focal_gamma': 2.804415976019726, 'label_smoothing': 0.021606119907435165, 'grad_clip_norm': 0.9308266984684189, 'sched_step': 10, 'sched_gamma': 0.15345020304856297, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:08:14,365 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 8, 'batch_size': 32, 'lr': 0.00099863797087451, 'weight_decay': 1.0028157115714436e-07, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.10691598190738263, 'use_focal_loss': True, 'focal_gamma': 2.804415976019726, 'label_smoothing': 0.021606119907435165, 'grad_clip_norm': 0.9308266984684189, 'sched_step': 10, 'sched_gamma': 0.15345020304856297, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:09:11,243 - INFO - _models.training_function_executor - Model: 90,237 parameters, 387.7KB storage
2025-10-02 22:09:11,243 - WARNING - _models.training_function_executor - Model storage 387.7KB exceeds 256KB limit!
2025-10-02 22:09:11,243 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.037278779551208986, 0.01980878739128429, 0.015858912090563473, 0.01376050377758652, 0.011768804455760177, 0.0118998125505656, 0.008992181356699424, 0.008767150294983712], 'val_losses': [0.02646686849322615, 0.015792438581568615, 0.0198726667289015, 0.0161654999741451, 0.014395628570357394, 0.02011623220980217, 0.016990812277252618, 0.018516128068719124], 'val_acc': [0.0808169402330535, 0.1680240571356973, 0.1777972685127177, 0.20636511715323894, 0.18518982583636137, 0.1724094724971808, 0.22415737376268638, 0.20711690264377897], 'best_val_acc': 0.22415737376268638, 'model_size_bytes': 373358, 'config_used': {'epochs': 8, 'batch_size': 32, 'lr': 0.00099863797087451, 'weight_decay': 1.0028157115714436e-07, 'stem_channels': 10, 'nhead': 4, 'd_model': 60, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.10691598190738263, 'use_focal_loss': True, 'focal_gamma': 2.804415976019726, 'label_smoothing': 0.021606119907435165, 'grad_clip_norm': 0.9308266984684189, 'sched_step': 10, 'sched_gamma': 0.15345020304856297, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 8, 'batch_size': 32, 'lr': 0.00099863797087451, 'weight_decay': 1.0028157115714436e-07, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.10691598190738263, 'use_focal_loss': True, 'focal_gamma': 2.804415976019726, 'label_smoothing': 0.021606119907435165, 'grad_clip_norm': 0.9308266984684189, 'sched_step': 10, 'sched_gamma': 0.15345020304856297, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 90237, 'model_storage_size_kb': 387.73710937500005, 'model_size_validation': 'FAIL'}
2025-10-02 22:09:11,243 - INFO - _models.training_function_executor - BO Objective: base=0.2071, size_penalty=0.2573, final=-0.0502
2025-10-02 22:09:11,243 - INFO - _models.training_function_executor - Model: 90,237 parameters, 387.7KB (FAIL 256KB limit)
2025-10-02 22:09:11,243 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 56.880s
2025-10-02 22:09:11,334 - INFO - bo.run_bo - Updated RF surrogate model with observation: -0.0502
2025-10-02 22:09:11,334 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.091s
2025-10-02 22:09:11,334 - INFO - bo.run_bo - Recorded observation #16: hparams={'epochs': np.int64(8), 'batch_size': np.int64(32), 'lr': 0.00099863797087451, 'weight_decay': 1.0028157115714436e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.10691598190738263, 'use_focal_loss': np.True_, 'focal_gamma': 2.804415976019726, 'label_smoothing': 0.021606119907435165, 'grad_clip_norm': 0.9308266984684189, 'sched_step': np.int64(10), 'sched_gamma': 0.15345020304856297, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=-0.0502
2025-10-02 22:09:11,334 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 16: {'epochs': np.int64(8), 'batch_size': np.int64(32), 'lr': 0.00099863797087451, 'weight_decay': 1.0028157115714436e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.10691598190738263, 'use_focal_loss': np.True_, 'focal_gamma': 2.804415976019726, 'label_smoothing': 0.021606119907435165, 'grad_clip_norm': 0.9308266984684189, 'sched_step': np.int64(10), 'sched_gamma': 0.15345020304856297, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> -0.0502
2025-10-02 22:09:11,335 - INFO - bo.run_bo - üîçBO Trial 17: Using RF surrogate + Expected Improvement
2025-10-02 22:09:11,335 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:09:11,335 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:09:11,335 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:09:11,335 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 7, 'batch_size': 32, 'lr': 0.0020020436971517367, 'weight_decay': 3.636810125123971e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.04945183662191624, 'use_focal_loss': True, 'focal_gamma': 2.83667714676681, 'label_smoothing': 0.009984197286891563, 'grad_clip_norm': 0.02971640994694192, 'sched_step': 4, 'sched_gamma': 0.906675220946786, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:09:11,336 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 7, 'batch_size': 32, 'lr': 0.0020020436971517367, 'weight_decay': 3.636810125123971e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.04945183662191624, 'use_focal_loss': True, 'focal_gamma': 2.83667714676681, 'label_smoothing': 0.009984197286891563, 'grad_clip_norm': 0.02971640994694192, 'sched_step': 4, 'sched_gamma': 0.906675220946786, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:10:01,788 - INFO - _models.training_function_executor - Model: 91,569 parameters, 393.5KB storage
2025-10-02 22:10:01,788 - WARNING - _models.training_function_executor - Model storage 393.5KB exceeds 256KB limit!
2025-10-02 22:10:01,788 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.055502007825587056, 0.03450036818651789, 0.026014933099278388, 0.024668795566048847, 0.019498330257172892, 0.019266084056017124, 0.016846037741108183], 'val_losses': [0.06824516359198655, 0.028904893986909718, 0.03302545140878621, 0.028285870499966805, 0.041389581855215206, 0.021021583497495323, 0.025564621881272724], 'val_acc': [0.2254103495802531, 0.2208996366370129, 0.25347700789374766, 0.29758175667209624, 0.2881844380403458, 0.2837990226788623, 0.30973562210249345], 'best_val_acc': 0.30973562210249345, 'model_size_bytes': 378478, 'config_used': {'epochs': 7, 'batch_size': 32, 'lr': 0.0020020436971517367, 'weight_decay': 3.636810125123971e-07, 'stem_channels': 16, 'nhead': 4, 'd_model': 60, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.04945183662191624, 'use_focal_loss': True, 'focal_gamma': 2.83667714676681, 'label_smoothing': 0.009984197286891563, 'grad_clip_norm': 0.02971640994694192, 'sched_step': 4, 'sched_gamma': 0.906675220946786, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 7, 'batch_size': 32, 'lr': 0.0020020436971517367, 'weight_decay': 3.636810125123971e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.04945183662191624, 'use_focal_loss': True, 'focal_gamma': 2.83667714676681, 'label_smoothing': 0.009984197286891563, 'grad_clip_norm': 0.02971640994694192, 'sched_step': 4, 'sched_gamma': 0.906675220946786, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 91569, 'model_storage_size_kb': 393.46054687500003, 'model_size_validation': 'FAIL'}
2025-10-02 22:10:01,788 - INFO - _models.training_function_executor - BO Objective: base=0.3097, size_penalty=0.2685, final=0.0413
2025-10-02 22:10:01,788 - INFO - _models.training_function_executor - Model: 91,569 parameters, 393.5KB (FAIL 256KB limit)
2025-10-02 22:10:01,788 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 50.453s
2025-10-02 22:10:01,878 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.0413
2025-10-02 22:10:01,878 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.090s
2025-10-02 22:10:01,878 - INFO - bo.run_bo - Recorded observation #17: hparams={'epochs': np.int64(7), 'batch_size': np.int64(32), 'lr': 0.0020020436971517367, 'weight_decay': 3.636810125123971e-07, 'stem_channels': np.int64(16), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.04945183662191624, 'use_focal_loss': np.True_, 'focal_gamma': 2.83667714676681, 'label_smoothing': 0.009984197286891563, 'grad_clip_norm': 0.02971640994694192, 'sched_step': np.int64(4), 'sched_gamma': 0.906675220946786, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.0413
2025-10-02 22:10:01,878 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 17: {'epochs': np.int64(7), 'batch_size': np.int64(32), 'lr': 0.0020020436971517367, 'weight_decay': 3.636810125123971e-07, 'stem_channels': np.int64(16), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.04945183662191624, 'use_focal_loss': np.True_, 'focal_gamma': 2.83667714676681, 'label_smoothing': 0.009984197286891563, 'grad_clip_norm': 0.02971640994694192, 'sched_step': np.int64(4), 'sched_gamma': 0.906675220946786, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.0413
2025-10-02 22:10:01,878 - INFO - bo.run_bo - üîçBO Trial 18: Using RF surrogate + Expected Improvement
2025-10-02 22:10:01,878 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:10:01,878 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:10:01,878 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:10:01,878 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 27, 'batch_size': 64, 'lr': 0.00283724263692823, 'weight_decay': 1.3041413515755317e-06, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.030763413049417338, 'use_focal_loss': False, 'focal_gamma': 2.017560215882953, 'label_smoothing': 0.0011381265161172663, 'grad_clip_norm': 0.38468206564631946, 'sched_step': 3, 'sched_gamma': 0.5829416439129095, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:10:01,880 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 27, 'batch_size': 64, 'lr': 0.00283724263692823, 'weight_decay': 1.3041413515755317e-06, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.030763413049417338, 'use_focal_loss': False, 'focal_gamma': 2.017560215882953, 'label_smoothing': 0.0011381265161172663, 'grad_clip_norm': 0.38468206564631946, 'sched_step': 3, 'sched_gamma': 0.5829416439129095, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:11:49,211 - INFO - _models.training_function_executor - Model: 46,872 parameters, 201.4KB storage
2025-10-02 22:11:49,211 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8631115133566012, 0.5406485417767268, 0.4670497376583903, 0.36570980378911744, 0.3401737832725823, 0.32501435311354143, 0.26415318638367324, 0.2512750802643036, 0.24050186761126194, 0.20187222822546994, 0.19797477937579674, 0.19171851649808058, 0.16855080975518058, 0.15978616749734706, 0.15494504143748167, 0.1442514717797343, 0.1407959637759387, 0.1337183813333392, 0.1262936309216648, 0.124193561642674, 0.12137701804813121, 0.11752277497483746, 0.11681405988408708, 0.11598259503260422, 0.11577192789196121, 0.11100983381559835, 0.11034187783329864], 'val_losses': [0.7290973775093454, 0.4812934680729488, 0.6032767449759433, 0.3762488333545014, 0.4389659012638078, 0.4264884699243843, 0.40597603376639724, 0.4274807198724865, 0.4157791698192567, 0.4228060905526506, 0.408218667540331, 0.5143353667134943, 0.4617311691016037, 0.4906974205500559, 0.5154630175853878, 0.5027495486487453, 0.5413446635877918, 0.5410441180067752, 0.5786680884602344, 0.5545713369850227, 0.6058854807246196, 0.5900294242041435, 0.5577697023728814, 0.5955326280010148, 0.5921016277234487, 0.584599690163379, 0.6000505003650122], 'val_acc': [0.7960155369001378, 0.7603057260994863, 0.7992732740258113, 0.8750783109885979, 0.8664327778473876, 0.8851021175291317, 0.8903646159629119, 0.8982583636135822, 0.9171782984588397, 0.908658062899386, 0.9214384162385666, 0.9463726350081444, 0.937727101866934, 0.939606565593284, 0.9412354341561208, 0.9364741260493672, 0.9389800776845006, 0.9419872196466608, 0.940358351083824, 0.9451196591905776, 0.9480015035709811, 0.9418619220649042, 0.9424884099736875, 0.9443678737000376, 0.9446184688635509, 0.9456208495176043, 0.9462473374263877], 'best_val_acc': 0.9480015035709811, 'model_size_bytes': 195922, 'config_used': {'epochs': 27, 'batch_size': 64, 'lr': 0.00283724263692823, 'weight_decay': 1.3041413515755317e-06, 'stem_channels': 13, 'nhead': 4, 'd_model': 60, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.030763413049417338, 'use_focal_loss': False, 'focal_gamma': 2.017560215882953, 'label_smoothing': 0.0011381265161172663, 'grad_clip_norm': 0.38468206564631946, 'sched_step': 3, 'sched_gamma': 0.5829416439129095, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 27, 'batch_size': 64, 'lr': 0.00283724263692823, 'weight_decay': 1.3041413515755317e-06, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.030763413049417338, 'use_focal_loss': False, 'focal_gamma': 2.017560215882953, 'label_smoothing': 0.0011381265161172663, 'grad_clip_norm': 0.38468206564631946, 'sched_step': 3, 'sched_gamma': 0.5829416439129095, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 46872, 'model_storage_size_kb': 201.40312500000002, 'model_size_validation': 'PASS'}
2025-10-02 22:11:49,211 - INFO - _models.training_function_executor - BO Objective: base=0.9462, size_penalty=0.0000, final=0.9462
2025-10-02 22:11:49,211 - INFO - _models.training_function_executor - Model: 46,872 parameters, 201.4KB (PASS 256KB limit)
2025-10-02 22:11:49,211 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 107.333s
2025-10-02 22:11:49,302 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9462
2025-10-02 22:11:49,302 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.091s
2025-10-02 22:11:49,302 - INFO - bo.run_bo - Recorded observation #18: hparams={'epochs': np.int64(27), 'batch_size': np.int64(64), 'lr': 0.00283724263692823, 'weight_decay': 1.3041413515755317e-06, 'stem_channels': np.int64(13), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.030763413049417338, 'use_focal_loss': np.False_, 'focal_gamma': 2.017560215882953, 'label_smoothing': 0.0011381265161172663, 'grad_clip_norm': 0.38468206564631946, 'sched_step': np.int64(3), 'sched_gamma': 0.5829416439129095, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.9462
2025-10-02 22:11:49,302 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 18: {'epochs': np.int64(27), 'batch_size': np.int64(64), 'lr': 0.00283724263692823, 'weight_decay': 1.3041413515755317e-06, 'stem_channels': np.int64(13), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.030763413049417338, 'use_focal_loss': np.False_, 'focal_gamma': 2.017560215882953, 'label_smoothing': 0.0011381265161172663, 'grad_clip_norm': 0.38468206564631946, 'sched_step': np.int64(3), 'sched_gamma': 0.5829416439129095, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.9462
2025-10-02 22:11:49,303 - INFO - bo.run_bo - üîçBO Trial 19: Using RF surrogate + Expected Improvement
2025-10-02 22:11:49,303 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:11:49,303 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:11:49,303 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:11:49,303 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 12, 'batch_size': 128, 'lr': 0.004753940240278101, 'weight_decay': 1.705808780819046e-06, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.020727904101008356, 'use_focal_loss': True, 'focal_gamma': 1.1110717161592314, 'label_smoothing': 0.03159271218182869, 'grad_clip_norm': 0.351388686913595, 'sched_step': 3, 'sched_gamma': 0.5742349442560839, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:11:49,304 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 12, 'batch_size': 128, 'lr': 0.004753940240278101, 'weight_decay': 1.705808780819046e-06, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.020727904101008356, 'use_focal_loss': True, 'focal_gamma': 1.1110717161592314, 'label_smoothing': 0.03159271218182869, 'grad_clip_norm': 0.351388686913595, 'sched_step': 3, 'sched_gamma': 0.5742349442560839, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:12:27,085 - INFO - _models.training_function_executor - Model: 59,787 parameters, 256.9KB storage
2025-10-02 22:12:27,085 - WARNING - _models.training_function_executor - Model storage 256.9KB exceeds 256KB limit!
2025-10-02 22:12:27,085 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.09661636078667268, 0.06446885888196377, 0.046800166215087445, 0.03451178206329654, 0.03000164387952272, 0.026154752965550098, 0.019388729820126963, 0.017554059637596032, 0.01596383918874955, 0.012176575377108317, 0.010572249982081847, 0.009520922829935722], 'val_losses': [0.07805036794818548, 0.07155651080167363, 0.052979769646120674, 0.037887381115509836, 0.03563349609668281, 0.034802306729115995, 0.035257281028149706, 0.035364823158918625, 0.03950478980132638, 0.03951488243706049, 0.04457121136201651, 0.04779824891599434], 'val_acc': [0.2272898133066032, 0.1782984588397444, 0.36035584513218893, 0.2950758050369628, 0.35622102493421876, 0.4169903520862047, 0.5306352587395063, 0.5385290063901766, 0.6413983210124045, 0.6276155870191705, 0.676356346322516, 0.69164265129683], 'best_val_acc': 0.69164265129683, 'model_size_bytes': 248146, 'config_used': {'epochs': 12, 'batch_size': 128, 'lr': 0.004753940240278101, 'weight_decay': 1.705808780819046e-06, 'stem_channels': 11, 'nhead': 4, 'd_model': 64, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.020727904101008356, 'use_focal_loss': True, 'focal_gamma': 1.1110717161592314, 'label_smoothing': 0.03159271218182869, 'grad_clip_norm': 0.351388686913595, 'sched_step': 3, 'sched_gamma': 0.5742349442560839, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 12, 'batch_size': 128, 'lr': 0.004753940240278101, 'weight_decay': 1.705808780819046e-06, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 3, 'dropout': 0.020727904101008356, 'use_focal_loss': True, 'focal_gamma': 1.1110717161592314, 'label_smoothing': 0.03159271218182869, 'grad_clip_norm': 0.351388686913595, 'sched_step': 3, 'sched_gamma': 0.5742349442560839, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 59787, 'model_storage_size_kb': 256.89726562500005, 'model_size_validation': 'FAIL'}
2025-10-02 22:12:27,085 - INFO - _models.training_function_executor - BO Objective: base=0.6916, size_penalty=0.0018, final=0.6899
2025-10-02 22:12:27,085 - INFO - _models.training_function_executor - Model: 59,787 parameters, 256.9KB (FAIL 256KB limit)
2025-10-02 22:12:27,085 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 37.783s
2025-10-02 22:12:27,178 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6899
2025-10-02 22:12:27,179 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.093s
2025-10-02 22:12:27,179 - INFO - bo.run_bo - Recorded observation #19: hparams={'epochs': np.int64(12), 'batch_size': np.int64(128), 'lr': 0.004753940240278101, 'weight_decay': 1.705808780819046e-06, 'stem_channels': np.int64(11), 'nhead': np.int64(4), 'd_model_factor': np.int64(16), 'num_layers': np.int64(1), 'ff_factor': np.int64(3), 'dropout': 0.020727904101008356, 'use_focal_loss': np.True_, 'focal_gamma': 1.1110717161592314, 'label_smoothing': 0.03159271218182869, 'grad_clip_norm': 0.351388686913595, 'sched_step': np.int64(3), 'sched_gamma': 0.5742349442560839, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.6899
2025-10-02 22:12:27,179 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 19: {'epochs': np.int64(12), 'batch_size': np.int64(128), 'lr': 0.004753940240278101, 'weight_decay': 1.705808780819046e-06, 'stem_channels': np.int64(11), 'nhead': np.int64(4), 'd_model_factor': np.int64(16), 'num_layers': np.int64(1), 'ff_factor': np.int64(3), 'dropout': 0.020727904101008356, 'use_focal_loss': np.True_, 'focal_gamma': 1.1110717161592314, 'label_smoothing': 0.03159271218182869, 'grad_clip_norm': 0.351388686913595, 'sched_step': np.int64(3), 'sched_gamma': 0.5742349442560839, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.6899
2025-10-02 22:12:27,179 - INFO - bo.run_bo - üîçBO Trial 20: Using RF surrogate + Expected Improvement
2025-10-02 22:12:27,179 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:12:27,179 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:12:27,179 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:12:27,179 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 22, 'batch_size': 32, 'lr': 0.0018568861852492323, 'weight_decay': 1.4703158571652986e-06, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.07371877120697728, 'use_focal_loss': False, 'focal_gamma': 2.96225279686237, 'label_smoothing': 0.03028743971119579, 'grad_clip_norm': 0.8153465405823048, 'sched_step': 1, 'sched_gamma': 0.5305522996459479, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:12:27,180 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 22, 'batch_size': 32, 'lr': 0.0018568861852492323, 'weight_decay': 1.4703158571652986e-06, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.07371877120697728, 'use_focal_loss': False, 'focal_gamma': 2.96225279686237, 'label_smoothing': 0.03028743971119579, 'grad_clip_norm': 0.8153465405823048, 'sched_step': 1, 'sched_gamma': 0.5305522996459479, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:13:59,662 - INFO - _models.training_function_executor - Model: 46,443 parameters, 199.6KB storage
2025-10-02 22:13:59,663 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1485822321989743, 0.895901299746298, 0.835360299311227, 0.798337529532403, 0.7728373342015498, 0.7567647040792117, 0.7522247755500983, 0.7470510269926891, 0.7447853159404834, 0.7433235018159895, 0.7450701697586779, 0.7446305215203761, 0.7496830734756847, 0.7440070474883076, 0.7389401492553296, 0.7389920788913936, 0.7447207576293559, 0.7398758968553967, 0.7408088332626921, 0.743615856241008, 0.7451121003090116, 0.7474620255040625], 'val_losses': [0.9450619053592689, 0.9388916484695108, 0.8694836825838126, 0.8420228155733813, 0.8723579330890046, 0.8352784554233319, 0.842963922921465, 0.8468589624386506, 0.8401518130030582, 0.8438546075481562, 0.8434324587605797, 0.8442809829256646, 0.8443208132123546, 0.8443418459073148, 0.8443721275612789, 0.8442743469966472, 0.8442911368954258, 0.8442897193190777, 0.8442919912709881, 0.8442908825245198, 0.8442899425919081, 0.844289761171531], 'val_acc': [0.8510211752913168, 0.9164265129682997, 0.9027690765568225, 0.8996366370129056, 0.9309610324520736, 0.901014910412229, 0.9097857411351961, 0.9169277032953264, 0.909033955644656, 0.9158000250595163, 0.9139205613331662, 0.9154241323142464, 0.9150482395689763, 0.9150482395689763, 0.915173537150733, 0.915173537150733, 0.915173537150733, 0.915173537150733, 0.915173537150733, 0.915173537150733, 0.915173537150733, 0.915173537150733], 'best_val_acc': 0.9309610324520736, 'model_size_bytes': 194258, 'config_used': {'epochs': 22, 'batch_size': 32, 'lr': 0.0018568861852492323, 'weight_decay': 1.4703158571652986e-06, 'stem_channels': 11, 'nhead': 4, 'd_model': 60, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.07371877120697728, 'use_focal_loss': False, 'focal_gamma': 2.96225279686237, 'label_smoothing': 0.03028743971119579, 'grad_clip_norm': 0.8153465405823048, 'sched_step': 1, 'sched_gamma': 0.5305522996459479, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 22, 'batch_size': 32, 'lr': 0.0018568861852492323, 'weight_decay': 1.4703158571652986e-06, 'stem_channels': 11, 'nhead': 4, 'd_model_factor': 15, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.07371877120697728, 'use_focal_loss': False, 'focal_gamma': 2.96225279686237, 'label_smoothing': 0.03028743971119579, 'grad_clip_norm': 0.8153465405823048, 'sched_step': 1, 'sched_gamma': 0.5305522996459479, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 46443, 'model_storage_size_kb': 199.559765625, 'model_size_validation': 'PASS'}
2025-10-02 22:13:59,663 - INFO - _models.training_function_executor - BO Objective: base=0.9152, size_penalty=0.0000, final=0.9152
2025-10-02 22:13:59,663 - INFO - _models.training_function_executor - Model: 46,443 parameters, 199.6KB (PASS 256KB limit)
2025-10-02 22:13:59,663 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 92.484s
2025-10-02 22:13:59,755 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9152
2025-10-02 22:13:59,756 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.093s
2025-10-02 22:13:59,756 - INFO - bo.run_bo - Recorded observation #20: hparams={'epochs': np.int64(22), 'batch_size': np.int64(32), 'lr': 0.0018568861852492323, 'weight_decay': 1.4703158571652986e-06, 'stem_channels': np.int64(11), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.07371877120697728, 'use_focal_loss': np.False_, 'focal_gamma': 2.96225279686237, 'label_smoothing': 0.03028743971119579, 'grad_clip_norm': 0.8153465405823048, 'sched_step': np.int64(1), 'sched_gamma': 0.5305522996459479, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.9152
2025-10-02 22:13:59,756 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 20: {'epochs': np.int64(22), 'batch_size': np.int64(32), 'lr': 0.0018568861852492323, 'weight_decay': 1.4703158571652986e-06, 'stem_channels': np.int64(11), 'nhead': np.int64(4), 'd_model_factor': np.int64(15), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.07371877120697728, 'use_focal_loss': np.False_, 'focal_gamma': 2.96225279686237, 'label_smoothing': 0.03028743971119579, 'grad_clip_norm': 0.8153465405823048, 'sched_step': np.int64(1), 'sched_gamma': 0.5305522996459479, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.9152
2025-10-02 22:13:59,756 - INFO - bo.run_bo - üîçBO Trial 21: Using RF surrogate + Expected Improvement
2025-10-02 22:13:59,756 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:13:59,756 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:13:59,756 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:13:59,756 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 27, 'batch_size': 256, 'lr': 0.003065553744435082, 'weight_decay': 1.5500510346108064e-07, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 11, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.06135523735101173, 'use_focal_loss': False, 'focal_gamma': 2.5518117079470786, 'label_smoothing': 0.00933248415732625, 'grad_clip_norm': 0.9419706121074667, 'sched_step': 2, 'sched_gamma': 0.6569471005910954, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:13:59,757 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 27, 'batch_size': 256, 'lr': 0.003065553744435082, 'weight_decay': 1.5500510346108064e-07, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 11, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.06135523735101173, 'use_focal_loss': False, 'focal_gamma': 2.5518117079470786, 'label_smoothing': 0.00933248415732625, 'grad_clip_norm': 0.9419706121074667, 'sched_step': 2, 'sched_gamma': 0.6569471005910954, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:15:21,721 - INFO - _models.training_function_executor - Model: 28,481 parameters, 122.4KB storage
2025-10-02 22:15:21,721 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1009983260451643, 0.7415349288262046, 0.5966594722905568, 0.5444883259022456, 0.4887699962980492, 0.4573938748600735, 0.42866214990048235, 0.4114395918596083, 0.3860752684047668, 0.3788948412549917, 0.3649871561955051, 0.35308236929123304, 0.3424211224323488, 0.34071229816676196, 0.333438362813633, 0.3279240892274231, 0.32499237775968787, 0.3242170560465635, 0.320228631378501, 0.3189168754117036, 0.3172470363698888, 0.3165360973397618, 0.31570172197100355, 0.31524830055202085, 0.31321315156245777, 0.31340755300855244, 0.3127220045021668], 'val_losses': [0.8660978768167901, 0.674838207379243, 0.6175574439985831, 0.6309432464947812, 0.5533404151996922, 0.5432492012876629, 0.5377284708797984, 0.5513612814317623, 0.5279404880961385, 0.561764935057439, 0.5362962636937475, 0.5532036916293412, 0.5775699789565005, 0.5439811740180273, 0.5536542981956376, 0.5514840879635678, 0.5636760763410428, 0.5631956127469304, 0.56754282376414, 0.5608880488798741, 0.565965616744856, 0.5682481877741965, 0.577687663663645, 0.5741209994654745, 0.5721339380109299, 0.5756532691980182, 0.5731344713093478], 'val_acc': [0.5751159002631249, 0.7540408470116526, 0.8139330910913419, 0.8094223781481017, 0.8466357599298333, 0.8025310111514847, 0.8654303971933341, 0.8968800902142589, 0.8768324771331913, 0.9040220523743892, 0.8830973562210249, 0.9028943741385791, 0.9120410976068162, 0.8990101491041222, 0.9031449693020924, 0.8988848515223656, 0.9069038967547927, 0.9008896128304724, 0.9046485402831725, 0.9036461596291192, 0.9070291943365493, 0.9047738378649292, 0.9096604435534394, 0.906402706427766, 0.9054003257737125, 0.9061521112642525, 0.9051497306101992], 'best_val_acc': 0.9120410976068162, 'model_size_bytes': 65618, 'config_used': {'epochs': 27, 'batch_size': 256, 'lr': 0.003065553744435082, 'weight_decay': 1.5500510346108064e-07, 'stem_channels': 10, 'nhead': 4, 'd_model': 44, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.06135523735101173, 'use_focal_loss': False, 'focal_gamma': 2.5518117079470786, 'label_smoothing': 0.00933248415732625, 'grad_clip_norm': 0.9419706121074667, 'sched_step': 2, 'sched_gamma': 0.6569471005910954, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 27, 'batch_size': 256, 'lr': 0.003065553744435082, 'weight_decay': 1.5500510346108064e-07, 'stem_channels': 10, 'nhead': 4, 'd_model_factor': 11, 'num_layers': 1, 'ff_factor': 2, 'dropout': 0.06135523735101173, 'use_focal_loss': False, 'focal_gamma': 2.5518117079470786, 'label_smoothing': 0.00933248415732625, 'grad_clip_norm': 0.9419706121074667, 'sched_step': 2, 'sched_gamma': 0.6569471005910954, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 28481, 'model_storage_size_kb': 122.37929687500001, 'model_size_validation': 'PASS'}
2025-10-02 22:15:21,721 - INFO - _models.training_function_executor - BO Objective: base=0.9051, size_penalty=0.0000, final=0.9051
2025-10-02 22:15:21,721 - INFO - _models.training_function_executor - Model: 28,481 parameters, 122.4KB (PASS 256KB limit)
2025-10-02 22:15:21,721 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 81.965s
2025-10-02 22:15:21,815 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9051
2025-10-02 22:15:21,815 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-02 22:15:21,815 - INFO - bo.run_bo - Recorded observation #21: hparams={'epochs': np.int64(27), 'batch_size': np.int64(256), 'lr': 0.003065553744435082, 'weight_decay': 1.5500510346108064e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(4), 'd_model_factor': np.int64(11), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.06135523735101173, 'use_focal_loss': np.False_, 'focal_gamma': 2.5518117079470786, 'label_smoothing': 0.00933248415732625, 'grad_clip_norm': 0.9419706121074667, 'sched_step': np.int64(2), 'sched_gamma': 0.6569471005910954, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.9051
2025-10-02 22:15:21,816 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 21: {'epochs': np.int64(27), 'batch_size': np.int64(256), 'lr': 0.003065553744435082, 'weight_decay': 1.5500510346108064e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(4), 'd_model_factor': np.int64(11), 'num_layers': np.int64(1), 'ff_factor': np.int64(2), 'dropout': 0.06135523735101173, 'use_focal_loss': np.False_, 'focal_gamma': 2.5518117079470786, 'label_smoothing': 0.00933248415732625, 'grad_clip_norm': 0.9419706121074667, 'sched_step': np.int64(2), 'sched_gamma': 0.6569471005910954, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.9051
2025-10-02 22:15:21,816 - INFO - bo.run_bo - üîçBO Trial 22: Using RF surrogate + Expected Improvement
2025-10-02 22:15:21,816 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:15:21,816 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:15:21,816 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:15:21,816 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 50, 'batch_size': 32, 'lr': 0.002319083337111503, 'weight_decay': 1.7460338537336055e-06, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.009935603502147162, 'use_focal_loss': False, 'focal_gamma': 2.510472574337971, 'label_smoothing': 0.013820836066519196, 'grad_clip_norm': 0.568807548059657, 'sched_step': 7, 'sched_gamma': 0.8105306226067164, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:15:21,817 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 50, 'batch_size': 32, 'lr': 0.002319083337111503, 'weight_decay': 1.7460338537336055e-06, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.009935603502147162, 'use_focal_loss': False, 'focal_gamma': 2.510472574337971, 'label_smoothing': 0.013820836066519196, 'grad_clip_norm': 0.568807548059657, 'sched_step': 7, 'sched_gamma': 0.8105306226067164, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:19:54,479 - INFO - _models.training_function_executor - Model: 23,385 parameters, 100.5KB storage
2025-10-02 22:19:54,480 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.941344718465126, 0.6826726908941143, 0.6220834993391494, 0.5899521685055883, 0.5627127166092816, 0.5441510213400544, 0.5320676653140493, 0.49615549943173987, 0.47709419823258986, 0.47205889031290543, 0.4638354442466363, 0.45712386761169344, 0.44265330072124887, 0.45252056691938075, 0.4223536741353402, 0.4090695181567504, 0.40528176976554253, 0.3988523259807962, 0.3910507519147384, 0.39694108119215715, 0.39055596042989366, 0.3653858399602534, 0.3632302777034442, 0.36357314265473006, 0.36203229683508975, 0.3569555174588179, 0.34530923645954487, 0.3515593847484811, 0.33821734857545016, 0.33510474651688765, 0.3242372025331937, 0.3279084088479472, 0.32273337166287625, 0.32286556960515234, 0.32991240922977416, 0.31564365414133483, 0.3143608878830137, 0.3117512803390182, 0.3192424057413006, 0.31437052041222174, 0.31126858025002263, 0.3118698630730871, 0.3066347032730335, 0.3098145229909682, 0.308058540935643, 0.30654344718393456, 0.30752604656289984, 0.30359168444800316, 0.30902044467750067, 0.3015462672854562], 'val_losses': [0.7643244583166686, 0.6130990943220411, 0.5909996824804635, 0.5942906033139885, 0.5714995389205145, 0.5547993786426703, 0.599172777526735, 0.5889708653471402, 0.5701783040220794, 0.5349421066802301, 0.5699225777657225, 0.6590959294041571, 0.638385928225329, 0.5883922413348136, 0.6061559298659548, 0.5771213289849249, 0.5889905045734822, 0.6277782953468096, 0.6069654833327975, 0.5676747070579448, 0.6173728262776197, 0.6350086821363827, 0.5988292394164152, 0.6586283894502912, 0.5829961747696578, 0.5925615539289092, 0.5896063149684863, 0.6233716267061299, 0.6028570474023106, 0.6405608861492087, 0.6381249595384463, 0.6409665557648392, 0.6559626413995857, 0.6879459564405909, 0.623453731211844, 0.6345940543481722, 0.6649897583533821, 0.6735807820051151, 0.6297066350013686, 0.6247162385298157, 0.6584071022961435, 0.6306328205308913, 0.6417197385179028, 0.6546861261611086, 0.6711175140768734, 0.6322484635542007, 0.6633259445305622, 0.6550880177638507, 0.6495767771159627, 0.6281030158652442], 'val_acc': [0.9216890114020799, 0.8661821826838741, 0.8755795013156246, 0.9250720461095101, 0.9363488284676106, 0.9294574614709936, 0.9466232301716577, 0.9532640020047614, 0.9391053752662574, 0.9397318631750408, 0.9317128179426137, 0.9411101365743642, 0.938478887357474, 0.9589023931838115, 0.961784237564215, 0.9602806665831349, 0.9640395940358351, 0.9530134068412479, 0.9636637012905651, 0.9620348327277284, 0.9622854278912417, 0.961784237564215, 0.9587770956020549, 0.9636637012905651, 0.9610324520736749, 0.9591529883473249, 0.9538904899135446, 0.9639142964540784, 0.9610324520736749, 0.9651672722716451, 0.9634131061270518, 0.9635384037088084, 0.9631625109635384, 0.9641648916175918, 0.9636637012905651, 0.9619095351459717, 0.9572735246209748, 0.9651672722716451, 0.9626613206365117, 0.9611577496554317, 0.9670467359979953, 0.9644154867811051, 0.9659190577621852, 0.9669214384162386, 0.9660443553439418, 0.9626613206365117, 0.9602806665831349, 0.9664202480892119, 0.9642901891993485, 0.9637889988723217], 'best_val_acc': 0.9670467359979953, 'model_size_bytes': 59886, 'config_used': {'epochs': 50, 'batch_size': 32, 'lr': 0.002319083337111503, 'weight_decay': 1.7460338537336055e-06, 'stem_channels': 16, 'nhead': 4, 'd_model': 32, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.009935603502147162, 'use_focal_loss': False, 'focal_gamma': 2.510472574337971, 'label_smoothing': 0.013820836066519196, 'grad_clip_norm': 0.568807548059657, 'sched_step': 7, 'sched_gamma': 0.8105306226067164, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 50, 'batch_size': 32, 'lr': 0.002319083337111503, 'weight_decay': 1.7460338537336055e-06, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.009935603502147162, 'use_focal_loss': False, 'focal_gamma': 2.510472574337971, 'label_smoothing': 0.013820836066519196, 'grad_clip_norm': 0.568807548059657, 'sched_step': 7, 'sched_gamma': 0.8105306226067164, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 23385, 'model_storage_size_kb': 100.48242187500001, 'model_size_validation': 'PASS'}
2025-10-02 22:19:54,480 - INFO - _models.training_function_executor - BO Objective: base=0.9638, size_penalty=0.0000, final=0.9638
2025-10-02 22:19:54,480 - INFO - _models.training_function_executor - Model: 23,385 parameters, 100.5KB (PASS 256KB limit)
2025-10-02 22:19:54,480 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 272.664s
2025-10-02 22:19:54,573 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9638
2025-10-02 22:19:54,574 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-02 22:19:54,574 - INFO - bo.run_bo - Recorded observation #22: hparams={'epochs': np.int64(50), 'batch_size': np.int64(32), 'lr': 0.002319083337111503, 'weight_decay': 1.7460338537336055e-06, 'stem_channels': np.int64(16), 'nhead': np.int64(4), 'd_model_factor': np.int64(8), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.009935603502147162, 'use_focal_loss': np.False_, 'focal_gamma': 2.510472574337971, 'label_smoothing': 0.013820836066519196, 'grad_clip_norm': 0.568807548059657, 'sched_step': np.int64(7), 'sched_gamma': 0.8105306226067164, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.9638
2025-10-02 22:19:54,574 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 22: {'epochs': np.int64(50), 'batch_size': np.int64(32), 'lr': 0.002319083337111503, 'weight_decay': 1.7460338537336055e-06, 'stem_channels': np.int64(16), 'nhead': np.int64(4), 'd_model_factor': np.int64(8), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.009935603502147162, 'use_focal_loss': np.False_, 'focal_gamma': 2.510472574337971, 'label_smoothing': 0.013820836066519196, 'grad_clip_norm': 0.568807548059657, 'sched_step': np.int64(7), 'sched_gamma': 0.8105306226067164, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.9638
2025-10-02 22:19:54,574 - INFO - bo.run_bo - üîçBO Trial 23: Using RF surrogate + Expected Improvement
2025-10-02 22:19:54,574 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:19:54,574 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:19:54,574 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:19:54,574 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 19, 'batch_size': 64, 'lr': 0.0021061271268479074, 'weight_decay': 1.370927893840392e-06, 'stem_channels': 13, 'nhead': 2, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.0915242080900303, 'use_focal_loss': False, 'focal_gamma': 2.862555818954932, 'label_smoothing': 0.0050216998158383215, 'grad_clip_norm': 0.8574377206799065, 'sched_step': 3, 'sched_gamma': 0.6945509840207928, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 22:19:54,575 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 19, 'batch_size': 64, 'lr': 0.0021061271268479074, 'weight_decay': 1.370927893840392e-06, 'stem_channels': 13, 'nhead': 2, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.0915242080900303, 'use_focal_loss': False, 'focal_gamma': 2.862555818954932, 'label_smoothing': 0.0050216998158383215, 'grad_clip_norm': 0.8574377206799065, 'sched_step': 3, 'sched_gamma': 0.6945509840207928, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 22:21:05,737 - INFO - _models.training_function_executor - Model: 19,752 parameters, 84.9KB storage
2025-10-02 22:21:05,737 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.026007924335917, 0.6063105871615185, 0.5119883004885563, 0.4395323625648432, 0.4125560824854558, 0.38692543813430424, 0.35031860368602, 0.34325549209886774, 0.331434835212607, 0.3014420503219768, 0.2995846386810661, 0.2846643334389465, 0.2663453456487131, 0.2649594421019994, 0.25659061571513075, 0.24586359524229837, 0.24336706024734903, 0.23661852202495232, 0.2277582689773856], 'val_losses': [0.6759218888733265, 0.5496750884061469, 0.5300794363529696, 0.4909542870169041, 0.4877029584622476, 0.4381814811286764, 0.41705915905780744, 0.4545341421004122, 0.4733899574040202, 0.4682197561465384, 0.4547848779745022, 0.4581303501424896, 0.4905491432007236, 0.5145521132722861, 0.4851818270752595, 0.469567684717397, 0.4905584564096661, 0.48766089632851395, 0.491127364506415], 'val_acc': [0.7811051246710938, 0.8029069038967548, 0.8740759303345446, 0.8705675980453578, 0.8862297957649418, 0.8857286054379151, 0.8952512216514221, 0.92281668963789, 0.9413607317378775, 0.929708056634507, 0.9490038842250345, 0.9292068663074803, 0.9419872196466608, 0.9357223405588272, 0.9467485277534143, 0.9437413857912542, 0.945746147099361, 0.9497556697155745, 0.945746147099361], 'best_val_acc': 0.9497556697155745, 'model_size_bytes': 91502, 'config_used': {'epochs': 19, 'batch_size': 64, 'lr': 0.0021061271268479074, 'weight_decay': 1.370927893840392e-06, 'stem_channels': 13, 'nhead': 2, 'd_model': 24, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.0915242080900303, 'use_focal_loss': False, 'focal_gamma': 2.862555818954932, 'label_smoothing': 0.0050216998158383215, 'grad_clip_norm': 0.8574377206799065, 'sched_step': 3, 'sched_gamma': 0.6945509840207928, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 19, 'batch_size': 64, 'lr': 0.0021061271268479074, 'weight_decay': 1.370927893840392e-06, 'stem_channels': 13, 'nhead': 2, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.0915242080900303, 'use_focal_loss': False, 'focal_gamma': 2.862555818954932, 'label_smoothing': 0.0050216998158383215, 'grad_clip_norm': 0.8574377206799065, 'sched_step': 3, 'sched_gamma': 0.6945509840207928, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 19752, 'model_storage_size_kb': 84.871875, 'model_size_validation': 'PASS'}
2025-10-02 22:21:05,738 - INFO - _models.training_function_executor - BO Objective: base=0.9457, size_penalty=0.0000, final=0.9457
2025-10-02 22:21:05,738 - INFO - _models.training_function_executor - Model: 19,752 parameters, 84.9KB (PASS 256KB limit)
2025-10-02 22:21:05,738 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 71.164s
2025-10-02 22:21:05,832 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9457
2025-10-02 22:21:05,832 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-02 22:21:05,832 - INFO - bo.run_bo - Recorded observation #23: hparams={'epochs': np.int64(19), 'batch_size': np.int64(64), 'lr': 0.0021061271268479074, 'weight_decay': 1.370927893840392e-06, 'stem_channels': np.int64(13), 'nhead': np.int64(2), 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.0915242080900303, 'use_focal_loss': np.False_, 'focal_gamma': 2.862555818954932, 'label_smoothing': 0.0050216998158383215, 'grad_clip_norm': 0.8574377206799065, 'sched_step': np.int64(3), 'sched_gamma': 0.6945509840207928, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.9457
2025-10-02 22:21:05,832 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 23: {'epochs': np.int64(19), 'batch_size': np.int64(64), 'lr': 0.0021061271268479074, 'weight_decay': 1.370927893840392e-06, 'stem_channels': np.int64(13), 'nhead': np.int64(2), 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.0915242080900303, 'use_focal_loss': np.False_, 'focal_gamma': 2.862555818954932, 'label_smoothing': 0.0050216998158383215, 'grad_clip_norm': 0.8574377206799065, 'sched_step': np.int64(3), 'sched_gamma': 0.6945509840207928, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.9457
2025-10-02 22:21:05,833 - INFO - bo.run_bo - üîçBO Trial 24: Using RF surrogate + Expected Improvement
2025-10-02 22:21:05,833 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:21:05,833 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:21:05,833 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:21:05,833 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 33, 'batch_size': 32, 'lr': 0.0028998991669712646, 'weight_decay': 2.9736397436918437e-07, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.07373634499412646, 'use_focal_loss': False, 'focal_gamma': 2.5368590944603815, 'label_smoothing': 0.008367833468316068, 'grad_clip_norm': 0.09591581817143338, 'sched_step': 5, 'sched_gamma': 0.9306297621322644, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:21:05,834 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 33, 'batch_size': 32, 'lr': 0.0028998991669712646, 'weight_decay': 2.9736397436918437e-07, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.07373634499412646, 'use_focal_loss': False, 'focal_gamma': 2.5368590944603815, 'label_smoothing': 0.008367833468316068, 'grad_clip_norm': 0.09591581817143338, 'sched_step': 5, 'sched_gamma': 0.9306297621322644, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:23:21,859 - INFO - _models.training_function_executor - Model: 10,817 parameters, 23.2KB storage
2025-10-02 22:23:21,859 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0113160083815445, 0.7131951805394952, 0.6609446863066384, 0.6176572097437097, 0.593664290632546, 0.5764232477187154, 0.5488720912740362, 0.5308864938284085, 0.5307340461561092, 0.5129246320453529, 0.4901741292257975, 0.48416709755479226, 0.4857149712107248, 0.47529624786546637, 0.4725144466244218, 0.460654861120877, 0.4481285866111292, 0.44664341970590615, 0.44014017601283245, 0.4414217783171939, 0.43229284493340564, 0.42206266327945113, 0.41254691703574303, 0.43206068479906135, 0.41673243122639614, 0.4054988487120526, 0.4120178163734044, 0.4017517776388507, 0.4047263127197371, 0.3960268875417773, 0.38473819907743806, 0.3879959725128941, 0.38464921978242345], 'val_losses': [0.8494708626256253, 0.69738353695312, 0.7644450643907706, 0.6594054413056885, 0.5965890074983126, 0.6746256165509833, 0.603139541513892, 0.6799989697359929, 0.6880625709676605, 0.5935539928329213, 0.6551241965136153, 0.7103820800811124, 0.6001961278282092, 0.6019891208461794, 0.5117385116918182, 0.569742672142566, 0.66403132234207, 0.6833300966171525, 0.5553756460272986, 0.7701032673591152, 0.6109889331071273, 0.6655534028767972, 0.6146515086694643, 0.5416983297901514, 0.6359518871407748, 0.6439034177193201, 0.7323090886878513, 0.7229821331264112, 0.6265331763489894, 0.6848304062585098, 0.6482561197276104, 0.6353181446424598, 0.6799721886618456], 'val_acc': [0.8799649166771081, 0.8438792131311865, 0.914045858914923, 0.9146723468237064, 0.8269640395940359, 0.9285803783986969, 0.9028943741385791, 0.9214384162385666, 0.940358351083824, 0.9173035960405964, 0.9436160882094976, 0.9478762059892244, 0.9456208495176043, 0.9429896003007142, 0.9226913920561333, 0.9422378148101742, 0.9468738253351711, 0.9531387044230046, 0.9478762059892244, 0.9532640020047614, 0.9505074552061146, 0.9556446560581381, 0.9478762059892244, 0.9320887106878837, 0.9442425761182809, 0.9522616213507079, 0.9573988222027315, 0.9591529883473249, 0.9551434657311114, 0.9516351334419245, 0.9579000125297582, 0.9557699536398947, 0.9528881092594913], 'best_val_acc': 0.9591529883473249, 'model_size_bytes': 34222, 'config_used': {'epochs': 33, 'batch_size': 32, 'lr': 0.0028998991669712646, 'weight_decay': 2.9736397436918437e-07, 'stem_channels': 24, 'nhead': 1, 'd_model': 15, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.07373634499412646, 'use_focal_loss': False, 'focal_gamma': 2.5368590944603815, 'label_smoothing': 0.008367833468316068, 'grad_clip_norm': 0.09591581817143338, 'sched_step': 5, 'sched_gamma': 0.9306297621322644, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 33, 'batch_size': 32, 'lr': 0.0028998991669712646, 'weight_decay': 2.9736397436918437e-07, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.07373634499412646, 'use_focal_loss': False, 'focal_gamma': 2.5368590944603815, 'label_smoothing': 0.008367833468316068, 'grad_clip_norm': 0.09591581817143338, 'sched_step': 5, 'sched_gamma': 0.9306297621322644, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 10817, 'model_storage_size_kb': 23.2396484375, 'model_size_validation': 'PASS'}
2025-10-02 22:23:21,859 - INFO - _models.training_function_executor - BO Objective: base=0.9529, size_penalty=0.0000, final=0.9529
2025-10-02 22:23:21,859 - INFO - _models.training_function_executor - Model: 10,817 parameters, 23.2KB (PASS 256KB limit)
2025-10-02 22:23:21,859 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 136.026s
2025-10-02 22:23:21,955 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9529
2025-10-02 22:23:21,955 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.096s
2025-10-02 22:23:21,955 - INFO - bo.run_bo - Recorded observation #24: hparams={'epochs': np.int64(33), 'batch_size': np.int64(32), 'lr': 0.0028998991669712646, 'weight_decay': 2.9736397436918437e-07, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.07373634499412646, 'use_focal_loss': np.False_, 'focal_gamma': 2.5368590944603815, 'label_smoothing': 0.008367833468316068, 'grad_clip_norm': 0.09591581817143338, 'sched_step': np.int64(5), 'sched_gamma': 0.9306297621322644, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.9529
2025-10-02 22:23:21,955 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 24: {'epochs': np.int64(33), 'batch_size': np.int64(32), 'lr': 0.0028998991669712646, 'weight_decay': 2.9736397436918437e-07, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.07373634499412646, 'use_focal_loss': np.False_, 'focal_gamma': 2.5368590944603815, 'label_smoothing': 0.008367833468316068, 'grad_clip_norm': 0.09591581817143338, 'sched_step': np.int64(5), 'sched_gamma': 0.9306297621322644, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.9529
2025-10-02 22:23:21,956 - INFO - bo.run_bo - üîçBO Trial 25: Using RF surrogate + Expected Improvement
2025-10-02 22:23:21,956 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:23:21,956 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:23:21,956 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:23:21,956 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 11, 'batch_size': 128, 'lr': 0.0016198958530750291, 'weight_decay': 1.9934096553983497e-07, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.06371013742973468, 'use_focal_loss': False, 'focal_gamma': 2.9137651006883534, 'label_smoothing': 0.01980066676294974, 'grad_clip_norm': 0.27043955608550013, 'sched_step': 4, 'sched_gamma': 0.5688635372874634, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:23:21,957 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 11, 'batch_size': 128, 'lr': 0.0016198958530750291, 'weight_decay': 1.9934096553983497e-07, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.06371013742973468, 'use_focal_loss': False, 'focal_gamma': 2.9137651006883534, 'label_smoothing': 0.01980066676294974, 'grad_clip_norm': 0.27043955608550013, 'sched_step': 4, 'sched_gamma': 0.5688635372874634, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:23:54,128 - INFO - _models.training_function_executor - Model: 5,307 parameters, 22.8KB storage
2025-10-02 22:23:54,128 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4364341935787912, 0.9974207972515288, 0.7971088398583225, 0.7220296415343708, 0.665226582035969, 0.6439152769631201, 0.6299322810363258, 0.6139334351766327, 0.5884415603492865, 0.5794232069234242, 0.5725009562422285], 'val_losses': [1.1447739125403407, 0.8937950625842025, 0.7554200049062643, 0.7173213623935545, 0.6856395140609531, 0.6801445037406603, 0.6555566637979954, 0.7019069595917053, 0.652474741360072, 0.6610758467405277, 0.6447462489798828], 'val_acc': [0.6209748151860669, 0.8541536148352337, 0.7629369753163764, 0.8140583886730987, 0.7930083949379777, 0.8512717704548303, 0.8550306979075304, 0.8877333667460218, 0.8706928956271144, 0.8610449818318506, 0.8708181932088711], 'best_val_acc': 0.8877333667460218, 'model_size_bytes': 33454, 'config_used': {'epochs': 11, 'batch_size': 128, 'lr': 0.0016198958530750291, 'weight_decay': 1.9934096553983497e-07, 'stem_channels': 16, 'nhead': 1, 'd_model': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.06371013742973468, 'use_focal_loss': False, 'focal_gamma': 2.9137651006883534, 'label_smoothing': 0.01980066676294974, 'grad_clip_norm': 0.27043955608550013, 'sched_step': 4, 'sched_gamma': 0.5688635372874634, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 11, 'batch_size': 128, 'lr': 0.0016198958530750291, 'weight_decay': 1.9934096553983497e-07, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.06371013742973468, 'use_focal_loss': False, 'focal_gamma': 2.9137651006883534, 'label_smoothing': 0.01980066676294974, 'grad_clip_norm': 0.27043955608550013, 'sched_step': 4, 'sched_gamma': 0.5688635372874634, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 5307, 'model_storage_size_kb': 22.803515625000003, 'model_size_validation': 'PASS'}
2025-10-02 22:23:54,128 - INFO - _models.training_function_executor - BO Objective: base=0.8708, size_penalty=0.0000, final=0.8708
2025-10-02 22:23:54,128 - INFO - _models.training_function_executor - Model: 5,307 parameters, 22.8KB (PASS 256KB limit)
2025-10-02 22:23:54,128 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 32.173s
2025-10-02 22:23:54,224 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8708
2025-10-02 22:23:54,224 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.096s
2025-10-02 22:23:54,224 - INFO - bo.run_bo - Recorded observation #25: hparams={'epochs': np.int64(11), 'batch_size': np.int64(128), 'lr': 0.0016198958530750291, 'weight_decay': 1.9934096553983497e-07, 'stem_channels': np.int64(16), 'nhead': np.int64(1), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.06371013742973468, 'use_focal_loss': np.False_, 'focal_gamma': 2.9137651006883534, 'label_smoothing': 0.01980066676294974, 'grad_clip_norm': 0.27043955608550013, 'sched_step': np.int64(4), 'sched_gamma': 0.5688635372874634, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.8708
2025-10-02 22:23:54,224 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 25: {'epochs': np.int64(11), 'batch_size': np.int64(128), 'lr': 0.0016198958530750291, 'weight_decay': 1.9934096553983497e-07, 'stem_channels': np.int64(16), 'nhead': np.int64(1), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.06371013742973468, 'use_focal_loss': np.False_, 'focal_gamma': 2.9137651006883534, 'label_smoothing': 0.01980066676294974, 'grad_clip_norm': 0.27043955608550013, 'sched_step': np.int64(4), 'sched_gamma': 0.5688635372874634, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.8708
2025-10-02 22:23:54,225 - INFO - bo.run_bo - üîçBO Trial 26: Using RF surrogate + Expected Improvement
2025-10-02 22:23:54,225 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:23:54,225 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:23:54,225 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:23:54,225 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 8, 'batch_size': 64, 'lr': 0.001972476979909275, 'weight_decay': 0.00015178286819440026, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.05510386690741924, 'use_focal_loss': False, 'focal_gamma': 2.8129769717412305, 'label_smoothing': 0.008916856522829987, 'grad_clip_norm': 0.5722684249762403, 'sched_step': 1, 'sched_gamma': 0.6350980535473774, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:23:54,226 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 8, 'batch_size': 64, 'lr': 0.001972476979909275, 'weight_decay': 0.00015178286819440026, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.05510386690741924, 'use_focal_loss': False, 'focal_gamma': 2.8129769717412305, 'label_smoothing': 0.008916856522829987, 'grad_clip_norm': 0.5722684249762403, 'sched_step': 1, 'sched_gamma': 0.6350980535473774, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:24:10,996 - INFO - _models.training_function_executor - Model: 6,841 parameters, 29.4KB storage
2025-10-02 22:24:10,997 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.207248404002655, 0.8300551615595441, 0.6821727234050639, 0.6312726174284259, 0.6012819913096235, 0.5804928872973886, 0.5685272632412447, 0.5629789269486193], 'val_losses': [0.9511196595910587, 0.7297690855113953, 0.6690463870857133, 0.6467538252239493, 0.6422086175320636, 0.6371918406093379, 0.6285246005259635, 0.6297328832259738], 'val_acc': [0.53877960155369, 0.7463976945244957, 0.7755920310738003, 0.8017792256609447, 0.829219396065656, 0.8141836862548553, 0.8421250469865932, 0.8462598671845634], 'best_val_acc': 0.8462598671845634, 'model_size_bytes': 22290, 'config_used': {'epochs': 8, 'batch_size': 64, 'lr': 0.001972476979909275, 'weight_decay': 0.00015178286819440026, 'stem_channels': 16, 'nhead': 1, 'd_model': 14, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.05510386690741924, 'use_focal_loss': False, 'focal_gamma': 2.8129769717412305, 'label_smoothing': 0.008916856522829987, 'grad_clip_norm': 0.5722684249762403, 'sched_step': 1, 'sched_gamma': 0.6350980535473774, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 8, 'batch_size': 64, 'lr': 0.001972476979909275, 'weight_decay': 0.00015178286819440026, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.05510386690741924, 'use_focal_loss': False, 'focal_gamma': 2.8129769717412305, 'label_smoothing': 0.008916856522829987, 'grad_clip_norm': 0.5722684249762403, 'sched_step': 1, 'sched_gamma': 0.6350980535473774, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 6841, 'model_storage_size_kb': 29.394921875, 'model_size_validation': 'PASS'}
2025-10-02 22:24:10,997 - INFO - _models.training_function_executor - BO Objective: base=0.8463, size_penalty=0.0000, final=0.8463
2025-10-02 22:24:10,997 - INFO - _models.training_function_executor - Model: 6,841 parameters, 29.4KB (PASS 256KB limit)
2025-10-02 22:24:10,997 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 16.772s
2025-10-02 22:24:11,094 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8463
2025-10-02 22:24:11,094 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.098s
2025-10-02 22:24:11,094 - INFO - bo.run_bo - Recorded observation #26: hparams={'epochs': np.int64(8), 'batch_size': np.int64(64), 'lr': 0.001972476979909275, 'weight_decay': 0.00015178286819440026, 'stem_channels': np.int64(16), 'nhead': np.int64(1), 'd_model_factor': np.int64(14), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.05510386690741924, 'use_focal_loss': np.False_, 'focal_gamma': 2.8129769717412305, 'label_smoothing': 0.008916856522829987, 'grad_clip_norm': 0.5722684249762403, 'sched_step': np.int64(1), 'sched_gamma': 0.6350980535473774, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.8463
2025-10-02 22:24:11,094 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 26: {'epochs': np.int64(8), 'batch_size': np.int64(64), 'lr': 0.001972476979909275, 'weight_decay': 0.00015178286819440026, 'stem_channels': np.int64(16), 'nhead': np.int64(1), 'd_model_factor': np.int64(14), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.05510386690741924, 'use_focal_loss': np.False_, 'focal_gamma': 2.8129769717412305, 'label_smoothing': 0.008916856522829987, 'grad_clip_norm': 0.5722684249762403, 'sched_step': np.int64(1), 'sched_gamma': 0.6350980535473774, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.8463
2025-10-02 22:24:11,095 - INFO - bo.run_bo - üîçBO Trial 27: Using RF surrogate + Expected Improvement
2025-10-02 22:24:11,095 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:24:11,095 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:24:11,095 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:24:11,095 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 34, 'batch_size': 256, 'lr': 0.003465453666278191, 'weight_decay': 1.5834807512922834e-06, 'stem_channels': 22, 'nhead': 1, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.251594605523974, 'use_focal_loss': False, 'focal_gamma': 2.6928360623863177, 'label_smoothing': 0.000421479093732502, 'grad_clip_norm': 0.32218468080986046, 'sched_step': 6, 'sched_gamma': 0.7024998593748555, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:24:11,096 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 34, 'batch_size': 256, 'lr': 0.003465453666278191, 'weight_decay': 1.5834807512922834e-06, 'stem_channels': 22, 'nhead': 1, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.251594605523974, 'use_focal_loss': False, 'focal_gamma': 2.6928360623863177, 'label_smoothing': 0.000421479093732502, 'grad_clip_norm': 0.32218468080986046, 'sched_step': 6, 'sched_gamma': 0.7024998593748555, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:25:12,441 - INFO - _models.training_function_executor - Model: 6,464 parameters, 27.8KB storage
2025-10-02 22:25:12,441 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3161657942669682, 0.8854447676118774, 0.7275570655580086, 0.5915883866534385, 0.5267905863363992, 0.47135495754709233, 0.42519913220156874, 0.3962092371310028, 0.37989382789412285, 0.36101614726133835, 0.3342535401897032, 0.32890156504635343, 0.29570588550632454, 0.2847952710775767, 0.27951087089845295, 0.26085184654324506, 0.25841502938224115, 0.2475781897194078, 0.23160004573306303, 0.22639987583679166, 0.2198512661781197, 0.2225822080034673, 0.21009590337159426, 0.20593644695723673, 0.19166004574681061, 0.18889679018510402, 0.18430412496028378, 0.17995362999032352, 0.18274208147635276, 0.17735115072483953, 0.16682599733319867, 0.1663697835783707, 0.16642821429936996, 0.16159806766379833], 'val_losses': [0.9975133934888516, 0.8602319708251069, 0.6390421658571375, 0.6447630188785061, 0.5320190321441701, 0.4988134305603506, 0.48886889270815453, 0.45454367637156307, 0.4527284301263828, 0.45026129621593686, 0.4809776404764013, 0.44420133964442743, 0.4700576267719209, 0.4368569072722911, 0.4727825463572446, 0.4263521454310659, 0.5347800110832609, 0.4599748734184531, 0.4041282697371292, 0.42070092432795575, 0.48210343288727053, 0.47900347269921206, 0.48560108034746075, 0.4769009187203304, 0.5053566118228288, 0.4719763814230459, 0.5020653524317847, 0.5264375227956362, 0.5504327064438163, 0.5467832486345092, 0.5375567408204601, 0.5430205920789344, 0.5535524925698972, 0.5496413788092255], 'val_acc': [0.5400325773712568, 0.546046861295577, 0.6959027690765568, 0.7981455957900012, 0.8115524370379652, 0.8087958902393184, 0.8100488660568851, 0.8547801027440171, 0.8438792131311865, 0.8675604560831975, 0.8373637388798396, 0.8882345570730484, 0.9057762185189826, 0.8742012279163012, 0.8757047988973813, 0.8909911038716952, 0.9041473499561459, 0.8825961658939983, 0.8782107505325147, 0.8793384287683248, 0.8953765192331788, 0.8938729482520987, 0.8908658062899386, 0.8966294950507455, 0.893747650670342, 0.8896128304723718, 0.8891116401453452, 0.9051497306101992, 0.8889863425635885, 0.8928705675980454, 0.9067785991730359, 0.9023931838115524, 0.9037714572108758, 0.8894875328906152], 'best_val_acc': 0.9067785991730359, 'model_size_bytes': 38510, 'config_used': {'epochs': 34, 'batch_size': 256, 'lr': 0.003465453666278191, 'weight_decay': 1.5834807512922834e-06, 'stem_channels': 22, 'nhead': 1, 'd_model': 8, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.251594605523974, 'use_focal_loss': False, 'focal_gamma': 2.6928360623863177, 'label_smoothing': 0.000421479093732502, 'grad_clip_norm': 0.32218468080986046, 'sched_step': 6, 'sched_gamma': 0.7024998593748555, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 34, 'batch_size': 256, 'lr': 0.003465453666278191, 'weight_decay': 1.5834807512922834e-06, 'stem_channels': 22, 'nhead': 1, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.251594605523974, 'use_focal_loss': False, 'focal_gamma': 2.6928360623863177, 'label_smoothing': 0.000421479093732502, 'grad_clip_norm': 0.32218468080986046, 'sched_step': 6, 'sched_gamma': 0.7024998593748555, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 6464, 'model_storage_size_kb': 27.775000000000002, 'model_size_validation': 'PASS'}
2025-10-02 22:25:12,442 - INFO - _models.training_function_executor - BO Objective: base=0.8895, size_penalty=0.0000, final=0.8895
2025-10-02 22:25:12,442 - INFO - _models.training_function_executor - Model: 6,464 parameters, 27.8KB (PASS 256KB limit)
2025-10-02 22:25:12,442 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 61.347s
2025-10-02 22:25:12,538 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8895
2025-10-02 22:25:12,538 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.096s
2025-10-02 22:25:12,538 - INFO - bo.run_bo - Recorded observation #27: hparams={'epochs': np.int64(34), 'batch_size': np.int64(256), 'lr': 0.003465453666278191, 'weight_decay': 1.5834807512922834e-06, 'stem_channels': np.int64(22), 'nhead': np.int64(1), 'd_model_factor': np.int64(8), 'num_layers': np.int64(2), 'ff_factor': np.int64(2), 'dropout': 0.251594605523974, 'use_focal_loss': np.False_, 'focal_gamma': 2.6928360623863177, 'label_smoothing': 0.000421479093732502, 'grad_clip_norm': 0.32218468080986046, 'sched_step': np.int64(6), 'sched_gamma': 0.7024998593748555, 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.8895
2025-10-02 22:25:12,538 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 27: {'epochs': np.int64(34), 'batch_size': np.int64(256), 'lr': 0.003465453666278191, 'weight_decay': 1.5834807512922834e-06, 'stem_channels': np.int64(22), 'nhead': np.int64(1), 'd_model_factor': np.int64(8), 'num_layers': np.int64(2), 'ff_factor': np.int64(2), 'dropout': 0.251594605523974, 'use_focal_loss': np.False_, 'focal_gamma': 2.6928360623863177, 'label_smoothing': 0.000421479093732502, 'grad_clip_norm': 0.32218468080986046, 'sched_step': np.int64(6), 'sched_gamma': 0.7024998593748555, 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.8895
2025-10-02 22:25:12,538 - INFO - bo.run_bo - üîçBO Trial 28: Using RF surrogate + Expected Improvement
2025-10-02 22:25:12,538 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:25:12,538 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:25:12,538 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:25:12,539 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 31, 'batch_size': 128, 'lr': 0.0022359764670209763, 'weight_decay': 1.79607734212221e-07, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.10823895351735785, 'use_focal_loss': False, 'focal_gamma': 2.9391189863716853, 'label_smoothing': 0.012010041241383154, 'grad_clip_norm': 0.48874031005132146, 'sched_step': 9, 'sched_gamma': 0.7720112135849607, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:25:12,540 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 31, 'batch_size': 128, 'lr': 0.0022359764670209763, 'weight_decay': 1.79607734212221e-07, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.10823895351735785, 'use_focal_loss': False, 'focal_gamma': 2.9391189863716853, 'label_smoothing': 0.012010041241383154, 'grad_clip_norm': 0.48874031005132146, 'sched_step': 9, 'sched_gamma': 0.7720112135849607, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:28:10,150 - INFO - _models.training_function_executor - Model: 42,764 parameters, 183.8KB storage
2025-10-02 22:28:10,150 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0285276939605064, 0.6772615841799309, 0.5987866108636265, 0.5616408205680619, 0.5227321847595039, 0.505084914181707, 0.48884224134724874, 0.47972475888548133, 0.46283694722242186, 0.42820094672711134, 0.41163262439484366, 0.3979337675178297, 0.3944309659978372, 0.3825004555186252, 0.3810253857602841, 0.3765873371344874, 0.36799103670265426, 0.3651645354910482, 0.3409170502783291, 0.32776871200354407, 0.3283763237959669, 0.3199184757891004, 0.31919054951176506, 0.31033521028022526, 0.3090669536368013, 0.3083770561236186, 0.30847325405915293, 0.28818190745145567, 0.28540226088293746, 0.28630493964571757, 0.2842772313777962], 'val_losses': [0.7087143591256566, 0.6469409903956004, 0.6300122443931531, 0.577754690920167, 0.559517816200156, 0.548576934686237, 0.5320529512199389, 0.5368395283801441, 0.5341687337630167, 0.6253526239313887, 0.5054765530224656, 0.496936876288991, 0.5070045171502747, 0.5600236659360073, 0.5871004729981322, 0.5095218576116529, 0.5018617043801678, 0.5459955004937158, 0.5507798558592333, 0.5490146804059034, 0.5504980657561025, 0.5150860671246654, 0.5236140471504918, 0.5162219350580852, 0.5291795045746074, 0.6137689643449286, 0.5281469892132119, 0.5980922866025943, 0.5595037554188967, 0.5839941222003612, 0.5624682741077931], 'val_acc': [0.7205863926826213, 0.7910036336298709, 0.7980202982082446, 0.8254604686129557, 0.8621726600676607, 0.9223154993108633, 0.8904899135446686, 0.8559077809798271, 0.9054003257737125, 0.9210625234932965, 0.8916175917804786, 0.9011402079939858, 0.930083949379777, 0.9419872196466608, 0.9520110261871946, 0.9330910913419371, 0.9288309735622102, 0.9427390051372009, 0.9528881092594913, 0.9586517980202982, 0.9481268011527377, 0.947249718080441, 0.9426137075554442, 0.9432401954642275, 0.9402330535020674, 0.9563964415486781, 0.930459842125047, 0.954516977822328, 0.9565217391304348, 0.9553940608946248, 0.9517604310236812], 'best_val_acc': 0.9586517980202982, 'model_size_bytes': 98478, 'config_used': {'epochs': 31, 'batch_size': 128, 'lr': 0.0022359764670209763, 'weight_decay': 1.79607734212221e-07, 'stem_channels': 12, 'nhead': 4, 'd_model': 36, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.10823895351735785, 'use_focal_loss': False, 'focal_gamma': 2.9391189863716853, 'label_smoothing': 0.012010041241383154, 'grad_clip_norm': 0.48874031005132146, 'sched_step': 9, 'sched_gamma': 0.7720112135849607, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 31, 'batch_size': 128, 'lr': 0.0022359764670209763, 'weight_decay': 1.79607734212221e-07, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.10823895351735785, 'use_focal_loss': False, 'focal_gamma': 2.9391189863716853, 'label_smoothing': 0.012010041241383154, 'grad_clip_norm': 0.48874031005132146, 'sched_step': 9, 'sched_gamma': 0.7720112135849607, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 42764, 'model_storage_size_kb': 183.7515625, 'model_size_validation': 'PASS'}
2025-10-02 22:28:10,150 - INFO - _models.training_function_executor - BO Objective: base=0.9518, size_penalty=0.0000, final=0.9518
2025-10-02 22:28:10,150 - INFO - _models.training_function_executor - Model: 42,764 parameters, 183.8KB (PASS 256KB limit)
2025-10-02 22:28:10,150 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 177.612s
2025-10-02 22:28:10,248 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9518
2025-10-02 22:28:10,248 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.097s
2025-10-02 22:28:10,248 - INFO - bo.run_bo - Recorded observation #28: hparams={'epochs': np.int64(31), 'batch_size': np.int64(128), 'lr': 0.0022359764670209763, 'weight_decay': 1.79607734212221e-07, 'stem_channels': np.int64(12), 'nhead': np.int64(4), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.10823895351735785, 'use_focal_loss': np.False_, 'focal_gamma': 2.9391189863716853, 'label_smoothing': 0.012010041241383154, 'grad_clip_norm': 0.48874031005132146, 'sched_step': np.int64(9), 'sched_gamma': 0.7720112135849607, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.9518
2025-10-02 22:28:10,248 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 28: {'epochs': np.int64(31), 'batch_size': np.int64(128), 'lr': 0.0022359764670209763, 'weight_decay': 1.79607734212221e-07, 'stem_channels': np.int64(12), 'nhead': np.int64(4), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.10823895351735785, 'use_focal_loss': np.False_, 'focal_gamma': 2.9391189863716853, 'label_smoothing': 0.012010041241383154, 'grad_clip_norm': 0.48874031005132146, 'sched_step': np.int64(9), 'sched_gamma': 0.7720112135849607, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.9518
2025-10-02 22:28:10,248 - INFO - bo.run_bo - üîçBO Trial 29: Using RF surrogate + Expected Improvement
2025-10-02 22:28:10,248 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:28:10,248 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:28:10,248 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:28:10,249 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 44, 'batch_size': 128, 'lr': 0.0036062669607052444, 'weight_decay': 1.4895195892916598e-07, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.14718098057160584, 'use_focal_loss': False, 'focal_gamma': 2.898230564674998, 'label_smoothing': 0.020866971552008565, 'grad_clip_norm': 0.6698332170848302, 'sched_step': 5, 'sched_gamma': 0.7949344793347665, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 22:28:10,250 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 44, 'batch_size': 128, 'lr': 0.0036062669607052444, 'weight_decay': 1.4895195892916598e-07, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.14718098057160584, 'use_focal_loss': False, 'focal_gamma': 2.898230564674998, 'label_smoothing': 0.020866971552008565, 'grad_clip_norm': 0.6698332170848302, 'sched_step': 5, 'sched_gamma': 0.7949344793347665, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 22:32:14,241 - INFO - _models.training_function_executor - Model: 10,400 parameters, 11.2KB storage
2025-10-02 22:32:14,242 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0868286905561149, 0.7890651847389868, 0.7100390677157379, 0.6709679088690965, 0.6385797255432734, 0.6145476410495971, 0.5881089837304729, 0.5755982810149264, 0.5563569214321394, 0.5499669822001821, 0.5191277172415865, 0.5149831149906935, 0.502374942449909, 0.48539228547513025, 0.48711607128748624, 0.4691962184782924, 0.4626535748014906, 0.4571523386572543, 0.45231707877758487, 0.45372756525276187, 0.4397234441220333, 0.4336437374877141, 0.42817278007638265, 0.42617381166120494, 0.42726271986658887, 0.414543928721157, 0.411855117249742, 0.4089827906688465, 0.4096365928672308, 0.4080277935766925, 0.399389230613664, 0.3983349119071296, 0.3979228969669333, 0.39989693153790656, 0.39381698423417344, 0.39212874298413414, 0.39004432913825593, 0.3907158028292252, 0.38913003851106487, 0.3915555907601653, 0.38856654629964105, 0.38633480608132803, 0.3834419861313126, 0.38566815416208616], 'val_losses': [0.8375878541664646, 0.741516518310532, 0.6967257293240645, 0.6585407607642918, 0.6838190469388121, 0.6976891659268339, 0.6356422458431682, 0.6297630399200436, 0.6097643542388316, 0.6638127416017554, 0.6654256417359674, 0.6206573982194558, 0.6468159375431514, 0.7089933330978969, 0.6275510129706332, 0.6698780835623311, 0.6804509778590956, 0.6240183078410736, 0.650128607343065, 0.6695291991894623, 0.6470447041728177, 0.7713676356773391, 0.7143072152463374, 0.7057507704663823, 0.6764144869529429, 0.7428311417909691, 0.7642565849594807, 0.7360727438546111, 0.7257444968932764, 0.6959645895114923, 0.7795101197616392, 0.6845135901852847, 0.7163648208928368, 0.7944169928295364, 0.783271233011735, 0.7937651761655684, 0.7421064448078807, 0.7761672911914633, 0.7253276630685288, 0.7503277721328554, 0.7684257167605376, 0.7622096784101993, 0.7684103589714537, 0.8146524966143976], 'val_acc': [0.6066908908658063, 0.8651798020298208, 0.8928705675980454, 0.8234557073048491, 0.8057887482771583, 0.9150482395689763, 0.8960030071419621, 0.9070291943365493, 0.891868186943992, 0.9282044856534268, 0.9312116276155871, 0.9042726475379025, 0.9358476381405839, 0.9512592406966546, 0.9329657937601804, 0.9402330535020674, 0.9535145971682747, 0.9176794887858665, 0.9379776970304473, 0.928956271143967, 0.9442425761182809, 0.9495050745520611, 0.9543916802405713, 0.9444931712817942, 0.9532640020047614, 0.9503821576243578, 0.955268763312868, 0.9600300714196216, 0.9562711439669215, 0.9551434657311114, 0.9592782859290816, 0.9502568600426011, 0.9594035835108382, 0.9636637012905651, 0.960656559328405, 0.9650419746898885, 0.9562711439669215, 0.9637889988723217, 0.9581506076932715, 0.9563964415486781, 0.9641648916175918, 0.9642901891993485, 0.963287808545295, 0.9620348327277284], 'best_val_acc': 0.9650419746898885, 'model_size_bytes': 118629, 'config_used': {'epochs': 44, 'batch_size': 128, 'lr': 0.0036062669607052444, 'weight_decay': 1.4895195892916598e-07, 'stem_channels': 13, 'nhead': 4, 'd_model': 40, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.14718098057160584, 'use_focal_loss': False, 'focal_gamma': 2.898230564674998, 'label_smoothing': 0.020866971552008565, 'grad_clip_norm': 0.6698332170848302, 'sched_step': 5, 'sched_gamma': 0.7949344793347665, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 44, 'batch_size': 128, 'lr': 0.0036062669607052444, 'weight_decay': 1.4895195892916598e-07, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.14718098057160584, 'use_focal_loss': False, 'focal_gamma': 2.898230564674998, 'label_smoothing': 0.020866971552008565, 'grad_clip_norm': 0.6698332170848302, 'sched_step': 5, 'sched_gamma': 0.7949344793347665, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 10400, 'model_storage_size_kb': 11.171875000000002, 'model_size_validation': 'PASS'}
2025-10-02 22:32:14,242 - INFO - _models.training_function_executor - BO Objective: base=0.9620, size_penalty=0.0000, final=0.9620
2025-10-02 22:32:14,242 - INFO - _models.training_function_executor - Model: 10,400 parameters, 11.2KB (PASS 256KB limit)
2025-10-02 22:32:14,242 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 243.993s
2025-10-02 22:32:14,341 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9620
2025-10-02 22:32:14,341 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.099s
2025-10-02 22:32:14,341 - INFO - bo.run_bo - Recorded observation #29: hparams={'epochs': np.int64(44), 'batch_size': np.int64(128), 'lr': 0.0036062669607052444, 'weight_decay': 1.4895195892916598e-07, 'stem_channels': np.int64(13), 'nhead': np.int64(4), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.14718098057160584, 'use_focal_loss': np.False_, 'focal_gamma': 2.898230564674998, 'label_smoothing': 0.020866971552008565, 'grad_clip_norm': 0.6698332170848302, 'sched_step': np.int64(5), 'sched_gamma': 0.7949344793347665, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.9620
2025-10-02 22:32:14,341 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 29: {'epochs': np.int64(44), 'batch_size': np.int64(128), 'lr': 0.0036062669607052444, 'weight_decay': 1.4895195892916598e-07, 'stem_channels': np.int64(13), 'nhead': np.int64(4), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.14718098057160584, 'use_focal_loss': np.False_, 'focal_gamma': 2.898230564674998, 'label_smoothing': 0.020866971552008565, 'grad_clip_norm': 0.6698332170848302, 'sched_step': np.int64(5), 'sched_gamma': 0.7949344793347665, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.9620
2025-10-02 22:32:14,342 - INFO - bo.run_bo - üîçBO Trial 30: Using RF surrogate + Expected Improvement
2025-10-02 22:32:14,342 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:32:14,342 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:32:14,342 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:32:14,342 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 46, 'batch_size': 32, 'lr': 0.0011054257996343788, 'weight_decay': 4.84590248526056e-07, 'stem_channels': 10, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.12832470723520353, 'use_focal_loss': False, 'focal_gamma': 1.688963514153874, 'label_smoothing': 0.01518370552726365, 'grad_clip_norm': 0.6657309766375726, 'sched_step': 5, 'sched_gamma': 0.9159347210699069, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:32:14,343 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 46, 'batch_size': 32, 'lr': 0.0011054257996343788, 'weight_decay': 4.84590248526056e-07, 'stem_channels': 10, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.12832470723520353, 'use_focal_loss': False, 'focal_gamma': 1.688963514153874, 'label_smoothing': 0.01518370552726365, 'grad_clip_norm': 0.6657309766375726, 'sched_step': 5, 'sched_gamma': 0.9159347210699069, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:35:23,628 - INFO - _models.training_function_executor - Model: 8,725 parameters, 37.5KB storage
2025-10-02 22:35:23,628 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.247729324369888, 0.819057400878859, 0.7420946310902099, 0.7011685330321891, 0.6728682230596826, 0.6429268485288462, 0.6217421801157532, 0.6031666457316027, 0.5939757244645871, 0.5840064193436673, 0.5714745599853176, 0.5643261194460651, 0.5473881760738221, 0.5393070383515233, 0.5397584304767598, 0.5227624778721718, 0.5213494795503142, 0.511426067307857, 0.5072070320432349, 0.5095890805811877, 0.49643151685901254, 0.48574395200548454, 0.4973465394668291, 0.48718133539543024, 0.48485368654527256, 0.4792914147014491, 0.47107296314984265, 0.4732865364827955, 0.4667146075389157, 0.46153037696801397, 0.45059844516249214, 0.4607757139735453, 0.4530964638249332, 0.4474772863626607, 0.4441812428765491, 0.44822587071588954, 0.4370865175397878, 0.44097758897044015, 0.4357221838365397, 0.432360117299453, 0.43180103703698014, 0.4286232141703363, 0.4257909998750939, 0.42035698615376543, 0.4212132386257112, 0.41604601208758796], 'val_losses': [0.9052138860371161, 0.7827033486645288, 0.7344153535767853, 0.6905201902336949, 0.6695414035485481, 0.727515074427363, 0.6528191020981349, 0.658844727858044, 0.6323538522286577, 0.7134436492916337, 0.7154781292620316, 0.6681620169217657, 0.6590335064253373, 0.7281691043571995, 0.693868599773245, 0.6316015422232183, 0.6481749634742139, 0.7227734543748136, 0.7041771590089816, 0.6844356502003127, 0.6827290671583615, 0.6456994457421723, 0.7085667939401781, 0.6309416021504298, 0.7891052003761773, 0.713838984980916, 0.7356187487556707, 0.7060514364665559, 0.6971972701752966, 0.7370522671692235, 0.736712129981487, 0.6699144008419237, 0.6857693842398076, 0.675588905415489, 0.698816946135056, 0.7355094351515766, 0.7091070268405378, 0.7021406760058626, 0.721189430640942, 0.7389825662714006, 0.7638931485618091, 0.71063650020336, 0.7544792125195493, 0.7318738207394669, 0.7484311997897941, 0.7694671319072042], 'val_acc': [0.8198220774339056, 0.8501440922190202, 0.8812178924946749, 0.8923693772710186, 0.9199348452574865, 0.9419872196466608, 0.9170530008770831, 0.9168024057135697, 0.9267009146723468, 0.9523869189324646, 0.9409848389926074, 0.938854780102744, 0.9146723468237064, 0.9535145971682747, 0.9513845382784112, 0.945746147099361, 0.9453702543540909, 0.9566470367121914, 0.9481268011527377, 0.9568976318757048, 0.9447437664453076, 0.9429896003007142, 0.9551434657311114, 0.9558952512216514, 0.9585265004385415, 0.9532640020047614, 0.9577747149480015, 0.9452449567723343, 0.9557699536398947, 0.9566470367121914, 0.9570229294574615, 0.9596541786743515, 0.9515098358601679, 0.9508833479513845, 0.9585265004385415, 0.955268763312868, 0.9538904899135446, 0.9517604310236812, 0.9581506076932715, 0.9582759052750282, 0.9612830472371883, 0.9522616213507079, 0.9573988222027315, 0.9487532890615211, 0.9532640020047614, 0.9512592406966546], 'best_val_acc': 0.9612830472371883, 'model_size_bytes': 46766, 'config_used': {'epochs': 46, 'batch_size': 32, 'lr': 0.0011054257996343788, 'weight_decay': 4.84590248526056e-07, 'stem_channels': 10, 'nhead': 1, 'd_model': 14, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.12832470723520353, 'use_focal_loss': False, 'focal_gamma': 1.688963514153874, 'label_smoothing': 0.01518370552726365, 'grad_clip_norm': 0.6657309766375726, 'sched_step': 5, 'sched_gamma': 0.9159347210699069, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 46, 'batch_size': 32, 'lr': 0.0011054257996343788, 'weight_decay': 4.84590248526056e-07, 'stem_channels': 10, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.12832470723520353, 'use_focal_loss': False, 'focal_gamma': 1.688963514153874, 'label_smoothing': 0.01518370552726365, 'grad_clip_norm': 0.6657309766375726, 'sched_step': 5, 'sched_gamma': 0.9159347210699069, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 8725, 'model_storage_size_kb': 37.490234375, 'model_size_validation': 'PASS'}
2025-10-02 22:35:23,628 - INFO - _models.training_function_executor - BO Objective: base=0.9513, size_penalty=0.0000, final=0.9513
2025-10-02 22:35:23,628 - INFO - _models.training_function_executor - Model: 8,725 parameters, 37.5KB (PASS 256KB limit)
2025-10-02 22:35:23,628 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 189.287s
2025-10-02 22:35:23,726 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9513
2025-10-02 22:35:23,726 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.097s
2025-10-02 22:35:23,726 - INFO - bo.run_bo - Recorded observation #30: hparams={'epochs': np.int64(46), 'batch_size': np.int64(32), 'lr': 0.0011054257996343788, 'weight_decay': 4.84590248526056e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(1), 'd_model_factor': np.int64(14), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.12832470723520353, 'use_focal_loss': np.False_, 'focal_gamma': 1.688963514153874, 'label_smoothing': 0.01518370552726365, 'grad_clip_norm': 0.6657309766375726, 'sched_step': np.int64(5), 'sched_gamma': 0.9159347210699069, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.9513
2025-10-02 22:35:23,726 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 30: {'epochs': np.int64(46), 'batch_size': np.int64(32), 'lr': 0.0011054257996343788, 'weight_decay': 4.84590248526056e-07, 'stem_channels': np.int64(10), 'nhead': np.int64(1), 'd_model_factor': np.int64(14), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.12832470723520353, 'use_focal_loss': np.False_, 'focal_gamma': 1.688963514153874, 'label_smoothing': 0.01518370552726365, 'grad_clip_norm': 0.6657309766375726, 'sched_step': np.int64(5), 'sched_gamma': 0.9159347210699069, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.9513
2025-10-02 22:35:23,726 - INFO - bo.run_bo - üîçBO Trial 31: Using RF surrogate + Expected Improvement
2025-10-02 22:35:23,726 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:35:23,726 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:35:23,726 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:35:23,726 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 30, 'batch_size': 256, 'lr': 0.0009813063998237732, 'weight_decay': 4.3858615991356225e-07, 'stem_channels': 9, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.09353416764786732, 'use_focal_loss': False, 'focal_gamma': 2.924527526655397, 'label_smoothing': 0.020501330970017276, 'grad_clip_norm': 0.8503468291382101, 'sched_step': 9, 'sched_gamma': 0.9817578211237036, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 22:35:23,727 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 30, 'batch_size': 256, 'lr': 0.0009813063998237732, 'weight_decay': 4.3858615991356225e-07, 'stem_channels': 9, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.09353416764786732, 'use_focal_loss': False, 'focal_gamma': 2.924527526655397, 'label_smoothing': 0.020501330970017276, 'grad_clip_norm': 0.8503468291382101, 'sched_step': 9, 'sched_gamma': 0.9817578211237036, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 22:36:16,037 - INFO - _models.training_function_executor - Model: 5,655 parameters, 12.1KB storage
2025-10-02 22:36:16,037 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5843472979673185, 1.2159583342462592, 1.042083086295448, 0.9627548159877224, 0.9124846003189484, 0.8721361179920611, 0.8346550294179104, 0.8046587874438796, 0.7825976740192532, 0.7455721798985128, 0.7159478915677618, 0.7019715831344209, 0.6859448817563983, 0.6791299001818719, 0.6659468455772907, 0.6547917966682376, 0.6470624280913941, 0.6415295840631626, 0.6316839225313192, 0.6258891022388706, 0.6219231873434207, 0.6169417380700339, 0.612867038403747, 0.6047407851681331, 0.6031173729632906, 0.5961099195699923, 0.5948070427702471, 0.5901941414786525, 0.5872941623615956, 0.5832805532570101], 'val_losses': [1.3828403996638585, 1.0991122978340935, 0.9937491841729071, 0.985577890753761, 0.9261196071141765, 0.8911395975035125, 0.9056465255931839, 0.8665932006457144, 0.8253238092701383, 0.8104653116187241, 0.8065613274167406, 0.7837749415584532, 0.7914644451521345, 0.7770049465567438, 0.7718480265748454, 0.7652379410142305, 0.7594239939619852, 0.7824919036479989, 0.7624420798402908, 0.7591760977738603, 0.7743786987602942, 0.8049584341861747, 0.783704046631887, 0.7806401751331482, 0.7747494314804574, 0.7727243884764972, 0.7551490472770398, 0.7821050145515238, 0.7591229135448541, 0.7707044749671602], 'val_acc': [0.3794010775592031, 0.4648540283172535, 0.5064528254604687, 0.6662072422002255, 0.6589399824583385, 0.6445307605563213, 0.7162009773211377, 0.6392682621225411, 0.7144468111765443, 0.7713319132940735, 0.7957649417366245, 0.7896253602305475, 0.7747149480015035, 0.7739631625109635, 0.8406214760055131, 0.8146848765818819, 0.7893747650670342, 0.8485152236561835, 0.8170655306352588, 0.8462598671845634, 0.8502693898007768, 0.854028317253477, 0.8480140333291567, 0.8255857661947125, 0.8457586768575367, 0.8828467610575116, 0.8119283297832351, 0.877333667460218, 0.84488159378524, 0.8407467735872698], 'best_val_acc': 0.8828467610575116, 'model_size_bytes': 19986, 'config_used': {'epochs': 30, 'batch_size': 256, 'lr': 0.0009813063998237732, 'weight_decay': 4.3858615991356225e-07, 'stem_channels': 9, 'nhead': 1, 'd_model': 14, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.09353416764786732, 'use_focal_loss': False, 'focal_gamma': 2.924527526655397, 'label_smoothing': 0.020501330970017276, 'grad_clip_norm': 0.8503468291382101, 'sched_step': 9, 'sched_gamma': 0.9817578211237036, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 30, 'batch_size': 256, 'lr': 0.0009813063998237732, 'weight_decay': 4.3858615991356225e-07, 'stem_channels': 9, 'nhead': 1, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.09353416764786732, 'use_focal_loss': False, 'focal_gamma': 2.924527526655397, 'label_smoothing': 0.020501330970017276, 'grad_clip_norm': 0.8503468291382101, 'sched_step': 9, 'sched_gamma': 0.9817578211237036, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 5655, 'model_storage_size_kb': 12.149414062500002, 'model_size_validation': 'PASS'}
2025-10-02 22:36:16,037 - INFO - _models.training_function_executor - BO Objective: base=0.8407, size_penalty=0.0000, final=0.8407
2025-10-02 22:36:16,037 - INFO - _models.training_function_executor - Model: 5,655 parameters, 12.1KB (PASS 256KB limit)
2025-10-02 22:36:16,037 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 52.311s
2025-10-02 22:36:16,137 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8407
2025-10-02 22:36:16,137 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.100s
2025-10-02 22:36:16,137 - INFO - bo.run_bo - Recorded observation #31: hparams={'epochs': np.int64(30), 'batch_size': np.int64(256), 'lr': 0.0009813063998237732, 'weight_decay': 4.3858615991356225e-07, 'stem_channels': np.int64(9), 'nhead': np.int64(1), 'd_model_factor': np.int64(14), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.09353416764786732, 'use_focal_loss': np.False_, 'focal_gamma': 2.924527526655397, 'label_smoothing': 0.020501330970017276, 'grad_clip_norm': 0.8503468291382101, 'sched_step': np.int64(9), 'sched_gamma': 0.9817578211237036, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.8407
2025-10-02 22:36:16,137 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 31: {'epochs': np.int64(30), 'batch_size': np.int64(256), 'lr': 0.0009813063998237732, 'weight_decay': 4.3858615991356225e-07, 'stem_channels': np.int64(9), 'nhead': np.int64(1), 'd_model_factor': np.int64(14), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.09353416764786732, 'use_focal_loss': np.False_, 'focal_gamma': 2.924527526655397, 'label_smoothing': 0.020501330970017276, 'grad_clip_norm': 0.8503468291382101, 'sched_step': np.int64(9), 'sched_gamma': 0.9817578211237036, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.8407
2025-10-02 22:36:16,137 - INFO - bo.run_bo - üîçBO Trial 32: Using RF surrogate + Expected Improvement
2025-10-02 22:36:16,138 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:36:16,138 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:36:16,138 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:36:16,138 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 20, 'batch_size': 64, 'lr': 0.0007183372082903062, 'weight_decay': 1.2151705507867004e-06, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.07749288055133632, 'use_focal_loss': False, 'focal_gamma': 2.212659776450657, 'label_smoothing': 0.007339372851869331, 'grad_clip_norm': 0.5505297486415646, 'sched_step': 4, 'sched_gamma': 0.7830575194803281, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:36:16,139 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 20, 'batch_size': 64, 'lr': 0.0007183372082903062, 'weight_decay': 1.2151705507867004e-06, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.07749288055133632, 'use_focal_loss': False, 'focal_gamma': 2.212659776450657, 'label_smoothing': 0.007339372851869331, 'grad_clip_norm': 0.5505297486415646, 'sched_step': 4, 'sched_gamma': 0.7830575194803281, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:37:21,717 - INFO - _models.training_function_executor - Model: 5,991 parameters, 25.7KB storage
2025-10-02 22:37:21,717 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.399644925485065, 0.9920332447318465, 0.7849728776574886, 0.6626465058758404, 0.6045192141593841, 0.5764426151261653, 0.5520481770619583, 0.5362748008856099, 0.5034956497752913, 0.4924508120791228, 0.47944128053180035, 0.4720174169312988, 0.4571524469680596, 0.45198300292541727, 0.4468169291125194, 0.4407196889540398, 0.4234219854453398, 0.41591770827762764, 0.4103730718276108, 0.4058004322720587], 'val_losses': [1.171686508821046, 0.8592101663683399, 0.7162977851523058, 0.6669083952814128, 0.5824927979133404, 0.596996414379105, 0.5951649404090383, 0.5752666111414242, 0.5915138463958465, 0.5675487960883063, 0.5517393559564729, 0.5363795461996413, 0.5227453631650325, 0.532035810608954, 0.550950650261572, 0.576377136891624, 0.5278086987761772, 0.5410532822153081, 0.5293064786144821, 0.5513969982660678], 'val_acc': [0.423756421501065, 0.807417616839995, 0.8595414108507706, 0.8721964666081945, 0.838366119533893, 0.8575366495426638, 0.8582884350332038, 0.8665580754291442, 0.878085452950758, 0.868562836737251, 0.8472622478386167, 0.8944994361608821, 0.8987595539406089, 0.8978824708683122, 0.9001378273399323, 0.9119158000250596, 0.9005137200852024, 0.9000125297581757, 0.8981330660318256, 0.9037714572108758], 'best_val_acc': 0.9119158000250596, 'model_size_bytes': 36142, 'config_used': {'epochs': 20, 'batch_size': 64, 'lr': 0.0007183372082903062, 'weight_decay': 1.2151705507867004e-06, 'stem_channels': 16, 'nhead': 1, 'd_model': 9, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.07749288055133632, 'use_focal_loss': False, 'focal_gamma': 2.212659776450657, 'label_smoothing': 0.007339372851869331, 'grad_clip_norm': 0.5505297486415646, 'sched_step': 4, 'sched_gamma': 0.7830575194803281, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 20, 'batch_size': 64, 'lr': 0.0007183372082903062, 'weight_decay': 1.2151705507867004e-06, 'stem_channels': 16, 'nhead': 1, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.07749288055133632, 'use_focal_loss': False, 'focal_gamma': 2.212659776450657, 'label_smoothing': 0.007339372851869331, 'grad_clip_norm': 0.5505297486415646, 'sched_step': 4, 'sched_gamma': 0.7830575194803281, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 5991, 'model_storage_size_kb': 25.742578125, 'model_size_validation': 'PASS'}
2025-10-02 22:37:21,717 - INFO - _models.training_function_executor - BO Objective: base=0.9038, size_penalty=0.0000, final=0.9038
2025-10-02 22:37:21,717 - INFO - _models.training_function_executor - Model: 5,991 parameters, 25.7KB (PASS 256KB limit)
2025-10-02 22:37:21,717 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 65.580s
2025-10-02 22:37:21,818 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9038
2025-10-02 22:37:21,818 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-10-02 22:37:21,819 - INFO - bo.run_bo - Recorded observation #32: hparams={'epochs': np.int64(20), 'batch_size': np.int64(64), 'lr': 0.0007183372082903062, 'weight_decay': 1.2151705507867004e-06, 'stem_channels': np.int64(16), 'nhead': np.int64(1), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.07749288055133632, 'use_focal_loss': np.False_, 'focal_gamma': 2.212659776450657, 'label_smoothing': 0.007339372851869331, 'grad_clip_norm': 0.5505297486415646, 'sched_step': np.int64(4), 'sched_gamma': 0.7830575194803281, 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.9038
2025-10-02 22:37:21,819 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 32: {'epochs': np.int64(20), 'batch_size': np.int64(64), 'lr': 0.0007183372082903062, 'weight_decay': 1.2151705507867004e-06, 'stem_channels': np.int64(16), 'nhead': np.int64(1), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.07749288055133632, 'use_focal_loss': np.False_, 'focal_gamma': 2.212659776450657, 'label_smoothing': 0.007339372851869331, 'grad_clip_norm': 0.5505297486415646, 'sched_step': np.int64(4), 'sched_gamma': 0.7830575194803281, 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.9038
2025-10-02 22:37:21,819 - INFO - bo.run_bo - üîçBO Trial 33: Using RF surrogate + Expected Improvement
2025-10-02 22:37:21,819 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:37:21,819 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:37:21,819 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:37:21,819 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 40, 'batch_size': 64, 'lr': 0.000711536160246545, 'weight_decay': 2.452941981372148e-07, 'stem_channels': 17, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.2517456458201104, 'use_focal_loss': False, 'focal_gamma': 1.827612290578371, 'label_smoothing': 0.016072845966106745, 'grad_clip_norm': 0.39803373596946434, 'sched_step': 5, 'sched_gamma': 0.8228112620732786, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:37:21,820 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 40, 'batch_size': 64, 'lr': 0.000711536160246545, 'weight_decay': 2.452941981372148e-07, 'stem_channels': 17, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.2517456458201104, 'use_focal_loss': False, 'focal_gamma': 1.827612290578371, 'label_smoothing': 0.016072845966106745, 'grad_clip_norm': 0.39803373596946434, 'sched_step': 5, 'sched_gamma': 0.8228112620732786, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:41:24,391 - INFO - _models.training_function_executor - Model: 28,051 parameters, 120.5KB storage
2025-10-02 22:41:24,392 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.100480439571593, 0.6923323742665134, 0.6168274167590552, 0.5694443112092146, 0.5351313962056008, 0.5080944682349128, 0.4873553780753134, 0.47693852143576243, 0.4630627785227754, 0.44455942569533163, 0.4285837007831841, 0.42349945617114954, 0.4197924507219563, 0.4073702880558213, 0.41248832961332416, 0.39643571271344585, 0.3939822290627292, 0.39205729712505777, 0.38149452702490433, 0.3801741705959357, 0.3660797114473714, 0.37162913957085186, 0.366482802702812, 0.3628862198946698, 0.35830928981854976, 0.35286113081228443, 0.3499532110786743, 0.34923612751414207, 0.34825783856503667, 0.3510606464962349, 0.34476673050571743, 0.34094078688193874, 0.33976711846120905, 0.3404051330765249, 0.3372720038797855, 0.3349089209225245, 0.33465222772420306, 0.3344046062756103, 0.3344760934801227, 0.3320597946033275], 'val_losses': [0.778123901446292, 0.6574697255819397, 0.6298433314841309, 0.6291028637438546, 0.6032706053241156, 0.580508893929154, 0.6183483361331551, 0.5734289506894427, 0.5728537228125078, 0.5676423248649017, 0.6247017339960463, 0.6094975032508859, 0.6469970621451476, 0.6495698653969038, 0.6303612264889611, 0.5861164813740124, 0.7138494428962772, 0.6329026241945364, 0.6442089048248681, 0.6169795273927918, 0.6913511746211423, 0.6221238908694809, 0.6557258082398076, 0.6521649985456209, 0.6759540104295448, 0.6969949873508539, 0.7108369875246981, 0.6720446032280463, 0.6949636235584846, 0.7221269952505547, 0.6765255831847616, 0.692517873100015, 0.7138776401277921, 0.6782741173364333, 0.7386697042617205, 0.7140898514534803, 0.6862521028476855, 0.7128312113798586, 0.7099445377610827, 0.7058857513719775], 'val_acc': [0.7814810174163639, 0.8255857661947125, 0.9005137200852024, 0.9028943741385791, 0.8894875328906152, 0.9100363362987094, 0.9373512091216639, 0.9441172785365243, 0.9269515098358602, 0.9216890114020799, 0.8851021175291317, 0.9437413857912542, 0.9419872196466608, 0.9513845382784112, 0.9463726350081444, 0.9487532890615211, 0.9634131061270518, 0.9631625109635384, 0.9500062648790878, 0.9560205488034081, 0.9581506076932715, 0.9576494173662449, 0.9586517980202982, 0.9595288810925949, 0.9657937601804285, 0.9640395940358351, 0.9594035835108382, 0.9607818569101616, 0.9631625109635384, 0.9652925698534018, 0.9567723342939481, 0.9599047738378649, 0.9576494173662449, 0.962160130309485, 0.9666708432527252, 0.9651672722716451, 0.9590276907655683, 0.9642901891993485, 0.9629119158000251, 0.9609071544919183], 'best_val_acc': 0.9666708432527252, 'model_size_bytes': 68974, 'config_used': {'epochs': 40, 'batch_size': 64, 'lr': 0.000711536160246545, 'weight_decay': 2.452941981372148e-07, 'stem_channels': 17, 'nhead': 4, 'd_model': 36, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.2517456458201104, 'use_focal_loss': False, 'focal_gamma': 1.827612290578371, 'label_smoothing': 0.016072845966106745, 'grad_clip_norm': 0.39803373596946434, 'sched_step': 5, 'sched_gamma': 0.8228112620732786, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 40, 'batch_size': 64, 'lr': 0.000711536160246545, 'weight_decay': 2.452941981372148e-07, 'stem_channels': 17, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.2517456458201104, 'use_focal_loss': False, 'focal_gamma': 1.827612290578371, 'label_smoothing': 0.016072845966106745, 'grad_clip_norm': 0.39803373596946434, 'sched_step': 5, 'sched_gamma': 0.8228112620732786, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 28051, 'model_storage_size_kb': 120.53164062500001, 'model_size_validation': 'PASS'}
2025-10-02 22:41:24,392 - INFO - _models.training_function_executor - BO Objective: base=0.9609, size_penalty=0.0000, final=0.9609
2025-10-02 22:41:24,392 - INFO - _models.training_function_executor - Model: 28,051 parameters, 120.5KB (PASS 256KB limit)
2025-10-02 22:41:24,392 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 242.573s
2025-10-02 22:41:24,493 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9609
2025-10-02 22:41:24,493 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.101s
2025-10-02 22:41:24,493 - INFO - bo.run_bo - Recorded observation #33: hparams={'epochs': np.int64(40), 'batch_size': np.int64(64), 'lr': 0.000711536160246545, 'weight_decay': 2.452941981372148e-07, 'stem_channels': np.int64(17), 'nhead': np.int64(4), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.2517456458201104, 'use_focal_loss': np.False_, 'focal_gamma': 1.827612290578371, 'label_smoothing': 0.016072845966106745, 'grad_clip_norm': 0.39803373596946434, 'sched_step': np.int64(5), 'sched_gamma': 0.8228112620732786, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.9609
2025-10-02 22:41:24,493 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 33: {'epochs': np.int64(40), 'batch_size': np.int64(64), 'lr': 0.000711536160246545, 'weight_decay': 2.452941981372148e-07, 'stem_channels': np.int64(17), 'nhead': np.int64(4), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.2517456458201104, 'use_focal_loss': np.False_, 'focal_gamma': 1.827612290578371, 'label_smoothing': 0.016072845966106745, 'grad_clip_norm': 0.39803373596946434, 'sched_step': np.int64(5), 'sched_gamma': 0.8228112620732786, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.9609
2025-10-02 22:41:24,493 - INFO - bo.run_bo - üîçBO Trial 34: Using RF surrogate + Expected Improvement
2025-10-02 22:41:24,493 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:41:24,493 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:41:24,493 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:41:24,493 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 50, 'batch_size': 32, 'lr': 0.0007734069290378093, 'weight_decay': 4.3596761737201564e-07, 'stem_channels': 20, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.15569786169744582, 'use_focal_loss': False, 'focal_gamma': 1.209329549276585, 'label_smoothing': 0.013777854699322004, 'grad_clip_norm': 0.520776165349772, 'sched_step': 8, 'sched_gamma': 0.8273846452278946, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:41:24,495 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 50, 'batch_size': 32, 'lr': 0.0007734069290378093, 'weight_decay': 4.3596761737201564e-07, 'stem_channels': 20, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.15569786169744582, 'use_focal_loss': False, 'focal_gamma': 1.209329549276585, 'label_smoothing': 0.013777854699322004, 'grad_clip_norm': 0.520776165349772, 'sched_step': 8, 'sched_gamma': 0.8273846452278946, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:44:46,008 - INFO - _models.training_function_executor - Model: 6,730 parameters, 28.9KB storage
2025-10-02 22:44:46,008 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2857857508807689, 0.8468556083936953, 0.6891772243659403, 0.6433083023772675, 0.6211382477063081, 0.6013222326107747, 0.5852262497665223, 0.5616299587226962, 0.5389769861181551, 0.5338761336025288, 0.527653394280208, 0.516751868915159, 0.5209324666104422, 0.5014507488889905, 0.49604491810636875, 0.4973787394501424, 0.48599623267790937, 0.48146261646981875, 0.4691661566199954, 0.4739913148968582, 0.4644625867417263, 0.46288903296428846, 0.46388487197759587, 0.4589753358173582, 0.4532289498992699, 0.4471242071258593, 0.4554162714145493, 0.44720509326895264, 0.44477451545748614, 0.436023979470742, 0.4400688414790556, 0.4368584040143124, 0.4302721426749339, 0.4223235364441689, 0.427478158891834, 0.4229599187150656, 0.42303775406631017, 0.4228340213812559, 0.4240646602418628, 0.42642874642168, 0.41165390114036193, 0.41628022070005416, 0.41262197158655395, 0.4150112906042445, 0.4065674782141003, 0.40023937640836005, 0.4123133596007068, 0.40790815181598195, 0.39565849717956986, 0.3991963863760234], 'val_losses': [0.9913620267979648, 0.7347330629429771, 0.6568138403352408, 0.7576419774220262, 0.6517682053991732, 0.7047257551631897, 0.6753588710388673, 0.6506197688693377, 0.595333138125804, 0.6723022372512617, 0.5666385747379356, 0.6380571286983918, 0.5886288375995494, 0.6569914520122909, 0.6626952256554127, 0.6130006282554505, 0.5791689204760414, 0.6138266553676841, 0.613034722605171, 0.6937490465079106, 0.6116140424689916, 0.5939694120985212, 0.6545936869747462, 0.6053389707703203, 0.6441462825166449, 0.6653725898156801, 0.6437172238322789, 0.6382470481781983, 0.6754336280491758, 0.6426987821349911, 0.633467724442467, 0.6581770060818501, 0.6910981718511932, 0.6697797188557504, 0.6616177118118807, 0.6790857224248732, 0.6003456232377781, 0.6415576815918833, 0.6458162149679779, 0.6540264294733307, 0.6315673071330479, 0.6900836531492481, 0.6874163132714024, 0.6445002941585785, 0.6750411425537819, 0.7161287393893773, 0.6761698794236474, 0.6972345495534681, 0.650064101323435, 0.6801896528139582], 'val_acc': [0.7654429269515098, 0.8104247588021551, 0.8848515223656184, 0.9191830597669465, 0.9339681744142339, 0.9441172785365243, 0.9404836486655808, 0.9350958526500438, 0.9485026938980078, 0.9501315624608445, 0.9507580503696279, 0.9591529883473249, 0.9423631123919308, 0.9579000125297582, 0.9550181681493547, 0.9453702543540909, 0.9379776970304473, 0.955268763312868, 0.9580253101115148, 0.9570229294574615, 0.9553940608946248, 0.9538904899135446, 0.9596541786743515, 0.9557699536398947, 0.9580253101115148, 0.9558952512216514, 0.9642901891993485, 0.9609071544919183, 0.9543916802405713, 0.9572735246209748, 0.9591529883473249, 0.953389299586518, 0.9627866182182684, 0.9626613206365117, 0.9602806665831349, 0.9528881092594913, 0.9548928705675981, 0.9579000125297582, 0.9599047738378649, 0.9600300714196216, 0.9570229294574615, 0.9596541786743515, 0.9607818569101616, 0.960656559328405, 0.9531387044230046, 0.9602806665831349, 0.9620348327277284, 0.9605312617466483, 0.9597794762561083, 0.9571482270392181], 'best_val_acc': 0.9642901891993485, 'model_size_bytes': 26158, 'config_used': {'epochs': 50, 'batch_size': 32, 'lr': 0.0007734069290378093, 'weight_decay': 4.3596761737201564e-07, 'stem_channels': 20, 'nhead': 1, 'd_model': 10, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.15569786169744582, 'use_focal_loss': False, 'focal_gamma': 1.209329549276585, 'label_smoothing': 0.013777854699322004, 'grad_clip_norm': 0.520776165349772, 'sched_step': 8, 'sched_gamma': 0.8273846452278946, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 50, 'batch_size': 32, 'lr': 0.0007734069290378093, 'weight_decay': 4.3596761737201564e-07, 'stem_channels': 20, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.15569786169744582, 'use_focal_loss': False, 'focal_gamma': 1.209329549276585, 'label_smoothing': 0.013777854699322004, 'grad_clip_norm': 0.520776165349772, 'sched_step': 8, 'sched_gamma': 0.8273846452278946, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 6730, 'model_storage_size_kb': 28.917968750000004, 'model_size_validation': 'PASS'}
2025-10-02 22:44:46,008 - INFO - _models.training_function_executor - BO Objective: base=0.9571, size_penalty=0.0000, final=0.9571
2025-10-02 22:44:46,008 - INFO - _models.training_function_executor - Model: 6,730 parameters, 28.9KB (PASS 256KB limit)
2025-10-02 22:44:46,008 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 201.515s
2025-10-02 22:44:46,110 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9571
2025-10-02 22:44:46,111 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-02 22:44:46,111 - INFO - bo.run_bo - Recorded observation #34: hparams={'epochs': np.int64(50), 'batch_size': np.int64(32), 'lr': 0.0007734069290378093, 'weight_decay': 4.3596761737201564e-07, 'stem_channels': np.int64(20), 'nhead': np.int64(1), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.15569786169744582, 'use_focal_loss': np.False_, 'focal_gamma': 1.209329549276585, 'label_smoothing': 0.013777854699322004, 'grad_clip_norm': 0.520776165349772, 'sched_step': np.int64(8), 'sched_gamma': 0.8273846452278946, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.9571
2025-10-02 22:44:46,111 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 34: {'epochs': np.int64(50), 'batch_size': np.int64(32), 'lr': 0.0007734069290378093, 'weight_decay': 4.3596761737201564e-07, 'stem_channels': np.int64(20), 'nhead': np.int64(1), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.15569786169744582, 'use_focal_loss': np.False_, 'focal_gamma': 1.209329549276585, 'label_smoothing': 0.013777854699322004, 'grad_clip_norm': 0.520776165349772, 'sched_step': np.int64(8), 'sched_gamma': 0.8273846452278946, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.9571
2025-10-02 22:44:46,111 - INFO - bo.run_bo - üîçBO Trial 35: Using RF surrogate + Expected Improvement
2025-10-02 22:44:46,111 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:44:46,111 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:44:46,111 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:44:46,111 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 49, 'batch_size': 64, 'lr': 0.0003053943012514547, 'weight_decay': 2.9007895988941683e-07, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 16, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.19083756790833853, 'use_focal_loss': False, 'focal_gamma': 1.8960896822937616, 'label_smoothing': 0.0031543379745381135, 'grad_clip_norm': 0.7070220098273021, 'sched_step': 5, 'sched_gamma': 0.8144938709156587, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:44:46,112 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 49, 'batch_size': 64, 'lr': 0.0003053943012514547, 'weight_decay': 2.9007895988941683e-07, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 16, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.19083756790833853, 'use_focal_loss': False, 'focal_gamma': 1.8960896822937616, 'label_smoothing': 0.0031543379745381135, 'grad_clip_norm': 0.7070220098273021, 'sched_step': 5, 'sched_gamma': 0.8144938709156587, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:46:42,753 - INFO - _models.training_function_executor - Model: 11,491 parameters, 49.4KB storage
2025-10-02 22:46:42,753 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.355300420373879, 0.9327612408692312, 0.7182563081632501, 0.5864703892201397, 0.5214295779367036, 0.46980996878733483, 0.44282593748919985, 0.4105271304254562, 0.3942895917339709, 0.37397938992144175, 0.34364246767962653, 0.33401225080291597, 0.33028402738664075, 0.31196092109525875, 0.30719104194963753, 0.2944622669421846, 0.28642424349273554, 0.282430852697509, 0.27297415748984016, 0.2642648496118602, 0.2589781063692584, 0.25934591790796524, 0.252028234729872, 0.2480234680493979, 0.24825231947479282, 0.24092761537768662, 0.23558580467100337, 0.2342461587553861, 0.23261608204996062, 0.2265414695981279, 0.2207680475505317, 0.22549860606485414, 0.21730161952508614, 0.21172140565859332, 0.21566809887997776, 0.21002822237120375, 0.2085671619580204, 0.21053165586857414, 0.20575440587241395, 0.20559111395019025, 0.2005351731614414, 0.2012630348801482, 0.1960284391779449, 0.19626959442207323, 0.19616940095672944, 0.19301054120498826, 0.19019000375475856, 0.19422359568106368, 0.18880683821064262], 'val_losses': [1.07326659458261, 0.8119265911214977, 0.6642931217150108, 0.5809213667193117, 0.5181805350072192, 0.49282342760862524, 0.4709192804115605, 0.46358310124760893, 0.45217404380028087, 0.45522579675090596, 0.4649440598523702, 0.4455054464935883, 0.43629378977313016, 0.4487673026355432, 0.4577687786360639, 0.45274835276045067, 0.4514453134625168, 0.46634611711811563, 0.4621379494801483, 0.5152047828181527, 0.4883601721061111, 0.465151274746454, 0.5387884311815833, 0.47168226118688816, 0.5060313162596329, 0.4868577316192409, 0.5356417610417958, 0.5730289225514977, 0.4941541510272961, 0.5173401102104397, 0.5007909277733847, 0.5126872446928059, 0.4773863483350568, 0.5386149040694643, 0.5417515961855908, 0.566770244139117, 0.5455940075049707, 0.5202123337768251, 0.5187634598370886, 0.5093781029934603, 0.4966060829676418, 0.535509611017019, 0.5443896596599919, 0.5412065619186207, 0.566432526462315, 0.5520850709768902, 0.536680587109371, 0.574498195439678, 0.5461546539319306], 'val_acc': [0.5437915048239569, 0.6659566470367122, 0.8173161257987721, 0.8411226663325397, 0.8457586768575367, 0.8388673098609197, 0.8629244455582007, 0.8738253351710312, 0.8993860418493923, 0.8778348577872447, 0.908658062899386, 0.8819696779852149, 0.9106628242074928, 0.9046485402831725, 0.9119158000250596, 0.9003884225034456, 0.9191830597669465, 0.9200601428392432, 0.9209372259115399, 0.9273274025811302, 0.9260744267635634, 0.9125422879338428, 0.930459842125047, 0.9184312742764065, 0.9303345445432903, 0.9209372259115399, 0.939230672848014, 0.9320887106878837, 0.9282044856534268, 0.9404836486655808, 0.9171782984588397, 0.9284550808169403, 0.9210625234932965, 0.9354717453953139, 0.9374765067034206, 0.9454955519358477, 0.9413607317378775, 0.9267009146723468, 0.9383535897757174, 0.9354717453953139, 0.9359729357223405, 0.9322140082696404, 0.9406089462473374, 0.9333416865054505, 0.9443678737000376, 0.9428643027189575, 0.939230672848014, 0.9345946623230171, 0.9398571607567974], 'best_val_acc': 0.9454955519358477, 'model_size_bytes': 35502, 'config_used': {'epochs': 49, 'batch_size': 64, 'lr': 0.0003053943012514547, 'weight_decay': 2.9007895988941683e-07, 'stem_channels': 24, 'nhead': 1, 'd_model': 16, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.19083756790833853, 'use_focal_loss': False, 'focal_gamma': 1.8960896822937616, 'label_smoothing': 0.0031543379745381135, 'grad_clip_norm': 0.7070220098273021, 'sched_step': 5, 'sched_gamma': 0.8144938709156587, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 49, 'batch_size': 64, 'lr': 0.0003053943012514547, 'weight_decay': 2.9007895988941683e-07, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 16, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.19083756790833853, 'use_focal_loss': False, 'focal_gamma': 1.8960896822937616, 'label_smoothing': 0.0031543379745381135, 'grad_clip_norm': 0.7070220098273021, 'sched_step': 5, 'sched_gamma': 0.8144938709156587, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 11491, 'model_storage_size_kb': 49.375390625, 'model_size_validation': 'PASS'}
2025-10-02 22:46:42,753 - INFO - _models.training_function_executor - BO Objective: base=0.9399, size_penalty=0.0000, final=0.9399
2025-10-02 22:46:42,753 - INFO - _models.training_function_executor - Model: 11,491 parameters, 49.4KB (PASS 256KB limit)
2025-10-02 22:46:42,753 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 116.642s
2025-10-02 22:46:42,856 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9399
2025-10-02 22:46:42,856 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-02 22:46:42,856 - INFO - bo.run_bo - Recorded observation #35: hparams={'epochs': np.int64(49), 'batch_size': np.int64(64), 'lr': 0.0003053943012514547, 'weight_decay': 2.9007895988941683e-07, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(16), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.19083756790833853, 'use_focal_loss': np.False_, 'focal_gamma': 1.8960896822937616, 'label_smoothing': 0.0031543379745381135, 'grad_clip_norm': 0.7070220098273021, 'sched_step': np.int64(5), 'sched_gamma': 0.8144938709156587, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.9399
2025-10-02 22:46:42,856 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 35: {'epochs': np.int64(49), 'batch_size': np.int64(64), 'lr': 0.0003053943012514547, 'weight_decay': 2.9007895988941683e-07, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(16), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.19083756790833853, 'use_focal_loss': np.False_, 'focal_gamma': 1.8960896822937616, 'label_smoothing': 0.0031543379745381135, 'grad_clip_norm': 0.7070220098273021, 'sched_step': np.int64(5), 'sched_gamma': 0.8144938709156587, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.9399
2025-10-02 22:46:42,857 - INFO - bo.run_bo - üîçBO Trial 36: Using RF surrogate + Expected Improvement
2025-10-02 22:46:42,857 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:46:42,857 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:46:42,857 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:46:42,857 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 38, 'batch_size': 256, 'lr': 0.0002600712253783014, 'weight_decay': 2.642859558005238e-07, 'stem_channels': 18, 'nhead': 1, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.08116279621467361, 'use_focal_loss': False, 'focal_gamma': 2.117307777547289, 'label_smoothing': 0.023096413157396804, 'grad_clip_norm': 0.4809892935400414, 'sched_step': 5, 'sched_gamma': 0.6044933176836832, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 22:46:42,858 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 38, 'batch_size': 256, 'lr': 0.0002600712253783014, 'weight_decay': 2.642859558005238e-07, 'stem_channels': 18, 'nhead': 1, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.08116279621467361, 'use_focal_loss': False, 'focal_gamma': 2.117307777547289, 'label_smoothing': 0.023096413157396804, 'grad_clip_norm': 0.4809892935400414, 'sched_step': 5, 'sched_gamma': 0.6044933176836832, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 22:47:58,790 - INFO - _models.training_function_executor - Model: 3,120 parameters, 3.4KB storage
2025-10-02 22:47:58,790 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.724319210313292, 1.5957870120986961, 1.4326395527206597, 1.3203703728556555, 1.242699406572188, 1.184270571695923, 1.1383497331934316, 1.0903919846910815, 1.052510317183824, 1.0216575893502715, 0.992059005470767, 0.9752927307993257, 0.958578905985924, 0.942182326450894, 0.9276804655311408, 0.912954325395595, 0.9033750124011718, 0.8964410763902219, 0.8856473552983898, 0.8771231644651672, 0.8675346824734692, 0.86448772345383, 0.8569572057818999, 0.8529614712837006, 0.8483530797221377, 0.8422499485445759, 0.8401020429201063, 0.8360546514962777, 0.8357682470704284, 0.8331058716238492, 0.8297841098304605, 0.825130755184057, 0.8276344546025077, 0.82397885020916, 0.8212753569195154, 0.8188190751926712, 0.8185721996922961, 0.8184806808053978], 'val_losses': [1.68035075500516, 1.5024998886157153, 1.3642896072202242, 1.289246532914334, 1.1959505399775197, 1.1589474822178085, 1.1104432246004217, 1.0681772116446104, 1.0353524575569832, 1.0076082604613434, 0.987300726692564, 0.9707971405764896, 0.9564517828444612, 0.9405640081241456, 0.9269709431308057, 0.9162440261003174, 0.907176376091121, 0.8997859869097695, 0.8896127024803405, 0.8859063607829957, 0.877925979091834, 0.8739457460979877, 0.8689433372703326, 0.8646794114998895, 0.8605333297955573, 0.8567158859216126, 0.8541272651759354, 0.8512073444134161, 0.8493303741492838, 0.8475933486754218, 0.8454681465969605, 0.8437141742701519, 0.8418197285305989, 0.8409556598983572, 0.8387060501927676, 0.8388479768953561, 0.8371380959039881, 0.8370649692424033], 'val_acc': [0.33379275779977446, 0.3624859040220524, 0.32502192707680744, 0.36261120160380905, 0.35308858539030197, 0.4040847011652675, 0.45232427014158627, 0.47512843002130056, 0.5495551935847638, 0.5763688760806917, 0.6258614208745771, 0.6120786868813431, 0.5960405964164892, 0.6244831474752537, 0.6217266006766069, 0.6352587395063275, 0.6481643904272647, 0.6467861170279413, 0.6710938478887357, 0.683623606064403, 0.6794887858664328, 0.7014158626738504, 0.6822453326650796, 0.6954015787495301, 0.7031700288184438, 0.6936474126049367, 0.6960280666583135, 0.7095602054880341, 0.6984087207116902, 0.7054253852900639, 0.7114396692143842, 0.7063024683623607, 0.7098108006515474, 0.7159503821576244, 0.7085578248339807, 0.7083072296704673, 0.7151985966670843, 0.7138203232677609], 'best_val_acc': 0.7159503821576244, 'model_size_bytes': 66469, 'config_used': {'epochs': 38, 'batch_size': 256, 'lr': 0.0002600712253783014, 'weight_decay': 2.642859558005238e-07, 'stem_channels': 18, 'nhead': 1, 'd_model': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.08116279621467361, 'use_focal_loss': False, 'focal_gamma': 2.117307777547289, 'label_smoothing': 0.023096413157396804, 'grad_clip_norm': 0.4809892935400414, 'sched_step': 5, 'sched_gamma': 0.6044933176836832, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 38, 'batch_size': 256, 'lr': 0.0002600712253783014, 'weight_decay': 2.642859558005238e-07, 'stem_channels': 18, 'nhead': 1, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.08116279621467361, 'use_focal_loss': False, 'focal_gamma': 2.117307777547289, 'label_smoothing': 0.023096413157396804, 'grad_clip_norm': 0.4809892935400414, 'sched_step': 5, 'sched_gamma': 0.6044933176836832, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 3120, 'model_storage_size_kb': 3.3515625000000004, 'model_size_validation': 'PASS'}
2025-10-02 22:47:58,790 - INFO - _models.training_function_executor - BO Objective: base=0.7138, size_penalty=0.0000, final=0.7138
2025-10-02 22:47:58,790 - INFO - _models.training_function_executor - Model: 3,120 parameters, 3.4KB (PASS 256KB limit)
2025-10-02 22:47:58,790 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 75.933s
2025-10-02 22:47:59,011 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7138
2025-10-02 22:47:59,011 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.221s
2025-10-02 22:47:59,011 - INFO - bo.run_bo - Recorded observation #36: hparams={'epochs': np.int64(38), 'batch_size': np.int64(256), 'lr': 0.0002600712253783014, 'weight_decay': 2.642859558005238e-07, 'stem_channels': np.int64(18), 'nhead': np.int64(1), 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.08116279621467361, 'use_focal_loss': np.False_, 'focal_gamma': 2.117307777547289, 'label_smoothing': 0.023096413157396804, 'grad_clip_norm': 0.4809892935400414, 'sched_step': np.int64(5), 'sched_gamma': 0.6044933176836832, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.7138
2025-10-02 22:47:59,011 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 36: {'epochs': np.int64(38), 'batch_size': np.int64(256), 'lr': 0.0002600712253783014, 'weight_decay': 2.642859558005238e-07, 'stem_channels': np.int64(18), 'nhead': np.int64(1), 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.08116279621467361, 'use_focal_loss': np.False_, 'focal_gamma': 2.117307777547289, 'label_smoothing': 0.023096413157396804, 'grad_clip_norm': 0.4809892935400414, 'sched_step': np.int64(5), 'sched_gamma': 0.6044933176836832, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.7138
2025-10-02 22:47:59,012 - INFO - bo.run_bo - üîçBO Trial 37: Using RF surrogate + Expected Improvement
2025-10-02 22:47:59,012 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:47:59,012 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:47:59,012 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:47:59,012 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 33, 'batch_size': 128, 'lr': 0.0003669267370412326, 'weight_decay': 6.292182200596367e-07, 'stem_channels': 19, 'nhead': 2, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.281772720867553, 'use_focal_loss': False, 'focal_gamma': 2.593314384053278, 'label_smoothing': 0.0013672290955701108, 'grad_clip_norm': 0.5508427353966819, 'sched_step': 1, 'sched_gamma': 0.6271129781486083, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:47:59,014 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 33, 'batch_size': 128, 'lr': 0.0003669267370412326, 'weight_decay': 6.292182200596367e-07, 'stem_channels': 19, 'nhead': 2, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.281772720867553, 'use_focal_loss': False, 'focal_gamma': 2.593314384053278, 'label_smoothing': 0.0013672290955701108, 'grad_clip_norm': 0.5508427353966819, 'sched_step': 1, 'sched_gamma': 0.6271129781486083, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:50:14,505 - INFO - _models.training_function_executor - Model: 14,631 parameters, 62.9KB storage
2025-10-02 22:50:14,505 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4088879551941436, 1.0867578154708406, 0.8981032915511638, 0.807196437520864, 0.7590132804792693, 0.73029013484118, 0.7106690977676745, 0.6992100378913815, 0.6921664608307949, 0.6889529891996662, 0.6854407128148616, 0.6845141071945833, 0.6794167134194424, 0.6772127200893728, 0.6805277284429294, 0.6802460171570064, 0.6803908656049229, 0.678902580429019, 0.6787963810112827, 0.679714707144407, 0.6785711727001776, 0.6853436776668069, 0.6810269952959328, 0.6790025129102546, 0.6784529996815247, 0.6820300370123371, 0.6803458946893057, 0.6789630907738683, 0.6806345975264957, 0.6817862649865084, 0.6805005053550316, 0.6800534075294503, 0.6792652690555877], 'val_losses': [1.1933782150565853, 0.9425748842967332, 0.8215417780384445, 0.7613158449763986, 0.7299992480443513, 0.7038905842010575, 0.6907127371573415, 0.680269460229404, 0.6757215841598281, 0.6722134184589393, 0.6720279424415467, 0.669785877559257, 0.6694585071546872, 0.6689167323603604, 0.6686618521822647, 0.6684426018848498, 0.6683354650564233, 0.6682618888618503, 0.6682181898744882, 0.6681772416552988, 0.6681605825043608, 0.6681530739994908, 0.6681453975097471, 0.6681428330611681, 0.6681421137426659, 0.6681417500878647, 0.6681415810947684, 0.6681414612282668, 0.6681414511908477, 0.6681414394357154, 0.668141437665724, 0.6681414378599003, 0.6681414359480109], 'val_acc': [0.5691016163388046, 0.6180929708056635, 0.6110763062272898, 0.644280165392808, 0.6604435534394186, 0.6901390803157499, 0.6972810424758802, 0.6868813431900764, 0.6942739005137201, 0.7006640771833104, 0.6917679488785866, 0.6969051497306102, 0.6962786618218268, 0.6966545545670969, 0.6965292569853402, 0.6966545545670969, 0.6964039594035835, 0.6965292569853402, 0.6966545545670969, 0.6966545545670969, 0.6967798521488535, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969, 0.6966545545670969], 'best_val_acc': 0.7006640771833104, 'model_size_bytes': 71086, 'config_used': {'epochs': 33, 'batch_size': 128, 'lr': 0.0003669267370412326, 'weight_decay': 6.292182200596367e-07, 'stem_channels': 19, 'nhead': 2, 'd_model': 22, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.281772720867553, 'use_focal_loss': False, 'focal_gamma': 2.593314384053278, 'label_smoothing': 0.0013672290955701108, 'grad_clip_norm': 0.5508427353966819, 'sched_step': 1, 'sched_gamma': 0.6271129781486083, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 33, 'batch_size': 128, 'lr': 0.0003669267370412326, 'weight_decay': 6.292182200596367e-07, 'stem_channels': 19, 'nhead': 2, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.281772720867553, 'use_focal_loss': False, 'focal_gamma': 2.593314384053278, 'label_smoothing': 0.0013672290955701108, 'grad_clip_norm': 0.5508427353966819, 'sched_step': 1, 'sched_gamma': 0.6271129781486083, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 14631, 'model_storage_size_kb': 62.86757812500001, 'model_size_validation': 'PASS'}
2025-10-02 22:50:14,506 - INFO - _models.training_function_executor - BO Objective: base=0.6967, size_penalty=0.0000, final=0.6967
2025-10-02 22:50:14,506 - INFO - _models.training_function_executor - Model: 14,631 parameters, 62.9KB (PASS 256KB limit)
2025-10-02 22:50:14,506 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 135.494s
2025-10-02 22:50:14,608 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6967
2025-10-02 22:50:14,608 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-02 22:50:14,608 - INFO - bo.run_bo - Recorded observation #37: hparams={'epochs': np.int64(33), 'batch_size': np.int64(128), 'lr': 0.0003669267370412326, 'weight_decay': 6.292182200596367e-07, 'stem_channels': np.int64(19), 'nhead': np.int64(2), 'd_model_factor': np.int64(11), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.281772720867553, 'use_focal_loss': np.False_, 'focal_gamma': 2.593314384053278, 'label_smoothing': 0.0013672290955701108, 'grad_clip_norm': 0.5508427353966819, 'sched_step': np.int64(1), 'sched_gamma': 0.6271129781486083, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.6967
2025-10-02 22:50:14,608 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 37: {'epochs': np.int64(33), 'batch_size': np.int64(128), 'lr': 0.0003669267370412326, 'weight_decay': 6.292182200596367e-07, 'stem_channels': np.int64(19), 'nhead': np.int64(2), 'd_model_factor': np.int64(11), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.281772720867553, 'use_focal_loss': np.False_, 'focal_gamma': 2.593314384053278, 'label_smoothing': 0.0013672290955701108, 'grad_clip_norm': 0.5508427353966819, 'sched_step': np.int64(1), 'sched_gamma': 0.6271129781486083, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.6967
2025-10-02 22:50:14,608 - INFO - bo.run_bo - üîçBO Trial 38: Using RF surrogate + Expected Improvement
2025-10-02 22:50:14,608 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:50:14,608 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:50:14,608 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:50:14,608 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 43, 'batch_size': 64, 'lr': 0.00016455991294015744, 'weight_decay': 1.9511804152780558e-06, 'stem_channels': 19, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.03488772682820769, 'use_focal_loss': False, 'focal_gamma': 2.3173509317696483, 'label_smoothing': 0.00423953777332461, 'grad_clip_norm': 0.8107173828506681, 'sched_step': 2, 'sched_gamma': 0.7679235479442075, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:50:14,610 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 43, 'batch_size': 64, 'lr': 0.00016455991294015744, 'weight_decay': 1.9511804152780558e-06, 'stem_channels': 19, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.03488772682820769, 'use_focal_loss': False, 'focal_gamma': 2.3173509317696483, 'label_smoothing': 0.00423953777332461, 'grad_clip_norm': 0.8107173828506681, 'sched_step': 2, 'sched_gamma': 0.7679235479442075, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 22:52:52,144 - INFO - _models.training_function_executor - Model: 7,008 parameters, 30.1KB storage
2025-10-02 22:52:52,144 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5343047390567275, 1.3101690849243495, 1.1534311399570971, 1.0616497696463605, 0.9990949471507781, 0.9526317517037373, 0.9162248858412798, 0.8782199811910032, 0.8491244753198068, 0.8238726062471137, 0.7935695282290335, 0.7713635730753864, 0.7546477052191014, 0.737552616921328, 0.7190200271595392, 0.7098662232548298, 0.6986367083798636, 0.6894423088229614, 0.6819529974964356, 0.676372893385446, 0.6693500985840981, 0.6638093849278981, 0.6590096163924459, 0.654960522119202, 0.6478730671758233, 0.6463951200738802, 0.6425963674082895, 0.6409325935456499, 0.6375191978011197, 0.6371577969573328, 0.6372231526810681, 0.6355516465147221, 0.631387720328952, 0.6342493374014664, 0.6334059731516963, 0.6290345129331759, 0.6315000879713397, 0.6323334286394631, 0.6291619832737607, 0.6292194575421424, 0.6280287318303913, 0.6321053134074237, 0.6240690998186672], 'val_losses': [1.413217054798316, 1.2256639868286137, 1.1048286655704682, 1.0309696318571198, 0.9865395293067294, 0.9479975952807561, 0.9097593487571197, 0.8676469086435651, 0.838698231879668, 0.8138216081649614, 0.7953313129645155, 0.7679577474754834, 0.7559023007924149, 0.7466761269241986, 0.731078169419344, 0.7185347053568818, 0.7084727859739044, 0.7021791444447925, 0.6963390886387779, 0.6902902877699715, 0.6830463168047796, 0.6786020474690212, 0.6764713487310258, 0.6747682926171168, 0.6718705226463597, 0.6686703096638794, 0.6666092801147827, 0.6648936001090324, 0.6629818137718791, 0.6612688285443228, 0.6604079937609257, 0.6595914792691895, 0.6587662379584237, 0.6579339822616334, 0.6571453938491959, 0.6565939441552932, 0.6561203610253296, 0.6554504954311546, 0.6549021196744746, 0.654675012505035, 0.6544785061182496, 0.6541861378150302, 0.6539984869114543], 'val_acc': [0.4426763563463225, 0.5479263250219271, 0.5683498308482646, 0.6496679614083448, 0.6248590402205237, 0.6321262999624108, 0.713444430522491, 0.6895125924069665, 0.6987846134569603, 0.7169527628116777, 0.7198346071920811, 0.7281042475880215, 0.7367497807292319, 0.7411351960907154, 0.7418869815812554, 0.7381280541285553, 0.7482771582508457, 0.7590527502819195, 0.7594286430271896, 0.7589274527001629, 0.7609322140082696, 0.7585515599548929, 0.7643152487156998, 0.7727101866933969, 0.7737125673474502, 0.7750908407467736, 0.7722089963663701, 0.776469114146097, 0.7748402455832603, 0.7754667334920436, 0.7753414359102869, 0.776845006891367, 0.7767197093096103, 0.779100363362987, 0.776469114146097, 0.7793509585265005, 0.7807292319258239, 0.7794762561082571, 0.7794762561082571, 0.7804786367623104, 0.7804786367623104, 0.7798521488535272, 0.7814810174163639], 'best_val_acc': 0.7814810174163639, 'model_size_bytes': 40174, 'config_used': {'epochs': 43, 'batch_size': 64, 'lr': 0.00016455991294015744, 'weight_decay': 1.9511804152780558e-06, 'stem_channels': 19, 'nhead': 1, 'd_model': 11, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.03488772682820769, 'use_focal_loss': False, 'focal_gamma': 2.3173509317696483, 'label_smoothing': 0.00423953777332461, 'grad_clip_norm': 0.8107173828506681, 'sched_step': 2, 'sched_gamma': 0.7679235479442075, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 43, 'batch_size': 64, 'lr': 0.00016455991294015744, 'weight_decay': 1.9511804152780558e-06, 'stem_channels': 19, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.03488772682820769, 'use_focal_loss': False, 'focal_gamma': 2.3173509317696483, 'label_smoothing': 0.00423953777332461, 'grad_clip_norm': 0.8107173828506681, 'sched_step': 2, 'sched_gamma': 0.7679235479442075, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 7008, 'model_storage_size_kb': 30.1125, 'model_size_validation': 'PASS'}
2025-10-02 22:52:52,144 - INFO - _models.training_function_executor - BO Objective: base=0.7815, size_penalty=0.0000, final=0.7815
2025-10-02 22:52:52,144 - INFO - _models.training_function_executor - Model: 7,008 parameters, 30.1KB (PASS 256KB limit)
2025-10-02 22:52:52,144 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 157.536s
2025-10-02 22:52:52,246 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7815
2025-10-02 22:52:52,246 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-02 22:52:52,246 - INFO - bo.run_bo - Recorded observation #38: hparams={'epochs': np.int64(43), 'batch_size': np.int64(64), 'lr': 0.00016455991294015744, 'weight_decay': 1.9511804152780558e-06, 'stem_channels': np.int64(19), 'nhead': np.int64(1), 'd_model_factor': np.int64(11), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.03488772682820769, 'use_focal_loss': np.False_, 'focal_gamma': 2.3173509317696483, 'label_smoothing': 0.00423953777332461, 'grad_clip_norm': 0.8107173828506681, 'sched_step': np.int64(2), 'sched_gamma': 0.7679235479442075, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7815
2025-10-02 22:52:52,246 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 38: {'epochs': np.int64(43), 'batch_size': np.int64(64), 'lr': 0.00016455991294015744, 'weight_decay': 1.9511804152780558e-06, 'stem_channels': np.int64(19), 'nhead': np.int64(1), 'd_model_factor': np.int64(11), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.03488772682820769, 'use_focal_loss': np.False_, 'focal_gamma': 2.3173509317696483, 'label_smoothing': 0.00423953777332461, 'grad_clip_norm': 0.8107173828506681, 'sched_step': np.int64(2), 'sched_gamma': 0.7679235479442075, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7815
2025-10-02 22:52:52,246 - INFO - bo.run_bo - üîçBO Trial 39: Using RF surrogate + Expected Improvement
2025-10-02 22:52:52,246 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:52:52,246 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:52:52,247 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:52:52,247 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 38, 'batch_size': 32, 'lr': 0.004563536211528441, 'weight_decay': 1.756136093164075e-07, 'stem_channels': 23, 'nhead': 1, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.2860913930664473, 'use_focal_loss': False, 'focal_gamma': 1.4373346639055673, 'label_smoothing': 0.059366563649005645, 'grad_clip_norm': 0.6780110339900385, 'sched_step': 5, 'sched_gamma': 0.8694390709943643, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:52:52,248 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 38, 'batch_size': 32, 'lr': 0.004563536211528441, 'weight_decay': 1.756136093164075e-07, 'stem_channels': 23, 'nhead': 1, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.2860913930664473, 'use_focal_loss': False, 'focal_gamma': 1.4373346639055673, 'label_smoothing': 0.059366563649005645, 'grad_clip_norm': 0.6780110339900385, 'sched_step': 5, 'sched_gamma': 0.8694390709943643, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:55:03,224 - INFO - _models.training_function_executor - Model: 10,416 parameters, 22.4KB storage
2025-10-02 22:55:03,224 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5273797517655858, 1.26868081491095, 1.2060010541341653, 1.1709075786414438, 1.1350719106491245, 1.1216547776220047, 1.1187009573415965, 1.095893506639991, 1.0797693825240826, 1.0874768286104157, 1.067436992380847, 1.0590813763681683, 1.041017789636508, 1.0398344872003285, 1.0354192929377224, 1.0322153200740387, 1.02720244608289, 1.0177640976383173, 1.0130036607577464, 1.0033611074536717, 1.0040162816231544, 0.9939290546360415, 0.9969897554493061, 1.0023457985251738, 0.995300747146322, 0.9880579463936603, 0.9869805932422144, 0.9881687806714123, 0.981476518977343, 0.9789583739849596, 0.9728852919392824, 0.9718219569440183, 0.9641554051576594, 0.9620418969138136, 0.9685410546256804, 0.9550477753559965, 0.9543367180725546, 0.956263352078244], 'val_losses': [1.3089969161010568, 1.2634782381127045, 1.2505046936253112, 1.2166867006722735, 1.20722565814048, 1.1739832030966562, 1.1602830663538117, 1.1634224462204448, 1.1543397265349307, 1.1451493903309342, 1.1366888401935817, 1.1298181883091767, 1.1607336190063215, 1.1403438297523143, 1.133562739907224, 1.1099125423342973, 1.1771837824822786, 1.1125735575626137, 1.1346417580790842, 1.1062259047928498, 1.1324863155419, 1.1614764787965275, 1.1228841240432026, 1.113966560889539, 1.1159154918913465, 1.1049959226264614, 1.1297438397112982, 1.1146875465294126, 1.1039933682145249, 1.1143123187332908, 1.1295940694975055, 1.1185842352005462, 1.1145730717500908, 1.129978225100027, 1.0988078166362771, 1.144172020610331, 1.1520578868107425, 1.1281015814702442], 'val_acc': [0.7948878586643278, 0.831850645282546, 0.8422503445683498, 0.913294073424383, 0.9099110387169528, 0.8638015286304974, 0.92544793885478, 0.9393559704297707, 0.9248214509459968, 0.9427390051372009, 0.9298333542162637, 0.9084074677358727, 0.9538904899135446, 0.9511339431148979, 0.9492544793885478, 0.9535145971682747, 0.929708056634507, 0.955268763312868, 0.9418619220649042, 0.9452449567723343, 0.9581506076932715, 0.9485026938980078, 0.9239443678737, 0.9573988222027315, 0.951885728605438, 0.9637889988723217, 0.9570229294574615, 0.962160130309485, 0.9616589399824583, 0.9492544793885478, 0.9624107254729983, 0.9627866182182684, 0.9627866182182684, 0.9471244204986844, 0.9548928705675981, 0.9481268011527377, 0.9560205488034081, 0.9563964415486781], 'best_val_acc': 0.9637889988723217, 'model_size_bytes': 33390, 'config_used': {'epochs': 38, 'batch_size': 32, 'lr': 0.004563536211528441, 'weight_decay': 1.756136093164075e-07, 'stem_channels': 23, 'nhead': 1, 'd_model': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.2860913930664473, 'use_focal_loss': False, 'focal_gamma': 1.4373346639055673, 'label_smoothing': 0.059366563649005645, 'grad_clip_norm': 0.6780110339900385, 'sched_step': 5, 'sched_gamma': 0.8694390709943643, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 38, 'batch_size': 32, 'lr': 0.004563536211528441, 'weight_decay': 1.756136093164075e-07, 'stem_channels': 23, 'nhead': 1, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.2860913930664473, 'use_focal_loss': False, 'focal_gamma': 1.4373346639055673, 'label_smoothing': 0.059366563649005645, 'grad_clip_norm': 0.6780110339900385, 'sched_step': 5, 'sched_gamma': 0.8694390709943643, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 10416, 'model_storage_size_kb': 22.378125, 'model_size_validation': 'PASS'}
2025-10-02 22:55:03,225 - INFO - _models.training_function_executor - BO Objective: base=0.9564, size_penalty=0.0000, final=0.9564
2025-10-02 22:55:03,225 - INFO - _models.training_function_executor - Model: 10,416 parameters, 22.4KB (PASS 256KB limit)
2025-10-02 22:55:03,225 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 130.978s
2025-10-02 22:55:03,328 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9564
2025-10-02 22:55:03,328 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-02 22:55:03,329 - INFO - bo.run_bo - Recorded observation #39: hparams={'epochs': np.int64(38), 'batch_size': np.int64(32), 'lr': 0.004563536211528441, 'weight_decay': 1.756136093164075e-07, 'stem_channels': np.int64(23), 'nhead': np.int64(1), 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.2860913930664473, 'use_focal_loss': np.False_, 'focal_gamma': 1.4373346639055673, 'label_smoothing': 0.059366563649005645, 'grad_clip_norm': 0.6780110339900385, 'sched_step': np.int64(5), 'sched_gamma': 0.8694390709943643, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.9564
2025-10-02 22:55:03,329 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 39: {'epochs': np.int64(38), 'batch_size': np.int64(32), 'lr': 0.004563536211528441, 'weight_decay': 1.756136093164075e-07, 'stem_channels': np.int64(23), 'nhead': np.int64(1), 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.2860913930664473, 'use_focal_loss': np.False_, 'focal_gamma': 1.4373346639055673, 'label_smoothing': 0.059366563649005645, 'grad_clip_norm': 0.6780110339900385, 'sched_step': np.int64(5), 'sched_gamma': 0.8694390709943643, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.9564
2025-10-02 22:55:03,329 - INFO - bo.run_bo - üîçBO Trial 40: Using RF surrogate + Expected Improvement
2025-10-02 22:55:03,329 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:55:03,329 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:55:03,329 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:55:03,329 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 42, 'batch_size': 128, 'lr': 0.0009051937645182962, 'weight_decay': 9.018178403763028e-07, 'stem_channels': 14, 'nhead': 2, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.19679538957386677, 'use_focal_loss': False, 'focal_gamma': 2.283424411498596, 'label_smoothing': 0.08507187879721506, 'grad_clip_norm': 0.013391941281464485, 'sched_step': 9, 'sched_gamma': 0.8605921437505849, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:55:03,330 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 42, 'batch_size': 128, 'lr': 0.0009051937645182962, 'weight_decay': 9.018178403763028e-07, 'stem_channels': 14, 'nhead': 2, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.19679538957386677, 'use_focal_loss': False, 'focal_gamma': 2.283424411498596, 'label_smoothing': 0.08507187879721506, 'grad_clip_norm': 0.013391941281464485, 'sched_step': 9, 'sched_gamma': 0.8605921437505849, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 22:57:04,170 - INFO - _models.training_function_executor - Model: 11,166 parameters, 48.0KB storage
2025-10-02 22:57:04,170 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.8843602761698595, 1.57893480666952, 1.391177278938021, 1.3354210609877815, 1.2941716850369667, 1.2750531475044256, 1.264719318687081, 1.244515519331404, 1.2321914489924324, 1.2187297515611026, 1.203583629676596, 1.1976381192712062, 1.1892076804069327, 1.1934443655174762, 1.177598954135828, 1.1714082254344904, 1.1659604006011066, 1.1680808973070398, 1.1596421854420496, 1.1531992986477606, 1.1532499743587887, 1.1510363944143003, 1.1487420930512302, 1.1420707491724815, 1.1418280130403888, 1.1413262834342968, 1.1321802595087942, 1.137435630864302, 1.129911112183374, 1.1261289845850408, 1.1263395033582344, 1.1271110083440474, 1.1265110127688298, 1.124753880219976, 1.1159992992693113, 1.1185676164653664, 1.1153574330788882, 1.1090405706164645, 1.1149677831016864, 1.1116417566121148, 1.104924405841859, 1.1095014671759098], 'val_losses': [1.6974519270432202, 1.4495216152480097, 1.3924891691789818, 1.3311354214050852, 1.3130202093842542, 1.2969616558778527, 1.2785138470862776, 1.2864805474763465, 1.2726857680274257, 1.2709161463035943, 1.2765666440739816, 1.2484509410184212, 1.2692930670015168, 1.259451015672802, 1.2576845457284704, 1.2864042355473246, 1.2867294539337004, 1.269612080022336, 1.2651675307292147, 1.3002679501391192, 1.2763905247087364, 1.2631232128183938, 1.265798333861926, 1.2878310712353804, 1.2568949342237024, 1.270154941382227, 1.2835065473397114, 1.2965597280687056, 1.2779355650332889, 1.319553344026572, 1.2880407011519397, 1.3015319862068184, 1.271387513620993, 1.2889293527232721, 1.3116840049447072, 1.2730851607758245, 1.2982961652332972, 1.277447120212191, 1.2887549569412307, 1.3130868173246022, 1.275215114287723, 1.2885109669073918], 'val_acc': [0.18656809923568476, 0.4211251722841749, 0.5244956772334294, 0.7395063275278787, 0.8180679112893121, 0.7579250720461095, 0.7679488785866433, 0.8478887357474001, 0.84563337927578, 0.6274902894374138, 0.8300964791379526, 0.8274652299210625, 0.869314622227791, 0.8587896253602305, 0.8462598671845634, 0.9030196717203358, 0.8827214634757549, 0.8907405087081819, 0.9072797895000626, 0.928956271143967, 0.878085452950758, 0.9183059766946498, 0.8934970555068287, 0.8789625360230547, 0.8698158125548177, 0.9076556822453327, 0.9255732364365368, 0.9265756170905901, 0.9401077559203107, 0.945746147099361, 0.92281668963789, 0.9376018042851773, 0.9453702543540909, 0.9344693647412605, 0.92469615336424, 0.9363488284676106, 0.9437413857912542, 0.9378523994486906, 0.9488785866432777, 0.9452449567723343, 0.931587520360857, 0.952637514095978], 'best_val_acc': 0.952637514095978, 'model_size_bytes': 57838, 'config_used': {'epochs': 42, 'batch_size': 128, 'lr': 0.0009051937645182962, 'weight_decay': 9.018178403763028e-07, 'stem_channels': 14, 'nhead': 2, 'd_model': 16, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.19679538957386677, 'use_focal_loss': False, 'focal_gamma': 2.283424411498596, 'label_smoothing': 0.08507187879721506, 'grad_clip_norm': 0.013391941281464485, 'sched_step': 9, 'sched_gamma': 0.8605921437505849, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 42, 'batch_size': 128, 'lr': 0.0009051937645182962, 'weight_decay': 9.018178403763028e-07, 'stem_channels': 14, 'nhead': 2, 'd_model_factor': 8, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.19679538957386677, 'use_focal_loss': False, 'focal_gamma': 2.283424411498596, 'label_smoothing': 0.08507187879721506, 'grad_clip_norm': 0.013391941281464485, 'sched_step': 9, 'sched_gamma': 0.8605921437505849, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 11166, 'model_storage_size_kb': 47.97890625, 'model_size_validation': 'PASS'}
2025-10-02 22:57:04,170 - INFO - _models.training_function_executor - BO Objective: base=0.9526, size_penalty=0.0000, final=0.9526
2025-10-02 22:57:04,170 - INFO - _models.training_function_executor - Model: 11,166 parameters, 48.0KB (PASS 256KB limit)
2025-10-02 22:57:04,170 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 120.841s
2025-10-02 22:57:04,278 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9526
2025-10-02 22:57:04,278 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-02 22:57:04,278 - INFO - bo.run_bo - Recorded observation #40: hparams={'epochs': np.int64(42), 'batch_size': np.int64(128), 'lr': 0.0009051937645182962, 'weight_decay': 9.018178403763028e-07, 'stem_channels': np.int64(14), 'nhead': np.int64(2), 'd_model_factor': np.int64(8), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.19679538957386677, 'use_focal_loss': np.False_, 'focal_gamma': 2.283424411498596, 'label_smoothing': 0.08507187879721506, 'grad_clip_norm': 0.013391941281464485, 'sched_step': np.int64(9), 'sched_gamma': 0.8605921437505849, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.9526
2025-10-02 22:57:04,278 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 40: {'epochs': np.int64(42), 'batch_size': np.int64(128), 'lr': 0.0009051937645182962, 'weight_decay': 9.018178403763028e-07, 'stem_channels': np.int64(14), 'nhead': np.int64(2), 'd_model_factor': np.int64(8), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.19679538957386677, 'use_focal_loss': np.False_, 'focal_gamma': 2.283424411498596, 'label_smoothing': 0.08507187879721506, 'grad_clip_norm': 0.013391941281464485, 'sched_step': np.int64(9), 'sched_gamma': 0.8605921437505849, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.9526
2025-10-02 22:57:04,279 - INFO - bo.run_bo - üîçBO Trial 41: Using RF surrogate + Expected Improvement
2025-10-02 22:57:04,279 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:57:04,279 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:57:04,279 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:57:04,279 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 37, 'batch_size': 32, 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27589837466691197, 'use_focal_loss': False, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': 9, 'sched_gamma': 0.9802751497189455, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:57:04,280 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 37, 'batch_size': 32, 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27589837466691197, 'use_focal_loss': False, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': 9, 'sched_gamma': 0.9802751497189455, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:59:36,462 - INFO - _models.training_function_executor - Model: 8,647 parameters, 18.6KB storage
2025-10-02 22:59:36,462 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1566390495933925, 0.8624164915673361, 0.7898499077768943, 0.7459446721606784, 0.7099231309140606, 0.6831568644154181, 0.6597506670830404, 0.6355192952064129, 0.61604204215722, 0.619643264555772, 0.599110079348261, 0.5941331960318983, 0.5876108235235976, 0.5796649828200777, 0.5733119546928318, 0.5720496787088495, 0.5628795876664461, 0.5549175978067267, 0.5507391609875356, 0.5506945113186041, 0.5406567563210888, 0.543929936478947, 0.5369589264335606, 0.5355584515833457, 0.5351652200117157, 0.5244108742555237, 0.5335626170005102, 0.5185816061342509, 0.5159486666794607, 0.509288689296123, 0.5160875279730963, 0.5155403149378903, 0.5143283103912937, 0.5061391933674659, 0.5107458639002248, 0.5039465283946473, 0.5004346026695525], 'val_losses': [0.8938268446082863, 0.8805827416060428, 0.7977715911325723, 0.8013033539097854, 0.7585938239423213, 0.7795128400964167, 0.7372421282841259, 0.7040151700446546, 0.6877580035705193, 0.6529296937255897, 0.6476890304575228, 0.6683189188413879, 0.6246939237786032, 0.658228659193672, 0.6360358004730725, 0.6429393409771543, 0.7584254607985812, 0.6855998505567372, 0.7069612674404843, 0.6991008837679218, 0.7021048463476793, 0.6666769905954267, 0.7270488646555897, 0.7918196354215866, 0.6742932396176434, 0.6809167245204788, 0.654030533754621, 0.6596910779808656, 0.7658928824074509, 0.7385506551675877, 0.7201034723106684, 0.8285321642948921, 0.6453711694679887, 0.6513893904355575, 0.8003708039768775, 0.7678828473498, 0.7147972391685616], 'val_acc': [0.7927577997744644, 0.8671845633379276, 0.9101616338804661, 0.8942488409973688, 0.8957524119784488, 0.9383535897757174, 0.9100363362987094, 0.9251973436912667, 0.9367247212128806, 0.9328404961784238, 0.9483773963162511, 0.9475003132439543, 0.9452449567723343, 0.9353464478135572, 0.9516351334419245, 0.953765192331788, 0.9631625109635384, 0.947249718080441, 0.9590276907655683, 0.962536023054755, 0.9560205488034081, 0.9611577496554317, 0.9671720335797519, 0.961408344818945, 0.9645407843628618, 0.9674226287432652, 0.9591529883473249, 0.9513845382784112, 0.9657937601804285, 0.9604059641648917, 0.9624107254729983, 0.9685503069790753, 0.9558952512216514, 0.9677985214885353, 0.9689261997243453, 0.9627866182182684, 0.968675604560832], 'best_val_acc': 0.9689261997243453, 'model_size_bytes': 29742, 'config_used': {'epochs': 37, 'batch_size': 32, 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': 24, 'nhead': 1, 'd_model': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27589837466691197, 'use_focal_loss': False, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': 9, 'sched_gamma': 0.9802751497189455, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 37, 'batch_size': 32, 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27589837466691197, 'use_focal_loss': False, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': 9, 'sched_gamma': 0.9802751497189455, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 8647, 'model_storage_size_kb': 18.5775390625, 'model_size_validation': 'PASS'}
2025-10-02 22:59:36,462 - INFO - _models.training_function_executor - BO Objective: base=0.9687, size_penalty=0.0000, final=0.9687
2025-10-02 22:59:36,462 - INFO - _models.training_function_executor - Model: 8,647 parameters, 18.6KB (PASS 256KB limit)
2025-10-02 22:59:36,462 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 152.183s
2025-10-02 22:59:36,566 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9687
2025-10-02 22:59:36,566 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-02 22:59:36,566 - INFO - bo.run_bo - Recorded observation #41: hparams={'epochs': np.int64(37), 'batch_size': np.int64(32), 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.27589837466691197, 'use_focal_loss': np.False_, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': np.int64(9), 'sched_gamma': 0.9802751497189455, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.9687
2025-10-02 22:59:36,566 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 41: {'epochs': np.int64(37), 'batch_size': np.int64(32), 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.27589837466691197, 'use_focal_loss': np.False_, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': np.int64(9), 'sched_gamma': 0.9802751497189455, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.9687
2025-10-02 22:59:36,566 - INFO - bo.run_bo - üîçBO Trial 42: Using RF surrogate + Expected Improvement
2025-10-02 22:59:36,566 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 22:59:36,566 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 22:59:36,566 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 22:59:36,566 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 40, 'batch_size': 32, 'lr': 0.0002113097969858739, 'weight_decay': 7.542408683134899e-07, 'stem_channels': 21, 'nhead': 4, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.12841395612384712, 'use_focal_loss': False, 'focal_gamma': 1.3689669670698301, 'label_smoothing': 0.08427801942956653, 'grad_clip_norm': 0.33838432788143763, 'sched_step': 10, 'sched_gamma': 0.8450149267142564, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 22:59:36,568 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 40, 'batch_size': 32, 'lr': 0.0002113097969858739, 'weight_decay': 7.542408683134899e-07, 'stem_channels': 21, 'nhead': 4, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.12841395612384712, 'use_focal_loss': False, 'focal_gamma': 1.3689669670698301, 'label_smoothing': 0.08427801942956653, 'grad_clip_norm': 0.33838432788143763, 'sched_step': 10, 'sched_gamma': 0.8450149267142564, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 23:02:42,098 - INFO - _models.training_function_executor - Model: 56,766 parameters, 122.0KB storage
2025-10-02 23:02:42,098 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7494176975771012, 1.4671924477647025, 1.4039560607907409, 1.3716841219653275, 1.353964235263335, 1.332320198955846, 1.3142861277037716, 1.302904441572276, 1.3058323413773116, 1.2797551940035126, 1.2634058339223189, 1.2622006140238315, 1.2518241439581, 1.2429897479723, 1.2417185457861932, 1.2377872535116865, 1.2304684482331645, 1.2292677140514479, 1.229057708031678, 1.2181158264048606, 1.2166036806548557, 1.2039059199019602, 1.2195161174264755, 1.2079645934022916, 1.199653320760165, 1.1947338403669756, 1.2004423586754551, 1.193509518299187, 1.1902269521900926, 1.1881713539878218, 1.1896254771731833, 1.1850870669465037, 1.176654380875281, 1.1840415780482965, 1.1836424689243168, 1.1802941361073507, 1.1756639470732333, 1.1688235001960905, 1.180172175186729, 1.1674926662562324], 'val_losses': [1.5096426057032872, 1.430131301203552, 1.4008075948676255, 1.3868945650761026, 1.3770541058583243, 1.3740169953588943, 1.356699895954359, 1.3876301930103367, 1.3327856341066733, 1.3505368964771567, 1.3306975890305268, 1.338623542382953, 1.3450617624574879, 1.3502421977600347, 1.3535774224773265, 1.3530038319917388, 1.3482387568057144, 1.34203671745871, 1.3468776852426456, 1.358689860702532, 1.3504004404368877, 1.341860218777601, 1.350028760808704, 1.3526074455549448, 1.3511196386991864, 1.399464244726621, 1.3558252002941666, 1.3582633947642013, 1.3545792198706923, 1.3905742384410267, 1.3563684995065968, 1.349326160479542, 1.3504284523047536, 1.3831583576802249, 1.3533798392711316, 1.368632654904154, 1.369916844914662, 1.3521479616307357, 1.362339839049859, 1.3640547062337676], 'val_acc': [0.5990477383786493, 0.7167021676481644, 0.7164515724846511, 0.8024057135697281, 0.8183185064528254, 0.8497681994737502, 0.84751284300213, 0.9027690765568225, 0.8059140458589149, 0.8856033078561584, 0.8247086831224157, 0.9070291943365493, 0.9427390051372009, 0.9355970429770706, 0.9364741260493672, 0.92319258238316, 0.9454955519358477, 0.9342187695777472, 0.9522616213507079, 0.930459842125047, 0.9522616213507079, 0.9439919809547676, 0.9423631123919308, 0.9571482270392181, 0.9543916802405713, 0.9548928705675981, 0.9536398947500313, 0.9561458463851648, 0.9521363237689513, 0.9587770956020549, 0.9577747149480015, 0.9551434657311114, 0.9520110261871946, 0.9594035835108382, 0.9560205488034081, 0.9536398947500313, 0.9576494173662449, 0.9553940608946248, 0.9563964415486781, 0.9567723342939481], 'best_val_acc': 0.9594035835108382, 'model_size_bytes': 122066, 'config_used': {'epochs': 40, 'batch_size': 32, 'lr': 0.0002113097969858739, 'weight_decay': 7.542408683134899e-07, 'stem_channels': 21, 'nhead': 4, 'd_model': 56, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.12841395612384712, 'use_focal_loss': False, 'focal_gamma': 1.3689669670698301, 'label_smoothing': 0.08427801942956653, 'grad_clip_norm': 0.33838432788143763, 'sched_step': 10, 'sched_gamma': 0.8450149267142564, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 40, 'batch_size': 32, 'lr': 0.0002113097969858739, 'weight_decay': 7.542408683134899e-07, 'stem_channels': 21, 'nhead': 4, 'd_model_factor': 14, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.12841395612384712, 'use_focal_loss': False, 'focal_gamma': 1.3689669670698301, 'label_smoothing': 0.08427801942956653, 'grad_clip_norm': 0.33838432788143763, 'sched_step': 10, 'sched_gamma': 0.8450149267142564, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 56766, 'model_storage_size_kb': 121.95820312500001, 'model_size_validation': 'PASS'}
2025-10-02 23:02:42,098 - INFO - _models.training_function_executor - BO Objective: base=0.9568, size_penalty=0.0000, final=0.9568
2025-10-02 23:02:42,098 - INFO - _models.training_function_executor - Model: 56,766 parameters, 122.0KB (PASS 256KB limit)
2025-10-02 23:02:42,098 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 185.532s
2025-10-02 23:02:42,204 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9568
2025-10-02 23:02:42,204 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.106s
2025-10-02 23:02:42,204 - INFO - bo.run_bo - Recorded observation #42: hparams={'epochs': np.int64(40), 'batch_size': np.int64(32), 'lr': 0.0002113097969858739, 'weight_decay': 7.542408683134899e-07, 'stem_channels': np.int64(21), 'nhead': np.int64(4), 'd_model_factor': np.int64(14), 'num_layers': np.int64(1), 'ff_factor': np.int64(4), 'dropout': 0.12841395612384712, 'use_focal_loss': np.False_, 'focal_gamma': 1.3689669670698301, 'label_smoothing': 0.08427801942956653, 'grad_clip_norm': 0.33838432788143763, 'sched_step': np.int64(10), 'sched_gamma': 0.8450149267142564, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.9568
2025-10-02 23:02:42,204 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 42: {'epochs': np.int64(40), 'batch_size': np.int64(32), 'lr': 0.0002113097969858739, 'weight_decay': 7.542408683134899e-07, 'stem_channels': np.int64(21), 'nhead': np.int64(4), 'd_model_factor': np.int64(14), 'num_layers': np.int64(1), 'ff_factor': np.int64(4), 'dropout': 0.12841395612384712, 'use_focal_loss': np.False_, 'focal_gamma': 1.3689669670698301, 'label_smoothing': 0.08427801942956653, 'grad_clip_norm': 0.33838432788143763, 'sched_step': np.int64(10), 'sched_gamma': 0.8450149267142564, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.9568
2025-10-02 23:02:42,205 - INFO - bo.run_bo - üîçBO Trial 43: Using RF surrogate + Expected Improvement
2025-10-02 23:02:42,205 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 23:02:42,205 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:02:42,205 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:02:42,205 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 47, 'batch_size': 128, 'lr': 9.098858454728993e-05, 'weight_decay': 4.61310672546087e-07, 'stem_channels': 20, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.20365158044245385, 'use_focal_loss': False, 'focal_gamma': 1.259684540439996, 'label_smoothing': 0.0435110924912292, 'grad_clip_norm': 0.6630482294459173, 'sched_step': 9, 'sched_gamma': 0.8794517763693284, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 23:02:42,206 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 47, 'batch_size': 128, 'lr': 9.098858454728993e-05, 'weight_decay': 4.61310672546087e-07, 'stem_channels': 20, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.20365158044245385, 'use_focal_loss': False, 'focal_gamma': 1.259684540439996, 'label_smoothing': 0.0435110924912292, 'grad_clip_norm': 0.6630482294459173, 'sched_step': 9, 'sched_gamma': 0.8794517763693284, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 23:04:11,751 - INFO - _models.training_function_executor - Model: 7,203 parameters, 15.5KB storage
2025-10-02 23:04:11,751 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.8763361359189277, 1.8315440000076324, 1.7577317923422249, 1.695512086792525, 1.6369701397171392, 1.5751025412228532, 1.5130602488245757, 1.4639819459322456, 1.4235714007315696, 1.3944265483947258, 1.3650063535076213, 1.342089458048592, 1.3175770541508276, 1.2964255220589884, 1.2745295347913639, 1.2516592676764355, 1.2248839311976445, 1.1976129904511212, 1.1699778877792213, 1.1501735200806675, 1.1273372454500301, 1.102793968280627, 1.084966948604993, 1.0646065489053764, 1.0487546978807014, 1.0353381635625682, 1.0224978795936002, 1.013150123263333, 1.0020386929224185, 0.9953985368048223, 0.9872713879218052, 0.9815268578977621, 0.9754808504390331, 0.9720059771311185, 0.9686806917347391, 0.9589227951921414, 0.9503755178348622, 0.9517250480170283, 0.9495484858823182, 0.9455523836195583, 0.9413695123206627, 0.937237291162341, 0.9313770849311971, 0.9335577867049246, 0.9284598426524886, 0.9228487435810115, 0.9219141614185786], 'val_losses': [1.8513993885773732, 1.7924097725030936, 1.7119805295430632, 1.6525037487472394, 1.587599884760199, 1.517576378548807, 1.4624495882540474, 1.4168197599333818, 1.383199300044253, 1.355951172817681, 1.3310612587085748, 1.3067532266505215, 1.2844846894934936, 1.2614468114296307, 1.2362587572025365, 1.2104193717670715, 1.183889747965442, 1.1617165210775497, 1.1406348853791781, 1.1155901941167519, 1.094573353887605, 1.0807212510662798, 1.0612337186572218, 1.0446931323286974, 1.0337164063842623, 1.021821248951061, 1.016900163592439, 1.0064788360133265, 1.0040644085985304, 0.998872675194864, 0.9934042204503293, 0.9892645655322413, 0.9895723069196595, 0.9850623596283655, 0.9811901358222173, 0.9769331935114944, 0.9736857276529824, 0.9766792192627591, 0.9758123577485003, 0.9671875222735111, 0.9715692074492138, 0.9645687187095884, 0.9629864196044852, 0.9686152877372662, 0.9574508929876976, 0.9532627967078798, 0.9553074942631704], 'val_acc': [0.26575617090590153, 0.28267134444305225, 0.30672848014033327, 0.3099862172660068, 0.31111389550181684, 0.3326650795639644, 0.35321388297205863, 0.36486655807542917, 0.4038341060017542, 0.4252599924821451, 0.4503195088334795, 0.5148477634381656, 0.5343941861922065, 0.5756170905901516, 0.637012905650921, 0.6402706427765944, 0.7098108006515474, 0.6842500939731864, 0.7068036586893873, 0.7342438290940985, 0.7485277534143591, 0.7245959152988347, 0.7574238817190828, 0.7481518606690891, 0.7529131687758426, 0.7620598922440797, 0.7646911414609698, 0.7641899511339432, 0.7490289437413858, 0.7799774464352838, 0.763438165643403, 0.7784738754542038, 0.7616839994988097, 0.7804786367623104, 0.8005262498433781, 0.7980202982082446, 0.7887482771582508, 0.7767197093096103, 0.7679488785866433, 0.7910036336298709, 0.792131311865681, 0.7967673223906778, 0.8101741636386418, 0.7902518481393309, 0.8097982708933718, 0.8002756546798647, 0.8110512467109385], 'best_val_acc': 0.8110512467109385, 'model_size_bytes': 23058, 'config_used': {'epochs': 47, 'batch_size': 128, 'lr': 9.098858454728993e-05, 'weight_decay': 4.61310672546087e-07, 'stem_channels': 20, 'nhead': 1, 'd_model': 11, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.20365158044245385, 'use_focal_loss': False, 'focal_gamma': 1.259684540439996, 'label_smoothing': 0.0435110924912292, 'grad_clip_norm': 0.6630482294459173, 'sched_step': 9, 'sched_gamma': 0.8794517763693284, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 47, 'batch_size': 128, 'lr': 9.098858454728993e-05, 'weight_decay': 4.61310672546087e-07, 'stem_channels': 20, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 1, 'ff_factor': 4, 'dropout': 0.20365158044245385, 'use_focal_loss': False, 'focal_gamma': 1.259684540439996, 'label_smoothing': 0.0435110924912292, 'grad_clip_norm': 0.6630482294459173, 'sched_step': 9, 'sched_gamma': 0.8794517763693284, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 7203, 'model_storage_size_kb': 15.475195312500002, 'model_size_validation': 'PASS'}
2025-10-02 23:04:11,751 - INFO - _models.training_function_executor - BO Objective: base=0.8111, size_penalty=0.0000, final=0.8111
2025-10-02 23:04:11,751 - INFO - _models.training_function_executor - Model: 7,203 parameters, 15.5KB (PASS 256KB limit)
2025-10-02 23:04:11,752 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 89.547s
2025-10-02 23:04:11,858 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8111
2025-10-02 23:04:11,858 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.106s
2025-10-02 23:04:11,858 - INFO - bo.run_bo - Recorded observation #43: hparams={'epochs': np.int64(47), 'batch_size': np.int64(128), 'lr': 9.098858454728993e-05, 'weight_decay': 4.61310672546087e-07, 'stem_channels': np.int64(20), 'nhead': np.int64(1), 'd_model_factor': np.int64(11), 'num_layers': np.int64(1), 'ff_factor': np.int64(4), 'dropout': 0.20365158044245385, 'use_focal_loss': np.False_, 'focal_gamma': 1.259684540439996, 'label_smoothing': 0.0435110924912292, 'grad_clip_norm': 0.6630482294459173, 'sched_step': np.int64(9), 'sched_gamma': 0.8794517763693284, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.8111
2025-10-02 23:04:11,858 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 43: {'epochs': np.int64(47), 'batch_size': np.int64(128), 'lr': 9.098858454728993e-05, 'weight_decay': 4.61310672546087e-07, 'stem_channels': np.int64(20), 'nhead': np.int64(1), 'd_model_factor': np.int64(11), 'num_layers': np.int64(1), 'ff_factor': np.int64(4), 'dropout': 0.20365158044245385, 'use_focal_loss': np.False_, 'focal_gamma': 1.259684540439996, 'label_smoothing': 0.0435110924912292, 'grad_clip_norm': 0.6630482294459173, 'sched_step': np.int64(9), 'sched_gamma': 0.8794517763693284, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.8111
2025-10-02 23:04:11,858 - INFO - bo.run_bo - üîçBO Trial 44: Using RF surrogate + Expected Improvement
2025-10-02 23:04:11,858 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 23:04:11,858 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:04:11,858 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:04:11,858 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 43, 'batch_size': 32, 'lr': 9.46218456816936e-05, 'weight_decay': 1.18522529007351e-06, 'stem_channels': 17, 'nhead': 4, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27100062480589715, 'use_focal_loss': False, 'focal_gamma': 1.7635672493102397, 'label_smoothing': 0.06531485952017028, 'grad_clip_norm': 0.29430779346927377, 'sched_step': 8, 'sched_gamma': 0.9311749026043176, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 23:04:11,860 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 43, 'batch_size': 32, 'lr': 9.46218456816936e-05, 'weight_decay': 1.18522529007351e-06, 'stem_channels': 17, 'nhead': 4, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27100062480589715, 'use_focal_loss': False, 'focal_gamma': 1.7635672493102397, 'label_smoothing': 0.06531485952017028, 'grad_clip_norm': 0.29430779346927377, 'sched_step': 8, 'sched_gamma': 0.9311749026043176, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 23:08:58,891 - INFO - _models.training_function_executor - Model: 62,311 parameters, 267.7KB storage
2025-10-02 23:08:58,891 - WARNING - _models.training_function_executor - Model storage 267.7KB exceeds 256KB limit!
2025-10-02 23:08:58,891 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.7828977302706854, 1.4489334985281006, 1.3027780824065622, 1.2387919304861787, 1.196647312835102, 1.1671319418195771, 1.1476196635356841, 1.137622921715082, 1.1234133293189317, 1.1152193875359557, 1.1139700392491798, 1.09791463285454, 1.0923796978241198, 1.08446120572778, 1.0849382832594556, 1.0816180273819078, 1.0637919200234847, 1.0617447088256395, 1.0542573630389678, 1.054843924341915, 1.0584855099741284, 1.0515960235626773, 1.0379496216456574, 1.0457940467395859, 1.0431782959607132, 1.0375797922825658, 1.0342467318082167, 1.0330513001489068, 1.0303722264992765, 1.02128240821901, 1.0302075418625187, 1.030646610625222, 1.0097026260403341, 1.0210700275731954, 1.0157367705391398, 1.0120292427739759, 1.000725854527206, 1.0086157790021415, 1.0135446639824708, 1.0033772451661827, 1.0073180955719188, 1.0032387932220042, 0.9989989254964055], 'val_losses': [1.5474141140119158, 1.3525794831572164, 1.2743942052286499, 1.24577746605189, 1.230811573198125, 1.2078592527362282, 1.1934661409368252, 1.1832939414747405, 1.1840960303877637, 1.1744078293642504, 1.1708451381170006, 1.1803235777666239, 1.178605311258352, 1.168254073140257, 1.176811139695015, 1.18744238993381, 1.1878487065447525, 1.1843259873179293, 1.1943493940047252, 1.1850532936341869, 1.1585940518574582, 1.2131791880459075, 1.1978785298608805, 1.1868690982556196, 1.1840093394835003, 1.1879346346200939, 1.1993471138340805, 1.1903338470699165, 1.188950491077006, 1.2083760127285164, 1.1824262104839807, 1.2181954925303142, 1.1963423177004309, 1.2090989883315546, 1.1911879056618186, 1.1971198826740743, 1.2075448715362673, 1.2083864297174955, 1.1927819041108865, 1.2075852775107707, 1.2105158456449385, 1.202241522449402, 1.2043516633355547], 'val_acc': [0.5281293071043729, 0.659942363112392, 0.7780979827089337, 0.7905024433028442, 0.8633003383034707, 0.8668086705926575, 0.8622979576494174, 0.8300964791379526, 0.8971306853777722, 0.9101616338804661, 0.9035208620473625, 0.8794637263500814, 0.9200601428392432, 0.9243202606189701, 0.8876080691642652, 0.9255732364365368, 0.9000125297581757, 0.9100363362987094, 0.9313369251973437, 0.9553940608946248, 0.9307104372885603, 0.9580253101115148, 0.9483773963162511, 0.952637514095978, 0.9463726350081444, 0.9387294825209873, 0.939606565593284, 0.9485026938980078, 0.9486279914797644, 0.954141085077058, 0.946497932589901, 0.9558952512216514, 0.9528881092594913, 0.9521363237689513, 0.9508833479513845, 0.9567723342939481, 0.9530134068412479, 0.9525122165142212, 0.954141085077058, 0.9535145971682747, 0.9575241197844881, 0.9575241197844881, 0.9580253101115148], 'best_val_acc': 0.9580253101115148, 'model_size_bytes': 262574, 'config_used': {'epochs': 43, 'batch_size': 32, 'lr': 9.46218456816936e-05, 'weight_decay': 1.18522529007351e-06, 'stem_channels': 17, 'nhead': 4, 'd_model': 48, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27100062480589715, 'use_focal_loss': False, 'focal_gamma': 1.7635672493102397, 'label_smoothing': 0.06531485952017028, 'grad_clip_norm': 0.29430779346927377, 'sched_step': 8, 'sched_gamma': 0.9311749026043176, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 43, 'batch_size': 32, 'lr': 9.46218456816936e-05, 'weight_decay': 1.18522529007351e-06, 'stem_channels': 17, 'nhead': 4, 'd_model_factor': 12, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27100062480589715, 'use_focal_loss': False, 'focal_gamma': 1.7635672493102397, 'label_smoothing': 0.06531485952017028, 'grad_clip_norm': 0.29430779346927377, 'sched_step': 8, 'sched_gamma': 0.9311749026043176, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 62311, 'model_storage_size_kb': 267.742578125, 'model_size_validation': 'FAIL'}
2025-10-02 23:08:58,891 - INFO - _models.training_function_executor - BO Objective: base=0.9580, size_penalty=0.0229, final=0.9351
2025-10-02 23:08:58,891 - INFO - _models.training_function_executor - Model: 62,311 parameters, 267.7KB (FAIL 256KB limit)
2025-10-02 23:08:58,892 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 287.033s
2025-10-02 23:08:58,998 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9351
2025-10-02 23:08:58,998 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-02 23:08:58,998 - INFO - bo.run_bo - Recorded observation #44: hparams={'epochs': np.int64(43), 'batch_size': np.int64(32), 'lr': 9.46218456816936e-05, 'weight_decay': 1.18522529007351e-06, 'stem_channels': np.int64(17), 'nhead': np.int64(4), 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.27100062480589715, 'use_focal_loss': np.False_, 'focal_gamma': 1.7635672493102397, 'label_smoothing': 0.06531485952017028, 'grad_clip_norm': 0.29430779346927377, 'sched_step': np.int64(8), 'sched_gamma': 0.9311749026043176, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.9351
2025-10-02 23:08:58,998 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 44: {'epochs': np.int64(43), 'batch_size': np.int64(32), 'lr': 9.46218456816936e-05, 'weight_decay': 1.18522529007351e-06, 'stem_channels': np.int64(17), 'nhead': np.int64(4), 'd_model_factor': np.int64(12), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.27100062480589715, 'use_focal_loss': np.False_, 'focal_gamma': 1.7635672493102397, 'label_smoothing': 0.06531485952017028, 'grad_clip_norm': 0.29430779346927377, 'sched_step': np.int64(8), 'sched_gamma': 0.9311749026043176, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.9351
2025-10-02 23:08:58,999 - INFO - bo.run_bo - üîçBO Trial 45: Using RF surrogate + Expected Improvement
2025-10-02 23:08:58,999 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-02 23:08:58,999 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:08:58,999 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:08:58,999 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 39, 'batch_size': 64, 'lr': 8.064621582249924e-05, 'weight_decay': 4.7646033231937616e-07, 'stem_channels': 23, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.16061863756219508, 'use_focal_loss': False, 'focal_gamma': 2.4425658248210262, 'label_smoothing': 0.021399503954852354, 'grad_clip_norm': 0.17249925525879065, 'sched_step': 4, 'sched_gamma': 0.8488336145776032, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 23:08:59,000 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 39, 'batch_size': 64, 'lr': 8.064621582249924e-05, 'weight_decay': 4.7646033231937616e-07, 'stem_channels': 23, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.16061863756219508, 'use_focal_loss': False, 'focal_gamma': 2.4425658248210262, 'label_smoothing': 0.021399503954852354, 'grad_clip_norm': 0.17249925525879065, 'sched_step': 4, 'sched_gamma': 0.8488336145776032, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 23:12:20,207 - INFO - _models.training_function_executor - Model: 7,800 parameters, 8.4KB storage
2025-10-02 23:12:20,207 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.6263552249025006, 1.3579675910116098, 1.2013435838059914, 1.0873266017754768, 0.9774500561310183, 0.8995232275284177, 0.8495977081679814, 0.8125592369829074, 0.7897527707839331, 0.7664278101003197, 0.7497678720037676, 0.7357338218933486, 0.717984467626264, 0.7131671525984447, 0.7001211883575662, 0.6915398211876962, 0.6838942744661475, 0.6733846511286057, 0.6697097174809047, 0.6597395412934527, 0.6547334074350436, 0.6502736940873998, 0.6454018515848641, 0.6433427672343898, 0.6361490433438584, 0.6334636911179896, 0.6246993881704679, 0.6232568251213939, 0.6261822009872301, 0.620003401370506, 0.6150701228390697, 0.6181939883447659, 0.6128101793759912, 0.6097877045283882, 0.6070631577571793, 0.6054831195944881, 0.6020533735367176, 0.6021604062627888, 0.6008117203723965], 'val_losses': [1.472765127932304, 1.2596551230222326, 1.1395278750931526, 1.023563898202695, 0.9400617916577144, 0.8763790886558367, 0.8355754822093044, 0.806651038643173, 0.7961192137763966, 0.7974904846120427, 0.7711976925512107, 0.7641979480294592, 0.7512019779983581, 0.7373048504437589, 0.7459733416421448, 0.7366293693989863, 0.7282946484382552, 0.7144025915279347, 0.7141123096486737, 0.7083217158247065, 0.7074654982690748, 0.7102941463591386, 0.6989233231592292, 0.693810576059334, 0.6900777199889406, 0.6964742868948276, 0.6869285752070964, 0.6863099388080856, 0.6806244825363876, 0.6892337973681537, 0.6942124886704543, 0.6807431517022547, 0.681314015729044, 0.6867142457021626, 0.6710595043660584, 0.6715991548645871, 0.694503929796949, 0.6742206332737634, 0.6792354651104462], 'val_acc': [0.42225285051998496, 0.4342814183686255, 0.6244831474752537, 0.7279789500062649, 0.8051622603683749, 0.8134319007643153, 0.8104247588021551, 0.815060769327152, 0.8402455832602431, 0.8590402205237438, 0.8119283297832351, 0.8333542162636262, 0.8357348703170029, 0.8621726600676607, 0.8477634381656434, 0.8562836737250971, 0.8634256358852274, 0.8516476632001002, 0.8742012279163012, 0.8580378398696905, 0.8564089713068538, 0.8562836737250971, 0.8689387294825209, 0.8753289061521112, 0.8740759303345446, 0.8793384287683248, 0.8790878336048115, 0.8759553940608946, 0.8864803909284551, 0.8985089587770956, 0.8917428893622353, 0.8823455707304849, 0.8879839619095351, 0.8950006264879088, 0.8891116401453452, 0.900263124921689, 0.8852274151108883, 0.8921187821075053, 0.9035208620473625], 'best_val_acc': 0.9035208620473625, 'model_size_bytes': 107877, 'config_used': {'epochs': 39, 'batch_size': 64, 'lr': 8.064621582249924e-05, 'weight_decay': 4.7646033231937616e-07, 'stem_channels': 23, 'nhead': 2, 'd_model': 30, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.16061863756219508, 'use_focal_loss': False, 'focal_gamma': 2.4425658248210262, 'label_smoothing': 0.021399503954852354, 'grad_clip_norm': 0.17249925525879065, 'sched_step': 4, 'sched_gamma': 0.8488336145776032, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 39, 'batch_size': 64, 'lr': 8.064621582249924e-05, 'weight_decay': 4.7646033231937616e-07, 'stem_channels': 23, 'nhead': 2, 'd_model_factor': 15, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.16061863756219508, 'use_focal_loss': False, 'focal_gamma': 2.4425658248210262, 'label_smoothing': 0.021399503954852354, 'grad_clip_norm': 0.17249925525879065, 'sched_step': 4, 'sched_gamma': 0.8488336145776032, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 7800, 'model_storage_size_kb': 8.37890625, 'model_size_validation': 'PASS'}
2025-10-02 23:12:20,207 - INFO - _models.training_function_executor - BO Objective: base=0.9035, size_penalty=0.0000, final=0.9035
2025-10-02 23:12:20,207 - INFO - _models.training_function_executor - Model: 7,800 parameters, 8.4KB (PASS 256KB limit)
2025-10-02 23:12:20,207 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 201.208s
2025-10-02 23:12:20,317 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9035
2025-10-02 23:12:20,317 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-02 23:12:20,317 - INFO - bo.run_bo - Recorded observation #45: hparams={'epochs': np.int64(39), 'batch_size': np.int64(64), 'lr': 8.064621582249924e-05, 'weight_decay': 4.7646033231937616e-07, 'stem_channels': np.int64(23), 'nhead': np.int64(2), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.16061863756219508, 'use_focal_loss': np.False_, 'focal_gamma': 2.4425658248210262, 'label_smoothing': 0.021399503954852354, 'grad_clip_norm': 0.17249925525879065, 'sched_step': np.int64(4), 'sched_gamma': 0.8488336145776032, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.9035
2025-10-02 23:12:20,317 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 45: {'epochs': np.int64(39), 'batch_size': np.int64(64), 'lr': 8.064621582249924e-05, 'weight_decay': 4.7646033231937616e-07, 'stem_channels': np.int64(23), 'nhead': np.int64(2), 'd_model_factor': np.int64(15), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.16061863756219508, 'use_focal_loss': np.False_, 'focal_gamma': 2.4425658248210262, 'label_smoothing': 0.021399503954852354, 'grad_clip_norm': 0.17249925525879065, 'sched_step': np.int64(4), 'sched_gamma': 0.8488336145776032, 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.9035
2025-10-02 23:12:20,318 - INFO - bo.run_bo - üîçBO Trial 46: Using RF surrogate + Expected Improvement
2025-10-02 23:12:20,318 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 23:12:20,318 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:12:20,318 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:12:20,318 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 34, 'batch_size': 128, 'lr': 6.190388356323335e-05, 'weight_decay': 7.475474116738931e-07, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 13, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.1922313096751467, 'use_focal_loss': False, 'focal_gamma': 2.401256175491752, 'label_smoothing': 0.09026933859084657, 'grad_clip_norm': 0.45033924942942216, 'sched_step': 10, 'sched_gamma': 0.817195663574285, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 23:12:20,319 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 34, 'batch_size': 128, 'lr': 6.190388356323335e-05, 'weight_decay': 7.475474116738931e-07, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 13, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.1922313096751467, 'use_focal_loss': False, 'focal_gamma': 2.401256175491752, 'label_smoothing': 0.09026933859084657, 'grad_clip_norm': 0.45033924942942216, 'sched_step': 10, 'sched_gamma': 0.817195663574285, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 23:15:44,125 - INFO - _models.training_function_executor - Model: 59,652 parameters, 256.3KB storage
2025-10-02 23:15:44,126 - WARNING - _models.training_function_executor - Model storage 256.3KB exceeds 256KB limit!
2025-10-02 23:15:44,126 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [2.0236690123420353, 1.8452588116820547, 1.7113511923900004, 1.6342691258149156, 1.5786899380399646, 1.5433179093113751, 1.5143955341874815, 1.48673796710882, 1.4762812533093452, 1.4518916053819473, 1.4330169728789395, 1.4190239396208948, 1.405697521382778, 1.386885429681126, 1.378160098096211, 1.3635542107954832, 1.3503124637569106, 1.3453746068575843, 1.3262752507431474, 1.325472887785024, 1.3152015164312, 1.3062718994048432, 1.301694334201211, 1.293604200795917, 1.2904341598951148, 1.2850974399792618, 1.2777887701416877, 1.27461929825491, 1.275879514212522, 1.2741748309839722, 1.2655922733586866, 1.2603587401233265, 1.2591025940111151, 1.2558813561354463], 'val_losses': [1.904331271144445, 1.7396891416426126, 1.6409277193320155, 1.5810364586505476, 1.5440472973691028, 1.5197908755846004, 1.4971252757644702, 1.4820071892427062, 1.4715478904951398, 1.4499068094993681, 1.4379512009473092, 1.4268353078885418, 1.4146120739138495, 1.4106625108070026, 1.3929071638790562, 1.384013819165762, 1.3732944181906133, 1.3647949468251563, 1.3550053287786195, 1.362422658542451, 1.3495717888980143, 1.344043908210614, 1.3435212820040194, 1.343200329266878, 1.3395987682183603, 1.3348182317622397, 1.3394362793248364, 1.333180557141521, 1.3238781480140338, 1.3245380001548477, 1.3226850167236117, 1.3214208456287257, 1.3296446812181242, 1.325605009331349], 'val_acc': [0.10951008645533142, 0.18305976694649792, 0.19872196466608194, 0.2648790878336048, 0.2726475379025185, 0.2950758050369628, 0.3929332163889237, 0.43478260869565216, 0.4697406340057637, 0.439042726475379, 0.5065781230422253, 0.5346447813557198, 0.5241197844881593, 0.5674727477759679, 0.5916551810550056, 0.5940358351083824, 0.5880215511840622, 0.6337551685252475, 0.6578123042225285, 0.6946497932589901, 0.6673349204360356, 0.6609447437664453, 0.6467861170279413, 0.6200977321137702, 0.714572108758301, 0.6683373010900889, 0.6786117027941361, 0.7148227039218144, 0.707680741761684, 0.6980328279664203, 0.724846510462348, 0.7178298458839745, 0.6823706302468362, 0.6920185440421], 'best_val_acc': 0.724846510462348, 'model_size_bytes': 131758, 'config_used': {'epochs': 34, 'batch_size': 128, 'lr': 6.190388356323335e-05, 'weight_decay': 7.475474116738931e-07, 'stem_channels': 13, 'nhead': 4, 'd_model': 52, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.1922313096751467, 'use_focal_loss': False, 'focal_gamma': 2.401256175491752, 'label_smoothing': 0.09026933859084657, 'grad_clip_norm': 0.45033924942942216, 'sched_step': 10, 'sched_gamma': 0.817195663574285, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 34, 'batch_size': 128, 'lr': 6.190388356323335e-05, 'weight_decay': 7.475474116738931e-07, 'stem_channels': 13, 'nhead': 4, 'd_model_factor': 13, 'num_layers': 2, 'ff_factor': 2, 'dropout': 0.1922313096751467, 'use_focal_loss': False, 'focal_gamma': 2.401256175491752, 'label_smoothing': 0.09026933859084657, 'grad_clip_norm': 0.45033924942942216, 'sched_step': 10, 'sched_gamma': 0.817195663574285, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 59652, 'model_storage_size_kb': 256.31718750000005, 'model_size_validation': 'FAIL'}
2025-10-02 23:15:44,126 - INFO - _models.training_function_executor - BO Objective: base=0.6920, size_penalty=0.0006, final=0.6914
2025-10-02 23:15:44,126 - INFO - _models.training_function_executor - Model: 59,652 parameters, 256.3KB (FAIL 256KB limit)
2025-10-02 23:15:44,126 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 203.808s
2025-10-02 23:15:44,234 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6914
2025-10-02 23:15:44,234 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-02 23:15:44,234 - INFO - bo.run_bo - Recorded observation #46: hparams={'epochs': np.int64(34), 'batch_size': np.int64(128), 'lr': 6.190388356323335e-05, 'weight_decay': 7.475474116738931e-07, 'stem_channels': np.int64(13), 'nhead': np.int64(4), 'd_model_factor': np.int64(13), 'num_layers': np.int64(2), 'ff_factor': np.int64(2), 'dropout': 0.1922313096751467, 'use_focal_loss': np.False_, 'focal_gamma': 2.401256175491752, 'label_smoothing': 0.09026933859084657, 'grad_clip_norm': 0.45033924942942216, 'sched_step': np.int64(10), 'sched_gamma': 0.817195663574285, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.6914
2025-10-02 23:15:44,234 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 46: {'epochs': np.int64(34), 'batch_size': np.int64(128), 'lr': 6.190388356323335e-05, 'weight_decay': 7.475474116738931e-07, 'stem_channels': np.int64(13), 'nhead': np.int64(4), 'd_model_factor': np.int64(13), 'num_layers': np.int64(2), 'ff_factor': np.int64(2), 'dropout': 0.1922313096751467, 'use_focal_loss': np.False_, 'focal_gamma': 2.401256175491752, 'label_smoothing': 0.09026933859084657, 'grad_clip_norm': 0.45033924942942216, 'sched_step': np.int64(10), 'sched_gamma': 0.817195663574285, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.6914
2025-10-02 23:15:44,235 - INFO - bo.run_bo - üîçBO Trial 47: Using RF surrogate + Expected Improvement
2025-10-02 23:15:44,235 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 23:15:44,235 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:15:44,235 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:15:44,235 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 45, 'batch_size': 32, 'lr': 6.0956618172018406e-05, 'weight_decay': 7.259673550550447e-07, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 14, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.2900848410496323, 'use_focal_loss': False, 'focal_gamma': 1.042995708006451, 'label_smoothing': 0.005659445623416071, 'grad_clip_norm': 0.2070768043512658, 'sched_step': 6, 'sched_gamma': 0.8730201751027078, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 23:15:44,236 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 45, 'batch_size': 32, 'lr': 6.0956618172018406e-05, 'weight_decay': 7.259673550550447e-07, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 14, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.2900848410496323, 'use_focal_loss': False, 'focal_gamma': 1.042995708006451, 'label_smoothing': 0.005659445623416071, 'grad_clip_norm': 0.2070768043512658, 'sched_step': 6, 'sched_gamma': 0.8730201751027078, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 23:20:53,243 - INFO - _models.training_function_executor - Model: 54,876 parameters, 235.8KB storage
2025-10-02 23:20:53,243 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3804961398397477, 0.9724098903263578, 0.7845479796148088, 0.690161068682473, 0.6183034166919145, 0.5757295916792452, 0.5425048168851659, 0.514555130535374, 0.49715993481911996, 0.480303657415072, 0.4657271485534732, 0.4518595356613802, 0.44174508925716266, 0.42854243459227437, 0.42011122543837265, 0.4178281485674036, 0.4133155343783543, 0.40216989013532783, 0.39972993759599146, 0.39057585260860084, 0.3845243917365789, 0.37572722903947925, 0.3794883463011385, 0.3762297097909676, 0.37467447106328794, 0.3659155994230795, 0.3592060375952263, 0.3589912175280787, 0.35468718644984365, 0.34962655372313867, 0.3470966073406395, 0.3441103531142634, 0.34533618848802483, 0.34493892121067793, 0.34384773235603655, 0.33559058293272176, 0.3402792392968123, 0.33728988439379615, 0.3326146404882035, 0.3272371961688598, 0.3268654095634752, 0.32405597855765034, 0.32069494065696785, 0.32403070141142654, 0.31632037041118055], 'val_losses': [1.0894592643501078, 0.8499388878931902, 0.7222105330123503, 0.6437480133953376, 0.6219942076749004, 0.5978627712441901, 0.5794747993994172, 0.5660026499747394, 0.5425896571253404, 0.5424516862114783, 0.5346330618472972, 0.5248492288941982, 0.5172093127278992, 0.5430172775162445, 0.5187598006077957, 0.5219495780425268, 0.5213014445438106, 0.5205351942658888, 0.535031966720364, 0.5162031884152195, 0.5334191170570441, 0.5146356456456903, 0.5231718448391087, 0.5514834180778615, 0.5411647915048508, 0.5416699899287021, 0.5655164344913305, 0.5748149180170319, 0.6004049873579088, 0.5636954104119174, 0.5277338192854559, 0.5585219019144314, 0.578540374814172, 0.558767753501178, 0.5990984518864656, 0.6185501979087741, 0.5868623698957133, 0.6102929405962341, 0.5869611221631806, 0.6097592748267476, 0.568202069701594, 0.595063073221954, 0.5858816925915631, 0.5776771777495602, 0.574020711928438], 'val_acc': [0.5786242325523118, 0.7069289562711439, 0.7708307229670467, 0.793258990101491, 0.8517729607818569, 0.8844756296203483, 0.8569101616338805, 0.8990101491041222, 0.8897381280541286, 0.8932464603433153, 0.9193083573487032, 0.8856033078561584, 0.8997619345946624, 0.928956271143967, 0.9193083573487032, 0.9099110387169528, 0.9110387169527628, 0.9268262122541034, 0.9210625234932965, 0.9221902017291066, 0.9251973436912667, 0.9245708557824834, 0.9307104372885603, 0.9339681744142339, 0.9283297832351836, 0.9344693647412605, 0.9478762059892244, 0.9292068663074803, 0.938102994612204, 0.9401077559203107, 0.9332163889236937, 0.9355970429770706, 0.9517604310236812, 0.9345946623230171, 0.9517604310236812, 0.9463726350081444, 0.9515098358601679, 0.9471244204986844, 0.9477509084074678, 0.9475003132439543, 0.9466232301716577, 0.9512592406966546, 0.9506327527878712, 0.9469991229169277, 0.9458714446811176], 'best_val_acc': 0.9517604310236812, 'model_size_bytes': 232046, 'config_used': {'epochs': 45, 'batch_size': 32, 'lr': 6.0956618172018406e-05, 'weight_decay': 7.259673550550447e-07, 'stem_channels': 12, 'nhead': 4, 'd_model': 56, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.2900848410496323, 'use_focal_loss': False, 'focal_gamma': 1.042995708006451, 'label_smoothing': 0.005659445623416071, 'grad_clip_norm': 0.2070768043512658, 'sched_step': 6, 'sched_gamma': 0.8730201751027078, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 45, 'batch_size': 32, 'lr': 6.0956618172018406e-05, 'weight_decay': 7.259673550550447e-07, 'stem_channels': 12, 'nhead': 4, 'd_model_factor': 14, 'num_layers': 2, 'ff_factor': 1, 'dropout': 0.2900848410496323, 'use_focal_loss': False, 'focal_gamma': 1.042995708006451, 'label_smoothing': 0.005659445623416071, 'grad_clip_norm': 0.2070768043512658, 'sched_step': 6, 'sched_gamma': 0.8730201751027078, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 54876, 'model_storage_size_kb': 235.79531250000002, 'model_size_validation': 'PASS'}
2025-10-02 23:20:53,243 - INFO - _models.training_function_executor - BO Objective: base=0.9459, size_penalty=0.0000, final=0.9459
2025-10-02 23:20:53,243 - INFO - _models.training_function_executor - Model: 54,876 parameters, 235.8KB (PASS 256KB limit)
2025-10-02 23:20:53,243 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 309.009s
2025-10-02 23:20:53,353 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9459
2025-10-02 23:20:53,353 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-02 23:20:53,353 - INFO - bo.run_bo - Recorded observation #47: hparams={'epochs': np.int64(45), 'batch_size': np.int64(32), 'lr': 6.0956618172018406e-05, 'weight_decay': 7.259673550550447e-07, 'stem_channels': np.int64(12), 'nhead': np.int64(4), 'd_model_factor': np.int64(14), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.2900848410496323, 'use_focal_loss': np.False_, 'focal_gamma': 1.042995708006451, 'label_smoothing': 0.005659445623416071, 'grad_clip_norm': 0.2070768043512658, 'sched_step': np.int64(6), 'sched_gamma': 0.8730201751027078, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.9459
2025-10-02 23:20:53,353 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 47: {'epochs': np.int64(45), 'batch_size': np.int64(32), 'lr': 6.0956618172018406e-05, 'weight_decay': 7.259673550550447e-07, 'stem_channels': np.int64(12), 'nhead': np.int64(4), 'd_model_factor': np.int64(14), 'num_layers': np.int64(2), 'ff_factor': np.int64(1), 'dropout': 0.2900848410496323, 'use_focal_loss': np.False_, 'focal_gamma': 1.042995708006451, 'label_smoothing': 0.005659445623416071, 'grad_clip_norm': 0.2070768043512658, 'sched_step': np.int64(6), 'sched_gamma': 0.8730201751027078, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.9459
2025-10-02 23:20:53,354 - INFO - bo.run_bo - üîçBO Trial 48: Using RF surrogate + Expected Improvement
2025-10-02 23:20:53,354 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 23:20:53,354 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:20:53,354 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:20:53,354 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 47, 'batch_size': 256, 'lr': 0.0014377350941563065, 'weight_decay': 0.0007075871934135383, 'stem_channels': 23, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.1073148417329723, 'use_focal_loss': False, 'focal_gamma': 2.2296799204977953, 'label_smoothing': 0.07021363410438457, 'grad_clip_norm': 0.9464677676999268, 'sched_step': 9, 'sched_gamma': 0.9527544854071087, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 23:20:53,355 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 47, 'batch_size': 256, 'lr': 0.0014377350941563065, 'weight_decay': 0.0007075871934135383, 'stem_channels': 23, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.1073148417329723, 'use_focal_loss': False, 'focal_gamma': 2.2296799204977953, 'label_smoothing': 0.07021363410438457, 'grad_clip_norm': 0.9464677676999268, 'sched_step': 9, 'sched_gamma': 0.9527544854071087, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-02 23:25:12,901 - INFO - _models.training_function_executor - Model: 40,176 parameters, 172.6KB storage
2025-10-02 23:25:12,901 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.607699426803897, 1.3233902174678955, 1.2259537543180394, 1.1489354714943092, 1.1148065164812682, 1.0898592167247474, 1.0696154573270449, 1.055736724959091, 1.044810203887823, 1.028914401925783, 1.0230146714650168, 1.013396836845505, 1.0023387882213068, 0.9969110933531833, 0.9879727576701551, 0.9887571187708397, 0.9800257405642335, 0.9755670218988569, 0.9644602807778125, 0.9706428590709769, 0.9612787246995375, 0.9597459151900711, 0.9526551402354902, 0.9508108498850506, 0.9559305529021882, 0.9463340043573494, 0.9446995425141403, 0.9442701693189565, 0.9363371802127679, 0.9373126895984185, 0.9373090084015163, 0.936929842383365, 0.9337188361249196, 0.931494759676081, 0.9275052045232068, 0.9330232944329595, 0.9314859157904674, 0.9253648845592963, 0.9250454218903008, 0.9271441529359755, 0.9259982437816803, 0.9229723052736833, 0.9213775285924507, 0.9227567967647665, 0.9230590261631217, 0.9218313459674431, 0.9218390748206787], 'val_losses': [1.3670916842601755, 1.2797541339629546, 1.1763292951491853, 1.1785571133040378, 1.1476348965049403, 1.1209658178795012, 1.1214295398500416, 1.1024696820362694, 1.0974228889060011, 1.0973470313494373, 1.1085467541401524, 1.1036776439122815, 1.0856649647707808, 1.0936438748747197, 1.1157629837922294, 1.1091618848883587, 1.101316684634595, 1.0930330956763394, 1.1465972347854596, 1.1010433708033665, 1.150219040367481, 1.1181560417357401, 1.1594693256102622, 1.1717124373941787, 1.1222832010975607, 1.1083621688391567, 1.1103582762488893, 1.166784214116087, 1.1409408360282784, 1.1518151064352826, 1.1383023932380136, 1.13681393926745, 1.1462452798211744, 1.1300945478548547, 1.1712139424428114, 1.1916417801324892, 1.1376369340484593, 1.12636323211755, 1.15790119587576, 1.124915560420153, 1.1237652116574048, 1.1408671964127504, 1.1296102193016977, 1.1483419767941856, 1.1312489343188399, 1.1546888315443138, 1.133866491420513], 'val_acc': [0.36574364114772584, 0.6233554692394436, 0.7327402581130185, 0.7431399573988222, 0.7817316125798772, 0.8872321764189951, 0.8149354717453953, 0.8362360606440296, 0.8347324896629496, 0.8818443804034583, 0.9005137200852024, 0.9141711564966796, 0.876581881969678, 0.9219396065655933, 0.9279538904899135, 0.8993860418493923, 0.9221902017291066, 0.9131687758426262, 0.938854780102744, 0.9165518105500564, 0.9412354341561208, 0.9371006139581506, 0.9434907906277409, 0.913294073424383, 0.9322140082696404, 0.8948753289061521, 0.9085327653176294, 0.9239443678737, 0.9413607317378775, 0.9442425761182809, 0.9521363237689513, 0.9492544793885478, 0.9309610324520736, 0.9498809672973312, 0.9630372133817817, 0.9129181806791129, 0.9557699536398947, 0.9551434657311114, 0.9535145971682747, 0.945746147099361, 0.944994361608821, 0.9513845382784112, 0.9567723342939481, 0.9480015035709811, 0.9466232301716577, 0.9478762059892244, 0.9441172785365243], 'best_val_acc': 0.9630372133817817, 'model_size_bytes': 93038, 'config_used': {'epochs': 47, 'batch_size': 256, 'lr': 0.0014377350941563065, 'weight_decay': 0.0007075871934135383, 'stem_channels': 23, 'nhead': 4, 'd_model': 36, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.1073148417329723, 'use_focal_loss': False, 'focal_gamma': 2.2296799204977953, 'label_smoothing': 0.07021363410438457, 'grad_clip_norm': 0.9464677676999268, 'sched_step': 9, 'sched_gamma': 0.9527544854071087, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 47, 'batch_size': 256, 'lr': 0.0014377350941563065, 'weight_decay': 0.0007075871934135383, 'stem_channels': 23, 'nhead': 4, 'd_model_factor': 9, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.1073148417329723, 'use_focal_loss': False, 'focal_gamma': 2.2296799204977953, 'label_smoothing': 0.07021363410438457, 'grad_clip_norm': 0.9464677676999268, 'sched_step': 9, 'sched_gamma': 0.9527544854071087, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 40176, 'model_storage_size_kb': 172.63125000000002, 'model_size_validation': 'PASS'}
2025-10-02 23:25:12,901 - INFO - _models.training_function_executor - BO Objective: base=0.9441, size_penalty=0.0000, final=0.9441
2025-10-02 23:25:12,901 - INFO - _models.training_function_executor - Model: 40,176 parameters, 172.6KB (PASS 256KB limit)
2025-10-02 23:25:12,901 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 259.547s
2025-10-02 23:25:13,011 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.9441
2025-10-02 23:25:13,011 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-02 23:25:13,012 - INFO - bo.run_bo - Recorded observation #48: hparams={'epochs': np.int64(47), 'batch_size': np.int64(256), 'lr': 0.0014377350941563065, 'weight_decay': 0.0007075871934135383, 'stem_channels': np.int64(23), 'nhead': np.int64(4), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.1073148417329723, 'use_focal_loss': np.False_, 'focal_gamma': 2.2296799204977953, 'label_smoothing': 0.07021363410438457, 'grad_clip_norm': 0.9464677676999268, 'sched_step': np.int64(9), 'sched_gamma': 0.9527544854071087, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.9441
2025-10-02 23:25:13,012 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 48: {'epochs': np.int64(47), 'batch_size': np.int64(256), 'lr': 0.0014377350941563065, 'weight_decay': 0.0007075871934135383, 'stem_channels': np.int64(23), 'nhead': np.int64(4), 'd_model_factor': np.int64(9), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.1073148417329723, 'use_focal_loss': np.False_, 'focal_gamma': 2.2296799204977953, 'label_smoothing': 0.07021363410438457, 'grad_clip_norm': 0.9464677676999268, 'sched_step': np.int64(9), 'sched_gamma': 0.9527544854071087, 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.9441
2025-10-02 23:25:13,012 - INFO - bo.run_bo - üîçBO Trial 49: Using RF surrogate + Expected Improvement
2025-10-02 23:25:13,012 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 23:25:13,012 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:25:13,012 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:25:13,012 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 43, 'batch_size': 256, 'lr': 5.6925655061636446e-05, 'weight_decay': 6.07905483363349e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.10630751085308987, 'use_focal_loss': False, 'focal_gamma': 1.9070198754771719, 'label_smoothing': 0.006959747983644406, 'grad_clip_norm': 0.9187067899635483, 'sched_step': 6, 'sched_gamma': 0.9351388258340169, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 23:25:13,014 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 43, 'batch_size': 256, 'lr': 5.6925655061636446e-05, 'weight_decay': 6.07905483363349e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.10630751085308987, 'use_focal_loss': False, 'focal_gamma': 1.9070198754771719, 'label_smoothing': 0.006959747983644406, 'grad_clip_norm': 0.9187067899635483, 'sched_step': 6, 'sched_gamma': 0.9351388258340169, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-02 23:27:17,625 - INFO - _models.training_function_executor - Model: 44,441 parameters, 191.0KB storage
2025-10-02 23:27:17,625 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5859484211960797, 1.4489852295847079, 1.3061113462215699, 1.2002330344074992, 1.1204091186149712, 1.046011657966982, 0.9850852318329572, 0.9305678743155936, 0.8837482628545841, 0.845256258016152, 0.8102853797534629, 0.7789471409966339, 0.7505028682260239, 0.7264390876186158, 0.7039957512042294, 0.6819136794959342, 0.663451073429091, 0.6447004407930877, 0.6282802741767223, 0.6166125959823952, 0.6042379282289582, 0.5914752696258989, 0.5791191704604155, 0.5712432261566073, 0.5591859548973103, 0.551334505385819, 0.5482926787661793, 0.5382957811235796, 0.5327499887849388, 0.5260581071131907, 0.5187749563555399, 0.5141077891267101, 0.507950889256889, 0.5021412638842983, 0.4971807830527444, 0.49357408215776816, 0.48632820035582053, 0.48197320329849086, 0.47657701757450627, 0.47222942640035814, 0.46660718301261717, 0.46460672274768244, 0.45763578716235714], 'val_losses': [1.5204315826328547, 1.3576007776131322, 1.2420894653930683, 1.151667561451604, 1.0728233685814308, 0.9955280757072859, 0.9453580837742067, 0.891626170495297, 0.8486982852186928, 0.8134149366296812, 0.7828600104553272, 0.7575131073704251, 0.7374188451894825, 0.7196066087685258, 0.7011514382319946, 0.6862768150932314, 0.6691414395634534, 0.6564438666276893, 0.6443158674771856, 0.6343118356308114, 0.6260751247734612, 0.617198369494358, 0.6077322111498994, 0.5997295895475386, 0.5943243684005116, 0.5927799510456927, 0.5838500234794234, 0.5934047117640748, 0.5752269378686486, 0.5699281981752833, 0.5667650155772572, 0.5653386539257405, 0.5580909088461221, 0.5529548762630601, 0.554581084282472, 0.5496784183946473, 0.5461705160117093, 0.5424962781407962, 0.5405710372257436, 0.5383383494587922, 0.5418954699906681, 0.5326424871541372, 0.5250862612862917], 'val_acc': [0.34745019421125173, 0.38503946873825334, 0.4122290439794512, 0.4484400451071294, 0.4742513469490039, 0.5342688886104499, 0.5729858413732615, 0.6139581506076933, 0.6355093346698408, 0.6650795639644155, 0.6571858163137452, 0.6758551559954893, 0.6965292569853402, 0.6917679488785866, 0.707304849016414, 0.7235935346447814, 0.7363738879839619, 0.7346197218393685, 0.7564215010650295, 0.7562962034832728, 0.7670717955143466, 0.7819822077433906, 0.76769828342313, 0.7856158376143341, 0.792883097356221, 0.8134319007643153, 0.8021551184062148, 0.8258363613582258, 0.792131311865681, 0.8123042225285052, 0.8165643403082321, 0.8302217767197093, 0.7998997619345947, 0.8287182057386292, 0.8377396316251097, 0.8264628492670092, 0.8198220774339056, 0.8319759428643028, 0.8348577872447062, 0.8408720711690264, 0.8505199849642902, 0.8465104623480767, 0.8323518356095727], 'best_val_acc': 0.8505199849642902, 'model_size_bytes': 186578, 'config_used': {'epochs': 43, 'batch_size': 256, 'lr': 5.6925655061636446e-05, 'weight_decay': 6.07905483363349e-07, 'stem_channels': 16, 'nhead': 4, 'd_model': 64, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.10630751085308987, 'use_focal_loss': False, 'focal_gamma': 1.9070198754771719, 'label_smoothing': 0.006959747983644406, 'grad_clip_norm': 0.9187067899635483, 'sched_step': 6, 'sched_gamma': 0.9351388258340169, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 43, 'batch_size': 256, 'lr': 5.6925655061636446e-05, 'weight_decay': 6.07905483363349e-07, 'stem_channels': 16, 'nhead': 4, 'd_model_factor': 16, 'num_layers': 1, 'ff_factor': 1, 'dropout': 0.10630751085308987, 'use_focal_loss': False, 'focal_gamma': 1.9070198754771719, 'label_smoothing': 0.006959747983644406, 'grad_clip_norm': 0.9187067899635483, 'sched_step': 6, 'sched_gamma': 0.9351388258340169, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 44441, 'model_storage_size_kb': 190.95742187500002, 'model_size_validation': 'PASS'}
2025-10-02 23:27:17,625 - INFO - _models.training_function_executor - BO Objective: base=0.8324, size_penalty=0.0000, final=0.8324
2025-10-02 23:27:17,625 - INFO - _models.training_function_executor - Model: 44,441 parameters, 191.0KB (PASS 256KB limit)
2025-10-02 23:27:17,625 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 124.613s
2025-10-02 23:27:17,736 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8324
2025-10-02 23:27:17,736 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-02 23:27:17,736 - INFO - bo.run_bo - Recorded observation #49: hparams={'epochs': np.int64(43), 'batch_size': np.int64(256), 'lr': 5.6925655061636446e-05, 'weight_decay': 6.07905483363349e-07, 'stem_channels': np.int64(16), 'nhead': np.int64(4), 'd_model_factor': np.int64(16), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.10630751085308987, 'use_focal_loss': np.False_, 'focal_gamma': 1.9070198754771719, 'label_smoothing': 0.006959747983644406, 'grad_clip_norm': 0.9187067899635483, 'sched_step': np.int64(6), 'sched_gamma': 0.9351388258340169, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.8324
2025-10-02 23:27:17,736 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 49: {'epochs': np.int64(43), 'batch_size': np.int64(256), 'lr': 5.6925655061636446e-05, 'weight_decay': 6.07905483363349e-07, 'stem_channels': np.int64(16), 'nhead': np.int64(4), 'd_model_factor': np.int64(16), 'num_layers': np.int64(1), 'ff_factor': np.int64(1), 'dropout': 0.10630751085308987, 'use_focal_loss': np.False_, 'focal_gamma': 1.9070198754771719, 'label_smoothing': 0.006959747983644406, 'grad_clip_norm': 0.9187067899635483, 'sched_step': np.int64(6), 'sched_gamma': 0.9351388258340169, 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.8324
2025-10-02 23:27:17,737 - INFO - bo.run_bo - üîçBO Trial 50: Using RF surrogate + Expected Improvement
2025-10-02 23:27:17,737 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-02 23:27:17,737 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:27:17,737 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:27:17,737 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': 39, 'batch_size': 32, 'lr': 4.402268420472009e-05, 'weight_decay': 1.8033944399941418e-07, 'stem_channels': 15, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.12090379302966281, 'use_focal_loss': False, 'focal_gamma': 1.0340981870206223, 'label_smoothing': 0.08896850458873501, 'grad_clip_norm': 0.1493005323161585, 'sched_step': 5, 'sched_gamma': 0.9546869806844438, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 23:27:17,738 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 39, 'batch_size': 32, 'lr': 4.402268420472009e-05, 'weight_decay': 1.8033944399941418e-07, 'stem_channels': 15, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.12090379302966281, 'use_focal_loss': False, 'focal_gamma': 1.0340981870206223, 'label_smoothing': 0.08896850458873501, 'grad_clip_norm': 0.1493005323161585, 'sched_step': 5, 'sched_gamma': 0.9546869806844438, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-02 23:30:12,768 - INFO - _models.training_function_executor - Model: 7,671 parameters, 33.0KB storage
2025-10-02 23:30:12,768 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [2.212954504524329, 2.1322664532659794, 2.0909200815002382, 2.0337789953044383, 2.0080274585284963, 1.970877944364459, 1.9263955082947295, 1.8852063193340796, 1.8638160729234248, 1.8298809605052857, 1.795330265618183, 1.7682050750603844, 1.7498372869563574, 1.7145676505008116, 1.688768187684418, 1.65836052688759, 1.6331230996153436, 1.6101112748784678, 1.5956524739277242, 1.5922521353701513, 1.5826495449050748, 1.564846394104837, 1.5644428676704198, 1.5545109695529808, 1.5545034968748064, 1.544038321885781, 1.5359974700108106, 1.5310457721971067, 1.5243926321254377, 1.5141983277643174, 1.5097994574350928, 1.520386688953406, 1.509659304406878, 1.5017328259491052, 1.5021045529199708, 1.4973032510590927, 1.4890989523739369, 1.4895985870475148, 1.4795255039403177], 'val_losses': [2.164074738840309, 2.1066078755837934, 2.0622298798455345, 2.0230640491855545, 1.9834570061098498, 1.936318999199532, 1.8957290800572817, 1.8521751584362647, 1.817890166997342, 1.793408690232589, 1.7638977588589755, 1.7386009741540451, 1.707147957298514, 1.6824936491551965, 1.669197162445469, 1.6330967885840584, 1.6154361282908338, 1.604678465779033, 1.5931416411340693, 1.5849953714341332, 1.5792181426279976, 1.573584880316232, 1.577271067114824, 1.5787380298207747, 1.5607762528816091, 1.5552679682536734, 1.5558418993094918, 1.5446623068168908, 1.5366664849013527, 1.5394869311951318, 1.5370528829409924, 1.535925391681988, 1.5365077136020258, 1.5249797759565729, 1.5290872168830725, 1.5199399095417458, 1.515027128011567, 1.5099474944621456, 1.5089190289454717], 'val_acc': [0.146347575491793, 0.09459967422628743, 0.08658062899386042, 0.09196842500939732, 0.10625234932965794, 0.14434281418368625, 0.13456960280666583, 0.1531136449066533, 0.19959904773837864, 0.18757047988973813, 0.2447061771707806, 0.2940734243829094, 0.3279037714572109, 0.36261120160380905, 0.41611326901390805, 0.46322515975441675, 0.46560581380779353, 0.49981205362736497, 0.5662197719584012, 0.5793760180428518, 0.5759929833354216, 0.6074426763563463, 0.6049367247212128, 0.6008019045232427, 0.6413983210124045, 0.6652048615461722, 0.6510462348076682, 0.6938980077684501, 0.6663325397819823, 0.6642024808921188, 0.6979075303846636, 0.6739756922691392, 0.6951509835860168, 0.6897631875704799, 0.6940233053502067, 0.6922691392056133, 0.714196216013031, 0.7165768700664077, 0.7055506828718205], 'best_val_acc': 0.7165768700664077, 'model_size_bytes': 42798, 'config_used': {'epochs': 39, 'batch_size': 32, 'lr': 4.402268420472009e-05, 'weight_decay': 1.8033944399941418e-07, 'stem_channels': 15, 'nhead': 1, 'd_model': 11, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.12090379302966281, 'use_focal_loss': False, 'focal_gamma': 1.0340981870206223, 'label_smoothing': 0.08896850458873501, 'grad_clip_norm': 0.1493005323161585, 'sched_step': 5, 'sched_gamma': 0.9546869806844438, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 39, 'batch_size': 32, 'lr': 4.402268420472009e-05, 'weight_decay': 1.8033944399941418e-07, 'stem_channels': 15, 'nhead': 1, 'd_model_factor': 11, 'num_layers': 2, 'ff_factor': 4, 'dropout': 0.12090379302966281, 'use_focal_loss': False, 'focal_gamma': 1.0340981870206223, 'label_smoothing': 0.08896850458873501, 'grad_clip_norm': 0.1493005323161585, 'sched_step': 5, 'sched_gamma': 0.9546869806844438, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 7671, 'model_storage_size_kb': 32.961328125, 'model_size_validation': 'PASS'}
2025-10-02 23:30:12,769 - INFO - _models.training_function_executor - BO Objective: base=0.7056, size_penalty=0.0000, final=0.7056
2025-10-02 23:30:12,769 - INFO - _models.training_function_executor - Model: 7,671 parameters, 33.0KB (PASS 256KB limit)
2025-10-02 23:30:12,769 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 175.032s
2025-10-02 23:30:12,879 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7056
2025-10-02 23:30:12,879 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.110s
2025-10-02 23:30:12,879 - INFO - bo.run_bo - Recorded observation #50: hparams={'epochs': np.int64(39), 'batch_size': np.int64(32), 'lr': 4.402268420472009e-05, 'weight_decay': 1.8033944399941418e-07, 'stem_channels': np.int64(15), 'nhead': np.int64(1), 'd_model_factor': np.int64(11), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.12090379302966281, 'use_focal_loss': np.False_, 'focal_gamma': 1.0340981870206223, 'label_smoothing': 0.08896850458873501, 'grad_clip_norm': 0.1493005323161585, 'sched_step': np.int64(5), 'sched_gamma': 0.9546869806844438, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.7056
2025-10-02 23:30:12,879 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 50: {'epochs': np.int64(39), 'batch_size': np.int64(32), 'lr': 4.402268420472009e-05, 'weight_decay': 1.8033944399941418e-07, 'stem_channels': np.int64(15), 'nhead': np.int64(1), 'd_model_factor': np.int64(11), 'num_layers': np.int64(2), 'ff_factor': np.int64(4), 'dropout': 0.12090379302966281, 'use_focal_loss': np.False_, 'focal_gamma': 1.0340981870206223, 'label_smoothing': 0.08896850458873501, 'grad_clip_norm': 0.1493005323161585, 'sched_step': np.int64(5), 'sched_gamma': 0.9546869806844438, 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.7056
2025-10-02 23:30:12,879 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.9687
2025-10-02 23:30:12,879 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'epochs': np.int64(37), 'batch_size': np.int64(32), 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.27589837466691197, 'use_focal_loss': np.False_, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': np.int64(9), 'sched_gamma': 0.9802751497189455, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}
2025-10-02 23:30:12,879 - INFO - visualization - Generating BO visualization charts with 50 trials...
2025-10-02 23:30:14,310 - INFO - visualization - BO summary saved to: charts/20251002_233012_BO_Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)/bo_summary.txt
2025-10-02 23:30:14,310 - INFO - visualization - BO charts saved to: charts/20251002_233012_BO_Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:30:14,310 - INFO - evaluation.code_generation_pipeline_orchestrator - üìä BO charts saved to: charts/20251002_233012_BO_Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:30:14,365 - INFO - evaluation.code_generation_pipeline_orchestrator - üöÄ STEP 4: Final Training Execution
2025-10-02 23:30:14,365 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (39904, 1000, 2), Val: (9977, 1000, 2), Test: (12471, 1000, 2)
2025-10-02 23:30:14,456 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-02 23:30:14,468 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-02 23:30:14,482 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-02 23:30:14,483 - INFO - _models.training_function_executor - Loaded training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:30:14,483 - INFO - _models.training_function_executor - Reasoning: No reasoning provided
2025-10-02 23:30:14,483 - INFO - _models.training_function_executor - Loaded training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:30:14,483 - INFO - _models.training_function_executor - Reasoning: No reasoning provided
2025-10-02 23:30:14,483 - INFO - evaluation.code_generation_pipeline_orchestrator - Executing final training with optimized params: {'epochs': np.int64(37), 'batch_size': np.int64(32), 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.27589837466691197, 'use_focal_loss': np.False_, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': np.int64(9), 'sched_gamma': 0.9802751497189455, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}
2025-10-02 23:30:14,483 - INFO - evaluation.code_generation_pipeline_orchestrator - Using test set for final training evaluation
2025-10-02 23:30:14,483 - INFO - _models.training_function_executor - Using device: cuda
2025-10-02 23:30:14,505 - INFO - _models.training_function_executor - Executing training function: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:30:14,505 - INFO - _models.training_function_executor - Hyperparameters: {'epochs': np.int64(37), 'batch_size': np.int64(32), 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': np.int64(24), 'nhead': np.int64(1), 'd_model_factor': np.int64(10), 'num_layers': np.int64(2), 'ff_factor': np.int64(3), 'dropout': 0.27589837466691197, 'use_focal_loss': np.False_, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': np.int64(9), 'sched_gamma': 0.9802751497189455, 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}
2025-10-02 23:30:14,507 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'epochs': 37, 'batch_size': 32, 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27589837466691197, 'use_focal_loss': False, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': 9, 'sched_gamma': 0.9802751497189455, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-02 23:33:29,319 - INFO - _models.training_function_executor - Model: 8,647 parameters, 18.6KB storage
2025-10-02 23:33:29,319 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1165874185998055, 0.7977393205488981, 0.7311314513373586, 0.6916787946520563, 0.6707741807318728, 0.6428302041200418, 0.6282918052785188, 0.6223426912556482, 0.607629168088568, 0.5927428486066144, 0.598438588243632, 0.5882212795801132, 0.5760831377127692, 0.5766732785447464, 0.5672849887427848, 0.5619877596903344, 0.5521185877042096, 0.5510756695925377, 0.5478635554611921, 0.5472762149720548, 0.5375529036176807, 0.534641840740883, 0.5319430535090094, 0.5322357382096571, 0.525863305773846, 0.5272131510371673, 0.5237135838033107, 0.513814745337942, 0.5218966422242552, 0.5158839330089121, 0.5145787692418936, 0.5113360379324403, 0.5063471162472138, 0.49918108085153956, 0.4993991584015925, 0.5053178682122693, 0.4970238124287023], 'val_losses': [0.9141047043039846, 0.8015880137263758, 0.7952165902831887, 0.7691344302397055, 0.7072989574106529, 0.7269204611834084, 0.7545221152239455, 0.7046351714525558, 0.8023732345294058, 0.8008195988857204, 0.7557864425970189, 0.6840434432933042, 0.7027883101065017, 0.6941275807177759, 0.6835131339532277, 0.6616516141790728, 0.715835278253205, 0.7216465869870223, 0.6585360235582328, 0.6837021501561746, 0.6524395145593559, 0.6792610929308817, 0.7421345913690263, 0.6379841447041418, 0.6655681069225501, 0.6263647728948584, 0.6526149441174809, 0.6403440730596218, 0.6754253340860996, 0.6063357082640444, 0.6565710076203888, 0.6242501272175232, 0.5905931589000447, 0.6117244275737407, 0.6277285844993309, 0.6624098018668494, 0.6263116596611794], 'val_acc': [0.8105204073450405, 0.8700986288188598, 0.9115548071525941, 0.9198139684067036, 0.923181781733622, 0.9257477347446075, 0.9484403816855104, 0.9406623366209607, 0.9599069842033517, 0.9599871702349451, 0.9387378718627215, 0.9457942426429315, 0.9492422420014434, 0.9566193569080266, 0.9599069842033517, 0.9611097746772512, 0.9481998235907305, 0.9560580546868735, 0.9643974019725764, 0.9573410311923662, 0.96375591371983, 0.9639162857830166, 0.9601475422981317, 0.9558976826236869, 0.9546147061181942, 0.9587843797610456, 0.9671237270467484, 0.9676048432363082, 0.9625531232459306, 0.9615107048352177, 0.9660813086360356, 0.9672039130783417, 0.9661614946676289, 0.9605484724560982, 0.9700906102157004, 0.9644775880041697, 0.9667227968887819], 'best_val_acc': 0.9700906102157004, 'model_size_bytes': 29742, 'config_used': {'epochs': 37, 'batch_size': 32, 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': 24, 'nhead': 1, 'd_model': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27589837466691197, 'use_focal_loss': False, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': 9, 'sched_gamma': 0.9802751497189455, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_name': 'Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'epochs': 37, 'batch_size': 32, 'lr': 0.004111029158116247, 'weight_decay': 0.0001680838775444637, 'stem_channels': 24, 'nhead': 1, 'd_model_factor': 10, 'num_layers': 2, 'ff_factor': 3, 'dropout': 0.27589837466691197, 'use_focal_loss': False, 'focal_gamma': 2.4022071626903534, 'label_smoothing': 0.018839562214466435, 'grad_clip_norm': 0.6105298155255798, 'sched_step': 9, 'sched_gamma': 0.9802751497189455, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 8647, 'model_storage_size_kb': 18.5775390625, 'model_size_validation': 'PASS'}
2025-10-02 23:33:29,319 - INFO - evaluation.code_generation_pipeline_orchestrator - Using final test metrics from training (avoids preprocessing mismatch)
2025-10-02 23:33:29,319 - INFO - evaluation.code_generation_pipeline_orchestrator - Final test metrics: {'acc': 0.9667227968887819, 'macro_f1': None}
2025-10-02 23:33:29,488 - INFO - evaluation.code_generation_pipeline_orchestrator - Model and test tensors saved to: trained_models/20251002_233014_Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:33:29,494 - INFO - evaluation.code_generation_pipeline_orchestrator - üìä STEP 5: Performance Analysis
2025-10-02 23:33:29,494 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated Model: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:33:29,494 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Score: 0.9687
2025-10-02 23:33:29,494 - INFO - evaluation.code_generation_pipeline_orchestrator - Final Score: 0.9667
2025-10-02 23:33:29,494 - INFO - evaluation.code_generation_pipeline_orchestrator - CODE GENERATION PIPELINE COMPLETE!
2025-10-02 23:33:29,494 - INFO - evaluation.code_generation_pipeline_orchestrator - Model: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)
2025-10-02 23:33:29,494 - INFO - evaluation.code_generation_pipeline_orchestrator - Score: 0.9667
2025-10-02 23:33:29,494 - INFO - __main__ - AI-enhanced training completed!
2025-10-02 23:33:29,494 - INFO - __main__ - Final model achieved: {'acc': 0.9667227968887819, 'macro_f1': None}
2025-10-02 23:33:29,494 - INFO - __main__ - Pipeline completed successfully in single attempt
2025-10-02 23:33:29,494 - INFO - __main__ - Pipeline completed: Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder), metrics: {'acc': 0.9667227968887819, 'macro_f1': None}
2025-10-02 23:33:29,495 - INFO - __main__ - Pipeline summary saved to charts/pipeline_summary_20251002_233329.json
2025-10-02 23:33:29,498 - INFO - __main__ - Model saved: trained_models/best_model_Two‚ÄëLead CAT‚ÄëNet (1D CNN + SE Channel Attention + Transformer Encoder)_20251002_233329.pth, performance: {'acc': 0.9667227968887819, 'macro_f1': None}
2025-10-02 23:33:29,498 - INFO - __main__ - AI-enhanced processing completed successfully
