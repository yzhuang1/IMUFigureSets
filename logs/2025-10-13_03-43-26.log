2025-10-13 03:43:27,452 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-13 03:43:27,588 - INFO - __main__ - Logging system initialized successfully
2025-10-13 03:43:27,588 - INFO - __main__ - Starting AI-Enhanced Machine Learning Pipeline
2025-10-13 03:43:27,588 - INFO - __main__ - Starting real data processing from data/dataset3/ directory
2025-10-13 03:43:27,589 - INFO - __main__ - Found 4 data files: ['sleep_sample.csv', 'X.npy', 'y.npy', 'sleep_metadata.json']
2025-10-13 03:43:27,589 - INFO - __main__ - Found NPY files, prioritizing them over CSV
2025-10-13 03:43:27,589 - INFO - __main__ - Attempting to load: X.npy
2025-10-13 03:43:34,382 - INFO - __main__ - Successfully loaded NPY data: X(89283, 6, 6000), y(89283,)
2025-10-13 03:43:39,234 - INFO - __main__ - Data loaded successfully: X.npy + y.npy, shape: (89283, 6, 6000), device: cuda
2025-10-13 03:43:39,234 - INFO - __main__ - Starting AI-enhanced data processing with new pipeline flow...
2025-10-13 03:43:39,234 - INFO - __main__ - Starting AI-enhanced training (single attempt, fail fast)
2025-10-13 03:43:39,234 - INFO - __main__ - Flow: Code Generation ‚Üí BO ‚Üí Evaluation
2025-10-13 03:43:39,239 - INFO - adapters.universal_converter - Data conversion: numpy_array -> torch_tensor
2025-10-13 03:43:39,239 - INFO - __main__ - Data profile: {'data_type': 'torch_tensor', 'shape': (89283, 6, 6000), 'dtype': 'float32', 'feature_count': 6000, 'sample_count': 89283, 'is_sequence': True, 'is_image': False, 'is_tabular': False, 'has_labels': True, 'label_count': 5, 'sequence_lengths': None, 'channels': None, 'height': None, 'width': None, 'metadata': {}}
2025-10-13 03:43:39,239 - INFO - evaluation.code_generation_pipeline_orchestrator - Code generation pipeline orchestrator initialized (no retry logic)
2025-10-13 03:43:39,239 - INFO - evaluation.code_generation_pipeline_orchestrator - Starting code generation pipeline execution (single attempt, fail fast)
2025-10-13 03:43:39,239 - INFO - evaluation.code_generation_pipeline_orchestrator - Flow: AI Code Generation ‚Üí JSON Storage ‚Üí BO ‚Üí Training Execution ‚Üí Evaluation
2025-10-13 03:43:39,239 - INFO - evaluation.code_generation_pipeline_orchestrator - Creating centralized data splits to prevent data leakage
2025-10-13 03:43:39,239 - INFO - data_splitting - Creating centralized data splits with test_size=0.2, val_size=0.2
2025-10-13 03:43:39,239 - INFO - data_splitting - Input data shape: X=(89283, 6, 6000), y=(89283,)
2025-10-13 03:43:39,239 - INFO - data_splitting - Class distribution: [20758 11387 28006 17266 11866]
2025-10-13 03:43:49,890 - INFO - data_splitting - Computed class weights: {np.int64(0): np.float64(0.8602182913059842), np.int64(1): np.float64(1.5682722656786057), np.int64(2): np.float64(0.6375808971211783), np.int64(3): np.float64(1.03420814479638), np.int64(4): np.float64(1.5048722675796682)}
2025-10-13 03:43:49,892 - INFO - class_balancing - Class imbalance analysis:
2025-10-13 03:43:49,892 - INFO - class_balancing -   Strategy: mild_imbalance
2025-10-13 03:43:49,892 - INFO - class_balancing -   Imbalance ratio: 2.46
2025-10-13 03:43:49,892 - INFO - class_balancing -   Recommendations: Standard training should work, Consider class_weight='balanced'
2025-10-13 03:43:49,892 - INFO - data_splitting - Final splits - Train: 57140, Val: 14286, Test: 17857
2025-10-13 03:43:49,892 - INFO - data_splitting - Train class distribution: [13285  7287 17924 11050  7594]
2025-10-13 03:43:49,892 - INFO - data_splitting - Val class distribution: [3321 1822 4481 2763 1899]
2025-10-13 03:43:49,893 - INFO - data_splitting - Test class distribution: [4152 2278 5601 3453 2373]
2025-10-13 03:43:49,893 - INFO - data_splitting - Recommended balancing strategy: mild_imbalance
2025-10-13 03:43:53,075 - INFO - data_splitting - Computed standardization stats - mean shape: torch.Size([1, 6000]), std shape: torch.Size([1, 6000])
2025-10-13 03:43:53,085 - INFO - evaluation.code_generation_pipeline_orchestrator - Computed standardization statistics from training data only
2025-10-13 03:43:53,085 - INFO - evaluation.code_generation_pipeline_orchestrator - 
============================================================
2025-10-13 03:43:53,085 - INFO - evaluation.code_generation_pipeline_orchestrator - PIPELINE EXECUTION (SINGLE ATTEMPT)
2025-10-13 03:43:53,085 - INFO - evaluation.code_generation_pipeline_orchestrator - ============================================================
2025-10-13 03:43:53,085 - INFO - evaluation.code_generation_pipeline_orchestrator - ü§ñ STEP 1: AI Training Code Generation
2025-10-13 03:43:53,086 - INFO - _models.ai_code_generator - Conducting literature review before code generation...
2025-10-13 03:47:31,897 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-13 03:47:31,922 - INFO - _models.ai_code_generator - Making API call to gpt-5
2025-10-13 03:47:31,922 - INFO - _models.ai_code_generator - Prompt length: 5454 characters
2025-10-13 03:47:31,922 - INFO - _models.ai_code_generator - Using API base URL: https://api.openai.com/v1
2025-10-13 03:47:31,923 - INFO - _models.ai_code_generator - Calling self.client.responses.create...
2025-10-13 03:47:31,923 - INFO - _models.ai_code_generator - Model parameter: gpt-5
2025-10-13 03:49:28,636 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 200 OK"
2025-10-13 03:49:28,637 - INFO - _models.ai_code_generator - Successfully extracted response content
2025-10-13 03:49:28,637 - INFO - _models.ai_code_generator - AI generated training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 03:49:28,637 - INFO - _models.ai_code_generator - Confidence: 0.86
2025-10-13 03:49:28,637 - INFO - _models.ai_code_generator - Literature review informed code generation (confidence: 0.76)
2025-10-13 03:49:28,637 - INFO - evaluation.code_generation_pipeline_orchestrator - Generated training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 03:49:28,637 - INFO - evaluation.code_generation_pipeline_orchestrator - BO parameters: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'hidden_size', 'd_model', 't_pooled', 'label_smoothing', 'use_focal_loss', 'focal_gamma', 'grad_clip_norm', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations']
2025-10-13 03:49:28,637 - INFO - evaluation.code_generation_pipeline_orchestrator - Confidence: 0.86
2025-10-13 03:49:28,647 - INFO - evaluation.code_generation_pipeline_orchestrator - üíæ STEP 2: Save Training Function to JSON
2025-10-13 03:49:28,648 - INFO - _models.ai_code_generator - Training function saved to: generated_training_functions/training_function_torch_tensor_MR-CNN_+_BiGRU__BiMamba-lite__for_ISRUC_1760345368.json
2025-10-13 03:49:28,648 - INFO - evaluation.code_generation_pipeline_orchestrator - Training function saved to: generated_training_functions/training_function_torch_tensor_MR-CNN_+_BiGRU__BiMamba-lite__for_ISRUC_1760345368.json
2025-10-13 03:49:28,648 - INFO - evaluation.code_generation_pipeline_orchestrator - üîç STEP 3: Bayesian Optimization
2025-10-13 03:49:28,648 - INFO - evaluation.code_generation_pipeline_orchestrator - Running BO for generated training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 03:49:28,648 - INFO - evaluation.code_generation_pipeline_orchestrator - üì¶ Installing dependencies for GPT-generated training code...
2025-10-13 03:49:28,661 - INFO - package_installer - üîç Analyzing GPT-generated code for package dependencies...
2025-10-13 03:49:28,663 - INFO - package_installer - Extracted imports from code: {'torch'}
2025-10-13 03:49:28,663 - INFO - package_installer - Available packages: {'torch'}
2025-10-13 03:49:28,663 - INFO - package_installer - Missing packages: set()
2025-10-13 03:49:28,663 - INFO - package_installer - ‚úÖ All required packages are already available
2025-10-13 03:49:28,663 - INFO - evaluation.code_generation_pipeline_orchestrator - ‚úÖ All dependencies installed successfully
2025-10-13 03:49:28,663 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-13 03:49:28,663 - INFO - evaluation.code_generation_pipeline_orchestrator - BO dataset size: 57140 samples (using bo_sample_num=100000000000000)
2025-10-13 03:49:28,663 - INFO - evaluation.code_generation_pipeline_orchestrator - BO will optimize: ['lr', 'batch_size', 'epochs', 'weight_decay', 'dropout', 'hidden_size', 'd_model', 't_pooled', 'label_smoothing', 'use_focal_loss', 'focal_gamma', 'grad_clip_norm', 'num_workers', 'quantization_bits', 'quantize_weights', 'quantize_activations']
2025-10-13 03:49:28,664 - INFO - _models.training_function_executor - GPU available: NVIDIA GeForce RTX 3070 Ti
2025-10-13 03:49:28,664 - INFO - data_splitting - Using all 57140 training samples for BO
2025-10-13 03:49:28,664 - INFO - _models.training_function_executor - Using BO subset for optimization: 57140 samples (bo_sample_num=100000000000000)
2025-10-13 03:49:29,229 - INFO - _models.training_function_executor - BO splits - Train: 45712, Val: 11428
2025-10-13 03:49:30,986 - INFO - bo.run_bo - Converted GPT search space: 16 parameters
2025-10-13 03:49:30,986 - INFO - bo.run_bo - Using GPT-generated search space
2025-10-13 03:49:30,988 - INFO - bo.run_bo - Initialized Random Forest Bayesian Optimizer
2025-10-13 03:49:30,989 - INFO - bo.run_bo - üîçBO Trial 1: Initial random exploration
2025-10-13 03:49:30,989 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 03:49:30,989 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 1 (NaN monitoring active)
2025-10-13 03:49:30,989 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 03:49:30,989 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 03:49:30,989 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.001412035543062636, 'batch_size': 8, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'hidden_size': 26, 'd_model': 30, 't_pooled': 128, 'label_smoothing': 0.17323522915498707, 'use_focal_loss': False, 'focal_gamma': 3.540362888980228, 'grad_clip_norm': 0.10292247147901225, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 03:49:30,990 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.001412035543062636, 'batch_size': 8, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'hidden_size': 26, 'd_model': 30, 't_pooled': 128, 'label_smoothing': 0.17323522915498707, 'use_focal_loss': False, 'focal_gamma': 3.540362888980228, 'grad_clip_norm': 0.10292247147901225, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 03:49:50,577 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0795 | val_loss=0.9545 | val_acc=0.7707 | time=18.8s
2025-10-13 03:50:04,639 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.9950 | val_loss=0.9395 | val_acc=0.7820 | time=14.1s
2025-10-13 03:50:18,695 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.9718 | val_loss=0.9608 | val_acc=0.7736 | time=14.1s
2025-10-13 03:50:32,887 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9606 | val_loss=0.9229 | val_acc=0.7922 | time=14.2s
2025-10-13 03:50:47,141 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9482 | val_loss=0.9142 | val_acc=0.7979 | time=14.3s
2025-10-13 03:51:01,288 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9415 | val_loss=0.9171 | val_acc=0.7938 | time=14.1s
2025-10-13 03:51:15,247 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9365 | val_loss=0.9142 | val_acc=0.7994 | time=14.0s
2025-10-13 03:51:29,332 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.9290 | val_loss=0.9337 | val_acc=0.7876 | time=14.1s
2025-10-13 03:51:43,460 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9230 | val_loss=0.9456 | val_acc=0.7822 | time=14.1s
2025-10-13 03:51:57,586 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9191 | val_loss=0.9123 | val_acc=0.8008 | time=14.1s
2025-10-13 03:52:11,890 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.9180 | val_loss=0.8971 | val_acc=0.8102 | time=14.3s
2025-10-13 03:52:26,085 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9132 | val_loss=0.9081 | val_acc=0.7974 | time=14.2s
2025-10-13 03:52:40,256 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9104 | val_loss=0.9240 | val_acc=0.7991 | time=14.2s
2025-10-13 03:52:54,477 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.9096 | val_loss=0.9060 | val_acc=0.8018 | time=14.2s
2025-10-13 03:53:08,675 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.9052 | val_loss=0.9014 | val_acc=0.8059 | time=14.2s
2025-10-13 03:53:22,880 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.9047 | val_loss=0.8992 | val_acc=0.8085 | time=14.2s
2025-10-13 03:53:37,182 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.9015 | val_loss=0.9027 | val_acc=0.8071 | time=14.3s
2025-10-13 03:53:51,488 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.9012 | val_loss=0.9470 | val_acc=0.7848 | time=14.3s
2025-10-13 03:54:05,659 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.9001 | val_loss=0.9080 | val_acc=0.8033 | time=14.2s
2025-10-13 03:54:19,903 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8963 | val_loss=0.9030 | val_acc=0.8073 | time=14.2s
2025-10-13 03:54:34,184 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8946 | val_loss=0.8898 | val_acc=0.8123 | time=14.3s
2025-10-13 03:54:48,423 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8942 | val_loss=0.9049 | val_acc=0.8090 | time=14.2s
2025-10-13 03:55:02,732 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8924 | val_loss=0.8978 | val_acc=0.8113 | time=14.3s
2025-10-13 03:55:16,975 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8911 | val_loss=0.8965 | val_acc=0.8114 | time=14.2s
2025-10-13 03:55:31,204 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8886 | val_loss=0.8982 | val_acc=0.8120 | time=14.2s
2025-10-13 03:55:45,353 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8895 | val_loss=0.8892 | val_acc=0.8140 | time=14.1s
2025-10-13 03:55:59,519 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8876 | val_loss=0.9127 | val_acc=0.8029 | time=14.2s
2025-10-13 03:56:13,631 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8879 | val_loss=0.9104 | val_acc=0.8018 | time=14.1s
2025-10-13 03:56:27,835 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8853 | val_loss=0.9299 | val_acc=0.7955 | time=14.2s
2025-10-13 03:56:42,041 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8858 | val_loss=0.8965 | val_acc=0.8125 | time=14.2s
2025-10-13 03:56:56,234 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8843 | val_loss=0.8928 | val_acc=0.8114 | time=14.2s
2025-10-13 03:57:10,343 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.8844 | val_loss=0.9228 | val_acc=0.7997 | time=14.1s
2025-10-13 03:57:24,532 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.8839 | val_loss=0.8980 | val_acc=0.8103 | time=14.2s
2025-10-13 03:57:38,796 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.8818 | val_loss=0.9184 | val_acc=0.7999 | time=14.3s
2025-10-13 03:57:53,035 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.8823 | val_loss=0.8906 | val_acc=0.8134 | time=14.2s
2025-10-13 03:58:07,163 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.8798 | val_loss=0.8992 | val_acc=0.8104 | time=14.1s
2025-10-13 03:58:21,301 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.8798 | val_loss=0.9046 | val_acc=0.8067 | time=14.1s
2025-10-13 03:58:35,507 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.8784 | val_loss=0.8956 | val_acc=0.8121 | time=14.2s
2025-10-13 03:58:49,606 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.8788 | val_loss=0.9245 | val_acc=0.8046 | time=14.1s
2025-10-13 03:59:03,885 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.8788 | val_loss=0.9088 | val_acc=0.8042 | time=14.3s
2025-10-13 03:59:18,170 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.8776 | val_loss=0.9113 | val_acc=0.8037 | time=14.3s
2025-10-13 03:59:32,386 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.8768 | val_loss=0.8952 | val_acc=0.8132 | time=14.2s
2025-10-13 03:59:46,577 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.8747 | val_loss=0.8977 | val_acc=0.8147 | time=14.2s
2025-10-13 04:00:00,796 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.8740 | val_loss=0.9009 | val_acc=0.8074 | time=14.2s
2025-10-13 04:00:14,985 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.8755 | val_loss=0.8945 | val_acc=0.8168 | time=14.2s
2025-10-13 04:00:29,133 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.8745 | val_loss=0.8905 | val_acc=0.8157 | time=14.1s
2025-10-13 04:00:43,204 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.8727 | val_loss=0.9076 | val_acc=0.8071 | time=14.1s
2025-10-13 04:00:57,383 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.8727 | val_loss=0.9057 | val_acc=0.8056 | time=14.2s
2025-10-13 04:01:11,588 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.8731 | val_loss=0.9058 | val_acc=0.8057 | time=14.2s
2025-10-13 04:01:25,758 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.8727 | val_loss=0.9113 | val_acc=0.8080 | time=14.2s
2025-10-13 04:01:39,955 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.8709 | val_loss=0.8961 | val_acc=0.8106 | time=14.2s
2025-10-13 04:01:54,279 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.8704 | val_loss=0.9005 | val_acc=0.8119 | time=14.3s
2025-10-13 04:02:08,503 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.8696 | val_loss=0.9014 | val_acc=0.8113 | time=14.2s
2025-10-13 04:02:22,640 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.8694 | val_loss=0.8930 | val_acc=0.8134 | time=14.1s
2025-10-13 04:02:36,762 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.8706 | val_loss=0.9020 | val_acc=0.8078 | time=14.1s
2025-10-13 04:02:51,001 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.8674 | val_loss=0.9149 | val_acc=0.8043 | time=14.2s
2025-10-13 04:03:05,276 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.8684 | val_loss=0.9090 | val_acc=0.8065 | time=14.3s
2025-10-13 04:03:19,515 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.8667 | val_loss=0.8972 | val_acc=0.8148 | time=14.2s
2025-10-13 04:03:33,641 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.8680 | val_loss=0.9026 | val_acc=0.8097 | time=14.1s
2025-10-13 04:03:47,904 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.8682 | val_loss=0.8997 | val_acc=0.8077 | time=14.3s
2025-10-13 04:04:02,208 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.8664 | val_loss=0.9064 | val_acc=0.8087 | time=14.3s
2025-10-13 04:04:16,388 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.8651 | val_loss=0.9094 | val_acc=0.8096 | time=14.2s
2025-10-13 04:04:30,663 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.8651 | val_loss=0.8991 | val_acc=0.8144 | time=14.3s
2025-10-13 04:04:44,879 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.8641 | val_loss=0.9024 | val_acc=0.8105 | time=14.2s
2025-10-13 04:04:59,146 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.8659 | val_loss=0.9024 | val_acc=0.8082 | time=14.3s
2025-10-13 04:05:13,371 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.8631 | val_loss=0.9074 | val_acc=0.8081 | time=14.2s
2025-10-13 04:05:27,553 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.8641 | val_loss=0.9000 | val_acc=0.8122 | time=14.2s
2025-10-13 04:05:41,649 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.8614 | val_loss=0.9046 | val_acc=0.8126 | time=14.1s
2025-10-13 04:05:55,875 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.8640 | val_loss=0.9016 | val_acc=0.8126 | time=14.2s
2025-10-13 04:06:09,877 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.8618 | val_loss=0.9135 | val_acc=0.8029 | time=14.0s
2025-10-13 04:06:23,976 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.8615 | val_loss=0.9023 | val_acc=0.8085 | time=14.1s
2025-10-13 04:06:38,258 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.8621 | val_loss=0.9130 | val_acc=0.8061 | time=14.3s
2025-10-13 04:06:52,463 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.8606 | val_loss=0.8986 | val_acc=0.8144 | time=14.2s
2025-10-13 04:07:06,677 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.8608 | val_loss=0.9000 | val_acc=0.8105 | time=14.2s
2025-10-13 04:07:20,797 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.8635 | val_loss=0.8947 | val_acc=0.8119 | time=14.1s
2025-10-13 04:07:35,056 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.8603 | val_loss=0.8956 | val_acc=0.8123 | time=14.3s
2025-10-13 04:07:35,061 - INFO - _models.training_function_executor - Quantized model size: 75009 bytes.
2025-10-13 04:07:36,558 - INFO - _models.training_function_executor - Model: 14,474 parameters, 62.2KB storage
2025-10-13 04:07:36,558 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0794941077688835, 0.995046658681997, 0.971768481501091, 0.960602106009491, 0.9482268366439801, 0.9415255966493622, 0.9365356275886767, 0.9289503509676202, 0.9229634682490436, 0.9190571433624939, 0.9179573683084455, 0.9131942319836615, 0.9103774417414714, 0.9095795833338463, 0.9052090950265897, 0.9046505040791972, 0.9014979209209766, 0.9012089705901167, 0.9000523173291657, 0.8963160177690815, 0.8946280370006454, 0.8942197612899143, 0.8924471392554756, 0.891135736220276, 0.8886383042746088, 0.889453909365414, 0.8876368677987475, 0.8878969735184624, 0.885305193793661, 0.8857882934973547, 0.8843429199477614, 0.8844285705601121, 0.8838830809201818, 0.8817513823029375, 0.8823055745026512, 0.879806735119621, 0.8798006611726565, 0.8784190446378303, 0.8788460239919282, 0.8788497000567597, 0.8776086182247145, 0.8767982353624197, 0.8747158648669824, 0.874023021028974, 0.8755328293797183, 0.8745223025174921, 0.87272175495592, 0.8727000303355221, 0.8730576118473244, 0.8726637395353721, 0.870898730372231, 0.8704201314555292, 0.869604249110287, 0.8694327412304196, 0.8706176549164949, 0.8674257097437869, 0.8683748668334181, 0.8667499278865997, 0.8680277334087413, 0.8681545879067263, 0.8663721501952416, 0.865094441715804, 0.8651310290057717, 0.8641313861248415, 0.8658921689911242, 0.8630864216411785, 0.864147346619338, 0.8614116918072652, 0.8639770728289184, 0.8617930275433373, 0.8614784718123106, 0.8620783811083698, 0.8605693127043313, 0.8607874933263827, 0.863486625022057, 0.8602533904789292], 'val_losses': [0.9545094593029403, 0.9395336640394356, 0.9608175733684451, 0.9228672020744936, 0.9141756450541586, 0.9171248206651665, 0.9142042296642935, 0.9337253257616609, 0.9456244552097914, 0.9123476890988562, 0.8970515975219452, 0.9080835022958041, 0.9239954821163013, 0.9059826072630116, 0.9013550372694521, 0.899218198174065, 0.9026967280387544, 0.9469858896160693, 0.9080391023849164, 0.9029643671221361, 0.8897715072177864, 0.9049290885531406, 0.8977501255505395, 0.8965298671550503, 0.8982312042979373, 0.8891845719356156, 0.912653894306773, 0.9103726905085717, 0.9298620162454151, 0.8964708448916747, 0.8928282382315508, 0.9227816471070479, 0.8979592960031875, 0.9183592827202434, 0.8906063311451333, 0.89917119053389, 0.9046129217755348, 0.8955799510606653, 0.924529297392728, 0.9088311741140951, 0.9112701097859925, 0.8952493019399419, 0.8977400357171628, 0.9008776042942905, 0.8945307956736614, 0.890479947538446, 0.9075853051444973, 0.9057005069286705, 0.9058426383453773, 0.9112661396409817, 0.896101362124414, 0.9004878197928012, 0.9013723272270867, 0.8930062893015295, 0.9020430522654329, 0.9148881060283502, 0.9089594309798145, 0.8971988180111787, 0.9026419263558659, 0.8996885854295805, 0.9064148830124078, 0.9094106190514223, 0.8990762058279086, 0.9023886996839361, 0.9024394849066889, 0.9073688608180571, 0.899975357916875, 0.9045678758521075, 0.9015593113580449, 0.9134570569644911, 0.9022570786294213, 0.9130110815767228, 0.8986046239551148, 0.8999723621628106, 0.894684699435396, 0.8955827371031828], 'val_acc': [0.7707385369268464, 0.7820266013300665, 0.7736261813090655, 0.7921771088554428, 0.7978648932446623, 0.7938396919845992, 0.7993524676233812, 0.7876268813440672, 0.782201610080504, 0.8008400420021001, 0.8102030101505076, 0.7974273713685684, 0.7990899544977249, 0.8018025901295065, 0.8059152957647883, 0.8084529226461323, 0.8071403570178509, 0.7848267413370669, 0.8032901645082254, 0.8073153657682884, 0.8123031151557578, 0.8089779488974449, 0.8113405670283514, 0.8114280714035702, 0.8119530976548828, 0.8139656982849143, 0.8028526426321316, 0.8018025901295065, 0.7955022751137557, 0.8124781239061953, 0.8114280714035702, 0.7997024851242562, 0.8102905145257263, 0.7998774938746938, 0.8134406720336017, 0.8103780189009451, 0.8067028351417571, 0.8121281064053203, 0.8046027301365068, 0.804165208260413, 0.8037276863843192, 0.8131781589079454, 0.8146657332866644, 0.8074028701435072, 0.8167658382919146, 0.8157157857892895, 0.8070528526426322, 0.8055652782639132, 0.805652782639132, 0.8080154007700385, 0.8105530276513826, 0.811865593279664, 0.8112530626531327, 0.8134406720336017, 0.807840392019601, 0.8043402170108506, 0.8065278263913196, 0.8147532376618831, 0.809677983899195, 0.8076653832691635, 0.8087154357717886, 0.8095904795239762, 0.8144032201610081, 0.8104655232761638, 0.808190409520476, 0.8081029051452573, 0.812215610780539, 0.8125656282814141, 0.8125656282814141, 0.8029401470073504, 0.8085404270213511, 0.8060903045152258, 0.8144032201610081, 0.8104655232761638, 0.811865593279664, 0.8123031151557578], 'model_size_bytes': 75009, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.001412035543062636, 'batch_size': 8, 'epochs': 76, 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'hidden_size': 26, 'd_model': 30, 't_pooled': 128, 'label_smoothing': 0.17323522915498707, 'use_focal_loss': False, 'focal_gamma': 3.540362888980228, 'grad_clip_norm': 0.10292247147901225, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 14474, 'model_storage_size_kb': 62.192968750000006, 'model_size_validation': 'PASS'}
2025-10-13 04:07:36,558 - INFO - _models.training_function_executor - BO Objective: base=0.8123, size_penalty=0.0000, final=0.8123
2025-10-13 04:07:36,558 - INFO - _models.training_function_executor - Model: 14,474 parameters, 62.2KB (PASS 256KB limit)
2025-10-13 04:07:36,558 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 1085.570s
2025-10-13 04:07:36,559 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8123
2025-10-13 04:07:36,559 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-13 04:07:36,560 - INFO - bo.run_bo - Recorded observation #1: hparams={'lr': 0.001412035543062636, 'batch_size': 8, 'epochs': np.int64(76), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'hidden_size': np.int64(26), 'd_model': np.int64(30), 't_pooled': 128, 'label_smoothing': 0.17323522915498707, 'use_focal_loss': False, 'focal_gamma': 3.540362888980228, 'grad_clip_norm': 0.10292247147901225, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, value=0.8123
2025-10-13 04:07:36,560 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 1: {'lr': 0.001412035543062636, 'batch_size': 8, 'epochs': np.int64(76), 'weight_decay': 0.0002481040974867812, 'dropout': 0.07800932022121827, 'hidden_size': np.int64(26), 'd_model': np.int64(30), 't_pooled': 128, 'label_smoothing': 0.17323522915498707, 'use_focal_loss': False, 'focal_gamma': 3.540362888980228, 'grad_clip_norm': 0.10292247147901225, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True} -> 0.8123
2025-10-13 04:07:36,560 - INFO - bo.run_bo - üîçBO Trial 2: Initial random exploration
2025-10-13 04:07:36,560 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 04:07:36,560 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 2 (NaN monitoring active)
2025-10-13 04:07:36,560 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 04:07:36,560 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 04:07:36,560 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 3.1261029103110605e-05, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'hidden_size': 17, 'd_model': 23, 't_pooled': 192, 'label_smoothing': 0.018121286906564164, 'use_focal_loss': False, 'focal_gamma': 1.9123099563358141, 'grad_clip_norm': 4.916154429033941, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 04:07:36,561 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 3.1261029103110605e-05, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'hidden_size': 17, 'd_model': 23, 't_pooled': 192, 'label_smoothing': 0.018121286906564164, 'use_focal_loss': False, 'focal_gamma': 1.9123099563358141, 'grad_clip_norm': 4.916154429033941, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 04:07:46,542 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3652 | val_loss=1.1749 | val_acc=0.5673 | time=10.0s
2025-10-13 04:07:53,728 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.1301 | val_loss=1.0280 | val_acc=0.6069 | time=7.2s
2025-10-13 04:08:00,894 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.0111 | val_loss=0.9234 | val_acc=0.6324 | time=7.2s
2025-10-13 04:08:08,100 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9354 | val_loss=0.8503 | val_acc=0.6652 | time=7.2s
2025-10-13 04:08:15,284 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.8906 | val_loss=0.8138 | val_acc=0.7082 | time=7.2s
2025-10-13 04:08:22,480 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.8479 | val_loss=0.7787 | val_acc=0.7182 | time=7.2s
2025-10-13 04:08:29,637 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8133 | val_loss=0.7399 | val_acc=0.7363 | time=7.2s
2025-10-13 04:08:36,853 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.7918 | val_loss=0.7217 | val_acc=0.7404 | time=7.2s
2025-10-13 04:08:44,011 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.7728 | val_loss=0.7003 | val_acc=0.7485 | time=7.2s
2025-10-13 04:08:51,194 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.7632 | val_loss=0.6944 | val_acc=0.7489 | time=7.2s
2025-10-13 04:08:58,374 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.7442 | val_loss=0.6794 | val_acc=0.7539 | time=7.2s
2025-10-13 04:09:05,562 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.7370 | val_loss=0.6719 | val_acc=0.7620 | time=7.2s
2025-10-13 04:09:12,751 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.7263 | val_loss=0.6602 | val_acc=0.7653 | time=7.2s
2025-10-13 04:09:19,918 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.7174 | val_loss=0.6565 | val_acc=0.7658 | time=7.2s
2025-10-13 04:09:27,097 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.7083 | val_loss=0.6438 | val_acc=0.7687 | time=7.2s
2025-10-13 04:09:34,255 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7006 | val_loss=0.6447 | val_acc=0.7688 | time=7.2s
2025-10-13 04:09:41,453 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.6920 | val_loss=0.6420 | val_acc=0.7744 | time=7.2s
2025-10-13 04:09:48,626 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.6819 | val_loss=0.6313 | val_acc=0.7766 | time=7.2s
2025-10-13 04:09:55,803 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.6751 | val_loss=0.6291 | val_acc=0.7749 | time=7.2s
2025-10-13 04:10:02,975 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.6747 | val_loss=0.6181 | val_acc=0.7824 | time=7.2s
2025-10-13 04:10:10,155 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.6707 | val_loss=0.6237 | val_acc=0.7772 | time=7.2s
2025-10-13 04:10:17,304 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.6619 | val_loss=0.6081 | val_acc=0.7854 | time=7.1s
2025-10-13 04:10:24,454 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.6587 | val_loss=0.6168 | val_acc=0.7802 | time=7.1s
2025-10-13 04:10:31,618 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.6550 | val_loss=0.6146 | val_acc=0.7809 | time=7.2s
2025-10-13 04:10:38,815 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.6506 | val_loss=0.6080 | val_acc=0.7843 | time=7.2s
2025-10-13 04:10:46,028 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.6509 | val_loss=0.6017 | val_acc=0.7881 | time=7.2s
2025-10-13 04:10:46,031 - INFO - _models.training_function_executor - Quantized model size: 54337 bytes.
2025-10-13 04:10:47,149 - INFO - _models.training_function_executor - Model: 9,239 parameters, 39.7KB storage
2025-10-13 04:10:47,150 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.365236666451228, 1.1300556232013776, 1.0110735203738308, 0.9354218553007171, 0.8905569356890629, 0.8479478009146829, 0.8132829570065105, 0.7918267530559617, 0.7728174725194723, 0.7632170271051485, 0.7441621125474609, 0.7370043600465103, 0.7262977046965718, 0.7174313734326281, 0.7083049693181042, 0.7006001626804736, 0.691971490985662, 0.6818974160171698, 0.6751315459050955, 0.6747116957995538, 0.6706737259550866, 0.6619387967710859, 0.6587041991185508, 0.6550215119649199, 0.6505560910666285, 0.6508660224149976], 'val_losses': [1.1749189731162621, 1.028026732941128, 0.9233503947526707, 0.8502729871617692, 0.8138233445973341, 0.7787336027200797, 0.739891896892103, 0.721659808714656, 0.7002526080228667, 0.6943651620516378, 0.6794393341108181, 0.6719304016723806, 0.6601552112059949, 0.6565006420584797, 0.6438286068934346, 0.6447397912762822, 0.6419624842711166, 0.6313071987680676, 0.629148351445163, 0.6181299427734792, 0.6236576554363826, 0.6081183026481184, 0.616780594017358, 0.6145780207625127, 0.6080499220382596, 0.6016675365588696], 'val_acc': [0.5672908645432272, 0.6069303465173259, 0.6323941197059852, 0.6652082604130206, 0.7081729086454323, 0.7182359117955898, 0.7363493174658733, 0.7403745187259363, 0.7485124256212811, 0.7489499474973749, 0.7538501925096255, 0.7619880994049703, 0.7653132656632832, 0.7658382919145957, 0.7687259362968148, 0.7688134406720336, 0.7744137206860343, 0.7766013300665033, 0.7749387469373469, 0.7823766188309416, 0.7772138606930347, 0.7853517675883794, 0.7801890094504725, 0.7808890444522226, 0.7843017150857543, 0.788064403220161], 'model_size_bytes': 54337, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 3.1261029103110605e-05, 'batch_size': 16, 'epochs': 26, 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'hidden_size': 17, 'd_model': 23, 't_pooled': 192, 'label_smoothing': 0.018121286906564164, 'use_focal_loss': False, 'focal_gamma': 1.9123099563358141, 'grad_clip_norm': 4.916154429033941, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 9239, 'model_storage_size_kb': 39.698828125000006, 'model_size_validation': 'PASS'}
2025-10-13 04:10:47,150 - INFO - _models.training_function_executor - BO Objective: base=0.7881, size_penalty=0.0000, final=0.7881
2025-10-13 04:10:47,150 - INFO - _models.training_function_executor - Model: 9,239 parameters, 39.7KB (PASS 256KB limit)
2025-10-13 04:10:47,150 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 190.589s
2025-10-13 04:10:47,151 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7881
2025-10-13 04:10:47,151 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.000s
2025-10-13 04:10:47,151 - INFO - bo.run_bo - Recorded observation #2: hparams={'lr': 3.1261029103110605e-05, 'batch_size': 16, 'epochs': np.int64(26), 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'hidden_size': np.int64(17), 'd_model': np.int64(23), 't_pooled': 192, 'label_smoothing': 0.018121286906564164, 'use_focal_loss': False, 'focal_gamma': 1.9123099563358141, 'grad_clip_norm': 4.916154429033941, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, value=0.7881
2025-10-13 04:10:47,151 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 2: {'lr': 3.1261029103110605e-05, 'batch_size': 16, 'epochs': np.int64(26), 'weight_decay': 1.0672476836323728e-06, 'dropout': 0.01153121252070788, 'hidden_size': np.int64(17), 'd_model': np.int64(23), 't_pooled': 192, 'label_smoothing': 0.018121286906564164, 'use_focal_loss': False, 'focal_gamma': 1.9123099563358141, 'grad_clip_norm': 4.916154429033941, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True} -> 0.7881
2025-10-13 04:10:47,152 - INFO - bo.run_bo - üîçBO Trial 3: Initial random exploration
2025-10-13 04:10:47,152 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 04:10:47,152 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 3 (NaN monitoring active)
2025-10-13 04:10:47,152 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 04:10:47,152 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 04:10:47,152 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.0859297527739004e-05, 'batch_size': 32, 'epochs': 18, 'weight_decay': 0.0017123375973164003, 'dropout': 0.15230688458668537, 'hidden_size': 28, 'd_model': 9, 't_pooled': 320, 'label_smoothing': 0.08803049874792028, 'use_focal_loss': True, 'focal_gamma': 2.4758845505563514, 'grad_clip_norm': 0.171942605576092, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 04:10:47,153 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.0859297527739004e-05, 'batch_size': 32, 'epochs': 18, 'weight_decay': 0.0017123375973164003, 'dropout': 0.15230688458668537, 'hidden_size': 28, 'd_model': 9, 't_pooled': 320, 'label_smoothing': 0.08803049874792028, 'use_focal_loss': True, 'focal_gamma': 2.4758845505563514, 'grad_clip_norm': 0.171942605576092, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 04:10:55,593 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8961 | val_loss=0.8735 | val_acc=0.3137 | time=8.4s
2025-10-13 04:11:01,191 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.8556 | val_loss=0.8316 | val_acc=0.3158 | time=5.6s
2025-10-13 04:11:06,799 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.8034 | val_loss=0.7641 | val_acc=0.4530 | time=5.6s
2025-10-13 04:11:12,394 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.7247 | val_loss=0.6743 | val_acc=0.5741 | time=5.6s
2025-10-13 04:11:17,995 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.6377 | val_loss=0.5921 | val_acc=0.5991 | time=5.6s
2025-10-13 04:11:23,595 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5713 | val_loss=0.5323 | val_acc=0.6090 | time=5.6s
2025-10-13 04:11:29,198 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5248 | val_loss=0.4924 | val_acc=0.6124 | time=5.6s
2025-10-13 04:11:34,801 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4936 | val_loss=0.4596 | val_acc=0.6218 | time=5.6s
2025-10-13 04:11:40,405 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4673 | val_loss=0.4388 | val_acc=0.6284 | time=5.6s
2025-10-13 04:11:45,996 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4498 | val_loss=0.4180 | val_acc=0.6443 | time=5.6s
2025-10-13 04:11:51,602 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.4368 | val_loss=0.4052 | val_acc=0.6490 | time=5.6s
2025-10-13 04:11:57,203 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.4297 | val_loss=0.3959 | val_acc=0.6533 | time=5.6s
2025-10-13 04:12:02,792 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.4219 | val_loss=0.3890 | val_acc=0.6621 | time=5.6s
2025-10-13 04:12:08,402 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.4131 | val_loss=0.3822 | val_acc=0.6633 | time=5.6s
2025-10-13 04:12:14,005 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.4095 | val_loss=0.3769 | val_acc=0.6685 | time=5.6s
2025-10-13 04:12:19,613 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.4050 | val_loss=0.3750 | val_acc=0.6735 | time=5.6s
2025-10-13 04:12:25,205 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.4000 | val_loss=0.3672 | val_acc=0.6754 | time=5.6s
2025-10-13 04:12:30,803 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3957 | val_loss=0.3630 | val_acc=0.6810 | time=5.6s
2025-10-13 04:12:30,807 - INFO - _models.training_function_executor - Quantized model size: 61441 bytes.
2025-10-13 04:12:31,889 - INFO - _models.training_function_executor - Model: 11,042 parameters, 47.4KB storage
2025-10-13 04:12:31,889 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8961020735205576, 0.8556147688829611, 0.803404671519129, 0.7246522325546457, 0.637667861442112, 0.5713439068887716, 0.5248476877302651, 0.49355925301968073, 0.46725205692704175, 0.44982916380627236, 0.4368143763248429, 0.42968946191494306, 0.4219036924701326, 0.41309129551319046, 0.40946062571066927, 0.40497531440652745, 0.4000011702225598, 0.3957238954745851], 'val_losses': [0.8734553805964786, 0.8316327270862311, 0.7640944984687722, 0.6742985803929917, 0.5921253982564975, 0.532324307921219, 0.4923718992880186, 0.45964871303660493, 0.43883290540558667, 0.4180253640020649, 0.40516328026166026, 0.3959006788975132, 0.38898313793428385, 0.38220191271020515, 0.3768653661836725, 0.3749544083508821, 0.3672005135695084, 0.3629941006911815], 'val_acc': [0.31370318515925794, 0.3158032901645082, 0.45301015050752536, 0.5741162058102905, 0.5991424571228562, 0.6090304515225762, 0.6124431221561079, 0.6218060903045153, 0.6283689184459222, 0.6442947147357367, 0.6490199509975498, 0.6533076653832691, 0.662145607280364, 0.6632831641582079, 0.6685334266713335, 0.6735211760588029, 0.6754462723136156, 0.6809590479523976], 'model_size_bytes': 61441, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.0859297527739004e-05, 'batch_size': 32, 'epochs': 18, 'weight_decay': 0.0017123375973164003, 'dropout': 0.15230688458668537, 'hidden_size': 28, 'd_model': 9, 't_pooled': 320, 'label_smoothing': 0.08803049874792028, 'use_focal_loss': True, 'focal_gamma': 2.4758845505563514, 'grad_clip_norm': 0.171942605576092, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 11042, 'model_storage_size_kb': 47.44609375, 'model_size_validation': 'PASS'}
2025-10-13 04:12:31,890 - INFO - _models.training_function_executor - BO Objective: base=0.6810, size_penalty=0.0000, final=0.6810
2025-10-13 04:12:31,890 - INFO - _models.training_function_executor - Model: 11,042 parameters, 47.4KB (PASS 256KB limit)
2025-10-13 04:12:31,890 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 104.738s
2025-10-13 04:12:31,971 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.6810
2025-10-13 04:12:31,971 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.078s
2025-10-13 04:12:31,971 - INFO - bo.run_bo - Recorded observation #3: hparams={'lr': 1.0859297527739004e-05, 'batch_size': 32, 'epochs': np.int64(18), 'weight_decay': 0.0017123375973164003, 'dropout': 0.15230688458668537, 'hidden_size': np.int64(28), 'd_model': np.int64(9), 't_pooled': 320, 'label_smoothing': 0.08803049874792028, 'use_focal_loss': True, 'focal_gamma': 2.4758845505563514, 'grad_clip_norm': 0.171942605576092, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}, value=0.6810
2025-10-13 04:12:31,971 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 3: {'lr': 1.0859297527739004e-05, 'batch_size': 32, 'epochs': np.int64(18), 'weight_decay': 0.0017123375973164003, 'dropout': 0.15230688458668537, 'hidden_size': np.int64(28), 'd_model': np.int64(9), 't_pooled': 320, 'label_smoothing': 0.08803049874792028, 'use_focal_loss': True, 'focal_gamma': 2.4758845505563514, 'grad_clip_norm': 0.171942605576092, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True} -> 0.6810
2025-10-13 04:12:31,971 - INFO - bo.run_bo - üîçBO Trial 4: Using RF surrogate + Expected Improvement
2025-10-13 04:12:31,971 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 04:12:31,971 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 4 (NaN monitoring active)
2025-10-13 04:12:31,971 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 04:12:31,971 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 04:12:31,971 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00025330746540014483, 'batch_size': 8, 'epochs': 43, 'weight_decay': 5.101503248952788e-05, 'dropout': 0.22762305349756756, 'hidden_size': 22, 'd_model': 15, 't_pooled': 192, 'label_smoothing': 0.1671960604953604, 'use_focal_loss': True, 'focal_gamma': 1.7214393940144554, 'grad_clip_norm': 3.798648010152272, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 04:12:31,972 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00025330746540014483, 'batch_size': 8, 'epochs': 43, 'weight_decay': 5.101503248952788e-05, 'dropout': 0.22762305349756756, 'hidden_size': 22, 'd_model': 15, 't_pooled': 192, 'label_smoothing': 0.1671960604953604, 'use_focal_loss': True, 'focal_gamma': 1.7214393940144554, 'grad_clip_norm': 3.798648010152272, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 04:12:49,559 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.6232 | val_loss=0.4760 | val_acc=0.7189 | time=17.6s
2025-10-13 04:13:04,424 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.4882 | val_loss=0.3995 | val_acc=0.7484 | time=14.9s
2025-10-13 04:13:19,364 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4398 | val_loss=0.3750 | val_acc=0.7705 | time=14.9s
2025-10-13 04:13:34,205 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4207 | val_loss=0.3525 | val_acc=0.7822 | time=14.8s
2025-10-13 04:13:49,106 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4058 | val_loss=0.3463 | val_acc=0.7808 | time=14.9s
2025-10-13 04:14:04,026 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3957 | val_loss=0.3378 | val_acc=0.7831 | time=14.9s
2025-10-13 04:14:18,972 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3908 | val_loss=0.3421 | val_acc=0.7834 | time=14.9s
2025-10-13 04:14:33,902 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3829 | val_loss=0.3371 | val_acc=0.7889 | time=14.9s
2025-10-13 04:14:48,580 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3750 | val_loss=0.3298 | val_acc=0.7903 | time=14.7s
2025-10-13 04:15:03,440 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3707 | val_loss=0.3366 | val_acc=0.7884 | time=14.9s
2025-10-13 04:15:18,218 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3654 | val_loss=0.3207 | val_acc=0.7960 | time=14.8s
2025-10-13 04:15:32,999 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3604 | val_loss=0.3345 | val_acc=0.7918 | time=14.8s
2025-10-13 04:15:47,923 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3578 | val_loss=0.3133 | val_acc=0.7981 | time=14.9s
2025-10-13 04:16:02,711 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3563 | val_loss=0.3290 | val_acc=0.7894 | time=14.8s
2025-10-13 04:16:17,446 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3527 | val_loss=0.3159 | val_acc=0.7991 | time=14.7s
2025-10-13 04:16:32,441 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3501 | val_loss=0.3151 | val_acc=0.8015 | time=15.0s
2025-10-13 04:16:47,343 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3483 | val_loss=0.3424 | val_acc=0.7827 | time=14.9s
2025-10-13 04:17:02,296 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3414 | val_loss=0.3202 | val_acc=0.8007 | time=15.0s
2025-10-13 04:17:17,151 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3401 | val_loss=0.3341 | val_acc=0.7932 | time=14.9s
2025-10-13 04:17:31,916 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3399 | val_loss=0.3139 | val_acc=0.8009 | time=14.8s
2025-10-13 04:17:46,816 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3361 | val_loss=0.3135 | val_acc=0.8034 | time=14.9s
2025-10-13 04:18:01,608 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3337 | val_loss=0.3126 | val_acc=0.7980 | time=14.8s
2025-10-13 04:18:16,475 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3333 | val_loss=0.3308 | val_acc=0.7949 | time=14.9s
2025-10-13 04:18:31,317 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3294 | val_loss=0.3110 | val_acc=0.7997 | time=14.8s
2025-10-13 04:18:46,182 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3285 | val_loss=0.3338 | val_acc=0.7910 | time=14.9s
2025-10-13 04:19:00,806 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.3249 | val_loss=0.3045 | val_acc=0.8047 | time=14.6s
2025-10-13 04:19:15,689 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.3258 | val_loss=0.3093 | val_acc=0.8022 | time=14.9s
2025-10-13 04:19:30,521 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.3223 | val_loss=0.3097 | val_acc=0.8029 | time=14.8s
2025-10-13 04:19:45,461 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.3222 | val_loss=0.3027 | val_acc=0.8049 | time=14.9s
2025-10-13 04:20:00,300 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.3197 | val_loss=0.3211 | val_acc=0.7929 | time=14.8s
2025-10-13 04:20:15,079 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.3195 | val_loss=0.3250 | val_acc=0.7940 | time=14.8s
2025-10-13 04:20:29,979 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.3171 | val_loss=0.3140 | val_acc=0.8034 | time=14.9s
2025-10-13 04:20:44,887 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.3169 | val_loss=0.3170 | val_acc=0.7973 | time=14.9s
2025-10-13 04:20:59,786 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.3134 | val_loss=0.3142 | val_acc=0.7992 | time=14.9s
2025-10-13 04:21:14,632 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.3133 | val_loss=0.3126 | val_acc=0.7976 | time=14.8s
2025-10-13 04:21:29,561 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.3117 | val_loss=0.3075 | val_acc=0.7990 | time=14.9s
2025-10-13 04:21:44,334 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.3126 | val_loss=0.3059 | val_acc=0.8040 | time=14.8s
2025-10-13 04:21:59,188 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.3093 | val_loss=0.3124 | val_acc=0.7999 | time=14.9s
2025-10-13 04:22:14,049 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.3078 | val_loss=0.2986 | val_acc=0.8080 | time=14.9s
2025-10-13 04:22:28,974 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.3079 | val_loss=0.3051 | val_acc=0.8029 | time=14.9s
2025-10-13 04:22:43,902 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.3069 | val_loss=0.3183 | val_acc=0.7971 | time=14.9s
2025-10-13 04:22:58,765 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.3066 | val_loss=0.3197 | val_acc=0.7937 | time=14.9s
2025-10-13 04:23:13,661 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.3046 | val_loss=0.3015 | val_acc=0.8038 | time=14.9s
2025-10-13 04:23:13,664 - INFO - _models.training_function_executor - Quantized model size: 56129 bytes.
2025-10-13 04:23:14,745 - INFO - _models.training_function_executor - Model: 9,795 parameters, 42.1KB storage
2025-10-13 04:23:14,745 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.6231505752097467, 0.48818751172373503, 0.43976190399624976, 0.42065310431986597, 0.40583831363213846, 0.39573050035104435, 0.3908240590003307, 0.38286564125632816, 0.37503803987870965, 0.37074114284668824, 0.3653841699464758, 0.36037269899524466, 0.35781996622994555, 0.35629311548223236, 0.35269344349006776, 0.35013839175665834, 0.3482727506290893, 0.34144256964533226, 0.3401146458574669, 0.33987918338846934, 0.3361207275274237, 0.3336720811569849, 0.3333166731312209, 0.3293941142431946, 0.3284749414900231, 0.32493702593035567, 0.32580631883605654, 0.3223131709553805, 0.32218002351434455, 0.3197074195817973, 0.3194706401917112, 0.31712530813635303, 0.3168744640105388, 0.31342572122267887, 0.3133043745629774, 0.311689293199787, 0.31262788917128703, 0.309257213138422, 0.3078014713481895, 0.3079199849964975, 0.3068990013250833, 0.30659115392751246, 0.3046403096178413], 'val_losses': [0.4759527783805689, 0.39954718839707054, 0.37501788605102343, 0.35251599962024116, 0.3463070362266499, 0.3378445513463016, 0.3420950834882877, 0.3371291381688668, 0.3297729916325557, 0.33658492766610176, 0.32071701173974076, 0.3345465921791317, 0.31330469718002796, 0.3290478921292293, 0.31590729666300743, 0.3151057040423812, 0.34237883774851186, 0.3201557202274446, 0.3340932800224925, 0.3139489266837565, 0.31350911879441956, 0.3125860103760351, 0.3308239294920804, 0.31096708704415926, 0.3338110200522254, 0.30446257943005195, 0.3092596053002721, 0.309707519523656, 0.302660018921493, 0.32112651130156494, 0.32500967775211703, 0.31404172706049055, 0.3169662431364903, 0.3141976375906022, 0.3126204589321182, 0.30751812643324905, 0.3058671782084662, 0.31236088752751795, 0.29857543175195767, 0.3050833890976702, 0.31834674771193194, 0.31974665995453844, 0.30147301034834323], 'val_acc': [0.7189359467973399, 0.7484249212460623, 0.7704760238011901, 0.782201610080504, 0.7808015400770039, 0.7830766538326916, 0.7834266713335667, 0.7889394469723486, 0.79025201260063, 0.7884144207210361, 0.7960273013650683, 0.7918270913545677, 0.7981274063703185, 0.7893769688484424, 0.7990899544977249, 0.8015400770038502, 0.7827266363318166, 0.8006650332516626, 0.7932271613580679, 0.8009275463773189, 0.8033776688834442, 0.797952397619881, 0.7948897444872244, 0.7997024851242562, 0.7910395519775989, 0.8046902345117256, 0.8021526076303815, 0.8029401470073504, 0.8048652432621631, 0.7928771438571929, 0.7940147007350368, 0.8033776688834442, 0.7972523626181309, 0.7991774588729437, 0.797602380119006, 0.7990024501225061, 0.8039901995099755, 0.7998774938746938, 0.8080154007700385, 0.8028526426321316, 0.7970773538676934, 0.7936646832341617, 0.803815190759538], 'model_size_bytes': 56129, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00025330746540014483, 'batch_size': 8, 'epochs': 43, 'weight_decay': 5.101503248952788e-05, 'dropout': 0.22762305349756756, 'hidden_size': 22, 'd_model': 15, 't_pooled': 192, 'label_smoothing': 0.1671960604953604, 'use_focal_loss': True, 'focal_gamma': 1.7214393940144554, 'grad_clip_norm': 3.798648010152272, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 9795, 'model_storage_size_kb': 42.087890625, 'model_size_validation': 'PASS'}
2025-10-13 04:23:14,745 - INFO - _models.training_function_executor - BO Objective: base=0.8038, size_penalty=0.0000, final=0.8038
2025-10-13 04:23:14,745 - INFO - _models.training_function_executor - Model: 9,795 parameters, 42.1KB (PASS 256KB limit)
2025-10-13 04:23:14,745 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 642.774s
2025-10-13 04:23:14,821 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8038
2025-10-13 04:23:14,821 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.075s
2025-10-13 04:23:14,821 - INFO - bo.run_bo - Recorded observation #4: hparams={'lr': 0.00025330746540014483, 'batch_size': np.int64(8), 'epochs': np.int64(43), 'weight_decay': 5.101503248952788e-05, 'dropout': 0.22762305349756756, 'hidden_size': np.int64(22), 'd_model': np.int64(15), 't_pooled': np.int64(192), 'label_smoothing': 0.1671960604953604, 'use_focal_loss': np.True_, 'focal_gamma': 1.7214393940144554, 'grad_clip_norm': 3.798648010152272, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.8038
2025-10-13 04:23:14,821 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 4: {'lr': 0.00025330746540014483, 'batch_size': np.int64(8), 'epochs': np.int64(43), 'weight_decay': 5.101503248952788e-05, 'dropout': 0.22762305349756756, 'hidden_size': np.int64(22), 'd_model': np.int64(15), 't_pooled': np.int64(192), 'label_smoothing': 0.1671960604953604, 'use_focal_loss': np.True_, 'focal_gamma': 1.7214393940144554, 'grad_clip_norm': 3.798648010152272, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.8038
2025-10-13 04:23:14,821 - INFO - bo.run_bo - üîçBO Trial 5: Using RF surrogate + Expected Improvement
2025-10-13 04:23:14,821 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 04:23:14,821 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 5 (NaN monitoring active)
2025-10-13 04:23:14,821 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 04:23:14,821 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 04:23:14,821 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00023077002725172647, 'batch_size': 16, 'epochs': 36, 'weight_decay': 4.017117247601545e-05, 'dropout': 0.2926667915506569, 'hidden_size': 17, 'd_model': 31, 't_pooled': 128, 'label_smoothing': 0.007582341221540158, 'use_focal_loss': True, 'focal_gamma': 2.475531769964284, 'grad_clip_norm': 3.6630588567435485, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 04:23:14,822 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00023077002725172647, 'batch_size': 16, 'epochs': 36, 'weight_decay': 4.017117247601545e-05, 'dropout': 0.2926667915506569, 'hidden_size': 17, 'd_model': 31, 't_pooled': 128, 'label_smoothing': 0.007582341221540158, 'use_focal_loss': True, 'focal_gamma': 2.475531769964284, 'grad_clip_norm': 3.6630588567435485, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 04:23:25,024 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.4294 | val_loss=0.2845 | val_acc=0.7326 | time=10.2s
2025-10-13 04:23:32,446 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.3108 | val_loss=0.2483 | val_acc=0.7640 | time=7.4s
2025-10-13 04:23:39,906 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.2760 | val_loss=0.2170 | val_acc=0.7812 | time=7.5s
2025-10-13 04:23:47,341 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.2628 | val_loss=0.2115 | val_acc=0.7814 | time=7.4s
2025-10-13 04:23:54,801 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.2483 | val_loss=0.2011 | val_acc=0.7886 | time=7.5s
2025-10-13 04:24:02,253 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.2414 | val_loss=0.1975 | val_acc=0.7906 | time=7.5s
2025-10-13 04:24:09,732 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.2326 | val_loss=0.1937 | val_acc=0.7944 | time=7.5s
2025-10-13 04:24:17,165 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.2293 | val_loss=0.1895 | val_acc=0.7959 | time=7.4s
2025-10-13 04:24:24,584 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.2250 | val_loss=0.1958 | val_acc=0.7833 | time=7.4s
2025-10-13 04:24:31,967 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.2219 | val_loss=0.2021 | val_acc=0.7854 | time=7.4s
2025-10-13 04:24:39,444 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.2158 | val_loss=0.1877 | val_acc=0.8008 | time=7.5s
2025-10-13 04:24:46,913 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.2115 | val_loss=0.1791 | val_acc=0.7986 | time=7.5s
2025-10-13 04:24:54,376 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.2102 | val_loss=0.1854 | val_acc=0.7953 | time=7.5s
2025-10-13 04:25:01,848 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.2062 | val_loss=0.1843 | val_acc=0.7982 | time=7.5s
2025-10-13 04:25:09,304 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.2046 | val_loss=0.1784 | val_acc=0.7981 | time=7.5s
2025-10-13 04:25:16,739 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.2034 | val_loss=0.1882 | val_acc=0.7989 | time=7.4s
2025-10-13 04:25:24,190 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.2009 | val_loss=0.1783 | val_acc=0.8015 | time=7.5s
2025-10-13 04:25:31,541 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.1976 | val_loss=0.1765 | val_acc=0.8047 | time=7.4s
2025-10-13 04:25:39,037 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.1974 | val_loss=0.1751 | val_acc=0.8054 | time=7.5s
2025-10-13 04:25:46,480 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.1946 | val_loss=0.1732 | val_acc=0.8027 | time=7.4s
2025-10-13 04:25:53,858 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.1940 | val_loss=0.1753 | val_acc=0.8043 | time=7.4s
2025-10-13 04:26:01,313 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.1907 | val_loss=0.1668 | val_acc=0.8089 | time=7.5s
2025-10-13 04:26:08,758 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.1900 | val_loss=0.1715 | val_acc=0.8062 | time=7.4s
2025-10-13 04:26:16,153 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.1874 | val_loss=0.1660 | val_acc=0.8095 | time=7.4s
2025-10-13 04:26:23,619 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.1851 | val_loss=0.1810 | val_acc=0.7949 | time=7.5s
2025-10-13 04:26:31,122 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.1857 | val_loss=0.1745 | val_acc=0.8023 | time=7.5s
2025-10-13 04:26:38,555 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.1839 | val_loss=0.1664 | val_acc=0.8100 | time=7.4s
2025-10-13 04:26:45,964 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.1831 | val_loss=0.1683 | val_acc=0.8086 | time=7.4s
2025-10-13 04:26:53,452 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.1812 | val_loss=0.1673 | val_acc=0.8071 | time=7.5s
2025-10-13 04:27:00,931 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.1803 | val_loss=0.1623 | val_acc=0.8115 | time=7.5s
2025-10-13 04:27:08,410 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.1798 | val_loss=0.1644 | val_acc=0.8074 | time=7.5s
2025-10-13 04:27:15,901 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.1790 | val_loss=0.1634 | val_acc=0.8116 | time=7.5s
2025-10-13 04:27:23,363 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.1775 | val_loss=0.1641 | val_acc=0.8081 | time=7.5s
2025-10-13 04:27:30,842 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.1776 | val_loss=0.1640 | val_acc=0.8099 | time=7.5s
2025-10-13 04:27:38,331 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.1771 | val_loss=0.1607 | val_acc=0.8123 | time=7.5s
2025-10-13 04:27:45,751 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.1749 | val_loss=0.1642 | val_acc=0.8094 | time=7.4s
2025-10-13 04:27:45,755 - INFO - _models.training_function_executor - Quantized model size: 59073 bytes.
2025-10-13 04:27:46,850 - INFO - _models.training_function_executor - Model: 10,477 parameters, 45.0KB storage
2025-10-13 04:27:46,850 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.4294012015959914, 0.31077806236425143, 0.2760299244086497, 0.2627657033010175, 0.24831849133473907, 0.2414459154168897, 0.23262784124662045, 0.22926485718032008, 0.22496946005748522, 0.221875597854198, 0.21576575415471674, 0.21154287921856094, 0.2101787140590977, 0.2061577150242851, 0.20462848880453088, 0.20341159333108208, 0.20090943049296534, 0.19760802741422284, 0.19741160082306464, 0.19456387913564535, 0.19400162131016724, 0.19066056337417486, 0.189967801790498, 0.1873835814164252, 0.18508391082938794, 0.1856904836905495, 0.1838737417215864, 0.18307607074743765, 0.1812195274776769, 0.1802948468505272, 0.1797819399067237, 0.17895288844643395, 0.17747546355984908, 0.1776297249722708, 0.17710582894952118, 0.17489735339205917], 'val_losses': [0.28448052526480005, 0.24825712567991337, 0.2169687527906323, 0.21148613540701489, 0.20109500467652075, 0.19754260993312614, 0.19370844228454598, 0.1895040848172124, 0.19584467025238356, 0.20211226961487108, 0.1877475276505943, 0.1791285202454803, 0.1854241805259982, 0.18431158536457706, 0.17835285588916383, 0.18820395027011852, 0.17826547447329932, 0.1764539110340311, 0.17507535654700715, 0.17316436262179974, 0.1752627078061718, 0.16679948777753154, 0.17149379219120517, 0.1659909151559699, 0.18104880203264428, 0.17451892016565712, 0.16640266743747764, 0.16825297154097613, 0.1672698337001883, 0.16233702498792266, 0.16439551883043005, 0.1633636209387482, 0.16410919579282524, 0.164010319505428, 0.1607432523947685, 0.16420708997791197], 'val_acc': [0.7325866293314666, 0.7640007000350018, 0.7812390619530977, 0.7814140707035352, 0.7885894294714736, 0.7906020301015051, 0.7943647182359118, 0.7958522926146308, 0.7832516625831292, 0.7854392719635982, 0.8008400420021001, 0.7985649282464123, 0.7953272663633182, 0.7982149107455373, 0.7981274063703185, 0.7989149457472874, 0.8014525726286315, 0.8046902345117256, 0.8053902695134757, 0.8026776338816941, 0.8042527126356318, 0.8088904445222261, 0.8061778088904445, 0.8095029751487575, 0.7948897444872244, 0.8023276163808191, 0.81002800140007, 0.8086279313965699, 0.8070528526426322, 0.811515575778789, 0.8074028701435072, 0.8116030801540077, 0.8081029051452573, 0.8099404970248513, 0.8123031151557578, 0.8094154707735387], 'model_size_bytes': 59073, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00023077002725172647, 'batch_size': 16, 'epochs': 36, 'weight_decay': 4.017117247601545e-05, 'dropout': 0.2926667915506569, 'hidden_size': 17, 'd_model': 31, 't_pooled': 128, 'label_smoothing': 0.007582341221540158, 'use_focal_loss': True, 'focal_gamma': 2.475531769964284, 'grad_clip_norm': 3.6630588567435485, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 10477, 'model_storage_size_kb': 45.018359375, 'model_size_validation': 'PASS'}
2025-10-13 04:27:46,850 - INFO - _models.training_function_executor - BO Objective: base=0.8094, size_penalty=0.0000, final=0.8094
2025-10-13 04:27:46,850 - INFO - _models.training_function_executor - Model: 10,477 parameters, 45.0KB (PASS 256KB limit)
2025-10-13 04:27:46,850 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 272.029s
2025-10-13 04:27:46,925 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8094
2025-10-13 04:27:46,926 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.074s
2025-10-13 04:27:46,926 - INFO - bo.run_bo - Recorded observation #5: hparams={'lr': 0.00023077002725172647, 'batch_size': np.int64(16), 'epochs': np.int64(36), 'weight_decay': 4.017117247601545e-05, 'dropout': 0.2926667915506569, 'hidden_size': np.int64(17), 'd_model': np.int64(31), 't_pooled': np.int64(128), 'label_smoothing': 0.007582341221540158, 'use_focal_loss': np.True_, 'focal_gamma': 2.475531769964284, 'grad_clip_norm': 3.6630588567435485, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.8094
2025-10-13 04:27:46,926 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 5: {'lr': 0.00023077002725172647, 'batch_size': np.int64(16), 'epochs': np.int64(36), 'weight_decay': 4.017117247601545e-05, 'dropout': 0.2926667915506569, 'hidden_size': np.int64(17), 'd_model': np.int64(31), 't_pooled': np.int64(128), 'label_smoothing': 0.007582341221540158, 'use_focal_loss': np.True_, 'focal_gamma': 2.475531769964284, 'grad_clip_norm': 3.6630588567435485, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.8094
2025-10-13 04:27:46,926 - INFO - bo.run_bo - üîçBO Trial 6: Using RF surrogate + Expected Improvement
2025-10-13 04:27:46,926 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 04:27:46,926 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 6 (NaN monitoring active)
2025-10-13 04:27:46,926 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 04:27:46,926 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 04:27:46,926 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0024591176063999973, 'batch_size': 32, 'epochs': 59, 'weight_decay': 3.471209520507529e-06, 'dropout': 0.10835486447547929, 'hidden_size': 13, 'd_model': 14, 't_pooled': 320, 'label_smoothing': 0.03708501917048739, 'use_focal_loss': True, 'focal_gamma': 0.8283946859947401, 'grad_clip_norm': 3.583531751527427, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 04:27:46,927 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0024591176063999973, 'batch_size': 32, 'epochs': 59, 'weight_decay': 3.471209520507529e-06, 'dropout': 0.10835486447547929, 'hidden_size': 13, 'd_model': 14, 't_pooled': 320, 'label_smoothing': 0.03708501917048739, 'use_focal_loss': True, 'focal_gamma': 0.8283946859947401, 'grad_clip_norm': 3.583531751527427, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 04:27:55,194 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.6217 | val_loss=0.5027 | val_acc=0.7443 | time=8.3s
2025-10-13 04:28:00,628 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.4726 | val_loss=0.4258 | val_acc=0.7797 | time=5.4s
2025-10-13 04:28:06,074 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4453 | val_loss=0.4078 | val_acc=0.7885 | time=5.4s
2025-10-13 04:28:11,501 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4309 | val_loss=0.4194 | val_acc=0.7815 | time=5.4s
2025-10-13 04:28:16,924 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4206 | val_loss=0.4094 | val_acc=0.7889 | time=5.4s
2025-10-13 04:28:22,355 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4126 | val_loss=0.4029 | val_acc=0.7847 | time=5.4s
2025-10-13 04:28:27,781 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4015 | val_loss=0.4209 | val_acc=0.7812 | time=5.4s
2025-10-13 04:28:33,216 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3975 | val_loss=0.4205 | val_acc=0.7773 | time=5.4s
2025-10-13 04:28:38,655 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3937 | val_loss=0.3984 | val_acc=0.7866 | time=5.4s
2025-10-13 04:28:44,081 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3883 | val_loss=0.3926 | val_acc=0.7936 | time=5.4s
2025-10-13 04:28:49,524 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3843 | val_loss=0.3773 | val_acc=0.8001 | time=5.4s
2025-10-13 04:28:54,952 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3820 | val_loss=0.3845 | val_acc=0.7976 | time=5.4s
2025-10-13 04:29:00,376 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3783 | val_loss=0.3677 | val_acc=0.8002 | time=5.4s
2025-10-13 04:29:05,806 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3781 | val_loss=0.4267 | val_acc=0.7816 | time=5.4s
2025-10-13 04:29:11,238 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3724 | val_loss=0.3540 | val_acc=0.8088 | time=5.4s
2025-10-13 04:29:16,681 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3710 | val_loss=0.3635 | val_acc=0.8047 | time=5.4s
2025-10-13 04:29:22,114 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3705 | val_loss=0.3693 | val_acc=0.8038 | time=5.4s
2025-10-13 04:29:27,543 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3666 | val_loss=0.3818 | val_acc=0.7959 | time=5.4s
2025-10-13 04:29:32,969 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3640 | val_loss=0.3714 | val_acc=0.8014 | time=5.4s
2025-10-13 04:29:38,402 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3628 | val_loss=0.3567 | val_acc=0.8123 | time=5.4s
2025-10-13 04:29:43,837 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3612 | val_loss=0.3570 | val_acc=0.8057 | time=5.4s
2025-10-13 04:29:49,267 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3590 | val_loss=0.3699 | val_acc=0.8050 | time=5.4s
2025-10-13 04:29:54,688 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3603 | val_loss=0.3687 | val_acc=0.7994 | time=5.4s
2025-10-13 04:30:00,117 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3583 | val_loss=0.3685 | val_acc=0.8061 | time=5.4s
2025-10-13 04:30:05,562 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3563 | val_loss=0.3494 | val_acc=0.8113 | time=5.4s
2025-10-13 04:30:10,990 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.3549 | val_loss=0.3637 | val_acc=0.8057 | time=5.4s
2025-10-13 04:30:16,421 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.3510 | val_loss=0.3646 | val_acc=0.8080 | time=5.4s
2025-10-13 04:30:21,849 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.3538 | val_loss=0.3728 | val_acc=0.7981 | time=5.4s
2025-10-13 04:30:27,279 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.3520 | val_loss=0.3748 | val_acc=0.8009 | time=5.4s
2025-10-13 04:30:32,706 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.3510 | val_loss=0.3551 | val_acc=0.8111 | time=5.4s
2025-10-13 04:30:38,149 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.3503 | val_loss=0.3648 | val_acc=0.8061 | time=5.4s
2025-10-13 04:30:43,588 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.3500 | val_loss=0.3523 | val_acc=0.8109 | time=5.4s
2025-10-13 04:30:49,026 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.3488 | val_loss=0.3544 | val_acc=0.8089 | time=5.4s
2025-10-13 04:30:54,460 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.3469 | val_loss=0.3485 | val_acc=0.8107 | time=5.4s
2025-10-13 04:30:59,895 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.3461 | val_loss=0.3622 | val_acc=0.8060 | time=5.4s
2025-10-13 04:31:05,323 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.3423 | val_loss=0.3648 | val_acc=0.8076 | time=5.4s
2025-10-13 04:31:10,750 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.3429 | val_loss=0.3610 | val_acc=0.8082 | time=5.4s
2025-10-13 04:31:16,182 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.3438 | val_loss=0.3554 | val_acc=0.8106 | time=5.4s
2025-10-13 04:31:21,619 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.3412 | val_loss=0.3602 | val_acc=0.8015 | time=5.4s
2025-10-13 04:31:27,049 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.3393 | val_loss=0.3493 | val_acc=0.8133 | time=5.4s
2025-10-13 04:31:32,470 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.3400 | val_loss=0.3498 | val_acc=0.8066 | time=5.4s
2025-10-13 04:31:37,910 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.3381 | val_loss=0.3553 | val_acc=0.8101 | time=5.4s
2025-10-13 04:31:43,344 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.3410 | val_loss=0.3516 | val_acc=0.8105 | time=5.4s
2025-10-13 04:31:48,777 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.3376 | val_loss=0.3543 | val_acc=0.8115 | time=5.4s
2025-10-13 04:31:54,212 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.3379 | val_loss=0.3864 | val_acc=0.7953 | time=5.4s
2025-10-13 04:31:59,647 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.3369 | val_loss=0.3678 | val_acc=0.8052 | time=5.4s
2025-10-13 04:32:05,066 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.3364 | val_loss=0.3440 | val_acc=0.8149 | time=5.4s
2025-10-13 04:32:10,497 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.3357 | val_loss=0.3834 | val_acc=0.7979 | time=5.4s
2025-10-13 04:32:15,929 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.3355 | val_loss=0.3526 | val_acc=0.8128 | time=5.4s
2025-10-13 04:32:21,364 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.3318 | val_loss=0.3651 | val_acc=0.8033 | time=5.4s
2025-10-13 04:32:26,792 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.3341 | val_loss=0.3525 | val_acc=0.8121 | time=5.4s
2025-10-13 04:32:32,230 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.3330 | val_loss=0.3779 | val_acc=0.8015 | time=5.4s
2025-10-13 04:32:37,671 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.3335 | val_loss=0.3702 | val_acc=0.8026 | time=5.4s
2025-10-13 04:32:43,115 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.3313 | val_loss=0.3548 | val_acc=0.8113 | time=5.4s
2025-10-13 04:32:48,544 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.3326 | val_loss=0.3617 | val_acc=0.8047 | time=5.4s
2025-10-13 04:32:53,976 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.3323 | val_loss=0.3593 | val_acc=0.8069 | time=5.4s
2025-10-13 04:32:59,406 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.3286 | val_loss=0.3768 | val_acc=0.8010 | time=5.4s
2025-10-13 04:33:04,844 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.3317 | val_loss=0.3583 | val_acc=0.8071 | time=5.4s
2025-10-13 04:33:10,270 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.3323 | val_loss=0.3540 | val_acc=0.8113 | time=5.4s
2025-10-13 04:33:10,274 - INFO - _models.training_function_executor - Quantized model size: 44225 bytes.
2025-10-13 04:33:11,375 - INFO - _models.training_function_executor - Model: 6,786 parameters, 29.2KB storage
2025-10-13 04:33:11,375 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.6216638828642435, 0.4725774120817161, 0.4453132649297517, 0.4309361567750109, 0.4206079319406315, 0.4125639408315693, 0.40146842200438126, 0.39747299226297544, 0.39367062693131233, 0.3883193461032109, 0.38433159427247265, 0.3819995430233932, 0.37834348135533596, 0.37806087844973474, 0.37235488760584, 0.37102920060020916, 0.3704566043919936, 0.3666425128270164, 0.3639857855018803, 0.36284744179369816, 0.3612287460787546, 0.3589903904730764, 0.3603486921931632, 0.3583293014111784, 0.3563059096282956, 0.3549183810303835, 0.3510373482258327, 0.35383496442102325, 0.3520446892203173, 0.35102367799078454, 0.3502532881656893, 0.3500270331379497, 0.34884014706908717, 0.3468699927852836, 0.34613823540714767, 0.34226431869463275, 0.3429141337997979, 0.3438198139586564, 0.3411969175320386, 0.3393108343687932, 0.339961507513801, 0.3380631441820907, 0.34099569447836675, 0.3375925637121838, 0.3379130248719677, 0.33686841039608356, 0.33639393229458686, 0.3356663180077706, 0.3354577823852717, 0.33184402433149374, 0.33411018234326534, 0.3330211081067123, 0.33350377788295854, 0.3313437958290663, 0.33263779658202236, 0.3322862752008822, 0.32864507909709023, 0.3316840487820809, 0.3322741638531333], 'val_losses': [0.5026536677678148, 0.42580537704016136, 0.40784729865409297, 0.4194383608906846, 0.40938457399137296, 0.40286331782609713, 0.42092357186283064, 0.42048625657931465, 0.3983710607657868, 0.39261706560944026, 0.37725337169409884, 0.38447899275156516, 0.36768595755913897, 0.42672971462635967, 0.35403223123465294, 0.3634803950327612, 0.3692526305977765, 0.3817706046183292, 0.37139569925477467, 0.3566851728094763, 0.35701062141972734, 0.36987395977323023, 0.36874713483998356, 0.3684787631848495, 0.34936734964099014, 0.3637039657391407, 0.3646454310131357, 0.3727848319102719, 0.37484396120489666, 0.3550841489433199, 0.36481869794457034, 0.352345448317209, 0.35437868933474054, 0.34854769242010125, 0.3621910210512383, 0.3647839440346432, 0.3609800379635948, 0.35540771846342306, 0.36020639508514085, 0.34929490098804705, 0.3498166699091538, 0.3552528682771495, 0.35159358174119915, 0.3542601164817643, 0.3863805962330735, 0.36776727198052334, 0.3440298402397041, 0.3834488958714932, 0.3525772204255574, 0.365109449099276, 0.3525215037738188, 0.3778657269177422, 0.3702274199117511, 0.3548170756033596, 0.3617311695217043, 0.35931796870283367, 0.37683925054521467, 0.35825518904384884, 0.3539908386618264], 'val_acc': [0.7443122156107805, 0.77966398319916, 0.7885019250962548, 0.781501575078754, 0.7888519425971299, 0.7847392369618481, 0.7811515575778789, 0.7773013650682534, 0.7865768288414421, 0.793577178858943, 0.80014000700035, 0.797602380119006, 0.8002275113755688, 0.7815890794539727, 0.8088029401470074, 0.8046902345117256, 0.803815190759538, 0.7959397969898495, 0.8013650682534127, 0.8123031151557578, 0.805652782639132, 0.8049527476373819, 0.7993524676233812, 0.8060903045152258, 0.8113405670283514, 0.8057402870143507, 0.8080154007700385, 0.7981274063703185, 0.8009275463773189, 0.8110780539026952, 0.8060903045152258, 0.8109030451522576, 0.8088904445222261, 0.8107280364018201, 0.806002800140007, 0.8075778788939447, 0.808190409520476, 0.8106405320266014, 0.8014525726286315, 0.8132656632831642, 0.8066153307665384, 0.8101155057752888, 0.8104655232761638, 0.811515575778789, 0.7953272663633182, 0.8052152607630382, 0.8149282464123206, 0.7978648932446623, 0.8128281414070704, 0.8032901645082254, 0.8121281064053203, 0.8014525726286315, 0.8025901295064753, 0.8112530626531327, 0.8046902345117256, 0.8068778438921946, 0.8010150507525376, 0.8071403570178509, 0.8112530626531327], 'model_size_bytes': 44225, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0024591176063999973, 'batch_size': 32, 'epochs': 59, 'weight_decay': 3.471209520507529e-06, 'dropout': 0.10835486447547929, 'hidden_size': 13, 'd_model': 14, 't_pooled': 320, 'label_smoothing': 0.03708501917048739, 'use_focal_loss': True, 'focal_gamma': 0.8283946859947401, 'grad_clip_norm': 3.583531751527427, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 6786, 'model_storage_size_kb': 29.15859375, 'model_size_validation': 'PASS'}
2025-10-13 04:33:11,375 - INFO - _models.training_function_executor - BO Objective: base=0.8113, size_penalty=0.0000, final=0.8113
2025-10-13 04:33:11,375 - INFO - _models.training_function_executor - Model: 6,786 parameters, 29.2KB (PASS 256KB limit)
2025-10-13 04:33:11,375 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 324.449s
2025-10-13 04:33:11,450 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8113
2025-10-13 04:33:11,450 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.073s
2025-10-13 04:33:11,451 - INFO - bo.run_bo - Recorded observation #6: hparams={'lr': 0.0024591176063999973, 'batch_size': np.int64(32), 'epochs': np.int64(59), 'weight_decay': 3.471209520507529e-06, 'dropout': 0.10835486447547929, 'hidden_size': np.int64(13), 'd_model': np.int64(14), 't_pooled': np.int64(320), 'label_smoothing': 0.03708501917048739, 'use_focal_loss': np.True_, 'focal_gamma': 0.8283946859947401, 'grad_clip_norm': 3.583531751527427, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8113
2025-10-13 04:33:11,451 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 6: {'lr': 0.0024591176063999973, 'batch_size': np.int64(32), 'epochs': np.int64(59), 'weight_decay': 3.471209520507529e-06, 'dropout': 0.10835486447547929, 'hidden_size': np.int64(13), 'd_model': np.int64(14), 't_pooled': np.int64(320), 'label_smoothing': 0.03708501917048739, 'use_focal_loss': np.True_, 'focal_gamma': 0.8283946859947401, 'grad_clip_norm': 3.583531751527427, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8113
2025-10-13 04:33:11,451 - INFO - bo.run_bo - üîçBO Trial 7: Using RF surrogate + Expected Improvement
2025-10-13 04:33:11,451 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 04:33:11,451 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 7 (NaN monitoring active)
2025-10-13 04:33:11,451 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 04:33:11,451 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 04:33:11,451 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00019784285076893693, 'batch_size': 8, 'epochs': 95, 'weight_decay': 2.2790780354299242e-06, 'dropout': 0.40984481537098816, 'hidden_size': 17, 'd_model': 16, 't_pooled': 192, 'label_smoothing': 0.007391155221791325, 'use_focal_loss': False, 'focal_gamma': 4.205113941343911, 'grad_clip_norm': 1.3326993475638984, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 04:33:11,452 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00019784285076893693, 'batch_size': 8, 'epochs': 95, 'weight_decay': 2.2790780354299242e-06, 'dropout': 0.40984481537098816, 'hidden_size': 17, 'd_model': 16, 't_pooled': 192, 'label_smoothing': 0.007391155221791325, 'use_focal_loss': False, 'focal_gamma': 4.205113941343911, 'grad_clip_norm': 1.3326993475638984, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 04:33:28,439 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0333 | val_loss=0.7831 | val_acc=0.6787 | time=17.0s
2025-10-13 04:33:42,654 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.8539 | val_loss=0.7110 | val_acc=0.7335 | time=14.2s
2025-10-13 04:33:56,874 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.7732 | val_loss=0.6491 | val_acc=0.7535 | time=14.2s
2025-10-13 04:34:11,158 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.7271 | val_loss=0.5987 | val_acc=0.7775 | time=14.3s
2025-10-13 04:34:25,514 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.7113 | val_loss=0.5890 | val_acc=0.7816 | time=14.4s
2025-10-13 04:34:39,865 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.6956 | val_loss=0.6226 | val_acc=0.7668 | time=14.4s
2025-10-13 04:34:54,292 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.6852 | val_loss=0.5890 | val_acc=0.7828 | time=14.4s
2025-10-13 04:35:08,533 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.6794 | val_loss=0.5776 | val_acc=0.7840 | time=14.2s
2025-10-13 04:35:22,775 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.6718 | val_loss=0.5718 | val_acc=0.7923 | time=14.2s
2025-10-13 04:35:37,120 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.6581 | val_loss=0.5708 | val_acc=0.7856 | time=14.3s
2025-10-13 04:35:51,346 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.6536 | val_loss=0.5987 | val_acc=0.7826 | time=14.2s
2025-10-13 04:36:05,736 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.6494 | val_loss=0.5665 | val_acc=0.7881 | time=14.4s
2025-10-13 04:36:19,973 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.6400 | val_loss=0.5569 | val_acc=0.7915 | time=14.2s
2025-10-13 04:36:34,242 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.6370 | val_loss=0.5823 | val_acc=0.7843 | time=14.3s
2025-10-13 04:36:48,570 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.6348 | val_loss=0.5468 | val_acc=0.7982 | time=14.3s
2025-10-13 04:37:02,848 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.6238 | val_loss=0.5987 | val_acc=0.7779 | time=14.3s
2025-10-13 04:37:17,128 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.6205 | val_loss=0.5600 | val_acc=0.7958 | time=14.3s
2025-10-13 04:37:31,350 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.6148 | val_loss=0.5615 | val_acc=0.7923 | time=14.2s
2025-10-13 04:37:45,647 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.6137 | val_loss=0.5434 | val_acc=0.8006 | time=14.3s
2025-10-13 04:37:59,983 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.6086 | val_loss=0.5450 | val_acc=0.8015 | time=14.3s
2025-10-13 04:38:14,084 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.6028 | val_loss=0.5328 | val_acc=0.8031 | time=14.1s
2025-10-13 04:38:28,456 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.6040 | val_loss=0.5640 | val_acc=0.7955 | time=14.4s
2025-10-13 04:38:42,791 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.5978 | val_loss=0.5409 | val_acc=0.8015 | time=14.3s
2025-10-13 04:38:57,043 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.5932 | val_loss=0.5656 | val_acc=0.7962 | time=14.3s
2025-10-13 04:39:11,338 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.5914 | val_loss=0.5652 | val_acc=0.7918 | time=14.3s
2025-10-13 04:39:25,727 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.5871 | val_loss=0.5516 | val_acc=0.7976 | time=14.4s
2025-10-13 04:39:40,046 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.5849 | val_loss=0.5320 | val_acc=0.8050 | time=14.3s
2025-10-13 04:39:54,406 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.5824 | val_loss=0.5329 | val_acc=0.8078 | time=14.4s
2025-10-13 04:40:08,554 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.5812 | val_loss=0.5226 | val_acc=0.8057 | time=14.1s
2025-10-13 04:40:22,940 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.5803 | val_loss=0.5216 | val_acc=0.8075 | time=14.4s
2025-10-13 04:40:37,280 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.5762 | val_loss=0.5449 | val_acc=0.7995 | time=14.3s
2025-10-13 04:40:51,441 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.5737 | val_loss=0.5541 | val_acc=0.7999 | time=14.2s
2025-10-13 04:41:05,613 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.5720 | val_loss=0.5557 | val_acc=0.8034 | time=14.2s
2025-10-13 04:41:19,848 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.5680 | val_loss=0.5285 | val_acc=0.8057 | time=14.2s
2025-10-13 04:41:34,087 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.5690 | val_loss=0.5316 | val_acc=0.8056 | time=14.2s
2025-10-13 04:41:48,377 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.5630 | val_loss=0.5408 | val_acc=0.8053 | time=14.3s
2025-10-13 04:42:02,577 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.5641 | val_loss=0.5598 | val_acc=0.7960 | time=14.2s
2025-10-13 04:42:16,845 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.5605 | val_loss=0.5668 | val_acc=0.7921 | time=14.3s
2025-10-13 04:42:30,955 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.5588 | val_loss=0.5322 | val_acc=0.8073 | time=14.1s
2025-10-13 04:42:45,139 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.5610 | val_loss=0.5407 | val_acc=0.8028 | time=14.2s
2025-10-13 04:42:59,344 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.5584 | val_loss=0.5351 | val_acc=0.8054 | time=14.2s
2025-10-13 04:43:13,591 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.5534 | val_loss=0.5188 | val_acc=0.8076 | time=14.2s
2025-10-13 04:43:27,905 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.5561 | val_loss=0.5365 | val_acc=0.8056 | time=14.3s
2025-10-13 04:43:42,194 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.5516 | val_loss=0.5386 | val_acc=0.8046 | time=14.3s
2025-10-13 04:43:56,443 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.5560 | val_loss=0.5382 | val_acc=0.8038 | time=14.2s
2025-10-13 04:44:10,596 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.5491 | val_loss=0.5503 | val_acc=0.8040 | time=14.2s
2025-10-13 04:44:24,840 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.5519 | val_loss=0.5416 | val_acc=0.8046 | time=14.2s
2025-10-13 04:44:39,147 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.5515 | val_loss=0.5117 | val_acc=0.8116 | time=14.3s
2025-10-13 04:44:53,439 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.5492 | val_loss=0.5255 | val_acc=0.8112 | time=14.3s
2025-10-13 04:45:07,701 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.5467 | val_loss=0.5169 | val_acc=0.8095 | time=14.3s
2025-10-13 04:45:21,970 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.5459 | val_loss=0.5141 | val_acc=0.8120 | time=14.3s
2025-10-13 04:45:36,158 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.5477 | val_loss=0.5397 | val_acc=0.8019 | time=14.2s
2025-10-13 04:45:50,368 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.5448 | val_loss=0.5263 | val_acc=0.8083 | time=14.2s
2025-10-13 04:46:04,633 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.5464 | val_loss=0.5221 | val_acc=0.8091 | time=14.3s
2025-10-13 04:46:18,852 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.5420 | val_loss=0.5343 | val_acc=0.8070 | time=14.2s
2025-10-13 04:46:33,087 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.5420 | val_loss=0.5107 | val_acc=0.8122 | time=14.2s
2025-10-13 04:46:47,541 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.5389 | val_loss=0.5153 | val_acc=0.8131 | time=14.5s
2025-10-13 04:47:01,839 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.5381 | val_loss=0.5243 | val_acc=0.8085 | time=14.3s
2025-10-13 04:47:16,105 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.5385 | val_loss=0.5213 | val_acc=0.8097 | time=14.3s
2025-10-13 04:47:30,270 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.5346 | val_loss=0.5235 | val_acc=0.8089 | time=14.2s
2025-10-13 04:47:44,385 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.5366 | val_loss=0.5194 | val_acc=0.8125 | time=14.1s
2025-10-13 04:47:58,675 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.5380 | val_loss=0.5216 | val_acc=0.8113 | time=14.3s
2025-10-13 04:48:12,955 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.5358 | val_loss=0.5562 | val_acc=0.8029 | time=14.3s
2025-10-13 04:48:27,225 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.5354 | val_loss=0.5099 | val_acc=0.8119 | time=14.3s
2025-10-13 04:48:41,393 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.5367 | val_loss=0.5264 | val_acc=0.8104 | time=14.2s
2025-10-13 04:48:55,617 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.5353 | val_loss=0.5057 | val_acc=0.8145 | time=14.2s
2025-10-13 04:49:09,909 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.5345 | val_loss=0.5258 | val_acc=0.8058 | time=14.3s
2025-10-13 04:49:24,225 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.5281 | val_loss=0.5321 | val_acc=0.8113 | time=14.3s
2025-10-13 04:49:38,508 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.5322 | val_loss=0.5138 | val_acc=0.8135 | time=14.3s
2025-10-13 04:49:52,773 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.5296 | val_loss=0.5468 | val_acc=0.8036 | time=14.3s
2025-10-13 04:50:07,086 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.5287 | val_loss=0.5182 | val_acc=0.8108 | time=14.3s
2025-10-13 04:50:21,167 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.5300 | val_loss=0.5424 | val_acc=0.8047 | time=14.1s
2025-10-13 04:50:35,222 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.5301 | val_loss=0.5163 | val_acc=0.8143 | time=14.1s
2025-10-13 04:50:49,491 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.5277 | val_loss=0.5289 | val_acc=0.8106 | time=14.3s
2025-10-13 04:51:03,730 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.5252 | val_loss=0.5380 | val_acc=0.8022 | time=14.2s
2025-10-13 04:51:17,968 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.5278 | val_loss=0.5466 | val_acc=0.8051 | time=14.2s
2025-10-13 04:51:32,168 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.5256 | val_loss=0.5150 | val_acc=0.8115 | time=14.2s
2025-10-13 04:51:46,478 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.5254 | val_loss=0.5193 | val_acc=0.8107 | time=14.3s
2025-10-13 04:52:00,712 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.5223 | val_loss=0.5142 | val_acc=0.8128 | time=14.2s
2025-10-13 04:52:15,072 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.5227 | val_loss=0.5252 | val_acc=0.8134 | time=14.4s
2025-10-13 04:52:29,388 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.5258 | val_loss=0.5246 | val_acc=0.8094 | time=14.3s
2025-10-13 04:52:43,553 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.5261 | val_loss=0.5185 | val_acc=0.8126 | time=14.2s
2025-10-13 04:52:57,781 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.5250 | val_loss=0.5205 | val_acc=0.8095 | time=14.2s
2025-10-13 04:53:12,026 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.5201 | val_loss=0.5240 | val_acc=0.8101 | time=14.2s
2025-10-13 04:53:26,159 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.5221 | val_loss=0.5139 | val_acc=0.8106 | time=14.1s
2025-10-13 04:53:40,429 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.5204 | val_loss=0.5220 | val_acc=0.8130 | time=14.3s
2025-10-13 04:53:54,710 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.5235 | val_loss=0.5175 | val_acc=0.8141 | time=14.3s
2025-10-13 04:54:09,073 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.5216 | val_loss=0.5139 | val_acc=0.8130 | time=14.4s
2025-10-13 04:54:23,387 - INFO - _models.training_function_executor - Epoch 089 | train_loss=0.5204 | val_loss=0.5200 | val_acc=0.8139 | time=14.3s
2025-10-13 04:54:37,713 - INFO - _models.training_function_executor - Epoch 090 | train_loss=0.5188 | val_loss=0.5264 | val_acc=0.8137 | time=14.3s
2025-10-13 04:54:52,009 - INFO - _models.training_function_executor - Epoch 091 | train_loss=0.5180 | val_loss=0.5107 | val_acc=0.8104 | time=14.3s
2025-10-13 04:55:06,281 - INFO - _models.training_function_executor - Epoch 092 | train_loss=0.5236 | val_loss=0.5462 | val_acc=0.8020 | time=14.3s
2025-10-13 04:55:20,478 - INFO - _models.training_function_executor - Epoch 093 | train_loss=0.5176 | val_loss=0.5156 | val_acc=0.8140 | time=14.2s
2025-10-13 04:55:34,538 - INFO - _models.training_function_executor - Epoch 094 | train_loss=0.5190 | val_loss=0.5393 | val_acc=0.8088 | time=14.1s
2025-10-13 04:55:48,650 - INFO - _models.training_function_executor - Epoch 095 | train_loss=0.5159 | val_loss=0.5177 | val_acc=0.8144 | time=14.1s
2025-10-13 04:55:48,657 - INFO - _models.training_function_executor - Quantized model size: 33665 bytes.
2025-10-13 04:55:49,767 - INFO - _models.training_function_executor - Model: 8,233 parameters, 17.7KB storage
2025-10-13 04:55:49,767 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.0333073732498896, 0.8539420415131955, 0.7731734226357699, 0.7270528053304804, 0.7112933601721166, 0.6955782375632569, 0.6851915165333428, 0.6793871332816637, 0.6717885294078341, 0.6580767725751789, 0.6535848308606272, 0.6493569678911535, 0.6399895665455854, 0.6369527814310666, 0.6348403632304428, 0.6238204650815588, 0.6205253399371329, 0.6148210573572461, 0.6136918681959589, 0.6085908502069102, 0.6028242523739252, 0.6039847006169198, 0.5978181339868162, 0.5931614515823754, 0.5913583888474423, 0.5870877477566304, 0.5848977454828139, 0.5824406753168015, 0.5811928494862422, 0.5803219767702671, 0.5762066767538944, 0.5737174933722147, 0.5719999625456106, 0.568029921469277, 0.5690392516162227, 0.5630404910246757, 0.5640855294808427, 0.5605498758341242, 0.5587927665415399, 0.5610375972930831, 0.5583742911144074, 0.5533926714241693, 0.5560800433895587, 0.5515915146557172, 0.5559972745513411, 0.5491466908287003, 0.5518647674692806, 0.5515235489052431, 0.549207841757767, 0.5467012223804231, 0.5458625254153131, 0.5476654208062159, 0.5448190193169541, 0.5464333040860772, 0.5419833327274891, 0.5420331410505594, 0.5389250832713167, 0.5381388021897072, 0.5385088319057324, 0.5346271695232095, 0.5366349286814753, 0.5379584029090021, 0.5358309869712827, 0.5353781370498895, 0.536730458350356, 0.5353485041584508, 0.5344883946752085, 0.5281354605377054, 0.5321615489006126, 0.5295978703718316, 0.5286666953875587, 0.5300220732013528, 0.5300879574638012, 0.5277268846372927, 0.5251998912756901, 0.5277876238155123, 0.5255705852017177, 0.5253946227202434, 0.5222876355290611, 0.5226860519389057, 0.5257623170945489, 0.5261417786425484, 0.5249987517235463, 0.5201203127965034, 0.5220545452625331, 0.520436986521966, 0.5234587038634101, 0.5216251752219669, 0.5204041913688955, 0.5188092890609216, 0.5180417846759215, 0.5235648493207196, 0.5175594139705963, 0.5190186923963699, 0.515858486472731], 'val_losses': [0.7830648243552453, 0.711046393951587, 0.6490547895316774, 0.5986736021521294, 0.5890388886151215, 0.6225608920963402, 0.5889707491777141, 0.577627090779601, 0.5717871844048762, 0.5708090679176963, 0.5986527291980289, 0.5664674587075761, 0.5569367992698542, 0.5822713619967128, 0.5467845513493521, 0.5986998554059664, 0.5599820097457875, 0.5614997560838364, 0.543398783570576, 0.5450057149048155, 0.5328170938021577, 0.5639517548245319, 0.5409192336546528, 0.5656121723486862, 0.5652490467417269, 0.5516406125019053, 0.5320426148053103, 0.5329419968608672, 0.5226433917092492, 0.521627076217917, 0.5448925710320055, 0.5541438793396466, 0.5557290722397937, 0.528499056116701, 0.5316210770976264, 0.5407832743072577, 0.5598073226559775, 0.5667537735044268, 0.532242139848976, 0.5406547844289983, 0.5351164246308541, 0.5187511349010184, 0.5364575239956525, 0.5385543976160334, 0.5382308298927276, 0.5502662676998398, 0.5416491590088216, 0.5116656896275869, 0.5255192958280095, 0.5169002281532531, 0.5141391565812647, 0.539682203548477, 0.526259475807168, 0.5220627590680106, 0.5342647896640819, 0.5106821825423355, 0.5152545253484451, 0.5243345286083004, 0.5213020246711944, 0.5235144490122503, 0.519401705427774, 0.5215766848823513, 0.5561829648878052, 0.509948548984394, 0.5263904365764701, 0.5057388063093813, 0.5258072968552819, 0.5321247713743994, 0.5137812213350894, 0.5467553415736995, 0.5181936230021504, 0.5424305815321397, 0.5163127932675368, 0.5288707942844981, 0.5379889814335023, 0.5465720980201604, 0.5149875082881417, 0.519301757852765, 0.5142305193427855, 0.5252437256785135, 0.5246133979698099, 0.5185388198469876, 0.5205074915095856, 0.524027746737963, 0.5139460622961805, 0.5219851921895687, 0.5174944894424176, 0.5138586888107379, 0.5199594948053526, 0.5264110651478761, 0.5107420332779365, 0.5461613687344018, 0.5155733407644237, 0.5392698913859578, 0.5177068844213325], 'val_acc': [0.6786839341967098, 0.7335491774588729, 0.7535001750087504, 0.777476373818691, 0.7815890794539727, 0.7668008400420021, 0.7828141407070354, 0.7839516975848793, 0.7922646132306616, 0.7856142807140357, 0.7826391319565978, 0.788064403220161, 0.7914770738536927, 0.7843017150857543, 0.7982149107455373, 0.7779138956947848, 0.795764788239412, 0.7922646132306616, 0.8005775288764438, 0.8014525726286315, 0.8031151557577879, 0.7955022751137557, 0.8015400770038502, 0.7962023101155058, 0.7918270913545677, 0.797602380119006, 0.8049527476373819, 0.807840392019601, 0.8057402870143507, 0.807490374518726, 0.7995274763738187, 0.7998774938746938, 0.8033776688834442, 0.8057402870143507, 0.8055652782639132, 0.8053027651382569, 0.7960273013650683, 0.792089604480224, 0.8073153657682884, 0.8027651382569129, 0.8053902695134757, 0.8075778788939447, 0.8055652782639132, 0.8046027301365068, 0.803815190759538, 0.8039901995099755, 0.8046027301365068, 0.8116030801540077, 0.8111655582779139, 0.8095029751487575, 0.8119530976548828, 0.8018900945047253, 0.8082779138956948, 0.8090654532726637, 0.8069653482674134, 0.812215610780539, 0.8130906545327267, 0.8084529226461323, 0.809677983899195, 0.8088904445222261, 0.8124781239061953, 0.8112530626531327, 0.8028526426321316, 0.811865593279664, 0.8103780189009451, 0.8144907245362268, 0.8058277913895695, 0.8112530626531327, 0.8135281764088205, 0.8035526776338817, 0.8108155407770389, 0.8046902345117256, 0.8143157157857893, 0.8105530276513826, 0.8022401120056003, 0.8051277563878194, 0.811515575778789, 0.8107280364018201, 0.8128281414070704, 0.8134406720336017, 0.8094154707735387, 0.8125656282814141, 0.8095029751487575, 0.8101155057752888, 0.8106405320266014, 0.8130031501575079, 0.814053202660133, 0.8130031501575079, 0.8138781939096955, 0.813703185159258, 0.8103780189009451, 0.801977598879944, 0.8139656982849143, 0.8088029401470074, 0.8144032201610081], 'model_size_bytes': 33665, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00019784285076893693, 'batch_size': 8, 'epochs': 95, 'weight_decay': 2.2790780354299242e-06, 'dropout': 0.40984481537098816, 'hidden_size': 17, 'd_model': 16, 't_pooled': 192, 'label_smoothing': 0.007391155221791325, 'use_focal_loss': False, 'focal_gamma': 4.205113941343911, 'grad_clip_norm': 1.3326993475638984, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 8233, 'model_storage_size_kb': 17.688085937500002, 'model_size_validation': 'PASS'}
2025-10-13 04:55:49,767 - INFO - _models.training_function_executor - BO Objective: base=0.8144, size_penalty=0.0000, final=0.8144
2025-10-13 04:55:49,767 - INFO - _models.training_function_executor - Model: 8,233 parameters, 17.7KB (PASS 256KB limit)
2025-10-13 04:55:49,767 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 1358.316s
2025-10-13 04:55:49,843 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8144
2025-10-13 04:55:49,843 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.075s
2025-10-13 04:55:49,843 - INFO - bo.run_bo - Recorded observation #7: hparams={'lr': 0.00019784285076893693, 'batch_size': np.int64(8), 'epochs': np.int64(95), 'weight_decay': 2.2790780354299242e-06, 'dropout': 0.40984481537098816, 'hidden_size': np.int64(17), 'd_model': np.int64(16), 't_pooled': np.int64(192), 'label_smoothing': 0.007391155221791325, 'use_focal_loss': np.False_, 'focal_gamma': 4.205113941343911, 'grad_clip_norm': 1.3326993475638984, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.8144
2025-10-13 04:55:49,843 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 7: {'lr': 0.00019784285076893693, 'batch_size': np.int64(8), 'epochs': np.int64(95), 'weight_decay': 2.2790780354299242e-06, 'dropout': 0.40984481537098816, 'hidden_size': np.int64(17), 'd_model': np.int64(16), 't_pooled': np.int64(192), 'label_smoothing': 0.007391155221791325, 'use_focal_loss': np.False_, 'focal_gamma': 4.205113941343911, 'grad_clip_norm': 1.3326993475638984, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.8144
2025-10-13 04:55:49,843 - INFO - bo.run_bo - üîçBO Trial 8: Using RF surrogate + Expected Improvement
2025-10-13 04:55:49,843 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 04:55:49,843 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 8 (NaN monitoring active)
2025-10-13 04:55:49,843 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 04:55:49,843 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 04:55:49,843 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00011192515664157624, 'batch_size': 8, 'epochs': 19, 'weight_decay': 2.11135649385118e-06, 'dropout': 0.1528933985126136, 'hidden_size': 20, 'd_model': 13, 't_pooled': 384, 'label_smoothing': 0.0225741214010377, 'use_focal_loss': True, 'focal_gamma': 3.5980790814347685, 'grad_clip_norm': 0.35268333991304585, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 04:55:49,844 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00011192515664157624, 'batch_size': 8, 'epochs': 19, 'weight_decay': 2.11135649385118e-06, 'dropout': 0.1528933985126136, 'hidden_size': 20, 'd_model': 13, 't_pooled': 384, 'label_smoothing': 0.0225741214010377, 'use_focal_loss': True, 'focal_gamma': 3.5980790814347685, 'grad_clip_norm': 0.35268333991304585, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 04:56:07,601 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.4090 | val_loss=0.2539 | val_acc=0.6932 | time=17.8s
2025-10-13 04:56:22,526 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.3012 | val_loss=0.2055 | val_acc=0.7399 | time=14.9s
2025-10-13 04:56:37,376 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.2592 | val_loss=0.1812 | val_acc=0.7518 | time=14.8s
2025-10-13 04:56:52,285 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.2384 | val_loss=0.1714 | val_acc=0.7587 | time=14.9s
2025-10-13 04:57:07,253 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.2296 | val_loss=0.1705 | val_acc=0.7635 | time=15.0s
2025-10-13 04:57:22,246 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.2144 | val_loss=0.1578 | val_acc=0.7668 | time=15.0s
2025-10-13 04:57:37,254 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.2055 | val_loss=0.1597 | val_acc=0.7736 | time=15.0s
2025-10-13 04:57:52,228 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.1989 | val_loss=0.1797 | val_acc=0.7595 | time=15.0s
2025-10-13 04:58:07,275 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.1935 | val_loss=0.1521 | val_acc=0.7801 | time=15.0s
2025-10-13 04:58:22,325 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.1867 | val_loss=0.1497 | val_acc=0.7805 | time=15.0s
2025-10-13 04:58:37,315 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.1824 | val_loss=0.1530 | val_acc=0.7757 | time=15.0s
2025-10-13 04:58:52,252 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.1813 | val_loss=0.1450 | val_acc=0.7850 | time=14.9s
2025-10-13 04:59:07,235 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.1776 | val_loss=0.1489 | val_acc=0.7882 | time=15.0s
2025-10-13 04:59:22,213 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.1761 | val_loss=0.1617 | val_acc=0.7773 | time=15.0s
2025-10-13 04:59:37,159 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.1740 | val_loss=0.1490 | val_acc=0.7837 | time=14.9s
2025-10-13 04:59:52,054 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.1732 | val_loss=0.1416 | val_acc=0.7869 | time=14.9s
2025-10-13 05:00:07,019 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.1712 | val_loss=0.1476 | val_acc=0.7903 | time=15.0s
2025-10-13 05:00:22,090 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.1671 | val_loss=0.1497 | val_acc=0.7872 | time=15.1s
2025-10-13 05:00:37,041 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.1685 | val_loss=0.1437 | val_acc=0.7904 | time=15.0s
2025-10-13 05:00:37,044 - INFO - _models.training_function_executor - Quantized model size: 52033 bytes.
2025-10-13 05:00:38,143 - INFO - _models.training_function_executor - Model: 8,761 parameters, 37.6KB storage
2025-10-13 05:00:38,144 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.40896950484281824, 0.3011940800694708, 0.25920087606119663, 0.23843697103033462, 0.22962236786042795, 0.21439478052864785, 0.2055413383493571, 0.1989244654236637, 0.1934864708346484, 0.1867086235675449, 0.18237142278248883, 0.181312382529639, 0.177555144431373, 0.1760865735855572, 0.17404634114889456, 0.17320201699954474, 0.1712077904089747, 0.16711462821969048, 0.1685114348279788], 'val_losses': [0.2539285471507061, 0.20554223439682603, 0.18120518297486407, 0.17144065958180124, 0.1704533589533786, 0.1577924581444739, 0.15971234400903675, 0.17973924191107293, 0.1520778302702757, 0.14965054898212787, 0.15304765335160628, 0.14502572893883184, 0.14887017744492595, 0.16173339786062113, 0.14901055014060824, 0.1415573626115793, 0.1475644216130823, 0.14968909429916627, 0.14365977114346823], 'val_acc': [0.6932096604830241, 0.7399369968498425, 0.7517500875043752, 0.7586629331466573, 0.7634756737836892, 0.7668008400420021, 0.7736261813090655, 0.7594504725236262, 0.7801015050752538, 0.7804515225761288, 0.7757262863143157, 0.7850017500875044, 0.7881519075953798, 0.7773013650682534, 0.783689184459223, 0.7869268463423171, 0.79025201260063, 0.7871893594679734, 0.7904270213510676], 'model_size_bytes': 52033, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00011192515664157624, 'batch_size': 8, 'epochs': 19, 'weight_decay': 2.11135649385118e-06, 'dropout': 0.1528933985126136, 'hidden_size': 20, 'd_model': 13, 't_pooled': 384, 'label_smoothing': 0.0225741214010377, 'use_focal_loss': True, 'focal_gamma': 3.5980790814347685, 'grad_clip_norm': 0.35268333991304585, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 8761, 'model_storage_size_kb': 37.644921875, 'model_size_validation': 'PASS'}
2025-10-13 05:00:38,144 - INFO - _models.training_function_executor - BO Objective: base=0.7904, size_penalty=0.0000, final=0.7904
2025-10-13 05:00:38,144 - INFO - _models.training_function_executor - Model: 8,761 parameters, 37.6KB (PASS 256KB limit)
2025-10-13 05:00:38,144 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 288.300s
2025-10-13 05:00:38,223 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7904
2025-10-13 05:00:38,223 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.078s
2025-10-13 05:00:38,223 - INFO - bo.run_bo - Recorded observation #8: hparams={'lr': 0.00011192515664157624, 'batch_size': np.int64(8), 'epochs': np.int64(19), 'weight_decay': 2.11135649385118e-06, 'dropout': 0.1528933985126136, 'hidden_size': np.int64(20), 'd_model': np.int64(13), 't_pooled': np.int64(384), 'label_smoothing': 0.0225741214010377, 'use_focal_loss': np.True_, 'focal_gamma': 3.5980790814347685, 'grad_clip_norm': 0.35268333991304585, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7904
2025-10-13 05:00:38,223 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 8: {'lr': 0.00011192515664157624, 'batch_size': np.int64(8), 'epochs': np.int64(19), 'weight_decay': 2.11135649385118e-06, 'dropout': 0.1528933985126136, 'hidden_size': np.int64(20), 'd_model': np.int64(13), 't_pooled': np.int64(384), 'label_smoothing': 0.0225741214010377, 'use_focal_loss': np.True_, 'focal_gamma': 3.5980790814347685, 'grad_clip_norm': 0.35268333991304585, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7904
2025-10-13 05:00:38,223 - INFO - bo.run_bo - üîçBO Trial 9: Using RF surrogate + Expected Improvement
2025-10-13 05:00:38,223 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 05:00:38,223 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 9 (NaN monitoring active)
2025-10-13 05:00:38,223 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 05:00:38,223 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 05:00:38,223 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.142976599637404e-05, 'batch_size': 32, 'epochs': 75, 'weight_decay': 0.005442809569460645, 'dropout': 0.32717465541324975, 'hidden_size': 20, 'd_model': 13, 't_pooled': 256, 'label_smoothing': 0.03233218354220558, 'use_focal_loss': False, 'focal_gamma': 4.015926058052669, 'grad_clip_norm': 1.2635177957606922, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 05:00:38,224 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.142976599637404e-05, 'batch_size': 32, 'epochs': 75, 'weight_decay': 0.005442809569460645, 'dropout': 0.32717465541324975, 'hidden_size': 20, 'd_model': 13, 't_pooled': 256, 'label_smoothing': 0.03233218354220558, 'use_focal_loss': False, 'focal_gamma': 4.015926058052669, 'grad_clip_norm': 1.2635177957606922, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 05:00:46,218 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5781 | val_loss=1.5039 | val_acc=0.4640 | time=8.0s
2025-10-13 05:00:51,387 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.4261 | val_loss=1.3248 | val_acc=0.5825 | time=5.2s
2025-10-13 05:00:56,578 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2551 | val_loss=1.1606 | val_acc=0.6173 | time=5.2s
2025-10-13 05:01:01,765 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1176 | val_loss=1.0408 | val_acc=0.6382 | time=5.2s
2025-10-13 05:01:06,945 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0292 | val_loss=0.9665 | val_acc=0.6413 | time=5.2s
2025-10-13 05:01:12,122 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9764 | val_loss=0.9170 | val_acc=0.6492 | time=5.2s
2025-10-13 05:01:17,296 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9397 | val_loss=0.8881 | val_acc=0.6552 | time=5.2s
2025-10-13 05:01:22,490 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.9204 | val_loss=0.8690 | val_acc=0.6710 | time=5.2s
2025-10-13 05:01:27,659 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9091 | val_loss=0.8570 | val_acc=0.6742 | time=5.2s
2025-10-13 05:01:32,829 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8952 | val_loss=0.8455 | val_acc=0.6845 | time=5.2s
2025-10-13 05:01:38,013 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8858 | val_loss=0.8365 | val_acc=0.6952 | time=5.2s
2025-10-13 05:01:43,201 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.8733 | val_loss=0.8302 | val_acc=0.6886 | time=5.2s
2025-10-13 05:01:48,366 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.8654 | val_loss=0.8200 | val_acc=0.7032 | time=5.2s
2025-10-13 05:01:53,539 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.8598 | val_loss=0.8111 | val_acc=0.7090 | time=5.2s
2025-10-13 05:01:58,714 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.8545 | val_loss=0.8054 | val_acc=0.7125 | time=5.2s
2025-10-13 05:02:03,910 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.8414 | val_loss=0.7962 | val_acc=0.7155 | time=5.2s
2025-10-13 05:02:09,090 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.8333 | val_loss=0.7911 | val_acc=0.7228 | time=5.2s
2025-10-13 05:02:14,268 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.8268 | val_loss=0.7841 | val_acc=0.7265 | time=5.2s
2025-10-13 05:02:19,461 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.8224 | val_loss=0.7773 | val_acc=0.7298 | time=5.2s
2025-10-13 05:02:24,655 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8168 | val_loss=0.7808 | val_acc=0.7233 | time=5.2s
2025-10-13 05:02:29,821 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8121 | val_loss=0.7706 | val_acc=0.7345 | time=5.2s
2025-10-13 05:02:35,011 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8068 | val_loss=0.7633 | val_acc=0.7356 | time=5.2s
2025-10-13 05:02:40,193 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.7963 | val_loss=0.7607 | val_acc=0.7371 | time=5.2s
2025-10-13 05:02:45,379 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.7936 | val_loss=0.7563 | val_acc=0.7405 | time=5.2s
2025-10-13 05:02:50,558 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.7923 | val_loss=0.7473 | val_acc=0.7445 | time=5.2s
2025-10-13 05:02:55,737 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.7868 | val_loss=0.7467 | val_acc=0.7440 | time=5.2s
2025-10-13 05:03:00,923 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.7785 | val_loss=0.7391 | val_acc=0.7484 | time=5.2s
2025-10-13 05:03:06,098 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.7781 | val_loss=0.7371 | val_acc=0.7482 | time=5.2s
2025-10-13 05:03:11,264 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.7722 | val_loss=0.7423 | val_acc=0.7463 | time=5.2s
2025-10-13 05:03:16,437 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.7691 | val_loss=0.7355 | val_acc=0.7497 | time=5.2s
2025-10-13 05:03:21,608 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.7649 | val_loss=0.7230 | val_acc=0.7567 | time=5.2s
2025-10-13 05:03:26,809 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.7565 | val_loss=0.7221 | val_acc=0.7547 | time=5.2s
2025-10-13 05:03:31,980 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.7528 | val_loss=0.7183 | val_acc=0.7566 | time=5.2s
2025-10-13 05:03:37,159 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.7557 | val_loss=0.7153 | val_acc=0.7553 | time=5.2s
2025-10-13 05:03:42,358 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.7484 | val_loss=0.7102 | val_acc=0.7584 | time=5.2s
2025-10-13 05:03:47,549 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.7502 | val_loss=0.7132 | val_acc=0.7586 | time=5.2s
2025-10-13 05:03:52,726 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.7427 | val_loss=0.7043 | val_acc=0.7629 | time=5.2s
2025-10-13 05:03:57,913 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.7396 | val_loss=0.7035 | val_acc=0.7594 | time=5.2s
2025-10-13 05:04:03,107 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.7378 | val_loss=0.7008 | val_acc=0.7609 | time=5.2s
2025-10-13 05:04:08,327 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.7377 | val_loss=0.7019 | val_acc=0.7638 | time=5.2s
2025-10-13 05:04:13,523 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.7312 | val_loss=0.6963 | val_acc=0.7656 | time=5.2s
2025-10-13 05:04:18,722 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.7300 | val_loss=0.6927 | val_acc=0.7678 | time=5.2s
2025-10-13 05:04:23,937 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.7293 | val_loss=0.6920 | val_acc=0.7676 | time=5.2s
2025-10-13 05:04:29,148 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.7234 | val_loss=0.7001 | val_acc=0.7653 | time=5.2s
2025-10-13 05:04:34,344 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.7255 | val_loss=0.6868 | val_acc=0.7684 | time=5.2s
2025-10-13 05:04:39,552 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.7232 | val_loss=0.6955 | val_acc=0.7646 | time=5.2s
2025-10-13 05:04:44,754 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.7190 | val_loss=0.6837 | val_acc=0.7700 | time=5.2s
2025-10-13 05:04:49,966 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.7162 | val_loss=0.6818 | val_acc=0.7714 | time=5.2s
2025-10-13 05:04:55,159 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.7147 | val_loss=0.6790 | val_acc=0.7736 | time=5.2s
2025-10-13 05:05:00,360 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.7140 | val_loss=0.6754 | val_acc=0.7749 | time=5.2s
2025-10-13 05:05:05,578 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.7096 | val_loss=0.6741 | val_acc=0.7746 | time=5.2s
2025-10-13 05:05:10,779 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.7097 | val_loss=0.6725 | val_acc=0.7735 | time=5.2s
2025-10-13 05:05:15,976 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.7088 | val_loss=0.6813 | val_acc=0.7714 | time=5.2s
2025-10-13 05:05:21,174 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.7052 | val_loss=0.6692 | val_acc=0.7763 | time=5.2s
2025-10-13 05:05:26,377 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.7047 | val_loss=0.6748 | val_acc=0.7757 | time=5.2s
2025-10-13 05:05:31,588 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.7034 | val_loss=0.6712 | val_acc=0.7778 | time=5.2s
2025-10-13 05:05:36,791 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.7026 | val_loss=0.6669 | val_acc=0.7770 | time=5.2s
2025-10-13 05:05:41,992 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.6984 | val_loss=0.6659 | val_acc=0.7769 | time=5.2s
2025-10-13 05:05:47,197 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.6992 | val_loss=0.6682 | val_acc=0.7768 | time=5.2s
2025-10-13 05:05:52,397 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.6948 | val_loss=0.6626 | val_acc=0.7784 | time=5.2s
2025-10-13 05:05:57,614 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.6946 | val_loss=0.6599 | val_acc=0.7815 | time=5.2s
2025-10-13 05:06:02,825 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.6959 | val_loss=0.6664 | val_acc=0.7778 | time=5.2s
2025-10-13 05:06:08,038 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.6934 | val_loss=0.6602 | val_acc=0.7820 | time=5.2s
2025-10-13 05:06:13,253 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.6935 | val_loss=0.6589 | val_acc=0.7798 | time=5.2s
2025-10-13 05:06:18,452 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.6927 | val_loss=0.6561 | val_acc=0.7820 | time=5.2s
2025-10-13 05:06:23,652 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.6853 | val_loss=0.6562 | val_acc=0.7828 | time=5.2s
2025-10-13 05:06:28,858 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.6868 | val_loss=0.6655 | val_acc=0.7775 | time=5.2s
2025-10-13 05:06:34,079 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.6886 | val_loss=0.6529 | val_acc=0.7834 | time=5.2s
2025-10-13 05:06:39,279 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.6872 | val_loss=0.6526 | val_acc=0.7832 | time=5.2s
2025-10-13 05:06:44,469 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.6847 | val_loss=0.6512 | val_acc=0.7836 | time=5.2s
2025-10-13 05:06:49,662 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.6822 | val_loss=0.6551 | val_acc=0.7801 | time=5.2s
2025-10-13 05:06:54,877 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.6834 | val_loss=0.6519 | val_acc=0.7846 | time=5.2s
2025-10-13 05:07:00,081 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.6839 | val_loss=0.6554 | val_acc=0.7813 | time=5.2s
2025-10-13 05:07:05,300 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.6849 | val_loss=0.6528 | val_acc=0.7815 | time=5.2s
2025-10-13 05:07:10,515 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.6801 | val_loss=0.6462 | val_acc=0.7854 | time=5.2s
2025-10-13 05:07:10,529 - INFO - _models.training_function_executor - Quantized model size: 41211 bytes.
2025-10-13 05:07:11,616 - INFO - _models.training_function_executor - Model: 4,356 parameters, 4.7KB storage
2025-10-13 05:07:11,616 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.578101727067068, 1.4260767274775787, 1.2551151621704715, 1.117564893912134, 1.0291595856418216, 0.9763863218552506, 0.9396697804775112, 0.9203570546034044, 0.9090662662032437, 0.8951995958178703, 0.8858052372390005, 0.8732794496534919, 0.8654219003503123, 0.8598363190253047, 0.8544801680157975, 0.8413671941493498, 0.8332850859638357, 0.8267751810514806, 0.8223571452511996, 0.816780221245278, 0.8121034871417825, 0.8067837892022632, 0.7962666691121497, 0.7936015604132324, 0.792279149879306, 0.7867563269044037, 0.7785135241793217, 0.7781481275952359, 0.7722332014418333, 0.7690669149212542, 0.7648915433366272, 0.7565363576498155, 0.7528443939417945, 0.7556858666301149, 0.748444254034501, 0.7501850037629846, 0.7426754078708164, 0.7395980415704745, 0.7377750242469943, 0.7377073424530897, 0.7311972579340189, 0.7300407118550288, 0.729328364978773, 0.7234123757680814, 0.7254798692717267, 0.7231515152995971, 0.7190439652887557, 0.7162344755724172, 0.714719198302535, 0.7140341000954171, 0.7095752873222937, 0.7097286604316159, 0.7088205860050817, 0.705197300888418, 0.7047434950525793, 0.7034316576148899, 0.7025852654002787, 0.6984488390357418, 0.6991885963502696, 0.694758432037479, 0.6946273607977379, 0.6958864385071107, 0.6934429233542346, 0.6934748142175338, 0.6926781072623254, 0.6853393066542776, 0.686762582225152, 0.6885523457063175, 0.6871842405451399, 0.6846589369084563, 0.6822428636338939, 0.6834062099415061, 0.6839081336870284, 0.6849489725675039, 0.6800753537658047], 'val_losses': [1.5038941050894326, 1.324836506015736, 1.16064181843545, 1.0407910619868572, 0.9664697372750631, 0.9170249835944985, 0.8881083511788819, 0.8689717673153822, 0.8570409839621448, 0.8455075909718376, 0.836510608193755, 0.8302233042022671, 0.8199815513122153, 0.811052592580119, 0.8053829737964693, 0.7962492328028934, 0.7910693441607295, 0.7840817491408199, 0.7773037574947986, 0.7808431287224075, 0.7706303144193922, 0.7632602180973984, 0.7606595891273894, 0.7562614882121689, 0.7473193928625436, 0.7466802288069774, 0.7390842963900648, 0.7371269149883752, 0.7422792172573812, 0.7355282743744054, 0.722983695178087, 0.7221269170158093, 0.718297401142571, 0.7152674453092448, 0.710210639319722, 0.7132338909239965, 0.7042955156594337, 0.7035015734876834, 0.7007986827980692, 0.7018615394194392, 0.6962826940660339, 0.6926891683676796, 0.6919594387887948, 0.7000710734400584, 0.686800964017577, 0.6955322283399994, 0.6837366233662288, 0.6818453112827718, 0.67904215287528, 0.6753925395712888, 0.6740571637127756, 0.6724857345176486, 0.6813429310516248, 0.669162978377424, 0.6747999020418922, 0.6711677494043231, 0.6669449844392062, 0.6658915126703401, 0.6681570016841267, 0.6625945260881919, 0.6598846978518693, 0.666364129623584, 0.6602265283095073, 0.6589001405581253, 0.656146501228448, 0.6562144417403084, 0.6654784879798775, 0.6529254148608953, 0.6526243032214105, 0.6512311683862744, 0.6551026022847315, 0.651913956981211, 0.6554182781637403, 0.6527942296066691, 0.6462152703349975], 'val_acc': [0.46403570178508924, 0.5825166258312916, 0.6173433671683585, 0.6381694084704235, 0.6413195659782989, 0.6491949597479874, 0.6552327616380819, 0.6709835491774588, 0.674221211060553, 0.6845467273363668, 0.6952222611130556, 0.6885719285964298, 0.7031851592579629, 0.7090479523976199, 0.7125481274063703, 0.7155232761638082, 0.7227861393069653, 0.7264613230661533, 0.7297864893244662, 0.7233111655582779, 0.7345117255862793, 0.7355617780889044, 0.7371368568428421, 0.7405495274763738, 0.7444872243612181, 0.7439621981099055, 0.7484249212460623, 0.7482499124956248, 0.746324816240812, 0.7497374868743437, 0.7567378368918446, 0.7547252362618131, 0.7565628281414071, 0.7552502625131257, 0.758400420021001, 0.7585754287714386, 0.7628631431571579, 0.7593629681484074, 0.7608505425271264, 0.7638256912845642, 0.7655757787889395, 0.7677633881694085, 0.767588379418971, 0.7653132656632832, 0.7683759187959398, 0.7646132306615331, 0.7699509975498775, 0.7713510675533777, 0.7736261813090655, 0.7748512425621281, 0.7745887294364718, 0.7734511725586279, 0.7714385719285964, 0.776338816940847, 0.7757262863143157, 0.777826391319566, 0.7770388519425971, 0.7768638431921596, 0.7767763388169409, 0.7783514175708786, 0.781501575078754, 0.777826391319566, 0.7820266013300665, 0.7797514875743787, 0.7820266013300665, 0.7828141407070354, 0.777476373818691, 0.7834266713335667, 0.7831641582079104, 0.7836016800840042, 0.7801015050752538, 0.7845642282114106, 0.7813265663283164, 0.781501575078754, 0.7854392719635982], 'model_size_bytes': 41211, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.142976599637404e-05, 'batch_size': 32, 'epochs': 75, 'weight_decay': 0.005442809569460645, 'dropout': 0.32717465541324975, 'hidden_size': 20, 'd_model': 13, 't_pooled': 256, 'label_smoothing': 0.03233218354220558, 'use_focal_loss': False, 'focal_gamma': 4.015926058052669, 'grad_clip_norm': 1.2635177957606922, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 4356, 'model_storage_size_kb': 4.679296875, 'model_size_validation': 'PASS'}
2025-10-13 05:07:11,616 - INFO - _models.training_function_executor - BO Objective: base=0.7854, size_penalty=0.0000, final=0.7854
2025-10-13 05:07:11,616 - INFO - _models.training_function_executor - Model: 4,356 parameters, 4.7KB (PASS 256KB limit)
2025-10-13 05:07:11,616 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 393.393s
2025-10-13 05:07:11,698 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7854
2025-10-13 05:07:11,699 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.080s
2025-10-13 05:07:11,699 - INFO - bo.run_bo - Recorded observation #9: hparams={'lr': 2.142976599637404e-05, 'batch_size': np.int64(32), 'epochs': np.int64(75), 'weight_decay': 0.005442809569460645, 'dropout': 0.32717465541324975, 'hidden_size': np.int64(20), 'd_model': np.int64(13), 't_pooled': np.int64(256), 'label_smoothing': 0.03233218354220558, 'use_focal_loss': np.False_, 'focal_gamma': 4.015926058052669, 'grad_clip_norm': 1.2635177957606922, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.7854
2025-10-13 05:07:11,699 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 9: {'lr': 2.142976599637404e-05, 'batch_size': np.int64(32), 'epochs': np.int64(75), 'weight_decay': 0.005442809569460645, 'dropout': 0.32717465541324975, 'hidden_size': np.int64(20), 'd_model': np.int64(13), 't_pooled': np.int64(256), 'label_smoothing': 0.03233218354220558, 'use_focal_loss': np.False_, 'focal_gamma': 4.015926058052669, 'grad_clip_norm': 1.2635177957606922, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.7854
2025-10-13 05:07:11,699 - INFO - bo.run_bo - üîçBO Trial 10: Using RF surrogate + Expected Improvement
2025-10-13 05:07:11,699 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 05:07:11,699 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 10 (NaN monitoring active)
2025-10-13 05:07:11,699 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 05:07:11,699 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 05:07:11,699 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0005001485177141082, 'batch_size': 8, 'epochs': 34, 'weight_decay': 0.005011120421307978, 'dropout': 0.0029767634955411024, 'hidden_size': 15, 'd_model': 8, 't_pooled': 128, 'label_smoothing': 0.1936748158409837, 'use_focal_loss': True, 'focal_gamma': 3.508018657616258, 'grad_clip_norm': 0.5943097195866732, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 05:07:11,700 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0005001485177141082, 'batch_size': 8, 'epochs': 34, 'weight_decay': 0.005011120421307978, 'dropout': 0.0029767634955411024, 'hidden_size': 15, 'd_model': 8, 't_pooled': 128, 'label_smoothing': 0.1936748158409837, 'use_focal_loss': True, 'focal_gamma': 3.508018657616258, 'grad_clip_norm': 0.5943097195866732, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 05:07:29,358 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.3348 | val_loss=0.2344 | val_acc=0.7447 | time=17.7s
2025-10-13 05:07:44,356 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.2594 | val_loss=0.2101 | val_acc=0.7562 | time=15.0s
2025-10-13 05:07:59,248 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.2396 | val_loss=0.1915 | val_acc=0.7702 | time=14.9s
2025-10-13 05:08:14,014 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.2281 | val_loss=0.1762 | val_acc=0.7838 | time=14.8s
2025-10-13 05:08:28,973 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.2186 | val_loss=0.1862 | val_acc=0.7778 | time=15.0s
2025-10-13 05:08:43,858 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.2123 | val_loss=0.1807 | val_acc=0.7828 | time=14.9s
2025-10-13 05:08:58,625 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.2060 | val_loss=0.1790 | val_acc=0.7861 | time=14.8s
2025-10-13 05:09:13,529 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.2027 | val_loss=0.1688 | val_acc=0.7982 | time=14.9s
2025-10-13 05:09:28,215 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.1985 | val_loss=0.1724 | val_acc=0.7939 | time=14.7s
2025-10-13 05:09:43,087 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.1964 | val_loss=0.1696 | val_acc=0.7918 | time=14.9s
2025-10-13 05:09:58,033 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.1936 | val_loss=0.1714 | val_acc=0.7903 | time=14.9s
2025-10-13 05:10:12,970 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.1896 | val_loss=0.1769 | val_acc=0.7815 | time=14.9s
2025-10-13 05:10:27,884 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.1872 | val_loss=0.1641 | val_acc=0.7929 | time=14.9s
2025-10-13 05:10:42,741 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.1896 | val_loss=0.1650 | val_acc=0.7968 | time=14.9s
2025-10-13 05:10:57,603 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.1854 | val_loss=0.1670 | val_acc=0.7918 | time=14.9s
2025-10-13 05:11:12,399 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.1834 | val_loss=0.1652 | val_acc=0.7966 | time=14.8s
2025-10-13 05:11:27,241 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.1818 | val_loss=0.1700 | val_acc=0.7939 | time=14.8s
2025-10-13 05:11:42,180 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.1796 | val_loss=0.1677 | val_acc=0.7928 | time=14.9s
2025-10-13 05:11:57,130 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.1802 | val_loss=0.1786 | val_acc=0.7854 | time=15.0s
2025-10-13 05:12:11,968 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.1783 | val_loss=0.1690 | val_acc=0.7943 | time=14.8s
2025-10-13 05:12:26,798 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.1779 | val_loss=0.1660 | val_acc=0.7930 | time=14.8s
2025-10-13 05:12:41,714 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.1764 | val_loss=0.1726 | val_acc=0.7939 | time=14.9s
2025-10-13 05:12:56,568 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.1758 | val_loss=0.1705 | val_acc=0.7924 | time=14.9s
2025-10-13 05:13:11,435 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.1763 | val_loss=0.1758 | val_acc=0.7896 | time=14.9s
2025-10-13 05:13:26,296 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.1740 | val_loss=0.1601 | val_acc=0.8014 | time=14.9s
2025-10-13 05:13:41,192 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.1721 | val_loss=0.1629 | val_acc=0.8034 | time=14.9s
2025-10-13 05:13:56,026 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.1724 | val_loss=0.1563 | val_acc=0.8069 | time=14.8s
2025-10-13 05:14:10,831 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.1715 | val_loss=0.1630 | val_acc=0.8001 | time=14.8s
2025-10-13 05:14:25,645 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.1706 | val_loss=0.1604 | val_acc=0.8045 | time=14.8s
2025-10-13 05:14:40,496 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.1695 | val_loss=0.1546 | val_acc=0.8089 | time=14.9s
2025-10-13 05:14:55,343 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.1707 | val_loss=0.1634 | val_acc=0.7973 | time=14.8s
2025-10-13 05:15:10,253 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.1687 | val_loss=0.1511 | val_acc=0.8090 | time=14.9s
2025-10-13 05:15:25,228 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.1684 | val_loss=0.1545 | val_acc=0.7973 | time=15.0s
2025-10-13 05:15:40,053 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.1666 | val_loss=0.1755 | val_acc=0.7963 | time=14.8s
2025-10-13 05:15:40,057 - INFO - _models.training_function_executor - Quantized model size: 43457 bytes.
2025-10-13 05:15:41,151 - INFO - _models.training_function_executor - Model: 6,579 parameters, 28.3KB storage
2025-10-13 05:15:41,151 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.334815406034504, 0.25938416858284224, 0.2396210259083159, 0.22813774975952925, 0.2185806015942873, 0.21227855060874143, 0.205989638890528, 0.20270797061236132, 0.19851649604161753, 0.1963902050868853, 0.19359283327275942, 0.1895867774833814, 0.18717092092076917, 0.1895969738895455, 0.1853974199671941, 0.1833828708159714, 0.18175265429202286, 0.17956823280378936, 0.1801832319052054, 0.17825731930960562, 0.177861351810841, 0.17641032748882707, 0.1758413447844928, 0.17634949436869915, 0.17402741508967495, 0.17209338658059972, 0.1724392790407644, 0.1714679229149098, 0.17058710642750638, 0.16946212200533975, 0.1706824383286366, 0.16874786239910491, 0.1684260559138719, 0.1665793510418259], 'val_losses': [0.23440288378093307, 0.21006115953580437, 0.1915012830845545, 0.1762390436932554, 0.18617589122983785, 0.18066514612559853, 0.17896448606726253, 0.1688134617794476, 0.17235717273391926, 0.16960272479881908, 0.17143832059270034, 0.17691654838311285, 0.1640835594676636, 0.16499243362874866, 0.16699669993422875, 0.1652088708077689, 0.16997402916425408, 0.16766964248063726, 0.17864098051503577, 0.1689749322010163, 0.16604714741194304, 0.17263674122204115, 0.17049705518421346, 0.17583074633848336, 0.16011723379467932, 0.16287951877860285, 0.1562883909084333, 0.16302701963928662, 0.160361240365623, 0.1546321560758778, 0.16340981136471566, 0.15114988381284952, 0.15451491808001763, 0.1754981094914579], 'val_acc': [0.7447497374868743, 0.756212810640532, 0.7702135106755338, 0.7837766888344417, 0.777826391319566, 0.7828141407070354, 0.7860518025901295, 0.7982149107455373, 0.793927196359818, 0.7918270913545677, 0.79025201260063, 0.781501575078754, 0.7928771438571929, 0.7968148407420371, 0.7918270913545677, 0.7966398319915996, 0.793927196359818, 0.7927896394819741, 0.7853517675883794, 0.794277213860693, 0.7929646482324116, 0.793927196359818, 0.7923521176058803, 0.78955197759888, 0.8013650682534127, 0.8033776688834442, 0.8068778438921946, 0.80014000700035, 0.8045152257612881, 0.8088904445222261, 0.7973398669933497, 0.8089779488974449, 0.7973398669933497, 0.7962898144907246], 'model_size_bytes': 43457, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0005001485177141082, 'batch_size': 8, 'epochs': 34, 'weight_decay': 0.005011120421307978, 'dropout': 0.0029767634955411024, 'hidden_size': 15, 'd_model': 8, 't_pooled': 128, 'label_smoothing': 0.1936748158409837, 'use_focal_loss': True, 'focal_gamma': 3.508018657616258, 'grad_clip_norm': 0.5943097195866732, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 6579, 'model_storage_size_kb': 28.269140625000002, 'model_size_validation': 'PASS'}
2025-10-13 05:15:41,151 - INFO - _models.training_function_executor - BO Objective: base=0.7963, size_penalty=0.0000, final=0.7963
2025-10-13 05:15:41,151 - INFO - _models.training_function_executor - Model: 6,579 parameters, 28.3KB (PASS 256KB limit)
2025-10-13 05:15:41,151 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 509.452s
2025-10-13 05:15:41,232 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7963
2025-10-13 05:15:41,232 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.080s
2025-10-13 05:15:41,232 - INFO - bo.run_bo - Recorded observation #10: hparams={'lr': 0.0005001485177141082, 'batch_size': np.int64(8), 'epochs': np.int64(34), 'weight_decay': 0.005011120421307978, 'dropout': 0.0029767634955411024, 'hidden_size': np.int64(15), 'd_model': np.int64(8), 't_pooled': np.int64(128), 'label_smoothing': 0.1936748158409837, 'use_focal_loss': np.True_, 'focal_gamma': 3.508018657616258, 'grad_clip_norm': 0.5943097195866732, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.7963
2025-10-13 05:15:41,232 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 10: {'lr': 0.0005001485177141082, 'batch_size': np.int64(8), 'epochs': np.int64(34), 'weight_decay': 0.005011120421307978, 'dropout': 0.0029767634955411024, 'hidden_size': np.int64(15), 'd_model': np.int64(8), 't_pooled': np.int64(128), 'label_smoothing': 0.1936748158409837, 'use_focal_loss': np.True_, 'focal_gamma': 3.508018657616258, 'grad_clip_norm': 0.5943097195866732, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.7963
2025-10-13 05:15:41,233 - INFO - bo.run_bo - üîçBO Trial 11: Using RF surrogate + Expected Improvement
2025-10-13 05:15:41,233 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 05:15:41,233 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 11 (NaN monitoring active)
2025-10-13 05:15:41,233 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 05:15:41,233 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 05:15:41,233 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00029705717269595523, 'batch_size': 16, 'epochs': 7, 'weight_decay': 0.0010057247118849361, 'dropout': 0.24029832943315416, 'hidden_size': 24, 'd_model': 20, 't_pooled': 128, 'label_smoothing': 0.14394652756900767, 'use_focal_loss': False, 'focal_gamma': 0.6854090833014282, 'grad_clip_norm': 2.3718351580331567, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 05:15:41,234 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00029705717269595523, 'batch_size': 16, 'epochs': 7, 'weight_decay': 0.0010057247118849361, 'dropout': 0.24029832943315416, 'hidden_size': 24, 'd_model': 20, 't_pooled': 128, 'label_smoothing': 0.14394652756900767, 'use_focal_loss': False, 'focal_gamma': 0.6854090833014282, 'grad_clip_norm': 2.3718351580331567, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 05:15:51,208 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.1037 | val_loss=0.9307 | val_acc=0.7630 | time=10.0s
2025-10-13 05:15:58,368 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.9626 | val_loss=0.9004 | val_acc=0.7792 | time=7.2s
2025-10-13 05:16:05,465 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.9414 | val_loss=0.8814 | val_acc=0.7911 | time=7.1s
2025-10-13 05:16:12,618 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9273 | val_loss=0.8826 | val_acc=0.7875 | time=7.2s
2025-10-13 05:16:19,795 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9182 | val_loss=0.8707 | val_acc=0.7957 | time=7.2s
2025-10-13 05:16:26,947 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9098 | val_loss=0.8843 | val_acc=0.7853 | time=7.2s
2025-10-13 05:16:34,136 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9049 | val_loss=0.8703 | val_acc=0.7929 | time=7.2s
2025-10-13 05:16:34,140 - INFO - _models.training_function_executor - Quantized model size: 63617 bytes.
2025-10-13 05:16:35,222 - INFO - _models.training_function_executor - Model: 11,538 parameters, 49.6KB storage
2025-10-13 05:16:35,222 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1036790055664512, 0.9625598061614659, 0.9414051782012528, 0.927337659398367, 0.9182398942412302, 0.9097984933252304, 0.9049266675447392], 'val_losses': [0.9306698271474682, 0.9004453494075633, 0.881404307784006, 0.8826452482401761, 0.8707185875171959, 0.8843473968782916, 0.8703327280347648], 'val_acc': [0.7630381519075954, 0.7792264613230662, 0.7911270563528177, 0.7875393769688485, 0.7956772838641932, 0.7852642632131607, 0.7928771438571929], 'model_size_bytes': 63617, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00029705717269595523, 'batch_size': 16, 'epochs': 7, 'weight_decay': 0.0010057247118849361, 'dropout': 0.24029832943315416, 'hidden_size': 24, 'd_model': 20, 't_pooled': 128, 'label_smoothing': 0.14394652756900767, 'use_focal_loss': False, 'focal_gamma': 0.6854090833014282, 'grad_clip_norm': 2.3718351580331567, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 11538, 'model_storage_size_kb': 49.577343750000004, 'model_size_validation': 'PASS'}
2025-10-13 05:16:35,222 - INFO - _models.training_function_executor - BO Objective: base=0.7929, size_penalty=0.0000, final=0.7929
2025-10-13 05:16:35,222 - INFO - _models.training_function_executor - Model: 11,538 parameters, 49.6KB (PASS 256KB limit)
2025-10-13 05:16:35,222 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 53.990s
2025-10-13 05:16:35,306 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7929
2025-10-13 05:16:35,306 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.082s
2025-10-13 05:16:35,306 - INFO - bo.run_bo - Recorded observation #11: hparams={'lr': 0.00029705717269595523, 'batch_size': np.int64(16), 'epochs': np.int64(7), 'weight_decay': 0.0010057247118849361, 'dropout': 0.24029832943315416, 'hidden_size': np.int64(24), 'd_model': np.int64(20), 't_pooled': np.int64(128), 'label_smoothing': 0.14394652756900767, 'use_focal_loss': np.False_, 'focal_gamma': 0.6854090833014282, 'grad_clip_norm': 2.3718351580331567, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.7929
2025-10-13 05:16:35,306 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 11: {'lr': 0.00029705717269595523, 'batch_size': np.int64(16), 'epochs': np.int64(7), 'weight_decay': 0.0010057247118849361, 'dropout': 0.24029832943315416, 'hidden_size': np.int64(24), 'd_model': np.int64(20), 't_pooled': np.int64(128), 'label_smoothing': 0.14394652756900767, 'use_focal_loss': np.False_, 'focal_gamma': 0.6854090833014282, 'grad_clip_norm': 2.3718351580331567, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.7929
2025-10-13 05:16:35,306 - INFO - bo.run_bo - üîçBO Trial 12: Using RF surrogate + Expected Improvement
2025-10-13 05:16:35,306 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 05:16:35,306 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 12 (NaN monitoring active)
2025-10-13 05:16:35,306 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 05:16:35,306 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 05:16:35,306 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0002021957590857316, 'batch_size': 8, 'epochs': 73, 'weight_decay': 0.0010003915101412042, 'dropout': 0.2889635313249583, 'hidden_size': 12, 'd_model': 12, 't_pooled': 256, 'label_smoothing': 0.1644084631538397, 'use_focal_loss': True, 'focal_gamma': 1.8394553240818148, 'grad_clip_norm': 0.07833408019672695, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 05:16:35,307 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0002021957590857316, 'batch_size': 8, 'epochs': 73, 'weight_decay': 0.0010003915101412042, 'dropout': 0.2889635313249583, 'hidden_size': 12, 'd_model': 12, 't_pooled': 256, 'label_smoothing': 0.1644084631538397, 'use_focal_loss': True, 'focal_gamma': 1.8394553240818148, 'grad_clip_norm': 0.07833408019672695, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 05:16:52,921 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.6618 | val_loss=0.4528 | val_acc=0.7078 | time=17.6s
2025-10-13 05:17:07,803 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5234 | val_loss=0.4279 | val_acc=0.7258 | time=14.9s
2025-10-13 05:17:22,784 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4723 | val_loss=0.3727 | val_acc=0.7648 | time=15.0s
2025-10-13 05:17:37,705 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4434 | val_loss=0.3541 | val_acc=0.7702 | time=14.9s
2025-10-13 05:17:52,542 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4259 | val_loss=0.3454 | val_acc=0.7725 | time=14.8s
2025-10-13 05:18:07,493 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4123 | val_loss=0.3388 | val_acc=0.7797 | time=15.0s
2025-10-13 05:18:22,458 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4040 | val_loss=0.3522 | val_acc=0.7749 | time=15.0s
2025-10-13 05:18:37,427 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3976 | val_loss=0.3307 | val_acc=0.7817 | time=15.0s
2025-10-13 05:18:52,400 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3869 | val_loss=0.3346 | val_acc=0.7841 | time=15.0s
2025-10-13 05:19:07,373 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3797 | val_loss=0.3266 | val_acc=0.7909 | time=15.0s
2025-10-13 05:19:22,327 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3754 | val_loss=0.3292 | val_acc=0.7894 | time=15.0s
2025-10-13 05:19:37,245 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3680 | val_loss=0.3192 | val_acc=0.7906 | time=14.9s
2025-10-13 05:19:52,208 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3647 | val_loss=0.3295 | val_acc=0.7871 | time=15.0s
2025-10-13 05:20:07,094 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3616 | val_loss=0.3166 | val_acc=0.7896 | time=14.9s
2025-10-13 05:20:22,007 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3568 | val_loss=0.3262 | val_acc=0.7905 | time=14.9s
2025-10-13 05:20:36,942 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3535 | val_loss=0.3153 | val_acc=0.7906 | time=14.9s
2025-10-13 05:20:51,847 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3515 | val_loss=0.3276 | val_acc=0.7904 | time=14.9s
2025-10-13 05:21:06,795 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3477 | val_loss=0.3290 | val_acc=0.7847 | time=14.9s
2025-10-13 05:21:21,652 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3458 | val_loss=0.3203 | val_acc=0.7854 | time=14.9s
2025-10-13 05:21:36,554 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3451 | val_loss=0.3128 | val_acc=0.7943 | time=14.9s
2025-10-13 05:21:51,344 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3427 | val_loss=0.3093 | val_acc=0.7972 | time=14.8s
2025-10-13 05:22:06,258 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3400 | val_loss=0.3153 | val_acc=0.7942 | time=14.9s
2025-10-13 05:22:21,243 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3383 | val_loss=0.3056 | val_acc=0.7942 | time=15.0s
2025-10-13 05:22:36,179 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3372 | val_loss=0.3305 | val_acc=0.7880 | time=14.9s
2025-10-13 05:22:51,097 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3353 | val_loss=0.3016 | val_acc=0.7983 | time=14.9s
2025-10-13 05:23:05,905 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.3375 | val_loss=0.3323 | val_acc=0.7847 | time=14.8s
2025-10-13 05:23:20,810 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.3349 | val_loss=0.3129 | val_acc=0.7979 | time=14.9s
2025-10-13 05:23:35,604 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.3310 | val_loss=0.3312 | val_acc=0.7888 | time=14.8s
2025-10-13 05:23:50,420 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.3360 | val_loss=0.3260 | val_acc=0.7930 | time=14.8s
2025-10-13 05:24:05,339 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.3308 | val_loss=0.3115 | val_acc=0.7992 | time=14.9s
2025-10-13 05:24:20,346 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.3293 | val_loss=0.3292 | val_acc=0.7915 | time=15.0s
2025-10-13 05:24:35,303 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.3278 | val_loss=0.3037 | val_acc=0.7975 | time=15.0s
2025-10-13 05:24:50,137 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.3301 | val_loss=0.3012 | val_acc=0.8018 | time=14.8s
2025-10-13 05:25:05,075 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.3280 | val_loss=0.3047 | val_acc=0.7999 | time=14.9s
2025-10-13 05:25:19,952 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.3270 | val_loss=0.3212 | val_acc=0.7943 | time=14.9s
2025-10-13 05:25:34,896 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.3250 | val_loss=0.3288 | val_acc=0.7897 | time=14.9s
2025-10-13 05:25:49,878 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.3256 | val_loss=0.3155 | val_acc=0.7972 | time=15.0s
2025-10-13 05:26:04,846 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.3226 | val_loss=0.3074 | val_acc=0.7999 | time=15.0s
2025-10-13 05:26:19,754 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.3256 | val_loss=0.3115 | val_acc=0.8014 | time=14.9s
2025-10-13 05:26:34,678 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.3263 | val_loss=0.3249 | val_acc=0.7896 | time=14.9s
2025-10-13 05:26:49,573 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.3229 | val_loss=0.3098 | val_acc=0.7993 | time=14.9s
2025-10-13 05:27:04,366 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.3209 | val_loss=0.3186 | val_acc=0.7957 | time=14.8s
2025-10-13 05:27:19,319 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.3190 | val_loss=0.3194 | val_acc=0.7897 | time=15.0s
2025-10-13 05:27:34,119 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.3204 | val_loss=0.3090 | val_acc=0.7943 | time=14.8s
2025-10-13 05:27:49,023 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.3208 | val_loss=0.3047 | val_acc=0.8023 | time=14.9s
2025-10-13 05:28:04,076 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.3201 | val_loss=0.3050 | val_acc=0.8008 | time=15.1s
2025-10-13 05:28:18,811 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.3197 | val_loss=0.3069 | val_acc=0.7993 | time=14.7s
2025-10-13 05:28:33,808 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.3174 | val_loss=0.3291 | val_acc=0.7890 | time=15.0s
2025-10-13 05:28:48,671 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.3181 | val_loss=0.3143 | val_acc=0.7981 | time=14.9s
2025-10-13 05:29:03,597 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.3172 | val_loss=0.3070 | val_acc=0.8029 | time=14.9s
2025-10-13 05:29:18,444 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.3169 | val_loss=0.3014 | val_acc=0.8044 | time=14.8s
2025-10-13 05:29:33,131 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.3165 | val_loss=0.3091 | val_acc=0.8002 | time=14.7s
2025-10-13 05:29:47,937 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.3135 | val_loss=0.3053 | val_acc=0.8025 | time=14.8s
2025-10-13 05:30:02,909 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.3140 | val_loss=0.3073 | val_acc=0.8030 | time=15.0s
2025-10-13 05:30:17,856 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.3137 | val_loss=0.3023 | val_acc=0.8010 | time=14.9s
2025-10-13 05:30:32,794 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.3158 | val_loss=0.3150 | val_acc=0.7987 | time=14.9s
2025-10-13 05:30:47,806 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.3130 | val_loss=0.3004 | val_acc=0.8007 | time=15.0s
2025-10-13 05:31:02,690 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.3131 | val_loss=0.3057 | val_acc=0.8044 | time=14.9s
2025-10-13 05:31:17,621 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.3139 | val_loss=0.3157 | val_acc=0.7992 | time=14.9s
2025-10-13 05:31:32,446 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.3120 | val_loss=0.3101 | val_acc=0.8049 | time=14.8s
2025-10-13 05:31:47,231 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.3131 | val_loss=0.3094 | val_acc=0.8042 | time=14.8s
2025-10-13 05:32:02,181 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.3099 | val_loss=0.3202 | val_acc=0.7980 | time=14.9s
2025-10-13 05:32:17,137 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.3115 | val_loss=0.3102 | val_acc=0.8010 | time=15.0s
2025-10-13 05:32:32,033 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.3115 | val_loss=0.3136 | val_acc=0.8015 | time=14.9s
2025-10-13 05:32:47,030 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.3104 | val_loss=0.2962 | val_acc=0.8049 | time=15.0s
2025-10-13 05:33:01,878 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.3094 | val_loss=0.3146 | val_acc=0.7983 | time=14.8s
2025-10-13 05:33:16,728 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.3079 | val_loss=0.3075 | val_acc=0.8017 | time=14.8s
2025-10-13 05:33:31,509 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.3096 | val_loss=0.3018 | val_acc=0.8067 | time=14.8s
2025-10-13 05:33:46,421 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.3106 | val_loss=0.3102 | val_acc=0.8041 | time=14.9s
2025-10-13 05:34:01,372 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.3045 | val_loss=0.3172 | val_acc=0.7996 | time=15.0s
2025-10-13 05:34:16,373 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.3075 | val_loss=0.3079 | val_acc=0.8017 | time=15.0s
2025-10-13 05:34:31,328 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.3076 | val_loss=0.2992 | val_acc=0.8075 | time=15.0s
2025-10-13 05:34:46,194 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.3080 | val_loss=0.3092 | val_acc=0.8006 | time=14.9s
2025-10-13 05:34:46,197 - INFO - _models.training_function_executor - Quantized model size: 42561 bytes.
2025-10-13 05:34:47,312 - INFO - _models.training_function_executor - Model: 6,320 parameters, 27.2KB storage
2025-10-13 05:34:47,313 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.6617947384887197, 0.5234483187515543, 0.47230434024072127, 0.4433767168189695, 0.4259303047787561, 0.4123374521950736, 0.403970413217383, 0.3975568562527642, 0.38686287001043945, 0.37970178744191413, 0.37543232839340707, 0.36799284693578665, 0.36468248792829777, 0.36160509167992083, 0.35682643307757583, 0.3534589689753045, 0.35150918443607393, 0.3477463752864529, 0.34582719940752166, 0.3450898666105614, 0.34272084549857623, 0.34004248498434037, 0.3382866162817181, 0.3371898770439258, 0.33531262175566956, 0.33753992231692476, 0.33485130139841385, 0.3309875927667636, 0.3359620181193636, 0.3307764068037913, 0.32925311885177594, 0.3277598214560665, 0.33012926311055796, 0.32803365293780057, 0.32703979561443736, 0.3250073731919613, 0.3255726760390221, 0.3226218646176102, 0.32555903574271866, 0.3263412856587819, 0.3228684752002928, 0.320859094548548, 0.3189900854754362, 0.320397860869895, 0.3207617039633488, 0.3200841430409384, 0.3196958850447896, 0.3174093495754918, 0.3181293294631404, 0.3172285810304792, 0.31687078951211894, 0.3164558686730985, 0.31349764090884796, 0.3139942066191761, 0.3136765690253755, 0.31575538448822815, 0.31298068774365984, 0.31305475176142844, 0.3139484036894105, 0.31196485661064094, 0.313117745009456, 0.30986440921541974, 0.3115458301606151, 0.3115161673585067, 0.31042953572321735, 0.3093768178291702, 0.3079229831487093, 0.3095817383227816, 0.3105842663337192, 0.3045393897121558, 0.3075301840635376, 0.3076120147588808, 0.3080446440916402], 'val_losses': [0.45276351544796106, 0.42789010483723317, 0.37266276744714266, 0.35407276215839517, 0.34543815048494286, 0.3388244508432161, 0.3522298665268045, 0.33074845549268117, 0.33456553682544077, 0.3266453651987123, 0.32922767829847555, 0.3192058470847309, 0.32952340772211824, 0.31660946339530505, 0.32618449194018434, 0.31532602972492163, 0.3276300829465902, 0.3289976065269729, 0.32033730755955514, 0.31275017052761084, 0.3093250018339454, 0.31533520960659417, 0.30555396246383837, 0.33048575836610955, 0.3016008929899409, 0.332303162930826, 0.31287045341498804, 0.33116456553096124, 0.3260302912074868, 0.3114773983551117, 0.3291959049226439, 0.3037111282004399, 0.30117105786311466, 0.30468807649747515, 0.3212443285578999, 0.328835224491532, 0.3154885912520076, 0.3074323444525846, 0.31151349704691766, 0.32485303678867655, 0.30976370752045523, 0.31858694537989024, 0.3194096254065534, 0.309049800112661, 0.3047456481516176, 0.3050021306922256, 0.3069380088182838, 0.3290791560575955, 0.3142861785640302, 0.3070434307178178, 0.3014307701958576, 0.3091248497229994, 0.30531835170462074, 0.3072731288534282, 0.3023345975093165, 0.3150288004240384, 0.3004181636986347, 0.3057159490542376, 0.3157154923685659, 0.3100591007417011, 0.3094140774753606, 0.32019802117741436, 0.31017341674264753, 0.3135623828519206, 0.2962175936737718, 0.31460979386660803, 0.30751000855399685, 0.30180891886360667, 0.31017401935399036, 0.3172398128818641, 0.3079317849658177, 0.29915484391778085, 0.3091959560274984], 'val_acc': [0.7078228911445572, 0.725848792439622, 0.7647882394119706, 0.7702135106755338, 0.7724886244312216, 0.77966398319916, 0.7748512425621281, 0.7816765838291915, 0.7841267063353168, 0.7908645432271614, 0.7893769688484424, 0.7906020301015051, 0.7871018550927547, 0.7896394819740987, 0.7905145257262863, 0.7906020301015051, 0.7904270213510676, 0.7847392369618481, 0.7853517675883794, 0.794277213860693, 0.7971648582429122, 0.7941897094854743, 0.7941897094854743, 0.7879768988449423, 0.7983024151207561, 0.7846517325866293, 0.7978648932446623, 0.7887644382219111, 0.7929646482324116, 0.7991774588729437, 0.7914770738536927, 0.7975148757437872, 0.8018025901295065, 0.7998774938746938, 0.794277213860693, 0.7897269863493175, 0.7971648582429122, 0.7998774938746938, 0.8013650682534127, 0.7896394819740987, 0.7992649632481624, 0.7956772838641932, 0.7897269863493175, 0.794277213860693, 0.8023276163808191, 0.8007525376268814, 0.7992649632481624, 0.7890269513475674, 0.7981274063703185, 0.8028526426321316, 0.8044277213860693, 0.8002275113755688, 0.8025026251312566, 0.8030276513825692, 0.8010150507525376, 0.7986524326216311, 0.8006650332516626, 0.8044277213860693, 0.7991774588729437, 0.8048652432621631, 0.804165208260413, 0.7980399019950998, 0.8010150507525376, 0.8015400770038502, 0.8048652432621631, 0.7983024151207561, 0.8017150857542877, 0.8067028351417571, 0.8040777038851943, 0.7996149807490375, 0.8017150857542877, 0.807490374518726, 0.8005775288764438], 'model_size_bytes': 42561, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0002021957590857316, 'batch_size': 8, 'epochs': 73, 'weight_decay': 0.0010003915101412042, 'dropout': 0.2889635313249583, 'hidden_size': 12, 'd_model': 12, 't_pooled': 256, 'label_smoothing': 0.1644084631538397, 'use_focal_loss': True, 'focal_gamma': 1.8394553240818148, 'grad_clip_norm': 0.07833408019672695, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 6320, 'model_storage_size_kb': 27.156250000000004, 'model_size_validation': 'PASS'}
2025-10-13 05:34:47,313 - INFO - _models.training_function_executor - BO Objective: base=0.8006, size_penalty=0.0000, final=0.8006
2025-10-13 05:34:47,313 - INFO - _models.training_function_executor - Model: 6,320 parameters, 27.2KB (PASS 256KB limit)
2025-10-13 05:34:47,313 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 1092.007s
2025-10-13 05:34:47,397 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8006
2025-10-13 05:34:47,398 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.084s
2025-10-13 05:34:47,398 - INFO - bo.run_bo - Recorded observation #12: hparams={'lr': 0.0002021957590857316, 'batch_size': np.int64(8), 'epochs': np.int64(73), 'weight_decay': 0.0010003915101412042, 'dropout': 0.2889635313249583, 'hidden_size': np.int64(12), 'd_model': np.int64(12), 't_pooled': np.int64(256), 'label_smoothing': 0.1644084631538397, 'use_focal_loss': np.True_, 'focal_gamma': 1.8394553240818148, 'grad_clip_norm': 0.07833408019672695, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.8006
2025-10-13 05:34:47,398 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 12: {'lr': 0.0002021957590857316, 'batch_size': np.int64(8), 'epochs': np.int64(73), 'weight_decay': 0.0010003915101412042, 'dropout': 0.2889635313249583, 'hidden_size': np.int64(12), 'd_model': np.int64(12), 't_pooled': np.int64(256), 'label_smoothing': 0.1644084631538397, 'use_focal_loss': np.True_, 'focal_gamma': 1.8394553240818148, 'grad_clip_norm': 0.07833408019672695, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.8006
2025-10-13 05:34:47,398 - INFO - bo.run_bo - üîçBO Trial 13: Using RF surrogate + Expected Improvement
2025-10-13 05:34:47,398 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 05:34:47,398 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 13 (NaN monitoring active)
2025-10-13 05:34:47,398 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 05:34:47,398 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 05:34:47,398 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0001489872394167183, 'batch_size': 16, 'epochs': 68, 'weight_decay': 0.00692761642348596, 'dropout': 0.11193094447686477, 'hidden_size': 27, 'd_model': 18, 't_pooled': 320, 'label_smoothing': 0.14786640246280536, 'use_focal_loss': False, 'focal_gamma': 2.6280184002764773, 'grad_clip_norm': 3.9275420809917923, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 05:34:47,399 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0001489872394167183, 'batch_size': 16, 'epochs': 68, 'weight_decay': 0.00692761642348596, 'dropout': 0.11193094447686477, 'hidden_size': 27, 'd_model': 18, 't_pooled': 320, 'label_smoothing': 0.14786640246280536, 'use_focal_loss': False, 'focal_gamma': 2.6280184002764773, 'grad_clip_norm': 3.9275420809917923, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 05:34:57,962 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.2008 | val_loss=1.0631 | val_acc=0.6692 | time=10.6s
2025-10-13 05:35:05,706 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.0593 | val_loss=0.9839 | val_acc=0.7300 | time=7.7s
2025-10-13 05:35:13,477 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.0003 | val_loss=0.9679 | val_acc=0.7420 | time=7.8s
2025-10-13 05:35:21,239 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9739 | val_loss=0.9387 | val_acc=0.7580 | time=7.8s
2025-10-13 05:35:29,038 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9617 | val_loss=0.9202 | val_acc=0.7678 | time=7.8s
2025-10-13 05:35:36,843 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9469 | val_loss=0.9088 | val_acc=0.7795 | time=7.8s
2025-10-13 05:35:44,655 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9395 | val_loss=0.9054 | val_acc=0.7774 | time=7.8s
2025-10-13 05:35:52,478 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.9322 | val_loss=0.8998 | val_acc=0.7812 | time=7.8s
2025-10-13 05:36:00,312 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9283 | val_loss=0.9021 | val_acc=0.7778 | time=7.8s
2025-10-13 05:36:08,083 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9220 | val_loss=0.8974 | val_acc=0.7817 | time=7.8s
2025-10-13 05:36:15,876 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.9167 | val_loss=0.9015 | val_acc=0.7786 | time=7.8s
2025-10-13 05:36:23,716 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9134 | val_loss=0.8916 | val_acc=0.7875 | time=7.8s
2025-10-13 05:36:31,508 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9095 | val_loss=0.8855 | val_acc=0.7904 | time=7.8s
2025-10-13 05:36:39,299 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.9047 | val_loss=0.8898 | val_acc=0.7923 | time=7.8s
2025-10-13 05:36:47,117 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.9051 | val_loss=0.8892 | val_acc=0.7904 | time=7.8s
2025-10-13 05:36:54,914 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.8979 | val_loss=0.8795 | val_acc=0.7966 | time=7.8s
2025-10-13 05:37:02,716 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.8986 | val_loss=0.9011 | val_acc=0.7862 | time=7.8s
2025-10-13 05:37:10,503 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.8970 | val_loss=0.8805 | val_acc=0.7903 | time=7.8s
2025-10-13 05:37:18,328 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.8949 | val_loss=0.8823 | val_acc=0.7922 | time=7.8s
2025-10-13 05:37:26,147 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8925 | val_loss=0.8838 | val_acc=0.7883 | time=7.8s
2025-10-13 05:37:33,927 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8883 | val_loss=0.8795 | val_acc=0.7920 | time=7.8s
2025-10-13 05:37:41,735 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8877 | val_loss=0.8733 | val_acc=0.7973 | time=7.8s
2025-10-13 05:37:49,503 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8870 | val_loss=0.8752 | val_acc=0.7987 | time=7.8s
2025-10-13 05:37:57,308 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8864 | val_loss=0.8745 | val_acc=0.7971 | time=7.8s
2025-10-13 05:38:05,093 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8841 | val_loss=0.8798 | val_acc=0.7949 | time=7.8s
2025-10-13 05:38:12,853 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8813 | val_loss=0.8877 | val_acc=0.7861 | time=7.8s
2025-10-13 05:38:20,628 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8812 | val_loss=0.8822 | val_acc=0.7898 | time=7.8s
2025-10-13 05:38:28,417 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8813 | val_loss=0.8717 | val_acc=0.7984 | time=7.8s
2025-10-13 05:38:36,222 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8779 | val_loss=0.8690 | val_acc=0.8008 | time=7.8s
2025-10-13 05:38:44,044 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8790 | val_loss=0.8690 | val_acc=0.7980 | time=7.8s
2025-10-13 05:38:51,907 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8756 | val_loss=0.8655 | val_acc=0.8021 | time=7.9s
2025-10-13 05:38:59,692 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.8751 | val_loss=0.8659 | val_acc=0.8022 | time=7.8s
2025-10-13 05:39:07,483 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.8715 | val_loss=0.8653 | val_acc=0.8051 | time=7.8s
2025-10-13 05:39:15,307 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.8714 | val_loss=0.8917 | val_acc=0.7924 | time=7.8s
2025-10-13 05:39:23,066 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.8708 | val_loss=0.8605 | val_acc=0.8049 | time=7.8s
2025-10-13 05:39:30,840 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.8697 | val_loss=0.8614 | val_acc=0.8053 | time=7.8s
2025-10-13 05:39:38,652 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.8703 | val_loss=0.8688 | val_acc=0.7996 | time=7.8s
2025-10-13 05:39:46,459 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.8677 | val_loss=0.8619 | val_acc=0.8077 | time=7.8s
2025-10-13 05:39:54,287 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.8688 | val_loss=0.8678 | val_acc=0.8003 | time=7.8s
2025-10-13 05:40:02,121 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.8671 | val_loss=0.8600 | val_acc=0.8067 | time=7.8s
2025-10-13 05:40:09,923 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.8664 | val_loss=0.8630 | val_acc=0.8081 | time=7.8s
2025-10-13 05:40:17,733 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.8626 | val_loss=0.8560 | val_acc=0.8054 | time=7.8s
2025-10-13 05:40:25,542 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.8620 | val_loss=0.8618 | val_acc=0.8062 | time=7.8s
2025-10-13 05:40:33,331 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.8626 | val_loss=0.8554 | val_acc=0.8093 | time=7.8s
2025-10-13 05:40:41,116 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.8629 | val_loss=0.8551 | val_acc=0.8078 | time=7.8s
2025-10-13 05:40:48,882 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.8623 | val_loss=0.8590 | val_acc=0.8062 | time=7.8s
2025-10-13 05:40:56,632 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.8607 | val_loss=0.8654 | val_acc=0.8009 | time=7.8s
2025-10-13 05:41:04,424 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.8594 | val_loss=0.8638 | val_acc=0.8037 | time=7.8s
2025-10-13 05:41:12,201 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.8584 | val_loss=0.8595 | val_acc=0.8088 | time=7.8s
2025-10-13 05:41:20,014 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.8555 | val_loss=0.8691 | val_acc=0.8016 | time=7.8s
2025-10-13 05:41:27,778 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.8571 | val_loss=0.9043 | val_acc=0.7839 | time=7.8s
2025-10-13 05:41:35,587 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.8566 | val_loss=0.8517 | val_acc=0.8118 | time=7.8s
2025-10-13 05:41:43,359 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.8571 | val_loss=0.8552 | val_acc=0.8078 | time=7.8s
2025-10-13 05:41:51,173 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.8528 | val_loss=0.8595 | val_acc=0.8049 | time=7.8s
2025-10-13 05:41:58,983 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.8566 | val_loss=0.8481 | val_acc=0.8141 | time=7.8s
2025-10-13 05:42:06,776 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.8538 | val_loss=0.8573 | val_acc=0.8059 | time=7.8s
2025-10-13 05:42:14,614 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.8528 | val_loss=0.8496 | val_acc=0.8129 | time=7.8s
2025-10-13 05:42:22,434 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.8534 | val_loss=0.8462 | val_acc=0.8109 | time=7.8s
2025-10-13 05:42:30,227 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.8523 | val_loss=0.8545 | val_acc=0.8107 | time=7.8s
2025-10-13 05:42:38,038 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.8519 | val_loss=0.8513 | val_acc=0.8092 | time=7.8s
2025-10-13 05:42:45,853 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.8505 | val_loss=0.8551 | val_acc=0.8078 | time=7.8s
2025-10-13 05:42:53,724 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.8516 | val_loss=0.8622 | val_acc=0.8060 | time=7.9s
2025-10-13 05:43:01,547 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.8500 | val_loss=0.8521 | val_acc=0.8097 | time=7.8s
2025-10-13 05:43:09,380 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.8491 | val_loss=0.8465 | val_acc=0.8128 | time=7.8s
2025-10-13 05:43:17,189 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.8500 | val_loss=0.8531 | val_acc=0.8108 | time=7.8s
2025-10-13 05:43:25,035 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.8486 | val_loss=0.8687 | val_acc=0.8006 | time=7.8s
2025-10-13 05:43:32,870 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.8487 | val_loss=0.8606 | val_acc=0.8031 | time=7.8s
2025-10-13 05:43:40,690 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.8469 | val_loss=0.8455 | val_acc=0.8100 | time=7.8s
2025-10-13 05:43:40,694 - INFO - _models.training_function_executor - Quantized model size: 67201 bytes.
2025-10-13 05:43:41,800 - INFO - _models.training_function_executor - Model: 12,447 parameters, 53.5KB storage
2025-10-13 05:43:41,800 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2008455702171152, 1.0592513888667503, 1.0002735472451485, 0.9738759113893586, 0.9617472179377459, 0.9469295003466728, 0.9395421190740848, 0.9321528332901868, 0.9283448895208061, 0.9219852533839489, 0.9167427362200677, 0.9133833827445004, 0.9095300224681062, 0.9047262726607839, 0.9051478072234205, 0.897947003760453, 0.8985512944047251, 0.8970001151313889, 0.894904440898014, 0.8925481009908935, 0.8883298895431642, 0.8877336607974102, 0.8870193497426117, 0.8864309434128008, 0.8841464213445381, 0.8813223520650453, 0.8811829764608491, 0.8813097187802639, 0.8779267640559457, 0.8790183339162352, 0.8756255748850256, 0.8751387986679531, 0.8714899667334965, 0.8714464441812827, 0.8708286327334355, 0.8696997261439582, 0.8703010925513947, 0.8676627072830654, 0.8687738840255363, 0.8670674771080912, 0.866360728103129, 0.8625872956108371, 0.8620415764919811, 0.8625789404040581, 0.8628762315777494, 0.862265661395343, 0.8606800462843281, 0.8594400303781888, 0.8584358369423704, 0.8554865458564905, 0.8571483204529174, 0.8565855664225529, 0.857107296017529, 0.8527684448313622, 0.8565780258612654, 0.8538187468097809, 0.8528424145710565, 0.8533520602996341, 0.8523095950906745, 0.8518623594099465, 0.8504638096482594, 0.8515630704688159, 0.8499951252246345, 0.8490643264699074, 0.8499746024712925, 0.8485880708168718, 0.8487015327123816, 0.8469282274776962], 'val_losses': [1.0631001402040774, 0.9838838455849775, 0.9679482963730248, 0.9387032978593949, 0.9201967715799788, 0.9088236828721566, 0.9054012006089368, 0.899807531932955, 0.9020621298408441, 0.8973752961193802, 0.9015352267838459, 0.8915543359269785, 0.8855314668258838, 0.889815557157405, 0.8891871948946511, 0.8795329102236448, 0.9010957786784041, 0.8805145276439829, 0.882298264818088, 0.8837960373491601, 0.8795393931519372, 0.8733207800607812, 0.8751692911274249, 0.8744780087245692, 0.8798210879368593, 0.8877237224478717, 0.8821609201112492, 0.8717191542283947, 0.8689633820037722, 0.8690114496552865, 0.865473893709353, 0.8659497259753878, 0.8652946835512209, 0.8917051733979655, 0.860465049576751, 0.8613543245272491, 0.8687693677167189, 0.8618849417443121, 0.8677603557137371, 0.8600129329286174, 0.8630288678697661, 0.8560028084725569, 0.861781335728211, 0.8553876651096978, 0.8550507042597423, 0.8590024237370716, 0.8654224503319874, 0.8637888236691745, 0.8594645461420267, 0.8690874815237535, 0.9042686267378116, 0.851748152299907, 0.855214995773764, 0.8594607074735546, 0.8480761228302036, 0.8572742167911123, 0.8495871274672399, 0.8462080658420967, 0.8544504746382663, 0.8512776626295504, 0.8550885266927226, 0.8622114006188686, 0.8520596241425249, 0.8464769499678273, 0.8531236052721749, 0.8687084678340133, 0.8606160778785695, 0.8454843314744644], 'val_acc': [0.6692334616730836, 0.7299614980749037, 0.7420371018550928, 0.7579628981449072, 0.7677633881694085, 0.7794889744487224, 0.7773888694434722, 0.7811515575778789, 0.777826391319566, 0.7816765838291915, 0.7786139306965348, 0.7875393769688485, 0.7904270213510676, 0.7922646132306616, 0.7904270213510676, 0.7965523276163808, 0.786226811340567, 0.7903395169758488, 0.7921771088554428, 0.7883269163458173, 0.7920021001050053, 0.7972523626181309, 0.7987399369968499, 0.7970773538676934, 0.7948897444872244, 0.7861393069653483, 0.7898144907245362, 0.7983899194959748, 0.8007525376268814, 0.7980399019950998, 0.8020651032551628, 0.8021526076303815, 0.8051277563878194, 0.7923521176058803, 0.8048652432621631, 0.8053027651382569, 0.7996149807490375, 0.8076653832691635, 0.8003150157507876, 0.8067028351417571, 0.8081029051452573, 0.8053902695134757, 0.8061778088904445, 0.8093279663983199, 0.807840392019601, 0.8061778088904445, 0.8009275463773189, 0.8037276863843192, 0.8088029401470074, 0.801627581379069, 0.7838641932096605, 0.8117780889044452, 0.807840392019601, 0.8048652432621631, 0.814053202660133, 0.8059152957647883, 0.8129156457822891, 0.8109030451522576, 0.8107280364018201, 0.8092404620231012, 0.8077528876443822, 0.806002800140007, 0.809677983899195, 0.8128281414070704, 0.8108155407770389, 0.8005775288764438, 0.8031151557577879, 0.81002800140007], 'model_size_bytes': 67201, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0001489872394167183, 'batch_size': 16, 'epochs': 68, 'weight_decay': 0.00692761642348596, 'dropout': 0.11193094447686477, 'hidden_size': 27, 'd_model': 18, 't_pooled': 320, 'label_smoothing': 0.14786640246280536, 'use_focal_loss': False, 'focal_gamma': 2.6280184002764773, 'grad_clip_norm': 3.9275420809917923, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 12447, 'model_storage_size_kb': 53.483203125, 'model_size_validation': 'PASS'}
2025-10-13 05:43:41,801 - INFO - _models.training_function_executor - BO Objective: base=0.8100, size_penalty=0.0000, final=0.8100
2025-10-13 05:43:41,801 - INFO - _models.training_function_executor - Model: 12,447 parameters, 53.5KB (PASS 256KB limit)
2025-10-13 05:43:41,801 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 534.403s
2025-10-13 05:43:41,889 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8100
2025-10-13 05:43:41,889 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.087s
2025-10-13 05:43:41,889 - INFO - bo.run_bo - Recorded observation #13: hparams={'lr': 0.0001489872394167183, 'batch_size': np.int64(16), 'epochs': np.int64(68), 'weight_decay': 0.00692761642348596, 'dropout': 0.11193094447686477, 'hidden_size': np.int64(27), 'd_model': np.int64(18), 't_pooled': np.int64(320), 'label_smoothing': 0.14786640246280536, 'use_focal_loss': np.False_, 'focal_gamma': 2.6280184002764773, 'grad_clip_norm': 3.9275420809917923, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8100
2025-10-13 05:43:41,889 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 13: {'lr': 0.0001489872394167183, 'batch_size': np.int64(16), 'epochs': np.int64(68), 'weight_decay': 0.00692761642348596, 'dropout': 0.11193094447686477, 'hidden_size': np.int64(27), 'd_model': np.int64(18), 't_pooled': np.int64(320), 'label_smoothing': 0.14786640246280536, 'use_focal_loss': np.False_, 'focal_gamma': 2.6280184002764773, 'grad_clip_norm': 3.9275420809917923, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8100
2025-10-13 05:43:41,889 - INFO - bo.run_bo - üîçBO Trial 14: Using RF surrogate + Expected Improvement
2025-10-13 05:43:41,889 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 05:43:41,889 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 14 (NaN monitoring active)
2025-10-13 05:43:41,889 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 05:43:41,889 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 05:43:41,889 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.003868436134645473, 'batch_size': 24, 'epochs': 21, 'weight_decay': 1.7345730019454237e-05, 'dropout': 0.007910871068945393, 'hidden_size': 31, 'd_model': 11, 't_pooled': 256, 'label_smoothing': 0.15393275042304427, 'use_focal_loss': False, 'focal_gamma': 3.7258330924412166, 'grad_clip_norm': 4.626106044025408, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 05:43:41,890 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.003868436134645473, 'batch_size': 24, 'epochs': 21, 'weight_decay': 1.7345730019454237e-05, 'dropout': 0.007910871068945393, 'hidden_size': 31, 'd_model': 11, 't_pooled': 256, 'label_smoothing': 0.15393275042304427, 'use_focal_loss': False, 'focal_gamma': 3.7258330924412166, 'grad_clip_norm': 4.626106044025408, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 05:43:50,676 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.0727 | val_loss=0.9519 | val_acc=0.7547 | time=8.8s
2025-10-13 05:43:56,658 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.9634 | val_loss=0.9203 | val_acc=0.7733 | time=6.0s
2025-10-13 05:44:02,632 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.9322 | val_loss=0.8961 | val_acc=0.7852 | time=6.0s
2025-10-13 05:44:08,592 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9187 | val_loss=0.8856 | val_acc=0.7888 | time=6.0s
2025-10-13 05:44:14,553 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9079 | val_loss=0.8798 | val_acc=0.7933 | time=6.0s
2025-10-13 05:44:20,518 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.8968 | val_loss=0.8816 | val_acc=0.7952 | time=6.0s
2025-10-13 05:44:26,490 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8919 | val_loss=0.8734 | val_acc=0.8012 | time=6.0s
2025-10-13 05:44:32,465 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.8836 | val_loss=0.8651 | val_acc=0.8053 | time=6.0s
2025-10-13 05:44:38,439 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.8808 | val_loss=0.8735 | val_acc=0.7942 | time=6.0s
2025-10-13 05:44:44,413 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8759 | val_loss=0.8707 | val_acc=0.8005 | time=6.0s
2025-10-13 05:44:50,374 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8740 | val_loss=0.9177 | val_acc=0.7742 | time=6.0s
2025-10-13 05:44:56,366 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.8719 | val_loss=0.8604 | val_acc=0.8060 | time=6.0s
2025-10-13 05:45:02,336 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.8681 | val_loss=0.8556 | val_acc=0.8120 | time=6.0s
2025-10-13 05:45:08,317 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.8676 | val_loss=0.8572 | val_acc=0.8071 | time=6.0s
2025-10-13 05:45:14,279 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.8652 | val_loss=0.8907 | val_acc=0.7837 | time=6.0s
2025-10-13 05:45:20,258 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.8676 | val_loss=0.8734 | val_acc=0.8000 | time=6.0s
2025-10-13 05:45:26,220 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.8834 | val_loss=0.9245 | val_acc=0.7720 | time=6.0s
2025-10-13 05:45:32,182 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.9061 | val_loss=0.8866 | val_acc=0.7898 | time=6.0s
2025-10-13 05:45:38,161 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.8758 | val_loss=0.9511 | val_acc=0.7622 | time=6.0s
2025-10-13 05:45:44,127 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8706 | val_loss=0.8888 | val_acc=0.7870 | time=6.0s
2025-10-13 05:45:50,089 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8794 | val_loss=0.8736 | val_acc=0.7993 | time=6.0s
2025-10-13 05:45:50,092 - INFO - _models.training_function_executor - Quantized model size: 68033 bytes.
2025-10-13 05:45:51,190 - INFO - _models.training_function_executor - Model: 12,766 parameters, 54.9KB storage
2025-10-13 05:45:51,190 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.072658876199008, 0.9633663152329855, 0.9321602478931115, 0.9187073701739019, 0.9078553332016523, 0.8968276657922977, 0.8919349961298347, 0.8836481253876317, 0.8808145729194456, 0.8758916793522152, 0.873997180673431, 0.8718995154112588, 0.8681138254855953, 0.8675504035264577, 0.8651663530298492, 0.867564116057959, 0.8833709619013547, 0.9061426160570871, 0.8757803632552114, 0.87064141441902, 0.8794478367144385], 'val_losses': [0.9518664141906321, 0.9203230937043811, 0.8960718385898696, 0.8856224437923251, 0.879750334699128, 0.8815919748127022, 0.8734256593255593, 0.8650994346322903, 0.8735384096788867, 0.8706636763470216, 0.9177300562631596, 0.8603666833450964, 0.8555909285688884, 0.85716479630749, 0.8907038715280433, 0.8734240836099098, 0.9244677839806583, 0.8866030058119737, 0.9510635067876669, 0.8888268560056383, 0.8736499599697792], 'val_acc': [0.7547252362618131, 0.7732761638081904, 0.7851767588379419, 0.7887644382219111, 0.7933146657332867, 0.7951522576128807, 0.8011900595029752, 0.8053027651382569, 0.7941897094854743, 0.8004900245012251, 0.7742387119355968, 0.806002800140007, 0.8120406020301015, 0.8070528526426322, 0.783689184459223, 0.7999649982499125, 0.771963598179909, 0.7898144907245362, 0.7621631081554078, 0.7870143507175359, 0.7992649632481624], 'model_size_bytes': 68033, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.003868436134645473, 'batch_size': 24, 'epochs': 21, 'weight_decay': 1.7345730019454237e-05, 'dropout': 0.007910871068945393, 'hidden_size': 31, 'd_model': 11, 't_pooled': 256, 'label_smoothing': 0.15393275042304427, 'use_focal_loss': False, 'focal_gamma': 3.7258330924412166, 'grad_clip_norm': 4.626106044025408, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 12766, 'model_storage_size_kb': 54.85390625, 'model_size_validation': 'PASS'}
2025-10-13 05:45:51,190 - INFO - _models.training_function_executor - BO Objective: base=0.7993, size_penalty=0.0000, final=0.7993
2025-10-13 05:45:51,190 - INFO - _models.training_function_executor - Model: 12,766 parameters, 54.9KB (PASS 256KB limit)
2025-10-13 05:45:51,190 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 129.301s
2025-10-13 05:45:51,399 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7993
2025-10-13 05:45:51,399 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.207s
2025-10-13 05:45:51,399 - INFO - bo.run_bo - Recorded observation #14: hparams={'lr': 0.003868436134645473, 'batch_size': np.int64(24), 'epochs': np.int64(21), 'weight_decay': 1.7345730019454237e-05, 'dropout': 0.007910871068945393, 'hidden_size': np.int64(31), 'd_model': np.int64(11), 't_pooled': np.int64(256), 'label_smoothing': 0.15393275042304427, 'use_focal_loss': np.False_, 'focal_gamma': 3.7258330924412166, 'grad_clip_norm': 4.626106044025408, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7993
2025-10-13 05:45:51,399 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 14: {'lr': 0.003868436134645473, 'batch_size': np.int64(24), 'epochs': np.int64(21), 'weight_decay': 1.7345730019454237e-05, 'dropout': 0.007910871068945393, 'hidden_size': np.int64(31), 'd_model': np.int64(11), 't_pooled': np.int64(256), 'label_smoothing': 0.15393275042304427, 'use_focal_loss': np.False_, 'focal_gamma': 3.7258330924412166, 'grad_clip_norm': 4.626106044025408, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7993
2025-10-13 05:45:51,400 - INFO - bo.run_bo - üîçBO Trial 15: Using RF surrogate + Expected Improvement
2025-10-13 05:45:51,400 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 05:45:51,400 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 15 (NaN monitoring active)
2025-10-13 05:45:51,400 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 05:45:51,400 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 05:45:51,400 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00013304836509663059, 'batch_size': 16, 'epochs': 90, 'weight_decay': 0.007127247675967111, 'dropout': 0.4126869407791733, 'hidden_size': 19, 'd_model': 18, 't_pooled': 256, 'label_smoothing': 0.08573040055291903, 'use_focal_loss': False, 'focal_gamma': 0.23953296510722483, 'grad_clip_norm': 0.2501768833471985, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 05:45:51,401 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00013304836509663059, 'batch_size': 16, 'epochs': 90, 'weight_decay': 0.007127247675967111, 'dropout': 0.4126869407791733, 'hidden_size': 19, 'd_model': 18, 't_pooled': 256, 'label_smoothing': 0.08573040055291903, 'use_focal_loss': False, 'focal_gamma': 0.23953296510722483, 'grad_clip_norm': 0.2501768833471985, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 05:46:01,549 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.2117 | val_loss=1.0014 | val_acc=0.6536 | time=10.1s
2025-10-13 05:46:08,887 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.0230 | val_loss=0.9321 | val_acc=0.6867 | time=7.3s
2025-10-13 05:46:16,216 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.9656 | val_loss=0.8738 | val_acc=0.7339 | time=7.3s
2025-10-13 05:46:23,503 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9284 | val_loss=0.8485 | val_acc=0.7456 | time=7.3s
2025-10-13 05:46:30,884 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9009 | val_loss=0.8251 | val_acc=0.7602 | time=7.4s
2025-10-13 05:46:38,215 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.8762 | val_loss=0.8079 | val_acc=0.7705 | time=7.3s
2025-10-13 05:46:45,589 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8649 | val_loss=0.7975 | val_acc=0.7748 | time=7.4s
2025-10-13 05:46:52,922 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.8542 | val_loss=0.7819 | val_acc=0.7833 | time=7.3s
2025-10-13 05:47:00,247 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.8472 | val_loss=0.7758 | val_acc=0.7862 | time=7.3s
2025-10-13 05:47:07,617 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8385 | val_loss=0.7745 | val_acc=0.7917 | time=7.4s
2025-10-13 05:47:14,960 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8328 | val_loss=0.7697 | val_acc=0.7889 | time=7.3s
2025-10-13 05:47:22,336 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.8300 | val_loss=0.7598 | val_acc=0.7944 | time=7.4s
2025-10-13 05:47:29,687 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.8267 | val_loss=0.7674 | val_acc=0.7914 | time=7.4s
2025-10-13 05:47:37,037 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.8220 | val_loss=0.7652 | val_acc=0.7880 | time=7.4s
2025-10-13 05:47:44,387 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.8158 | val_loss=0.7611 | val_acc=0.7920 | time=7.3s
2025-10-13 05:47:51,716 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.8142 | val_loss=0.7653 | val_acc=0.7912 | time=7.3s
2025-10-13 05:47:59,036 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.8129 | val_loss=0.7552 | val_acc=0.7945 | time=7.3s
2025-10-13 05:48:06,367 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.8106 | val_loss=0.7559 | val_acc=0.7942 | time=7.3s
2025-10-13 05:48:13,717 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.8064 | val_loss=0.7514 | val_acc=0.7958 | time=7.3s
2025-10-13 05:48:21,108 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8045 | val_loss=0.7643 | val_acc=0.7882 | time=7.4s
2025-10-13 05:48:28,442 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8043 | val_loss=0.7646 | val_acc=0.7907 | time=7.3s
2025-10-13 05:48:35,791 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8007 | val_loss=0.7483 | val_acc=0.7973 | time=7.3s
2025-10-13 05:48:43,141 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.7951 | val_loss=0.7561 | val_acc=0.7917 | time=7.3s
2025-10-13 05:48:50,510 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.7987 | val_loss=0.7562 | val_acc=0.7957 | time=7.4s
2025-10-13 05:48:57,828 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.7985 | val_loss=0.7471 | val_acc=0.7961 | time=7.3s
2025-10-13 05:49:05,176 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.7925 | val_loss=0.7494 | val_acc=0.7959 | time=7.3s
2025-10-13 05:49:12,536 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.7951 | val_loss=0.7447 | val_acc=0.7983 | time=7.4s
2025-10-13 05:49:19,978 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.7881 | val_loss=0.7508 | val_acc=0.7969 | time=7.4s
2025-10-13 05:49:27,336 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.7865 | val_loss=0.7372 | val_acc=0.8008 | time=7.4s
2025-10-13 05:49:34,715 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.7850 | val_loss=0.7416 | val_acc=0.8005 | time=7.4s
2025-10-13 05:49:42,093 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.7851 | val_loss=0.7455 | val_acc=0.8007 | time=7.4s
2025-10-13 05:49:49,420 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.7838 | val_loss=0.7534 | val_acc=0.7964 | time=7.3s
2025-10-13 05:49:56,732 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.7800 | val_loss=0.7400 | val_acc=0.8022 | time=7.3s
2025-10-13 05:50:04,086 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.7785 | val_loss=0.7638 | val_acc=0.7867 | time=7.4s
2025-10-13 05:50:11,439 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.7795 | val_loss=0.7447 | val_acc=0.7979 | time=7.4s
2025-10-13 05:50:18,787 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.7794 | val_loss=0.7419 | val_acc=0.8007 | time=7.3s
2025-10-13 05:50:26,179 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.7776 | val_loss=0.7320 | val_acc=0.8073 | time=7.4s
2025-10-13 05:50:33,535 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.7759 | val_loss=0.7472 | val_acc=0.7977 | time=7.4s
2025-10-13 05:50:40,932 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.7759 | val_loss=0.7326 | val_acc=0.8037 | time=7.4s
2025-10-13 05:50:48,296 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.7701 | val_loss=0.7471 | val_acc=0.7938 | time=7.4s
2025-10-13 05:50:55,628 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.7732 | val_loss=0.7528 | val_acc=0.7950 | time=7.3s
2025-10-13 05:51:02,954 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.7704 | val_loss=0.7393 | val_acc=0.7987 | time=7.3s
2025-10-13 05:51:10,284 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.7692 | val_loss=0.7295 | val_acc=0.8037 | time=7.3s
2025-10-13 05:51:17,631 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.7691 | val_loss=0.7321 | val_acc=0.8036 | time=7.3s
2025-10-13 05:51:24,979 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.7688 | val_loss=0.7328 | val_acc=0.8045 | time=7.3s
2025-10-13 05:51:32,327 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.7663 | val_loss=0.7317 | val_acc=0.8030 | time=7.3s
2025-10-13 05:51:39,714 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.7663 | val_loss=0.7352 | val_acc=0.8022 | time=7.4s
2025-10-13 05:51:47,066 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.7622 | val_loss=0.7309 | val_acc=0.8040 | time=7.4s
2025-10-13 05:51:54,405 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.7630 | val_loss=0.7411 | val_acc=0.7981 | time=7.3s
2025-10-13 05:52:01,738 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.7638 | val_loss=0.7484 | val_acc=0.7959 | time=7.3s
2025-10-13 05:52:09,114 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.7641 | val_loss=0.7342 | val_acc=0.8031 | time=7.4s
2025-10-13 05:52:16,493 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.7617 | val_loss=0.7245 | val_acc=0.8076 | time=7.4s
2025-10-13 05:52:23,832 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.7603 | val_loss=0.7421 | val_acc=0.7979 | time=7.3s
2025-10-13 05:52:31,191 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.7580 | val_loss=0.7286 | val_acc=0.8053 | time=7.4s
2025-10-13 05:52:38,561 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.7602 | val_loss=0.7265 | val_acc=0.8026 | time=7.4s
2025-10-13 05:52:45,891 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.7569 | val_loss=0.7418 | val_acc=0.7966 | time=7.3s
2025-10-13 05:52:53,257 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.7563 | val_loss=0.7349 | val_acc=0.8030 | time=7.4s
2025-10-13 05:53:00,583 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.7572 | val_loss=0.7276 | val_acc=0.8041 | time=7.3s
2025-10-13 05:53:07,927 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.7548 | val_loss=0.7332 | val_acc=0.8005 | time=7.3s
2025-10-13 05:53:15,289 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.7554 | val_loss=0.7321 | val_acc=0.8036 | time=7.4s
2025-10-13 05:53:22,665 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.7558 | val_loss=0.7251 | val_acc=0.8064 | time=7.4s
2025-10-13 05:53:30,033 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.7532 | val_loss=0.7361 | val_acc=0.8002 | time=7.4s
2025-10-13 05:53:37,357 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.7532 | val_loss=0.7279 | val_acc=0.8060 | time=7.3s
2025-10-13 05:53:44,695 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.7511 | val_loss=0.7458 | val_acc=0.7964 | time=7.3s
2025-10-13 05:53:52,057 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.7512 | val_loss=0.7420 | val_acc=0.8008 | time=7.4s
2025-10-13 05:53:59,376 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.7508 | val_loss=0.7226 | val_acc=0.8073 | time=7.3s
2025-10-13 05:54:06,722 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.7496 | val_loss=0.7261 | val_acc=0.8078 | time=7.3s
2025-10-13 05:54:14,053 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.7511 | val_loss=0.7348 | val_acc=0.8033 | time=7.3s
2025-10-13 05:54:21,408 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.7486 | val_loss=0.7346 | val_acc=0.8006 | time=7.4s
2025-10-13 05:54:28,720 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.7477 | val_loss=0.7278 | val_acc=0.8065 | time=7.3s
2025-10-13 05:54:36,047 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.7484 | val_loss=0.7223 | val_acc=0.8078 | time=7.3s
2025-10-13 05:54:43,392 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.7498 | val_loss=0.7284 | val_acc=0.8053 | time=7.3s
2025-10-13 05:54:50,783 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.7472 | val_loss=0.7212 | val_acc=0.8080 | time=7.4s
2025-10-13 05:54:58,097 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.7471 | val_loss=0.7233 | val_acc=0.8085 | time=7.3s
2025-10-13 05:55:05,443 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.7452 | val_loss=0.7215 | val_acc=0.8079 | time=7.3s
2025-10-13 05:55:12,772 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.7464 | val_loss=0.7275 | val_acc=0.8071 | time=7.3s
2025-10-13 05:55:20,111 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.7445 | val_loss=0.7172 | val_acc=0.8114 | time=7.3s
2025-10-13 05:55:27,459 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.7442 | val_loss=0.7171 | val_acc=0.8111 | time=7.3s
2025-10-13 05:55:34,800 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.7463 | val_loss=0.7191 | val_acc=0.8103 | time=7.3s
2025-10-13 05:55:42,133 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.7442 | val_loss=0.7178 | val_acc=0.8098 | time=7.3s
2025-10-13 05:55:49,448 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.7426 | val_loss=0.7320 | val_acc=0.8035 | time=7.3s
2025-10-13 05:55:56,794 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.7440 | val_loss=0.7235 | val_acc=0.8079 | time=7.3s
2025-10-13 05:56:04,129 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.7402 | val_loss=0.7184 | val_acc=0.8117 | time=7.3s
2025-10-13 05:56:11,454 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.7421 | val_loss=0.7226 | val_acc=0.8073 | time=7.3s
2025-10-13 05:56:18,781 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.7439 | val_loss=0.7229 | val_acc=0.8094 | time=7.3s
2025-10-13 05:56:26,095 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.7438 | val_loss=0.7266 | val_acc=0.8063 | time=7.3s
2025-10-13 05:56:33,424 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.7403 | val_loss=0.7587 | val_acc=0.7922 | time=7.3s
2025-10-13 05:56:40,732 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.7438 | val_loss=0.7284 | val_acc=0.8079 | time=7.3s
2025-10-13 05:56:48,068 - INFO - _models.training_function_executor - Epoch 089 | train_loss=0.7407 | val_loss=0.7249 | val_acc=0.8096 | time=7.3s
2025-10-13 05:56:55,416 - INFO - _models.training_function_executor - Epoch 090 | train_loss=0.7403 | val_loss=0.7226 | val_acc=0.8085 | time=7.3s
2025-10-13 05:56:55,420 - INFO - _models.training_function_executor - Quantized model size: 54081 bytes.
2025-10-13 05:56:56,543 - INFO - _models.training_function_executor - Model: 9,199 parameters, 39.5KB storage
2025-10-13 05:56:56,543 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2117412790661306, 1.02303576020874, 0.9655567097380147, 0.9283610584437951, 0.9009197026564184, 0.87622030671343, 0.864949145974669, 0.854236070889462, 0.84724707437805, 0.8384872825570485, 0.8328400244131179, 0.8299872496660498, 0.8267261280769813, 0.8219850388468668, 0.8157569673518681, 0.8142453477459435, 0.8129138739158275, 0.8105619646449752, 0.8064252216059885, 0.804498816771569, 0.8042875622947774, 0.8006812355549218, 0.7951309172098229, 0.798680796160496, 0.7984594275348872, 0.7925388005633516, 0.7950935651674361, 0.788057722722395, 0.7865418499172006, 0.7849868144611817, 0.7851266694060564, 0.7837535278714534, 0.7800208379911884, 0.7785201211116679, 0.7794666519355307, 0.7793969866233895, 0.777597530773982, 0.7759016295246282, 0.7759160495718167, 0.7701022232646996, 0.7731502310229132, 0.7704105071037601, 0.7691815682211913, 0.7690506810632084, 0.768761919497776, 0.766289689343085, 0.7662885910487484, 0.762189718040921, 0.762966309002241, 0.7637723180477461, 0.7641100857927118, 0.7617178483884736, 0.7603016886149497, 0.7579687573732844, 0.760163222769152, 0.7568545133073638, 0.7563172290906816, 0.7571831248233817, 0.7548361932914242, 0.7553639364776638, 0.7557828459011161, 0.7531679626899789, 0.7532320745370169, 0.7510870869734674, 0.7512008199689268, 0.7507968933944482, 0.749598552432142, 0.751133999333834, 0.7485612036362369, 0.7477044613264556, 0.7483934766039549, 0.7497875082834976, 0.7472086856738228, 0.747051386564897, 0.745170773786392, 0.7464274692084767, 0.7445146738439746, 0.7441558782604553, 0.746304536579287, 0.7441634492708079, 0.7426164386612074, 0.7439862602671669, 0.7402108943792002, 0.7421319312072109, 0.7438584715805981, 0.743771721995874, 0.7402627044701268, 0.7438359518838922, 0.7407199621284012, 0.7403214829949428], 'val_losses': [1.001351752521527, 0.9320940549948602, 0.8737865933013371, 0.8484874181410296, 0.8250594701973926, 0.8078599626007387, 0.7974861860692521, 0.781851791505176, 0.775809369055508, 0.7744631016216872, 0.7696581962937278, 0.7598206023465598, 0.7673903724343617, 0.7651909196714776, 0.76111306274609, 0.7653338106353674, 0.7552087703992906, 0.7558995566878821, 0.7513542516188977, 0.7642627167960419, 0.7645964139109522, 0.7483483190339555, 0.7560971411617227, 0.7562174124445663, 0.7470971108484318, 0.7493699673468056, 0.7447321366963372, 0.7508170075211277, 0.7372303317592075, 0.7416332891073351, 0.7454843466666599, 0.753387412429899, 0.7400224864962721, 0.7638482624181802, 0.7447155703186447, 0.7418961723158732, 0.7319912518243252, 0.7471592522059699, 0.7326280631967304, 0.747052889396813, 0.7527945138459278, 0.7393311598854212, 0.7294689631979492, 0.732112448324805, 0.7328185185837003, 0.7317493968924568, 0.7352104187846226, 0.7308978796380777, 0.7411344330607906, 0.7484411137855925, 0.7342380648899379, 0.7244750804987912, 0.7420608781624976, 0.7285813883463319, 0.7264500312718387, 0.7418267379534758, 0.734934870788673, 0.7275579669987108, 0.7331700551372163, 0.7321087816273119, 0.7250612679585987, 0.7361272870555473, 0.7279303241618914, 0.7458389409363666, 0.7419983770073733, 0.7225675581216728, 0.7260823100231559, 0.734846569772446, 0.7346101138697748, 0.7277530488911149, 0.7223419386647071, 0.7283518929810302, 0.7212319658234022, 0.7233043028250999, 0.7215133213187416, 0.7274697163658289, 0.7172424489900204, 0.7171020263510648, 0.7191285356425471, 0.7178495771867394, 0.7319548239355785, 0.7235347123508233, 0.7183534972184514, 0.7226296934707623, 0.7228953137988597, 0.7266073565529826, 0.7587361321985033, 0.7284182088960081, 0.7249241637566058, 0.7225944593856499], 'val_acc': [0.6535701785089254, 0.6867343367168358, 0.733899194959748, 0.745624781239062, 0.7601505075253763, 0.7704760238011901, 0.7747637381869094, 0.7832516625831292, 0.786226811340567, 0.7916520826041302, 0.7889394469723486, 0.7943647182359118, 0.7913895694784739, 0.7879768988449423, 0.7920021001050053, 0.7912145607280364, 0.7945397269863493, 0.7941897094854743, 0.795764788239412, 0.7882394119705985, 0.7906895344767239, 0.7972523626181309, 0.791739586979349, 0.7956772838641932, 0.796114805740287, 0.7958522926146308, 0.7983024151207561, 0.7969023451172559, 0.8007525376268814, 0.8004900245012251, 0.8006650332516626, 0.7963773188659433, 0.8021526076303815, 0.7866643332166608, 0.7978648932446623, 0.8006650332516626, 0.8073153657682884, 0.7976898844942247, 0.8037276863843192, 0.7938396919845992, 0.7949772488624431, 0.7986524326216311, 0.8037276863843192, 0.8035526776338817, 0.8045152257612881, 0.8030276513825692, 0.8021526076303815, 0.8039901995099755, 0.7981274063703185, 0.7958522926146308, 0.8031151557577879, 0.8075778788939447, 0.7978648932446623, 0.8053027651382569, 0.8025901295064753, 0.7965523276163808, 0.8030276513825692, 0.8040777038851943, 0.8004900245012251, 0.8035526776338817, 0.8063528176408821, 0.8002275113755688, 0.806002800140007, 0.7963773188659433, 0.8008400420021001, 0.8073153657682884, 0.807840392019601, 0.8032901645082254, 0.8005775288764438, 0.8065278263913196, 0.8077528876443822, 0.8053027651382569, 0.8080154007700385, 0.8084529226461323, 0.8079278963948198, 0.8070528526426322, 0.8114280714035702, 0.8110780539026952, 0.8102905145257263, 0.8097654882744137, 0.803465173258663, 0.8079278963948198, 0.8116905845292265, 0.8073153657682884, 0.8094154707735387, 0.8062653132656633, 0.7921771088554428, 0.8079278963948198, 0.8095904795239762, 0.8084529226461323], 'model_size_bytes': 54081, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00013304836509663059, 'batch_size': 16, 'epochs': 90, 'weight_decay': 0.007127247675967111, 'dropout': 0.4126869407791733, 'hidden_size': 19, 'd_model': 18, 't_pooled': 256, 'label_smoothing': 0.08573040055291903, 'use_focal_loss': False, 'focal_gamma': 0.23953296510722483, 'grad_clip_norm': 0.2501768833471985, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 9199, 'model_storage_size_kb': 39.526953125000006, 'model_size_validation': 'PASS'}
2025-10-13 05:56:56,543 - INFO - _models.training_function_executor - BO Objective: base=0.8085, size_penalty=0.0000, final=0.8085
2025-10-13 05:56:56,543 - INFO - _models.training_function_executor - Model: 9,199 parameters, 39.5KB (PASS 256KB limit)
2025-10-13 05:56:56,543 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 665.143s
2025-10-13 05:56:56,632 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8085
2025-10-13 05:56:56,632 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.088s
2025-10-13 05:56:56,632 - INFO - bo.run_bo - Recorded observation #15: hparams={'lr': 0.00013304836509663059, 'batch_size': np.int64(16), 'epochs': np.int64(90), 'weight_decay': 0.007127247675967111, 'dropout': 0.4126869407791733, 'hidden_size': np.int64(19), 'd_model': np.int64(18), 't_pooled': np.int64(256), 'label_smoothing': 0.08573040055291903, 'use_focal_loss': np.False_, 'focal_gamma': 0.23953296510722483, 'grad_clip_norm': 0.2501768833471985, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8085
2025-10-13 05:56:56,632 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 15: {'lr': 0.00013304836509663059, 'batch_size': np.int64(16), 'epochs': np.int64(90), 'weight_decay': 0.007127247675967111, 'dropout': 0.4126869407791733, 'hidden_size': np.int64(19), 'd_model': np.int64(18), 't_pooled': np.int64(256), 'label_smoothing': 0.08573040055291903, 'use_focal_loss': np.False_, 'focal_gamma': 0.23953296510722483, 'grad_clip_norm': 0.2501768833471985, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8085
2025-10-13 05:56:56,632 - INFO - bo.run_bo - üîçBO Trial 16: Using RF surrogate + Expected Improvement
2025-10-13 05:56:56,632 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 05:56:56,632 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 16 (NaN monitoring active)
2025-10-13 05:56:56,632 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 05:56:56,632 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 05:56:56,632 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00011976883697892742, 'batch_size': 32, 'epochs': 83, 'weight_decay': 4.805784704471621e-06, 'dropout': 0.47947536470498753, 'hidden_size': 31, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.12856837448066746, 'use_focal_loss': False, 'focal_gamma': 2.7778862612242823, 'grad_clip_norm': 0.8283158198924035, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 05:56:56,634 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00011976883697892742, 'batch_size': 32, 'epochs': 83, 'weight_decay': 4.805784704471621e-06, 'dropout': 0.47947536470498753, 'hidden_size': 31, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.12856837448066746, 'use_focal_loss': False, 'focal_gamma': 2.7778862612242823, 'grad_clip_norm': 0.8283158198924035, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 05:57:04,265 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.2508 | val_loss=1.0275 | val_acc=0.7034 | time=7.6s
2025-10-13 05:57:09,079 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.0297 | val_loss=0.9596 | val_acc=0.7379 | time=4.8s
2025-10-13 05:57:13,939 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.9817 | val_loss=0.9259 | val_acc=0.7513 | time=4.9s
2025-10-13 05:57:18,760 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9532 | val_loss=0.9039 | val_acc=0.7609 | time=4.8s
2025-10-13 05:57:23,585 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9377 | val_loss=0.8936 | val_acc=0.7658 | time=4.8s
2025-10-13 05:57:28,390 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9240 | val_loss=0.8867 | val_acc=0.7711 | time=4.8s
2025-10-13 05:57:33,215 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9191 | val_loss=0.8777 | val_acc=0.7784 | time=4.8s
2025-10-13 05:57:38,046 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.9116 | val_loss=0.8765 | val_acc=0.7748 | time=4.8s
2025-10-13 05:57:42,852 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9036 | val_loss=0.8652 | val_acc=0.7837 | time=4.8s
2025-10-13 05:57:47,655 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8983 | val_loss=0.8649 | val_acc=0.7808 | time=4.8s
2025-10-13 05:57:52,471 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8943 | val_loss=0.8595 | val_acc=0.7865 | time=4.8s
2025-10-13 05:57:57,321 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.8918 | val_loss=0.8553 | val_acc=0.7873 | time=4.8s
2025-10-13 05:58:02,187 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.8844 | val_loss=0.8503 | val_acc=0.7903 | time=4.9s
2025-10-13 05:58:07,017 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.8834 | val_loss=0.8530 | val_acc=0.7915 | time=4.8s
2025-10-13 05:58:11,835 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.8822 | val_loss=0.8542 | val_acc=0.7850 | time=4.8s
2025-10-13 05:58:16,643 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.8785 | val_loss=0.8487 | val_acc=0.7891 | time=4.8s
2025-10-13 05:58:21,487 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.8766 | val_loss=0.8463 | val_acc=0.7882 | time=4.8s
2025-10-13 05:58:26,301 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.8698 | val_loss=0.8471 | val_acc=0.7909 | time=4.8s
2025-10-13 05:58:31,126 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.8678 | val_loss=0.8454 | val_acc=0.7939 | time=4.8s
2025-10-13 05:58:35,955 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8650 | val_loss=0.8392 | val_acc=0.7949 | time=4.8s
2025-10-13 05:58:40,783 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8646 | val_loss=0.8366 | val_acc=0.7977 | time=4.8s
2025-10-13 05:58:45,651 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8619 | val_loss=0.8391 | val_acc=0.7972 | time=4.9s
2025-10-13 05:58:50,482 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8625 | val_loss=0.8346 | val_acc=0.7974 | time=4.8s
2025-10-13 05:58:55,293 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8598 | val_loss=0.8403 | val_acc=0.7959 | time=4.8s
2025-10-13 05:59:00,143 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8583 | val_loss=0.8334 | val_acc=0.7966 | time=4.8s
2025-10-13 05:59:04,972 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8554 | val_loss=0.8297 | val_acc=0.8010 | time=4.8s
2025-10-13 05:59:09,793 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8561 | val_loss=0.8317 | val_acc=0.8000 | time=4.8s
2025-10-13 05:59:14,605 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8529 | val_loss=0.8321 | val_acc=0.7966 | time=4.8s
2025-10-13 05:59:19,435 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8534 | val_loss=0.8321 | val_acc=0.7994 | time=4.8s
2025-10-13 05:59:24,247 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8527 | val_loss=0.8324 | val_acc=0.7971 | time=4.8s
2025-10-13 05:59:29,058 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8472 | val_loss=0.8316 | val_acc=0.7979 | time=4.8s
2025-10-13 05:59:33,886 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.8483 | val_loss=0.8330 | val_acc=0.7959 | time=4.8s
2025-10-13 05:59:38,724 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.8459 | val_loss=0.8227 | val_acc=0.8050 | time=4.8s
2025-10-13 05:59:43,596 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.8453 | val_loss=0.8274 | val_acc=0.8014 | time=4.9s
2025-10-13 05:59:48,474 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.8447 | val_loss=0.8259 | val_acc=0.8029 | time=4.9s
2025-10-13 05:59:53,334 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.8457 | val_loss=0.8216 | val_acc=0.8037 | time=4.9s
2025-10-13 05:59:58,170 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.8436 | val_loss=0.8283 | val_acc=0.8007 | time=4.8s
2025-10-13 06:00:03,024 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.8438 | val_loss=0.8266 | val_acc=0.7992 | time=4.9s
2025-10-13 06:00:07,865 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.8424 | val_loss=0.8269 | val_acc=0.8027 | time=4.8s
2025-10-13 06:00:12,666 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.8395 | val_loss=0.8178 | val_acc=0.8046 | time=4.8s
2025-10-13 06:00:17,486 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.8406 | val_loss=0.8219 | val_acc=0.8028 | time=4.8s
2025-10-13 06:00:22,323 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.8400 | val_loss=0.8203 | val_acc=0.8028 | time=4.8s
2025-10-13 06:00:27,153 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.8376 | val_loss=0.8194 | val_acc=0.8029 | time=4.8s
2025-10-13 06:00:31,972 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.8371 | val_loss=0.8287 | val_acc=0.7963 | time=4.8s
2025-10-13 06:00:36,794 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.8357 | val_loss=0.8178 | val_acc=0.8068 | time=4.8s
2025-10-13 06:00:41,656 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.8349 | val_loss=0.8205 | val_acc=0.8054 | time=4.9s
2025-10-13 06:00:46,465 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.8334 | val_loss=0.8182 | val_acc=0.8043 | time=4.8s
2025-10-13 06:00:51,326 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.8314 | val_loss=0.8253 | val_acc=0.7972 | time=4.9s
2025-10-13 06:00:56,152 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.8325 | val_loss=0.8243 | val_acc=0.8001 | time=4.8s
2025-10-13 06:01:00,994 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.8318 | val_loss=0.8167 | val_acc=0.8043 | time=4.8s
2025-10-13 06:01:05,865 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.8299 | val_loss=0.8178 | val_acc=0.8035 | time=4.9s
2025-10-13 06:01:10,694 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.8320 | val_loss=0.8182 | val_acc=0.8027 | time=4.8s
2025-10-13 06:01:15,543 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.8297 | val_loss=0.8143 | val_acc=0.8080 | time=4.8s
2025-10-13 06:01:20,391 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.8282 | val_loss=0.8191 | val_acc=0.8038 | time=4.8s
2025-10-13 06:01:25,261 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.8281 | val_loss=0.8162 | val_acc=0.8067 | time=4.9s
2025-10-13 06:01:30,113 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.8277 | val_loss=0.8217 | val_acc=0.8020 | time=4.9s
2025-10-13 06:01:34,964 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.8265 | val_loss=0.8157 | val_acc=0.8080 | time=4.9s
2025-10-13 06:01:39,790 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.8261 | val_loss=0.8132 | val_acc=0.8057 | time=4.8s
2025-10-13 06:01:44,616 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.8260 | val_loss=0.8194 | val_acc=0.8050 | time=4.8s
2025-10-13 06:01:49,473 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.8257 | val_loss=0.8122 | val_acc=0.8082 | time=4.9s
2025-10-13 06:01:54,313 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.8249 | val_loss=0.8129 | val_acc=0.8064 | time=4.8s
2025-10-13 06:01:59,146 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.8241 | val_loss=0.8166 | val_acc=0.8071 | time=4.8s
2025-10-13 06:02:03,982 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.8232 | val_loss=0.8151 | val_acc=0.8054 | time=4.8s
2025-10-13 06:02:08,820 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.8236 | val_loss=0.8181 | val_acc=0.8029 | time=4.8s
2025-10-13 06:02:13,629 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.8246 | val_loss=0.8086 | val_acc=0.8102 | time=4.8s
2025-10-13 06:02:18,509 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.8214 | val_loss=0.8147 | val_acc=0.8052 | time=4.9s
2025-10-13 06:02:23,337 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.8208 | val_loss=0.8135 | val_acc=0.8057 | time=4.8s
2025-10-13 06:02:28,167 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.8223 | val_loss=0.8120 | val_acc=0.8066 | time=4.8s
2025-10-13 06:02:32,972 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.8199 | val_loss=0.8094 | val_acc=0.8096 | time=4.8s
2025-10-13 06:02:37,798 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.8206 | val_loss=0.8098 | val_acc=0.8093 | time=4.8s
2025-10-13 06:02:42,627 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.8201 | val_loss=0.8191 | val_acc=0.8043 | time=4.8s
2025-10-13 06:02:47,464 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.8168 | val_loss=0.8101 | val_acc=0.8086 | time=4.8s
2025-10-13 06:02:52,367 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.8168 | val_loss=0.8079 | val_acc=0.8122 | time=4.9s
2025-10-13 06:02:57,231 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.8161 | val_loss=0.8123 | val_acc=0.8061 | time=4.9s
2025-10-13 06:03:02,101 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.8182 | val_loss=0.8111 | val_acc=0.8088 | time=4.9s
2025-10-13 06:03:06,974 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.8176 | val_loss=0.8075 | val_acc=0.8117 | time=4.9s
2025-10-13 06:03:11,837 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.8169 | val_loss=0.8058 | val_acc=0.8095 | time=4.9s
2025-10-13 06:03:16,696 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.8151 | val_loss=0.8161 | val_acc=0.8031 | time=4.9s
2025-10-13 06:03:21,529 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.8163 | val_loss=0.8172 | val_acc=0.8025 | time=4.8s
2025-10-13 06:03:26,356 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.8157 | val_loss=0.8065 | val_acc=0.8113 | time=4.8s
2025-10-13 06:03:31,200 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.8133 | val_loss=0.8085 | val_acc=0.8096 | time=4.8s
2025-10-13 06:03:36,026 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.8137 | val_loss=0.8065 | val_acc=0.8087 | time=4.8s
2025-10-13 06:03:40,839 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.8119 | val_loss=0.8121 | val_acc=0.8060 | time=4.8s
2025-10-13 06:03:40,843 - INFO - _models.training_function_executor - Quantized model size: 75521 bytes.
2025-10-13 06:03:41,945 - INFO - _models.training_function_executor - Model: 14,580 parameters, 62.6KB storage
2025-10-13 06:03:41,945 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.250839474070185, 1.0296822183400047, 0.9816733776876299, 0.9532048506548156, 0.9376530697348238, 0.9240101079319923, 0.9191461572456827, 0.9116122076926133, 0.9036114576357747, 0.8982507044258424, 0.8943211869172045, 0.8918424676171457, 0.8843588381327655, 0.8834192254637604, 0.8822307275190276, 0.8784891780039461, 0.8765867939352531, 0.8697780557641793, 0.8677953812556122, 0.8650484241553024, 0.8645865377279942, 0.8618701794033164, 0.862477108507587, 0.8597888345271089, 0.8583149955453763, 0.8553565986556192, 0.856119106439264, 0.8528980746901782, 0.8533986047468363, 0.8527354221474177, 0.8472046764488608, 0.8482743370645648, 0.8459241336819839, 0.8452761148630342, 0.8446754178343263, 0.8456917684688241, 0.8435605964879286, 0.8437768621464731, 0.8423969682213474, 0.8394710771637778, 0.8406339791799952, 0.8400179080959796, 0.8376123181664531, 0.8371057184292463, 0.8356669414364711, 0.8348932800736927, 0.8333752423806503, 0.8313664501682211, 0.8325321626780039, 0.8318436860954758, 0.8299321351787365, 0.8320196859895829, 0.8297196362333195, 0.8281912073873747, 0.828070186946957, 0.8276961027511901, 0.82646943390432, 0.8260965340613985, 0.8260161114356549, 0.82568635847087, 0.824946104729138, 0.8240639590532746, 0.8231661515215872, 0.8236272488601732, 0.8246104989095213, 0.8214202098884823, 0.8207928394161407, 0.8223170882177636, 0.8198578178068955, 0.8206333963863491, 0.8200544218187529, 0.8168410143111192, 0.8168349264591859, 0.8160952847655687, 0.8181955913667875, 0.8176471985091602, 0.8169069497118807, 0.815124146997574, 0.8163050144837793, 0.8157131429481306, 0.8133452242598235, 0.8137177950775953, 0.8118891098468421], 'val_losses': [1.0274657804648026, 0.9596107635291089, 0.9258615442786051, 0.9038680679196447, 0.8936370321616953, 0.8866980636207465, 0.8776939414913604, 0.8764965393178564, 0.8652050599461049, 0.8648959780056492, 0.8594648224263497, 0.8553472822013751, 0.8502807450077523, 0.8529957002970903, 0.8541916169442619, 0.8486889233570813, 0.8463072730896563, 0.8470553396922289, 0.8454233432383566, 0.8391593132437966, 0.8365649111962711, 0.8391435929516374, 0.8346127170885531, 0.8403024322969078, 0.8334423111667573, 0.8296565461876428, 0.8317340616584032, 0.8320699333727339, 0.8320640643076084, 0.8324301188168177, 0.8315880251047617, 0.8330338487351404, 0.8227220806868543, 0.8274199352591531, 0.8259069817359105, 0.8215611727871092, 0.8283412721051092, 0.8266039463578299, 0.8268606124910642, 0.8177740066502951, 0.8218502279841737, 0.8203244527236624, 0.8193942381445244, 0.828674053161095, 0.8177634030319737, 0.8204896125836851, 0.8182284165855718, 0.8253386327341632, 0.8242773055028866, 0.8167039325990834, 0.8178202088662783, 0.8182386654759355, 0.81430662888349, 0.8190790929909474, 0.8161853355546911, 0.821713040373231, 0.8157334643975813, 0.8131775095365161, 0.8193868885183818, 0.8122170365144625, 0.8129359808759252, 0.816579652804781, 0.8151418611141281, 0.8180613341263052, 0.8085941073566539, 0.8146727488180286, 0.8135126584845487, 0.8119505481950294, 0.8094354034262935, 0.8097628755172233, 0.8190585815034465, 0.8101351588682816, 0.8078592181164024, 0.8122904667455415, 0.8111287472253919, 0.807475190334567, 0.8058084735179389, 0.8160716673273868, 0.8172167949130746, 0.8064862053461913, 0.8084969043648239, 0.8065067146431119, 0.8121147787066076], 'val_acc': [0.7033601680084004, 0.737924396219811, 0.7513125656282814, 0.7608505425271264, 0.765750787539377, 0.7710885544277214, 0.7784389219460973, 0.7747637381869094, 0.783689184459223, 0.7808015400770039, 0.7864893244662233, 0.7872768638431922, 0.79025201260063, 0.7914770738536927, 0.7850017500875044, 0.7891144557227862, 0.7881519075953798, 0.7908645432271614, 0.793927196359818, 0.7948897444872244, 0.7976898844942247, 0.7971648582429122, 0.7974273713685684, 0.7958522926146308, 0.7966398319915996, 0.8010150507525376, 0.7999649982499125, 0.7966398319915996, 0.7993524676233812, 0.7970773538676934, 0.7978648932446623, 0.7959397969898495, 0.8049527476373819, 0.8013650682534127, 0.8028526426321316, 0.8037276863843192, 0.8006650332516626, 0.7991774588729437, 0.8026776338816941, 0.8046027301365068, 0.8027651382569129, 0.8027651382569129, 0.8029401470073504, 0.7962898144907246, 0.8067903395169759, 0.8053902695134757, 0.8043402170108506, 0.7971648582429122, 0.80014000700035, 0.8042527126356318, 0.803465173258663, 0.8026776338816941, 0.8080154007700385, 0.803815190759538, 0.8067028351417571, 0.801977598879944, 0.8080154007700385, 0.8057402870143507, 0.8050402520126007, 0.808190409520476, 0.8064403220161008, 0.8071403570178509, 0.8053902695134757, 0.8029401470073504, 0.8102030101505076, 0.8052152607630382, 0.8057402870143507, 0.8066153307665384, 0.8095904795239762, 0.8093279663983199, 0.8043402170108506, 0.8086279313965699, 0.812215610780539, 0.8060903045152258, 0.8088029401470074, 0.8116905845292265, 0.8095029751487575, 0.8031151557577879, 0.8025026251312566, 0.8113405670283514, 0.8095904795239762, 0.8087154357717886, 0.806002800140007], 'model_size_bytes': 75521, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00011976883697892742, 'batch_size': 32, 'epochs': 83, 'weight_decay': 4.805784704471621e-06, 'dropout': 0.47947536470498753, 'hidden_size': 31, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.12856837448066746, 'use_focal_loss': False, 'focal_gamma': 2.7778862612242823, 'grad_clip_norm': 0.8283158198924035, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 14580, 'model_storage_size_kb': 62.64843750000001, 'model_size_validation': 'PASS'}
2025-10-13 06:03:41,945 - INFO - _models.training_function_executor - BO Objective: base=0.8060, size_penalty=0.0000, final=0.8060
2025-10-13 06:03:41,945 - INFO - _models.training_function_executor - Model: 14,580 parameters, 62.6KB (PASS 256KB limit)
2025-10-13 06:03:41,945 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 405.313s
2025-10-13 06:03:42,037 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8060
2025-10-13 06:03:42,037 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.089s
2025-10-13 06:03:42,037 - INFO - bo.run_bo - Recorded observation #16: hparams={'lr': 0.00011976883697892742, 'batch_size': np.int64(32), 'epochs': np.int64(83), 'weight_decay': 4.805784704471621e-06, 'dropout': 0.47947536470498753, 'hidden_size': np.int64(31), 'd_model': np.int64(19), 't_pooled': np.int64(128), 'label_smoothing': 0.12856837448066746, 'use_focal_loss': np.False_, 'focal_gamma': 2.7778862612242823, 'grad_clip_norm': 0.8283158198924035, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8060
2025-10-13 06:03:42,037 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 16: {'lr': 0.00011976883697892742, 'batch_size': np.int64(32), 'epochs': np.int64(83), 'weight_decay': 4.805784704471621e-06, 'dropout': 0.47947536470498753, 'hidden_size': np.int64(31), 'd_model': np.int64(19), 't_pooled': np.int64(128), 'label_smoothing': 0.12856837448066746, 'use_focal_loss': np.False_, 'focal_gamma': 2.7778862612242823, 'grad_clip_norm': 0.8283158198924035, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8060
2025-10-13 06:03:42,037 - INFO - bo.run_bo - üîçBO Trial 17: Using RF surrogate + Expected Improvement
2025-10-13 06:03:42,037 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 06:03:42,037 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 17 (NaN monitoring active)
2025-10-13 06:03:42,038 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 06:03:42,038 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 06:03:42,038 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 7.086124973271892e-05, 'batch_size': 8, 'epochs': 83, 'weight_decay': 1.7851895807385955e-05, 'dropout': 0.18012458689992525, 'hidden_size': 26, 'd_model': 29, 't_pooled': 128, 'label_smoothing': 0.03945110555919776, 'use_focal_loss': True, 'focal_gamma': 3.233916703246188, 'grad_clip_norm': 0.009481227166003305, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 06:03:42,039 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 7.086124973271892e-05, 'batch_size': 8, 'epochs': 83, 'weight_decay': 1.7851895807385955e-05, 'dropout': 0.18012458689992525, 'hidden_size': 26, 'd_model': 29, 't_pooled': 128, 'label_smoothing': 0.03945110555919776, 'use_focal_loss': True, 'focal_gamma': 3.233916703246188, 'grad_clip_norm': 0.009481227166003305, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 06:03:59,722 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.4537 | val_loss=0.2694 | val_acc=0.6932 | time=17.7s
2025-10-13 06:04:14,678 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.3282 | val_loss=0.2301 | val_acc=0.7345 | time=15.0s
2025-10-13 06:04:29,603 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.2946 | val_loss=0.2108 | val_acc=0.7458 | time=14.9s
2025-10-13 06:04:44,647 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.2748 | val_loss=0.1991 | val_acc=0.7601 | time=15.0s
2025-10-13 06:04:59,674 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.2603 | val_loss=0.1987 | val_acc=0.7658 | time=15.0s
2025-10-13 06:05:14,619 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.2524 | val_loss=0.1897 | val_acc=0.7700 | time=14.9s
2025-10-13 06:05:29,648 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.2440 | val_loss=0.2048 | val_acc=0.7518 | time=15.0s
2025-10-13 06:05:44,600 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.2367 | val_loss=0.1933 | val_acc=0.7693 | time=15.0s
2025-10-13 06:05:59,610 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.2266 | val_loss=0.1816 | val_acc=0.7732 | time=15.0s
2025-10-13 06:06:14,557 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.2256 | val_loss=0.1786 | val_acc=0.7796 | time=14.9s
2025-10-13 06:06:29,550 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.2165 | val_loss=0.1772 | val_acc=0.7753 | time=15.0s
2025-10-13 06:06:44,430 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.2132 | val_loss=0.1782 | val_acc=0.7788 | time=14.9s
2025-10-13 06:06:59,317 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.2103 | val_loss=0.1812 | val_acc=0.7787 | time=14.9s
2025-10-13 06:07:14,315 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.2058 | val_loss=0.1716 | val_acc=0.7812 | time=15.0s
2025-10-13 06:07:29,215 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.2009 | val_loss=0.1724 | val_acc=0.7847 | time=14.9s
2025-10-13 06:07:44,156 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.2005 | val_loss=0.1652 | val_acc=0.7910 | time=14.9s
2025-10-13 06:07:59,143 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.1968 | val_loss=0.1685 | val_acc=0.7869 | time=15.0s
2025-10-13 06:08:14,130 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.1960 | val_loss=0.1711 | val_acc=0.7866 | time=15.0s
2025-10-13 06:08:29,077 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.1914 | val_loss=0.1652 | val_acc=0.7891 | time=14.9s
2025-10-13 06:08:44,055 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.1936 | val_loss=0.1611 | val_acc=0.7885 | time=15.0s
2025-10-13 06:08:59,062 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.1895 | val_loss=0.1634 | val_acc=0.7912 | time=15.0s
2025-10-13 06:09:14,089 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.1865 | val_loss=0.1620 | val_acc=0.7846 | time=15.0s
2025-10-13 06:09:28,900 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.1868 | val_loss=0.1680 | val_acc=0.7849 | time=14.8s
2025-10-13 06:09:43,736 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.1836 | val_loss=0.1655 | val_acc=0.7863 | time=14.8s
2025-10-13 06:09:58,609 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.1835 | val_loss=0.1587 | val_acc=0.7896 | time=14.9s
2025-10-13 06:10:13,585 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.1850 | val_loss=0.1587 | val_acc=0.7966 | time=15.0s
2025-10-13 06:10:28,462 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.1803 | val_loss=0.1622 | val_acc=0.7938 | time=14.9s
2025-10-13 06:10:43,425 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.1804 | val_loss=0.1580 | val_acc=0.7945 | time=15.0s
2025-10-13 06:10:58,312 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.1767 | val_loss=0.1628 | val_acc=0.7939 | time=14.9s
2025-10-13 06:11:13,312 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.1793 | val_loss=0.1553 | val_acc=0.7973 | time=15.0s
2025-10-13 06:11:28,277 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.1774 | val_loss=0.1519 | val_acc=0.7949 | time=15.0s
2025-10-13 06:11:43,268 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.1764 | val_loss=0.1601 | val_acc=0.7970 | time=15.0s
2025-10-13 06:11:58,286 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.1752 | val_loss=0.1594 | val_acc=0.7918 | time=15.0s
2025-10-13 06:12:13,100 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.1743 | val_loss=0.1560 | val_acc=0.8006 | time=14.8s
2025-10-13 06:12:28,088 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.1736 | val_loss=0.1577 | val_acc=0.7951 | time=15.0s
2025-10-13 06:12:43,014 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.1722 | val_loss=0.1621 | val_acc=0.7937 | time=14.9s
2025-10-13 06:12:57,919 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.1730 | val_loss=0.1536 | val_acc=0.7978 | time=14.9s
2025-10-13 06:13:12,847 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.1703 | val_loss=0.1551 | val_acc=0.8008 | time=14.9s
2025-10-13 06:13:27,803 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.1716 | val_loss=0.1530 | val_acc=0.7943 | time=15.0s
2025-10-13 06:13:42,893 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.1712 | val_loss=0.1517 | val_acc=0.8022 | time=15.1s
2025-10-13 06:13:57,778 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.1703 | val_loss=0.1519 | val_acc=0.8026 | time=14.9s
2025-10-13 06:14:12,782 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.1681 | val_loss=0.1617 | val_acc=0.7980 | time=15.0s
2025-10-13 06:14:27,770 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.1689 | val_loss=0.1554 | val_acc=0.8017 | time=15.0s
2025-10-13 06:14:42,758 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.1671 | val_loss=0.1641 | val_acc=0.7966 | time=15.0s
2025-10-13 06:14:57,803 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.1650 | val_loss=0.1546 | val_acc=0.8010 | time=15.0s
2025-10-13 06:15:12,807 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.1664 | val_loss=0.1619 | val_acc=0.7980 | time=15.0s
2025-10-13 06:15:27,728 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.1637 | val_loss=0.1565 | val_acc=0.7979 | time=14.9s
2025-10-13 06:15:42,610 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.1656 | val_loss=0.1527 | val_acc=0.8008 | time=14.9s
2025-10-13 06:15:57,673 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.1648 | val_loss=0.1581 | val_acc=0.8015 | time=15.1s
2025-10-13 06:16:12,518 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.1649 | val_loss=0.1613 | val_acc=0.7954 | time=14.8s
2025-10-13 06:16:27,348 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.1633 | val_loss=0.1591 | val_acc=0.8000 | time=14.8s
2025-10-13 06:16:42,306 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.1656 | val_loss=0.1529 | val_acc=0.8008 | time=15.0s
2025-10-13 06:16:57,254 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.1625 | val_loss=0.1526 | val_acc=0.8009 | time=14.9s
2025-10-13 06:17:12,173 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.1625 | val_loss=0.1594 | val_acc=0.7973 | time=14.9s
2025-10-13 06:17:27,108 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.1622 | val_loss=0.1539 | val_acc=0.8028 | time=14.9s
2025-10-13 06:17:41,986 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.1596 | val_loss=0.1515 | val_acc=0.8035 | time=14.9s
2025-10-13 06:17:56,849 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.1614 | val_loss=0.1535 | val_acc=0.8041 | time=14.9s
2025-10-13 06:18:11,723 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.1606 | val_loss=0.1494 | val_acc=0.8064 | time=14.9s
2025-10-13 06:18:26,584 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.1591 | val_loss=0.1622 | val_acc=0.8006 | time=14.9s
2025-10-13 06:18:41,435 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.1587 | val_loss=0.1588 | val_acc=0.8035 | time=14.9s
2025-10-13 06:18:56,447 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.1584 | val_loss=0.1592 | val_acc=0.8018 | time=15.0s
2025-10-13 06:19:11,330 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.1587 | val_loss=0.1592 | val_acc=0.8031 | time=14.9s
2025-10-13 06:19:26,341 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.1575 | val_loss=0.1497 | val_acc=0.8045 | time=15.0s
2025-10-13 06:19:41,303 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.1564 | val_loss=0.1588 | val_acc=0.8058 | time=15.0s
2025-10-13 06:19:56,217 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.1575 | val_loss=0.1483 | val_acc=0.8078 | time=14.9s
2025-10-13 06:20:11,116 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.1576 | val_loss=0.1506 | val_acc=0.8010 | time=14.9s
2025-10-13 06:20:26,159 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.1562 | val_loss=0.1557 | val_acc=0.8044 | time=15.0s
2025-10-13 06:20:41,199 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.1581 | val_loss=0.1536 | val_acc=0.8069 | time=15.0s
2025-10-13 06:20:56,092 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.1545 | val_loss=0.1515 | val_acc=0.8071 | time=14.9s
2025-10-13 06:21:10,997 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.1538 | val_loss=0.1575 | val_acc=0.7975 | time=14.9s
2025-10-13 06:21:25,996 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.1546 | val_loss=0.1559 | val_acc=0.8059 | time=15.0s
2025-10-13 06:21:40,934 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.1540 | val_loss=0.1587 | val_acc=0.8059 | time=14.9s
2025-10-13 06:21:55,914 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.1547 | val_loss=0.1482 | val_acc=0.8050 | time=15.0s
2025-10-13 06:22:10,700 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.1518 | val_loss=0.1565 | val_acc=0.8082 | time=14.8s
2025-10-13 06:22:25,637 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.1537 | val_loss=0.1513 | val_acc=0.8050 | time=14.9s
2025-10-13 06:22:40,552 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.1514 | val_loss=0.1575 | val_acc=0.8032 | time=14.9s
2025-10-13 06:22:55,393 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.1528 | val_loss=0.1509 | val_acc=0.8076 | time=14.8s
2025-10-13 06:23:10,361 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.1531 | val_loss=0.1674 | val_acc=0.8016 | time=15.0s
2025-10-13 06:23:25,404 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.1530 | val_loss=0.1531 | val_acc=0.8089 | time=15.0s
2025-10-13 06:23:40,363 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.1542 | val_loss=0.1485 | val_acc=0.8096 | time=15.0s
2025-10-13 06:23:55,340 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.1538 | val_loss=0.1524 | val_acc=0.8093 | time=15.0s
2025-10-13 06:24:10,323 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.1505 | val_loss=0.1483 | val_acc=0.8092 | time=15.0s
2025-10-13 06:24:25,325 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.1513 | val_loss=0.1596 | val_acc=0.8029 | time=15.0s
2025-10-13 06:24:25,328 - INFO - _models.training_function_executor - Quantized model size: 74113 bytes.
2025-10-13 06:24:26,430 - INFO - _models.training_function_executor - Model: 14,277 parameters, 61.3KB storage
2025-10-13 06:24:26,430 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.453732498872883, 0.32816229114360457, 0.2946383670193434, 0.2747881156915592, 0.26032713786407125, 0.25240175088308164, 0.24397894921609894, 0.2367462177465399, 0.22662646468495054, 0.22564036299686097, 0.21645905234188229, 0.21323865357888122, 0.2102793802563942, 0.2057830937792937, 0.20094164995144756, 0.2004582416333436, 0.1968329349648609, 0.19597994584601933, 0.19138847176182955, 0.1936074499378475, 0.1895491060509751, 0.18648686725409921, 0.18681723340768153, 0.18358201528535906, 0.18348919513525647, 0.1850474658517521, 0.180266368471146, 0.180398368071737, 0.17673104629918868, 0.17927689525968823, 0.177405910189006, 0.1763815261401951, 0.17518310240657475, 0.1742950482578584, 0.17357378843380447, 0.17218108293397458, 0.1729675826426621, 0.1703333719559767, 0.17161898757828192, 0.1711637278807729, 0.17033689060074605, 0.1680751070245337, 0.16891780108871332, 0.16708278628815118, 0.16496466077089725, 0.16639752794305854, 0.16367014934711654, 0.16563983193054221, 0.16477643518142585, 0.16491855748927534, 0.16327660093192772, 0.1655804779369395, 0.16248104541780822, 0.16252972235894017, 0.16221041484838752, 0.15964919571195688, 0.16143264357186152, 0.16059101264849285, 0.1590928975102356, 0.15872701133904854, 0.1583986950534685, 0.15873376119364663, 0.15751445311900367, 0.1563726830287193, 0.15750371552436176, 0.15762982729547637, 0.1561681181053857, 0.1580601792555908, 0.15454286809813128, 0.1538496479437648, 0.15461954737426764, 0.15403058189139768, 0.15474663207116435, 0.15179145560214963, 0.1537063217793269, 0.15144867404137657, 0.15278701323036167, 0.15314080120990262, 0.15302099330411836, 0.1541626866665901, 0.15382668335343774, 0.15047267904043526, 0.15131110310185578], 'val_losses': [0.26938639562687844, 0.23007140449180777, 0.21079506972425877, 0.19914851941906325, 0.1987161816661414, 0.18974119191744818, 0.20477911145685487, 0.19327053759021487, 0.18159656734282387, 0.17864657398772915, 0.1771661714126842, 0.17816381496603845, 0.1812252955409181, 0.17156352731765964, 0.17243548835789746, 0.16520703844087167, 0.16852557733961396, 0.1710978439794889, 0.16523457387228205, 0.16111051888241948, 0.16341540105800617, 0.1620494683658118, 0.168012215503246, 0.16553194968777654, 0.15867465547614235, 0.1587496881538172, 0.16223769176993905, 0.15796963607117867, 0.16280486713345124, 0.15525582264191193, 0.1518721345000068, 0.1600997852646258, 0.1594191335150134, 0.1560203636354921, 0.15766376286460165, 0.16212282394977287, 0.15359260864708393, 0.15507469606762808, 0.1529893006923738, 0.15172868584372992, 0.15187797245579632, 0.16174004943571962, 0.15539788737786184, 0.1640945105997785, 0.1546335320403564, 0.16191360661528528, 0.1565187079200373, 0.1526967917093378, 0.1581138419321522, 0.16134631352699277, 0.15914049613024514, 0.15293522225692868, 0.15260379728712833, 0.1593882054718662, 0.15393991366297394, 0.15151270136571598, 0.15347452665749894, 0.1494297297532244, 0.16216405771889827, 0.15875295658948244, 0.159201153652794, 0.15915996663707238, 0.14970258466500397, 0.158821482334653, 0.14830112658290465, 0.1506199178345062, 0.15570708125541857, 0.153563080786551, 0.15148644384562626, 0.15746492802729067, 0.15587464531382894, 0.15871024912063164, 0.1481710746067768, 0.15652176368434606, 0.15130918797004173, 0.1574920068111461, 0.15093801633885479, 0.16741982869529104, 0.15311497995898188, 0.148500301295746, 0.15238954509298117, 0.14828342257463953, 0.15964359302760067], 'val_acc': [0.6932096604830241, 0.7345117255862793, 0.7457997899894995, 0.7600630031501575, 0.765750787539377, 0.7700385019250963, 0.751837591879594, 0.7693384669233462, 0.7731886594329717, 0.7795764788239412, 0.7752887644382219, 0.7787889394469724, 0.7787014350717536, 0.7812390619530977, 0.7847392369618481, 0.7910395519775989, 0.7869268463423171, 0.7865768288414421, 0.7891144557227862, 0.7885019250962548, 0.7912145607280364, 0.7845642282114106, 0.7849142457122856, 0.7863143157157858, 0.78955197759888, 0.7966398319915996, 0.7938396919845992, 0.7945397269863493, 0.793927196359818, 0.7972523626181309, 0.7948897444872244, 0.7969898494924746, 0.7918270913545677, 0.8005775288764438, 0.7950647532376619, 0.7936646832341617, 0.7977773888694435, 0.8007525376268814, 0.794277213860693, 0.8022401120056003, 0.8025901295064753, 0.7980399019950998, 0.8017150857542877, 0.7965523276163808, 0.8010150507525376, 0.7980399019950998, 0.7978648932446623, 0.8007525376268814, 0.8014525726286315, 0.795414770738537, 0.7999649982499125, 0.8007525376268814, 0.8009275463773189, 0.7972523626181309, 0.8027651382569129, 0.803465173258663, 0.8040777038851943, 0.8064403220161008, 0.8005775288764438, 0.803465173258663, 0.8018025901295065, 0.8031151557577879, 0.8045152257612881, 0.8058277913895695, 0.8077528876443822, 0.8010150507525376, 0.8044277213860693, 0.8068778438921946, 0.8070528526426322, 0.7975148757437872, 0.8059152957647883, 0.8059152957647883, 0.8050402520126007, 0.808190409520476, 0.8049527476373819, 0.8032026601330067, 0.8075778788939447, 0.801627581379069, 0.8088904445222261, 0.8095904795239762, 0.8093279663983199, 0.8092404620231012, 0.8029401470073504], 'model_size_bytes': 74113, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 7.086124973271892e-05, 'batch_size': 8, 'epochs': 83, 'weight_decay': 1.7851895807385955e-05, 'dropout': 0.18012458689992525, 'hidden_size': 26, 'd_model': 29, 't_pooled': 128, 'label_smoothing': 0.03945110555919776, 'use_focal_loss': True, 'focal_gamma': 3.233916703246188, 'grad_clip_norm': 0.009481227166003305, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 14277, 'model_storage_size_kb': 61.346484375, 'model_size_validation': 'PASS'}
2025-10-13 06:24:26,430 - INFO - _models.training_function_executor - BO Objective: base=0.8029, size_penalty=0.0000, final=0.8029
2025-10-13 06:24:26,430 - INFO - _models.training_function_executor - Model: 14,277 parameters, 61.3KB (PASS 256KB limit)
2025-10-13 06:24:26,430 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 1244.393s
2025-10-13 06:24:26,522 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8029
2025-10-13 06:24:26,522 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.090s
2025-10-13 06:24:26,522 - INFO - bo.run_bo - Recorded observation #17: hparams={'lr': 7.086124973271892e-05, 'batch_size': np.int64(8), 'epochs': np.int64(83), 'weight_decay': 1.7851895807385955e-05, 'dropout': 0.18012458689992525, 'hidden_size': np.int64(26), 'd_model': np.int64(29), 't_pooled': np.int64(128), 'label_smoothing': 0.03945110555919776, 'use_focal_loss': np.True_, 'focal_gamma': 3.233916703246188, 'grad_clip_norm': 0.009481227166003305, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8029
2025-10-13 06:24:26,522 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 17: {'lr': 7.086124973271892e-05, 'batch_size': np.int64(8), 'epochs': np.int64(83), 'weight_decay': 1.7851895807385955e-05, 'dropout': 0.18012458689992525, 'hidden_size': np.int64(26), 'd_model': np.int64(29), 't_pooled': np.int64(128), 'label_smoothing': 0.03945110555919776, 'use_focal_loss': np.True_, 'focal_gamma': 3.233916703246188, 'grad_clip_norm': 0.009481227166003305, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8029
2025-10-13 06:24:26,522 - INFO - bo.run_bo - üîçBO Trial 18: Using RF surrogate + Expected Improvement
2025-10-13 06:24:26,522 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 06:24:26,522 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 18 (NaN monitoring active)
2025-10-13 06:24:26,522 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 06:24:26,522 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 06:24:26,522 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.0657330769586447e-05, 'batch_size': 16, 'epochs': 55, 'weight_decay': 3.4611627735648494e-06, 'dropout': 0.10244230084508668, 'hidden_size': 18, 'd_model': 28, 't_pooled': 128, 'label_smoothing': 0.06999919255180351, 'use_focal_loss': False, 'focal_gamma': 2.621200725870618, 'grad_clip_norm': 2.811774012303719, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 06:24:26,523 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.0657330769586447e-05, 'batch_size': 16, 'epochs': 55, 'weight_decay': 3.4611627735648494e-06, 'dropout': 0.10244230084508668, 'hidden_size': 18, 'd_model': 28, 't_pooled': 128, 'label_smoothing': 0.06999919255180351, 'use_focal_loss': False, 'focal_gamma': 2.621200725870618, 'grad_clip_norm': 2.811774012303719, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 06:24:36,434 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5637 | val_loss=1.5043 | val_acc=0.4730 | time=9.9s
2025-10-13 06:24:43,568 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.4161 | val_loss=1.2859 | val_acc=0.6080 | time=7.1s
2025-10-13 06:24:50,744 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2210 | val_loss=1.1358 | val_acc=0.6253 | time=7.2s
2025-10-13 06:24:57,887 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1284 | val_loss=1.0660 | val_acc=0.6327 | time=7.1s
2025-10-13 06:25:05,029 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0792 | val_loss=1.0214 | val_acc=0.6411 | time=7.1s
2025-10-13 06:25:12,155 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0495 | val_loss=0.9925 | val_acc=0.6477 | time=7.1s
2025-10-13 06:25:19,320 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.0233 | val_loss=0.9691 | val_acc=0.6509 | time=7.2s
2025-10-13 06:25:26,484 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.0046 | val_loss=0.9558 | val_acc=0.6575 | time=7.2s
2025-10-13 06:25:33,652 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9883 | val_loss=0.9443 | val_acc=0.6628 | time=7.2s
2025-10-13 06:25:40,772 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9816 | val_loss=0.9225 | val_acc=0.6859 | time=7.1s
2025-10-13 06:25:47,918 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.9734 | val_loss=0.9114 | val_acc=0.6992 | time=7.1s
2025-10-13 06:25:55,096 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9638 | val_loss=0.9016 | val_acc=0.7062 | time=7.2s
2025-10-13 06:26:02,264 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9500 | val_loss=0.8916 | val_acc=0.7099 | time=7.2s
2025-10-13 06:26:09,437 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.9425 | val_loss=0.8867 | val_acc=0.7118 | time=7.2s
2025-10-13 06:26:16,638 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.9364 | val_loss=0.8751 | val_acc=0.7220 | time=7.2s
2025-10-13 06:26:23,795 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.9240 | val_loss=0.8739 | val_acc=0.7230 | time=7.2s
2025-10-13 06:26:30,962 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.9195 | val_loss=0.8644 | val_acc=0.7304 | time=7.2s
2025-10-13 06:26:38,136 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.9151 | val_loss=0.8607 | val_acc=0.7319 | time=7.2s
2025-10-13 06:26:45,300 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.9077 | val_loss=0.8503 | val_acc=0.7339 | time=7.2s
2025-10-13 06:26:52,465 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8997 | val_loss=0.8445 | val_acc=0.7372 | time=7.2s
2025-10-13 06:26:59,601 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8939 | val_loss=0.8432 | val_acc=0.7351 | time=7.1s
2025-10-13 06:27:06,779 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8884 | val_loss=0.8364 | val_acc=0.7395 | time=7.2s
2025-10-13 06:27:13,939 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8832 | val_loss=0.8330 | val_acc=0.7454 | time=7.2s
2025-10-13 06:27:21,103 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8827 | val_loss=0.8261 | val_acc=0.7424 | time=7.2s
2025-10-13 06:27:28,265 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8763 | val_loss=0.8237 | val_acc=0.7439 | time=7.2s
2025-10-13 06:27:35,403 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8741 | val_loss=0.8202 | val_acc=0.7449 | time=7.1s
2025-10-13 06:27:42,550 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8675 | val_loss=0.8176 | val_acc=0.7490 | time=7.1s
2025-10-13 06:27:49,701 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8640 | val_loss=0.8157 | val_acc=0.7502 | time=7.2s
2025-10-13 06:27:56,854 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8592 | val_loss=0.8112 | val_acc=0.7524 | time=7.2s
2025-10-13 06:28:04,042 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8586 | val_loss=0.8037 | val_acc=0.7530 | time=7.2s
2025-10-13 06:28:11,251 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8534 | val_loss=0.8036 | val_acc=0.7504 | time=7.2s
2025-10-13 06:28:18,456 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.8491 | val_loss=0.7995 | val_acc=0.7571 | time=7.2s
2025-10-13 06:28:25,603 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.8470 | val_loss=0.7968 | val_acc=0.7559 | time=7.1s
2025-10-13 06:28:32,750 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.8450 | val_loss=0.7962 | val_acc=0.7573 | time=7.1s
2025-10-13 06:28:39,933 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.8414 | val_loss=0.7932 | val_acc=0.7576 | time=7.2s
2025-10-13 06:28:47,138 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.8431 | val_loss=0.7902 | val_acc=0.7601 | time=7.2s
2025-10-13 06:28:54,288 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.8393 | val_loss=0.7909 | val_acc=0.7608 | time=7.1s
2025-10-13 06:29:01,451 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.8341 | val_loss=0.7874 | val_acc=0.7595 | time=7.2s
2025-10-13 06:29:08,597 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.8336 | val_loss=0.7844 | val_acc=0.7637 | time=7.1s
2025-10-13 06:29:15,782 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.8308 | val_loss=0.7846 | val_acc=0.7602 | time=7.2s
2025-10-13 06:29:22,984 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.8270 | val_loss=0.7799 | val_acc=0.7640 | time=7.2s
2025-10-13 06:29:30,151 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.8261 | val_loss=0.7811 | val_acc=0.7657 | time=7.2s
2025-10-13 06:29:37,347 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.8235 | val_loss=0.7770 | val_acc=0.7658 | time=7.2s
2025-10-13 06:29:44,501 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.8203 | val_loss=0.7778 | val_acc=0.7646 | time=7.2s
2025-10-13 06:29:51,685 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.8232 | val_loss=0.7911 | val_acc=0.7595 | time=7.2s
2025-10-13 06:29:58,901 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.8191 | val_loss=0.7728 | val_acc=0.7687 | time=7.2s
2025-10-13 06:30:06,074 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.8200 | val_loss=0.7712 | val_acc=0.7681 | time=7.2s
2025-10-13 06:30:13,269 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.8189 | val_loss=0.7734 | val_acc=0.7658 | time=7.2s
2025-10-13 06:30:20,465 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.8170 | val_loss=0.7704 | val_acc=0.7713 | time=7.2s
2025-10-13 06:30:27,683 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.8112 | val_loss=0.7726 | val_acc=0.7686 | time=7.2s
2025-10-13 06:30:34,825 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.8090 | val_loss=0.7721 | val_acc=0.7683 | time=7.1s
2025-10-13 06:30:42,004 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.8093 | val_loss=0.7654 | val_acc=0.7732 | time=7.2s
2025-10-13 06:30:49,179 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.8052 | val_loss=0.7652 | val_acc=0.7707 | time=7.2s
2025-10-13 06:30:56,303 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.8068 | val_loss=0.7629 | val_acc=0.7728 | time=7.1s
2025-10-13 06:31:03,481 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.8030 | val_loss=0.7656 | val_acc=0.7713 | time=7.2s
2025-10-13 06:31:03,484 - INFO - _models.training_function_executor - Quantized model size: 59009 bytes.
2025-10-13 06:31:04,611 - INFO - _models.training_function_executor - Model: 10,448 parameters, 44.9KB storage
2025-10-13 06:31:04,612 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5637433419579763, 1.4161457358685081, 1.220967371750846, 1.12840712491891, 1.079159110732374, 1.0495026020224294, 1.0232640941909947, 1.0046165715909563, 0.9882818986412358, 0.9816410620395312, 0.9734390210888375, 0.9638326405477474, 0.949968975325502, 0.9425009302338563, 0.936392091290284, 0.9240218683227109, 0.9194932193408949, 0.9151295000725707, 0.9076769127476912, 0.8997252700126042, 0.8938924596156947, 0.8883677917445586, 0.8832001069291389, 0.88268473123728, 0.8762797336395612, 0.8740532396972117, 0.8675418023488135, 0.8640207291317019, 0.8591970292512963, 0.858565831167697, 0.853446930667759, 0.8491465967979137, 0.8469944578765947, 0.8450352688706918, 0.8414147483079968, 0.8431451963322706, 0.8392773976078141, 0.8340655749479207, 0.8335637837533647, 0.8307802737760593, 0.8270230134509016, 0.8261152129094835, 0.8234647931879869, 0.8203436739281169, 0.8231515511374896, 0.8191140317336888, 0.8199939368840986, 0.8188726094727087, 0.8170326094987053, 0.8112097446698178, 0.809033173810864, 0.8092840530257314, 0.805184198283298, 0.8067773837370601, 0.803049262019776], 'val_losses': [1.5043008446818595, 1.2859298474812866, 1.1357799690421495, 1.0659738301312878, 1.021360041004484, 0.9925375733293768, 0.9691037605974613, 0.9558025067362453, 0.9442969846858985, 0.9224793610557794, 0.9114156975210401, 0.9015984713384477, 0.8916417934863685, 0.8866786977232525, 0.8750530394549799, 0.8738578572154755, 0.8644474251811889, 0.8606933652833078, 0.8502578218791883, 0.8444864150732599, 0.8432035096300037, 0.8364046199946792, 0.8329974089338098, 0.826093244081116, 0.823669124680213, 0.820247790134992, 0.8176357322403465, 0.8156855039175966, 0.8111812575196402, 0.8036559000272286, 0.8036200447352899, 0.7994758455870992, 0.7967821161439046, 0.7961695645712538, 0.7931578173101637, 0.7902492037552155, 0.7908614814010249, 0.7873660391930062, 0.7843967044649734, 0.7845736549039967, 0.7799454250450856, 0.7810588857282239, 0.7770410517023959, 0.7777788432736809, 0.7910756239492158, 0.7728249536012911, 0.7711587050681269, 0.773427017489471, 0.7704049405160383, 0.7726366292316262, 0.7721018280271972, 0.7653659058067821, 0.7651964747117123, 0.7629272020860364, 0.7656094455869206], 'val_acc': [0.47296114805740286, 0.607980399019951, 0.6253062653132656, 0.6327441372068603, 0.6411445572278613, 0.6477073853692684, 0.6508575428771438, 0.6575078753937696, 0.6628456422821141, 0.685946797339867, 0.6991599579978999, 0.7061603080154008, 0.7099229961498075, 0.7118480924046202, 0.7219985999299965, 0.7229611480574029, 0.7303990199509975, 0.7318865943297165, 0.733899194959748, 0.7372243612180609, 0.7351242562128106, 0.7394994749737487, 0.7453622681134057, 0.7423871193559678, 0.7438746937346867, 0.7449247462373119, 0.7490374518725936, 0.7501750087504375, 0.7523626181309065, 0.7529751487574379, 0.7504375218760938, 0.7570878543927196, 0.755862793139657, 0.7572628631431572, 0.7576128806440322, 0.7600630031501575, 0.7607630381519076, 0.7594504725236262, 0.7636506825341267, 0.7601505075253763, 0.7640007000350018, 0.7656632831641582, 0.765750787539377, 0.7646132306615331, 0.759537976898845, 0.7687259362968148, 0.7681134056702835, 0.765750787539377, 0.7712635631781589, 0.7686384319215961, 0.768288414420721, 0.7731886594329717, 0.7706510325516276, 0.7728386419320966, 0.7712635631781589], 'model_size_bytes': 59009, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.0657330769586447e-05, 'batch_size': 16, 'epochs': 55, 'weight_decay': 3.4611627735648494e-06, 'dropout': 0.10244230084508668, 'hidden_size': 18, 'd_model': 28, 't_pooled': 128, 'label_smoothing': 0.06999919255180351, 'use_focal_loss': False, 'focal_gamma': 2.621200725870618, 'grad_clip_norm': 2.811774012303719, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 10448, 'model_storage_size_kb': 44.893750000000004, 'model_size_validation': 'PASS'}
2025-10-13 06:31:04,612 - INFO - _models.training_function_executor - BO Objective: base=0.7713, size_penalty=0.0000, final=0.7713
2025-10-13 06:31:04,612 - INFO - _models.training_function_executor - Model: 10,448 parameters, 44.9KB (PASS 256KB limit)
2025-10-13 06:31:04,612 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 398.090s
2025-10-13 06:31:04,706 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7713
2025-10-13 06:31:04,707 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.093s
2025-10-13 06:31:04,707 - INFO - bo.run_bo - Recorded observation #18: hparams={'lr': 1.0657330769586447e-05, 'batch_size': np.int64(16), 'epochs': np.int64(55), 'weight_decay': 3.4611627735648494e-06, 'dropout': 0.10244230084508668, 'hidden_size': np.int64(18), 'd_model': np.int64(28), 't_pooled': np.int64(128), 'label_smoothing': 0.06999919255180351, 'use_focal_loss': np.False_, 'focal_gamma': 2.621200725870618, 'grad_clip_norm': 2.811774012303719, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7713
2025-10-13 06:31:04,707 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 18: {'lr': 1.0657330769586447e-05, 'batch_size': np.int64(16), 'epochs': np.int64(55), 'weight_decay': 3.4611627735648494e-06, 'dropout': 0.10244230084508668, 'hidden_size': np.int64(18), 'd_model': np.int64(28), 't_pooled': np.int64(128), 'label_smoothing': 0.06999919255180351, 'use_focal_loss': np.False_, 'focal_gamma': 2.621200725870618, 'grad_clip_norm': 2.811774012303719, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7713
2025-10-13 06:31:04,707 - INFO - bo.run_bo - üîçBO Trial 19: Using RF surrogate + Expected Improvement
2025-10-13 06:31:04,707 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 06:31:04,707 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 19 (NaN monitoring active)
2025-10-13 06:31:04,707 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 06:31:04,707 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 06:31:04,707 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 4.742157382736943e-05, 'batch_size': 24, 'epochs': 69, 'weight_decay': 2.1505645031344884e-06, 'dropout': 0.0979028248679121, 'hidden_size': 29, 'd_model': 14, 't_pooled': 192, 'label_smoothing': 0.010634516361012028, 'use_focal_loss': False, 'focal_gamma': 3.739907369287357, 'grad_clip_norm': 3.9691189092465473, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 06:31:04,708 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 4.742157382736943e-05, 'batch_size': 24, 'epochs': 69, 'weight_decay': 2.1505645031344884e-06, 'dropout': 0.0979028248679121, 'hidden_size': 29, 'd_model': 14, 't_pooled': 192, 'label_smoothing': 0.010634516361012028, 'use_focal_loss': False, 'focal_gamma': 3.739907369287357, 'grad_clip_norm': 3.9691189092465473, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 06:31:13,195 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3359 | val_loss=1.0508 | val_acc=0.6082 | time=8.5s
2025-10-13 06:31:18,826 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.9741 | val_loss=0.8728 | val_acc=0.6516 | time=5.6s
2025-10-13 06:31:24,434 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.8902 | val_loss=0.8157 | val_acc=0.6804 | time=5.6s
2025-10-13 06:31:30,153 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.8489 | val_loss=0.7830 | val_acc=0.6989 | time=5.7s
2025-10-13 06:31:35,790 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.8230 | val_loss=0.7520 | val_acc=0.7202 | time=5.6s
2025-10-13 06:31:41,403 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.7944 | val_loss=0.7344 | val_acc=0.7255 | time=5.6s
2025-10-13 06:31:46,999 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.7709 | val_loss=0.7142 | val_acc=0.7378 | time=5.6s
2025-10-13 06:31:52,662 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.7526 | val_loss=0.6965 | val_acc=0.7411 | time=5.7s
2025-10-13 06:31:58,304 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.7322 | val_loss=0.6808 | val_acc=0.7464 | time=5.6s
2025-10-13 06:32:03,951 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.7196 | val_loss=0.6614 | val_acc=0.7553 | time=5.6s
2025-10-13 06:32:09,548 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.7041 | val_loss=0.6465 | val_acc=0.7609 | time=5.6s
2025-10-13 06:32:15,214 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.6932 | val_loss=0.6359 | val_acc=0.7658 | time=5.7s
2025-10-13 06:32:20,930 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.6821 | val_loss=0.6272 | val_acc=0.7686 | time=5.7s
2025-10-13 06:32:26,580 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.6671 | val_loss=0.6293 | val_acc=0.7642 | time=5.6s
2025-10-13 06:32:32,192 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.6612 | val_loss=0.6113 | val_acc=0.7763 | time=5.6s
2025-10-13 06:32:37,884 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.6547 | val_loss=0.6021 | val_acc=0.7788 | time=5.7s
2025-10-13 06:32:43,467 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.6499 | val_loss=0.6019 | val_acc=0.7792 | time=5.6s
2025-10-13 06:32:49,110 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.6441 | val_loss=0.5943 | val_acc=0.7806 | time=5.6s
2025-10-13 06:32:54,768 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.6387 | val_loss=0.5940 | val_acc=0.7816 | time=5.7s
2025-10-13 06:33:00,377 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.6319 | val_loss=0.5851 | val_acc=0.7864 | time=5.6s
2025-10-13 06:33:05,999 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.6267 | val_loss=0.5873 | val_acc=0.7845 | time=5.6s
2025-10-13 06:33:11,597 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.6251 | val_loss=0.5822 | val_acc=0.7864 | time=5.6s
2025-10-13 06:33:17,257 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.6216 | val_loss=0.5740 | val_acc=0.7902 | time=5.7s
2025-10-13 06:33:22,853 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.6201 | val_loss=0.5724 | val_acc=0.7909 | time=5.6s
2025-10-13 06:33:28,523 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.6133 | val_loss=0.5767 | val_acc=0.7901 | time=5.7s
2025-10-13 06:33:34,147 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.6090 | val_loss=0.5731 | val_acc=0.7925 | time=5.6s
2025-10-13 06:33:39,753 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.6080 | val_loss=0.5740 | val_acc=0.7886 | time=5.6s
2025-10-13 06:33:45,374 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.6029 | val_loss=0.5757 | val_acc=0.7915 | time=5.6s
2025-10-13 06:33:51,025 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.6043 | val_loss=0.5657 | val_acc=0.7909 | time=5.7s
2025-10-13 06:33:56,675 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.6031 | val_loss=0.5634 | val_acc=0.7957 | time=5.6s
2025-10-13 06:34:02,290 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.6019 | val_loss=0.5611 | val_acc=0.7932 | time=5.6s
2025-10-13 06:34:07,973 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.6005 | val_loss=0.5602 | val_acc=0.7958 | time=5.7s
2025-10-13 06:34:13,641 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.5961 | val_loss=0.5563 | val_acc=0.7960 | time=5.7s
2025-10-13 06:34:19,239 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.5957 | val_loss=0.5582 | val_acc=0.7959 | time=5.6s
2025-10-13 06:34:24,882 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.5933 | val_loss=0.5545 | val_acc=0.7971 | time=5.6s
2025-10-13 06:34:30,574 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.5903 | val_loss=0.5583 | val_acc=0.7944 | time=5.7s
2025-10-13 06:34:36,159 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.5871 | val_loss=0.5499 | val_acc=0.7990 | time=5.6s
2025-10-13 06:34:41,787 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.5869 | val_loss=0.5571 | val_acc=0.7961 | time=5.6s
2025-10-13 06:34:47,411 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.5824 | val_loss=0.5553 | val_acc=0.7968 | time=5.6s
2025-10-13 06:34:53,087 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.5793 | val_loss=0.5475 | val_acc=0.8001 | time=5.7s
2025-10-13 06:34:58,778 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.5802 | val_loss=0.5510 | val_acc=0.7971 | time=5.7s
2025-10-13 06:35:04,506 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.5783 | val_loss=0.5514 | val_acc=0.7988 | time=5.7s
2025-10-13 06:35:10,182 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.5771 | val_loss=0.5465 | val_acc=0.8023 | time=5.7s
2025-10-13 06:35:15,800 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.5749 | val_loss=0.5519 | val_acc=0.7961 | time=5.6s
2025-10-13 06:35:21,403 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.5768 | val_loss=0.5440 | val_acc=0.8011 | time=5.6s
2025-10-13 06:35:27,039 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.5723 | val_loss=0.5422 | val_acc=0.8029 | time=5.6s
2025-10-13 06:35:32,636 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.5703 | val_loss=0.5412 | val_acc=0.8037 | time=5.6s
2025-10-13 06:35:38,291 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.5684 | val_loss=0.5423 | val_acc=0.8027 | time=5.7s
2025-10-13 06:35:43,934 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.5681 | val_loss=0.5395 | val_acc=0.8027 | time=5.6s
2025-10-13 06:35:49,600 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.5667 | val_loss=0.5478 | val_acc=0.7995 | time=5.7s
2025-10-13 06:35:55,251 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.5677 | val_loss=0.5384 | val_acc=0.8048 | time=5.7s
2025-10-13 06:36:00,865 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.5662 | val_loss=0.5410 | val_acc=0.8019 | time=5.6s
2025-10-13 06:36:06,468 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.5640 | val_loss=0.5390 | val_acc=0.8056 | time=5.6s
2025-10-13 06:36:12,071 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.5602 | val_loss=0.5465 | val_acc=0.8010 | time=5.6s
2025-10-13 06:36:17,696 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.5636 | val_loss=0.5418 | val_acc=0.8055 | time=5.6s
2025-10-13 06:36:23,269 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.5633 | val_loss=0.5338 | val_acc=0.8052 | time=5.6s
2025-10-13 06:36:28,852 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.5585 | val_loss=0.5351 | val_acc=0.8040 | time=5.6s
2025-10-13 06:36:34,504 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.5596 | val_loss=0.5340 | val_acc=0.8063 | time=5.7s
2025-10-13 06:36:40,152 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.5625 | val_loss=0.5435 | val_acc=0.8019 | time=5.6s
2025-10-13 06:36:45,798 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.5581 | val_loss=0.5406 | val_acc=0.8025 | time=5.6s
2025-10-13 06:36:51,403 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.5589 | val_loss=0.5356 | val_acc=0.8062 | time=5.6s
2025-10-13 06:36:57,016 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.5548 | val_loss=0.5304 | val_acc=0.8068 | time=5.6s
2025-10-13 06:37:02,658 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.5542 | val_loss=0.5332 | val_acc=0.8051 | time=5.6s
2025-10-13 06:37:08,272 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.5552 | val_loss=0.5329 | val_acc=0.8071 | time=5.6s
2025-10-13 06:37:13,890 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.5517 | val_loss=0.5360 | val_acc=0.8050 | time=5.6s
2025-10-13 06:37:19,497 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.5527 | val_loss=0.5318 | val_acc=0.8071 | time=5.6s
2025-10-13 06:37:25,132 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.5505 | val_loss=0.5337 | val_acc=0.8066 | time=5.6s
2025-10-13 06:37:30,849 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.5507 | val_loss=0.5367 | val_acc=0.8060 | time=5.7s
2025-10-13 06:37:36,497 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.5506 | val_loss=0.5336 | val_acc=0.8052 | time=5.6s
2025-10-13 06:37:36,501 - INFO - _models.training_function_executor - Quantized model size: 67137 bytes.
2025-10-13 06:37:37,578 - INFO - _models.training_function_executor - Model: 12,514 parameters, 53.8KB storage
2025-10-13 06:37:37,578 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.335859763442865, 0.9740806145813234, 0.8902063806719575, 0.8488722681988775, 0.8230133641629859, 0.7944478759471044, 0.7708797132975161, 0.7526302355536223, 0.7321669424867396, 0.7196422824763233, 0.704090162308474, 0.6931568161409386, 0.6821240051970601, 0.6670573949057571, 0.6612216334921687, 0.6546523907216312, 0.6498942158002723, 0.644148384928599, 0.6387055947161405, 0.6318742238900483, 0.6266569584675882, 0.6251167434629211, 0.6216094657090272, 0.6201442630820062, 0.6132836911278376, 0.6090040403644147, 0.6079935329618428, 0.602898408933603, 0.6042905764476294, 0.6030919082882649, 0.6019228142554167, 0.6004851901571902, 0.59606902569136, 0.5957167815126277, 0.5933237855313206, 0.5903460610974782, 0.587142307630756, 0.5868979372191062, 0.5823592651461987, 0.5792994643576211, 0.5802353142200336, 0.5783068347913968, 0.5771317044634856, 0.5749348856047145, 0.5767572548737215, 0.5723090977321608, 0.5703292888884867, 0.5684414158621199, 0.5681277596980782, 0.5667426788962342, 0.5677243793578176, 0.5662364463602533, 0.564027108134696, 0.5602151961292384, 0.563568238558826, 0.563274697517656, 0.5585218247001431, 0.5595958631669553, 0.5625376004541842, 0.5581300271101919, 0.5589325821009556, 0.554777637682138, 0.5541831825813882, 0.5551701782021566, 0.5516696380393298, 0.5527336393118865, 0.550540076972285, 0.5506606340971617, 0.5505551654176567], 'val_losses': [1.0507959616864357, 0.872848073919628, 0.8156539532409751, 0.7830174734928744, 0.7520365804527704, 0.734372823627253, 0.7142452803115391, 0.6964510312687904, 0.6807556473211597, 0.6613824587207096, 0.6465354092604304, 0.6358766953637227, 0.6271769598016882, 0.6293247852201932, 0.611322173569058, 0.6021252969865996, 0.6018848000058437, 0.5943253568139242, 0.5940156668727115, 0.5851424484349732, 0.587341376752089, 0.5822265531618694, 0.5739768363814443, 0.5723841081852257, 0.5767478291851513, 0.573053462254154, 0.5739893056960802, 0.5756969588867717, 0.5656698105382802, 0.5633825004872718, 0.5610885405336012, 0.5602391677738112, 0.556338705464097, 0.5581769230777165, 0.5544959512422833, 0.5583234138846773, 0.5499312446475821, 0.557090869588705, 0.5552986537634096, 0.5475487242243195, 0.550982199178987, 0.5513821495843593, 0.5464774392412224, 0.5519201712181487, 0.5439728919728302, 0.5421901737679791, 0.5411767953648866, 0.5422547994469027, 0.539488351413909, 0.5477913327731575, 0.5384455442918862, 0.5409541987521606, 0.5389843498195933, 0.5465478626140815, 0.5417631691544048, 0.5338290084751912, 0.5350550722785875, 0.53395188027927, 0.5434997662208194, 0.5406044855593884, 0.5355626396680988, 0.5303612122449751, 0.5332468754142825, 0.5328972756257623, 0.5360414350850623, 0.5317585264672589, 0.5337394967200584, 0.5367070905835553, 0.5335678622194383], 'val_acc': [0.6082429121456073, 0.6515575778788939, 0.680434021701085, 0.6988974448722436, 0.7202485124256213, 0.7254987749387469, 0.7378368918445922, 0.7410745537276864, 0.7464123206160308, 0.7552502625131257, 0.7609380469023451, 0.765750787539377, 0.7686384319215961, 0.7641757087854393, 0.7762513125656283, 0.7787889394469724, 0.7792264613230662, 0.7806265313265663, 0.7815890794539727, 0.7864018200910046, 0.7844767238361918, 0.7864018200910046, 0.7901645082254113, 0.7908645432271614, 0.7900770038501925, 0.7925271263563178, 0.7885894294714736, 0.7914770738536927, 0.7908645432271614, 0.7956772838641932, 0.7932271613580679, 0.795764788239412, 0.7960273013650683, 0.7958522926146308, 0.7970773538676934, 0.7943647182359118, 0.7990024501225061, 0.796114805740287, 0.7968148407420371, 0.8000525026251313, 0.7970773538676934, 0.7988274413720686, 0.8023276163808191, 0.796114805740287, 0.8011025551277564, 0.8028526426321316, 0.8037276863843192, 0.8026776338816941, 0.8026776338816941, 0.7995274763738187, 0.8047777388869444, 0.8018900945047253, 0.8055652782639132, 0.8010150507525376, 0.8054777738886945, 0.8052152607630382, 0.8039901995099755, 0.8062653132656633, 0.8018900945047253, 0.8025026251312566, 0.8061778088904445, 0.8067903395169759, 0.8051277563878194, 0.8070528526426322, 0.8049527476373819, 0.8070528526426322, 0.8066153307665384, 0.806002800140007, 0.8052152607630382], 'model_size_bytes': 67137, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 4.742157382736943e-05, 'batch_size': 24, 'epochs': 69, 'weight_decay': 2.1505645031344884e-06, 'dropout': 0.0979028248679121, 'hidden_size': 29, 'd_model': 14, 't_pooled': 192, 'label_smoothing': 0.010634516361012028, 'use_focal_loss': False, 'focal_gamma': 3.739907369287357, 'grad_clip_norm': 3.9691189092465473, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 12514, 'model_storage_size_kb': 53.771093750000006, 'model_size_validation': 'PASS'}
2025-10-13 06:37:37,578 - INFO - _models.training_function_executor - BO Objective: base=0.8052, size_penalty=0.0000, final=0.8052
2025-10-13 06:37:37,578 - INFO - _models.training_function_executor - Model: 12,514 parameters, 53.8KB (PASS 256KB limit)
2025-10-13 06:37:37,578 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 392.872s
2025-10-13 06:37:37,674 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8052
2025-10-13 06:37:37,674 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.094s
2025-10-13 06:37:37,674 - INFO - bo.run_bo - Recorded observation #19: hparams={'lr': 4.742157382736943e-05, 'batch_size': np.int64(24), 'epochs': np.int64(69), 'weight_decay': 2.1505645031344884e-06, 'dropout': 0.0979028248679121, 'hidden_size': np.int64(29), 'd_model': np.int64(14), 't_pooled': np.int64(192), 'label_smoothing': 0.010634516361012028, 'use_focal_loss': np.False_, 'focal_gamma': 3.739907369287357, 'grad_clip_norm': 3.9691189092465473, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.8052
2025-10-13 06:37:37,674 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 19: {'lr': 4.742157382736943e-05, 'batch_size': np.int64(24), 'epochs': np.int64(69), 'weight_decay': 2.1505645031344884e-06, 'dropout': 0.0979028248679121, 'hidden_size': np.int64(29), 'd_model': np.int64(14), 't_pooled': np.int64(192), 'label_smoothing': 0.010634516361012028, 'use_focal_loss': np.False_, 'focal_gamma': 3.739907369287357, 'grad_clip_norm': 3.9691189092465473, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.8052
2025-10-13 06:37:37,675 - INFO - bo.run_bo - üîçBO Trial 20: Using RF surrogate + Expected Improvement
2025-10-13 06:37:37,675 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 06:37:37,675 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 20 (NaN monitoring active)
2025-10-13 06:37:37,675 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 06:37:37,675 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 06:37:37,675 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 3.5383737383536464e-05, 'batch_size': 24, 'epochs': 73, 'weight_decay': 0.005984658184985259, 'dropout': 0.49577326516182574, 'hidden_size': 10, 'd_model': 18, 't_pooled': 128, 'label_smoothing': 0.012662389751489126, 'use_focal_loss': False, 'focal_gamma': 0.4362454267154909, 'grad_clip_norm': 1.3003871002690612, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 06:37:37,676 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 3.5383737383536464e-05, 'batch_size': 24, 'epochs': 73, 'weight_decay': 0.005984658184985259, 'dropout': 0.49577326516182574, 'hidden_size': 10, 'd_model': 18, 't_pooled': 128, 'label_smoothing': 0.012662389751489126, 'use_focal_loss': False, 'focal_gamma': 0.4362454267154909, 'grad_clip_norm': 1.3003871002690612, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 06:37:46,131 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5090 | val_loss=1.3440 | val_acc=0.5137 | time=8.5s
2025-10-13 06:37:51,717 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2578 | val_loss=1.1195 | val_acc=0.6170 | time=5.6s
2025-10-13 06:37:57,291 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1056 | val_loss=0.9990 | val_acc=0.6409 | time=5.6s
2025-10-13 06:38:02,930 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0165 | val_loss=0.9206 | val_acc=0.6488 | time=5.6s
2025-10-13 06:38:08,547 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9613 | val_loss=0.8694 | val_acc=0.6590 | time=5.6s
2025-10-13 06:38:14,118 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9211 | val_loss=0.8354 | val_acc=0.6659 | time=5.6s
2025-10-13 06:38:19,725 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8942 | val_loss=0.8097 | val_acc=0.6738 | time=5.6s
2025-10-13 06:38:25,390 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.8745 | val_loss=0.7907 | val_acc=0.6864 | time=5.7s
2025-10-13 06:38:30,995 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.8604 | val_loss=0.7713 | val_acc=0.6874 | time=5.6s
2025-10-13 06:38:36,584 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8465 | val_loss=0.7631 | val_acc=0.6865 | time=5.6s
2025-10-13 06:38:42,182 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8333 | val_loss=0.7504 | val_acc=0.6998 | time=5.6s
2025-10-13 06:38:47,735 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.8232 | val_loss=0.7445 | val_acc=0.6988 | time=5.6s
2025-10-13 06:38:53,329 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.8164 | val_loss=0.7316 | val_acc=0.7085 | time=5.6s
2025-10-13 06:38:58,895 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.8063 | val_loss=0.7272 | val_acc=0.7237 | time=5.6s
2025-10-13 06:39:04,467 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.8002 | val_loss=0.7243 | val_acc=0.7123 | time=5.6s
2025-10-13 06:39:10,030 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7946 | val_loss=0.7084 | val_acc=0.7334 | time=5.6s
2025-10-13 06:39:15,615 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.7843 | val_loss=0.7016 | val_acc=0.7323 | time=5.6s
2025-10-13 06:39:21,198 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.7804 | val_loss=0.6939 | val_acc=0.7416 | time=5.6s
2025-10-13 06:39:26,763 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.7764 | val_loss=0.6906 | val_acc=0.7415 | time=5.6s
2025-10-13 06:39:32,347 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.7693 | val_loss=0.6837 | val_acc=0.7440 | time=5.6s
2025-10-13 06:39:37,954 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.7645 | val_loss=0.6780 | val_acc=0.7468 | time=5.6s
2025-10-13 06:39:43,522 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.7572 | val_loss=0.6745 | val_acc=0.7496 | time=5.6s
2025-10-13 06:39:49,240 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.7511 | val_loss=0.6697 | val_acc=0.7574 | time=5.7s
2025-10-13 06:39:54,908 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.7441 | val_loss=0.6674 | val_acc=0.7560 | time=5.7s
2025-10-13 06:40:00,501 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.7449 | val_loss=0.6615 | val_acc=0.7625 | time=5.6s
2025-10-13 06:40:06,053 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.7373 | val_loss=0.6558 | val_acc=0.7597 | time=5.6s
2025-10-13 06:40:11,645 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.7325 | val_loss=0.6515 | val_acc=0.7573 | time=5.6s
2025-10-13 06:40:17,190 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.7277 | val_loss=0.6537 | val_acc=0.7578 | time=5.5s
2025-10-13 06:40:22,752 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.7249 | val_loss=0.6553 | val_acc=0.7566 | time=5.6s
2025-10-13 06:40:28,317 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.7210 | val_loss=0.6412 | val_acc=0.7652 | time=5.6s
2025-10-13 06:40:33,904 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.7177 | val_loss=0.6384 | val_acc=0.7651 | time=5.6s
2025-10-13 06:40:39,471 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.7139 | val_loss=0.6364 | val_acc=0.7648 | time=5.6s
2025-10-13 06:40:45,087 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.7109 | val_loss=0.6338 | val_acc=0.7678 | time=5.6s
2025-10-13 06:40:50,654 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.7089 | val_loss=0.6259 | val_acc=0.7739 | time=5.6s
2025-10-13 06:40:56,237 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.7075 | val_loss=0.6203 | val_acc=0.7764 | time=5.6s
2025-10-13 06:41:01,809 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.6989 | val_loss=0.6151 | val_acc=0.7789 | time=5.6s
2025-10-13 06:41:07,386 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.6992 | val_loss=0.6234 | val_acc=0.7707 | time=5.6s
2025-10-13 06:41:12,966 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.6937 | val_loss=0.6131 | val_acc=0.7782 | time=5.6s
2025-10-13 06:41:18,571 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.6959 | val_loss=0.6119 | val_acc=0.7793 | time=5.6s
2025-10-13 06:41:24,170 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.6936 | val_loss=0.6045 | val_acc=0.7812 | time=5.6s
2025-10-13 06:41:29,732 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.6869 | val_loss=0.6072 | val_acc=0.7833 | time=5.6s
2025-10-13 06:41:35,319 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.6879 | val_loss=0.6062 | val_acc=0.7809 | time=5.6s
2025-10-13 06:41:40,898 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.6869 | val_loss=0.6059 | val_acc=0.7794 | time=5.6s
2025-10-13 06:41:46,461 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.6848 | val_loss=0.6084 | val_acc=0.7798 | time=5.6s
2025-10-13 06:41:52,037 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.6797 | val_loss=0.5949 | val_acc=0.7835 | time=5.6s
2025-10-13 06:41:57,619 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.6811 | val_loss=0.5988 | val_acc=0.7788 | time=5.6s
2025-10-13 06:42:03,225 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.6761 | val_loss=0.5928 | val_acc=0.7870 | time=5.6s
2025-10-13 06:42:08,835 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.6719 | val_loss=0.5943 | val_acc=0.7853 | time=5.6s
2025-10-13 06:42:14,418 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.6714 | val_loss=0.5926 | val_acc=0.7826 | time=5.6s
2025-10-13 06:42:20,000 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.6741 | val_loss=0.5858 | val_acc=0.7842 | time=5.6s
2025-10-13 06:42:25,606 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.6683 | val_loss=0.5860 | val_acc=0.7847 | time=5.6s
2025-10-13 06:42:31,174 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.6678 | val_loss=0.5917 | val_acc=0.7807 | time=5.6s
2025-10-13 06:42:36,765 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.6668 | val_loss=0.5909 | val_acc=0.7869 | time=5.6s
2025-10-13 06:42:42,410 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.6669 | val_loss=0.5793 | val_acc=0.7871 | time=5.6s
2025-10-13 06:42:48,047 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.6627 | val_loss=0.5817 | val_acc=0.7874 | time=5.6s
2025-10-13 06:42:53,679 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.6663 | val_loss=0.5844 | val_acc=0.7857 | time=5.6s
2025-10-13 06:42:59,260 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.6623 | val_loss=0.5801 | val_acc=0.7889 | time=5.6s
2025-10-13 06:43:04,820 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.6542 | val_loss=0.5766 | val_acc=0.7892 | time=5.6s
2025-10-13 06:43:10,402 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.6582 | val_loss=0.5808 | val_acc=0.7866 | time=5.6s
2025-10-13 06:43:15,979 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.6571 | val_loss=0.5750 | val_acc=0.7901 | time=5.6s
2025-10-13 06:43:21,558 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.6546 | val_loss=0.5776 | val_acc=0.7924 | time=5.6s
2025-10-13 06:43:27,112 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.6566 | val_loss=0.5768 | val_acc=0.7912 | time=5.6s
2025-10-13 06:43:32,691 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.6550 | val_loss=0.5698 | val_acc=0.7918 | time=5.6s
2025-10-13 06:43:38,276 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.6512 | val_loss=0.5719 | val_acc=0.7915 | time=5.6s
2025-10-13 06:43:43,926 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.6474 | val_loss=0.5707 | val_acc=0.7913 | time=5.6s
2025-10-13 06:43:49,597 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.6496 | val_loss=0.5739 | val_acc=0.7931 | time=5.7s
2025-10-13 06:43:55,168 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.6493 | val_loss=0.5735 | val_acc=0.7883 | time=5.6s
2025-10-13 06:44:00,731 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.6493 | val_loss=0.5679 | val_acc=0.7936 | time=5.6s
2025-10-13 06:44:06,323 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.6486 | val_loss=0.5674 | val_acc=0.7947 | time=5.6s
2025-10-13 06:44:11,937 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.6467 | val_loss=0.5675 | val_acc=0.7903 | time=5.6s
2025-10-13 06:44:17,524 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.6479 | val_loss=0.5644 | val_acc=0.7973 | time=5.6s
2025-10-13 06:44:23,125 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.6469 | val_loss=0.5659 | val_acc=0.7936 | time=5.6s
2025-10-13 06:44:28,715 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.6425 | val_loss=0.5671 | val_acc=0.7938 | time=5.6s
2025-10-13 06:44:28,719 - INFO - _models.training_function_executor - Quantized model size: 43009 bytes.
2025-10-13 06:44:29,820 - INFO - _models.training_function_executor - Model: 6,463 parameters, 27.8KB storage
2025-10-13 06:44:29,820 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5090291944257772, 1.2578007776627893, 1.1056477069792148, 1.0164619143250357, 0.9613224936712443, 0.921057849100181, 0.8941950695807591, 0.8744588868577121, 0.8604105250439863, 0.8465282168365835, 0.8333418126869001, 0.8231539608383246, 0.8164010203600264, 0.8063171495288078, 0.800239664187872, 0.7945867347464847, 0.7842817621753481, 0.7804122123845106, 0.7764433484197205, 0.7693228647660492, 0.764507229272035, 0.757203381066561, 0.7510852701010134, 0.7441439298970907, 0.7448846233560774, 0.7373056468437467, 0.7324777602586122, 0.7276952590951146, 0.7248567049376898, 0.7209826713785826, 0.7177247474472715, 0.7139474583706907, 0.7108696121976723, 0.7088741587203076, 0.7074598832891085, 0.6988946724269705, 0.6991981559432717, 0.6937338281990058, 0.6959352071442969, 0.6936469181933977, 0.6868827536957723, 0.6879097015072426, 0.6869064157279088, 0.6847891911087146, 0.6796994048438374, 0.6811286271463377, 0.6761277410578886, 0.6718928188210732, 0.6713684290897859, 0.6741431961536908, 0.6683323023711045, 0.6678336237641661, 0.6668325114107274, 0.6669393688059579, 0.6627466688581309, 0.666294207692793, 0.6622764497974514, 0.6542425865596267, 0.6582441232214451, 0.6570526745625421, 0.6546170197669802, 0.6565612757856878, 0.6549873938239618, 0.6511955355999142, 0.6473830599268708, 0.6495867293271979, 0.6492601052959315, 0.6492621778951561, 0.6485985519223001, 0.64674750464099, 0.6479321260358597, 0.6469304001400176, 0.6424518734122808], 'val_losses': [1.3440248324481348, 1.1195352413790352, 0.9989702617283421, 0.9206234477890677, 0.8694416837839134, 0.8353982111103351, 0.8097229851556483, 0.7907389486674709, 0.7713419680500264, 0.7631218433380127, 0.7503704676521296, 0.74447725795139, 0.7316126517891508, 0.727166701112129, 0.7243116390342098, 0.7084149176689725, 0.7016291891543815, 0.6938737305073542, 0.6906454402081066, 0.6837107696272837, 0.678039563257126, 0.6744923582016942, 0.669739800616499, 0.6673953260080273, 0.6614659457908546, 0.6557876786486352, 0.6514958685663642, 0.6536572064329453, 0.6553129931513479, 0.641191278089791, 0.6383933246156575, 0.6364043645292135, 0.6337610111501111, 0.6258855610720795, 0.6202638218525535, 0.61512634240542, 0.6233911548809944, 0.6130848828628842, 0.6118912866034623, 0.6045047021909405, 0.6072368233467592, 0.606173366798485, 0.6058537902054271, 0.6084478025695933, 0.5948959262086496, 0.5987596671335923, 0.592832139782193, 0.5942682564300301, 0.5925813891439534, 0.5857650999906892, 0.5859914807160084, 0.5917331718839379, 0.5909029380775307, 0.579259608210823, 0.5817264342093159, 0.5844280715793173, 0.5800720550795305, 0.5765801661595373, 0.5808092149292041, 0.5749500638638755, 0.5776239340752624, 0.5767918918405666, 0.5697509163757868, 0.5719039661820885, 0.5707412679784983, 0.5738884960077925, 0.5734832612083723, 0.5679397122047145, 0.5674212869539684, 0.5674939434303868, 0.56440334321946, 0.5659439521556473, 0.5670992534217778], 'val_acc': [0.5137381869093455, 0.6169933496674834, 0.6408820441022051, 0.6487574378718935, 0.6589954497724886, 0.6659082954147707, 0.6737836891844592, 0.6863843192159608, 0.6874343717185859, 0.6864718235911795, 0.6997724886244312, 0.6988099404970248, 0.7085229261463073, 0.723661183059153, 0.712285614280714, 0.7333741687084354, 0.7323241162058103, 0.741599579978999, 0.7415120756037802, 0.7440497024851243, 0.7467623381169058, 0.7495624781239062, 0.7574378718935947, 0.7560378018900945, 0.7625131256562828, 0.7597129856492825, 0.7572628631431572, 0.7577878893944697, 0.7565628281414071, 0.7652257612880644, 0.7650507525376269, 0.7647882394119706, 0.7677633881694085, 0.7738886944347217, 0.7764263213160658, 0.7788764438221911, 0.7706510325516276, 0.778176408820441, 0.7793139656982849, 0.7811515575778789, 0.7832516625831292, 0.7808890444522226, 0.7794014700735037, 0.7798389919495975, 0.7835141757087855, 0.7787889394469724, 0.7870143507175359, 0.7852642632131607, 0.7825516275813791, 0.7842142107105355, 0.7847392369618481, 0.7807140357017851, 0.7869268463423171, 0.7871018550927547, 0.7873643682184109, 0.7857017850892545, 0.7889394469723486, 0.7892019600980049, 0.7865768288414421, 0.7900770038501925, 0.7924396219810991, 0.7912145607280364, 0.7918270913545677, 0.7914770738536927, 0.7913020651032552, 0.7930521526076304, 0.7883269163458173, 0.793577178858943, 0.7947147357367869, 0.79025201260063, 0.7973398669933497, 0.793577178858943, 0.7937521876093805], 'model_size_bytes': 43009, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 3.5383737383536464e-05, 'batch_size': 24, 'epochs': 73, 'weight_decay': 0.005984658184985259, 'dropout': 0.49577326516182574, 'hidden_size': 10, 'd_model': 18, 't_pooled': 128, 'label_smoothing': 0.012662389751489126, 'use_focal_loss': False, 'focal_gamma': 0.4362454267154909, 'grad_clip_norm': 1.3003871002690612, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 6463, 'model_storage_size_kb': 27.770703125, 'model_size_validation': 'PASS'}
2025-10-13 06:44:29,820 - INFO - _models.training_function_executor - BO Objective: base=0.7938, size_penalty=0.0000, final=0.7938
2025-10-13 06:44:29,820 - INFO - _models.training_function_executor - Model: 6,463 parameters, 27.8KB (PASS 256KB limit)
2025-10-13 06:44:29,820 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 412.146s
2025-10-13 06:44:29,914 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7938
2025-10-13 06:44:29,914 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.092s
2025-10-13 06:44:29,914 - INFO - bo.run_bo - Recorded observation #20: hparams={'lr': 3.5383737383536464e-05, 'batch_size': np.int64(24), 'epochs': np.int64(73), 'weight_decay': 0.005984658184985259, 'dropout': 0.49577326516182574, 'hidden_size': np.int64(10), 'd_model': np.int64(18), 't_pooled': np.int64(128), 'label_smoothing': 0.012662389751489126, 'use_focal_loss': np.False_, 'focal_gamma': 0.4362454267154909, 'grad_clip_norm': 1.3003871002690612, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7938
2025-10-13 06:44:29,914 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 20: {'lr': 3.5383737383536464e-05, 'batch_size': np.int64(24), 'epochs': np.int64(73), 'weight_decay': 0.005984658184985259, 'dropout': 0.49577326516182574, 'hidden_size': np.int64(10), 'd_model': np.int64(18), 't_pooled': np.int64(128), 'label_smoothing': 0.012662389751489126, 'use_focal_loss': np.False_, 'focal_gamma': 0.4362454267154909, 'grad_clip_norm': 1.3003871002690612, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7938
2025-10-13 06:44:29,914 - INFO - bo.run_bo - üîçBO Trial 21: Using RF surrogate + Expected Improvement
2025-10-13 06:44:29,914 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 06:44:29,914 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 21 (NaN monitoring active)
2025-10-13 06:44:29,914 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 06:44:29,914 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 06:44:29,914 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.8291129530231187e-05, 'batch_size': 8, 'epochs': 88, 'weight_decay': 0.005469135471327652, 'dropout': 0.10271933072924164, 'hidden_size': 14, 'd_model': 16, 't_pooled': 192, 'label_smoothing': 0.03897939586194102, 'use_focal_loss': False, 'focal_gamma': 3.9292833908193106, 'grad_clip_norm': 3.9448071112848755, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 06:44:29,915 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.8291129530231187e-05, 'batch_size': 8, 'epochs': 88, 'weight_decay': 0.005469135471327652, 'dropout': 0.10271933072924164, 'hidden_size': 14, 'd_model': 16, 't_pooled': 192, 'label_smoothing': 0.03897939586194102, 'use_focal_loss': False, 'focal_gamma': 3.9292833908193106, 'grad_clip_norm': 3.9448071112848755, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 06:44:46,959 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.4435 | val_loss=1.1835 | val_acc=0.5185 | time=17.0s
2025-10-13 06:45:01,309 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.1695 | val_loss=1.0541 | val_acc=0.6402 | time=14.3s
2025-10-13 06:45:15,454 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.0681 | val_loss=0.9554 | val_acc=0.6482 | time=14.1s
2025-10-13 06:45:29,811 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0274 | val_loss=0.9225 | val_acc=0.6531 | time=14.4s
2025-10-13 06:45:44,166 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0030 | val_loss=0.9035 | val_acc=0.6566 | time=14.4s
2025-10-13 06:45:58,482 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9777 | val_loss=0.8790 | val_acc=0.6634 | time=14.3s
2025-10-13 06:46:12,849 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9472 | val_loss=0.8494 | val_acc=0.7177 | time=14.4s
2025-10-13 06:46:27,346 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.9181 | val_loss=0.8108 | val_acc=0.7257 | time=14.5s
2025-10-13 06:46:41,715 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.8843 | val_loss=0.7905 | val_acc=0.7348 | time=14.4s
2025-10-13 06:46:56,062 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8683 | val_loss=0.7815 | val_acc=0.7349 | time=14.3s
2025-10-13 06:47:10,325 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8466 | val_loss=0.7599 | val_acc=0.7463 | time=14.3s
2025-10-13 06:47:24,737 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.8364 | val_loss=0.7444 | val_acc=0.7511 | time=14.4s
2025-10-13 06:47:39,002 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.8287 | val_loss=0.7640 | val_acc=0.7378 | time=14.3s
2025-10-13 06:47:53,345 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.8154 | val_loss=0.7336 | val_acc=0.7552 | time=14.3s
2025-10-13 06:48:07,770 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.8088 | val_loss=0.7218 | val_acc=0.7593 | time=14.4s
2025-10-13 06:48:22,101 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7984 | val_loss=0.7196 | val_acc=0.7625 | time=14.3s
2025-10-13 06:48:36,542 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.7966 | val_loss=0.7066 | val_acc=0.7695 | time=14.4s
2025-10-13 06:48:50,844 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.7813 | val_loss=0.7016 | val_acc=0.7726 | time=14.3s
2025-10-13 06:49:05,246 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.7791 | val_loss=0.7041 | val_acc=0.7691 | time=14.4s
2025-10-13 06:49:19,600 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.7705 | val_loss=0.6974 | val_acc=0.7744 | time=14.4s
2025-10-13 06:49:34,065 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.7693 | val_loss=0.7052 | val_acc=0.7656 | time=14.5s
2025-10-13 06:49:48,397 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.7640 | val_loss=0.6862 | val_acc=0.7773 | time=14.3s
2025-10-13 06:50:02,748 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.7546 | val_loss=0.6852 | val_acc=0.7803 | time=14.4s
2025-10-13 06:50:17,075 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.7586 | val_loss=0.6796 | val_acc=0.7767 | time=14.3s
2025-10-13 06:50:31,384 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.7504 | val_loss=0.6806 | val_acc=0.7822 | time=14.3s
2025-10-13 06:50:45,709 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.7510 | val_loss=0.6741 | val_acc=0.7812 | time=14.3s
2025-10-13 06:51:00,078 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.7449 | val_loss=0.6710 | val_acc=0.7812 | time=14.4s
2025-10-13 06:51:14,527 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.7448 | val_loss=0.6778 | val_acc=0.7771 | time=14.4s
2025-10-13 06:51:28,801 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.7390 | val_loss=0.6683 | val_acc=0.7827 | time=14.3s
2025-10-13 06:51:43,073 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.7374 | val_loss=0.6717 | val_acc=0.7820 | time=14.3s
2025-10-13 06:51:57,499 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.7376 | val_loss=0.6768 | val_acc=0.7805 | time=14.4s
2025-10-13 06:52:11,814 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.7353 | val_loss=0.6773 | val_acc=0.7757 | time=14.3s
2025-10-13 06:52:26,199 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.7310 | val_loss=0.6774 | val_acc=0.7774 | time=14.4s
2025-10-13 06:52:40,456 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.7300 | val_loss=0.6639 | val_acc=0.7851 | time=14.3s
2025-10-13 06:52:54,732 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.7270 | val_loss=0.6630 | val_acc=0.7843 | time=14.3s
2025-10-13 06:53:09,217 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.7255 | val_loss=0.6758 | val_acc=0.7791 | time=14.5s
2025-10-13 06:53:23,315 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.7253 | val_loss=0.6708 | val_acc=0.7760 | time=14.1s
2025-10-13 06:53:37,719 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.7202 | val_loss=0.6605 | val_acc=0.7855 | time=14.4s
2025-10-13 06:53:51,940 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.7249 | val_loss=0.6695 | val_acc=0.7779 | time=14.2s
2025-10-13 06:54:06,265 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.7166 | val_loss=0.6603 | val_acc=0.7867 | time=14.3s
2025-10-13 06:54:20,678 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.7154 | val_loss=0.6681 | val_acc=0.7822 | time=14.4s
2025-10-13 06:54:35,080 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.7144 | val_loss=0.6620 | val_acc=0.7851 | time=14.4s
2025-10-13 06:54:49,541 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.7151 | val_loss=0.6661 | val_acc=0.7820 | time=14.5s
2025-10-13 06:55:03,727 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.7155 | val_loss=0.6612 | val_acc=0.7823 | time=14.2s
2025-10-13 06:55:17,982 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.7109 | val_loss=0.6646 | val_acc=0.7807 | time=14.3s
2025-10-13 06:55:32,340 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.7084 | val_loss=0.6607 | val_acc=0.7861 | time=14.4s
2025-10-13 06:55:46,773 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.7143 | val_loss=0.6585 | val_acc=0.7858 | time=14.4s
2025-10-13 06:56:01,005 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.7038 | val_loss=0.6612 | val_acc=0.7875 | time=14.2s
2025-10-13 06:56:15,225 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.7056 | val_loss=0.6628 | val_acc=0.7848 | time=14.2s
2025-10-13 06:56:29,538 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.7067 | val_loss=0.6669 | val_acc=0.7791 | time=14.3s
2025-10-13 06:56:43,778 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.7015 | val_loss=0.6604 | val_acc=0.7888 | time=14.2s
2025-10-13 06:56:58,175 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.7035 | val_loss=0.6590 | val_acc=0.7829 | time=14.4s
2025-10-13 06:57:12,411 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.7025 | val_loss=0.6571 | val_acc=0.7863 | time=14.2s
2025-10-13 06:57:26,854 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.7028 | val_loss=0.6511 | val_acc=0.7886 | time=14.4s
2025-10-13 06:57:41,089 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.6996 | val_loss=0.6509 | val_acc=0.7881 | time=14.2s
2025-10-13 06:57:55,392 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.7027 | val_loss=0.6512 | val_acc=0.7903 | time=14.3s
2025-10-13 06:58:09,738 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.6977 | val_loss=0.6496 | val_acc=0.7909 | time=14.3s
2025-10-13 06:58:24,133 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.6989 | val_loss=0.6511 | val_acc=0.7896 | time=14.4s
2025-10-13 06:58:38,554 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.6970 | val_loss=0.6541 | val_acc=0.7877 | time=14.4s
2025-10-13 06:58:52,922 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.6951 | val_loss=0.6564 | val_acc=0.7887 | time=14.4s
2025-10-13 06:59:07,268 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.6967 | val_loss=0.6539 | val_acc=0.7876 | time=14.3s
2025-10-13 06:59:21,651 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.6970 | val_loss=0.6466 | val_acc=0.7917 | time=14.4s
2025-10-13 06:59:36,042 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.6921 | val_loss=0.6493 | val_acc=0.7911 | time=14.4s
2025-10-13 06:59:50,353 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.6892 | val_loss=0.6488 | val_acc=0.7912 | time=14.3s
2025-10-13 07:00:04,777 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.6927 | val_loss=0.6497 | val_acc=0.7915 | time=14.4s
2025-10-13 07:00:19,161 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.6893 | val_loss=0.6448 | val_acc=0.7931 | time=14.4s
2025-10-13 07:00:33,478 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.6911 | val_loss=0.6473 | val_acc=0.7917 | time=14.3s
2025-10-13 07:00:47,951 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.6898 | val_loss=0.6491 | val_acc=0.7912 | time=14.5s
2025-10-13 07:01:02,272 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.6875 | val_loss=0.6551 | val_acc=0.7867 | time=14.3s
2025-10-13 07:01:16,545 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.6882 | val_loss=0.6478 | val_acc=0.7925 | time=14.3s
2025-10-13 07:01:30,898 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.6859 | val_loss=0.6497 | val_acc=0.7910 | time=14.4s
2025-10-13 07:01:45,149 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.6854 | val_loss=0.6475 | val_acc=0.7929 | time=14.3s
2025-10-13 07:01:59,513 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.6842 | val_loss=0.6647 | val_acc=0.7852 | time=14.4s
2025-10-13 07:02:13,726 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.6844 | val_loss=0.6435 | val_acc=0.7896 | time=14.2s
2025-10-13 07:02:27,952 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.6840 | val_loss=0.6640 | val_acc=0.7832 | time=14.2s
2025-10-13 07:02:42,188 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.6835 | val_loss=0.6469 | val_acc=0.7937 | time=14.2s
2025-10-13 07:02:56,491 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.6835 | val_loss=0.6448 | val_acc=0.7952 | time=14.3s
2025-10-13 07:03:10,898 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.6826 | val_loss=0.6450 | val_acc=0.7931 | time=14.4s
2025-10-13 07:03:25,240 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.6782 | val_loss=0.6483 | val_acc=0.7948 | time=14.3s
2025-10-13 07:03:39,627 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.6805 | val_loss=0.6499 | val_acc=0.7902 | time=14.4s
2025-10-13 07:03:54,030 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.6811 | val_loss=0.6441 | val_acc=0.7933 | time=14.4s
2025-10-13 07:04:08,477 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.6770 | val_loss=0.6509 | val_acc=0.7925 | time=14.4s
2025-10-13 07:04:22,754 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.6774 | val_loss=0.6503 | val_acc=0.7931 | time=14.3s
2025-10-13 07:04:37,012 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.6779 | val_loss=0.6566 | val_acc=0.7854 | time=14.3s
2025-10-13 07:04:51,426 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.6782 | val_loss=0.6420 | val_acc=0.7937 | time=14.4s
2025-10-13 07:05:05,684 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.6765 | val_loss=0.6543 | val_acc=0.7924 | time=14.3s
2025-10-13 07:05:20,043 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.6767 | val_loss=0.6444 | val_acc=0.7927 | time=14.4s
2025-10-13 07:05:34,482 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.6762 | val_loss=0.6506 | val_acc=0.7875 | time=14.4s
2025-10-13 07:05:34,487 - INFO - _models.training_function_executor - Quantized model size: 31937 bytes.
2025-10-13 07:05:35,580 - INFO - _models.training_function_executor - Model: 7,321 parameters, 15.7KB storage
2025-10-13 07:05:35,580 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4435004998763876, 1.1695293199778187, 1.0681064495067727, 1.0274238228213757, 1.00301326278794, 0.9777368549902956, 0.9472488049948429, 0.9181410132858108, 0.8842696269148081, 0.8683495466050711, 0.8466051330996595, 0.8363563990442745, 0.8287387454597358, 0.815447263484824, 0.8087626761193871, 0.7984455226756577, 0.7965522467944018, 0.781263487939656, 0.7791456710240788, 0.7704984106079115, 0.7693223747280372, 0.7639585007184195, 0.7546469047091873, 0.7585957443532637, 0.7503579891605272, 0.7510053100788723, 0.7449293196263912, 0.7448263074635499, 0.7390327891990109, 0.7374469332363083, 0.737604074558262, 0.7352840064558317, 0.7310497412705155, 0.7300166281257678, 0.7269822779389624, 0.7254863058875022, 0.7253211422148267, 0.720219976970542, 0.7248786717163002, 0.716605093954721, 0.715439767594683, 0.7144138597324882, 0.7150927072362879, 0.7155364697755405, 0.7109258036133415, 0.708350732781731, 0.7142661009811838, 0.7037705564789936, 0.7056050036163818, 0.706721052756917, 0.7014679052809297, 0.7035098231215346, 0.7025093020813258, 0.7027746157281917, 0.6996342839453451, 0.7027325493772213, 0.6977218239091266, 0.698940025488, 0.6969595205405187, 0.6951132468986144, 0.6967053641263613, 0.697001074697323, 0.6921362980579554, 0.6891944918326453, 0.6926955159181142, 0.6892879046930022, 0.6910711032660182, 0.6897803683656681, 0.6874744973041438, 0.6882083416115499, 0.6858670313170752, 0.6854048838404079, 0.6842128326415515, 0.6843856939818419, 0.6839729360049531, 0.6835116466489712, 0.6834781761243705, 0.6826064832114781, 0.6782202863733919, 0.6804527682798244, 0.6811056705931704, 0.6769864135218076, 0.6773836632781735, 0.6778505488964157, 0.6781813757123127, 0.6765023759420534, 0.6766944143752932, 0.6762274122312222], 'val_losses': [1.1834885257084051, 1.0541350554243267, 0.9553714591930244, 0.9225313965991364, 0.903530178952142, 0.8789577941857813, 0.84943863569042, 0.8108475863161645, 0.7904549339433462, 0.7815037942408347, 0.7598574359307642, 0.7443714543347765, 0.7639895773013238, 0.73356091649665, 0.7218117552033912, 0.7195983669496643, 0.7065692008856005, 0.7016153685855498, 0.7040883013949263, 0.6974310521003788, 0.705198643755821, 0.6861519121522873, 0.6852294379049221, 0.6796344460246027, 0.6806355042602785, 0.6740995522850579, 0.6710343366325173, 0.677802358019548, 0.6682780043704133, 0.6716738236734906, 0.6768005616835125, 0.6772999614007748, 0.6773685171736008, 0.6639312986293622, 0.6629957886667656, 0.6758078255768544, 0.6708437353633357, 0.6605426305693098, 0.6694771358713972, 0.6602956102909974, 0.6680935147261762, 0.6620481169157025, 0.6661408548072205, 0.6611792015411823, 0.6645728664086088, 0.6606535214121041, 0.6584570456268823, 0.6612083863702987, 0.6628182856278024, 0.6669062086344183, 0.6604135648683522, 0.6589947010738932, 0.6570868556487798, 0.6510664569693175, 0.6508557516709883, 0.651181480112216, 0.6496369911421, 0.6510947676630424, 0.65412675966155, 0.6563849342236537, 0.6538923317146, 0.6466097238391774, 0.6493473038896214, 0.6488200752185198, 0.6496633918063391, 0.6448257572278719, 0.6472562069362137, 0.64913319557707, 0.6550518121175262, 0.6477946424175486, 0.649656358687745, 0.6475096197344433, 0.6646784911069746, 0.6434618899006087, 0.66404922962147, 0.6469356613452092, 0.6448372477391069, 0.6449673302552481, 0.6482769645695758, 0.6499329534993957, 0.6440713698833941, 0.6508572503512332, 0.6503107267574367, 0.6566048614996315, 0.6419717098475755, 0.6543410606199851, 0.644438558748063, 0.6506408719821205], 'val_acc': [0.5184634231711586, 0.640182009100455, 0.648232411620581, 0.6531326566328316, 0.656632831641582, 0.6633706685334266, 0.7177108855442772, 0.7256737836891844, 0.7347742387119356, 0.7349492474623731, 0.746324816240812, 0.7511375568778439, 0.7378368918445922, 0.7551627581379069, 0.7592754637731887, 0.7625131256562828, 0.7695134756737837, 0.7725761288064403, 0.7690759537976899, 0.7744137206860343, 0.7655757787889395, 0.7773013650682534, 0.7802765138256913, 0.7766888344417221, 0.782201610080504, 0.7811515575778789, 0.7812390619530977, 0.7771263563178159, 0.7827266363318166, 0.7820266013300665, 0.7805390269513476, 0.7757262863143157, 0.7773888694434722, 0.7850892544627232, 0.7843017150857543, 0.7790514525726286, 0.775988799439972, 0.785526776338817, 0.7779138956947848, 0.7866643332166608, 0.782201610080504, 0.7850892544627232, 0.7820266013300665, 0.7822891144557228, 0.7807140357017851, 0.7860518025901295, 0.7857892894644732, 0.7874518725936297, 0.7848267413370669, 0.7791389569478474, 0.7887644382219111, 0.7829016450822541, 0.7863143157157858, 0.7885894294714736, 0.788064403220161, 0.79025201260063, 0.7908645432271614, 0.7896394819740987, 0.787714385719286, 0.7886769338466924, 0.7876268813440672, 0.791739586979349, 0.7911270563528177, 0.7912145607280364, 0.7914770738536927, 0.7930521526076304, 0.7916520826041302, 0.7912145607280364, 0.7866643332166608, 0.7925271263563178, 0.7910395519775989, 0.7928771438571929, 0.7851767588379419, 0.7896394819740987, 0.7831641582079104, 0.7936646832341617, 0.7951522576128807, 0.7930521526076304, 0.7948022401120056, 0.7901645082254113, 0.7933146657332867, 0.7925271263563178, 0.7930521526076304, 0.7853517675883794, 0.7936646832341617, 0.7923521176058803, 0.7927021351067554, 0.7874518725936297], 'model_size_bytes': 31937, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.8291129530231187e-05, 'batch_size': 8, 'epochs': 88, 'weight_decay': 0.005469135471327652, 'dropout': 0.10271933072924164, 'hidden_size': 14, 'd_model': 16, 't_pooled': 192, 'label_smoothing': 0.03897939586194102, 'use_focal_loss': False, 'focal_gamma': 3.9292833908193106, 'grad_clip_norm': 3.9448071112848755, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 7321, 'model_storage_size_kb': 15.7287109375, 'model_size_validation': 'PASS'}
2025-10-13 07:05:35,580 - INFO - _models.training_function_executor - BO Objective: base=0.7875, size_penalty=0.0000, final=0.7875
2025-10-13 07:05:35,580 - INFO - _models.training_function_executor - Model: 7,321 parameters, 15.7KB (PASS 256KB limit)
2025-10-13 07:05:35,580 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 1265.666s
2025-10-13 07:05:35,677 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7875
2025-10-13 07:05:35,677 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.096s
2025-10-13 07:05:35,677 - INFO - bo.run_bo - Recorded observation #21: hparams={'lr': 2.8291129530231187e-05, 'batch_size': np.int64(8), 'epochs': np.int64(88), 'weight_decay': 0.005469135471327652, 'dropout': 0.10271933072924164, 'hidden_size': np.int64(14), 'd_model': np.int64(16), 't_pooled': np.int64(192), 'label_smoothing': 0.03897939586194102, 'use_focal_loss': np.False_, 'focal_gamma': 3.9292833908193106, 'grad_clip_norm': 3.9448071112848755, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7875
2025-10-13 07:05:35,677 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 21: {'lr': 2.8291129530231187e-05, 'batch_size': np.int64(8), 'epochs': np.int64(88), 'weight_decay': 0.005469135471327652, 'dropout': 0.10271933072924164, 'hidden_size': np.int64(14), 'd_model': np.int64(16), 't_pooled': np.int64(192), 'label_smoothing': 0.03897939586194102, 'use_focal_loss': np.False_, 'focal_gamma': 3.9292833908193106, 'grad_clip_norm': 3.9448071112848755, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7875
2025-10-13 07:05:35,677 - INFO - bo.run_bo - üîçBO Trial 22: Using RF surrogate + Expected Improvement
2025-10-13 07:05:35,677 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:05:35,677 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 22 (NaN monitoring active)
2025-10-13 07:05:35,677 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:05:35,677 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:05:35,677 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.8131516059217964e-05, 'batch_size': 24, 'epochs': 72, 'weight_decay': 1.330316607406794e-05, 'dropout': 0.3303586868086414, 'hidden_size': 19, 'd_model': 32, 't_pooled': 384, 'label_smoothing': 0.0815935893354164, 'use_focal_loss': False, 'focal_gamma': 4.035058128529766, 'grad_clip_norm': 0.35837969826216737, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 07:05:35,678 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.8131516059217964e-05, 'batch_size': 24, 'epochs': 72, 'weight_decay': 1.330316607406794e-05, 'dropout': 0.3303586868086414, 'hidden_size': 19, 'd_model': 32, 't_pooled': 384, 'label_smoothing': 0.0815935893354164, 'use_focal_loss': False, 'focal_gamma': 4.035058128529766, 'grad_clip_norm': 0.35837969826216737, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 07:05:44,987 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.4805 | val_loss=1.3185 | val_acc=0.5762 | time=9.3s
2025-10-13 07:05:51,555 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2620 | val_loss=1.1805 | val_acc=0.6066 | time=6.6s
2025-10-13 07:05:58,145 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1487 | val_loss=1.0698 | val_acc=0.6414 | time=6.6s
2025-10-13 07:06:04,725 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0763 | val_loss=1.0100 | val_acc=0.6483 | time=6.6s
2025-10-13 07:06:11,301 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0316 | val_loss=0.9740 | val_acc=0.6674 | time=6.6s
2025-10-13 07:06:17,873 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0040 | val_loss=0.9496 | val_acc=0.6737 | time=6.6s
2025-10-13 07:06:24,451 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.9854 | val_loss=0.9294 | val_acc=0.6944 | time=6.6s
2025-10-13 07:06:31,039 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.9654 | val_loss=0.9119 | val_acc=0.7066 | time=6.6s
2025-10-13 07:06:37,627 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9480 | val_loss=0.9017 | val_acc=0.7101 | time=6.6s
2025-10-13 07:06:44,202 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9355 | val_loss=0.8906 | val_acc=0.7219 | time=6.6s
2025-10-13 07:06:50,778 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.9243 | val_loss=0.8774 | val_acc=0.7294 | time=6.6s
2025-10-13 07:06:57,373 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9144 | val_loss=0.8728 | val_acc=0.7286 | time=6.6s
2025-10-13 07:07:03,944 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9031 | val_loss=0.8595 | val_acc=0.7339 | time=6.6s
2025-10-13 07:07:10,533 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.8948 | val_loss=0.8617 | val_acc=0.7329 | time=6.6s
2025-10-13 07:07:17,116 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.8872 | val_loss=0.8450 | val_acc=0.7422 | time=6.6s
2025-10-13 07:07:23,697 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.8783 | val_loss=0.8352 | val_acc=0.7499 | time=6.6s
2025-10-13 07:07:30,273 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.8734 | val_loss=0.8294 | val_acc=0.7518 | time=6.6s
2025-10-13 07:07:36,875 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.8678 | val_loss=0.8242 | val_acc=0.7566 | time=6.6s
2025-10-13 07:07:43,455 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.8618 | val_loss=0.8246 | val_acc=0.7539 | time=6.6s
2025-10-13 07:07:50,033 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8557 | val_loss=0.8185 | val_acc=0.7594 | time=6.6s
2025-10-13 07:07:56,628 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8524 | val_loss=0.8135 | val_acc=0.7614 | time=6.6s
2025-10-13 07:08:03,202 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8476 | val_loss=0.8062 | val_acc=0.7657 | time=6.6s
2025-10-13 07:08:09,776 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8442 | val_loss=0.8033 | val_acc=0.7681 | time=6.6s
2025-10-13 07:08:16,349 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8416 | val_loss=0.7987 | val_acc=0.7686 | time=6.6s
2025-10-13 07:08:22,930 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8345 | val_loss=0.7994 | val_acc=0.7707 | time=6.6s
2025-10-13 07:08:29,509 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8342 | val_loss=0.7939 | val_acc=0.7744 | time=6.6s
2025-10-13 07:08:36,082 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8322 | val_loss=0.7952 | val_acc=0.7717 | time=6.6s
2025-10-13 07:08:42,675 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8286 | val_loss=0.7893 | val_acc=0.7742 | time=6.6s
2025-10-13 07:08:49,273 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8265 | val_loss=0.7955 | val_acc=0.7700 | time=6.6s
2025-10-13 07:08:55,851 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8216 | val_loss=0.7817 | val_acc=0.7787 | time=6.6s
2025-10-13 07:09:02,446 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8200 | val_loss=0.7820 | val_acc=0.7777 | time=6.6s
2025-10-13 07:09:09,015 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.8136 | val_loss=0.7783 | val_acc=0.7801 | time=6.6s
2025-10-13 07:09:15,599 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.8141 | val_loss=0.7833 | val_acc=0.7779 | time=6.6s
2025-10-13 07:09:22,174 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.8123 | val_loss=0.7733 | val_acc=0.7827 | time=6.6s
2025-10-13 07:09:28,761 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.8077 | val_loss=0.7725 | val_acc=0.7824 | time=6.6s
2025-10-13 07:09:35,342 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.8074 | val_loss=0.7739 | val_acc=0.7814 | time=6.6s
2025-10-13 07:09:41,925 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.8068 | val_loss=0.7720 | val_acc=0.7822 | time=6.6s
2025-10-13 07:09:48,506 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.8069 | val_loss=0.7689 | val_acc=0.7841 | time=6.6s
2025-10-13 07:09:55,096 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.8026 | val_loss=0.7661 | val_acc=0.7844 | time=6.6s
2025-10-13 07:10:01,680 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.8010 | val_loss=0.7660 | val_acc=0.7871 | time=6.6s
2025-10-13 07:10:08,263 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.7969 | val_loss=0.7658 | val_acc=0.7850 | time=6.6s
2025-10-13 07:10:14,846 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.7955 | val_loss=0.7662 | val_acc=0.7855 | time=6.6s
2025-10-13 07:10:21,428 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.7946 | val_loss=0.7689 | val_acc=0.7833 | time=6.6s
2025-10-13 07:10:28,012 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.7949 | val_loss=0.7626 | val_acc=0.7868 | time=6.6s
2025-10-13 07:10:34,601 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.7913 | val_loss=0.7601 | val_acc=0.7893 | time=6.6s
2025-10-13 07:10:41,180 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.7927 | val_loss=0.7592 | val_acc=0.7890 | time=6.6s
2025-10-13 07:10:47,765 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.7886 | val_loss=0.7602 | val_acc=0.7844 | time=6.6s
2025-10-13 07:10:54,353 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.7874 | val_loss=0.7570 | val_acc=0.7896 | time=6.6s
2025-10-13 07:11:00,934 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.7853 | val_loss=0.7545 | val_acc=0.7912 | time=6.6s
2025-10-13 07:11:07,503 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.7868 | val_loss=0.7554 | val_acc=0.7889 | time=6.6s
2025-10-13 07:11:14,071 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.7846 | val_loss=0.7533 | val_acc=0.7921 | time=6.6s
2025-10-13 07:11:20,654 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.7842 | val_loss=0.7522 | val_acc=0.7909 | time=6.6s
2025-10-13 07:11:27,240 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.7811 | val_loss=0.7563 | val_acc=0.7865 | time=6.6s
2025-10-13 07:11:33,827 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.7816 | val_loss=0.7547 | val_acc=0.7874 | time=6.6s
2025-10-13 07:11:40,423 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.7791 | val_loss=0.7510 | val_acc=0.7918 | time=6.6s
2025-10-13 07:11:47,010 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.7759 | val_loss=0.7531 | val_acc=0.7920 | time=6.6s
2025-10-13 07:11:53,599 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.7779 | val_loss=0.7486 | val_acc=0.7938 | time=6.6s
2025-10-13 07:12:00,184 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.7738 | val_loss=0.7490 | val_acc=0.7924 | time=6.6s
2025-10-13 07:12:06,770 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.7750 | val_loss=0.7496 | val_acc=0.7922 | time=6.6s
2025-10-13 07:12:13,355 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.7745 | val_loss=0.7489 | val_acc=0.7936 | time=6.6s
2025-10-13 07:12:19,945 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.7734 | val_loss=0.7474 | val_acc=0.7938 | time=6.6s
2025-10-13 07:12:26,533 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.7715 | val_loss=0.7468 | val_acc=0.7936 | time=6.6s
2025-10-13 07:12:33,124 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.7720 | val_loss=0.7430 | val_acc=0.7968 | time=6.6s
2025-10-13 07:12:39,709 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.7698 | val_loss=0.7463 | val_acc=0.7925 | time=6.6s
2025-10-13 07:12:46,289 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.7682 | val_loss=0.7469 | val_acc=0.7952 | time=6.6s
2025-10-13 07:12:52,862 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.7676 | val_loss=0.7438 | val_acc=0.7947 | time=6.6s
2025-10-13 07:12:59,452 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.7677 | val_loss=0.7446 | val_acc=0.7948 | time=6.6s
2025-10-13 07:13:06,022 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.7692 | val_loss=0.7439 | val_acc=0.7955 | time=6.6s
2025-10-13 07:13:12,635 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.7664 | val_loss=0.7495 | val_acc=0.7907 | time=6.6s
2025-10-13 07:13:19,222 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.7641 | val_loss=0.7432 | val_acc=0.7948 | time=6.6s
2025-10-13 07:13:25,804 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.7632 | val_loss=0.7429 | val_acc=0.7956 | time=6.6s
2025-10-13 07:13:32,403 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.7660 | val_loss=0.7400 | val_acc=0.7966 | time=6.6s
2025-10-13 07:13:32,407 - INFO - _models.training_function_executor - Quantized model size: 63681 bytes.
2025-10-13 07:13:33,538 - INFO - _models.training_function_executor - Model: 11,545 parameters, 49.6KB storage
2025-10-13 07:13:33,539 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4804817413924916, 1.2620128212502506, 1.1487262839928014, 1.076277574814405, 1.0315737554795015, 1.0039983819550804, 0.985439703708184, 0.9653871265123639, 0.9479565590275807, 0.9355276818975603, 0.9242637596599363, 0.9144221328963005, 0.9030920876607972, 0.8947928619105205, 0.8872334129917985, 0.878308995217763, 0.8733741037904862, 0.8677672895990471, 0.8618397601926748, 0.8556810157842306, 0.8523557704668342, 0.8475853067242185, 0.8442390383927606, 0.8416241728470882, 0.8344855701794022, 0.8341793893286512, 0.8321971755408306, 0.8286389920848793, 0.8265121311084933, 0.8216012325431234, 0.8199766362917186, 0.8135835633469413, 0.814084738096575, 0.81233196623433, 0.8076546438557308, 0.8074335480929673, 0.8068403599142903, 0.8068742705342817, 0.8026058946168627, 0.8010322682958488, 0.7969470065469128, 0.7954502447026153, 0.7946263838000008, 0.7948555745442597, 0.7912500946149151, 0.7927233964611611, 0.7886066568776114, 0.7874418984072418, 0.7852553155900384, 0.786817849381303, 0.7845731233962149, 0.7842136451235843, 0.7811033514712631, 0.781604049175112, 0.7791185024623734, 0.7759473220447498, 0.7778929022587718, 0.7737761190565975, 0.7749835861430203, 0.7745243965807519, 0.7734242458056853, 0.7714816187754518, 0.7720470716267313, 0.7697953968447407, 0.7682126814777883, 0.76759675819535, 0.7677303266704687, 0.7692454727923991, 0.7664378390868811, 0.7641422930227363, 0.763172996912046, 0.7659930129661651], 'val_losses': [1.3184674460027532, 1.1804852229045912, 1.0698480858517394, 1.010023201893041, 0.9740315454173931, 0.949573014430913, 0.9294287109024507, 0.911917390421132, 0.9017253213092336, 0.8906057935767463, 0.8774223389807472, 0.8727851490437004, 0.8594806273166308, 0.8617027522927613, 0.845031012427277, 0.8351948149645708, 0.8293878893189636, 0.8241845439020303, 0.8245682294526465, 0.8185374148458628, 0.8134602016195952, 0.8061658230577268, 0.8032751684636138, 0.7986962736216215, 0.7993879060166091, 0.7938855899185578, 0.795183286222078, 0.7892757502309835, 0.7955459914175748, 0.7816990385908408, 0.782029389709203, 0.7783395747934808, 0.7832744403406169, 0.7733178814683379, 0.772546537989789, 0.7739344566570198, 0.7720470256141152, 0.7689225168173072, 0.7661085903206446, 0.7659857351336815, 0.7658192504941895, 0.7662135116028377, 0.7689012825635083, 0.7625892222198858, 0.760084278190474, 0.7592474756476175, 0.7602477610674528, 0.7569530773797067, 0.7544962129769811, 0.7554306492006023, 0.7532650567369524, 0.7522010992968629, 0.7563407763051202, 0.7546519429732921, 0.7510189978985424, 0.7530543881360576, 0.7486084112763863, 0.7490200219264512, 0.7496175738661115, 0.7488594642251282, 0.7473967406855707, 0.7468261535575768, 0.7430254483414898, 0.7462619631950531, 0.7468771647438954, 0.74378889392296, 0.7446274892053781, 0.743862918677512, 0.7494802698832023, 0.7431612064423659, 0.7428972567759238, 0.740010561791174], 'val_acc': [0.5762163108155408, 0.6065803290164509, 0.6414070703535176, 0.6483199159957997, 0.6673958697934896, 0.6736961848092404, 0.6944347217360868, 0.7065978298914946, 0.710098004900245, 0.7219110955547777, 0.7294364718235912, 0.7285614280714036, 0.733899194959748, 0.7329366468323416, 0.7422121106055303, 0.7499124956247812, 0.751837591879594, 0.7565628281414071, 0.7539376968848442, 0.7593629681484074, 0.7613755687784389, 0.7656632831641582, 0.7681134056702835, 0.7686384319215961, 0.7706510325516276, 0.7744137206860343, 0.7717010850542527, 0.7742387119355968, 0.7700385019250963, 0.7787014350717536, 0.7776513825691285, 0.7801015050752538, 0.7779138956947848, 0.7827266363318166, 0.7823766188309416, 0.7814140707035352, 0.782201610080504, 0.7841267063353168, 0.7843892194609731, 0.7871018550927547, 0.7850017500875044, 0.785526776338817, 0.7832516625831292, 0.7868393419670984, 0.7892894644732237, 0.7890269513475674, 0.7843892194609731, 0.7896394819740987, 0.7912145607280364, 0.7889394469723486, 0.792089604480224, 0.7908645432271614, 0.7864893244662233, 0.7873643682184109, 0.7918270913545677, 0.7920021001050053, 0.7937521876093805, 0.7923521176058803, 0.7921771088554428, 0.793577178858943, 0.7938396919845992, 0.793577178858943, 0.7968148407420371, 0.7925271263563178, 0.7951522576128807, 0.7947147357367869, 0.7948022401120056, 0.7955022751137557, 0.7906895344767239, 0.7948022401120056, 0.7955897794889745, 0.7966398319915996], 'model_size_bytes': 63681, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.8131516059217964e-05, 'batch_size': 24, 'epochs': 72, 'weight_decay': 1.330316607406794e-05, 'dropout': 0.3303586868086414, 'hidden_size': 19, 'd_model': 32, 't_pooled': 384, 'label_smoothing': 0.0815935893354164, 'use_focal_loss': False, 'focal_gamma': 4.035058128529766, 'grad_clip_norm': 0.35837969826216737, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 11545, 'model_storage_size_kb': 49.60742187500001, 'model_size_validation': 'PASS'}
2025-10-13 07:13:33,539 - INFO - _models.training_function_executor - BO Objective: base=0.7966, size_penalty=0.0000, final=0.7966
2025-10-13 07:13:33,539 - INFO - _models.training_function_executor - Model: 11,545 parameters, 49.6KB (PASS 256KB limit)
2025-10-13 07:13:33,539 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 477.861s
2025-10-13 07:13:33,634 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7966
2025-10-13 07:13:33,634 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.093s
2025-10-13 07:13:33,634 - INFO - bo.run_bo - Recorded observation #22: hparams={'lr': 2.8131516059217964e-05, 'batch_size': np.int64(24), 'epochs': np.int64(72), 'weight_decay': 1.330316607406794e-05, 'dropout': 0.3303586868086414, 'hidden_size': np.int64(19), 'd_model': np.int64(32), 't_pooled': np.int64(384), 'label_smoothing': 0.0815935893354164, 'use_focal_loss': np.False_, 'focal_gamma': 4.035058128529766, 'grad_clip_norm': 0.35837969826216737, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.7966
2025-10-13 07:13:33,634 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 22: {'lr': 2.8131516059217964e-05, 'batch_size': np.int64(24), 'epochs': np.int64(72), 'weight_decay': 1.330316607406794e-05, 'dropout': 0.3303586868086414, 'hidden_size': np.int64(19), 'd_model': np.int64(32), 't_pooled': np.int64(384), 'label_smoothing': 0.0815935893354164, 'use_focal_loss': np.False_, 'focal_gamma': 4.035058128529766, 'grad_clip_norm': 0.35837969826216737, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.7966
2025-10-13 07:13:33,634 - INFO - bo.run_bo - üîçBO Trial 23: Using RF surrogate + Expected Improvement
2025-10-13 07:13:33,635 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:13:33,635 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 23 (NaN monitoring active)
2025-10-13 07:13:33,635 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:13:33,635 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:13:33,635 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0007391509592552704, 'batch_size': 8, 'epochs': 6, 'weight_decay': 0.001569185656592481, 'dropout': 0.028008195923991792, 'hidden_size': 11, 'd_model': 20, 't_pooled': 128, 'label_smoothing': 0.0057423271041607835, 'use_focal_loss': False, 'focal_gamma': 2.733763724199822, 'grad_clip_norm': 0.4709013127663415, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 07:13:33,636 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0007391509592552704, 'batch_size': 8, 'epochs': 6, 'weight_decay': 0.001569185656592481, 'dropout': 0.028008195923991792, 'hidden_size': 11, 'd_model': 20, 't_pooled': 128, 'label_smoothing': 0.0057423271041607835, 'use_focal_loss': False, 'focal_gamma': 2.733763724199822, 'grad_clip_norm': 0.4709013127663415, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 07:13:50,737 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8595 | val_loss=0.6284 | val_acc=0.7655 | time=17.1s
2025-10-13 07:14:05,055 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.6973 | val_loss=0.6009 | val_acc=0.7749 | time=14.3s
2025-10-13 07:14:19,459 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6573 | val_loss=0.6165 | val_acc=0.7693 | time=14.4s
2025-10-13 07:14:33,509 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6330 | val_loss=0.5837 | val_acc=0.7788 | time=14.1s
2025-10-13 07:14:47,798 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.6149 | val_loss=0.6207 | val_acc=0.7711 | time=14.3s
2025-10-13 07:15:02,089 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5998 | val_loss=0.5976 | val_acc=0.7748 | time=14.3s
2025-10-13 07:15:02,093 - INFO - _models.training_function_executor - Quantized model size: 45249 bytes.
2025-10-13 07:15:03,188 - INFO - _models.training_function_executor - Model: 6,962 parameters, 29.9KB storage
2025-10-13 07:15:03,188 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8595308423913314, 0.6973397674147883, 0.6572529485082143, 0.6329612043504641, 0.6148921236002053, 0.5998096735062489], 'val_losses': [0.6283873962143897, 0.6009324559088475, 0.6164878618427202, 0.58372334395312, 0.6207268589003795, 0.5976233362817748], 'val_acc': [0.7654882744137207, 0.7749387469373469, 0.7693384669233462, 0.7787889394469724, 0.7710885544277214, 0.7747637381869094], 'model_size_bytes': 45249, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0007391509592552704, 'batch_size': 8, 'epochs': 6, 'weight_decay': 0.001569185656592481, 'dropout': 0.028008195923991792, 'hidden_size': 11, 'd_model': 20, 't_pooled': 128, 'label_smoothing': 0.0057423271041607835, 'use_focal_loss': False, 'focal_gamma': 2.733763724199822, 'grad_clip_norm': 0.4709013127663415, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 6962, 'model_storage_size_kb': 29.914843750000003, 'model_size_validation': 'PASS'}
2025-10-13 07:15:03,188 - INFO - _models.training_function_executor - BO Objective: base=0.7748, size_penalty=0.0000, final=0.7748
2025-10-13 07:15:03,188 - INFO - _models.training_function_executor - Model: 6,962 parameters, 29.9KB (PASS 256KB limit)
2025-10-13 07:15:03,188 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 89.553s
2025-10-13 07:15:03,284 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7748
2025-10-13 07:15:03,284 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-13 07:15:03,284 - INFO - bo.run_bo - Recorded observation #23: hparams={'lr': 0.0007391509592552704, 'batch_size': np.int64(8), 'epochs': np.int64(6), 'weight_decay': 0.001569185656592481, 'dropout': 0.028008195923991792, 'hidden_size': np.int64(11), 'd_model': np.int64(20), 't_pooled': np.int64(128), 'label_smoothing': 0.0057423271041607835, 'use_focal_loss': np.False_, 'focal_gamma': 2.733763724199822, 'grad_clip_norm': 0.4709013127663415, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.7748
2025-10-13 07:15:03,284 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 23: {'lr': 0.0007391509592552704, 'batch_size': np.int64(8), 'epochs': np.int64(6), 'weight_decay': 0.001569185656592481, 'dropout': 0.028008195923991792, 'hidden_size': np.int64(11), 'd_model': np.int64(20), 't_pooled': np.int64(128), 'label_smoothing': 0.0057423271041607835, 'use_focal_loss': np.False_, 'focal_gamma': 2.733763724199822, 'grad_clip_norm': 0.4709013127663415, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.7748
2025-10-13 07:15:03,285 - INFO - bo.run_bo - üîçBO Trial 24: Using RF surrogate + Expected Improvement
2025-10-13 07:15:03,285 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:15:03,285 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 24 (NaN monitoring active)
2025-10-13 07:15:03,285 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:15:03,285 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:15:03,285 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.6133104633198637e-05, 'batch_size': 24, 'epochs': 93, 'weight_decay': 1.8092934870993484e-05, 'dropout': 0.29716939835417405, 'hidden_size': 22, 'd_model': 23, 't_pooled': 192, 'label_smoothing': 0.17691533069811693, 'use_focal_loss': False, 'focal_gamma': 0.2081558618766877, 'grad_clip_norm': 3.3783031620537125, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 07:15:03,286 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.6133104633198637e-05, 'batch_size': 24, 'epochs': 93, 'weight_decay': 1.8092934870993484e-05, 'dropout': 0.29716939835417405, 'hidden_size': 22, 'd_model': 23, 't_pooled': 192, 'label_smoothing': 0.17691533069811693, 'use_focal_loss': False, 'focal_gamma': 0.2081558618766877, 'grad_clip_norm': 3.3783031620537125, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 07:15:11,771 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5670 | val_loss=1.5051 | val_acc=0.4533 | time=8.5s
2025-10-13 07:15:17,399 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.4216 | val_loss=1.3276 | val_acc=0.6173 | time=5.6s
2025-10-13 07:15:23,105 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2988 | val_loss=1.2481 | val_acc=0.6324 | time=5.7s
2025-10-13 07:15:28,782 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.2440 | val_loss=1.2036 | val_acc=0.6418 | time=5.7s
2025-10-13 07:15:34,490 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.2072 | val_loss=1.1644 | val_acc=0.6471 | time=5.7s
2025-10-13 07:15:40,118 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1800 | val_loss=1.1404 | val_acc=0.6500 | time=5.6s
2025-10-13 07:15:45,731 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1629 | val_loss=1.1254 | val_acc=0.6543 | time=5.6s
2025-10-13 07:15:51,338 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1516 | val_loss=1.1137 | val_acc=0.6654 | time=5.6s
2025-10-13 07:15:56,947 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1405 | val_loss=1.1035 | val_acc=0.6747 | time=5.6s
2025-10-13 07:16:02,596 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1316 | val_loss=1.0935 | val_acc=0.6880 | time=5.6s
2025-10-13 07:16:08,245 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.1227 | val_loss=1.0839 | val_acc=0.6990 | time=5.6s
2025-10-13 07:16:13,898 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.1123 | val_loss=1.0797 | val_acc=0.6946 | time=5.7s
2025-10-13 07:16:19,534 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.1034 | val_loss=1.0675 | val_acc=0.7110 | time=5.6s
2025-10-13 07:16:25,217 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.0945 | val_loss=1.0574 | val_acc=0.7237 | time=5.7s
2025-10-13 07:16:30,911 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.0853 | val_loss=1.0495 | val_acc=0.7262 | time=5.7s
2025-10-13 07:16:36,584 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.0799 | val_loss=1.0403 | val_acc=0.7345 | time=5.7s
2025-10-13 07:16:42,233 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.0706 | val_loss=1.0374 | val_acc=0.7339 | time=5.6s
2025-10-13 07:16:47,881 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.0649 | val_loss=1.0295 | val_acc=0.7413 | time=5.6s
2025-10-13 07:16:53,494 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.0582 | val_loss=1.0231 | val_acc=0.7424 | time=5.6s
2025-10-13 07:16:59,142 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0538 | val_loss=1.0169 | val_acc=0.7467 | time=5.6s
2025-10-13 07:17:04,790 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0488 | val_loss=1.0125 | val_acc=0.7485 | time=5.6s
2025-10-13 07:17:10,456 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.0435 | val_loss=1.0085 | val_acc=0.7527 | time=5.7s
2025-10-13 07:17:16,122 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.0409 | val_loss=1.0084 | val_acc=0.7472 | time=5.7s
2025-10-13 07:17:21,775 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.0387 | val_loss=1.0030 | val_acc=0.7529 | time=5.7s
2025-10-13 07:17:27,420 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.0348 | val_loss=0.9996 | val_acc=0.7553 | time=5.6s
2025-10-13 07:17:33,037 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.0327 | val_loss=0.9996 | val_acc=0.7543 | time=5.6s
2025-10-13 07:17:38,659 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.0292 | val_loss=0.9964 | val_acc=0.7561 | time=5.6s
2025-10-13 07:17:44,329 - INFO - _models.training_function_executor - Epoch 028 | train_loss=1.0280 | val_loss=0.9964 | val_acc=0.7562 | time=5.7s
2025-10-13 07:17:49,975 - INFO - _models.training_function_executor - Epoch 029 | train_loss=1.0271 | val_loss=0.9911 | val_acc=0.7582 | time=5.6s
2025-10-13 07:17:55,582 - INFO - _models.training_function_executor - Epoch 030 | train_loss=1.0249 | val_loss=0.9902 | val_acc=0.7627 | time=5.6s
2025-10-13 07:18:01,204 - INFO - _models.training_function_executor - Epoch 031 | train_loss=1.0216 | val_loss=0.9877 | val_acc=0.7607 | time=5.6s
2025-10-13 07:18:06,873 - INFO - _models.training_function_executor - Epoch 032 | train_loss=1.0202 | val_loss=0.9865 | val_acc=0.7620 | time=5.7s
2025-10-13 07:18:12,560 - INFO - _models.training_function_executor - Epoch 033 | train_loss=1.0175 | val_loss=0.9846 | val_acc=0.7632 | time=5.7s
2025-10-13 07:18:18,192 - INFO - _models.training_function_executor - Epoch 034 | train_loss=1.0152 | val_loss=0.9823 | val_acc=0.7648 | time=5.6s
2025-10-13 07:18:23,896 - INFO - _models.training_function_executor - Epoch 035 | train_loss=1.0147 | val_loss=0.9812 | val_acc=0.7651 | time=5.7s
2025-10-13 07:18:29,614 - INFO - _models.training_function_executor - Epoch 036 | train_loss=1.0122 | val_loss=0.9833 | val_acc=0.7637 | time=5.7s
2025-10-13 07:18:35,248 - INFO - _models.training_function_executor - Epoch 037 | train_loss=1.0106 | val_loss=0.9772 | val_acc=0.7679 | time=5.6s
2025-10-13 07:18:40,903 - INFO - _models.training_function_executor - Epoch 038 | train_loss=1.0097 | val_loss=0.9769 | val_acc=0.7695 | time=5.7s
2025-10-13 07:18:46,549 - INFO - _models.training_function_executor - Epoch 039 | train_loss=1.0078 | val_loss=0.9744 | val_acc=0.7711 | time=5.6s
2025-10-13 07:18:52,226 - INFO - _models.training_function_executor - Epoch 040 | train_loss=1.0084 | val_loss=0.9764 | val_acc=0.7682 | time=5.7s
2025-10-13 07:18:57,869 - INFO - _models.training_function_executor - Epoch 041 | train_loss=1.0046 | val_loss=0.9739 | val_acc=0.7707 | time=5.6s
2025-10-13 07:19:03,548 - INFO - _models.training_function_executor - Epoch 042 | train_loss=1.0041 | val_loss=0.9715 | val_acc=0.7725 | time=5.7s
2025-10-13 07:19:09,192 - INFO - _models.training_function_executor - Epoch 043 | train_loss=1.0026 | val_loss=0.9710 | val_acc=0.7729 | time=5.6s
2025-10-13 07:19:14,852 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.9993 | val_loss=0.9696 | val_acc=0.7763 | time=5.7s
2025-10-13 07:19:20,465 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.9979 | val_loss=0.9665 | val_acc=0.7755 | time=5.6s
2025-10-13 07:19:26,106 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.9982 | val_loss=0.9661 | val_acc=0.7748 | time=5.6s
2025-10-13 07:19:31,797 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.9959 | val_loss=0.9643 | val_acc=0.7785 | time=5.7s
2025-10-13 07:19:37,427 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.9940 | val_loss=0.9643 | val_acc=0.7770 | time=5.6s
2025-10-13 07:19:43,058 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.9958 | val_loss=0.9613 | val_acc=0.7796 | time=5.6s
2025-10-13 07:19:48,733 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.9930 | val_loss=0.9610 | val_acc=0.7787 | time=5.7s
2025-10-13 07:19:54,395 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.9920 | val_loss=0.9603 | val_acc=0.7799 | time=5.7s
2025-10-13 07:20:00,089 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.9917 | val_loss=0.9589 | val_acc=0.7812 | time=5.7s
2025-10-13 07:20:05,720 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.9911 | val_loss=0.9715 | val_acc=0.7693 | time=5.6s
2025-10-13 07:20:11,370 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.9895 | val_loss=0.9602 | val_acc=0.7776 | time=5.6s
2025-10-13 07:20:17,084 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.9876 | val_loss=0.9566 | val_acc=0.7819 | time=5.7s
2025-10-13 07:20:22,700 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.9864 | val_loss=0.9693 | val_acc=0.7744 | time=5.6s
2025-10-13 07:20:28,348 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.9855 | val_loss=0.9552 | val_acc=0.7835 | time=5.6s
2025-10-13 07:20:33,974 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.9868 | val_loss=0.9537 | val_acc=0.7828 | time=5.6s
2025-10-13 07:20:39,637 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.9848 | val_loss=0.9531 | val_acc=0.7847 | time=5.7s
2025-10-13 07:20:45,284 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.9853 | val_loss=0.9551 | val_acc=0.7822 | time=5.6s
2025-10-13 07:20:50,976 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.9819 | val_loss=0.9504 | val_acc=0.7856 | time=5.7s
2025-10-13 07:20:56,647 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.9802 | val_loss=0.9532 | val_acc=0.7815 | time=5.7s
2025-10-13 07:21:02,256 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.9792 | val_loss=0.9498 | val_acc=0.7857 | time=5.6s
2025-10-13 07:21:07,851 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.9804 | val_loss=0.9491 | val_acc=0.7844 | time=5.6s
2025-10-13 07:21:13,484 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.9779 | val_loss=0.9509 | val_acc=0.7833 | time=5.6s
2025-10-13 07:21:19,161 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.9809 | val_loss=0.9479 | val_acc=0.7847 | time=5.7s
2025-10-13 07:21:24,864 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.9777 | val_loss=0.9470 | val_acc=0.7861 | time=5.7s
2025-10-13 07:21:30,563 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.9758 | val_loss=0.9463 | val_acc=0.7863 | time=5.7s
2025-10-13 07:21:36,187 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.9746 | val_loss=0.9457 | val_acc=0.7874 | time=5.6s
2025-10-13 07:21:41,886 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.9749 | val_loss=0.9438 | val_acc=0.7878 | time=5.7s
2025-10-13 07:21:47,552 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.9743 | val_loss=0.9444 | val_acc=0.7882 | time=5.7s
2025-10-13 07:21:53,234 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.9737 | val_loss=0.9433 | val_acc=0.7875 | time=5.7s
2025-10-13 07:21:58,854 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.9744 | val_loss=0.9414 | val_acc=0.7896 | time=5.6s
2025-10-13 07:22:04,452 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.9722 | val_loss=0.9419 | val_acc=0.7882 | time=5.6s
2025-10-13 07:22:10,135 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.9710 | val_loss=0.9400 | val_acc=0.7905 | time=5.7s
2025-10-13 07:22:15,771 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.9714 | val_loss=0.9424 | val_acc=0.7878 | time=5.6s
2025-10-13 07:22:21,435 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.9726 | val_loss=0.9407 | val_acc=0.7898 | time=5.7s
2025-10-13 07:22:27,087 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.9687 | val_loss=0.9396 | val_acc=0.7907 | time=5.7s
2025-10-13 07:22:32,767 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.9718 | val_loss=0.9394 | val_acc=0.7889 | time=5.7s
2025-10-13 07:22:38,418 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.9677 | val_loss=0.9460 | val_acc=0.7863 | time=5.7s
2025-10-13 07:22:44,115 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.9679 | val_loss=0.9409 | val_acc=0.7895 | time=5.7s
2025-10-13 07:22:49,792 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.9669 | val_loss=0.9405 | val_acc=0.7889 | time=5.7s
2025-10-13 07:22:55,442 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.9679 | val_loss=0.9393 | val_acc=0.7884 | time=5.7s
2025-10-13 07:23:01,059 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.9669 | val_loss=0.9374 | val_acc=0.7896 | time=5.6s
2025-10-13 07:23:06,689 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.9666 | val_loss=0.9342 | val_acc=0.7924 | time=5.6s
2025-10-13 07:23:12,361 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.9637 | val_loss=0.9347 | val_acc=0.7927 | time=5.7s
2025-10-13 07:23:17,977 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.9655 | val_loss=0.9347 | val_acc=0.7927 | time=5.6s
2025-10-13 07:23:23,593 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.9639 | val_loss=0.9351 | val_acc=0.7937 | time=5.6s
2025-10-13 07:23:29,226 - INFO - _models.training_function_executor - Epoch 089 | train_loss=0.9617 | val_loss=0.9389 | val_acc=0.7890 | time=5.6s
2025-10-13 07:23:34,872 - INFO - _models.training_function_executor - Epoch 090 | train_loss=0.9634 | val_loss=0.9325 | val_acc=0.7954 | time=5.6s
2025-10-13 07:23:40,526 - INFO - _models.training_function_executor - Epoch 091 | train_loss=0.9616 | val_loss=0.9330 | val_acc=0.7931 | time=5.7s
2025-10-13 07:23:46,209 - INFO - _models.training_function_executor - Epoch 092 | train_loss=0.9611 | val_loss=0.9326 | val_acc=0.7924 | time=5.7s
2025-10-13 07:23:51,855 - INFO - _models.training_function_executor - Epoch 093 | train_loss=0.9594 | val_loss=0.9313 | val_acc=0.7926 | time=5.6s
2025-10-13 07:23:51,859 - INFO - _models.training_function_executor - Quantized model size: 62081 bytes.
2025-10-13 07:23:52,977 - INFO - _models.training_function_executor - Model: 11,209 parameters, 48.2KB storage
2025-10-13 07:23:52,977 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5669696928948258, 1.421583054321898, 1.2988466504866065, 1.2439571406338905, 1.207193450490453, 1.1799876890296823, 1.1628878010416681, 1.1515647941404261, 1.1405031129764769, 1.1315848324988995, 1.122742884333083, 1.1122933895929235, 1.1034202512991274, 1.0944514510971206, 1.085314434716699, 1.0798808073283994, 1.0705977560946438, 1.0649491233616222, 1.05824245629838, 1.053814774163336, 1.0488155211211503, 1.0435056800833105, 1.0409291883761707, 1.0386532172691083, 1.0347981098902406, 1.0327357454841521, 1.0292045631148325, 1.0279719405525582, 1.0271494008671123, 1.0249352823156639, 1.0215515582804335, 1.0201693456470027, 1.0175086135813354, 1.0152040995477503, 1.0146759679299115, 1.0121746357083112, 1.010565753610225, 1.0097314874046033, 1.0078211398361694, 1.0083810327392715, 1.0045549907298783, 1.0040732363136573, 1.002637276626109, 0.9993026710115699, 0.9978501632220269, 0.9981717671449258, 0.9958702767170682, 0.993969642035311, 0.9957573914970181, 0.9930090336771248, 0.9920415057036941, 0.9917243140892086, 0.9910766571645433, 0.9894794639712411, 0.9875731819006459, 0.9864003832185022, 0.9855169791168877, 0.986789481807598, 0.9848022481591542, 0.9852779756215723, 0.9819251440457627, 0.9801713442172376, 0.979241776453852, 0.9804145236677918, 0.9778792562291135, 0.9808792359435896, 0.9777468525950292, 0.9757908229482395, 0.9746040483016755, 0.9748982366123606, 0.9743023014982388, 0.9737117454581716, 0.9744287776412938, 0.9722037532549035, 0.9709855943949522, 0.971438847912497, 0.9725955506179731, 0.9687342967109159, 0.9718174221927067, 0.9676741680295308, 0.9679244692128648, 0.9669479741097164, 0.9678504196943251, 0.9669295142883598, 0.9666240342876733, 0.9636831121570713, 0.9655148440885261, 0.9639241982370063, 0.9616723315862663, 0.9633543924263903, 0.9615583326960928, 0.96113432416517, 0.9593971243032343], 'val_losses': [1.5050598864460225, 1.3276162963669575, 1.248105846671404, 1.2035600737670855, 1.1644113690109574, 1.1404481511204485, 1.1254060342255947, 1.1137134869865575, 1.1035344009012202, 1.0934652897875168, 1.0839228899194346, 1.07968255144172, 1.067457111202256, 1.0573697243698168, 1.0494780084408368, 1.0403493888777873, 1.0373667771473272, 1.0294752193782395, 1.0231490834926782, 1.0169322417672797, 1.0124940181220792, 1.0085180260979048, 1.0083704553453248, 1.0029939656746651, 0.9995995651686738, 0.9996346911225737, 0.9963704396846372, 0.9963981402600441, 0.9910704957508398, 0.9902322273551479, 0.987654225701922, 0.9865397198199392, 0.9846380119937927, 0.9823455266865726, 0.9812055570410815, 0.9833124797578704, 0.9772059950830221, 0.9768528653309401, 0.9744270819027105, 0.9764038546543502, 0.9739177783219014, 0.9714776427336076, 0.9709746128285227, 0.969620025904812, 0.9665250022135125, 0.9660619228170767, 0.9643230988380999, 0.9642914206071213, 0.9613002334852756, 0.9609641847303375, 0.9603465393910593, 0.9589328281855224, 0.9714752487840876, 0.9602125319393106, 0.9565566656970877, 0.9693076048524888, 0.9551565898937656, 0.9536593279139245, 0.9531022354485816, 0.9550777623025029, 0.9504390422138752, 0.9531890206458813, 0.9497785532770767, 0.9490687585102331, 0.9509286473671122, 0.9479434143049048, 0.947010943469861, 0.9462651111130786, 0.9457415274735885, 0.9437748347290087, 0.9444380497907399, 0.9433025477605973, 0.9414236537217676, 0.9418975164475539, 0.9400391852601158, 0.9423764790735922, 0.9406780804584691, 0.9395693685360041, 0.939411803271581, 0.9459523718633308, 0.9409390928697703, 0.9405130513865171, 0.9392561235751645, 0.9373807001247413, 0.9342279040734168, 0.9347348829479037, 0.9347154179110074, 0.9351412695439746, 0.9388660946466475, 0.9325003392386778, 0.9330255615156265, 0.9325868916920445, 0.9313172385915409], 'val_acc': [0.45327266363318164, 0.6172558627931397, 0.6323941197059852, 0.6418445922296114, 0.6470948547427371, 0.6499824991249562, 0.6542702135106755, 0.6653832691634581, 0.6746587329366468, 0.6879593979698985, 0.6989849492474624, 0.6946097304865243, 0.7109730486524326, 0.723661183059153, 0.726198809940497, 0.7345117255862793, 0.733899194959748, 0.7413370668533427, 0.7423871193559678, 0.7466748337416871, 0.7485124256212811, 0.7527126356317816, 0.7471998599929996, 0.7528876443822191, 0.7552502625131257, 0.7542877143857193, 0.7561253062653133, 0.756212810640532, 0.7582254112705635, 0.7626881344067203, 0.7606755337766888, 0.7619880994049703, 0.7632131606580329, 0.7647882394119706, 0.7650507525376269, 0.7637381869093455, 0.7678508925446272, 0.7695134756737837, 0.7710885544277214, 0.7682009100455023, 0.7706510325516276, 0.7724886244312216, 0.7729261463073154, 0.7762513125656283, 0.7754637731886594, 0.7747637381869094, 0.7785264263213161, 0.7769513475673784, 0.7795764788239412, 0.7787014350717536, 0.7799264963248163, 0.7811515575778789, 0.7693384669233462, 0.7775638781939097, 0.781851592579629, 0.7744137206860343, 0.7835141757087855, 0.7828141407070354, 0.7846517325866293, 0.782201610080504, 0.7856142807140357, 0.781501575078754, 0.7857017850892545, 0.7843892194609731, 0.7832516625831292, 0.7846517325866293, 0.7861393069653483, 0.7863143157157858, 0.7873643682184109, 0.7878018900945047, 0.7881519075953798, 0.7875393769688485, 0.7896394819740987, 0.7882394119705985, 0.7905145257262863, 0.7878018900945047, 0.7898144907245362, 0.7906895344767239, 0.7889394469723486, 0.7863143157157858, 0.7894644732236612, 0.7888519425971299, 0.7884144207210361, 0.7896394819740987, 0.7923521176058803, 0.7927021351067554, 0.7927021351067554, 0.7936646832341617, 0.7890269513475674, 0.795414770738537, 0.7930521526076304, 0.7923521176058803, 0.7926146307315366], 'model_size_bytes': 62081, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.6133104633198637e-05, 'batch_size': 24, 'epochs': 93, 'weight_decay': 1.8092934870993484e-05, 'dropout': 0.29716939835417405, 'hidden_size': 22, 'd_model': 23, 't_pooled': 192, 'label_smoothing': 0.17691533069811693, 'use_focal_loss': False, 'focal_gamma': 0.2081558618766877, 'grad_clip_norm': 3.3783031620537125, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 11209, 'model_storage_size_kb': 48.163671875000006, 'model_size_validation': 'PASS'}
2025-10-13 07:23:52,977 - INFO - _models.training_function_executor - BO Objective: base=0.7926, size_penalty=0.0000, final=0.7926
2025-10-13 07:23:52,977 - INFO - _models.training_function_executor - Model: 11,209 parameters, 48.2KB (PASS 256KB limit)
2025-10-13 07:23:52,977 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 529.692s
2025-10-13 07:23:53,074 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7926
2025-10-13 07:23:53,074 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-13 07:23:53,074 - INFO - bo.run_bo - Recorded observation #24: hparams={'lr': 1.6133104633198637e-05, 'batch_size': np.int64(24), 'epochs': np.int64(93), 'weight_decay': 1.8092934870993484e-05, 'dropout': 0.29716939835417405, 'hidden_size': np.int64(22), 'd_model': np.int64(23), 't_pooled': np.int64(192), 'label_smoothing': 0.17691533069811693, 'use_focal_loss': np.False_, 'focal_gamma': 0.2081558618766877, 'grad_clip_norm': 3.3783031620537125, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.7926
2025-10-13 07:23:53,074 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 24: {'lr': 1.6133104633198637e-05, 'batch_size': np.int64(24), 'epochs': np.int64(93), 'weight_decay': 1.8092934870993484e-05, 'dropout': 0.29716939835417405, 'hidden_size': np.int64(22), 'd_model': np.int64(23), 't_pooled': np.int64(192), 'label_smoothing': 0.17691533069811693, 'use_focal_loss': np.False_, 'focal_gamma': 0.2081558618766877, 'grad_clip_norm': 3.3783031620537125, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.7926
2025-10-13 07:23:53,075 - INFO - bo.run_bo - üîçBO Trial 25: Using RF surrogate + Expected Improvement
2025-10-13 07:23:53,075 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:23:53,075 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 25 (NaN monitoring active)
2025-10-13 07:23:53,075 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:23:53,075 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:23:53,075 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00031221094379884154, 'batch_size': 32, 'epochs': 7, 'weight_decay': 1.0544212089739018e-06, 'dropout': 0.15727052402684302, 'hidden_size': 16, 'd_model': 15, 't_pooled': 384, 'label_smoothing': 0.0819829708336311, 'use_focal_loss': False, 'focal_gamma': 2.245916623334788, 'grad_clip_norm': 4.229091564369159, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:23:53,076 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00031221094379884154, 'batch_size': 32, 'epochs': 7, 'weight_decay': 1.0544212089739018e-06, 'dropout': 0.15727052402684302, 'hidden_size': 16, 'd_model': 15, 't_pooled': 384, 'label_smoothing': 0.0819829708336311, 'use_focal_loss': False, 'focal_gamma': 2.245916623334788, 'grad_clip_norm': 4.229091564369159, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:24:01,524 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.1184 | val_loss=0.9658 | val_acc=0.6706 | time=8.4s
2025-10-13 07:24:07,175 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.9657 | val_loss=0.9119 | val_acc=0.7125 | time=5.7s
2025-10-13 07:24:12,831 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.9075 | val_loss=0.8571 | val_acc=0.7411 | time=5.7s
2025-10-13 07:24:18,474 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.8657 | val_loss=0.8183 | val_acc=0.7603 | time=5.6s
2025-10-13 07:24:24,127 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.8466 | val_loss=0.8031 | val_acc=0.7658 | time=5.7s
2025-10-13 07:24:29,776 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.8245 | val_loss=0.7881 | val_acc=0.7791 | time=5.6s
2025-10-13 07:24:35,431 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8144 | val_loss=0.7857 | val_acc=0.7702 | time=5.7s
2025-10-13 07:24:35,439 - INFO - _models.training_function_executor - Quantized model size: 40443 bytes.
2025-10-13 07:24:36,526 - INFO - _models.training_function_executor - Model: 4,422 parameters, 4.8KB storage
2025-10-13 07:24:36,526 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1184195843784384, 0.9657496366210446, 0.9075387423798719, 0.8656516033826193, 0.8466384004453366, 0.8244720593089611, 0.814395752014044], 'val_losses': [0.9658072475874637, 0.9118998739783648, 0.8570612087757136, 0.8183124641000202, 0.8030842625055857, 0.7881205710949162, 0.7856850286943745], 'val_acc': [0.6706335316765838, 0.7125481274063703, 0.7410745537276864, 0.7603255162758138, 0.7658382919145957, 0.7790514525726286, 0.7702135106755338], 'model_size_bytes': 40443, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00031221094379884154, 'batch_size': 32, 'epochs': 7, 'weight_decay': 1.0544212089739018e-06, 'dropout': 0.15727052402684302, 'hidden_size': 16, 'd_model': 15, 't_pooled': 384, 'label_smoothing': 0.0819829708336311, 'use_focal_loss': False, 'focal_gamma': 2.245916623334788, 'grad_clip_norm': 4.229091564369159, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 4422, 'model_storage_size_kb': 4.750195312500001, 'model_size_validation': 'PASS'}
2025-10-13 07:24:36,526 - INFO - _models.training_function_executor - BO Objective: base=0.7702, size_penalty=0.0000, final=0.7702
2025-10-13 07:24:36,526 - INFO - _models.training_function_executor - Model: 4,422 parameters, 4.8KB (PASS 256KB limit)
2025-10-13 07:24:36,526 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 43.452s
2025-10-13 07:24:36,625 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7702
2025-10-13 07:24:36,625 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.096s
2025-10-13 07:24:36,625 - INFO - bo.run_bo - Recorded observation #25: hparams={'lr': 0.00031221094379884154, 'batch_size': np.int64(32), 'epochs': np.int64(7), 'weight_decay': 1.0544212089739018e-06, 'dropout': 0.15727052402684302, 'hidden_size': np.int64(16), 'd_model': np.int64(15), 't_pooled': np.int64(384), 'label_smoothing': 0.0819829708336311, 'use_focal_loss': np.False_, 'focal_gamma': 2.245916623334788, 'grad_clip_norm': 4.229091564369159, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7702
2025-10-13 07:24:36,625 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 25: {'lr': 0.00031221094379884154, 'batch_size': np.int64(32), 'epochs': np.int64(7), 'weight_decay': 1.0544212089739018e-06, 'dropout': 0.15727052402684302, 'hidden_size': np.int64(16), 'd_model': np.int64(15), 't_pooled': np.int64(384), 'label_smoothing': 0.0819829708336311, 'use_focal_loss': np.False_, 'focal_gamma': 2.245916623334788, 'grad_clip_norm': 4.229091564369159, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7702
2025-10-13 07:24:36,626 - INFO - bo.run_bo - üîçBO Trial 26: Using RF surrogate + Expected Improvement
2025-10-13 07:24:36,626 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:24:36,626 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 26 (NaN monitoring active)
2025-10-13 07:24:36,626 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:24:36,626 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:24:36,626 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0007623916004853267, 'batch_size': 32, 'epochs': 18, 'weight_decay': 0.0002439037683236985, 'dropout': 0.4162587654668742, 'hidden_size': 26, 'd_model': 17, 't_pooled': 256, 'label_smoothing': 0.008200078322066219, 'use_focal_loss': False, 'focal_gamma': 2.612356606746793, 'grad_clip_norm': 3.878603167980172, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:24:36,627 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0007623916004853267, 'batch_size': 32, 'epochs': 18, 'weight_decay': 0.0002439037683236985, 'dropout': 0.4162587654668742, 'hidden_size': 26, 'd_model': 17, 't_pooled': 256, 'label_smoothing': 0.008200078322066219, 'use_focal_loss': False, 'focal_gamma': 2.612356606746793, 'grad_clip_norm': 3.878603167980172, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:24:44,745 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8900 | val_loss=0.7099 | val_acc=0.7236 | time=8.1s
2025-10-13 07:24:50,062 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.6825 | val_loss=0.6943 | val_acc=0.7447 | time=5.3s
2025-10-13 07:24:55,366 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6390 | val_loss=0.5745 | val_acc=0.7852 | time=5.3s
2025-10-13 07:25:00,676 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6248 | val_loss=0.6003 | val_acc=0.7747 | time=5.3s
2025-10-13 07:25:05,976 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.6105 | val_loss=0.5611 | val_acc=0.7917 | time=5.3s
2025-10-13 07:25:11,247 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5951 | val_loss=0.5921 | val_acc=0.7784 | time=5.3s
2025-10-13 07:25:16,573 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5896 | val_loss=0.5844 | val_acc=0.7840 | time=5.3s
2025-10-13 07:25:21,873 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.5841 | val_loss=0.5661 | val_acc=0.7928 | time=5.3s
2025-10-13 07:25:27,197 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.5744 | val_loss=0.5548 | val_acc=0.7895 | time=5.3s
2025-10-13 07:25:32,508 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.5732 | val_loss=0.5416 | val_acc=0.7973 | time=5.3s
2025-10-13 07:25:37,822 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.5644 | val_loss=0.5763 | val_acc=0.7888 | time=5.3s
2025-10-13 07:25:43,157 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.5606 | val_loss=0.5246 | val_acc=0.8045 | time=5.3s
2025-10-13 07:25:48,492 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.5572 | val_loss=0.5293 | val_acc=0.8042 | time=5.3s
2025-10-13 07:25:53,808 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.5536 | val_loss=0.5139 | val_acc=0.8095 | time=5.3s
2025-10-13 07:25:59,153 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.5511 | val_loss=0.5341 | val_acc=0.8001 | time=5.3s
2025-10-13 07:26:04,488 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.5471 | val_loss=0.5193 | val_acc=0.8074 | time=5.3s
2025-10-13 07:26:09,820 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.5477 | val_loss=0.5154 | val_acc=0.8091 | time=5.3s
2025-10-13 07:26:15,173 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.5412 | val_loss=0.5254 | val_acc=0.8064 | time=5.4s
2025-10-13 07:26:15,176 - INFO - _models.training_function_executor - Quantized model size: 64385 bytes.
2025-10-13 07:26:16,285 - INFO - _models.training_function_executor - Model: 11,808 parameters, 50.7KB storage
2025-10-13 07:26:16,285 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8900358493110289, 0.6825394340232406, 0.6390166827795345, 0.62483192065983, 0.6105315143677335, 0.5950629843629069, 0.5895796187553198, 0.5840707739667121, 0.574382994479135, 0.5732187754860866, 0.5643937242043615, 0.560602316238432, 0.5572328992060193, 0.5536476349367476, 0.551107667743805, 0.5471444858885496, 0.5476917903720394, 0.5412239244675194], 'val_losses': [0.7099315923621365, 0.6943379338070526, 0.5745191164353864, 0.6003341740000527, 0.5611062137280305, 0.5920887144245298, 0.5844006258831351, 0.566069220198924, 0.5548335994337253, 0.5416170242870025, 0.5763226536591236, 0.5245885056321922, 0.5293085418425117, 0.5139071519428255, 0.5340836488328532, 0.5192879707528696, 0.5153922415151019, 0.5253737767050639], 'val_acc': [0.7235736786839342, 0.7447497374868743, 0.7851767588379419, 0.7746762338116906, 0.7916520826041302, 0.7784389219460973, 0.7839516975848793, 0.7927896394819741, 0.7894644732236612, 0.7973398669933497, 0.7887644382219111, 0.8045152257612881, 0.804165208260413, 0.8095029751487575, 0.80014000700035, 0.8074028701435072, 0.8090654532726637, 0.8063528176408821], 'model_size_bytes': 64385, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0007623916004853267, 'batch_size': 32, 'epochs': 18, 'weight_decay': 0.0002439037683236985, 'dropout': 0.4162587654668742, 'hidden_size': 26, 'd_model': 17, 't_pooled': 256, 'label_smoothing': 0.008200078322066219, 'use_focal_loss': False, 'focal_gamma': 2.612356606746793, 'grad_clip_norm': 3.878603167980172, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 11808, 'model_storage_size_kb': 50.737500000000004, 'model_size_validation': 'PASS'}
2025-10-13 07:26:16,285 - INFO - _models.training_function_executor - BO Objective: base=0.8064, size_penalty=0.0000, final=0.8064
2025-10-13 07:26:16,285 - INFO - _models.training_function_executor - Model: 11,808 parameters, 50.7KB (PASS 256KB limit)
2025-10-13 07:26:16,285 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 99.659s
2025-10-13 07:26:16,383 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8064
2025-10-13 07:26:16,383 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.095s
2025-10-13 07:26:16,383 - INFO - bo.run_bo - Recorded observation #26: hparams={'lr': 0.0007623916004853267, 'batch_size': np.int64(32), 'epochs': np.int64(18), 'weight_decay': 0.0002439037683236985, 'dropout': 0.4162587654668742, 'hidden_size': np.int64(26), 'd_model': np.int64(17), 't_pooled': np.int64(256), 'label_smoothing': 0.008200078322066219, 'use_focal_loss': np.False_, 'focal_gamma': 2.612356606746793, 'grad_clip_norm': 3.878603167980172, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8064
2025-10-13 07:26:16,383 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 26: {'lr': 0.0007623916004853267, 'batch_size': np.int64(32), 'epochs': np.int64(18), 'weight_decay': 0.0002439037683236985, 'dropout': 0.4162587654668742, 'hidden_size': np.int64(26), 'd_model': np.int64(17), 't_pooled': np.int64(256), 'label_smoothing': 0.008200078322066219, 'use_focal_loss': np.False_, 'focal_gamma': 2.612356606746793, 'grad_clip_norm': 3.878603167980172, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8064
2025-10-13 07:26:16,383 - INFO - bo.run_bo - üîçBO Trial 27: Using RF surrogate + Expected Improvement
2025-10-13 07:26:16,383 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:26:16,384 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 27 (NaN monitoring active)
2025-10-13 07:26:16,384 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:26:16,384 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:26:16,384 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00043655606972035254, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.338652597371245e-05, 'dropout': 0.43757314509610695, 'hidden_size': 26, 'd_model': 32, 't_pooled': 320, 'label_smoothing': 0.057158554265500615, 'use_focal_loss': True, 'focal_gamma': 0.2338310180656106, 'grad_clip_norm': 0.26363109448203254, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:26:16,385 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00043655606972035254, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.338652597371245e-05, 'dropout': 0.43757314509610695, 'hidden_size': 26, 'd_model': 32, 't_pooled': 320, 'label_smoothing': 0.057158554265500615, 'use_focal_loss': True, 'focal_gamma': 0.2338310180656106, 'grad_clip_norm': 0.26363109448203254, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:26:24,815 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9430 | val_loss=0.7736 | val_acc=0.7055 | time=8.4s
2025-10-13 07:26:30,411 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7679 | val_loss=0.6833 | val_acc=0.7552 | time=5.6s
2025-10-13 07:26:36,024 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6950 | val_loss=0.6622 | val_acc=0.7573 | time=5.6s
2025-10-13 07:26:41,626 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6659 | val_loss=0.6147 | val_acc=0.7849 | time=5.6s
2025-10-13 07:26:47,236 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.6507 | val_loss=0.6399 | val_acc=0.7727 | time=5.6s
2025-10-13 07:26:52,853 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.6371 | val_loss=0.6664 | val_acc=0.7616 | time=5.6s
2025-10-13 07:26:58,473 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.6299 | val_loss=0.6253 | val_acc=0.7855 | time=5.6s
2025-10-13 07:27:04,112 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.6230 | val_loss=0.5933 | val_acc=0.7910 | time=5.6s
2025-10-13 07:27:09,730 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.6164 | val_loss=0.5742 | val_acc=0.8008 | time=5.6s
2025-10-13 07:27:15,355 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.6111 | val_loss=0.5755 | val_acc=0.7984 | time=5.6s
2025-10-13 07:27:20,974 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.6080 | val_loss=0.5842 | val_acc=0.7969 | time=5.6s
2025-10-13 07:27:26,592 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.6013 | val_loss=0.5646 | val_acc=0.8033 | time=5.6s
2025-10-13 07:27:32,207 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.5939 | val_loss=0.5990 | val_acc=0.7907 | time=5.6s
2025-10-13 07:27:37,834 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.5891 | val_loss=0.5753 | val_acc=0.7981 | time=5.6s
2025-10-13 07:27:43,457 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.5874 | val_loss=0.5547 | val_acc=0.8040 | time=5.6s
2025-10-13 07:27:49,087 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.5847 | val_loss=0.5489 | val_acc=0.8105 | time=5.6s
2025-10-13 07:27:49,095 - INFO - _models.training_function_executor - Quantized model size: 50939 bytes.
2025-10-13 07:27:50,173 - INFO - _models.training_function_executor - Model: 5,308 parameters, 5.7KB storage
2025-10-13 07:27:50,174 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.942960054986244, 0.7678540460830557, 0.694991861559688, 0.6659199070129355, 0.6507015272291715, 0.6371409791330378, 0.6299278638059959, 0.6229744323659369, 0.6163828015369179, 0.6111400147856304, 0.6080277772019866, 0.6013306908812771, 0.593870167011225, 0.5890916916804169, 0.5874117502057974, 0.5847313770014463], 'val_losses': [0.7736169929516078, 0.6832657177046875, 0.6621791616285603, 0.6146669316258428, 0.6398534305787479, 0.6663595007398055, 0.6252907565581369, 0.5932603178739464, 0.5742467014281367, 0.5755277182261427, 0.5842217550250172, 0.5645693617973622, 0.5989531119323753, 0.5752709434296979, 0.5546835226573684, 0.5488630826234567], 'val_acc': [0.7055477773888694, 0.7551627581379069, 0.7572628631431572, 0.7849142457122856, 0.7726636331816591, 0.7615505775288764, 0.785526776338817, 0.7909520476023801, 0.8007525376268814, 0.7983899194959748, 0.7969023451172559, 0.8032901645082254, 0.7906895344767239, 0.7981274063703185, 0.8039901995099755, 0.8104655232761638], 'model_size_bytes': 50939, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00043655606972035254, 'batch_size': 32, 'epochs': 16, 'weight_decay': 1.338652597371245e-05, 'dropout': 0.43757314509610695, 'hidden_size': 26, 'd_model': 32, 't_pooled': 320, 'label_smoothing': 0.057158554265500615, 'use_focal_loss': True, 'focal_gamma': 0.2338310180656106, 'grad_clip_norm': 0.26363109448203254, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 5308, 'model_storage_size_kb': 5.701953125, 'model_size_validation': 'PASS'}
2025-10-13 07:27:50,174 - INFO - _models.training_function_executor - BO Objective: base=0.8105, size_penalty=0.0000, final=0.8105
2025-10-13 07:27:50,174 - INFO - _models.training_function_executor - Model: 5,308 parameters, 5.7KB (PASS 256KB limit)
2025-10-13 07:27:50,174 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 93.790s
2025-10-13 07:27:50,275 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8105
2025-10-13 07:27:50,275 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.099s
2025-10-13 07:27:50,275 - INFO - bo.run_bo - Recorded observation #27: hparams={'lr': 0.00043655606972035254, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 1.338652597371245e-05, 'dropout': 0.43757314509610695, 'hidden_size': np.int64(26), 'd_model': np.int64(32), 't_pooled': np.int64(320), 'label_smoothing': 0.057158554265500615, 'use_focal_loss': np.True_, 'focal_gamma': 0.2338310180656106, 'grad_clip_norm': 0.26363109448203254, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.8105
2025-10-13 07:27:50,275 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 27: {'lr': 0.00043655606972035254, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 1.338652597371245e-05, 'dropout': 0.43757314509610695, 'hidden_size': np.int64(26), 'd_model': np.int64(32), 't_pooled': np.int64(320), 'label_smoothing': 0.057158554265500615, 'use_focal_loss': np.True_, 'focal_gamma': 0.2338310180656106, 'grad_clip_norm': 0.26363109448203254, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.8105
2025-10-13 07:27:50,275 - INFO - bo.run_bo - üîçBO Trial 28: Using RF surrogate + Expected Improvement
2025-10-13 07:27:50,275 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:27:50,275 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 28 (NaN monitoring active)
2025-10-13 07:27:50,275 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:27:50,276 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:27:50,276 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.2330170922494898e-05, 'batch_size': 32, 'epochs': 82, 'weight_decay': 2.955883306784522e-06, 'dropout': 0.49329545691404214, 'hidden_size': 29, 'd_model': 13, 't_pooled': 320, 'label_smoothing': 0.003933458953462355, 'use_focal_loss': True, 'focal_gamma': 2.5664450873252447, 'grad_clip_norm': 1.353053107231039, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 07:27:50,277 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.2330170922494898e-05, 'batch_size': 32, 'epochs': 82, 'weight_decay': 2.955883306784522e-06, 'dropout': 0.49329545691404214, 'hidden_size': 29, 'd_model': 13, 't_pooled': 320, 'label_smoothing': 0.003933458953462355, 'use_focal_loss': True, 'focal_gamma': 2.5664450873252447, 'grad_clip_norm': 1.353053107231039, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 07:27:58,803 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8759 | val_loss=0.8391 | val_acc=0.3153 | time=8.5s
2025-10-13 07:28:04,463 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7988 | val_loss=0.7326 | val_acc=0.5216 | time=5.7s
2025-10-13 07:28:10,123 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6867 | val_loss=0.6218 | val_acc=0.5893 | time=5.7s
2025-10-13 07:28:15,789 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5970 | val_loss=0.5498 | val_acc=0.5854 | time=5.7s
2025-10-13 07:28:21,460 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.5433 | val_loss=0.4986 | val_acc=0.5916 | time=5.7s
2025-10-13 07:28:27,143 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.5055 | val_loss=0.4648 | val_acc=0.6047 | time=5.7s
2025-10-13 07:28:32,839 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4760 | val_loss=0.4293 | val_acc=0.6164 | time=5.7s
2025-10-13 07:28:38,528 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4496 | val_loss=0.3993 | val_acc=0.6221 | time=5.7s
2025-10-13 07:28:44,223 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4269 | val_loss=0.3766 | val_acc=0.6375 | time=5.7s
2025-10-13 07:28:49,925 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4100 | val_loss=0.3650 | val_acc=0.6516 | time=5.7s
2025-10-13 07:28:55,605 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3998 | val_loss=0.3493 | val_acc=0.6547 | time=5.7s
2025-10-13 07:29:01,296 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3883 | val_loss=0.3535 | val_acc=0.6348 | time=5.7s
2025-10-13 07:29:06,992 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3778 | val_loss=0.3342 | val_acc=0.6714 | time=5.7s
2025-10-13 07:29:12,695 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3738 | val_loss=0.3283 | val_acc=0.6751 | time=5.7s
2025-10-13 07:29:18,393 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3694 | val_loss=0.3245 | val_acc=0.6717 | time=5.7s
2025-10-13 07:29:24,081 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3616 | val_loss=0.3197 | val_acc=0.6790 | time=5.7s
2025-10-13 07:29:29,784 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3611 | val_loss=0.3170 | val_acc=0.6796 | time=5.7s
2025-10-13 07:29:35,478 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3582 | val_loss=0.3167 | val_acc=0.6762 | time=5.7s
2025-10-13 07:29:41,170 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3539 | val_loss=0.3114 | val_acc=0.6843 | time=5.7s
2025-10-13 07:29:46,879 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3510 | val_loss=0.3092 | val_acc=0.6890 | time=5.7s
2025-10-13 07:29:52,581 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3451 | val_loss=0.3077 | val_acc=0.6873 | time=5.7s
2025-10-13 07:29:58,277 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3439 | val_loss=0.3103 | val_acc=0.6845 | time=5.7s
2025-10-13 07:30:03,961 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3438 | val_loss=0.3031 | val_acc=0.6963 | time=5.7s
2025-10-13 07:30:09,644 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3418 | val_loss=0.3047 | val_acc=0.6894 | time=5.7s
2025-10-13 07:30:15,331 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3374 | val_loss=0.3027 | val_acc=0.7048 | time=5.7s
2025-10-13 07:30:21,019 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.3356 | val_loss=0.2968 | val_acc=0.7029 | time=5.7s
2025-10-13 07:30:26,715 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.3354 | val_loss=0.3017 | val_acc=0.6926 | time=5.7s
2025-10-13 07:30:32,405 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.3282 | val_loss=0.2953 | val_acc=0.7055 | time=5.7s
2025-10-13 07:30:38,097 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.3274 | val_loss=0.2934 | val_acc=0.7048 | time=5.7s
2025-10-13 07:30:43,786 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.3272 | val_loss=0.2909 | val_acc=0.7114 | time=5.7s
2025-10-13 07:30:49,473 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.3267 | val_loss=0.2892 | val_acc=0.7089 | time=5.7s
2025-10-13 07:30:55,170 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.3244 | val_loss=0.2917 | val_acc=0.7149 | time=5.7s
2025-10-13 07:31:00,885 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.3200 | val_loss=0.2876 | val_acc=0.7161 | time=5.7s
2025-10-13 07:31:06,583 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.3169 | val_loss=0.2836 | val_acc=0.7188 | time=5.7s
2025-10-13 07:31:12,268 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.3154 | val_loss=0.2864 | val_acc=0.7130 | time=5.7s
2025-10-13 07:31:17,958 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.3142 | val_loss=0.2812 | val_acc=0.7185 | time=5.7s
2025-10-13 07:31:23,635 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.3147 | val_loss=0.2804 | val_acc=0.7233 | time=5.7s
2025-10-13 07:31:29,329 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.3089 | val_loss=0.2790 | val_acc=0.7230 | time=5.7s
2025-10-13 07:31:35,012 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.3098 | val_loss=0.2778 | val_acc=0.7251 | time=5.7s
2025-10-13 07:31:40,694 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.3066 | val_loss=0.2746 | val_acc=0.7282 | time=5.7s
2025-10-13 07:31:46,387 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.3045 | val_loss=0.2752 | val_acc=0.7272 | time=5.7s
2025-10-13 07:31:52,092 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.3007 | val_loss=0.2761 | val_acc=0.7285 | time=5.7s
2025-10-13 07:31:57,794 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.3026 | val_loss=0.2773 | val_acc=0.7251 | time=5.7s
2025-10-13 07:32:03,498 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.2996 | val_loss=0.2712 | val_acc=0.7316 | time=5.7s
2025-10-13 07:32:09,189 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.2984 | val_loss=0.2680 | val_acc=0.7335 | time=5.7s
2025-10-13 07:32:14,884 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.2930 | val_loss=0.2713 | val_acc=0.7347 | time=5.7s
2025-10-13 07:32:20,590 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.2949 | val_loss=0.2655 | val_acc=0.7373 | time=5.7s
2025-10-13 07:32:26,290 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.2931 | val_loss=0.2638 | val_acc=0.7359 | time=5.7s
2025-10-13 07:32:31,984 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.2885 | val_loss=0.2631 | val_acc=0.7375 | time=5.7s
2025-10-13 07:32:37,671 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.2870 | val_loss=0.2606 | val_acc=0.7379 | time=5.7s
2025-10-13 07:32:43,360 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.2849 | val_loss=0.2595 | val_acc=0.7381 | time=5.7s
2025-10-13 07:32:49,054 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.2831 | val_loss=0.2555 | val_acc=0.7439 | time=5.7s
2025-10-13 07:32:54,742 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.2816 | val_loss=0.2611 | val_acc=0.7393 | time=5.7s
2025-10-13 07:33:00,436 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.2786 | val_loss=0.2525 | val_acc=0.7433 | time=5.7s
2025-10-13 07:33:06,134 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.2787 | val_loss=0.2510 | val_acc=0.7447 | time=5.7s
2025-10-13 07:33:11,825 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.2754 | val_loss=0.2547 | val_acc=0.7426 | time=5.7s
2025-10-13 07:33:17,516 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.2751 | val_loss=0.2496 | val_acc=0.7466 | time=5.7s
2025-10-13 07:33:23,210 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.2723 | val_loss=0.2448 | val_acc=0.7483 | time=5.7s
2025-10-13 07:33:28,901 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.2723 | val_loss=0.2451 | val_acc=0.7451 | time=5.7s
2025-10-13 07:33:34,591 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.2677 | val_loss=0.2424 | val_acc=0.7496 | time=5.7s
2025-10-13 07:33:40,286 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.2695 | val_loss=0.2403 | val_acc=0.7508 | time=5.7s
2025-10-13 07:33:45,975 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.2670 | val_loss=0.2388 | val_acc=0.7510 | time=5.7s
2025-10-13 07:33:51,670 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.2645 | val_loss=0.2413 | val_acc=0.7509 | time=5.7s
2025-10-13 07:33:57,364 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.2646 | val_loss=0.2362 | val_acc=0.7546 | time=5.7s
2025-10-13 07:34:03,069 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.2622 | val_loss=0.2341 | val_acc=0.7556 | time=5.7s
2025-10-13 07:34:08,759 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.2588 | val_loss=0.2366 | val_acc=0.7553 | time=5.7s
2025-10-13 07:34:14,447 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.2599 | val_loss=0.2342 | val_acc=0.7544 | time=5.7s
2025-10-13 07:34:20,130 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.2562 | val_loss=0.2323 | val_acc=0.7560 | time=5.7s
2025-10-13 07:34:25,818 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.2563 | val_loss=0.2290 | val_acc=0.7570 | time=5.7s
2025-10-13 07:34:31,499 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.2574 | val_loss=0.2284 | val_acc=0.7585 | time=5.7s
2025-10-13 07:34:37,202 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.2539 | val_loss=0.2278 | val_acc=0.7579 | time=5.7s
2025-10-13 07:34:42,894 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.2522 | val_loss=0.2272 | val_acc=0.7582 | time=5.7s
2025-10-13 07:34:48,590 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.2543 | val_loss=0.2253 | val_acc=0.7604 | time=5.7s
2025-10-13 07:34:54,279 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.2507 | val_loss=0.2280 | val_acc=0.7572 | time=5.7s
2025-10-13 07:34:59,971 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.2510 | val_loss=0.2242 | val_acc=0.7611 | time=5.7s
2025-10-13 07:35:05,669 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.2493 | val_loss=0.2267 | val_acc=0.7599 | time=5.7s
2025-10-13 07:35:11,367 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.2493 | val_loss=0.2235 | val_acc=0.7615 | time=5.7s
2025-10-13 07:35:17,069 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.2492 | val_loss=0.2217 | val_acc=0.7629 | time=5.7s
2025-10-13 07:35:22,765 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.2466 | val_loss=0.2221 | val_acc=0.7617 | time=5.7s
2025-10-13 07:35:28,468 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.2458 | val_loss=0.2215 | val_acc=0.7628 | time=5.7s
2025-10-13 07:35:34,171 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.2492 | val_loss=0.2206 | val_acc=0.7602 | time=5.7s
2025-10-13 07:35:39,872 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.2463 | val_loss=0.2226 | val_acc=0.7614 | time=5.7s
2025-10-13 07:35:39,875 - INFO - _models.training_function_executor - Quantized model size: 66241 bytes.
2025-10-13 07:35:40,969 - INFO - _models.training_function_executor - Model: 12,307 parameters, 52.9KB storage
2025-10-13 07:35:40,969 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8759342663597719, 0.7987836136824609, 0.6866529823434407, 0.5969951329091066, 0.5433178487506662, 0.5055158651079545, 0.47603545751778614, 0.44964328040015167, 0.4268948345969597, 0.4100059397703791, 0.3997645298417398, 0.3882938873884684, 0.3778375275159241, 0.373819477639709, 0.3693709441277795, 0.3615657899673477, 0.3610643025332495, 0.3581889769415109, 0.35392026892691425, 0.35104043236720134, 0.3450873683894227, 0.3438769514468069, 0.3437946513477722, 0.3417986858900836, 0.3373988915207422, 0.33562146433383633, 0.33540900204412827, 0.32824419957797846, 0.3273514939284967, 0.3272216071250516, 0.32670190317004055, 0.3243796820662678, 0.3199977853475937, 0.3168983760051557, 0.31540543498131707, 0.31417266273982547, 0.31466060397526496, 0.30888940471638154, 0.30982808278998086, 0.3065752463195555, 0.3045180319780063, 0.3007014150130486, 0.3025613397172084, 0.2995953515229377, 0.29835911315765085, 0.2930384498137797, 0.29490371434409846, 0.29306944795826495, 0.2884548523958471, 0.2870108088413902, 0.28494453845342893, 0.2830772929083938, 0.2816360958043119, 0.27863466008939564, 0.2787199716938097, 0.2753878819815212, 0.27505442779674205, 0.2723147723280053, 0.27232364219596095, 0.2676750325607928, 0.26947147364763685, 0.267039789117046, 0.2644930822024364, 0.26461289297316015, 0.26219994272537317, 0.25878131009395783, 0.25992966150440533, 0.2561979477727668, 0.25632462923056104, 0.2573532699067817, 0.25392290212847696, 0.25223811854838823, 0.25426686274283494, 0.2507420693519944, 0.2510439853151653, 0.24929540370951844, 0.2492615322904817, 0.24921781475054955, 0.24658883234442303, 0.24577980460634924, 0.24918539259591885, 0.24629607173918341], 'val_losses': [0.8391293834713651, 0.7325582068034057, 0.6217606101246368, 0.5498086110586714, 0.4985540780021379, 0.4648497768494897, 0.42926579902628564, 0.399297004464543, 0.3766346833152624, 0.3650174305953886, 0.3492993619064789, 0.3535008015939728, 0.3342401787435253, 0.3282853708343986, 0.324525441527158, 0.31966549152880647, 0.3170159497292759, 0.31668259340606036, 0.3114278991144355, 0.30916727991174225, 0.3077424472138562, 0.3102747537756367, 0.3031049993255566, 0.3047000335351462, 0.3026949642085929, 0.2967628225981459, 0.3016587803632511, 0.29526549982448785, 0.29338521197683376, 0.2908932730675495, 0.28915951215578284, 0.2916828352471603, 0.2876495376599599, 0.2835557174027529, 0.2864080926662231, 0.28123470234900116, 0.28038623809063395, 0.2790456467996246, 0.27781788672564706, 0.2746059767664585, 0.2752144236298846, 0.27608835816612853, 0.27730242833416907, 0.271216904945961, 0.2679528852349025, 0.2713381150801949, 0.2654953606695323, 0.26381433274535643, 0.2630736315671823, 0.26057585075075157, 0.25953358245930724, 0.25553604499898175, 0.26106569297692556, 0.2525283366984156, 0.25099100420263876, 0.25466881764385724, 0.2496130347283186, 0.24480403138283546, 0.2451173603107014, 0.24243385239126466, 0.24026743674929174, 0.2387956137585398, 0.2412982796053808, 0.23619026846409177, 0.23411909440492557, 0.23658050744838968, 0.23418106478246142, 0.23226084816505913, 0.22900381769840225, 0.2284381363070174, 0.22781662624179377, 0.22722290442212711, 0.2252679635302187, 0.22798306894210574, 0.22416621204602538, 0.22672295361746847, 0.22347339284161316, 0.22170457623619944, 0.2221037577374815, 0.22146155187872518, 0.22059638708266588, 0.22258412095792734], 'val_acc': [0.31527826391319563, 0.521613580679034, 0.589341967098355, 0.5854042702135107, 0.5916170808540427, 0.6046552327616381, 0.6163808190409521, 0.6220686034301716, 0.6374693734686734, 0.6515575778788939, 0.6547077353867693, 0.6348442422121106, 0.6714210710535526, 0.6750962548127406, 0.6716835841792089, 0.6790339516975848, 0.6796464823241162, 0.6762338116905845, 0.6842842142107105, 0.6890094504725236, 0.6873468673433671, 0.684459222961148, 0.6962723136156808, 0.6893594679733986, 0.7048477423871193, 0.7029226461323066, 0.6925971298564928, 0.7055477773888694, 0.7047602380119006, 0.7114105705285264, 0.7088729436471823, 0.7149107455372768, 0.7161358067903395, 0.7188484424221211, 0.7129856492824641, 0.718498424921246, 0.7233111655582779, 0.7229611480574029, 0.7251487574378719, 0.7282114105705285, 0.7271613580679034, 0.7284739236961848, 0.7251487574378719, 0.7316240812040602, 0.7334616730836542, 0.7346867343367168, 0.7373118655932797, 0.7359117955897795, 0.7374868743437172, 0.737924396219811, 0.7380994049702485, 0.7438746937346867, 0.7393244662233112, 0.7433496674833742, 0.7446622331116556, 0.7426496324816241, 0.7465873293664683, 0.7483374168708435, 0.7450997549877494, 0.749649982499125, 0.7507875393769688, 0.7509625481274064, 0.7508750437521876, 0.7546377318865943, 0.7556002800140007, 0.7552502625131257, 0.754375218760938, 0.7559502975148757, 0.7570003500175009, 0.7584879243962198, 0.7578753937696885, 0.7582254112705635, 0.7604130206510326, 0.7571753587679384, 0.7611130556527826, 0.75988799439972, 0.7614630731536577, 0.7628631431571579, 0.761725586279314, 0.7627756387819391, 0.760238011900595, 0.7613755687784389], 'model_size_bytes': 66241, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.2330170922494898e-05, 'batch_size': 32, 'epochs': 82, 'weight_decay': 2.955883306784522e-06, 'dropout': 0.49329545691404214, 'hidden_size': 29, 'd_model': 13, 't_pooled': 320, 'label_smoothing': 0.003933458953462355, 'use_focal_loss': True, 'focal_gamma': 2.5664450873252447, 'grad_clip_norm': 1.353053107231039, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 12307, 'model_storage_size_kb': 52.881640625, 'model_size_validation': 'PASS'}
2025-10-13 07:35:40,969 - INFO - _models.training_function_executor - BO Objective: base=0.7614, size_penalty=0.0000, final=0.7614
2025-10-13 07:35:40,969 - INFO - _models.training_function_executor - Model: 12,307 parameters, 52.9KB (PASS 256KB limit)
2025-10-13 07:35:40,969 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 470.694s
2025-10-13 07:35:41,076 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7614
2025-10-13 07:35:41,076 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-13 07:35:41,076 - INFO - bo.run_bo - Recorded observation #28: hparams={'lr': 1.2330170922494898e-05, 'batch_size': np.int64(32), 'epochs': np.int64(82), 'weight_decay': 2.955883306784522e-06, 'dropout': 0.49329545691404214, 'hidden_size': np.int64(29), 'd_model': np.int64(13), 't_pooled': np.int64(320), 'label_smoothing': 0.003933458953462355, 'use_focal_loss': np.True_, 'focal_gamma': 2.5664450873252447, 'grad_clip_norm': 1.353053107231039, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.7614
2025-10-13 07:35:41,076 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 28: {'lr': 1.2330170922494898e-05, 'batch_size': np.int64(32), 'epochs': np.int64(82), 'weight_decay': 2.955883306784522e-06, 'dropout': 0.49329545691404214, 'hidden_size': np.int64(29), 'd_model': np.int64(13), 't_pooled': np.int64(320), 'label_smoothing': 0.003933458953462355, 'use_focal_loss': np.True_, 'focal_gamma': 2.5664450873252447, 'grad_clip_norm': 1.353053107231039, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.7614
2025-10-13 07:35:41,076 - INFO - bo.run_bo - üîçBO Trial 29: Using RF surrogate + Expected Improvement
2025-10-13 07:35:41,077 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:35:41,077 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 29 (NaN monitoring active)
2025-10-13 07:35:41,077 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:35:41,077 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:35:41,077 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.7410953156036948e-05, 'batch_size': 32, 'epochs': 21, 'weight_decay': 0.0026194333722354113, 'dropout': 0.35936519157465935, 'hidden_size': 30, 'd_model': 31, 't_pooled': 320, 'label_smoothing': 0.10993632394047614, 'use_focal_loss': True, 'focal_gamma': 2.5974120285227347, 'grad_clip_norm': 2.0073301749857864, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:35:41,078 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.7410953156036948e-05, 'batch_size': 32, 'epochs': 21, 'weight_decay': 0.0026194333722354113, 'dropout': 0.35936519157465935, 'hidden_size': 30, 'd_model': 31, 't_pooled': 320, 'label_smoothing': 0.10993632394047614, 'use_focal_loss': True, 'focal_gamma': 2.5974120285227347, 'grad_clip_norm': 2.0073301749857864, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:35:49,611 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.8560 | val_loss=0.8212 | val_acc=0.3137 | time=8.5s
2025-10-13 07:35:55,321 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7839 | val_loss=0.7096 | val_acc=0.5367 | time=5.7s
2025-10-13 07:36:01,027 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6295 | val_loss=0.5317 | val_acc=0.6053 | time=5.7s
2025-10-13 07:36:06,759 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.5148 | val_loss=0.4561 | val_acc=0.6257 | time=5.7s
2025-10-13 07:36:12,495 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4695 | val_loss=0.4229 | val_acc=0.6371 | time=5.7s
2025-10-13 07:36:18,230 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4461 | val_loss=0.4096 | val_acc=0.6406 | time=5.7s
2025-10-13 07:36:23,957 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4304 | val_loss=0.3921 | val_acc=0.6558 | time=5.7s
2025-10-13 07:36:29,679 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4213 | val_loss=0.3861 | val_acc=0.6558 | time=5.7s
2025-10-13 07:36:35,406 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4126 | val_loss=0.3759 | val_acc=0.6665 | time=5.7s
2025-10-13 07:36:41,139 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.4084 | val_loss=0.3707 | val_acc=0.6736 | time=5.7s
2025-10-13 07:36:46,869 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3994 | val_loss=0.3704 | val_acc=0.6628 | time=5.7s
2025-10-13 07:36:52,598 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3919 | val_loss=0.3591 | val_acc=0.6831 | time=5.7s
2025-10-13 07:36:58,330 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3883 | val_loss=0.3534 | val_acc=0.6806 | time=5.7s
2025-10-13 07:37:04,053 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3844 | val_loss=0.3519 | val_acc=0.6850 | time=5.7s
2025-10-13 07:37:09,782 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3778 | val_loss=0.3429 | val_acc=0.6880 | time=5.7s
2025-10-13 07:37:15,516 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3715 | val_loss=0.3382 | val_acc=0.6943 | time=5.7s
2025-10-13 07:37:21,255 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3666 | val_loss=0.3343 | val_acc=0.6933 | time=5.7s
2025-10-13 07:37:26,982 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3634 | val_loss=0.3313 | val_acc=0.7014 | time=5.7s
2025-10-13 07:37:32,714 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3592 | val_loss=0.3256 | val_acc=0.7028 | time=5.7s
2025-10-13 07:37:38,443 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3529 | val_loss=0.3255 | val_acc=0.6985 | time=5.7s
2025-10-13 07:37:44,173 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3493 | val_loss=0.3180 | val_acc=0.7094 | time=5.7s
2025-10-13 07:37:44,180 - INFO - _models.training_function_executor - Quantized model size: 52283 bytes.
2025-10-13 07:37:45,296 - INFO - _models.training_function_executor - Model: 5,202 parameters, 5.6KB storage
2025-10-13 07:37:45,296 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.8559669911298128, 0.7838573523405594, 0.6295293066983128, 0.5148383141982626, 0.46946801707842234, 0.4460714007429531, 0.4304308148794004, 0.42128011127389475, 0.4126314997026292, 0.4084023690156933, 0.39940031697418793, 0.39192580434046803, 0.38827211461703093, 0.3844000566744245, 0.3777686455448399, 0.3714814835968325, 0.3666254248304471, 0.36341905890121967, 0.3592218706605315, 0.3528911186695767, 0.3492804213779391], 'val_losses': [0.8212358605874182, 0.7096315033585199, 0.5317262099220655, 0.4561139260466632, 0.42288423379401374, 0.4095756173926631, 0.3920893756751627, 0.3860683149293373, 0.3759125952416882, 0.370680076553557, 0.3703686610192822, 0.3591066485190667, 0.3533607351642244, 0.3518725091817707, 0.3428756415447573, 0.33817342981450993, 0.33431688479956606, 0.331303969729727, 0.32559469400647223, 0.3255211813782828, 0.31803798713089915], 'val_acc': [0.31370318515925794, 0.5366643332166608, 0.6052677633881695, 0.6256562828141407, 0.6371193559677983, 0.6406195309765488, 0.6557577878893944, 0.6558452922646132, 0.666520826041302, 0.6736086804340217, 0.6627581379068953, 0.6830591529576479, 0.6806090304515225, 0.6849842492124606, 0.6879593979698985, 0.694347217360868, 0.6932971648582429, 0.7014350717535877, 0.7028351417570878, 0.6985474273713685, 0.7093979698984949], 'model_size_bytes': 52283, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.7410953156036948e-05, 'batch_size': 32, 'epochs': 21, 'weight_decay': 0.0026194333722354113, 'dropout': 0.35936519157465935, 'hidden_size': 30, 'd_model': 31, 't_pooled': 320, 'label_smoothing': 0.10993632394047614, 'use_focal_loss': True, 'focal_gamma': 2.5974120285227347, 'grad_clip_norm': 2.0073301749857864, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 5202, 'model_storage_size_kb': 5.588085937500001, 'model_size_validation': 'PASS'}
2025-10-13 07:37:45,296 - INFO - _models.training_function_executor - BO Objective: base=0.7094, size_penalty=0.0000, final=0.7094
2025-10-13 07:37:45,296 - INFO - _models.training_function_executor - Model: 5,202 parameters, 5.6KB (PASS 256KB limit)
2025-10-13 07:37:45,296 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 124.220s
2025-10-13 07:37:45,518 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7094
2025-10-13 07:37:45,518 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.219s
2025-10-13 07:37:45,519 - INFO - bo.run_bo - Recorded observation #29: hparams={'lr': 1.7410953156036948e-05, 'batch_size': np.int64(32), 'epochs': np.int64(21), 'weight_decay': 0.0026194333722354113, 'dropout': 0.35936519157465935, 'hidden_size': np.int64(30), 'd_model': np.int64(31), 't_pooled': np.int64(320), 'label_smoothing': 0.10993632394047614, 'use_focal_loss': np.True_, 'focal_gamma': 2.5974120285227347, 'grad_clip_norm': 2.0073301749857864, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7094
2025-10-13 07:37:45,519 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 29: {'lr': 1.7410953156036948e-05, 'batch_size': np.int64(32), 'epochs': np.int64(21), 'weight_decay': 0.0026194333722354113, 'dropout': 0.35936519157465935, 'hidden_size': np.int64(30), 'd_model': np.int64(31), 't_pooled': np.int64(320), 'label_smoothing': 0.10993632394047614, 'use_focal_loss': np.True_, 'focal_gamma': 2.5974120285227347, 'grad_clip_norm': 2.0073301749857864, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7094
2025-10-13 07:37:45,519 - INFO - bo.run_bo - üîçBO Trial 30: Using RF surrogate + Expected Improvement
2025-10-13 07:37:45,519 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:37:45,519 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 30 (NaN monitoring active)
2025-10-13 07:37:45,519 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:37:45,519 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:37:45,519 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.004312892312531868, 'batch_size': 32, 'epochs': 22, 'weight_decay': 1.537664823013164e-05, 'dropout': 0.49953567623473166, 'hidden_size': 31, 'd_model': 22, 't_pooled': 320, 'label_smoothing': 0.11191307563209474, 'use_focal_loss': True, 'focal_gamma': 1.5761228487084287, 'grad_clip_norm': 0.9366759034183493, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:37:45,520 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.004312892312531868, 'batch_size': 32, 'epochs': 22, 'weight_decay': 1.537664823013164e-05, 'dropout': 0.49953567623473166, 'hidden_size': 31, 'd_model': 22, 't_pooled': 320, 'label_smoothing': 0.11191307563209474, 'use_focal_loss': True, 'focal_gamma': 1.5761228487084287, 'grad_clip_norm': 0.9366759034183493, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:37:54,022 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.5553 | val_loss=0.6154 | val_acc=0.6124 | time=8.5s
2025-10-13 07:37:59,762 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.4339 | val_loss=0.4226 | val_acc=0.7426 | time=5.7s
2025-10-13 07:38:05,521 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.4004 | val_loss=0.3784 | val_acc=0.7602 | time=5.8s
2025-10-13 07:38:11,269 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.3814 | val_loss=0.3381 | val_acc=0.7783 | time=5.7s
2025-10-13 07:38:17,024 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.3700 | val_loss=0.3475 | val_acc=0.7797 | time=5.8s
2025-10-13 07:38:22,790 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.3622 | val_loss=0.3626 | val_acc=0.7730 | time=5.8s
2025-10-13 07:38:28,557 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.3526 | val_loss=0.3223 | val_acc=0.7907 | time=5.8s
2025-10-13 07:38:34,301 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.3454 | val_loss=0.3338 | val_acc=0.7788 | time=5.7s
2025-10-13 07:38:40,041 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3421 | val_loss=0.3267 | val_acc=0.7941 | time=5.7s
2025-10-13 07:38:45,817 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3356 | val_loss=0.3632 | val_acc=0.7714 | time=5.8s
2025-10-13 07:38:51,581 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3313 | val_loss=0.3559 | val_acc=0.7757 | time=5.8s
2025-10-13 07:38:57,336 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3252 | val_loss=0.3285 | val_acc=0.7840 | time=5.8s
2025-10-13 07:39:03,079 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3217 | val_loss=0.3466 | val_acc=0.7734 | time=5.7s
2025-10-13 07:39:08,834 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3202 | val_loss=0.3827 | val_acc=0.7642 | time=5.8s
2025-10-13 07:39:14,607 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3171 | val_loss=0.3050 | val_acc=0.7966 | time=5.8s
2025-10-13 07:39:20,353 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3133 | val_loss=0.2975 | val_acc=0.8017 | time=5.7s
2025-10-13 07:39:26,089 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3129 | val_loss=0.2939 | val_acc=0.8056 | time=5.7s
2025-10-13 07:39:31,830 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3104 | val_loss=0.3008 | val_acc=0.8035 | time=5.7s
2025-10-13 07:39:37,603 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3094 | val_loss=0.3506 | val_acc=0.7818 | time=5.8s
2025-10-13 07:39:43,350 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3070 | val_loss=0.3078 | val_acc=0.7999 | time=5.7s
2025-10-13 07:39:49,094 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3080 | val_loss=0.2993 | val_acc=0.8021 | time=5.7s
2025-10-13 07:39:54,843 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3062 | val_loss=0.3107 | val_acc=0.7975 | time=5.7s
2025-10-13 07:39:54,850 - INFO - _models.training_function_executor - Quantized model size: 49403 bytes.
2025-10-13 07:39:55,958 - INFO - _models.training_function_executor - Model: 4,743 parameters, 5.1KB storage
2025-10-13 07:39:55,958 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.5552548676218066, 0.43386676395360846, 0.4003899901385569, 0.3814108913277345, 0.3700059427689705, 0.3621686451296144, 0.35258756468961155, 0.3453989591857625, 0.34210344561756095, 0.3355834595350523, 0.331266954468187, 0.325215513316284, 0.32173915007625964, 0.3201526457304966, 0.3171162865703908, 0.3133234871922359, 0.3128850190924063, 0.3104372467554905, 0.3094438728874782, 0.30695336755648084, 0.3080036881287531, 0.30619418914183727], 'val_losses': [0.6154356017828738, 0.4225806037696208, 0.37843110338557545, 0.3380817069763648, 0.3475299248505106, 0.3626461882127262, 0.3222642564715144, 0.3338355375391894, 0.3267089043426731, 0.3632187085381996, 0.3558970593335873, 0.3285239687385699, 0.3466365834842164, 0.3827476718123659, 0.30502012676351087, 0.2974664622361651, 0.29388082557868656, 0.3008454289883219, 0.3505608516298352, 0.30777327557272705, 0.29925733044780045, 0.3106732740763563], 'val_acc': [0.6123556177808891, 0.7425621281064053, 0.760238011900595, 0.7782639131956598, 0.77966398319916, 0.7730136506825341, 0.7906895344767239, 0.7787889394469724, 0.7941022051102555, 0.7714385719285964, 0.7757262863143157, 0.784039201960098, 0.7733636681834092, 0.7641757087854393, 0.7966398319915996, 0.8017150857542877, 0.8055652782639132, 0.803465173258663, 0.7817640882044102, 0.7998774938746938, 0.8020651032551628, 0.7975148757437872], 'model_size_bytes': 49403, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.004312892312531868, 'batch_size': 32, 'epochs': 22, 'weight_decay': 1.537664823013164e-05, 'dropout': 0.49953567623473166, 'hidden_size': 31, 'd_model': 22, 't_pooled': 320, 'label_smoothing': 0.11191307563209474, 'use_focal_loss': True, 'focal_gamma': 1.5761228487084287, 'grad_clip_norm': 0.9366759034183493, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 4743, 'model_storage_size_kb': 5.09501953125, 'model_size_validation': 'PASS'}
2025-10-13 07:39:55,958 - INFO - _models.training_function_executor - BO Objective: base=0.7975, size_penalty=0.0000, final=0.7975
2025-10-13 07:39:55,958 - INFO - _models.training_function_executor - Model: 4,743 parameters, 5.1KB (PASS 256KB limit)
2025-10-13 07:39:55,958 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 130.439s
2025-10-13 07:39:56,063 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7975
2025-10-13 07:39:56,063 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-13 07:39:56,063 - INFO - bo.run_bo - Recorded observation #30: hparams={'lr': 0.004312892312531868, 'batch_size': np.int64(32), 'epochs': np.int64(22), 'weight_decay': 1.537664823013164e-05, 'dropout': 0.49953567623473166, 'hidden_size': np.int64(31), 'd_model': np.int64(22), 't_pooled': np.int64(320), 'label_smoothing': 0.11191307563209474, 'use_focal_loss': np.True_, 'focal_gamma': 1.5761228487084287, 'grad_clip_norm': 0.9366759034183493, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7975
2025-10-13 07:39:56,063 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 30: {'lr': 0.004312892312531868, 'batch_size': np.int64(32), 'epochs': np.int64(22), 'weight_decay': 1.537664823013164e-05, 'dropout': 0.49953567623473166, 'hidden_size': np.int64(31), 'd_model': np.int64(22), 't_pooled': np.int64(320), 'label_smoothing': 0.11191307563209474, 'use_focal_loss': np.True_, 'focal_gamma': 1.5761228487084287, 'grad_clip_norm': 0.9366759034183493, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7975
2025-10-13 07:39:56,064 - INFO - bo.run_bo - üîçBO Trial 31: Using RF surrogate + Expected Improvement
2025-10-13 07:39:56,064 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:39:56,064 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 31 (NaN monitoring active)
2025-10-13 07:39:56,064 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:39:56,064 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:39:56,064 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00017652317169403894, 'batch_size': 32, 'epochs': 16, 'weight_decay': 0.00013926218774029837, 'dropout': 0.09422305794950123, 'hidden_size': 28, 'd_model': 29, 't_pooled': 320, 'label_smoothing': 0.07662655856613707, 'use_focal_loss': True, 'focal_gamma': 1.229342803728631, 'grad_clip_norm': 0.10324151619461876, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 07:39:56,065 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00017652317169403894, 'batch_size': 32, 'epochs': 16, 'weight_decay': 0.00013926218774029837, 'dropout': 0.09422305794950123, 'hidden_size': 28, 'd_model': 29, 't_pooled': 320, 'label_smoothing': 0.07662655856613707, 'use_focal_loss': True, 'focal_gamma': 1.229342803728631, 'grad_clip_norm': 0.10324151619461876, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 07:40:04,584 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.7504 | val_loss=0.5842 | val_acc=0.6565 | time=8.5s
2025-10-13 07:40:10,255 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.5667 | val_loss=0.5185 | val_acc=0.7004 | time=5.7s
2025-10-13 07:40:15,925 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5239 | val_loss=0.4907 | val_acc=0.7140 | time=5.7s
2025-10-13 07:40:21,602 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4949 | val_loss=0.4573 | val_acc=0.7430 | time=5.7s
2025-10-13 07:40:27,278 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4627 | val_loss=0.4422 | val_acc=0.7511 | time=5.7s
2025-10-13 07:40:32,975 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4389 | val_loss=0.4089 | val_acc=0.7671 | time=5.7s
2025-10-13 07:40:38,654 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4156 | val_loss=0.3969 | val_acc=0.7725 | time=5.7s
2025-10-13 07:40:44,349 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4084 | val_loss=0.4102 | val_acc=0.7636 | time=5.7s
2025-10-13 07:40:50,026 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.4022 | val_loss=0.3737 | val_acc=0.7861 | time=5.7s
2025-10-13 07:40:55,707 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3901 | val_loss=0.3790 | val_acc=0.7802 | time=5.7s
2025-10-13 07:41:01,392 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3881 | val_loss=0.3739 | val_acc=0.7864 | time=5.7s
2025-10-13 07:41:07,066 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3823 | val_loss=0.3736 | val_acc=0.7848 | time=5.7s
2025-10-13 07:41:12,745 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3770 | val_loss=0.3681 | val_acc=0.7889 | time=5.7s
2025-10-13 07:41:18,430 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3750 | val_loss=0.3640 | val_acc=0.7897 | time=5.7s
2025-10-13 07:41:24,107 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3712 | val_loss=0.3510 | val_acc=0.7993 | time=5.7s
2025-10-13 07:41:29,776 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3694 | val_loss=0.3595 | val_acc=0.7914 | time=5.7s
2025-10-13 07:41:29,779 - INFO - _models.training_function_executor - Quantized model size: 78529 bytes.
2025-10-13 07:41:30,877 - INFO - _models.training_function_executor - Model: 15,317 parameters, 65.8KB storage
2025-10-13 07:41:30,877 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.7503510618860754, 0.5667130084650309, 0.5238663221849276, 0.4949231970798398, 0.4626906563925251, 0.43885293209682114, 0.41561650829295155, 0.4083827583782315, 0.4022191214236005, 0.39012663308394135, 0.3881490826189497, 0.38231152141682534, 0.37697450662769133, 0.3749897218914686, 0.37119859358439883, 0.3694370401085028], 'val_losses': [0.5841773803266647, 0.5184907313719219, 0.49069332296213236, 0.4572637811131022, 0.4421726252373841, 0.4089437053050868, 0.39694308884126306, 0.410190677336141, 0.37371906598506377, 0.3789739660712694, 0.3739493702690544, 0.3736095627496657, 0.3681044297740724, 0.3640051390225962, 0.35095413492866695, 0.35946756922618717], 'val_acc': [0.6564578228911445, 0.7003850192509625, 0.7140357017850892, 0.7429996499824991, 0.7510500525026251, 0.7670633531676584, 0.7724886244312216, 0.763563178158908, 0.7860518025901295, 0.7801890094504725, 0.7864018200910046, 0.7848267413370669, 0.7888519425971299, 0.7897269863493175, 0.7992649632481624, 0.7913895694784739], 'model_size_bytes': 78529, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00017652317169403894, 'batch_size': 32, 'epochs': 16, 'weight_decay': 0.00013926218774029837, 'dropout': 0.09422305794950123, 'hidden_size': 28, 'd_model': 29, 't_pooled': 320, 'label_smoothing': 0.07662655856613707, 'use_focal_loss': True, 'focal_gamma': 1.229342803728631, 'grad_clip_norm': 0.10324151619461876, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 15317, 'model_storage_size_kb': 65.815234375, 'model_size_validation': 'PASS'}
2025-10-13 07:41:30,877 - INFO - _models.training_function_executor - BO Objective: base=0.7914, size_penalty=0.0000, final=0.7914
2025-10-13 07:41:30,877 - INFO - _models.training_function_executor - Model: 15,317 parameters, 65.8KB (PASS 256KB limit)
2025-10-13 07:41:30,877 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 94.814s
2025-10-13 07:41:30,983 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7914
2025-10-13 07:41:30,983 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.103s
2025-10-13 07:41:30,983 - INFO - bo.run_bo - Recorded observation #31: hparams={'lr': 0.00017652317169403894, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 0.00013926218774029837, 'dropout': 0.09422305794950123, 'hidden_size': np.int64(28), 'd_model': np.int64(29), 't_pooled': np.int64(320), 'label_smoothing': 0.07662655856613707, 'use_focal_loss': np.True_, 'focal_gamma': 1.229342803728631, 'grad_clip_norm': 0.10324151619461876, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7914
2025-10-13 07:41:30,983 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 31: {'lr': 0.00017652317169403894, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 0.00013926218774029837, 'dropout': 0.09422305794950123, 'hidden_size': np.int64(28), 'd_model': np.int64(29), 't_pooled': np.int64(320), 'label_smoothing': 0.07662655856613707, 'use_focal_loss': np.True_, 'focal_gamma': 1.229342803728631, 'grad_clip_norm': 0.10324151619461876, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7914
2025-10-13 07:41:30,983 - INFO - bo.run_bo - üîçBO Trial 32: Using RF surrogate + Expected Improvement
2025-10-13 07:41:30,983 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:41:30,983 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 32 (NaN monitoring active)
2025-10-13 07:41:30,983 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:41:30,984 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:41:30,984 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 2.102150495624063e-05, 'batch_size': 16, 'epochs': 81, 'weight_decay': 0.0035966508913657883, 'dropout': 0.3818178253837516, 'hidden_size': 26, 'd_model': 30, 't_pooled': 128, 'label_smoothing': 0.19631811134627933, 'use_focal_loss': True, 'focal_gamma': 0.9653152825757552, 'grad_clip_norm': 2.7532481230717365, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:41:30,985 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 2.102150495624063e-05, 'batch_size': 16, 'epochs': 81, 'weight_decay': 0.0035966508913657883, 'dropout': 0.3818178253837516, 'hidden_size': 26, 'd_model': 30, 't_pooled': 128, 'label_smoothing': 0.19631811134627933, 'use_focal_loss': True, 'focal_gamma': 0.9653152825757552, 'grad_clip_norm': 2.7532481230717365, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:41:41,294 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.1831 | val_loss=0.9848 | val_acc=0.6126 | time=10.3s
2025-10-13 07:41:48,814 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.9067 | val_loss=0.7916 | val_acc=0.6418 | time=7.5s
2025-10-13 07:41:56,323 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.8143 | val_loss=0.7384 | val_acc=0.6502 | time=7.5s
2025-10-13 07:42:03,820 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.7844 | val_loss=0.7190 | val_acc=0.6547 | time=7.5s
2025-10-13 07:42:11,374 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.7596 | val_loss=0.6999 | val_acc=0.6569 | time=7.6s
2025-10-13 07:42:18,926 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.7439 | val_loss=0.6831 | val_acc=0.6656 | time=7.6s
2025-10-13 07:42:26,498 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.7278 | val_loss=0.6669 | val_acc=0.6809 | time=7.6s
2025-10-13 07:42:34,085 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.7157 | val_loss=0.6533 | val_acc=0.6901 | time=7.6s
2025-10-13 07:42:41,586 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.6955 | val_loss=0.6390 | val_acc=0.7059 | time=7.5s
2025-10-13 07:42:49,138 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.6861 | val_loss=0.6289 | val_acc=0.7166 | time=7.6s
2025-10-13 07:42:56,652 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.6763 | val_loss=0.6124 | val_acc=0.7263 | time=7.5s
2025-10-13 07:43:04,204 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.6609 | val_loss=0.5977 | val_acc=0.7363 | time=7.6s
2025-10-13 07:43:11,748 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.6476 | val_loss=0.5851 | val_acc=0.7433 | time=7.5s
2025-10-13 07:43:19,313 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.6348 | val_loss=0.5753 | val_acc=0.7485 | time=7.6s
2025-10-13 07:43:26,790 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.6218 | val_loss=0.5658 | val_acc=0.7525 | time=7.5s
2025-10-13 07:43:34,306 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.6128 | val_loss=0.5567 | val_acc=0.7574 | time=7.5s
2025-10-13 07:43:41,810 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.6045 | val_loss=0.5444 | val_acc=0.7616 | time=7.5s
2025-10-13 07:43:49,335 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.5986 | val_loss=0.5401 | val_acc=0.7646 | time=7.5s
2025-10-13 07:43:56,851 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.5875 | val_loss=0.5347 | val_acc=0.7658 | time=7.5s
2025-10-13 07:44:04,412 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.5842 | val_loss=0.5314 | val_acc=0.7678 | time=7.6s
2025-10-13 07:44:11,917 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.5796 | val_loss=0.5391 | val_acc=0.7661 | time=7.5s
2025-10-13 07:44:19,478 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.5786 | val_loss=0.5232 | val_acc=0.7731 | time=7.6s
2025-10-13 07:44:26,958 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.5735 | val_loss=0.5177 | val_acc=0.7768 | time=7.5s
2025-10-13 07:44:34,513 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.5684 | val_loss=0.5156 | val_acc=0.7761 | time=7.6s
2025-10-13 07:44:42,015 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.5682 | val_loss=0.5110 | val_acc=0.7790 | time=7.5s
2025-10-13 07:44:49,513 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.5607 | val_loss=0.5088 | val_acc=0.7788 | time=7.5s
2025-10-13 07:44:57,077 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.5604 | val_loss=0.5111 | val_acc=0.7793 | time=7.6s
2025-10-13 07:45:04,580 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.5591 | val_loss=0.5129 | val_acc=0.7800 | time=7.5s
2025-10-13 07:45:12,095 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.5546 | val_loss=0.5033 | val_acc=0.7808 | time=7.5s
2025-10-13 07:45:19,605 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.5529 | val_loss=0.4987 | val_acc=0.7843 | time=7.5s
2025-10-13 07:45:27,136 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.5504 | val_loss=0.5029 | val_acc=0.7829 | time=7.5s
2025-10-13 07:45:34,667 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.5476 | val_loss=0.4933 | val_acc=0.7867 | time=7.5s
2025-10-13 07:45:42,207 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.5440 | val_loss=0.4955 | val_acc=0.7865 | time=7.5s
2025-10-13 07:45:49,685 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.5459 | val_loss=0.4905 | val_acc=0.7872 | time=7.5s
2025-10-13 07:45:57,196 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.5461 | val_loss=0.4982 | val_acc=0.7824 | time=7.5s
2025-10-13 07:46:04,734 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.5417 | val_loss=0.4920 | val_acc=0.7854 | time=7.5s
2025-10-13 07:46:12,258 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.5384 | val_loss=0.4898 | val_acc=0.7853 | time=7.5s
2025-10-13 07:46:19,795 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.5360 | val_loss=0.4919 | val_acc=0.7887 | time=7.5s
2025-10-13 07:46:27,324 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.5375 | val_loss=0.4941 | val_acc=0.7853 | time=7.5s
2025-10-13 07:46:34,852 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.5310 | val_loss=0.4938 | val_acc=0.7874 | time=7.5s
2025-10-13 07:46:42,366 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.5340 | val_loss=0.4846 | val_acc=0.7919 | time=7.5s
2025-10-13 07:46:49,892 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.5305 | val_loss=0.4866 | val_acc=0.7877 | time=7.5s
2025-10-13 07:46:57,386 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.5310 | val_loss=0.4831 | val_acc=0.7940 | time=7.5s
2025-10-13 07:47:04,897 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.5282 | val_loss=0.4875 | val_acc=0.7900 | time=7.5s
2025-10-13 07:47:12,442 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.5307 | val_loss=0.4811 | val_acc=0.7905 | time=7.5s
2025-10-13 07:47:19,956 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.5266 | val_loss=0.4890 | val_acc=0.7874 | time=7.5s
2025-10-13 07:47:27,413 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.5263 | val_loss=0.4802 | val_acc=0.7920 | time=7.5s
2025-10-13 07:47:34,810 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.5237 | val_loss=0.4781 | val_acc=0.7942 | time=7.4s
2025-10-13 07:47:42,309 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.5227 | val_loss=0.4767 | val_acc=0.7939 | time=7.5s
2025-10-13 07:47:49,875 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.5222 | val_loss=0.4843 | val_acc=0.7900 | time=7.6s
2025-10-13 07:47:57,393 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.5205 | val_loss=0.4734 | val_acc=0.7953 | time=7.5s
2025-10-13 07:48:04,880 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.5196 | val_loss=0.4794 | val_acc=0.7945 | time=7.5s
2025-10-13 07:48:12,427 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.5202 | val_loss=0.4805 | val_acc=0.7938 | time=7.5s
2025-10-13 07:48:19,942 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.5162 | val_loss=0.4786 | val_acc=0.7935 | time=7.5s
2025-10-13 07:48:27,390 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.5187 | val_loss=0.4743 | val_acc=0.7960 | time=7.4s
2025-10-13 07:48:34,952 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.5180 | val_loss=0.4738 | val_acc=0.7947 | time=7.6s
2025-10-13 07:48:42,449 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.5168 | val_loss=0.4743 | val_acc=0.7960 | time=7.5s
2025-10-13 07:48:49,982 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.5177 | val_loss=0.4747 | val_acc=0.7973 | time=7.5s
2025-10-13 07:48:57,481 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.5139 | val_loss=0.4733 | val_acc=0.7960 | time=7.5s
2025-10-13 07:49:04,969 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.5166 | val_loss=0.4714 | val_acc=0.7962 | time=7.5s
2025-10-13 07:49:12,495 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.5124 | val_loss=0.4703 | val_acc=0.7982 | time=7.5s
2025-10-13 07:49:20,018 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.5139 | val_loss=0.4777 | val_acc=0.7927 | time=7.5s
2025-10-13 07:49:27,557 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.5117 | val_loss=0.4731 | val_acc=0.7943 | time=7.5s
2025-10-13 07:49:35,082 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.5113 | val_loss=0.4714 | val_acc=0.7965 | time=7.5s
2025-10-13 07:49:42,587 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.5113 | val_loss=0.4749 | val_acc=0.7929 | time=7.5s
2025-10-13 07:49:50,148 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.5092 | val_loss=0.4667 | val_acc=0.7999 | time=7.6s
2025-10-13 07:49:57,682 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.5089 | val_loss=0.4670 | val_acc=0.8020 | time=7.5s
2025-10-13 07:50:05,188 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.5062 | val_loss=0.4720 | val_acc=0.7990 | time=7.5s
2025-10-13 07:50:12,757 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.5058 | val_loss=0.4683 | val_acc=0.8004 | time=7.6s
2025-10-13 07:50:20,321 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.5060 | val_loss=0.4720 | val_acc=0.7973 | time=7.6s
2025-10-13 07:50:27,906 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.5064 | val_loss=0.4664 | val_acc=0.7966 | time=7.6s
2025-10-13 07:50:35,409 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.5045 | val_loss=0.4750 | val_acc=0.7953 | time=7.5s
2025-10-13 07:50:42,901 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.5051 | val_loss=0.4679 | val_acc=0.7993 | time=7.5s
2025-10-13 07:50:50,445 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.5028 | val_loss=0.4629 | val_acc=0.8017 | time=7.5s
2025-10-13 07:50:57,947 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.5041 | val_loss=0.4687 | val_acc=0.7952 | time=7.5s
2025-10-13 07:51:05,456 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.5027 | val_loss=0.4656 | val_acc=0.8006 | time=7.5s
2025-10-13 07:51:12,946 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.5010 | val_loss=0.4641 | val_acc=0.8011 | time=7.5s
2025-10-13 07:51:20,484 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.5005 | val_loss=0.4629 | val_acc=0.7982 | time=7.5s
2025-10-13 07:51:27,999 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.5035 | val_loss=0.4692 | val_acc=0.7957 | time=7.5s
2025-10-13 07:51:35,493 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.5006 | val_loss=0.4702 | val_acc=0.7991 | time=7.5s
2025-10-13 07:51:43,029 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.5013 | val_loss=0.4707 | val_acc=0.7981 | time=7.5s
2025-10-13 07:51:43,032 - INFO - _models.training_function_executor - Quantized model size: 75009 bytes.
2025-10-13 07:51:44,142 - INFO - _models.training_function_executor - Model: 14,474 parameters, 62.2KB storage
2025-10-13 07:51:44,142 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.1830973824212967, 0.9066513383100614, 0.8143081197715282, 0.7843566083974841, 0.7596271414522279, 0.7439167989189073, 0.7278188379298235, 0.7157480181577868, 0.6954671949732333, 0.6861356020724811, 0.6763368399567983, 0.6608855434760874, 0.6476078492738919, 0.6348321370866526, 0.6217617419504977, 0.6127592601223679, 0.6045009374649825, 0.5986328407011126, 0.5875251416272119, 0.5842380759116859, 0.5796091681725085, 0.5785837502726985, 0.5734822051661558, 0.5683926793925613, 0.5682336139197027, 0.5607222518826599, 0.5604150542584507, 0.559087931556972, 0.5545849723126616, 0.5529141749927202, 0.5504462679168083, 0.5475546128273344, 0.54396177059001, 0.5458741818310541, 0.54606418658177, 0.5417163802593122, 0.538363145903603, 0.5359870294538628, 0.5375404386074759, 0.5309697011101693, 0.5340480444405853, 0.5305297540766107, 0.5309802493485363, 0.5282366694605429, 0.5307207936678561, 0.5266128908510304, 0.5262734982666537, 0.5236978120306467, 0.5226966315449473, 0.5221799372437537, 0.5205044610530796, 0.5195637040041025, 0.5201529183607232, 0.5161963847208616, 0.5186678503395837, 0.5180234877554988, 0.5168407962096501, 0.5176902357769213, 0.5138755998188564, 0.5165800344528834, 0.5124370178685641, 0.5139130290192159, 0.511667622720753, 0.5112742707889565, 0.511304234332833, 0.5091615292547798, 0.5088761077635056, 0.5061894702272979, 0.5057814066273205, 0.505981962649314, 0.5064100973415008, 0.5044545985792206, 0.5051056208244812, 0.502813261569506, 0.5041449082859505, 0.5026829221635003, 0.5009772573468315, 0.5004534725781751, 0.5034947119624539, 0.5006168075310087, 0.5012941016709007], 'val_losses': [0.9848083983487419, 0.7915930468008825, 0.738355662278625, 0.7189506341161784, 0.6998765842456437, 0.6830524161098135, 0.6669160104064955, 0.6533292595598303, 0.6390367285705422, 0.6289378299260832, 0.6124492071498554, 0.5977090997090071, 0.585058026289581, 0.575312959133932, 0.5657953539218442, 0.5567165839951649, 0.5443627351766539, 0.540115656669548, 0.5347462363350755, 0.5313750970267649, 0.5391331435000934, 0.5232156214073149, 0.5177473717629597, 0.5156134435418689, 0.5110363817565459, 0.5087685148053375, 0.5110883795071783, 0.5129238765974916, 0.5033310391517382, 0.49865836723934825, 0.5029475568556727, 0.49326496579908263, 0.4954989108227332, 0.4904731083759112, 0.498217481456105, 0.4919601938588493, 0.48978799285277813, 0.491890891327656, 0.49407520094325086, 0.4938090560650717, 0.4846177787934311, 0.4866095054470913, 0.483082941853587, 0.48745601057046606, 0.48105462314283925, 0.4890116258104823, 0.48018371105444446, 0.47813851621796044, 0.4767310246746983, 0.4843230722749154, 0.47343393096274583, 0.47941209967836534, 0.48051836791470787, 0.4786253179709395, 0.47430972404984023, 0.4738212462109121, 0.4742537453160404, 0.47473101593791334, 0.47325677436926084, 0.4713891565611949, 0.47029551562204785, 0.4777093796534767, 0.4730557990441341, 0.47140711570979416, 0.4749394624559538, 0.4667345450230733, 0.46703054725936044, 0.4720434783992126, 0.46830036113802104, 0.47197071227903836, 0.46636680067941616, 0.4749575809536174, 0.4678984059918624, 0.4629395340846726, 0.4686841039879572, 0.4655542999432977, 0.46410673565701, 0.462895477437706, 0.46920291397761, 0.47024008767313585, 0.4706965886841381], 'val_acc': [0.6126181309065454, 0.6418445922296114, 0.6502450122506125, 0.6547077353867693, 0.6568953447672383, 0.6656457822891144, 0.6808715435771788, 0.6901470073503675, 0.7058977948897445, 0.7165733286664333, 0.7262863143157158, 0.7362618130906545, 0.7433496674833742, 0.7485124256212811, 0.7524501225061253, 0.7574378718935947, 0.7616380819040952, 0.7646132306615331, 0.765750787539377, 0.7677633881694085, 0.766100805040252, 0.7731011550577529, 0.7767763388169409, 0.7760763038151908, 0.7789639481974099, 0.7787889394469724, 0.7793139656982849, 0.780014000700035, 0.7808015400770039, 0.7843017150857543, 0.7829016450822541, 0.7866643332166608, 0.7864893244662233, 0.7871893594679734, 0.7823766188309416, 0.7853517675883794, 0.7852642632131607, 0.7886769338466924, 0.7852642632131607, 0.7873643682184109, 0.7919145957297865, 0.787714385719286, 0.7940147007350368, 0.7899894994749738, 0.7905145257262863, 0.7873643682184109, 0.7920021001050053, 0.7941897094854743, 0.793927196359818, 0.7899894994749738, 0.7953272663633182, 0.7944522226111306, 0.7937521876093805, 0.7934896744837242, 0.7960273013650683, 0.7947147357367869, 0.7960273013650683, 0.7972523626181309, 0.7960273013650683, 0.7962023101155058, 0.7982149107455373, 0.7927021351067554, 0.794277213860693, 0.7964648232411621, 0.7928771438571929, 0.7998774938746938, 0.801977598879944, 0.7990024501225061, 0.8004025201260063, 0.7972523626181309, 0.7966398319915996, 0.7953272663633182, 0.7992649632481624, 0.8017150857542877, 0.7951522576128807, 0.8005775288764438, 0.8011025551277564, 0.7982149107455373, 0.7956772838641932, 0.7990899544977249, 0.7981274063703185], 'model_size_bytes': 75009, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 2.102150495624063e-05, 'batch_size': 16, 'epochs': 81, 'weight_decay': 0.0035966508913657883, 'dropout': 0.3818178253837516, 'hidden_size': 26, 'd_model': 30, 't_pooled': 128, 'label_smoothing': 0.19631811134627933, 'use_focal_loss': True, 'focal_gamma': 0.9653152825757552, 'grad_clip_norm': 2.7532481230717365, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 14474, 'model_storage_size_kb': 62.192968750000006, 'model_size_validation': 'PASS'}
2025-10-13 07:51:44,142 - INFO - _models.training_function_executor - BO Objective: base=0.7981, size_penalty=0.0000, final=0.7981
2025-10-13 07:51:44,142 - INFO - _models.training_function_executor - Model: 14,474 parameters, 62.2KB (PASS 256KB limit)
2025-10-13 07:51:44,142 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 613.158s
2025-10-13 07:51:44,246 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7981
2025-10-13 07:51:44,246 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-13 07:51:44,246 - INFO - bo.run_bo - Recorded observation #32: hparams={'lr': 2.102150495624063e-05, 'batch_size': np.int64(16), 'epochs': np.int64(81), 'weight_decay': 0.0035966508913657883, 'dropout': 0.3818178253837516, 'hidden_size': np.int64(26), 'd_model': np.int64(30), 't_pooled': np.int64(128), 'label_smoothing': 0.19631811134627933, 'use_focal_loss': np.True_, 'focal_gamma': 0.9653152825757552, 'grad_clip_norm': 2.7532481230717365, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7981
2025-10-13 07:51:44,246 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 32: {'lr': 2.102150495624063e-05, 'batch_size': np.int64(16), 'epochs': np.int64(81), 'weight_decay': 0.0035966508913657883, 'dropout': 0.3818178253837516, 'hidden_size': np.int64(26), 'd_model': np.int64(30), 't_pooled': np.int64(128), 'label_smoothing': 0.19631811134627933, 'use_focal_loss': np.True_, 'focal_gamma': 0.9653152825757552, 'grad_clip_norm': 2.7532481230717365, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7981
2025-10-13 07:51:44,246 - INFO - bo.run_bo - üîçBO Trial 33: Using RF surrogate + Expected Improvement
2025-10-13 07:51:44,246 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 07:51:44,246 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 33 (NaN monitoring active)
2025-10-13 07:51:44,246 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 07:51:44,246 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 07:51:44,246 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.9216912490217687e-05, 'batch_size': 32, 'epochs': 89, 'weight_decay': 3.87831247462903e-06, 'dropout': 0.49152422938715773, 'hidden_size': 22, 'd_model': 27, 't_pooled': 320, 'label_smoothing': 0.041349946926132836, 'use_focal_loss': True, 'focal_gamma': 4.726495920144097, 'grad_clip_norm': 3.3355048137567858, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:51:44,248 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.9216912490217687e-05, 'batch_size': 32, 'epochs': 89, 'weight_decay': 3.87831247462903e-06, 'dropout': 0.49152422938715773, 'hidden_size': 22, 'd_model': 27, 't_pooled': 320, 'label_smoothing': 0.041349946926132836, 'use_focal_loss': True, 'focal_gamma': 4.726495920144097, 'grad_clip_norm': 3.3355048137567858, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 07:51:52,632 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.5214 | val_loss=0.4861 | val_acc=0.3433 | time=8.4s
2025-10-13 07:51:58,220 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.4486 | val_loss=0.3856 | val_acc=0.5886 | time=5.6s
2025-10-13 07:52:03,807 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.3512 | val_loss=0.2963 | val_acc=0.6130 | time=5.6s
2025-10-13 07:52:09,381 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.2890 | val_loss=0.2465 | val_acc=0.6266 | time=5.6s
2025-10-13 07:52:14,956 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.2558 | val_loss=0.2209 | val_acc=0.6534 | time=5.6s
2025-10-13 07:52:20,577 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.2404 | val_loss=0.2085 | val_acc=0.6688 | time=5.6s
2025-10-13 07:52:26,182 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.2311 | val_loss=0.1982 | val_acc=0.6831 | time=5.6s
2025-10-13 07:52:31,801 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.2206 | val_loss=0.1920 | val_acc=0.6873 | time=5.6s
2025-10-13 07:52:37,417 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.2156 | val_loss=0.1846 | val_acc=0.6985 | time=5.6s
2025-10-13 07:52:43,023 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.2091 | val_loss=0.1796 | val_acc=0.7016 | time=5.6s
2025-10-13 07:52:48,640 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.2035 | val_loss=0.1769 | val_acc=0.7040 | time=5.6s
2025-10-13 07:52:54,250 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.1975 | val_loss=0.1723 | val_acc=0.7081 | time=5.6s
2025-10-13 07:52:59,859 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.1949 | val_loss=0.1663 | val_acc=0.7181 | time=5.6s
2025-10-13 07:53:05,472 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.1901 | val_loss=0.1618 | val_acc=0.7239 | time=5.6s
2025-10-13 07:53:11,073 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.1834 | val_loss=0.1583 | val_acc=0.7253 | time=5.6s
2025-10-13 07:53:16,679 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.1803 | val_loss=0.1549 | val_acc=0.7314 | time=5.6s
2025-10-13 07:53:22,288 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.1781 | val_loss=0.1516 | val_acc=0.7300 | time=5.6s
2025-10-13 07:53:27,918 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.1738 | val_loss=0.1482 | val_acc=0.7367 | time=5.6s
2025-10-13 07:53:33,547 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.1706 | val_loss=0.1442 | val_acc=0.7412 | time=5.6s
2025-10-13 07:53:39,146 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.1670 | val_loss=0.1412 | val_acc=0.7430 | time=5.6s
2025-10-13 07:53:44,768 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.1645 | val_loss=0.1398 | val_acc=0.7421 | time=5.6s
2025-10-13 07:53:50,400 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.1627 | val_loss=0.1399 | val_acc=0.7435 | time=5.6s
2025-10-13 07:53:56,015 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.1592 | val_loss=0.1356 | val_acc=0.7485 | time=5.6s
2025-10-13 07:54:01,641 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.1572 | val_loss=0.1323 | val_acc=0.7511 | time=5.6s
2025-10-13 07:54:07,246 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.1534 | val_loss=0.1314 | val_acc=0.7540 | time=5.6s
2025-10-13 07:54:12,854 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.1522 | val_loss=0.1293 | val_acc=0.7560 | time=5.6s
2025-10-13 07:54:18,472 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.1496 | val_loss=0.1267 | val_acc=0.7583 | time=5.6s
2025-10-13 07:54:24,082 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.1492 | val_loss=0.1251 | val_acc=0.7588 | time=5.6s
2025-10-13 07:54:29,705 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.1453 | val_loss=0.1248 | val_acc=0.7596 | time=5.6s
2025-10-13 07:54:35,334 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.1447 | val_loss=0.1219 | val_acc=0.7615 | time=5.6s
2025-10-13 07:54:40,945 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.1439 | val_loss=0.1206 | val_acc=0.7621 | time=5.6s
2025-10-13 07:54:46,567 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.1427 | val_loss=0.1205 | val_acc=0.7630 | time=5.6s
2025-10-13 07:54:52,169 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.1416 | val_loss=0.1176 | val_acc=0.7660 | time=5.6s
2025-10-13 07:54:57,783 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.1408 | val_loss=0.1173 | val_acc=0.7662 | time=5.6s
2025-10-13 07:55:03,412 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.1389 | val_loss=0.1174 | val_acc=0.7696 | time=5.6s
2025-10-13 07:55:09,035 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.1390 | val_loss=0.1156 | val_acc=0.7685 | time=5.6s
2025-10-13 07:55:14,651 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.1359 | val_loss=0.1151 | val_acc=0.7721 | time=5.6s
2025-10-13 07:55:20,265 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.1369 | val_loss=0.1136 | val_acc=0.7709 | time=5.6s
2025-10-13 07:55:25,875 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.1346 | val_loss=0.1132 | val_acc=0.7700 | time=5.6s
2025-10-13 07:55:31,501 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.1346 | val_loss=0.1129 | val_acc=0.7732 | time=5.6s
2025-10-13 07:55:37,111 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.1330 | val_loss=0.1127 | val_acc=0.7741 | time=5.6s
2025-10-13 07:55:42,722 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.1346 | val_loss=0.1115 | val_acc=0.7744 | time=5.6s
2025-10-13 07:55:48,340 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.1302 | val_loss=0.1101 | val_acc=0.7745 | time=5.6s
2025-10-13 07:55:53,949 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.1316 | val_loss=0.1094 | val_acc=0.7778 | time=5.6s
2025-10-13 07:55:59,577 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.1293 | val_loss=0.1090 | val_acc=0.7785 | time=5.6s
2025-10-13 07:56:05,204 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.1298 | val_loss=0.1081 | val_acc=0.7788 | time=5.6s
2025-10-13 07:56:10,836 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.1288 | val_loss=0.1080 | val_acc=0.7777 | time=5.6s
2025-10-13 07:56:16,460 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.1279 | val_loss=0.1073 | val_acc=0.7784 | time=5.6s
2025-10-13 07:56:22,085 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.1287 | val_loss=0.1074 | val_acc=0.7809 | time=5.6s
2025-10-13 07:56:27,698 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.1266 | val_loss=0.1079 | val_acc=0.7782 | time=5.6s
2025-10-13 07:56:33,297 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.1271 | val_loss=0.1061 | val_acc=0.7814 | time=5.6s
2025-10-13 07:56:38,914 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.1261 | val_loss=0.1058 | val_acc=0.7812 | time=5.6s
2025-10-13 07:56:44,525 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.1248 | val_loss=0.1058 | val_acc=0.7805 | time=5.6s
2025-10-13 07:56:50,141 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.1245 | val_loss=0.1054 | val_acc=0.7797 | time=5.6s
2025-10-13 07:56:55,763 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.1237 | val_loss=0.1048 | val_acc=0.7833 | time=5.6s
2025-10-13 07:57:01,383 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.1235 | val_loss=0.1050 | val_acc=0.7830 | time=5.6s
2025-10-13 07:57:06,991 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.1240 | val_loss=0.1043 | val_acc=0.7831 | time=5.6s
2025-10-13 07:57:12,613 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.1241 | val_loss=0.1034 | val_acc=0.7842 | time=5.6s
2025-10-13 07:57:18,222 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.1239 | val_loss=0.1028 | val_acc=0.7835 | time=5.6s
2025-10-13 07:57:23,844 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.1229 | val_loss=0.1038 | val_acc=0.7854 | time=5.6s
2025-10-13 07:57:29,454 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.1199 | val_loss=0.1035 | val_acc=0.7851 | time=5.6s
2025-10-13 07:57:35,060 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.1200 | val_loss=0.1033 | val_acc=0.7853 | time=5.6s
2025-10-13 07:57:40,668 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.1208 | val_loss=0.1026 | val_acc=0.7865 | time=5.6s
2025-10-13 07:57:46,286 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.1194 | val_loss=0.1022 | val_acc=0.7861 | time=5.6s
2025-10-13 07:57:51,895 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.1204 | val_loss=0.1019 | val_acc=0.7855 | time=5.6s
2025-10-13 07:57:57,525 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.1193 | val_loss=0.1032 | val_acc=0.7854 | time=5.6s
2025-10-13 07:58:03,150 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.1196 | val_loss=0.1002 | val_acc=0.7881 | time=5.6s
2025-10-13 07:58:08,768 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.1178 | val_loss=0.1011 | val_acc=0.7889 | time=5.6s
2025-10-13 07:58:14,379 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.1182 | val_loss=0.1015 | val_acc=0.7854 | time=5.6s
2025-10-13 07:58:19,990 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.1179 | val_loss=0.1007 | val_acc=0.7868 | time=5.6s
2025-10-13 07:58:25,606 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.1164 | val_loss=0.0994 | val_acc=0.7890 | time=5.6s
2025-10-13 07:58:31,230 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.1166 | val_loss=0.0994 | val_acc=0.7887 | time=5.6s
2025-10-13 07:58:36,847 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.1166 | val_loss=0.0997 | val_acc=0.7876 | time=5.6s
2025-10-13 07:58:42,467 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.1161 | val_loss=0.0985 | val_acc=0.7896 | time=5.6s
2025-10-13 07:58:48,089 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.1176 | val_loss=0.0990 | val_acc=0.7885 | time=5.6s
2025-10-13 07:58:53,702 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.1172 | val_loss=0.0985 | val_acc=0.7898 | time=5.6s
2025-10-13 07:58:59,310 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.1167 | val_loss=0.0999 | val_acc=0.7873 | time=5.6s
2025-10-13 07:59:04,928 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.1165 | val_loss=0.0991 | val_acc=0.7875 | time=5.6s
2025-10-13 07:59:10,548 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.1147 | val_loss=0.0998 | val_acc=0.7889 | time=5.6s
2025-10-13 07:59:16,153 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.1148 | val_loss=0.0978 | val_acc=0.7900 | time=5.6s
2025-10-13 07:59:21,769 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.1143 | val_loss=0.0989 | val_acc=0.7876 | time=5.6s
2025-10-13 07:59:27,381 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.1135 | val_loss=0.0975 | val_acc=0.7888 | time=5.6s
2025-10-13 07:59:32,988 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.1139 | val_loss=0.0991 | val_acc=0.7890 | time=5.6s
2025-10-13 07:59:38,606 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.1133 | val_loss=0.0967 | val_acc=0.7905 | time=5.6s
2025-10-13 07:59:44,221 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.1140 | val_loss=0.0991 | val_acc=0.7895 | time=5.6s
2025-10-13 07:59:49,829 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.1148 | val_loss=0.0975 | val_acc=0.7890 | time=5.6s
2025-10-13 07:59:55,441 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.1141 | val_loss=0.0963 | val_acc=0.7904 | time=5.6s
2025-10-13 08:00:01,054 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.1114 | val_loss=0.0968 | val_acc=0.7927 | time=5.6s
2025-10-13 08:00:06,670 - INFO - _models.training_function_executor - Epoch 089 | train_loss=0.1125 | val_loss=0.0963 | val_acc=0.7908 | time=5.6s
2025-10-13 08:00:06,677 - INFO - _models.training_function_executor - Quantized model size: 46587 bytes.
2025-10-13 08:00:07,771 - INFO - _models.training_function_executor - Model: 4,983 parameters, 5.4KB storage
2025-10-13 08:00:07,771 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.5213780584016545, 0.4486035811325283, 0.35124392943612587, 0.28904138972261045, 0.25579412602276747, 0.24037462726397074, 0.23106174367080004, 0.22056667956806872, 0.2156460464814346, 0.2090812581279998, 0.20348453804417677, 0.1974597771553923, 0.19491456088368442, 0.19008395643262627, 0.18343000044595706, 0.18034456631166768, 0.1780931172142047, 0.17381313027495224, 0.17062101582254943, 0.1670458017893091, 0.16447387612237352, 0.16272296023183158, 0.15919597427359736, 0.15716114033653805, 0.15339507170394454, 0.15215864555638364, 0.14964164814354033, 0.14919856855418243, 0.14525666457004677, 0.14474074281739072, 0.1438555355266253, 0.1427483664115576, 0.1416123047950888, 0.14081629418621625, 0.13891590368374268, 0.1389960916853051, 0.1358925278201089, 0.13693761301908536, 0.13456981514388547, 0.13459206815570396, 0.13299759173564324, 0.1345916206775364, 0.13018353261108326, 0.13156267805797553, 0.12933100288877922, 0.12976354432035084, 0.12879995625670823, 0.12792210937547735, 0.1287467785148321, 0.12661495335507025, 0.1270526801077874, 0.12609656333485222, 0.1247652237586179, 0.12447020071690676, 0.12368851987332742, 0.12350952071631585, 0.12396821458939701, 0.12409801933605395, 0.1239047600650729, 0.12288816601669075, 0.11986596702337578, 0.11999303385834408, 0.12077063060240767, 0.11936872988146503, 0.12041242600353105, 0.11928677514826538, 0.1196423688102194, 0.11780861270179438, 0.11824971274073448, 0.1179169871051244, 0.11636262371911843, 0.11659714630695753, 0.11656675557516277, 0.11610839322553593, 0.11759592716588313, 0.11724708405723303, 0.11672068265092969, 0.11652688577244405, 0.11467976336806522, 0.1148316064848844, 0.11426075526940518, 0.1135239779889208, 0.11391111048923576, 0.1133258011495896, 0.1140474577544868, 0.11476103931999224, 0.11406903426558311, 0.11140923230463197, 0.11248807687055493], 'val_losses': [0.4861362203251535, 0.3856493895876687, 0.29625814939279593, 0.2465441713163725, 0.22090698228376413, 0.20854593287680087, 0.19815688292108968, 0.1919775765531331, 0.18458037593166937, 0.17958986572464905, 0.17691090288886582, 0.17232203507573612, 0.16633676637666894, 0.16182748046545536, 0.158291321108297, 0.15485475119235928, 0.15159198714274813, 0.14822353153513326, 0.14415344003409325, 0.14120910610086984, 0.13976098733700193, 0.1398508468467454, 0.135561420626894, 0.13233629196600602, 0.13135793740187318, 0.12928234590990043, 0.12665585385707862, 0.12509825483543455, 0.1248008912187337, 0.1218755591581199, 0.12059546346780425, 0.12046425668851954, 0.11763132157017395, 0.1172873159263532, 0.1174105925027165, 0.11563718685600613, 0.1150590880171878, 0.11356213096350609, 0.11318893176736555, 0.11288254548713049, 0.11272342869471452, 0.11149429412813591, 0.11008427961539421, 0.10942295650303843, 0.10902685299385333, 0.10813059569406559, 0.1079681429113589, 0.10730165090851321, 0.1074386971566199, 0.10791595500010813, 0.10612809812695069, 0.10575771041274447, 0.10584939651694547, 0.10540240599343857, 0.10483958573974761, 0.10503365604828235, 0.1043101762391113, 0.10337061727322354, 0.1027645328149622, 0.10375931549988136, 0.10354585434210063, 0.10327672461320939, 0.10259316144214463, 0.10218510809356114, 0.10187501852271187, 0.10323550829603241, 0.10020617281416308, 0.10110568780012594, 0.10154341880752359, 0.10068432584347572, 0.09942529436838472, 0.09939876951650176, 0.09974191059698415, 0.09849925799765369, 0.0989843659601013, 0.09852678343617169, 0.09990656099976215, 0.09909209566002423, 0.09982869935788848, 0.09778497743886128, 0.09886441632354222, 0.09753175045790312, 0.09913889725265863, 0.0967294773283145, 0.09909819955274196, 0.09751513441010794, 0.09633751249277887, 0.09680624365399758, 0.09629092503979275], 'val_acc': [0.34327966398319915, 0.5885544277213861, 0.6129681484074204, 0.626618830941547, 0.6533951697584879, 0.6687959397969898, 0.6831466573328666, 0.6872593629681484, 0.6985474273713685, 0.7016100805040252, 0.7039726986349317, 0.7080854042702135, 0.7180609030451522, 0.7239236961848092, 0.7253237661883094, 0.7314490724536227, 0.7300490024501225, 0.7366993349667483, 0.7411620581029051, 0.7429996499824991, 0.7421246062303115, 0.7435246762338117, 0.7485124256212811, 0.7511375568778439, 0.754025201260063, 0.7559502975148757, 0.7583129156457823, 0.7587504375218761, 0.7596254812740637, 0.7614630731536577, 0.762075603780189, 0.7630381519075954, 0.7660133006650333, 0.7661883094154708, 0.7696009800490025, 0.7684634231711586, 0.7721386069303465, 0.7709135456772839, 0.7700385019250963, 0.7731886594329717, 0.7740637031851593, 0.7744137206860343, 0.7745012250612531, 0.777826391319566, 0.7785264263213161, 0.7787889394469724, 0.7777388869443472, 0.7784389219460973, 0.7808890444522226, 0.778176408820441, 0.7814140707035352, 0.7812390619530977, 0.7805390269513476, 0.77966398319916, 0.7833391669583479, 0.7829891494574729, 0.7830766538326916, 0.7842142107105355, 0.7835141757087855, 0.7853517675883794, 0.7850892544627232, 0.7852642632131607, 0.7864893244662233, 0.7860518025901295, 0.785526776338817, 0.7854392719635982, 0.788064403220161, 0.7889394469723486, 0.7853517675883794, 0.7868393419670984, 0.7890269513475674, 0.7886769338466924, 0.7876268813440672, 0.7896394819740987, 0.7885019250962548, 0.7898144907245362, 0.7872768638431922, 0.7875393769688485, 0.7888519425971299, 0.7899894994749738, 0.7876268813440672, 0.7887644382219111, 0.7890269513475674, 0.7905145257262863, 0.7894644732236612, 0.7890269513475674, 0.7904270213510676, 0.7927021351067554, 0.7907770388519426], 'model_size_bytes': 46587, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.9216912490217687e-05, 'batch_size': 32, 'epochs': 89, 'weight_decay': 3.87831247462903e-06, 'dropout': 0.49152422938715773, 'hidden_size': 22, 'd_model': 27, 't_pooled': 320, 'label_smoothing': 0.041349946926132836, 'use_focal_loss': True, 'focal_gamma': 4.726495920144097, 'grad_clip_norm': 3.3355048137567858, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 4983, 'model_storage_size_kb': 5.35283203125, 'model_size_validation': 'PASS'}
2025-10-13 08:00:07,771 - INFO - _models.training_function_executor - BO Objective: base=0.7908, size_penalty=0.0000, final=0.7908
2025-10-13 08:00:07,771 - INFO - _models.training_function_executor - Model: 4,983 parameters, 5.4KB (PASS 256KB limit)
2025-10-13 08:00:07,771 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 503.525s
2025-10-13 08:00:07,877 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7908
2025-10-13 08:00:07,877 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.102s
2025-10-13 08:00:07,877 - INFO - bo.run_bo - Recorded observation #33: hparams={'lr': 1.9216912490217687e-05, 'batch_size': np.int64(32), 'epochs': np.int64(89), 'weight_decay': 3.87831247462903e-06, 'dropout': 0.49152422938715773, 'hidden_size': np.int64(22), 'd_model': np.int64(27), 't_pooled': np.int64(320), 'label_smoothing': 0.041349946926132836, 'use_focal_loss': np.True_, 'focal_gamma': 4.726495920144097, 'grad_clip_norm': 3.3355048137567858, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7908
2025-10-13 08:00:07,877 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 33: {'lr': 1.9216912490217687e-05, 'batch_size': np.int64(32), 'epochs': np.int64(89), 'weight_decay': 3.87831247462903e-06, 'dropout': 0.49152422938715773, 'hidden_size': np.int64(22), 'd_model': np.int64(27), 't_pooled': np.int64(320), 'label_smoothing': 0.041349946926132836, 'use_focal_loss': np.True_, 'focal_gamma': 4.726495920144097, 'grad_clip_norm': 3.3355048137567858, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7908
2025-10-13 08:00:07,878 - INFO - bo.run_bo - üîçBO Trial 34: Using RF surrogate + Expected Improvement
2025-10-13 08:00:07,878 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 08:00:07,878 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 34 (NaN monitoring active)
2025-10-13 08:00:07,878 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 08:00:07,878 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 08:00:07,878 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.8712062984247893e-05, 'batch_size': 24, 'epochs': 54, 'weight_decay': 0.00024162254846980146, 'dropout': 0.45042749520746955, 'hidden_size': 28, 'd_model': 9, 't_pooled': 192, 'label_smoothing': 0.0085343630677186, 'use_focal_loss': True, 'focal_gamma': 2.3043638970350067, 'grad_clip_norm': 2.832837371590298, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 08:00:07,879 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.8712062984247893e-05, 'batch_size': 24, 'epochs': 54, 'weight_decay': 0.00024162254846980146, 'dropout': 0.45042749520746955, 'hidden_size': 28, 'd_model': 9, 't_pooled': 192, 'label_smoothing': 0.0085343630677186, 'use_focal_loss': True, 'focal_gamma': 2.3043638970350067, 'grad_clip_norm': 2.832837371590298, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 08:00:16,503 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9163 | val_loss=0.8642 | val_acc=0.3351 | time=8.6s
2025-10-13 08:00:22,334 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7635 | val_loss=0.6136 | val_acc=0.5984 | time=5.8s
2025-10-13 08:00:28,132 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.5586 | val_loss=0.4597 | val_acc=0.6177 | time=5.8s
2025-10-13 08:00:33,955 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.4796 | val_loss=0.4108 | val_acc=0.6379 | time=5.8s
2025-10-13 08:00:39,743 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.4528 | val_loss=0.3925 | val_acc=0.6572 | time=5.8s
2025-10-13 08:00:45,592 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.4297 | val_loss=0.3714 | val_acc=0.6778 | time=5.8s
2025-10-13 08:00:51,411 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.4158 | val_loss=0.3578 | val_acc=0.6840 | time=5.8s
2025-10-13 08:00:57,243 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.4015 | val_loss=0.3495 | val_acc=0.6915 | time=5.8s
2025-10-13 08:01:03,117 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.3920 | val_loss=0.3394 | val_acc=0.6952 | time=5.9s
2025-10-13 08:01:08,952 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.3809 | val_loss=0.3321 | val_acc=0.7069 | time=5.8s
2025-10-13 08:01:14,793 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.3732 | val_loss=0.3246 | val_acc=0.7113 | time=5.8s
2025-10-13 08:01:20,563 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.3673 | val_loss=0.3188 | val_acc=0.7160 | time=5.8s
2025-10-13 08:01:26,356 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.3601 | val_loss=0.3130 | val_acc=0.7231 | time=5.8s
2025-10-13 08:01:32,173 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.3531 | val_loss=0.3097 | val_acc=0.7268 | time=5.8s
2025-10-13 08:01:37,995 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.3518 | val_loss=0.3048 | val_acc=0.7295 | time=5.8s
2025-10-13 08:01:43,806 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.3455 | val_loss=0.2975 | val_acc=0.7342 | time=5.8s
2025-10-13 08:01:49,650 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.3392 | val_loss=0.2924 | val_acc=0.7368 | time=5.8s
2025-10-13 08:01:55,480 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.3341 | val_loss=0.2881 | val_acc=0.7414 | time=5.8s
2025-10-13 08:02:01,304 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.3280 | val_loss=0.2875 | val_acc=0.7412 | time=5.8s
2025-10-13 08:02:07,049 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.3263 | val_loss=0.2837 | val_acc=0.7471 | time=5.7s
2025-10-13 08:02:12,856 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.3207 | val_loss=0.2757 | val_acc=0.7474 | time=5.8s
2025-10-13 08:02:18,735 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.3142 | val_loss=0.2695 | val_acc=0.7551 | time=5.9s
2025-10-13 08:02:24,548 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.3121 | val_loss=0.2684 | val_acc=0.7565 | time=5.8s
2025-10-13 08:02:30,338 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.3057 | val_loss=0.2635 | val_acc=0.7606 | time=5.8s
2025-10-13 08:02:36,123 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.3021 | val_loss=0.2581 | val_acc=0.7600 | time=5.8s
2025-10-13 08:02:41,906 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.2994 | val_loss=0.2599 | val_acc=0.7538 | time=5.8s
2025-10-13 08:02:47,699 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.2963 | val_loss=0.2516 | val_acc=0.7640 | time=5.8s
2025-10-13 08:02:53,531 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.2908 | val_loss=0.2478 | val_acc=0.7676 | time=5.8s
2025-10-13 08:02:59,329 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.2889 | val_loss=0.2478 | val_acc=0.7668 | time=5.8s
2025-10-13 08:03:05,172 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.2858 | val_loss=0.2499 | val_acc=0.7608 | time=5.8s
2025-10-13 08:03:10,989 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.2843 | val_loss=0.2402 | val_acc=0.7712 | time=5.8s
2025-10-13 08:03:16,796 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.2839 | val_loss=0.2375 | val_acc=0.7690 | time=5.8s
2025-10-13 08:03:22,649 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.2810 | val_loss=0.2350 | val_acc=0.7737 | time=5.9s
2025-10-13 08:03:28,453 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.2774 | val_loss=0.2339 | val_acc=0.7745 | time=5.8s
2025-10-13 08:03:34,246 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.2779 | val_loss=0.2379 | val_acc=0.7712 | time=5.8s
2025-10-13 08:03:40,040 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.2722 | val_loss=0.2357 | val_acc=0.7726 | time=5.8s
2025-10-13 08:03:45,832 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.2714 | val_loss=0.2329 | val_acc=0.7715 | time=5.8s
2025-10-13 08:03:51,765 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.2695 | val_loss=0.2276 | val_acc=0.7786 | time=5.9s
2025-10-13 08:03:57,587 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.2670 | val_loss=0.2335 | val_acc=0.7701 | time=5.8s
2025-10-13 08:04:03,394 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.2660 | val_loss=0.2236 | val_acc=0.7803 | time=5.8s
2025-10-13 08:04:09,203 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.2645 | val_loss=0.2240 | val_acc=0.7790 | time=5.8s
2025-10-13 08:04:15,007 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.2653 | val_loss=0.2273 | val_acc=0.7791 | time=5.8s
2025-10-13 08:04:20,823 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.2624 | val_loss=0.2242 | val_acc=0.7795 | time=5.8s
2025-10-13 08:04:26,657 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.2639 | val_loss=0.2200 | val_acc=0.7820 | time=5.8s
2025-10-13 08:04:32,499 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.2615 | val_loss=0.2208 | val_acc=0.7821 | time=5.8s
2025-10-13 08:04:38,298 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.2588 | val_loss=0.2200 | val_acc=0.7808 | time=5.8s
2025-10-13 08:04:44,134 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.2566 | val_loss=0.2221 | val_acc=0.7826 | time=5.8s
2025-10-13 08:04:49,947 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.2581 | val_loss=0.2164 | val_acc=0.7844 | time=5.8s
2025-10-13 08:04:55,814 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.2546 | val_loss=0.2176 | val_acc=0.7843 | time=5.9s
2025-10-13 08:05:01,645 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.2564 | val_loss=0.2153 | val_acc=0.7863 | time=5.8s
2025-10-13 08:05:07,479 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.2510 | val_loss=0.2152 | val_acc=0.7847 | time=5.8s
2025-10-13 08:05:13,301 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.2511 | val_loss=0.2132 | val_acc=0.7876 | time=5.8s
2025-10-13 08:05:19,109 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.2523 | val_loss=0.2118 | val_acc=0.7873 | time=5.8s
2025-10-13 08:05:24,923 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.2540 | val_loss=0.2146 | val_acc=0.7862 | time=5.8s
2025-10-13 08:05:24,926 - INFO - _models.training_function_executor - Quantized model size: 61441 bytes.
2025-10-13 08:05:26,022 - INFO - _models.training_function_executor - Model: 11,042 parameters, 47.4KB storage
2025-10-13 08:05:26,022 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9162676209309404, 0.7635195867651027, 0.5585801887906512, 0.47960474916874296, 0.4527614079428837, 0.4297133747528682, 0.41581831929053215, 0.40154929721703847, 0.391971331513508, 0.3808716197566924, 0.37324118005006846, 0.36725789503613926, 0.36010808019521023, 0.35306419352233137, 0.3517843264620914, 0.34553676763973873, 0.33920076440421276, 0.3340951018257078, 0.32804284629822406, 0.3263135819774451, 0.32068193931684114, 0.3142351337314424, 0.31207335793136465, 0.3057024018655801, 0.3021024250936208, 0.2994421042885278, 0.29633832558348, 0.29078211748661553, 0.28889813388889807, 0.2857695701259873, 0.2842632686242717, 0.2839079835811694, 0.2809893126342945, 0.2773686126239616, 0.27787736883614506, 0.2722233475274271, 0.2713610062654051, 0.26949032821024593, 0.2669687997836634, 0.26597267209878533, 0.2644864489873014, 0.26529801261667024, 0.2623532663380136, 0.2639120844873121, 0.26153835996276104, 0.25881369428831064, 0.256602662505623, 0.2581002008890955, 0.25462585478489075, 0.2563605547983996, 0.25095072054585504, 0.2510965962920013, 0.25225726338895543, 0.2539809933933014], 'val_losses': [0.8642289531076542, 0.6135826864816695, 0.4597437359942896, 0.4107855375325467, 0.39250935500929063, 0.3713719923783317, 0.35782164422874063, 0.3495213237307812, 0.3394214039525662, 0.3320998543828444, 0.32464904305523495, 0.31875689380395067, 0.3129715910419368, 0.309664886618228, 0.30477521239688943, 0.2974953704836655, 0.29243092946669086, 0.2881157069636843, 0.2875377287815032, 0.2837230534686214, 0.27565324494773624, 0.2694829915176541, 0.26841564266298634, 0.26346777044145386, 0.2580604543417202, 0.2598786394694989, 0.2515921927766863, 0.24779965976004756, 0.2477957236733435, 0.2499109652541424, 0.24016706273611668, 0.23752981850973243, 0.23499020961747955, 0.23393588554861247, 0.2378744760884828, 0.23571216143696383, 0.2329188952464343, 0.2275669850437717, 0.23347439440629011, 0.22360463808905132, 0.22399951224983009, 0.22726907194609988, 0.22420996672411586, 0.2200176544698711, 0.22081903290781976, 0.21999022575590133, 0.22208041052823305, 0.21639451096117976, 0.2175703905431549, 0.21528762704140247, 0.21522903076503758, 0.21323806337169887, 0.2118498615850132, 0.21460922429579973], 'val_acc': [0.3350542527126356, 0.5984424221211061, 0.6176933846692335, 0.6379068953447672, 0.6571578578928946, 0.6778088904445222, 0.6840217010850542, 0.6915470773538677, 0.6952222611130556, 0.7068603430171508, 0.7113230661533076, 0.7160483024151207, 0.7231361568078404, 0.7268113405670283, 0.7295239761988099, 0.734249212460623, 0.7367868393419671, 0.7414245712285614, 0.7411620581029051, 0.7471123556177809, 0.7473748687434372, 0.7550752537626881, 0.7564753237661883, 0.7605880294014701, 0.7599754987749388, 0.7537626881344067, 0.7640007000350018, 0.767588379418971, 0.7668008400420021, 0.7607630381519076, 0.7711760588029402, 0.7689884494224711, 0.7737136856842842, 0.7745012250612531, 0.7711760588029402, 0.7725761288064403, 0.7715260763038152, 0.7786139306965348, 0.770126006300315, 0.7802765138256913, 0.7789639481974099, 0.7791389569478474, 0.7794889744487224, 0.7820266013300665, 0.7821141057052853, 0.7808015400770039, 0.7825516275813791, 0.7843892194609731, 0.7843017150857543, 0.7863143157157858, 0.7846517325866293, 0.7876268813440672, 0.7872768638431922, 0.786226811340567], 'model_size_bytes': 61441, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.8712062984247893e-05, 'batch_size': 24, 'epochs': 54, 'weight_decay': 0.00024162254846980146, 'dropout': 0.45042749520746955, 'hidden_size': 28, 'd_model': 9, 't_pooled': 192, 'label_smoothing': 0.0085343630677186, 'use_focal_loss': True, 'focal_gamma': 2.3043638970350067, 'grad_clip_norm': 2.832837371590298, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 11042, 'model_storage_size_kb': 47.44609375, 'model_size_validation': 'PASS'}
2025-10-13 08:05:26,022 - INFO - _models.training_function_executor - BO Objective: base=0.7862, size_penalty=0.0000, final=0.7862
2025-10-13 08:05:26,022 - INFO - _models.training_function_executor - Model: 11,042 parameters, 47.4KB (PASS 256KB limit)
2025-10-13 08:05:26,022 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 318.144s
2025-10-13 08:05:26,129 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7862
2025-10-13 08:05:26,129 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.105s
2025-10-13 08:05:26,129 - INFO - bo.run_bo - Recorded observation #34: hparams={'lr': 1.8712062984247893e-05, 'batch_size': np.int64(24), 'epochs': np.int64(54), 'weight_decay': 0.00024162254846980146, 'dropout': 0.45042749520746955, 'hidden_size': np.int64(28), 'd_model': np.int64(9), 't_pooled': np.int64(192), 'label_smoothing': 0.0085343630677186, 'use_focal_loss': np.True_, 'focal_gamma': 2.3043638970350067, 'grad_clip_norm': 2.832837371590298, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7862
2025-10-13 08:05:26,129 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 34: {'lr': 1.8712062984247893e-05, 'batch_size': np.int64(24), 'epochs': np.int64(54), 'weight_decay': 0.00024162254846980146, 'dropout': 0.45042749520746955, 'hidden_size': np.int64(28), 'd_model': np.int64(9), 't_pooled': np.int64(192), 'label_smoothing': 0.0085343630677186, 'use_focal_loss': np.True_, 'focal_gamma': 2.3043638970350067, 'grad_clip_norm': 2.832837371590298, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7862
2025-10-13 08:05:26,129 - INFO - bo.run_bo - üîçBO Trial 35: Using RF surrogate + Expected Improvement
2025-10-13 08:05:26,129 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 08:05:26,129 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 35 (NaN monitoring active)
2025-10-13 08:05:26,129 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 08:05:26,129 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 08:05:26,129 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.8071523841722756e-05, 'batch_size': 8, 'epochs': 95, 'weight_decay': 0.00041031208646193676, 'dropout': 0.0750963926737508, 'hidden_size': 32, 'd_model': 17, 't_pooled': 256, 'label_smoothing': 0.17560069752637247, 'use_focal_loss': False, 'focal_gamma': 0.8482796616197625, 'grad_clip_norm': 1.1421466036233159, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 08:05:26,131 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.8071523841722756e-05, 'batch_size': 8, 'epochs': 95, 'weight_decay': 0.00041031208646193676, 'dropout': 0.0750963926737508, 'hidden_size': 32, 'd_model': 17, 't_pooled': 256, 'label_smoothing': 0.17560069752637247, 'use_focal_loss': False, 'focal_gamma': 0.8482796616197625, 'grad_clip_norm': 1.1421466036233159, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 08:05:43,332 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.4784 | val_loss=1.2768 | val_acc=0.5926 | time=17.2s
2025-10-13 08:05:57,899 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2650 | val_loss=1.1774 | val_acc=0.6318 | time=14.6s
2025-10-13 08:06:12,389 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2272 | val_loss=1.1535 | val_acc=0.6434 | time=14.5s
2025-10-13 08:06:26,813 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.2047 | val_loss=1.1301 | val_acc=0.6538 | time=14.4s
2025-10-13 08:06:41,315 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.1845 | val_loss=1.1138 | val_acc=0.6582 | time=14.5s
2025-10-13 08:06:55,862 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1656 | val_loss=1.1029 | val_acc=0.6620 | time=14.5s
2025-10-13 08:07:10,336 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1533 | val_loss=1.0936 | val_acc=0.6663 | time=14.5s
2025-10-13 08:07:24,649 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1418 | val_loss=1.0843 | val_acc=0.6727 | time=14.3s
2025-10-13 08:07:39,182 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1344 | val_loss=1.0770 | val_acc=0.6802 | time=14.5s
2025-10-13 08:07:53,687 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1229 | val_loss=1.0632 | val_acc=0.7006 | time=14.5s
2025-10-13 08:08:08,203 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.1175 | val_loss=1.0555 | val_acc=0.7092 | time=14.5s
2025-10-13 08:08:22,636 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.1073 | val_loss=1.0432 | val_acc=0.7212 | time=14.4s
2025-10-13 08:08:37,184 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.1008 | val_loss=1.0384 | val_acc=0.7267 | time=14.5s
2025-10-13 08:08:51,708 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.0916 | val_loss=1.0315 | val_acc=0.7300 | time=14.5s
2025-10-13 08:09:06,215 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.0848 | val_loss=1.0257 | val_acc=0.7341 | time=14.5s
2025-10-13 08:09:20,654 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.0771 | val_loss=1.0181 | val_acc=0.7391 | time=14.4s
2025-10-13 08:09:35,143 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.0705 | val_loss=1.0123 | val_acc=0.7419 | time=14.5s
2025-10-13 08:09:49,598 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.0613 | val_loss=1.0078 | val_acc=0.7451 | time=14.5s
2025-10-13 08:10:03,964 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.0582 | val_loss=1.0047 | val_acc=0.7464 | time=14.4s
2025-10-13 08:10:18,383 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0535 | val_loss=0.9989 | val_acc=0.7522 | time=14.4s
2025-10-13 08:10:32,821 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0444 | val_loss=1.0050 | val_acc=0.7440 | time=14.4s
2025-10-13 08:10:47,361 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.0423 | val_loss=0.9919 | val_acc=0.7540 | time=14.5s
2025-10-13 08:11:01,962 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.0379 | val_loss=0.9920 | val_acc=0.7567 | time=14.6s
2025-10-13 08:11:16,374 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.0325 | val_loss=0.9874 | val_acc=0.7561 | time=14.4s
2025-10-13 08:11:30,744 - INFO - _models.training_function_executor - Epoch 025 | train_loss=1.0299 | val_loss=0.9882 | val_acc=0.7573 | time=14.4s
2025-10-13 08:11:45,228 - INFO - _models.training_function_executor - Epoch 026 | train_loss=1.0260 | val_loss=0.9803 | val_acc=0.7630 | time=14.5s
2025-10-13 08:11:59,590 - INFO - _models.training_function_executor - Epoch 027 | train_loss=1.0224 | val_loss=0.9832 | val_acc=0.7566 | time=14.4s
2025-10-13 08:12:14,099 - INFO - _models.training_function_executor - Epoch 028 | train_loss=1.0162 | val_loss=0.9773 | val_acc=0.7609 | time=14.5s
2025-10-13 08:12:28,534 - INFO - _models.training_function_executor - Epoch 029 | train_loss=1.0133 | val_loss=0.9790 | val_acc=0.7607 | time=14.4s
2025-10-13 08:12:42,953 - INFO - _models.training_function_executor - Epoch 030 | train_loss=1.0113 | val_loss=0.9718 | val_acc=0.7636 | time=14.4s
2025-10-13 08:12:57,214 - INFO - _models.training_function_executor - Epoch 031 | train_loss=1.0066 | val_loss=0.9800 | val_acc=0.7651 | time=14.3s
2025-10-13 08:13:11,644 - INFO - _models.training_function_executor - Epoch 032 | train_loss=1.0039 | val_loss=0.9670 | val_acc=0.7694 | time=14.4s
2025-10-13 08:13:26,163 - INFO - _models.training_function_executor - Epoch 033 | train_loss=1.0004 | val_loss=0.9736 | val_acc=0.7693 | time=14.5s
2025-10-13 08:13:40,552 - INFO - _models.training_function_executor - Epoch 034 | train_loss=1.0002 | val_loss=0.9721 | val_acc=0.7648 | time=14.4s
2025-10-13 08:13:55,101 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.9964 | val_loss=0.9603 | val_acc=0.7737 | time=14.5s
2025-10-13 08:14:09,622 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.9937 | val_loss=0.9634 | val_acc=0.7707 | time=14.5s
2025-10-13 08:14:24,254 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.9907 | val_loss=0.9615 | val_acc=0.7717 | time=14.6s
2025-10-13 08:14:38,827 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.9895 | val_loss=0.9556 | val_acc=0.7756 | time=14.6s
2025-10-13 08:14:53,333 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.9843 | val_loss=0.9547 | val_acc=0.7778 | time=14.5s
2025-10-13 08:15:07,864 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.9841 | val_loss=0.9571 | val_acc=0.7745 | time=14.5s
2025-10-13 08:15:22,343 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.9832 | val_loss=0.9505 | val_acc=0.7803 | time=14.5s
2025-10-13 08:15:36,796 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.9783 | val_loss=0.9520 | val_acc=0.7767 | time=14.5s
2025-10-13 08:15:51,281 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.9774 | val_loss=0.9510 | val_acc=0.7791 | time=14.5s
2025-10-13 08:16:05,863 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.9765 | val_loss=0.9463 | val_acc=0.7821 | time=14.6s
2025-10-13 08:16:20,361 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.9722 | val_loss=0.9463 | val_acc=0.7855 | time=14.5s
2025-10-13 08:16:34,918 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.9737 | val_loss=0.9463 | val_acc=0.7840 | time=14.6s
2025-10-13 08:16:49,410 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.9718 | val_loss=0.9456 | val_acc=0.7868 | time=14.5s
2025-10-13 08:17:03,895 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.9692 | val_loss=0.9473 | val_acc=0.7826 | time=14.5s
2025-10-13 08:17:18,419 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.9690 | val_loss=0.9461 | val_acc=0.7847 | time=14.5s
2025-10-13 08:17:32,984 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.9669 | val_loss=0.9455 | val_acc=0.7825 | time=14.6s
2025-10-13 08:17:47,544 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.9664 | val_loss=0.9456 | val_acc=0.7846 | time=14.6s
2025-10-13 08:18:01,795 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.9663 | val_loss=0.9438 | val_acc=0.7849 | time=14.3s
2025-10-13 08:18:16,241 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.9633 | val_loss=0.9389 | val_acc=0.7903 | time=14.4s
2025-10-13 08:18:30,856 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.9590 | val_loss=0.9399 | val_acc=0.7864 | time=14.6s
2025-10-13 08:18:45,381 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.9603 | val_loss=0.9367 | val_acc=0.7903 | time=14.5s
2025-10-13 08:19:00,000 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.9600 | val_loss=0.9400 | val_acc=0.7868 | time=14.6s
2025-10-13 08:19:14,575 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.9597 | val_loss=0.9370 | val_acc=0.7910 | time=14.6s
2025-10-13 08:19:28,946 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.9582 | val_loss=0.9376 | val_acc=0.7908 | time=14.4s
2025-10-13 08:19:43,614 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.9580 | val_loss=0.9408 | val_acc=0.7895 | time=14.7s
2025-10-13 08:19:58,085 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.9549 | val_loss=0.9346 | val_acc=0.7910 | time=14.5s
2025-10-13 08:20:12,590 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.9566 | val_loss=0.9375 | val_acc=0.7909 | time=14.5s
2025-10-13 08:20:27,035 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.9532 | val_loss=0.9379 | val_acc=0.7860 | time=14.4s
2025-10-13 08:20:41,485 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.9532 | val_loss=0.9370 | val_acc=0.7865 | time=14.4s
2025-10-13 08:20:56,057 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.9513 | val_loss=0.9343 | val_acc=0.7916 | time=14.6s
2025-10-13 08:21:10,488 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.9498 | val_loss=0.9344 | val_acc=0.7916 | time=14.4s
2025-10-13 08:21:24,960 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.9508 | val_loss=0.9325 | val_acc=0.7924 | time=14.5s
2025-10-13 08:21:39,469 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.9515 | val_loss=0.9333 | val_acc=0.7931 | time=14.5s
2025-10-13 08:21:53,915 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.9504 | val_loss=0.9335 | val_acc=0.7922 | time=14.4s
2025-10-13 08:22:08,353 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.9493 | val_loss=0.9309 | val_acc=0.7917 | time=14.4s
2025-10-13 08:22:22,882 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.9473 | val_loss=0.9318 | val_acc=0.7915 | time=14.5s
2025-10-13 08:22:37,357 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.9487 | val_loss=0.9391 | val_acc=0.7895 | time=14.5s
2025-10-13 08:22:51,815 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.9489 | val_loss=0.9332 | val_acc=0.7928 | time=14.5s
2025-10-13 08:23:06,321 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.9464 | val_loss=0.9343 | val_acc=0.7922 | time=14.5s
2025-10-13 08:23:20,860 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.9467 | val_loss=0.9302 | val_acc=0.7924 | time=14.5s
2025-10-13 08:23:35,240 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.9450 | val_loss=0.9317 | val_acc=0.7946 | time=14.4s
2025-10-13 08:23:49,750 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.9438 | val_loss=0.9268 | val_acc=0.7969 | time=14.5s
2025-10-13 08:24:04,249 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.9436 | val_loss=0.9286 | val_acc=0.7972 | time=14.5s
2025-10-13 08:24:18,743 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.9442 | val_loss=0.9327 | val_acc=0.7917 | time=14.5s
2025-10-13 08:24:33,202 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.9428 | val_loss=0.9324 | val_acc=0.7904 | time=14.5s
2025-10-13 08:24:47,765 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.9412 | val_loss=0.9259 | val_acc=0.7966 | time=14.6s
2025-10-13 08:25:02,266 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.9426 | val_loss=0.9289 | val_acc=0.7934 | time=14.5s
2025-10-13 08:25:16,808 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.9416 | val_loss=0.9260 | val_acc=0.7947 | time=14.5s
2025-10-13 08:25:31,229 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.9417 | val_loss=0.9297 | val_acc=0.7935 | time=14.4s
2025-10-13 08:25:45,775 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.9401 | val_loss=0.9249 | val_acc=0.7928 | time=14.5s
2025-10-13 08:26:00,306 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.9401 | val_loss=0.9290 | val_acc=0.7925 | time=14.5s
2025-10-13 08:26:14,793 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.9414 | val_loss=0.9244 | val_acc=0.7934 | time=14.5s
2025-10-13 08:26:29,205 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.9385 | val_loss=0.9275 | val_acc=0.7945 | time=14.4s
2025-10-13 08:26:43,699 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.9382 | val_loss=0.9256 | val_acc=0.7948 | time=14.5s
2025-10-13 08:26:58,145 - INFO - _models.training_function_executor - Epoch 089 | train_loss=0.9363 | val_loss=0.9312 | val_acc=0.7917 | time=14.4s
2025-10-13 08:27:12,564 - INFO - _models.training_function_executor - Epoch 090 | train_loss=0.9402 | val_loss=0.9268 | val_acc=0.7959 | time=14.4s
2025-10-13 08:27:26,976 - INFO - _models.training_function_executor - Epoch 091 | train_loss=0.9377 | val_loss=0.9246 | val_acc=0.7963 | time=14.4s
2025-10-13 08:27:41,491 - INFO - _models.training_function_executor - Epoch 092 | train_loss=0.9378 | val_loss=0.9312 | val_acc=0.7924 | time=14.5s
2025-10-13 08:27:55,987 - INFO - _models.training_function_executor - Epoch 093 | train_loss=0.9372 | val_loss=0.9218 | val_acc=0.7956 | time=14.5s
2025-10-13 08:28:10,452 - INFO - _models.training_function_executor - Epoch 094 | train_loss=0.9382 | val_loss=0.9254 | val_acc=0.7976 | time=14.5s
2025-10-13 08:28:24,860 - INFO - _models.training_function_executor - Epoch 095 | train_loss=0.9360 | val_loss=0.9296 | val_acc=0.7938 | time=14.4s
2025-10-13 08:28:24,864 - INFO - _models.training_function_executor - Quantized model size: 76161 bytes.
2025-10-13 08:28:25,963 - INFO - _models.training_function_executor - Model: 14,640 parameters, 62.9KB storage
2025-10-13 08:28:25,963 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4783546148604099, 1.2649701425338233, 1.2271884471271937, 1.2046745776566834, 1.1845304737422364, 1.1655817004217315, 1.1532828751188664, 1.1417875730119305, 1.1343970039131177, 1.122852517678515, 1.117517221837683, 1.1072744355570574, 1.1008357131318443, 1.091581541934045, 1.0847715124367916, 1.0770868995117064, 1.0705432075593786, 1.0613056846774038, 1.058161052981164, 1.053455276916108, 1.0443806728158416, 1.0422668319337636, 1.0378772620558947, 1.0324503178983708, 1.0299404054974024, 1.0260047982070344, 1.0224483401824596, 1.016216844435042, 1.0133409109364284, 1.0113153480381911, 1.0066357813162699, 1.0039327010475843, 1.0004086807803085, 1.000226720202666, 0.9963583787254491, 0.9936722200944117, 0.9906912465007063, 0.9894526261610713, 0.9842737641291139, 0.9841378414635062, 0.9832285628750227, 0.9782822881601972, 0.977402765276468, 0.9765451523049294, 0.972210461280961, 0.9736767723128893, 0.9717576521069677, 0.9692337325623205, 0.96895693247244, 0.9668818177524295, 0.9663673380496078, 0.9663211249954683, 0.9632758314808975, 0.9589721491109837, 0.9602840688206076, 0.9599709046921782, 0.9596738181082486, 0.9582012683977228, 0.9579960817238398, 0.9548614237810875, 0.9565576132377795, 0.9532301850697775, 0.9532455886561928, 0.9512919280071712, 0.9498407805157909, 0.9508235545833502, 0.9515356034781076, 0.9504247397278254, 0.9493435516843939, 0.947338371801343, 0.9486511637687183, 0.9489471008508907, 0.9463751223544621, 0.9467477208882894, 0.9450362697113299, 0.9438433618573906, 0.9435900924691463, 0.9441535618178362, 0.9427777118602748, 0.9411738897938807, 0.9426197338279495, 0.9415784452317851, 0.9417301924820334, 0.9401276121199611, 0.9400648723793564, 0.94144401661491, 0.9384534571255927, 0.9381661807422584, 0.9362738250455199, 0.9401521167222712, 0.9376647398527744, 0.9378112692556725, 0.9372272655227029, 0.9382090683287159, 0.936022670213935], 'val_losses': [1.2767501832056096, 1.1773607016944951, 1.153480225732621, 1.1300682910556012, 1.113844028752627, 1.1028930721142762, 1.0936484968574638, 1.0842834600085431, 1.077039916531206, 1.0632162455457634, 1.0554767904016242, 1.0432069005355327, 1.0383910104491554, 1.031549480356117, 1.025747582592829, 1.0180528339573582, 1.012330573757587, 1.0077774623786397, 1.004667524382665, 0.9988905740944205, 1.0049823479173399, 0.9918683373014285, 0.9920047300446897, 0.9873556502432017, 0.9882176747720977, 0.9803390348963191, 0.9832071735594379, 0.9773332695882555, 0.9789701735259855, 0.9717783244873703, 0.9800244016500466, 0.9669563113537375, 0.9736311831255663, 0.9721255435533026, 0.9603196193924057, 0.963415252231909, 0.961475611692715, 0.9555997209695823, 0.9546806890730012, 0.9570882607474376, 0.9505023503578915, 0.9520278006197482, 0.9509667932131843, 0.9462749898371098, 0.9463114397568347, 0.9463050036652337, 0.9455996801021177, 0.9473470078092127, 0.9461445845546195, 0.9455148902939131, 0.9455643071968071, 0.9438426510454017, 0.938915845310517, 0.9399114469986175, 0.9366974620331739, 0.9400421255820691, 0.9369819363723236, 0.9376223136963943, 0.9407794082919994, 0.9346293530182109, 0.9375324667772714, 0.9378681758253734, 0.9370002712784508, 0.934312631293615, 0.9344069999875745, 0.932527863357632, 0.9332863522193463, 0.9334614807632281, 0.9309140198874148, 0.9317543928048224, 0.9391073426626176, 0.9332314461396631, 0.9343136618260032, 0.9302286044008297, 0.9317169017961987, 0.9267784706311999, 0.9285808451158165, 0.9327449152258505, 0.9323623595973767, 0.9258616815549658, 0.9289037081007779, 0.9259720982310236, 0.9296676941922715, 0.9248500149025548, 0.9290478915070002, 0.9243619199144619, 0.9275203077034555, 0.9256010553742523, 0.9311620587855317, 0.9267590078891972, 0.9246297066638134, 0.9312439407549582, 0.9217884114959418, 0.9253617937347044, 0.9295535516104666], 'val_acc': [0.5925796289814491, 0.6317815890794539, 0.6434196709835491, 0.6538326916345817, 0.6582079103955197, 0.6619705985299265, 0.6662583129156457, 0.6727336366818341, 0.6801715085754287, 0.7005600280014, 0.7092229611480574, 0.7212110605530276, 0.7267238361918096, 0.7300490024501225, 0.7340742037101855, 0.7390619530976549, 0.7418620931046552, 0.7450997549877494, 0.7464123206160308, 0.752187609380469, 0.7439621981099055, 0.754025201260063, 0.7567378368918446, 0.7561253062653133, 0.7572628631431572, 0.7629506475323766, 0.7565628281414071, 0.7609380469023451, 0.7606755337766888, 0.763563178158908, 0.7651382569128456, 0.7694259712985649, 0.7693384669233462, 0.7647882394119706, 0.7737136856842842, 0.7707385369268464, 0.7717010850542527, 0.7755512775638782, 0.777826391319566, 0.7745012250612531, 0.7802765138256913, 0.7766888344417221, 0.7790514525726286, 0.7821141057052853, 0.785526776338817, 0.7839516975848793, 0.7868393419670984, 0.7825516275813791, 0.7847392369618481, 0.7824641232061603, 0.7845642282114106, 0.7849142457122856, 0.79025201260063, 0.7864018200910046, 0.79025201260063, 0.7868393419670984, 0.7910395519775989, 0.7907770388519426, 0.7894644732236612, 0.7910395519775989, 0.7908645432271614, 0.7859642982149108, 0.7864893244662233, 0.7915645782289115, 0.7915645782289115, 0.7924396219810991, 0.7930521526076304, 0.7921771088554428, 0.7916520826041302, 0.7914770738536927, 0.7894644732236612, 0.7927896394819741, 0.7921771088554428, 0.7924396219810991, 0.7946272313615681, 0.7969023451172559, 0.7971648582429122, 0.791739586979349, 0.7904270213510676, 0.7966398319915996, 0.7934021701085054, 0.7947147357367869, 0.7934896744837242, 0.7927896394819741, 0.7925271263563178, 0.7934021701085054, 0.7945397269863493, 0.7948022401120056, 0.791739586979349, 0.7959397969898495, 0.7962898144907246, 0.7923521176058803, 0.7955897794889745, 0.797602380119006, 0.7937521876093805], 'model_size_bytes': 76161, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.8071523841722756e-05, 'batch_size': 8, 'epochs': 95, 'weight_decay': 0.00041031208646193676, 'dropout': 0.0750963926737508, 'hidden_size': 32, 'd_model': 17, 't_pooled': 256, 'label_smoothing': 0.17560069752637247, 'use_focal_loss': False, 'focal_gamma': 0.8482796616197625, 'grad_clip_norm': 1.1421466036233159, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 14640, 'model_storage_size_kb': 62.90625000000001, 'model_size_validation': 'PASS'}
2025-10-13 08:28:25,963 - INFO - _models.training_function_executor - BO Objective: base=0.7938, size_penalty=0.0000, final=0.7938
2025-10-13 08:28:25,963 - INFO - _models.training_function_executor - Model: 14,640 parameters, 62.9KB (PASS 256KB limit)
2025-10-13 08:28:25,963 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 1379.833s
2025-10-13 08:28:26,071 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7938
2025-10-13 08:28:26,071 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-13 08:28:26,071 - INFO - bo.run_bo - Recorded observation #35: hparams={'lr': 1.8071523841722756e-05, 'batch_size': np.int64(8), 'epochs': np.int64(95), 'weight_decay': 0.00041031208646193676, 'dropout': 0.0750963926737508, 'hidden_size': np.int64(32), 'd_model': np.int64(17), 't_pooled': np.int64(256), 'label_smoothing': 0.17560069752637247, 'use_focal_loss': np.False_, 'focal_gamma': 0.8482796616197625, 'grad_clip_norm': 1.1421466036233159, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.7938
2025-10-13 08:28:26,071 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 35: {'lr': 1.8071523841722756e-05, 'batch_size': np.int64(8), 'epochs': np.int64(95), 'weight_decay': 0.00041031208646193676, 'dropout': 0.0750963926737508, 'hidden_size': np.int64(32), 'd_model': np.int64(17), 't_pooled': np.int64(256), 'label_smoothing': 0.17560069752637247, 'use_focal_loss': np.False_, 'focal_gamma': 0.8482796616197625, 'grad_clip_norm': 1.1421466036233159, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.7938
2025-10-13 08:28:26,072 - INFO - bo.run_bo - üîçBO Trial 36: Using RF surrogate + Expected Improvement
2025-10-13 08:28:26,072 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 08:28:26,072 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 36 (NaN monitoring active)
2025-10-13 08:28:26,072 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 08:28:26,072 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 08:28:26,072 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.7995549111091134e-05, 'batch_size': 8, 'epochs': 61, 'weight_decay': 0.002519446581930337, 'dropout': 0.19745262012981551, 'hidden_size': 30, 'd_model': 10, 't_pooled': 192, 'label_smoothing': 0.15318310404983607, 'use_focal_loss': True, 'focal_gamma': 0.7447418159973308, 'grad_clip_norm': 3.739555553293163, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 08:28:26,073 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.7995549111091134e-05, 'batch_size': 8, 'epochs': 61, 'weight_decay': 0.002519446581930337, 'dropout': 0.19745262012981551, 'hidden_size': 30, 'd_model': 10, 't_pooled': 192, 'label_smoothing': 0.15318310404983607, 'use_focal_loss': True, 'focal_gamma': 0.7447418159973308, 'grad_clip_norm': 3.739555553293163, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 08:28:43,851 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.2648 | val_loss=1.0603 | val_acc=0.5510 | time=17.8s
2025-10-13 08:28:58,888 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.0243 | val_loss=0.9157 | val_acc=0.6105 | time=15.0s
2025-10-13 08:29:13,930 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.9554 | val_loss=0.8667 | val_acc=0.6302 | time=15.0s
2025-10-13 08:29:28,950 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9247 | val_loss=0.8319 | val_acc=0.6385 | time=15.0s
2025-10-13 08:29:44,000 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.8984 | val_loss=0.8129 | val_acc=0.6357 | time=15.1s
2025-10-13 08:29:59,052 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.8815 | val_loss=0.7871 | val_acc=0.6453 | time=15.1s
2025-10-13 08:30:14,155 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8651 | val_loss=0.7731 | val_acc=0.6503 | time=15.1s
2025-10-13 08:30:29,285 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.8438 | val_loss=0.7518 | val_acc=0.6584 | time=15.1s
2025-10-13 08:30:44,403 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.8245 | val_loss=0.7409 | val_acc=0.6578 | time=15.1s
2025-10-13 08:30:59,435 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8112 | val_loss=0.7290 | val_acc=0.6650 | time=15.0s
2025-10-13 08:31:14,479 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8003 | val_loss=0.7229 | val_acc=0.6698 | time=15.0s
2025-10-13 08:31:29,463 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.7903 | val_loss=0.7177 | val_acc=0.6618 | time=15.0s
2025-10-13 08:31:44,404 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.7838 | val_loss=0.7050 | val_acc=0.6807 | time=14.9s
2025-10-13 08:31:59,192 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.7774 | val_loss=0.6973 | val_acc=0.6932 | time=14.8s
2025-10-13 08:32:14,252 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.7670 | val_loss=0.6917 | val_acc=0.6932 | time=15.1s
2025-10-13 08:32:29,209 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7617 | val_loss=0.6855 | val_acc=0.7053 | time=15.0s
2025-10-13 08:32:44,167 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.7542 | val_loss=0.6896 | val_acc=0.6851 | time=15.0s
2025-10-13 08:32:59,236 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.7474 | val_loss=0.6838 | val_acc=0.7109 | time=15.1s
2025-10-13 08:33:14,301 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.7451 | val_loss=0.6666 | val_acc=0.7193 | time=15.1s
2025-10-13 08:33:29,167 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.7352 | val_loss=0.6642 | val_acc=0.7172 | time=14.9s
2025-10-13 08:33:44,089 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.7303 | val_loss=0.6619 | val_acc=0.7178 | time=14.9s
2025-10-13 08:33:59,137 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.7203 | val_loss=0.6504 | val_acc=0.7311 | time=15.0s
2025-10-13 08:34:14,183 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.7174 | val_loss=0.6383 | val_acc=0.7399 | time=15.0s
2025-10-13 08:34:29,148 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.7036 | val_loss=0.6315 | val_acc=0.7434 | time=15.0s
2025-10-13 08:34:44,231 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.7029 | val_loss=0.6483 | val_acc=0.7310 | time=15.1s
2025-10-13 08:34:59,261 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.7024 | val_loss=0.6257 | val_acc=0.7475 | time=15.0s
2025-10-13 08:35:14,319 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.6929 | val_loss=0.6199 | val_acc=0.7468 | time=15.1s
2025-10-13 08:35:29,369 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.6883 | val_loss=0.6187 | val_acc=0.7462 | time=15.0s
2025-10-13 08:35:44,418 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.6828 | val_loss=0.6057 | val_acc=0.7528 | time=15.0s
2025-10-13 08:35:59,509 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.6811 | val_loss=0.6029 | val_acc=0.7549 | time=15.1s
2025-10-13 08:36:14,602 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.6800 | val_loss=0.5994 | val_acc=0.7567 | time=15.1s
2025-10-13 08:36:29,693 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.6768 | val_loss=0.6139 | val_acc=0.7478 | time=15.1s
2025-10-13 08:36:44,558 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.6689 | val_loss=0.6008 | val_acc=0.7553 | time=14.9s
2025-10-13 08:36:59,543 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.6694 | val_loss=0.5962 | val_acc=0.7572 | time=15.0s
2025-10-13 08:37:14,581 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.6656 | val_loss=0.5962 | val_acc=0.7574 | time=15.0s
2025-10-13 08:37:29,747 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.6661 | val_loss=0.5885 | val_acc=0.7610 | time=15.2s
2025-10-13 08:37:44,607 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.6607 | val_loss=0.5897 | val_acc=0.7581 | time=14.9s
2025-10-13 08:37:59,496 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.6620 | val_loss=0.5858 | val_acc=0.7602 | time=14.9s
2025-10-13 08:38:14,622 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.6571 | val_loss=0.5839 | val_acc=0.7646 | time=15.1s
2025-10-13 08:38:29,619 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.6509 | val_loss=0.5860 | val_acc=0.7640 | time=15.0s
2025-10-13 08:38:44,700 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.6533 | val_loss=0.5829 | val_acc=0.7619 | time=15.1s
2025-10-13 08:38:59,798 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.6490 | val_loss=0.5925 | val_acc=0.7623 | time=15.1s
2025-10-13 08:39:14,869 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.6485 | val_loss=0.6186 | val_acc=0.7495 | time=15.1s
2025-10-13 08:39:30,029 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.6434 | val_loss=0.5726 | val_acc=0.7651 | time=15.2s
2025-10-13 08:39:45,160 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.6437 | val_loss=0.5798 | val_acc=0.7650 | time=15.1s
2025-10-13 08:40:00,286 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.6393 | val_loss=0.5767 | val_acc=0.7642 | time=15.1s
2025-10-13 08:40:15,455 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.6357 | val_loss=0.5741 | val_acc=0.7661 | time=15.2s
2025-10-13 08:40:30,531 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.6350 | val_loss=0.5732 | val_acc=0.7693 | time=15.1s
2025-10-13 08:40:45,600 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.6337 | val_loss=0.5724 | val_acc=0.7671 | time=15.1s
2025-10-13 08:41:00,531 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.6305 | val_loss=0.5782 | val_acc=0.7668 | time=14.9s
2025-10-13 08:41:15,541 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.6321 | val_loss=0.5764 | val_acc=0.7656 | time=15.0s
2025-10-13 08:41:30,569 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.6256 | val_loss=0.5632 | val_acc=0.7696 | time=15.0s
2025-10-13 08:41:45,582 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.6227 | val_loss=0.5733 | val_acc=0.7639 | time=15.0s
2025-10-13 08:42:00,618 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.6232 | val_loss=0.5643 | val_acc=0.7697 | time=15.0s
2025-10-13 08:42:15,655 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.6215 | val_loss=0.5674 | val_acc=0.7712 | time=15.0s
2025-10-13 08:42:30,535 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.6206 | val_loss=0.5687 | val_acc=0.7660 | time=14.9s
2025-10-13 08:42:45,426 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.6153 | val_loss=0.5692 | val_acc=0.7715 | time=14.9s
2025-10-13 08:43:00,622 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.6132 | val_loss=0.5615 | val_acc=0.7731 | time=15.2s
2025-10-13 08:43:15,622 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.6119 | val_loss=0.5592 | val_acc=0.7722 | time=15.0s
2025-10-13 08:43:30,657 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.6126 | val_loss=0.5612 | val_acc=0.7719 | time=15.0s
2025-10-13 08:43:45,740 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.6081 | val_loss=0.5685 | val_acc=0.7714 | time=15.1s
2025-10-13 08:43:45,744 - INFO - _models.training_function_executor - Quantized model size: 65473 bytes.
2025-10-13 08:43:46,860 - INFO - _models.training_function_executor - Model: 12,101 parameters, 52.0KB storage
2025-10-13 08:43:46,861 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2647521158991304, 1.024297851483681, 0.955354270346314, 0.9247140470797005, 0.8983745962579558, 0.8814804087652791, 0.8650545578060094, 0.8437799449082977, 0.8244700466507917, 0.8112451461674159, 0.8002702884237833, 0.7903077492022956, 0.7838289435297031, 0.7774222774974191, 0.7669559267483519, 0.7617164170816098, 0.7542467333837994, 0.7474321633431308, 0.7450918919000336, 0.7352064561397411, 0.7302970265305289, 0.7202733418101358, 0.7173833667783417, 0.7035770728678231, 0.70285973474931, 0.7023739946167036, 0.6928879749062473, 0.6882972800370735, 0.6827706325724904, 0.6810639057547052, 0.679973765394051, 0.6768135818143303, 0.6689152643553936, 0.669410616334164, 0.6656331393449174, 0.6660989605823951, 0.6607124156047717, 0.6619883406676527, 0.6571365989050979, 0.6508989252064, 0.6532587446676588, 0.6490032396256131, 0.6484858315799217, 0.6434327319647763, 0.6437457191764704, 0.6392744626559116, 0.6357448900944501, 0.6350193470429615, 0.6336508664645784, 0.6305324013221397, 0.6321401774849369, 0.6256124209123639, 0.6227122090879461, 0.6231835167418213, 0.6214578759210757, 0.6206254336577447, 0.6152823608763722, 0.6132157803231137, 0.6118789098486643, 0.6126315298199779, 0.608094597767972], 'val_losses': [1.060300555227518, 0.9156540563609744, 0.8667202811162706, 0.8319486070230034, 0.8129453379289229, 0.7870617210552081, 0.773130154866291, 0.7518054698787872, 0.7408577268529197, 0.729030468871137, 0.7229267473315959, 0.7177370798662904, 0.704957046311011, 0.6972715717889981, 0.6917221572772998, 0.6855062352096363, 0.6895810122418161, 0.6837859751880273, 0.666629907902947, 0.6641614806894076, 0.6619272715965266, 0.6504175653710497, 0.6382625886285727, 0.6315105155835337, 0.6482974539322164, 0.6256953154175191, 0.6198754838433431, 0.6187416329995543, 0.60569781876545, 0.6028636930328505, 0.5993869827371149, 0.6139033764006168, 0.6007752422586287, 0.5961738513990595, 0.5961684622066106, 0.588507611172826, 0.5897332203578064, 0.5858100062281175, 0.5839142695011941, 0.5860159036148918, 0.5829401659431431, 0.5925491175213017, 0.6185667066410117, 0.5726261294551525, 0.579782497373794, 0.57667771891401, 0.5740607546725222, 0.5732291826302245, 0.5724224955584146, 0.578173532711696, 0.5764161572773056, 0.563215127849145, 0.5732557934806362, 0.5643365216090372, 0.5674488466176947, 0.5687429001479871, 0.5691762638073264, 0.5614893256647836, 0.5592404773206531, 0.5611810070111445, 0.5684509917149646], 'val_acc': [0.5510150507525376, 0.6105180259012951, 0.6302065103255162, 0.6385194259712985, 0.6357192859642982, 0.6452572628631431, 0.6503325166258312, 0.6583829191459573, 0.6577703885194259, 0.6650332516625831, 0.669845992299615, 0.6617955897794889, 0.6806965348267413, 0.6932096604830241, 0.6932096604830241, 0.7052852642632131, 0.6850717535876794, 0.7108855442772138, 0.7192859642982149, 0.7171858592929646, 0.717798389919496, 0.7310990549527476, 0.7399369968498425, 0.7434371718585929, 0.7310115505775289, 0.7475498774938747, 0.7468498424921246, 0.7462373118655933, 0.7528001400070004, 0.7549002450122506, 0.7566503325166258, 0.747812390619531, 0.7552502625131257, 0.7571753587679384, 0.7573503675183759, 0.7610255512775639, 0.758050402520126, 0.7601505075253763, 0.7646132306615331, 0.7640007000350018, 0.7619005950297515, 0.7623381169058453, 0.7494749737486874, 0.7650507525376269, 0.7649632481624081, 0.7641757087854393, 0.766100805040252, 0.7692509625481274, 0.7670633531676584, 0.7668008400420021, 0.7655757787889395, 0.7696009800490025, 0.763913195659783, 0.7696884844242212, 0.7711760588029402, 0.7660133006650333, 0.7715260763038152, 0.7731011550577529, 0.7722261113055653, 0.7718760938046902, 0.7713510675533777], 'model_size_bytes': 65473, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.7995549111091134e-05, 'batch_size': 8, 'epochs': 61, 'weight_decay': 0.002519446581930337, 'dropout': 0.19745262012981551, 'hidden_size': 30, 'd_model': 10, 't_pooled': 192, 'label_smoothing': 0.15318310404983607, 'use_focal_loss': True, 'focal_gamma': 0.7447418159973308, 'grad_clip_norm': 3.739555553293163, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 12101, 'model_storage_size_kb': 51.996484375, 'model_size_validation': 'PASS'}
2025-10-13 08:43:46,861 - INFO - _models.training_function_executor - BO Objective: base=0.7714, size_penalty=0.0000, final=0.7714
2025-10-13 08:43:46,861 - INFO - _models.training_function_executor - Model: 12,101 parameters, 52.0KB (PASS 256KB limit)
2025-10-13 08:43:46,861 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 920.789s
2025-10-13 08:43:46,966 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7714
2025-10-13 08:43:46,966 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.104s
2025-10-13 08:43:46,966 - INFO - bo.run_bo - Recorded observation #36: hparams={'lr': 1.7995549111091134e-05, 'batch_size': np.int64(8), 'epochs': np.int64(61), 'weight_decay': 0.002519446581930337, 'dropout': 0.19745262012981551, 'hidden_size': np.int64(30), 'd_model': np.int64(10), 't_pooled': np.int64(192), 'label_smoothing': 0.15318310404983607, 'use_focal_loss': np.True_, 'focal_gamma': 0.7447418159973308, 'grad_clip_norm': 3.739555553293163, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7714
2025-10-13 08:43:46,966 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 36: {'lr': 1.7995549111091134e-05, 'batch_size': np.int64(8), 'epochs': np.int64(61), 'weight_decay': 0.002519446581930337, 'dropout': 0.19745262012981551, 'hidden_size': np.int64(30), 'd_model': np.int64(10), 't_pooled': np.int64(192), 'label_smoothing': 0.15318310404983607, 'use_focal_loss': np.True_, 'focal_gamma': 0.7447418159973308, 'grad_clip_norm': 3.739555553293163, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7714
2025-10-13 08:43:46,967 - INFO - bo.run_bo - üîçBO Trial 37: Using RF surrogate + Expected Improvement
2025-10-13 08:43:46,967 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 08:43:46,967 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 37 (NaN monitoring active)
2025-10-13 08:43:46,967 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 08:43:46,967 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 08:43:46,967 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.7955041749777162e-05, 'batch_size': 16, 'epochs': 91, 'weight_decay': 0.0006206942299224536, 'dropout': 0.40591203636079265, 'hidden_size': 27, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.17515103137712967, 'use_focal_loss': True, 'focal_gamma': 4.912875119510988, 'grad_clip_norm': 0.3607439469941743, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 08:43:46,968 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.7955041749777162e-05, 'batch_size': 16, 'epochs': 91, 'weight_decay': 0.0006206942299224536, 'dropout': 0.40591203636079265, 'hidden_size': 27, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.17515103137712967, 'use_focal_loss': True, 'focal_gamma': 4.912875119510988, 'grad_clip_norm': 0.3607439469941743, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 08:43:57,318 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.4805 | val_loss=0.3979 | val_acc=0.5420 | time=10.3s
2025-10-13 08:44:04,837 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.3354 | val_loss=0.2679 | val_acc=0.6073 | time=7.5s
2025-10-13 08:44:12,313 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.2690 | val_loss=0.2195 | val_acc=0.6403 | time=7.5s
2025-10-13 08:44:19,861 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.2427 | val_loss=0.2031 | val_acc=0.6586 | time=7.5s
2025-10-13 08:44:27,390 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.2300 | val_loss=0.1861 | val_acc=0.6738 | time=7.5s
2025-10-13 08:44:34,901 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.2200 | val_loss=0.1776 | val_acc=0.6832 | time=7.5s
2025-10-13 08:44:42,432 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.2102 | val_loss=0.1750 | val_acc=0.6830 | time=7.5s
2025-10-13 08:44:49,902 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.2053 | val_loss=0.1659 | val_acc=0.7020 | time=7.5s
2025-10-13 08:44:57,422 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.2006 | val_loss=0.1659 | val_acc=0.6979 | time=7.5s
2025-10-13 08:45:04,927 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.1947 | val_loss=0.1581 | val_acc=0.7244 | time=7.5s
2025-10-13 08:45:12,414 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.1890 | val_loss=0.1565 | val_acc=0.7216 | time=7.5s
2025-10-13 08:45:19,921 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.1860 | val_loss=0.1509 | val_acc=0.7342 | time=7.5s
2025-10-13 08:45:27,436 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.1812 | val_loss=0.1481 | val_acc=0.7359 | time=7.5s
2025-10-13 08:45:34,921 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.1797 | val_loss=0.1460 | val_acc=0.7357 | time=7.5s
2025-10-13 08:45:42,434 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.1748 | val_loss=0.1433 | val_acc=0.7398 | time=7.5s
2025-10-13 08:45:49,940 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.1705 | val_loss=0.1405 | val_acc=0.7426 | time=7.5s
2025-10-13 08:45:57,408 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.1691 | val_loss=0.1374 | val_acc=0.7457 | time=7.5s
2025-10-13 08:46:04,884 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.1659 | val_loss=0.1396 | val_acc=0.7399 | time=7.5s
2025-10-13 08:46:12,347 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.1629 | val_loss=0.1308 | val_acc=0.7540 | time=7.5s
2025-10-13 08:46:19,824 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.1591 | val_loss=0.1295 | val_acc=0.7515 | time=7.5s
2025-10-13 08:46:27,317 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.1572 | val_loss=0.1269 | val_acc=0.7561 | time=7.5s
2025-10-13 08:46:34,822 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.1543 | val_loss=0.1281 | val_acc=0.7539 | time=7.5s
2025-10-13 08:46:42,319 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.1530 | val_loss=0.1203 | val_acc=0.7659 | time=7.5s
2025-10-13 08:46:49,822 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.1507 | val_loss=0.1201 | val_acc=0.7658 | time=7.5s
2025-10-13 08:46:57,357 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.1495 | val_loss=0.1167 | val_acc=0.7701 | time=7.5s
2025-10-13 08:47:04,875 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.1473 | val_loss=0.1158 | val_acc=0.7738 | time=7.5s
2025-10-13 08:47:12,446 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.1448 | val_loss=0.1145 | val_acc=0.7719 | time=7.6s
2025-10-13 08:47:19,967 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.1438 | val_loss=0.1120 | val_acc=0.7771 | time=7.5s
2025-10-13 08:47:27,489 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.1421 | val_loss=0.1114 | val_acc=0.7762 | time=7.5s
2025-10-13 08:47:35,056 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.1412 | val_loss=0.1106 | val_acc=0.7767 | time=7.6s
2025-10-13 08:47:42,474 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.1398 | val_loss=0.1105 | val_acc=0.7784 | time=7.4s
2025-10-13 08:47:49,991 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.1395 | val_loss=0.1104 | val_acc=0.7768 | time=7.5s
2025-10-13 08:47:57,502 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.1372 | val_loss=0.1081 | val_acc=0.7777 | time=7.5s
2025-10-13 08:48:05,058 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.1393 | val_loss=0.1083 | val_acc=0.7793 | time=7.6s
2025-10-13 08:48:12,600 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.1381 | val_loss=0.1072 | val_acc=0.7824 | time=7.5s
2025-10-13 08:48:20,104 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.1341 | val_loss=0.1071 | val_acc=0.7811 | time=7.5s
2025-10-13 08:48:27,692 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.1371 | val_loss=0.1069 | val_acc=0.7806 | time=7.6s
2025-10-13 08:48:35,155 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.1357 | val_loss=0.1065 | val_acc=0.7807 | time=7.5s
2025-10-13 08:48:42,662 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.1352 | val_loss=0.1052 | val_acc=0.7828 | time=7.5s
2025-10-13 08:48:50,138 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.1331 | val_loss=0.1041 | val_acc=0.7824 | time=7.5s
2025-10-13 08:48:57,653 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.1332 | val_loss=0.1050 | val_acc=0.7798 | time=7.5s
2025-10-13 08:49:05,180 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.1337 | val_loss=0.1048 | val_acc=0.7833 | time=7.5s
2025-10-13 08:49:12,685 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.1331 | val_loss=0.1047 | val_acc=0.7821 | time=7.5s
2025-10-13 08:49:20,257 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.1309 | val_loss=0.1045 | val_acc=0.7854 | time=7.6s
2025-10-13 08:49:27,751 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.1314 | val_loss=0.1092 | val_acc=0.7724 | time=7.5s
2025-10-13 08:49:35,256 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.1308 | val_loss=0.1041 | val_acc=0.7838 | time=7.5s
2025-10-13 08:49:42,728 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.1291 | val_loss=0.1035 | val_acc=0.7861 | time=7.5s
2025-10-13 08:49:50,259 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.1293 | val_loss=0.1021 | val_acc=0.7864 | time=7.5s
2025-10-13 08:49:57,772 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.1296 | val_loss=0.1026 | val_acc=0.7847 | time=7.5s
2025-10-13 08:50:05,274 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.1300 | val_loss=0.1043 | val_acc=0.7817 | time=7.5s
2025-10-13 08:50:12,767 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.1293 | val_loss=0.1032 | val_acc=0.7837 | time=7.5s
2025-10-13 08:50:20,305 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.1284 | val_loss=0.1026 | val_acc=0.7858 | time=7.5s
2025-10-13 08:50:27,855 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.1291 | val_loss=0.1027 | val_acc=0.7868 | time=7.5s
2025-10-13 08:50:35,352 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.1260 | val_loss=0.1014 | val_acc=0.7859 | time=7.5s
2025-10-13 08:50:42,861 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.1273 | val_loss=0.1010 | val_acc=0.7863 | time=7.5s
2025-10-13 08:50:50,372 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.1278 | val_loss=0.1008 | val_acc=0.7878 | time=7.5s
2025-10-13 08:50:57,882 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.1258 | val_loss=0.1014 | val_acc=0.7867 | time=7.5s
2025-10-13 08:51:05,382 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.1261 | val_loss=0.1000 | val_acc=0.7891 | time=7.5s
2025-10-13 08:51:12,887 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.1265 | val_loss=0.1006 | val_acc=0.7886 | time=7.5s
2025-10-13 08:51:20,358 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.1250 | val_loss=0.1002 | val_acc=0.7913 | time=7.5s
2025-10-13 08:51:27,824 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.1253 | val_loss=0.1017 | val_acc=0.7875 | time=7.5s
2025-10-13 08:51:35,298 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.1242 | val_loss=0.1032 | val_acc=0.7874 | time=7.5s
2025-10-13 08:51:42,790 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.1246 | val_loss=0.1027 | val_acc=0.7864 | time=7.5s
2025-10-13 08:51:50,297 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.1227 | val_loss=0.0993 | val_acc=0.7912 | time=7.5s
2025-10-13 08:51:57,791 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.1235 | val_loss=0.0997 | val_acc=0.7914 | time=7.5s
2025-10-13 08:52:05,321 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.1240 | val_loss=0.1011 | val_acc=0.7886 | time=7.5s
2025-10-13 08:52:12,789 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.1242 | val_loss=0.0992 | val_acc=0.7911 | time=7.5s
2025-10-13 08:52:20,307 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.1224 | val_loss=0.1002 | val_acc=0.7904 | time=7.5s
2025-10-13 08:52:27,790 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.1240 | val_loss=0.1013 | val_acc=0.7900 | time=7.5s
2025-10-13 08:52:35,286 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.1226 | val_loss=0.0994 | val_acc=0.7924 | time=7.5s
2025-10-13 08:52:42,794 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.1217 | val_loss=0.0996 | val_acc=0.7903 | time=7.5s
2025-10-13 08:52:50,294 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.1223 | val_loss=0.0982 | val_acc=0.7924 | time=7.5s
2025-10-13 08:52:57,817 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.1220 | val_loss=0.1005 | val_acc=0.7906 | time=7.5s
2025-10-13 08:53:05,356 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.1214 | val_loss=0.0993 | val_acc=0.7910 | time=7.5s
2025-10-13 08:53:12,847 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.1201 | val_loss=0.0985 | val_acc=0.7910 | time=7.5s
2025-10-13 08:53:20,351 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.1198 | val_loss=0.0970 | val_acc=0.7909 | time=7.5s
2025-10-13 08:53:27,850 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.1219 | val_loss=0.1005 | val_acc=0.7906 | time=7.5s
2025-10-13 08:53:35,332 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.1207 | val_loss=0.0993 | val_acc=0.7910 | time=7.5s
2025-10-13 08:53:42,882 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.1210 | val_loss=0.0979 | val_acc=0.7917 | time=7.5s
2025-10-13 08:53:50,417 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.1204 | val_loss=0.0960 | val_acc=0.7938 | time=7.5s
2025-10-13 08:53:57,913 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.1206 | val_loss=0.0996 | val_acc=0.7922 | time=7.5s
2025-10-13 08:54:05,391 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.1196 | val_loss=0.0984 | val_acc=0.7931 | time=7.5s
2025-10-13 08:54:12,892 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.1197 | val_loss=0.0980 | val_acc=0.7924 | time=7.5s
2025-10-13 08:54:20,403 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.1182 | val_loss=0.0982 | val_acc=0.7896 | time=7.5s
2025-10-13 08:54:27,900 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.1183 | val_loss=0.0966 | val_acc=0.7964 | time=7.5s
2025-10-13 08:54:35,457 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.1166 | val_loss=0.0981 | val_acc=0.7929 | time=7.6s
2025-10-13 08:54:42,993 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.1177 | val_loss=0.0977 | val_acc=0.7931 | time=7.5s
2025-10-13 08:54:50,521 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.1182 | val_loss=0.0988 | val_acc=0.7910 | time=7.5s
2025-10-13 08:54:58,069 - INFO - _models.training_function_executor - Epoch 089 | train_loss=0.1187 | val_loss=0.0987 | val_acc=0.7900 | time=7.5s
2025-10-13 08:55:05,598 - INFO - _models.training_function_executor - Epoch 090 | train_loss=0.1183 | val_loss=0.0966 | val_acc=0.7949 | time=7.5s
2025-10-13 08:55:13,129 - INFO - _models.training_function_executor - Epoch 091 | train_loss=0.1184 | val_loss=0.0951 | val_acc=0.7954 | time=7.5s
2025-10-13 08:55:13,134 - INFO - _models.training_function_executor - Quantized model size: 42433 bytes.
2025-10-13 08:55:14,242 - INFO - _models.training_function_executor - Model: 12,644 parameters, 27.2KB storage
2025-10-13 08:55:14,243 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.4804944881597598, 0.3354031268401625, 0.26900700090135526, 0.2427493110116562, 0.22999938472317866, 0.21997905801883894, 0.2101569611684797, 0.20534183885439275, 0.2005795305089534, 0.19466790824210597, 0.18896562791513236, 0.18600946445230593, 0.18122090006786332, 0.17967699644229798, 0.1747630051486155, 0.17047789990954104, 0.1691107854799954, 0.16585564082061385, 0.16290798671621834, 0.15914466501515792, 0.15721289144739597, 0.15425186096646587, 0.15304620290226584, 0.15074856660863736, 0.14949095975588075, 0.14731154616858247, 0.14476385701801087, 0.14376891088255705, 0.1420781421920074, 0.14117753062896643, 0.13979936672826412, 0.13948881682653944, 0.13717378532832783, 0.13931867757816707, 0.13807962448614897, 0.13408824059548946, 0.1371293499900206, 0.13569636739553126, 0.13515953949333478, 0.1330546674500834, 0.13323820443510342, 0.1337024309503884, 0.1331313782602048, 0.13089484949444646, 0.1314068081253135, 0.1308241201698973, 0.12907838486434906, 0.12928824073129447, 0.12955517262985783, 0.12995806757144246, 0.12934418454131266, 0.12843576143862465, 0.1291229959028373, 0.12600396272469158, 0.12732154318504102, 0.12781173055962192, 0.12583024580472357, 0.12614548951582993, 0.12646874412926848, 0.12497185541614812, 0.1252833009209506, 0.12418598426120615, 0.1246460982258368, 0.12271839003660512, 0.12351157772721508, 0.12396925029931294, 0.12421100421120518, 0.12237526828277756, 0.12398955273015916, 0.12260834834811245, 0.12172612140465647, 0.12234962283867376, 0.12197596965130128, 0.12137616005435059, 0.12009694960488591, 0.11979412078684001, 0.12185209715855592, 0.12074886577508334, 0.12101657085458392, 0.12037086423641637, 0.12061458706789274, 0.1195927762785339, 0.11974083679497742, 0.11824047515096418, 0.1182949205320674, 0.1165589464562373, 0.11773259035843964, 0.11816765814543678, 0.11866952786104748, 0.11831432949499959, 0.11838645073084834], 'val_losses': [0.39791260559032293, 0.26785663833224277, 0.21950348462723, 0.2030582985429026, 0.18610569350695252, 0.1776469083497021, 0.17495313898057507, 0.165949535517998, 0.16590122054476064, 0.15811942428569506, 0.15650042454951035, 0.15087864478338753, 0.14811819125753123, 0.14597108734313283, 0.1432802865283657, 0.14051509107957572, 0.13742083180167686, 0.1395712478264337, 0.13083084248916477, 0.12946178747153925, 0.12690657487815188, 0.12808192326528525, 0.1203352745425505, 0.12006698548793793, 0.11669934217354865, 0.11581146481844942, 0.11452371988277316, 0.11195509268983411, 0.1113807112056766, 0.11062723188278013, 0.11046960322192219, 0.11041776364682895, 0.10814902064086342, 0.10826602473849803, 0.1072333132731443, 0.10707574976640104, 0.10692717271081459, 0.10645468544252777, 0.10515570444194094, 0.10405035029300076, 0.10496915702010144, 0.10484681929121661, 0.10474137992897692, 0.10454335958965183, 0.1091996284503598, 0.10406022904441413, 0.10346341376689334, 0.10209121030785005, 0.1025860503858355, 0.10427100191301593, 0.10323705359782252, 0.10256988198962877, 0.10273685426271, 0.10141765210082533, 0.10095215424514543, 0.10080585247091492, 0.10135628693366451, 0.10001924503196942, 0.10062115443730255, 0.10018743008589011, 0.10171632448880874, 0.10316901834336745, 0.1026982965992909, 0.09932359567744606, 0.0997031217204302, 0.10110494718451078, 0.0991812283743667, 0.10022827293260932, 0.10128535915102248, 0.09940072998279327, 0.09963736315947293, 0.09820533547997683, 0.10047216566737857, 0.09927648421680756, 0.0984989492562337, 0.09703402495807728, 0.10050955150989666, 0.09928285897607397, 0.09788764356435034, 0.09601206136988016, 0.09959111359696686, 0.09835910794641699, 0.0979707017175835, 0.09817054247340833, 0.09661777647806082, 0.09807801961580648, 0.09768149080612273, 0.09884829165027365, 0.09870226701573555, 0.09661695133082342, 0.095128760026037], 'val_acc': [0.5420021001050053, 0.607280364018201, 0.6402695134756737, 0.6585579278963948, 0.6737836891844592, 0.6832341617080854, 0.6829716485824291, 0.7019600980049002, 0.6979348967448372, 0.7244487224361218, 0.7216485824291214, 0.7341617080854043, 0.7359117955897795, 0.735736786839342, 0.7398494924746237, 0.7426496324816241, 0.7457122856142807, 0.7399369968498425, 0.754025201260063, 0.7514875743787189, 0.7561253062653133, 0.7539376968848442, 0.7659257962898145, 0.7658382919145957, 0.770126006300315, 0.773801190059503, 0.7718760938046902, 0.7771263563178159, 0.7761638081904095, 0.7766888344417221, 0.7783514175708786, 0.7767763388169409, 0.7777388869443472, 0.7793139656982849, 0.7823766188309416, 0.7810640532026601, 0.7806265313265663, 0.7807140357017851, 0.7828141407070354, 0.7823766188309416, 0.7797514875743787, 0.7833391669583479, 0.7821141057052853, 0.7854392719635982, 0.7724011200560028, 0.7837766888344417, 0.7860518025901295, 0.7864018200910046, 0.7847392369618481, 0.7816765838291915, 0.783689184459223, 0.7857892894644732, 0.7867518375918796, 0.785876793839692, 0.7863143157157858, 0.7878018900945047, 0.7866643332166608, 0.7891144557227862, 0.7885894294714736, 0.7913020651032552, 0.7875393769688485, 0.7873643682184109, 0.7864018200910046, 0.7912145607280364, 0.7913895694784739, 0.7885894294714736, 0.7911270563528177, 0.7904270213510676, 0.7899894994749738, 0.7923521176058803, 0.7903395169758488, 0.7924396219810991, 0.7906020301015051, 0.7910395519775989, 0.7910395519775989, 0.7908645432271614, 0.7906020301015051, 0.7909520476023801, 0.791739586979349, 0.7938396919845992, 0.7921771088554428, 0.7931396569828492, 0.7924396219810991, 0.78955197759888, 0.7963773188659433, 0.7928771438571929, 0.7930521526076304, 0.7910395519775989, 0.7899894994749738, 0.7948897444872244, 0.795414770738537], 'model_size_bytes': 42433, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.7955041749777162e-05, 'batch_size': 16, 'epochs': 91, 'weight_decay': 0.0006206942299224536, 'dropout': 0.40591203636079265, 'hidden_size': 27, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.17515103137712967, 'use_focal_loss': True, 'focal_gamma': 4.912875119510988, 'grad_clip_norm': 0.3607439469941743, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 12644, 'model_storage_size_kb': 27.164843750000003, 'model_size_validation': 'PASS'}
2025-10-13 08:55:14,243 - INFO - _models.training_function_executor - BO Objective: base=0.7954, size_penalty=0.0000, final=0.7954
2025-10-13 08:55:14,243 - INFO - _models.training_function_executor - Model: 12,644 parameters, 27.2KB (PASS 256KB limit)
2025-10-13 08:55:14,243 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 687.276s
2025-10-13 08:55:14,349 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7954
2025-10-13 08:55:14,349 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.105s
2025-10-13 08:55:14,349 - INFO - bo.run_bo - Recorded observation #37: hparams={'lr': 1.7955041749777162e-05, 'batch_size': np.int64(16), 'epochs': np.int64(91), 'weight_decay': 0.0006206942299224536, 'dropout': 0.40591203636079265, 'hidden_size': np.int64(27), 'd_model': np.int64(19), 't_pooled': np.int64(128), 'label_smoothing': 0.17515103137712967, 'use_focal_loss': np.True_, 'focal_gamma': 4.912875119510988, 'grad_clip_norm': 0.3607439469941743, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7954
2025-10-13 08:55:14,349 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 37: {'lr': 1.7955041749777162e-05, 'batch_size': np.int64(16), 'epochs': np.int64(91), 'weight_decay': 0.0006206942299224536, 'dropout': 0.40591203636079265, 'hidden_size': np.int64(27), 'd_model': np.int64(19), 't_pooled': np.int64(128), 'label_smoothing': 0.17515103137712967, 'use_focal_loss': np.True_, 'focal_gamma': 4.912875119510988, 'grad_clip_norm': 0.3607439469941743, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7954
2025-10-13 08:55:14,349 - INFO - bo.run_bo - üîçBO Trial 38: Using RF surrogate + Expected Improvement
2025-10-13 08:55:14,350 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 08:55:14,350 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 38 (NaN monitoring active)
2025-10-13 08:55:14,350 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 08:55:14,350 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 08:55:14,350 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.7692072464294852e-05, 'batch_size': 16, 'epochs': 79, 'weight_decay': 0.00018924638294399155, 'dropout': 0.2627123638082337, 'hidden_size': 11, 'd_model': 24, 't_pooled': 192, 'label_smoothing': 0.07364732651577949, 'use_focal_loss': False, 'focal_gamma': 1.8418559948146698, 'grad_clip_norm': 4.371925757771646, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 08:55:14,351 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.7692072464294852e-05, 'batch_size': 16, 'epochs': 79, 'weight_decay': 0.00018924638294399155, 'dropout': 0.2627123638082337, 'hidden_size': 11, 'd_model': 24, 't_pooled': 192, 'label_smoothing': 0.07364732651577949, 'use_focal_loss': False, 'focal_gamma': 1.8418559948146698, 'grad_clip_norm': 4.371925757771646, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 08:55:24,484 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5241 | val_loss=1.4137 | val_acc=0.4385 | time=10.1s
2025-10-13 08:55:31,740 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3427 | val_loss=1.2373 | val_acc=0.5916 | time=7.3s
2025-10-13 08:55:38,966 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2160 | val_loss=1.1332 | val_acc=0.6320 | time=7.2s
2025-10-13 08:55:46,257 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.1439 | val_loss=1.0808 | val_acc=0.6329 | time=7.3s
2025-10-13 08:55:53,535 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0960 | val_loss=1.0398 | val_acc=0.6369 | time=7.3s
2025-10-13 08:56:00,813 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0672 | val_loss=0.9995 | val_acc=0.6495 | time=7.3s
2025-10-13 08:56:08,093 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.0434 | val_loss=0.9798 | val_acc=0.6530 | time=7.3s
2025-10-13 08:56:15,420 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.0245 | val_loss=0.9564 | val_acc=0.6644 | time=7.3s
2025-10-13 08:56:22,716 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.0087 | val_loss=0.9375 | val_acc=0.6677 | time=7.3s
2025-10-13 08:56:29,999 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9912 | val_loss=0.9228 | val_acc=0.6774 | time=7.3s
2025-10-13 08:56:37,268 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.9778 | val_loss=0.9087 | val_acc=0.6988 | time=7.3s
2025-10-13 08:56:44,514 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9661 | val_loss=0.8927 | val_acc=0.7075 | time=7.2s
2025-10-13 08:56:51,756 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9491 | val_loss=0.8850 | val_acc=0.7105 | time=7.2s
2025-10-13 08:56:59,013 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.9379 | val_loss=0.8711 | val_acc=0.7354 | time=7.3s
2025-10-13 08:57:06,252 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.9262 | val_loss=0.8568 | val_acc=0.7401 | time=7.2s
2025-10-13 08:57:13,540 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.9148 | val_loss=0.8474 | val_acc=0.7469 | time=7.3s
2025-10-13 08:57:20,769 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.9044 | val_loss=0.8420 | val_acc=0.7473 | time=7.2s
2025-10-13 08:57:28,044 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.8973 | val_loss=0.8313 | val_acc=0.7481 | time=7.3s
2025-10-13 08:57:35,310 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.8872 | val_loss=0.8243 | val_acc=0.7508 | time=7.3s
2025-10-13 08:57:42,609 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8859 | val_loss=0.8191 | val_acc=0.7538 | time=7.3s
2025-10-13 08:57:49,883 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8749 | val_loss=0.8141 | val_acc=0.7542 | time=7.3s
2025-10-13 08:57:57,112 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8700 | val_loss=0.8133 | val_acc=0.7542 | time=7.2s
2025-10-13 08:58:04,418 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8674 | val_loss=0.8108 | val_acc=0.7563 | time=7.3s
2025-10-13 08:58:11,685 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8653 | val_loss=0.8059 | val_acc=0.7580 | time=7.3s
2025-10-13 08:58:18,965 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8640 | val_loss=0.7966 | val_acc=0.7606 | time=7.3s
2025-10-13 08:58:26,197 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8571 | val_loss=0.7940 | val_acc=0.7630 | time=7.2s
2025-10-13 08:58:33,393 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8548 | val_loss=0.7927 | val_acc=0.7608 | time=7.2s
2025-10-13 08:58:40,662 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8519 | val_loss=0.7908 | val_acc=0.7651 | time=7.3s
2025-10-13 08:58:47,910 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8492 | val_loss=0.7913 | val_acc=0.7630 | time=7.2s
2025-10-13 08:58:55,151 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8472 | val_loss=0.7847 | val_acc=0.7671 | time=7.2s
2025-10-13 08:59:02,389 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8487 | val_loss=0.7832 | val_acc=0.7683 | time=7.2s
2025-10-13 08:59:09,699 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.8406 | val_loss=0.7818 | val_acc=0.7686 | time=7.3s
2025-10-13 08:59:17,030 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.8409 | val_loss=0.7867 | val_acc=0.7637 | time=7.3s
2025-10-13 08:59:24,309 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.8401 | val_loss=0.7820 | val_acc=0.7661 | time=7.3s
2025-10-13 08:59:31,606 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.8354 | val_loss=0.7747 | val_acc=0.7711 | time=7.3s
2025-10-13 08:59:38,902 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.8326 | val_loss=0.7725 | val_acc=0.7721 | time=7.3s
2025-10-13 08:59:46,171 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.8303 | val_loss=0.7719 | val_acc=0.7728 | time=7.3s
2025-10-13 08:59:53,400 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.8304 | val_loss=0.7706 | val_acc=0.7746 | time=7.2s
2025-10-13 09:00:00,651 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.8280 | val_loss=0.7682 | val_acc=0.7738 | time=7.3s
2025-10-13 09:00:07,975 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.8280 | val_loss=0.7684 | val_acc=0.7730 | time=7.3s
2025-10-13 09:00:15,262 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.8246 | val_loss=0.7695 | val_acc=0.7707 | time=7.3s
2025-10-13 09:00:22,530 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.8243 | val_loss=0.7648 | val_acc=0.7741 | time=7.3s
2025-10-13 09:00:29,784 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.8254 | val_loss=0.7748 | val_acc=0.7708 | time=7.3s
2025-10-13 09:00:37,053 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.8231 | val_loss=0.7635 | val_acc=0.7777 | time=7.3s
2025-10-13 09:00:44,309 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.8215 | val_loss=0.7616 | val_acc=0.7774 | time=7.3s
2025-10-13 09:00:51,610 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.8202 | val_loss=0.7622 | val_acc=0.7755 | time=7.3s
2025-10-13 09:00:58,907 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.8183 | val_loss=0.7606 | val_acc=0.7761 | time=7.3s
2025-10-13 09:01:06,157 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.8197 | val_loss=0.7676 | val_acc=0.7749 | time=7.2s
2025-10-13 09:01:13,416 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.8142 | val_loss=0.7595 | val_acc=0.7793 | time=7.3s
2025-10-13 09:01:20,708 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.8127 | val_loss=0.7539 | val_acc=0.7793 | time=7.3s
2025-10-13 09:01:27,930 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.8135 | val_loss=0.7555 | val_acc=0.7800 | time=7.2s
2025-10-13 09:01:35,218 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.8109 | val_loss=0.7529 | val_acc=0.7806 | time=7.3s
2025-10-13 09:01:42,411 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.8139 | val_loss=0.7539 | val_acc=0.7815 | time=7.2s
2025-10-13 09:01:49,709 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.8063 | val_loss=0.7511 | val_acc=0.7805 | time=7.3s
2025-10-13 09:01:56,962 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.8070 | val_loss=0.7538 | val_acc=0.7786 | time=7.3s
2025-10-13 09:02:04,207 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.8077 | val_loss=0.7495 | val_acc=0.7812 | time=7.2s
2025-10-13 09:02:11,468 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.8056 | val_loss=0.7480 | val_acc=0.7816 | time=7.3s
2025-10-13 09:02:18,772 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.8054 | val_loss=0.7478 | val_acc=0.7812 | time=7.3s
2025-10-13 09:02:26,042 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.8036 | val_loss=0.7463 | val_acc=0.7834 | time=7.3s
2025-10-13 09:02:33,318 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.8038 | val_loss=0.7461 | val_acc=0.7829 | time=7.3s
2025-10-13 09:02:40,593 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.8027 | val_loss=0.7461 | val_acc=0.7812 | time=7.3s
2025-10-13 09:02:47,855 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.7991 | val_loss=0.7461 | val_acc=0.7840 | time=7.3s
2025-10-13 09:02:55,130 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.7991 | val_loss=0.7422 | val_acc=0.7838 | time=7.3s
2025-10-13 09:03:02,382 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.7970 | val_loss=0.7439 | val_acc=0.7841 | time=7.3s
2025-10-13 09:03:09,618 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.7984 | val_loss=0.7428 | val_acc=0.7840 | time=7.2s
2025-10-13 09:03:16,887 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.7960 | val_loss=0.7439 | val_acc=0.7831 | time=7.3s
2025-10-13 09:03:24,201 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.7952 | val_loss=0.7504 | val_acc=0.7777 | time=7.3s
2025-10-13 09:03:31,505 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.7988 | val_loss=0.7542 | val_acc=0.7756 | time=7.3s
2025-10-13 09:03:38,774 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.7951 | val_loss=0.7440 | val_acc=0.7840 | time=7.3s
2025-10-13 09:03:46,064 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.7965 | val_loss=0.7398 | val_acc=0.7855 | time=7.3s
2025-10-13 09:03:53,375 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.7941 | val_loss=0.7401 | val_acc=0.7846 | time=7.3s
2025-10-13 09:04:00,646 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.7915 | val_loss=0.7404 | val_acc=0.7839 | time=7.3s
2025-10-13 09:04:07,890 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.7892 | val_loss=0.7369 | val_acc=0.7869 | time=7.2s
2025-10-13 09:04:15,187 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.7868 | val_loss=0.7389 | val_acc=0.7838 | time=7.3s
2025-10-13 09:04:22,480 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.7889 | val_loss=0.7356 | val_acc=0.7871 | time=7.3s
2025-10-13 09:04:29,739 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.7857 | val_loss=0.7382 | val_acc=0.7880 | time=7.3s
2025-10-13 09:04:37,008 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.7856 | val_loss=0.7365 | val_acc=0.7847 | time=7.3s
2025-10-13 09:04:44,306 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.7863 | val_loss=0.7365 | val_acc=0.7852 | time=7.3s
2025-10-13 09:04:51,595 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.7871 | val_loss=0.7326 | val_acc=0.7893 | time=7.3s
2025-10-13 09:04:51,600 - INFO - _models.training_function_executor - Quantized model size: 32001 bytes.
2025-10-13 09:04:52,715 - INFO - _models.training_function_executor - Model: 7,423 parameters, 15.9KB storage
2025-10-13 09:04:52,715 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5241009576111186, 1.342704751585846, 1.2160079760029052, 1.1439196946823726, 1.0960219435062615, 1.0672419768219275, 1.0434103959250125, 1.0244705374523773, 1.0087143637143443, 0.9911687330720639, 0.9778451281783879, 0.9660955314082118, 0.9490968577503782, 0.937859907261258, 0.9262185416565435, 0.9148083995137133, 0.9044427432231983, 0.89734235336032, 0.8871876589059412, 0.8858914923471799, 0.874895235532057, 0.8699691109215834, 0.8673767109183445, 0.8652519770422973, 0.8639816750502061, 0.8570950847115181, 0.8547893923648304, 0.8519416578194876, 0.8492338216550959, 0.8471992569325226, 0.848670537160083, 0.8406064962648119, 0.8409288686745476, 0.8401038843850218, 0.835420558929944, 0.83256362771337, 0.830267760546674, 0.8304047162690528, 0.8279909824924448, 0.8279926470726322, 0.8245532425041586, 0.8242999512831315, 0.825364013130447, 0.8231038926446359, 0.8214607097842204, 0.8202301907422537, 0.8183415654888927, 0.8196976904711358, 0.8142408786076201, 0.8127164416664499, 0.8134627249280931, 0.8108584137387654, 0.8138572616325962, 0.806310720332319, 0.8070438197537824, 0.8076922191912618, 0.8056273469463444, 0.8054404817951865, 0.8036264933966489, 0.803815606635978, 0.8027421372375748, 0.7991273216759779, 0.799112004012464, 0.7969906744545558, 0.7983977915650696, 0.7959926144973273, 0.7952068014749081, 0.7988295577437802, 0.7950596382224063, 0.7964568993387666, 0.794093981432172, 0.7914695489289755, 0.7892354757668132, 0.786845700407846, 0.7889166478932134, 0.7856627945032911, 0.7856405695752327, 0.786276726224934, 0.7871496806329975], 'val_losses': [1.4137001684757642, 1.2372633964814295, 1.1332336441386526, 1.080806781956062, 1.0397891098066856, 0.9995285917880613, 0.9797654946366932, 0.9564062951534913, 0.9374964146460526, 0.9227728530748933, 0.9086640554998235, 0.8927030991665083, 0.885038331959437, 0.8710687539358009, 0.8568483302131749, 0.8473635648237394, 0.8420180139902133, 0.8312814632495217, 0.8242710868420199, 0.81914964463271, 0.8141153582460112, 0.8132696348259738, 0.8107571417441684, 0.8058814830741642, 0.7965845635064966, 0.7939958165982907, 0.7926535181203087, 0.7908446242185919, 0.7913104885726865, 0.7846661065690451, 0.7832455741470412, 0.7817938590450307, 0.7867314365722101, 0.7820254931468249, 0.7746903904676855, 0.7725114345258459, 0.7718842067958844, 0.7706317182266508, 0.7682473276894035, 0.7683704464761869, 0.7694961560702966, 0.7647827884138653, 0.7747748018896659, 0.763543946992529, 0.7615870371080171, 0.7622229649463983, 0.760610567843284, 0.7676309102224979, 0.7595161197900688, 0.7539139632624599, 0.755535569314486, 0.7529332097235116, 0.7539160544737928, 0.7510567202741631, 0.7537571934915983, 0.7494734810664598, 0.7479806672370972, 0.7477603251173816, 0.7462965277136728, 0.74607140576877, 0.7461048456017771, 0.7460862612615818, 0.7422328744895983, 0.7438549932834357, 0.7428171592114228, 0.7438876879645011, 0.7503929556062849, 0.7542136089760898, 0.7439663391618992, 0.7398430044767028, 0.7401251071685254, 0.7403829196636853, 0.7368861343587743, 0.7388965433028598, 0.7355751015316326, 0.7382186750536162, 0.7365393048405939, 0.7364737645996422, 0.7326292722509756], 'val_acc': [0.43848442422121103, 0.5916170808540427, 0.6319565978298914, 0.6329191459572978, 0.6368568428421421, 0.6495449772488624, 0.6530451522576128, 0.6644207210360518, 0.6676583829191459, 0.6773713685684284, 0.6988099404970248, 0.7074728736436822, 0.7105355267763388, 0.7353867693384669, 0.74011200560028, 0.7469373468673434, 0.7472873643682184, 0.7480749037451873, 0.7507875393769688, 0.7537626881344067, 0.7542002100105005, 0.7542002100105005, 0.7563003150157508, 0.7579628981449072, 0.7605880294014701, 0.7630381519075954, 0.7607630381519076, 0.7651382569128456, 0.7629506475323766, 0.7670633531676584, 0.768288414420721, 0.7686384319215961, 0.7637381869093455, 0.766100805040252, 0.7710885544277214, 0.7721386069303465, 0.7728386419320966, 0.7745887294364718, 0.773801190059503, 0.7730136506825341, 0.7707385369268464, 0.7740637031851593, 0.7708260413020651, 0.7776513825691285, 0.7773888694434722, 0.7754637731886594, 0.7760763038151908, 0.7749387469373469, 0.7793139656982849, 0.7793139656982849, 0.780014000700035, 0.7806265313265663, 0.781501575078754, 0.7804515225761288, 0.7786139306965348, 0.7811515575778789, 0.7815890794539727, 0.7812390619530977, 0.7834266713335667, 0.7829016450822541, 0.7811515575778789, 0.784039201960098, 0.7837766888344417, 0.7841267063353168, 0.7839516975848793, 0.7830766538326916, 0.7777388869443472, 0.775638781939097, 0.7839516975848793, 0.785526776338817, 0.7845642282114106, 0.7838641932096605, 0.7869268463423171, 0.7837766888344417, 0.7871018550927547, 0.7879768988449423, 0.7846517325866293, 0.7851767588379419, 0.7892894644732237], 'model_size_bytes': 32001, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.7692072464294852e-05, 'batch_size': 16, 'epochs': 79, 'weight_decay': 0.00018924638294399155, 'dropout': 0.2627123638082337, 'hidden_size': 11, 'd_model': 24, 't_pooled': 192, 'label_smoothing': 0.07364732651577949, 'use_focal_loss': False, 'focal_gamma': 1.8418559948146698, 'grad_clip_norm': 4.371925757771646, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 7423, 'model_storage_size_kb': 15.947851562500002, 'model_size_validation': 'PASS'}
2025-10-13 09:04:52,715 - INFO - _models.training_function_executor - BO Objective: base=0.7893, size_penalty=0.0000, final=0.7893
2025-10-13 09:04:52,715 - INFO - _models.training_function_executor - Model: 7,423 parameters, 15.9KB (PASS 256KB limit)
2025-10-13 09:04:52,715 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 578.365s
2025-10-13 09:04:52,821 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7893
2025-10-13 09:04:52,821 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.105s
2025-10-13 09:04:52,821 - INFO - bo.run_bo - Recorded observation #38: hparams={'lr': 1.7692072464294852e-05, 'batch_size': np.int64(16), 'epochs': np.int64(79), 'weight_decay': 0.00018924638294399155, 'dropout': 0.2627123638082337, 'hidden_size': np.int64(11), 'd_model': np.int64(24), 't_pooled': np.int64(192), 'label_smoothing': 0.07364732651577949, 'use_focal_loss': np.False_, 'focal_gamma': 1.8418559948146698, 'grad_clip_norm': 4.371925757771646, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7893
2025-10-13 09:04:52,821 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 38: {'lr': 1.7692072464294852e-05, 'batch_size': np.int64(16), 'epochs': np.int64(79), 'weight_decay': 0.00018924638294399155, 'dropout': 0.2627123638082337, 'hidden_size': np.int64(11), 'd_model': np.int64(24), 't_pooled': np.int64(192), 'label_smoothing': 0.07364732651577949, 'use_focal_loss': np.False_, 'focal_gamma': 1.8418559948146698, 'grad_clip_norm': 4.371925757771646, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7893
2025-10-13 09:04:52,822 - INFO - bo.run_bo - üîçBO Trial 39: Using RF surrogate + Expected Improvement
2025-10-13 09:04:52,822 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 09:04:52,822 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 39 (NaN monitoring active)
2025-10-13 09:04:52,822 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 09:04:52,822 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 09:04:52,822 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0012428952928190263, 'batch_size': 8, 'epochs': 88, 'weight_decay': 2.621322213950748e-06, 'dropout': 0.12344106101379035, 'hidden_size': 25, 'd_model': 8, 't_pooled': 320, 'label_smoothing': 0.013146010370641273, 'use_focal_loss': False, 'focal_gamma': 4.479587399512877, 'grad_clip_norm': 3.8311787527030825, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:04:52,823 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0012428952928190263, 'batch_size': 8, 'epochs': 88, 'weight_decay': 2.621322213950748e-06, 'dropout': 0.12344106101379035, 'hidden_size': 25, 'd_model': 8, 't_pooled': 320, 'label_smoothing': 0.013146010370641273, 'use_focal_loss': False, 'focal_gamma': 4.479587399512877, 'grad_clip_norm': 3.8311787527030825, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:05:09,898 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9018 | val_loss=0.6839 | val_acc=0.7461 | time=17.1s
2025-10-13 09:05:24,447 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7304 | val_loss=0.6325 | val_acc=0.7677 | time=14.5s
2025-10-13 09:05:39,006 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6924 | val_loss=0.6913 | val_acc=0.7479 | time=14.6s
2025-10-13 09:05:53,586 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6578 | val_loss=0.6311 | val_acc=0.7685 | time=14.6s
2025-10-13 09:06:07,997 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.6337 | val_loss=0.6187 | val_acc=0.7766 | time=14.4s
2025-10-13 09:06:22,540 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.6202 | val_loss=0.6153 | val_acc=0.7737 | time=14.5s
2025-10-13 09:06:37,076 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.6089 | val_loss=0.5906 | val_acc=0.7842 | time=14.5s
2025-10-13 09:06:51,706 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.5975 | val_loss=0.5640 | val_acc=0.7935 | time=14.6s
2025-10-13 09:07:06,198 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.5897 | val_loss=0.5897 | val_acc=0.7867 | time=14.5s
2025-10-13 09:07:20,730 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.5820 | val_loss=0.5845 | val_acc=0.7867 | time=14.5s
2025-10-13 09:07:35,265 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.5795 | val_loss=0.5506 | val_acc=0.7982 | time=14.5s
2025-10-13 09:07:49,874 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.5722 | val_loss=0.5509 | val_acc=0.7990 | time=14.6s
2025-10-13 09:08:04,429 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.5684 | val_loss=0.5674 | val_acc=0.7879 | time=14.6s
2025-10-13 09:08:18,997 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.5631 | val_loss=0.5410 | val_acc=0.7990 | time=14.6s
2025-10-13 09:08:33,502 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.5587 | val_loss=0.5522 | val_acc=0.7940 | time=14.5s
2025-10-13 09:08:48,069 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.5537 | val_loss=0.5595 | val_acc=0.7930 | time=14.6s
2025-10-13 09:09:02,657 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.5519 | val_loss=0.5557 | val_acc=0.7974 | time=14.6s
2025-10-13 09:09:17,254 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.5480 | val_loss=0.5352 | val_acc=0.8023 | time=14.6s
2025-10-13 09:09:31,979 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.5423 | val_loss=0.5467 | val_acc=0.8001 | time=14.7s
2025-10-13 09:09:46,432 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.5400 | val_loss=0.5362 | val_acc=0.8027 | time=14.5s
2025-10-13 09:10:01,060 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.5375 | val_loss=0.5633 | val_acc=0.7906 | time=14.6s
2025-10-13 09:10:15,668 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.5350 | val_loss=0.5445 | val_acc=0.8001 | time=14.6s
2025-10-13 09:10:30,248 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.5351 | val_loss=0.5345 | val_acc=0.8048 | time=14.6s
2025-10-13 09:10:44,847 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.5309 | val_loss=0.5317 | val_acc=0.8037 | time=14.6s
2025-10-13 09:10:59,386 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.5302 | val_loss=0.5694 | val_acc=0.7920 | time=14.5s
2025-10-13 09:11:13,816 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.5268 | val_loss=0.5321 | val_acc=0.8022 | time=14.4s
2025-10-13 09:11:28,406 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.5242 | val_loss=0.5644 | val_acc=0.7949 | time=14.6s
2025-10-13 09:11:43,046 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.5233 | val_loss=0.5338 | val_acc=0.8051 | time=14.6s
2025-10-13 09:11:57,649 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.5217 | val_loss=0.5430 | val_acc=0.8000 | time=14.6s
2025-10-13 09:12:12,220 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.5208 | val_loss=0.5298 | val_acc=0.8064 | time=14.6s
2025-10-13 09:12:26,786 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.5188 | val_loss=0.5348 | val_acc=0.8039 | time=14.6s
2025-10-13 09:12:41,369 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.5171 | val_loss=0.5346 | val_acc=0.8022 | time=14.6s
2025-10-13 09:12:55,996 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.5158 | val_loss=0.5310 | val_acc=0.8057 | time=14.6s
2025-10-13 09:13:10,533 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.5159 | val_loss=0.5405 | val_acc=0.8020 | time=14.5s
2025-10-13 09:13:25,065 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.5141 | val_loss=0.5284 | val_acc=0.8056 | time=14.5s
2025-10-13 09:13:39,657 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.5126 | val_loss=0.5393 | val_acc=0.8015 | time=14.6s
2025-10-13 09:13:54,290 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.5113 | val_loss=0.5387 | val_acc=0.8015 | time=14.6s
2025-10-13 09:14:08,881 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.5097 | val_loss=0.5365 | val_acc=0.8040 | time=14.6s
2025-10-13 09:14:23,417 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.5088 | val_loss=0.5341 | val_acc=0.8027 | time=14.5s
2025-10-13 09:14:37,952 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.5078 | val_loss=0.5381 | val_acc=0.8044 | time=14.5s
2025-10-13 09:14:52,484 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.5055 | val_loss=0.5424 | val_acc=0.8010 | time=14.5s
2025-10-13 09:15:07,027 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.5071 | val_loss=0.5352 | val_acc=0.8043 | time=14.5s
2025-10-13 09:15:21,489 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.5037 | val_loss=0.5425 | val_acc=0.8018 | time=14.5s
2025-10-13 09:15:35,994 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.5039 | val_loss=0.5254 | val_acc=0.8051 | time=14.5s
2025-10-13 09:15:50,600 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.5032 | val_loss=0.5416 | val_acc=0.8012 | time=14.6s
2025-10-13 09:16:05,039 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.5009 | val_loss=0.5361 | val_acc=0.8033 | time=14.4s
2025-10-13 09:16:19,659 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.4966 | val_loss=0.5398 | val_acc=0.8012 | time=14.6s
2025-10-13 09:16:34,057 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.5017 | val_loss=0.5315 | val_acc=0.8064 | time=14.4s
2025-10-13 09:16:48,597 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.4968 | val_loss=0.5324 | val_acc=0.8033 | time=14.5s
2025-10-13 09:17:03,163 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.4977 | val_loss=0.5325 | val_acc=0.8048 | time=14.6s
2025-10-13 09:17:17,722 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.4964 | val_loss=0.5295 | val_acc=0.8043 | time=14.6s
2025-10-13 09:17:32,353 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.4955 | val_loss=0.5280 | val_acc=0.8036 | time=14.6s
2025-10-13 09:17:46,806 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.4972 | val_loss=0.5494 | val_acc=0.7999 | time=14.5s
2025-10-13 09:18:01,355 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.4935 | val_loss=0.5290 | val_acc=0.8069 | time=14.5s
2025-10-13 09:18:15,888 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.4941 | val_loss=0.5299 | val_acc=0.8026 | time=14.5s
2025-10-13 09:18:30,392 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.4935 | val_loss=0.5283 | val_acc=0.8057 | time=14.5s
2025-10-13 09:18:44,940 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.4923 | val_loss=0.5290 | val_acc=0.8032 | time=14.5s
2025-10-13 09:18:59,506 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.4903 | val_loss=0.5500 | val_acc=0.7977 | time=14.6s
2025-10-13 09:19:14,130 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.4910 | val_loss=0.5308 | val_acc=0.8051 | time=14.6s
2025-10-13 09:19:28,709 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.4902 | val_loss=0.5259 | val_acc=0.8058 | time=14.6s
2025-10-13 09:19:43,190 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.4869 | val_loss=0.5283 | val_acc=0.8097 | time=14.5s
2025-10-13 09:19:57,622 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.4903 | val_loss=0.5621 | val_acc=0.7931 | time=14.4s
2025-10-13 09:20:12,243 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.4872 | val_loss=0.5486 | val_acc=0.8016 | time=14.6s
2025-10-13 09:20:26,828 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.4861 | val_loss=0.5433 | val_acc=0.8029 | time=14.6s
2025-10-13 09:20:41,254 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.4872 | val_loss=0.5367 | val_acc=0.8053 | time=14.4s
2025-10-13 09:20:55,857 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.4855 | val_loss=0.5576 | val_acc=0.7977 | time=14.6s
2025-10-13 09:21:10,424 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.4871 | val_loss=0.5271 | val_acc=0.8067 | time=14.6s
2025-10-13 09:21:25,006 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.4874 | val_loss=0.5547 | val_acc=0.7994 | time=14.6s
2025-10-13 09:21:39,435 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.4841 | val_loss=0.5460 | val_acc=0.8020 | time=14.4s
2025-10-13 09:21:54,037 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.4843 | val_loss=0.5458 | val_acc=0.7994 | time=14.6s
2025-10-13 09:22:08,602 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.4862 | val_loss=0.5385 | val_acc=0.8017 | time=14.6s
2025-10-13 09:22:23,044 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.4836 | val_loss=0.5487 | val_acc=0.7998 | time=14.4s
2025-10-13 09:22:37,621 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.4829 | val_loss=0.5553 | val_acc=0.7942 | time=14.6s
2025-10-13 09:22:52,093 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.4819 | val_loss=0.5386 | val_acc=0.7999 | time=14.5s
2025-10-13 09:23:06,614 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.4831 | val_loss=0.5340 | val_acc=0.8039 | time=14.5s
2025-10-13 09:23:21,222 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.4824 | val_loss=0.5423 | val_acc=0.8076 | time=14.6s
2025-10-13 09:23:35,849 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.4803 | val_loss=0.5380 | val_acc=0.8023 | time=14.6s
2025-10-13 09:23:50,435 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.4812 | val_loss=0.5445 | val_acc=0.8031 | time=14.6s
2025-10-13 09:24:04,992 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.4799 | val_loss=0.5344 | val_acc=0.8050 | time=14.6s
2025-10-13 09:24:19,571 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.4808 | val_loss=0.5361 | val_acc=0.8054 | time=14.6s
2025-10-13 09:24:34,021 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.4799 | val_loss=0.5328 | val_acc=0.8055 | time=14.4s
2025-10-13 09:24:48,605 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.4789 | val_loss=0.5303 | val_acc=0.8027 | time=14.6s
2025-10-13 09:25:03,117 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.4756 | val_loss=0.5337 | val_acc=0.8018 | time=14.5s
2025-10-13 09:25:17,730 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.4789 | val_loss=0.5402 | val_acc=0.8064 | time=14.6s
2025-10-13 09:25:32,297 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.4768 | val_loss=0.5602 | val_acc=0.7962 | time=14.6s
2025-10-13 09:25:46,898 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.4766 | val_loss=0.5402 | val_acc=0.8036 | time=14.6s
2025-10-13 09:26:01,265 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.4761 | val_loss=0.5398 | val_acc=0.8026 | time=14.4s
2025-10-13 09:26:15,735 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.4781 | val_loss=0.5471 | val_acc=0.7987 | time=14.5s
2025-10-13 09:26:15,743 - INFO - _models.training_function_executor - Quantized model size: 41915 bytes.
2025-10-13 09:26:16,837 - INFO - _models.training_function_executor - Model: 4,174 parameters, 4.5KB storage
2025-10-13 09:26:16,837 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9017993279680281, 0.7304127274650271, 0.6924380508959189, 0.6578382291773378, 0.6336678634607942, 0.6202082694239203, 0.6089267452574398, 0.597487173253448, 0.5896897119165803, 0.5819600896129439, 0.5794708287544837, 0.5721944321754057, 0.5683559858620605, 0.5630632319497737, 0.5586718534310777, 0.553748804822924, 0.5518974582666298, 0.5479854903045989, 0.542273362771871, 0.5399746365250617, 0.5374772073097962, 0.5349759165527502, 0.5350519789341742, 0.5309495187169258, 0.5302252342737364, 0.5268352021824074, 0.5241774934590759, 0.5233321406030659, 0.5216809045164827, 0.5207533150660979, 0.5187530843844187, 0.517051502346398, 0.5158399867234862, 0.5159193438731752, 0.5141417991616403, 0.5125864538897741, 0.5112512769959254, 0.509739088629316, 0.5087573282410204, 0.5077784177428323, 0.5054579913110261, 0.507126027129468, 0.5036600020824611, 0.5038985330500635, 0.5031646608792593, 0.5008854871765066, 0.49655824537575766, 0.5016844741488967, 0.49677113557053815, 0.4977204182508278, 0.49639130941675935, 0.4954810006622881, 0.4972429897454931, 0.493486918219537, 0.49413403238492243, 0.4935054881970887, 0.49231647305114934, 0.49026173099974546, 0.49104659113150234, 0.49024279468024906, 0.48690080350753223, 0.49029630268208413, 0.48721073046170166, 0.48613565139626347, 0.4872099216082086, 0.48546499351875994, 0.4871381422727101, 0.48737765993762566, 0.4841038618663161, 0.4843273426819753, 0.48616642660096593, 0.48356582542263965, 0.48285427388217134, 0.4819499857940163, 0.48312601041456893, 0.48237406069821603, 0.48026860853618664, 0.4811549071440298, 0.4798980301267562, 0.480841562039772, 0.4799227368205233, 0.4789470905619962, 0.4755795753561286, 0.4789478118952897, 0.4768415667171407, 0.47662202027614275, 0.47613246973224527, 0.4781457041831942], 'val_losses': [0.6838983403121753, 0.6325079109082908, 0.6912725879714586, 0.6310967500544863, 0.6187362461854496, 0.6152788642969923, 0.5905555079700565, 0.5639950943746307, 0.5896552303766178, 0.5845313088112375, 0.5505652423031396, 0.5509201790387704, 0.5673506368508404, 0.5410326394556617, 0.5521542115002026, 0.5595486774586863, 0.5557395798428976, 0.5351638795457856, 0.5467309370652587, 0.5361559678926558, 0.5633333630606892, 0.5444531396453849, 0.5345004962735715, 0.5316692644278403, 0.5693538728234315, 0.5320654376470254, 0.5643688447885593, 0.533783027925064, 0.5429823556781274, 0.5298392875371047, 0.5347792320435891, 0.534612752515451, 0.5309729179772289, 0.5405210263409063, 0.5284493615838419, 0.5392803777691197, 0.5386642327425903, 0.536549790509731, 0.5341315811273724, 0.5381338412961135, 0.5424304036700647, 0.535163522434268, 0.5424734567757207, 0.5254178215072502, 0.5416033738740975, 0.5361066378201894, 0.5397990709643369, 0.5315072993048012, 0.5323752448103584, 0.5325115919582569, 0.5295468241518763, 0.527985370838229, 0.5494370726978691, 0.5290349462637752, 0.5298708169755295, 0.5283050450790083, 0.5290268175995012, 0.5500446543864199, 0.5307780926956511, 0.5259220095042962, 0.52825517337515, 0.5620859257973363, 0.5485509924478451, 0.5432576210057773, 0.5367162094578944, 0.5575612537826238, 0.5270749367760493, 0.5547041024857565, 0.5460351719320509, 0.5458145129344745, 0.5384791764943467, 0.5486730082201131, 0.5552511942691222, 0.5385550675085052, 0.5340274392849171, 0.5423473024654105, 0.5380260234879246, 0.5445331899820194, 0.5344216535673051, 0.5361256687362419, 0.5328330355463305, 0.5302881310985019, 0.5337062581179232, 0.5402372048937611, 0.5602293496141076, 0.5401536821953934, 0.5397847041586792, 0.5470713862264578], 'val_acc': [0.7461498074903745, 0.7676758837941897, 0.7478998949947497, 0.7684634231711586, 0.7766013300665033, 0.7737136856842842, 0.7842142107105355, 0.7934896744837242, 0.7866643332166608, 0.7866643332166608, 0.7982149107455373, 0.7990024501225061, 0.7878893944697235, 0.7990024501225061, 0.7940147007350368, 0.7929646482324116, 0.7974273713685684, 0.8023276163808191, 0.80014000700035, 0.8026776338816941, 0.7906020301015051, 0.8000525026251313, 0.8047777388869444, 0.8037276863843192, 0.7920021001050053, 0.8022401120056003, 0.7948897444872244, 0.8051277563878194, 0.7999649982499125, 0.8064403220161008, 0.8039026951347568, 0.8022401120056003, 0.8057402870143507, 0.801977598879944, 0.8055652782639132, 0.8015400770038502, 0.8015400770038502, 0.8039901995099755, 0.8026776338816941, 0.8044277213860693, 0.8010150507525376, 0.8043402170108506, 0.8018025901295065, 0.8051277563878194, 0.8011900595029752, 0.8032901645082254, 0.8011900595029752, 0.8064403220161008, 0.8032901645082254, 0.8047777388869444, 0.8042527126356318, 0.8036401820091005, 0.7998774938746938, 0.8068778438921946, 0.8025901295064753, 0.8057402870143507, 0.8032026601330067, 0.7976898844942247, 0.8051277563878194, 0.8058277913895695, 0.809677983899195, 0.7931396569828492, 0.801627581379069, 0.8029401470073504, 0.8053027651382569, 0.7976898844942247, 0.8067028351417571, 0.7994399719986, 0.801977598879944, 0.7994399719986, 0.8017150857542877, 0.799789989499475, 0.7941897094854743, 0.7998774938746938, 0.8039026951347568, 0.8075778788939447, 0.8023276163808191, 0.8031151557577879, 0.8049527476373819, 0.8053902695134757, 0.8054777738886945, 0.8026776338816941, 0.8018025901295065, 0.8064403220161008, 0.7962023101155058, 0.8035526776338817, 0.8025901295064753, 0.7986524326216311], 'model_size_bytes': 41915, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0012428952928190263, 'batch_size': 8, 'epochs': 88, 'weight_decay': 2.621322213950748e-06, 'dropout': 0.12344106101379035, 'hidden_size': 25, 'd_model': 8, 't_pooled': 320, 'label_smoothing': 0.013146010370641273, 'use_focal_loss': False, 'focal_gamma': 4.479587399512877, 'grad_clip_norm': 3.8311787527030825, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 4174, 'model_storage_size_kb': 4.4837890625000005, 'model_size_validation': 'PASS'}
2025-10-13 09:26:16,837 - INFO - _models.training_function_executor - BO Objective: base=0.7987, size_penalty=0.0000, final=0.7987
2025-10-13 09:26:16,838 - INFO - _models.training_function_executor - Model: 4,174 parameters, 4.5KB (PASS 256KB limit)
2025-10-13 09:26:16,838 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 1284.016s
2025-10-13 09:26:16,946 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7987
2025-10-13 09:26:16,947 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-13 09:26:16,947 - INFO - bo.run_bo - Recorded observation #39: hparams={'lr': 0.0012428952928190263, 'batch_size': np.int64(8), 'epochs': np.int64(88), 'weight_decay': 2.621322213950748e-06, 'dropout': 0.12344106101379035, 'hidden_size': np.int64(25), 'd_model': np.int64(8), 't_pooled': np.int64(320), 'label_smoothing': 0.013146010370641273, 'use_focal_loss': np.False_, 'focal_gamma': 4.479587399512877, 'grad_clip_norm': 3.8311787527030825, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7987
2025-10-13 09:26:16,947 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 39: {'lr': 0.0012428952928190263, 'batch_size': np.int64(8), 'epochs': np.int64(88), 'weight_decay': 2.621322213950748e-06, 'dropout': 0.12344106101379035, 'hidden_size': np.int64(25), 'd_model': np.int64(8), 't_pooled': np.int64(320), 'label_smoothing': 0.013146010370641273, 'use_focal_loss': np.False_, 'focal_gamma': 4.479587399512877, 'grad_clip_norm': 3.8311787527030825, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7987
2025-10-13 09:26:16,947 - INFO - bo.run_bo - üîçBO Trial 40: Using RF surrogate + Expected Improvement
2025-10-13 09:26:16,947 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 09:26:16,947 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 40 (NaN monitoring active)
2025-10-13 09:26:16,947 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 09:26:16,947 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 09:26:16,947 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.7596174490303624e-05, 'batch_size': 16, 'epochs': 24, 'weight_decay': 0.0001700825529522009, 'dropout': 0.3704012818724515, 'hidden_size': 17, 'd_model': 27, 't_pooled': 320, 'label_smoothing': 0.1999523423880112, 'use_focal_loss': False, 'focal_gamma': 4.880512590266301, 'grad_clip_norm': 0.1614518918833069, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:26:16,948 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.7596174490303624e-05, 'batch_size': 16, 'epochs': 24, 'weight_decay': 0.0001700825529522009, 'dropout': 0.3704012818724515, 'hidden_size': 17, 'd_model': 27, 't_pooled': 320, 'label_smoothing': 0.1999523423880112, 'use_focal_loss': False, 'focal_gamma': 4.880512590266301, 'grad_clip_norm': 0.1614518918833069, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:26:27,515 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5405 | val_loss=1.4196 | val_acc=0.5961 | time=10.6s
2025-10-13 09:26:35,240 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3712 | val_loss=1.2963 | val_acc=0.6356 | time=7.7s
2025-10-13 09:26:42,963 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2924 | val_loss=1.2270 | val_acc=0.6503 | time=7.7s
2025-10-13 09:26:50,691 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.2496 | val_loss=1.1872 | val_acc=0.6535 | time=7.7s
2025-10-13 09:26:58,419 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.2227 | val_loss=1.1691 | val_acc=0.6561 | time=7.7s
2025-10-13 09:27:06,101 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.2097 | val_loss=1.1561 | val_acc=0.6596 | time=7.7s
2025-10-13 09:27:13,815 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1971 | val_loss=1.1421 | val_acc=0.6628 | time=7.7s
2025-10-13 09:27:21,512 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1894 | val_loss=1.1330 | val_acc=0.6675 | time=7.7s
2025-10-13 09:27:29,237 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1792 | val_loss=1.1281 | val_acc=0.6669 | time=7.7s
2025-10-13 09:27:36,955 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1699 | val_loss=1.1193 | val_acc=0.6702 | time=7.7s
2025-10-13 09:27:44,689 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.1657 | val_loss=1.1120 | val_acc=0.6771 | time=7.7s
2025-10-13 09:27:52,421 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.1553 | val_loss=1.1054 | val_acc=0.6854 | time=7.7s
2025-10-13 09:28:00,166 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.1512 | val_loss=1.0986 | val_acc=0.6946 | time=7.7s
2025-10-13 09:28:07,877 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.1429 | val_loss=1.0904 | val_acc=0.7020 | time=7.7s
2025-10-13 09:28:15,564 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.1333 | val_loss=1.0834 | val_acc=0.7244 | time=7.7s
2025-10-13 09:28:23,294 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.1252 | val_loss=1.0739 | val_acc=0.7259 | time=7.7s
2025-10-13 09:28:31,012 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.1158 | val_loss=1.0617 | val_acc=0.7377 | time=7.7s
2025-10-13 09:28:38,739 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.1077 | val_loss=1.0542 | val_acc=0.7397 | time=7.7s
2025-10-13 09:28:46,434 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.1006 | val_loss=1.0455 | val_acc=0.7433 | time=7.7s
2025-10-13 09:28:54,168 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0955 | val_loss=1.0398 | val_acc=0.7502 | time=7.7s
2025-10-13 09:29:01,869 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0896 | val_loss=1.0354 | val_acc=0.7524 | time=7.7s
2025-10-13 09:29:09,621 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.0876 | val_loss=1.0315 | val_acc=0.7532 | time=7.8s
2025-10-13 09:29:17,332 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.0836 | val_loss=1.0288 | val_acc=0.7567 | time=7.7s
2025-10-13 09:29:25,045 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.0804 | val_loss=1.0332 | val_acc=0.7528 | time=7.7s
2025-10-13 09:29:25,050 - INFO - _models.training_function_executor - Quantized model size: 36865 bytes.
2025-10-13 09:29:26,196 - INFO - _models.training_function_executor - Model: 9,850 parameters, 21.2KB storage
2025-10-13 09:29:26,196 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5405076740085974, 1.371236676430427, 1.2923656485695751, 1.2496465804445855, 1.2227140413241908, 1.2096852894258283, 1.1971425241551117, 1.1894415881527776, 1.1791719548093884, 1.1699143062323842, 1.1657427564591931, 1.1552650565069624, 1.1511843656592324, 1.1428883756254369, 1.1332932118982295, 1.1252256219604861, 1.1158181956734823, 1.107710924313792, 1.1005569407895681, 1.095532858501083, 1.0895638604618094, 1.0875559176312153, 1.0836430058889885, 1.0804414895392815], 'val_losses': [1.419648366914081, 1.2963211656576443, 1.227037442869601, 1.1871583709192726, 1.1691253446472831, 1.1560857026861562, 1.1420557498931885, 1.1330310841895168, 1.1280641705997347, 1.119318243545129, 1.1119947422205838, 1.1054049421116152, 1.0985541328667843, 1.0903918390554441, 1.0833832821647396, 1.0738704168675537, 1.0617049363972133, 1.0541656212578048, 1.0455101787689312, 1.0397719141274513, 1.0354356245640737, 1.0315224015508284, 1.0288452480404287, 1.0331603760981334], 'val_acc': [0.5960798039901996, 0.6356317815890794, 0.6503325166258312, 0.6534826741337066, 0.6561078053902695, 0.6596079803990199, 0.6627581379068953, 0.6674833741687084, 0.6668708435421771, 0.67019600980049, 0.6771088554427721, 0.6854217710885544, 0.6946097304865243, 0.7019600980049002, 0.7244487224361218, 0.7259362968148407, 0.7377493874693735, 0.7396744837241862, 0.7432621631081554, 0.7501750087504375, 0.7523626181309065, 0.7532376618830942, 0.7566503325166258, 0.7528001400070004], 'model_size_bytes': 36865, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.7596174490303624e-05, 'batch_size': 16, 'epochs': 24, 'weight_decay': 0.0001700825529522009, 'dropout': 0.3704012818724515, 'hidden_size': 17, 'd_model': 27, 't_pooled': 320, 'label_smoothing': 0.1999523423880112, 'use_focal_loss': False, 'focal_gamma': 4.880512590266301, 'grad_clip_norm': 0.1614518918833069, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 9850, 'model_storage_size_kb': 21.162109375, 'model_size_validation': 'PASS'}
2025-10-13 09:29:26,196 - INFO - _models.training_function_executor - BO Objective: base=0.7528, size_penalty=0.0000, final=0.7528
2025-10-13 09:29:26,196 - INFO - _models.training_function_executor - Model: 9,850 parameters, 21.2KB (PASS 256KB limit)
2025-10-13 09:29:26,196 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 189.249s
2025-10-13 09:29:26,303 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7528
2025-10-13 09:29:26,303 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.106s
2025-10-13 09:29:26,303 - INFO - bo.run_bo - Recorded observation #40: hparams={'lr': 1.7596174490303624e-05, 'batch_size': np.int64(16), 'epochs': np.int64(24), 'weight_decay': 0.0001700825529522009, 'dropout': 0.3704012818724515, 'hidden_size': np.int64(17), 'd_model': np.int64(27), 't_pooled': np.int64(320), 'label_smoothing': 0.1999523423880112, 'use_focal_loss': np.False_, 'focal_gamma': 4.880512590266301, 'grad_clip_norm': 0.1614518918833069, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7528
2025-10-13 09:29:26,303 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 40: {'lr': 1.7596174490303624e-05, 'batch_size': np.int64(16), 'epochs': np.int64(24), 'weight_decay': 0.0001700825529522009, 'dropout': 0.3704012818724515, 'hidden_size': np.int64(17), 'd_model': np.int64(27), 't_pooled': np.int64(320), 'label_smoothing': 0.1999523423880112, 'use_focal_loss': np.False_, 'focal_gamma': 4.880512590266301, 'grad_clip_norm': 0.1614518918833069, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7528
2025-10-13 09:29:26,304 - INFO - bo.run_bo - üîçBO Trial 41: Using RF surrogate + Expected Improvement
2025-10-13 09:29:26,304 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 09:29:26,304 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 41 (NaN monitoring active)
2025-10-13 09:29:26,304 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 09:29:26,304 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 09:29:26,304 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.7664321368453407e-05, 'batch_size': 24, 'epochs': 77, 'weight_decay': 8.610732148128482e-05, 'dropout': 0.441420242697489, 'hidden_size': 19, 'd_model': 28, 't_pooled': 128, 'label_smoothing': 0.0033862199786353305, 'use_focal_loss': False, 'focal_gamma': 3.760581402290763, 'grad_clip_norm': 3.9744148550655125, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 09:29:26,305 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.7664321368453407e-05, 'batch_size': 24, 'epochs': 77, 'weight_decay': 8.610732148128482e-05, 'dropout': 0.441420242697489, 'hidden_size': 19, 'd_model': 28, 't_pooled': 128, 'label_smoothing': 0.0033862199786353305, 'use_focal_loss': False, 'focal_gamma': 3.760581402290763, 'grad_clip_norm': 3.9744148550655125, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 09:29:34,633 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5522 | val_loss=1.4456 | val_acc=0.5220 | time=8.3s
2025-10-13 09:29:40,207 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.3265 | val_loss=1.1806 | val_acc=0.5960 | time=5.6s
2025-10-13 09:29:45,750 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1256 | val_loss=1.0234 | val_acc=0.6236 | time=5.5s
2025-10-13 09:29:51,284 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0094 | val_loss=0.9227 | val_acc=0.6397 | time=5.5s
2025-10-13 09:29:56,832 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9447 | val_loss=0.8612 | val_acc=0.6488 | time=5.5s
2025-10-13 09:30:02,401 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.9020 | val_loss=0.8228 | val_acc=0.6614 | time=5.6s
2025-10-13 09:30:07,971 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8654 | val_loss=0.7939 | val_acc=0.6775 | time=5.6s
2025-10-13 09:30:13,584 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.8434 | val_loss=0.7698 | val_acc=0.6894 | time=5.6s
2025-10-13 09:30:19,150 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.8222 | val_loss=0.7548 | val_acc=0.6968 | time=5.6s
2025-10-13 09:30:24,687 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8095 | val_loss=0.7380 | val_acc=0.7148 | time=5.5s
2025-10-13 09:30:30,244 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.7929 | val_loss=0.7256 | val_acc=0.7232 | time=5.6s
2025-10-13 09:30:35,799 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.7799 | val_loss=0.7191 | val_acc=0.7272 | time=5.6s
2025-10-13 09:30:41,390 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.7693 | val_loss=0.7013 | val_acc=0.7355 | time=5.6s
2025-10-13 09:30:46,925 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.7630 | val_loss=0.7020 | val_acc=0.7342 | time=5.5s
2025-10-13 09:30:52,464 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.7507 | val_loss=0.6878 | val_acc=0.7390 | time=5.5s
2025-10-13 09:30:58,052 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7466 | val_loss=0.6787 | val_acc=0.7438 | time=5.6s
2025-10-13 09:31:03,542 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.7382 | val_loss=0.6716 | val_acc=0.7459 | time=5.5s
2025-10-13 09:31:09,076 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.7304 | val_loss=0.6649 | val_acc=0.7480 | time=5.5s
2025-10-13 09:31:14,637 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.7234 | val_loss=0.6575 | val_acc=0.7494 | time=5.6s
2025-10-13 09:31:20,236 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.7156 | val_loss=0.6526 | val_acc=0.7531 | time=5.6s
2025-10-13 09:31:25,764 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.7121 | val_loss=0.6445 | val_acc=0.7543 | time=5.5s
2025-10-13 09:31:31,305 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.7077 | val_loss=0.6436 | val_acc=0.7518 | time=5.5s
2025-10-13 09:31:36,836 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.6997 | val_loss=0.6324 | val_acc=0.7585 | time=5.5s
2025-10-13 09:31:42,381 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.6904 | val_loss=0.6299 | val_acc=0.7570 | time=5.5s
2025-10-13 09:31:47,934 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.6874 | val_loss=0.6227 | val_acc=0.7613 | time=5.6s
2025-10-13 09:31:53,467 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.6841 | val_loss=0.6207 | val_acc=0.7614 | time=5.5s
2025-10-13 09:31:59,042 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.6796 | val_loss=0.6153 | val_acc=0.7628 | time=5.6s
2025-10-13 09:32:04,585 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.6748 | val_loss=0.6093 | val_acc=0.7668 | time=5.5s
2025-10-13 09:32:10,119 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.6690 | val_loss=0.6061 | val_acc=0.7679 | time=5.5s
2025-10-13 09:32:15,785 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.6652 | val_loss=0.6015 | val_acc=0.7689 | time=5.7s
2025-10-13 09:32:21,378 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.6629 | val_loss=0.6080 | val_acc=0.7630 | time=5.6s
2025-10-13 09:32:26,906 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.6577 | val_loss=0.5976 | val_acc=0.7683 | time=5.5s
2025-10-13 09:32:32,450 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.6578 | val_loss=0.6070 | val_acc=0.7619 | time=5.5s
2025-10-13 09:32:38,073 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.6533 | val_loss=0.5899 | val_acc=0.7733 | time=5.6s
2025-10-13 09:32:43,640 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.6541 | val_loss=0.5873 | val_acc=0.7753 | time=5.6s
2025-10-13 09:32:49,229 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.6530 | val_loss=0.5872 | val_acc=0.7750 | time=5.6s
2025-10-13 09:32:54,790 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.6387 | val_loss=0.5866 | val_acc=0.7761 | time=5.6s
2025-10-13 09:33:00,338 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.6436 | val_loss=0.5854 | val_acc=0.7707 | time=5.5s
2025-10-13 09:33:05,873 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.6382 | val_loss=0.5855 | val_acc=0.7755 | time=5.5s
2025-10-13 09:33:11,445 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.6360 | val_loss=0.5770 | val_acc=0.7772 | time=5.6s
2025-10-13 09:33:16,997 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.6366 | val_loss=0.5755 | val_acc=0.7759 | time=5.6s
2025-10-13 09:33:22,616 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.6304 | val_loss=0.5766 | val_acc=0.7762 | time=5.6s
2025-10-13 09:33:28,149 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.6317 | val_loss=0.5763 | val_acc=0.7763 | time=5.5s
2025-10-13 09:33:33,651 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.6271 | val_loss=0.5691 | val_acc=0.7779 | time=5.5s
2025-10-13 09:33:39,165 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.6286 | val_loss=0.5689 | val_acc=0.7789 | time=5.5s
2025-10-13 09:33:44,720 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.6279 | val_loss=0.5665 | val_acc=0.7805 | time=5.6s
2025-10-13 09:33:50,297 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.6252 | val_loss=0.5668 | val_acc=0.7811 | time=5.6s
2025-10-13 09:33:55,894 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.6235 | val_loss=0.5701 | val_acc=0.7775 | time=5.6s
2025-10-13 09:34:01,507 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.6229 | val_loss=0.5632 | val_acc=0.7816 | time=5.6s
2025-10-13 09:34:07,056 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.6165 | val_loss=0.5649 | val_acc=0.7791 | time=5.5s
2025-10-13 09:34:12,605 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.6199 | val_loss=0.5662 | val_acc=0.7787 | time=5.5s
2025-10-13 09:34:18,230 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.6084 | val_loss=0.5599 | val_acc=0.7824 | time=5.6s
2025-10-13 09:34:23,770 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.6165 | val_loss=0.5582 | val_acc=0.7826 | time=5.5s
2025-10-13 09:34:29,320 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.6120 | val_loss=0.5538 | val_acc=0.7858 | time=5.6s
2025-10-13 09:34:34,921 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.6112 | val_loss=0.5570 | val_acc=0.7834 | time=5.6s
2025-10-13 09:34:40,501 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.6113 | val_loss=0.5516 | val_acc=0.7861 | time=5.6s
2025-10-13 09:34:46,119 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.6089 | val_loss=0.5560 | val_acc=0.7833 | time=5.6s
2025-10-13 09:34:51,649 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.6055 | val_loss=0.5597 | val_acc=0.7847 | time=5.5s
2025-10-13 09:34:57,170 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.6065 | val_loss=0.5549 | val_acc=0.7835 | time=5.5s
2025-10-13 09:35:02,711 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.6065 | val_loss=0.5486 | val_acc=0.7874 | time=5.5s
2025-10-13 09:35:08,235 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.6019 | val_loss=0.5460 | val_acc=0.7886 | time=5.5s
2025-10-13 09:35:13,797 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.6045 | val_loss=0.5460 | val_acc=0.7861 | time=5.6s
2025-10-13 09:35:19,372 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.6038 | val_loss=0.5453 | val_acc=0.7885 | time=5.6s
2025-10-13 09:35:24,931 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.5994 | val_loss=0.5448 | val_acc=0.7896 | time=5.6s
2025-10-13 09:35:30,470 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.5983 | val_loss=0.5476 | val_acc=0.7893 | time=5.5s
2025-10-13 09:35:36,047 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.5983 | val_loss=0.5441 | val_acc=0.7920 | time=5.6s
2025-10-13 09:35:41,568 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.5973 | val_loss=0.5407 | val_acc=0.7926 | time=5.5s
2025-10-13 09:35:47,083 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.5927 | val_loss=0.5444 | val_acc=0.7885 | time=5.5s
2025-10-13 09:35:52,611 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.5930 | val_loss=0.5396 | val_acc=0.7908 | time=5.5s
2025-10-13 09:35:58,150 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.5934 | val_loss=0.5481 | val_acc=0.7896 | time=5.5s
2025-10-13 09:36:03,742 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.5921 | val_loss=0.5384 | val_acc=0.7926 | time=5.6s
2025-10-13 09:36:09,333 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.5961 | val_loss=0.5402 | val_acc=0.7921 | time=5.6s
2025-10-13 09:36:14,850 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.5888 | val_loss=0.5350 | val_acc=0.7944 | time=5.5s
2025-10-13 09:36:20,359 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.5834 | val_loss=0.5380 | val_acc=0.7933 | time=5.5s
2025-10-13 09:36:25,898 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.5909 | val_loss=0.5365 | val_acc=0.7932 | time=5.5s
2025-10-13 09:36:31,452 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.5894 | val_loss=0.5362 | val_acc=0.7926 | time=5.6s
2025-10-13 09:36:37,000 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.5865 | val_loss=0.5406 | val_acc=0.7900 | time=5.5s
2025-10-13 09:36:37,004 - INFO - _models.training_function_executor - Quantized model size: 60545 bytes.
2025-10-13 09:36:38,108 - INFO - _models.training_function_executor - Model: 10,860 parameters, 46.7KB storage
2025-10-13 09:36:38,108 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5522310273773319, 1.3264981928324842, 1.1255531884967176, 1.009379616318193, 0.9447448955973337, 0.9020417039215795, 0.8653585288933119, 0.8433875813063183, 0.8221764449039288, 0.8095157745786176, 0.792920796201285, 0.7799274812566261, 0.7693037041207064, 0.7630218684120449, 0.7506661703943748, 0.7466102750632243, 0.7381794253585219, 0.7303887004717939, 0.7234417001632364, 0.7156332569822048, 0.7120752622760339, 0.7076578632930713, 0.6997133138601622, 0.6903715089959701, 0.687380528393683, 0.6840558672831698, 0.6796258966072397, 0.6747725773152873, 0.6689555916725275, 0.665169029217898, 0.6628575275046116, 0.6577008836751098, 0.6577591046685726, 0.6533286246801324, 0.6541146395801664, 0.6529710263347642, 0.638683010788493, 0.6435982401883389, 0.6382057840173421, 0.636029497957288, 0.6365591018354095, 0.6304429062949556, 0.6316804932935655, 0.6270536399717969, 0.6285702225536702, 0.6278516206346612, 0.6252090404312803, 0.6235304867700759, 0.622859963066915, 0.6164835291384274, 0.6198679320657633, 0.6084425390512533, 0.6165188276761472, 0.6120198839661914, 0.6111600750318599, 0.6113014084723474, 0.6088609445812738, 0.6055346241975148, 0.606469889649633, 0.6065403769300624, 0.6019092179446276, 0.6045040935538722, 0.6037712940332729, 0.5993975063027683, 0.5982917654433991, 0.5982969649759339, 0.5973080781568462, 0.5927317778980519, 0.5929919818105254, 0.5934086562319155, 0.5920920401556032, 0.5961187238960488, 0.5888026728209057, 0.583441763446074, 0.590858681879137, 0.5893749060108606, 0.586464769522815], 'val_losses': [1.445622987458453, 1.180588108115485, 1.0234462226609646, 0.9227165739812507, 0.8611724937467005, 0.822840297414074, 0.7939304018045665, 0.7698460058561771, 0.7548276777028787, 0.7379790428096196, 0.7255636245419106, 0.7191299744365013, 0.7013328080415976, 0.7020048055984276, 0.687771063940818, 0.6786882576092916, 0.6716456181693419, 0.6648739758053567, 0.6574997101415901, 0.6526481243001026, 0.6444896754994858, 0.6436341846577555, 0.6323804528845913, 0.6299499984925804, 0.6226599930903275, 0.6207482913364929, 0.615310809956091, 0.6092669624401048, 0.606098665071193, 0.6014954100591468, 0.6080304540075704, 0.5975780959182742, 0.60700300663428, 0.58988822989836, 0.5873280863558282, 0.5871907113876883, 0.5865622974793978, 0.5854436085697317, 0.5855319328061092, 0.5769628462859873, 0.5755385828677448, 0.5766475805044592, 0.5763427730223329, 0.5691319380006383, 0.5688834605327134, 0.5664997814854918, 0.5667670242616168, 0.5700658795234412, 0.5632382607466281, 0.5649068796910062, 0.5661963843093454, 0.5599498565709378, 0.5581637312158405, 0.5538452709361645, 0.556959151903524, 0.5515940935097668, 0.5560279026872676, 0.5597131257556642, 0.5549498246523062, 0.5485600317258872, 0.5459675633921922, 0.545968370464535, 0.5452814373596173, 0.544824640396011, 0.5475868358556149, 0.5441498238701565, 0.5406881567165073, 0.5443689599189885, 0.5395712049734689, 0.5481355786114921, 0.5384440354463058, 0.5402240053648543, 0.5350439824140443, 0.5380409277524404, 0.5364732834939819, 0.5362497736596544, 0.5405519782641487], 'val_acc': [0.521963598179909, 0.5959922996149808, 0.6236436821841093, 0.6396569828491424, 0.6488449422471123, 0.6613580679033951, 0.6775463773188659, 0.6893594679733986, 0.6967973398669933, 0.7148232411620581, 0.7232236611830591, 0.7271613580679034, 0.7354742737136857, 0.7341617080854043, 0.7389744487224361, 0.743787189359468, 0.7458872943647182, 0.7479873993699685, 0.7493874693734687, 0.7530626531326566, 0.7542877143857193, 0.7517500875043752, 0.7584879243962198, 0.7570003500175009, 0.7612880644032202, 0.7613755687784389, 0.7627756387819391, 0.7668008400420021, 0.767938396919846, 0.7689009450472524, 0.7629506475323766, 0.768288414420721, 0.7619005950297515, 0.7732761638081904, 0.7752887644382219, 0.7750262513125656, 0.7760763038151908, 0.7706510325516276, 0.7754637731886594, 0.7772138606930347, 0.7759012950647532, 0.7761638081904095, 0.7762513125656283, 0.7779138956947848, 0.7788764438221911, 0.7804515225761288, 0.7810640532026601, 0.777476373818691, 0.7815890794539727, 0.7791389569478474, 0.7787014350717536, 0.7823766188309416, 0.7826391319565978, 0.7857892894644732, 0.7834266713335667, 0.7860518025901295, 0.7832516625831292, 0.7847392369618481, 0.7835141757087855, 0.7873643682184109, 0.7885894294714736, 0.7861393069653483, 0.7885019250962548, 0.78955197759888, 0.7892894644732237, 0.7920021001050053, 0.7926146307315366, 0.7885019250962548, 0.7907770388519426, 0.78955197759888, 0.7926146307315366, 0.792089604480224, 0.7943647182359118, 0.7933146657332867, 0.7932271613580679, 0.7926146307315366, 0.7899894994749738], 'model_size_bytes': 60545, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.7664321368453407e-05, 'batch_size': 24, 'epochs': 77, 'weight_decay': 8.610732148128482e-05, 'dropout': 0.441420242697489, 'hidden_size': 19, 'd_model': 28, 't_pooled': 128, 'label_smoothing': 0.0033862199786353305, 'use_focal_loss': False, 'focal_gamma': 3.760581402290763, 'grad_clip_norm': 3.9744148550655125, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 10860, 'model_storage_size_kb': 46.66406250000001, 'model_size_validation': 'PASS'}
2025-10-13 09:36:38,109 - INFO - _models.training_function_executor - BO Objective: base=0.7900, size_penalty=0.0000, final=0.7900
2025-10-13 09:36:38,109 - INFO - _models.training_function_executor - Model: 10,860 parameters, 46.7KB (PASS 256KB limit)
2025-10-13 09:36:38,109 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 431.805s
2025-10-13 09:36:38,217 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7900
2025-10-13 09:36:38,217 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-13 09:36:38,217 - INFO - bo.run_bo - Recorded observation #41: hparams={'lr': 1.7664321368453407e-05, 'batch_size': np.int64(24), 'epochs': np.int64(77), 'weight_decay': 8.610732148128482e-05, 'dropout': 0.441420242697489, 'hidden_size': np.int64(19), 'd_model': np.int64(28), 't_pooled': np.int64(128), 'label_smoothing': 0.0033862199786353305, 'use_focal_loss': np.False_, 'focal_gamma': 3.760581402290763, 'grad_clip_norm': 3.9744148550655125, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7900
2025-10-13 09:36:38,217 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 41: {'lr': 1.7664321368453407e-05, 'batch_size': np.int64(24), 'epochs': np.int64(77), 'weight_decay': 8.610732148128482e-05, 'dropout': 0.441420242697489, 'hidden_size': np.int64(19), 'd_model': np.int64(28), 't_pooled': np.int64(128), 'label_smoothing': 0.0033862199786353305, 'use_focal_loss': np.False_, 'focal_gamma': 3.760581402290763, 'grad_clip_norm': 3.9744148550655125, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7900
2025-10-13 09:36:38,218 - INFO - bo.run_bo - üîçBO Trial 42: Using RF surrogate + Expected Improvement
2025-10-13 09:36:38,218 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 09:36:38,218 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 42 (NaN monitoring active)
2025-10-13 09:36:38,218 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 09:36:38,218 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 09:36:38,218 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.7566808400905703e-05, 'batch_size': 16, 'epochs': 78, 'weight_decay': 0.00049740320014252, 'dropout': 0.1853993257090927, 'hidden_size': 30, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.09087967526431262, 'use_focal_loss': False, 'focal_gamma': 3.4736356391138346, 'grad_clip_norm': 4.974461764046135, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:36:38,219 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.7566808400905703e-05, 'batch_size': 16, 'epochs': 78, 'weight_decay': 0.00049740320014252, 'dropout': 0.1853993257090927, 'hidden_size': 30, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.09087967526431262, 'use_focal_loss': False, 'focal_gamma': 3.4736356391138346, 'grad_clip_norm': 4.974461764046135, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:36:48,220 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.4668 | val_loss=1.2848 | val_acc=0.5844 | time=10.0s
2025-10-13 09:36:55,483 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2207 | val_loss=1.1363 | val_acc=0.6245 | time=7.3s
2025-10-13 09:37:02,719 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1324 | val_loss=1.0579 | val_acc=0.6421 | time=7.2s
2025-10-13 09:37:10,000 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0791 | val_loss=1.0204 | val_acc=0.6460 | time=7.3s
2025-10-13 09:37:17,188 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0512 | val_loss=0.9913 | val_acc=0.6576 | time=7.2s
2025-10-13 09:37:24,447 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0341 | val_loss=0.9743 | val_acc=0.6698 | time=7.3s
2025-10-13 09:37:31,697 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.0208 | val_loss=0.9576 | val_acc=0.6847 | time=7.3s
2025-10-13 09:37:38,948 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.0003 | val_loss=0.9405 | val_acc=0.7072 | time=7.2s
2025-10-13 09:37:46,151 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9820 | val_loss=0.9344 | val_acc=0.7107 | time=7.2s
2025-10-13 09:37:53,414 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9613 | val_loss=0.9104 | val_acc=0.7254 | time=7.3s
2025-10-13 09:38:00,592 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.9537 | val_loss=0.9011 | val_acc=0.7302 | time=7.2s
2025-10-13 09:38:07,804 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9391 | val_loss=0.8878 | val_acc=0.7365 | time=7.2s
2025-10-13 09:38:15,052 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9317 | val_loss=0.8782 | val_acc=0.7394 | time=7.2s
2025-10-13 09:38:22,278 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.9229 | val_loss=0.8721 | val_acc=0.7431 | time=7.2s
2025-10-13 09:38:29,471 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.9144 | val_loss=0.8635 | val_acc=0.7461 | time=7.2s
2025-10-13 09:38:36,716 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.9063 | val_loss=0.8564 | val_acc=0.7507 | time=7.2s
2025-10-13 09:38:43,910 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.8979 | val_loss=0.8565 | val_acc=0.7441 | time=7.2s
2025-10-13 09:38:51,168 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.8917 | val_loss=0.8538 | val_acc=0.7458 | time=7.3s
2025-10-13 09:38:58,432 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.8844 | val_loss=0.8545 | val_acc=0.7458 | time=7.3s
2025-10-13 09:39:05,676 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.8820 | val_loss=0.8373 | val_acc=0.7587 | time=7.2s
2025-10-13 09:39:12,900 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.8790 | val_loss=0.8287 | val_acc=0.7635 | time=7.2s
2025-10-13 09:39:20,110 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8733 | val_loss=0.8259 | val_acc=0.7673 | time=7.2s
2025-10-13 09:39:27,308 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8718 | val_loss=0.8243 | val_acc=0.7695 | time=7.2s
2025-10-13 09:39:34,524 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8615 | val_loss=0.8198 | val_acc=0.7705 | time=7.2s
2025-10-13 09:39:41,735 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8647 | val_loss=0.8148 | val_acc=0.7700 | time=7.2s
2025-10-13 09:39:48,968 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8572 | val_loss=0.8183 | val_acc=0.7658 | time=7.2s
2025-10-13 09:39:56,205 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8571 | val_loss=0.8172 | val_acc=0.7664 | time=7.2s
2025-10-13 09:40:03,454 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8536 | val_loss=0.8125 | val_acc=0.7692 | time=7.2s
2025-10-13 09:40:10,681 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8514 | val_loss=0.8080 | val_acc=0.7726 | time=7.2s
2025-10-13 09:40:17,896 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8488 | val_loss=0.8030 | val_acc=0.7793 | time=7.2s
2025-10-13 09:40:25,089 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8450 | val_loss=0.8062 | val_acc=0.7724 | time=7.2s
2025-10-13 09:40:32,277 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.8449 | val_loss=0.8024 | val_acc=0.7758 | time=7.2s
2025-10-13 09:40:39,532 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.8408 | val_loss=0.7987 | val_acc=0.7773 | time=7.3s
2025-10-13 09:40:46,751 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.8383 | val_loss=0.7978 | val_acc=0.7765 | time=7.2s
2025-10-13 09:40:53,993 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.8396 | val_loss=0.7989 | val_acc=0.7767 | time=7.2s
2025-10-13 09:41:01,233 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.8367 | val_loss=0.7977 | val_acc=0.7765 | time=7.2s
2025-10-13 09:41:08,507 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.8340 | val_loss=0.7931 | val_acc=0.7789 | time=7.3s
2025-10-13 09:41:15,737 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.8385 | val_loss=0.7960 | val_acc=0.7765 | time=7.2s
2025-10-13 09:41:23,011 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.8328 | val_loss=0.7888 | val_acc=0.7825 | time=7.3s
2025-10-13 09:41:30,270 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.8306 | val_loss=0.7915 | val_acc=0.7793 | time=7.3s
2025-10-13 09:41:37,490 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.8294 | val_loss=0.7892 | val_acc=0.7816 | time=7.2s
2025-10-13 09:41:44,735 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.8278 | val_loss=0.7905 | val_acc=0.7820 | time=7.2s
2025-10-13 09:41:51,937 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.8265 | val_loss=0.7872 | val_acc=0.7810 | time=7.2s
2025-10-13 09:41:59,129 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.8255 | val_loss=0.7994 | val_acc=0.7741 | time=7.2s
2025-10-13 09:42:06,347 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.8215 | val_loss=0.7866 | val_acc=0.7806 | time=7.2s
2025-10-13 09:42:13,601 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.8237 | val_loss=0.7896 | val_acc=0.7806 | time=7.3s
2025-10-13 09:42:20,827 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.8218 | val_loss=0.7813 | val_acc=0.7856 | time=7.2s
2025-10-13 09:42:28,081 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.8179 | val_loss=0.7898 | val_acc=0.7803 | time=7.3s
2025-10-13 09:42:35,326 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.8181 | val_loss=0.7822 | val_acc=0.7840 | time=7.2s
2025-10-13 09:42:42,554 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.8230 | val_loss=0.7783 | val_acc=0.7873 | time=7.2s
2025-10-13 09:42:49,768 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.8132 | val_loss=0.7786 | val_acc=0.7868 | time=7.2s
2025-10-13 09:42:56,968 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.8176 | val_loss=0.7795 | val_acc=0.7902 | time=7.2s
2025-10-13 09:43:04,181 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.8144 | val_loss=0.7838 | val_acc=0.7820 | time=7.2s
2025-10-13 09:43:11,450 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.8125 | val_loss=0.7785 | val_acc=0.7861 | time=7.3s
2025-10-13 09:43:18,668 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.8130 | val_loss=0.7742 | val_acc=0.7879 | time=7.2s
2025-10-13 09:43:25,909 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.8114 | val_loss=0.7764 | val_acc=0.7882 | time=7.2s
2025-10-13 09:43:33,108 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.8105 | val_loss=0.7738 | val_acc=0.7872 | time=7.2s
2025-10-13 09:43:40,336 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.8075 | val_loss=0.7740 | val_acc=0.7890 | time=7.2s
2025-10-13 09:43:47,535 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.8097 | val_loss=0.7696 | val_acc=0.7931 | time=7.2s
2025-10-13 09:43:54,760 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.8059 | val_loss=0.7704 | val_acc=0.7903 | time=7.2s
2025-10-13 09:44:01,989 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.8048 | val_loss=0.7737 | val_acc=0.7887 | time=7.2s
2025-10-13 09:44:09,245 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.8058 | val_loss=0.7693 | val_acc=0.7905 | time=7.3s
2025-10-13 09:44:16,446 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.8067 | val_loss=0.7744 | val_acc=0.7877 | time=7.2s
2025-10-13 09:44:23,669 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.8047 | val_loss=0.7693 | val_acc=0.7910 | time=7.2s
2025-10-13 09:44:30,915 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.8023 | val_loss=0.7685 | val_acc=0.7926 | time=7.2s
2025-10-13 09:44:38,170 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.8022 | val_loss=0.7684 | val_acc=0.7900 | time=7.3s
2025-10-13 09:44:45,402 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.8006 | val_loss=0.7744 | val_acc=0.7878 | time=7.2s
2025-10-13 09:44:52,628 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.8002 | val_loss=0.7646 | val_acc=0.7924 | time=7.2s
2025-10-13 09:44:59,888 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.8011 | val_loss=0.7648 | val_acc=0.7911 | time=7.3s
2025-10-13 09:45:07,120 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.7973 | val_loss=0.7658 | val_acc=0.7924 | time=7.2s
2025-10-13 09:45:14,336 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.7986 | val_loss=0.7673 | val_acc=0.7917 | time=7.2s
2025-10-13 09:45:21,568 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.7962 | val_loss=0.7650 | val_acc=0.7921 | time=7.2s
2025-10-13 09:45:28,817 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.7988 | val_loss=0.7612 | val_acc=0.7942 | time=7.2s
2025-10-13 09:45:36,039 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.7972 | val_loss=0.7623 | val_acc=0.7945 | time=7.2s
2025-10-13 09:45:43,225 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.7959 | val_loss=0.7614 | val_acc=0.7953 | time=7.2s
2025-10-13 09:45:50,437 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.7930 | val_loss=0.7615 | val_acc=0.7940 | time=7.2s
2025-10-13 09:45:57,677 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.7945 | val_loss=0.7600 | val_acc=0.7938 | time=7.2s
2025-10-13 09:46:04,908 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.7941 | val_loss=0.7596 | val_acc=0.7956 | time=7.2s
2025-10-13 09:46:04,912 - INFO - _models.training_function_executor - Quantized model size: 73409 bytes.
2025-10-13 09:46:06,021 - INFO - _models.training_function_executor - Model: 14,078 parameters, 60.5KB storage
2025-10-13 09:46:06,021 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.4667557442901766, 1.2207362077058426, 1.1323979422684771, 1.0790667308766315, 1.0511699263182477, 1.0340757492876236, 1.0207635892576632, 1.000297137436685, 0.9820327379922997, 0.9612669684188451, 0.9536816336326679, 0.939076802511085, 0.9316825599031178, 0.9228978075470422, 0.9143577541009839, 0.9063494279328701, 0.8978756968379229, 0.8916959440453636, 0.8844070316696234, 0.8820222423841872, 0.8790156061431517, 0.8733388867501742, 0.8718192863597877, 0.8614862481217557, 0.8647036853894764, 0.8572164429289751, 0.8571004149669277, 0.8535705522344293, 0.8513988488030092, 0.8487839144574707, 0.8449900540848232, 0.84485046767379, 0.8407698353354147, 0.8383194112385491, 0.8396248141806318, 0.8367052105890106, 0.8340416782211916, 0.8384857234585148, 0.832802392779675, 0.8306380983391215, 0.8293578419436681, 0.8277627631922806, 0.8265020897390962, 0.8255047745165559, 0.8214629346313783, 0.8236954039445823, 0.8218300848688159, 0.8179094356008455, 0.8180520009297694, 0.8229957322557782, 0.813165835663285, 0.8175546970031959, 0.8143684030997824, 0.8124656715007524, 0.8129767301118495, 0.8114122532446317, 0.810520546708359, 0.8075074739689004, 0.8096800573668281, 0.805851789884397, 0.804829423614094, 0.8058409043175381, 0.8067398466323696, 0.804710748732236, 0.8023028189083643, 0.8022224488252521, 0.8005798283493681, 0.8002230581867558, 0.8010907144157629, 0.797287142043102, 0.7986292242169338, 0.7962435770794192, 0.7988077979593541, 0.7972077684340713, 0.7959253502593076, 0.7929738188774635, 0.7944895018845285, 0.794070651220783], 'val_losses': [1.2848243478882508, 1.1363061364397202, 1.0578757697650507, 1.0204131203303606, 0.9912605242041553, 0.974336096069635, 0.9575788511193462, 0.94051452401972, 0.9343618727831896, 0.9104436784721898, 0.9011251034334401, 0.887806776085641, 0.878213591871038, 0.8720910362025679, 0.8635186275736535, 0.8564200972943278, 0.8565414679772294, 0.8538097293384433, 0.8545257373835851, 0.837275543995658, 0.8286629472948848, 0.8259109655251068, 0.8242570254658335, 0.8198474262158771, 0.8148142324697316, 0.8183309228469493, 0.8172203853783759, 0.8125008460229454, 0.8080329702248471, 0.8030485677101581, 0.8062290240093508, 0.8023895112041998, 0.7987223577157242, 0.7978119879992308, 0.7988633421237626, 0.7976659967384432, 0.7931395161181094, 0.7959683895277986, 0.7888486881459723, 0.7914682268303593, 0.789241569376843, 0.7905053160680438, 0.7872036997989045, 0.7994342856695905, 0.7865560774749754, 0.789592262786462, 0.7813289867734258, 0.7897825742836052, 0.7822483129379505, 0.77831758670887, 0.7786337698010828, 0.7795267197524162, 0.7837721131087434, 0.7784998530393553, 0.7741693383461535, 0.7764090301066711, 0.7738371540250835, 0.7739930362562888, 0.7695771750345654, 0.7704083526055213, 0.7737270360502865, 0.769275569951238, 0.7744246076611234, 0.7692971175727538, 0.7684822437393528, 0.768351277355385, 0.7744142228713351, 0.7645512699747069, 0.7648019028014555, 0.7658254109169162, 0.7672650739576669, 0.7649745284196668, 0.7612451521988135, 0.7623244382866121, 0.7613988518714905, 0.7615150000233729, 0.7599883162353603, 0.7596222246427573], 'val_acc': [0.5843542177108856, 0.6245187259362969, 0.6421071053552677, 0.646044802240112, 0.6575953797689884, 0.6697584879243962, 0.6847217360868043, 0.7072103605180259, 0.7107105355267763, 0.7254112705635282, 0.73022401120056, 0.7365243262163108, 0.7394119705985299, 0.7430871543577179, 0.7461498074903745, 0.7507000350017501, 0.744137206860343, 0.7457997899894995, 0.7457997899894995, 0.7586629331466573, 0.7634756737836892, 0.7673258662933147, 0.7695134756737837, 0.7704760238011901, 0.7699509975498775, 0.7658382919145957, 0.7663633181659083, 0.7691634581729087, 0.7725761288064403, 0.7793139656982849, 0.7724011200560028, 0.7758137906895345, 0.7773013650682534, 0.7765138256912846, 0.7766888344417221, 0.7765138256912846, 0.7788764438221911, 0.7765138256912846, 0.7824641232061603, 0.7793139656982849, 0.7815890794539727, 0.7820266013300665, 0.7809765488274414, 0.7740637031851593, 0.7806265313265663, 0.7806265313265663, 0.7856142807140357, 0.7802765138256913, 0.7839516975848793, 0.7872768638431922, 0.7867518375918796, 0.7901645082254113, 0.7820266013300665, 0.7860518025901295, 0.7878893944697235, 0.7882394119705985, 0.7871893594679734, 0.7890269513475674, 0.7931396569828492, 0.79025201260063, 0.7886769338466924, 0.7905145257262863, 0.787714385719286, 0.7909520476023801, 0.7926146307315366, 0.7899894994749738, 0.7878018900945047, 0.7923521176058803, 0.7911270563528177, 0.7923521176058803, 0.791739586979349, 0.792089604480224, 0.7941897094854743, 0.7944522226111306, 0.7953272663633182, 0.7940147007350368, 0.7938396919845992, 0.7955897794889745], 'model_size_bytes': 73409, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.7566808400905703e-05, 'batch_size': 16, 'epochs': 78, 'weight_decay': 0.00049740320014252, 'dropout': 0.1853993257090927, 'hidden_size': 30, 'd_model': 19, 't_pooled': 128, 'label_smoothing': 0.09087967526431262, 'use_focal_loss': False, 'focal_gamma': 3.4736356391138346, 'grad_clip_norm': 4.974461764046135, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 14078, 'model_storage_size_kb': 60.491406250000004, 'model_size_validation': 'PASS'}
2025-10-13 09:46:06,021 - INFO - _models.training_function_executor - BO Objective: base=0.7956, size_penalty=0.0000, final=0.7956
2025-10-13 09:46:06,021 - INFO - _models.training_function_executor - Model: 14,078 parameters, 60.5KB (PASS 256KB limit)
2025-10-13 09:46:06,021 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 567.803s
2025-10-13 09:46:06,133 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7956
2025-10-13 09:46:06,133 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 09:46:06,133 - INFO - bo.run_bo - Recorded observation #42: hparams={'lr': 1.7566808400905703e-05, 'batch_size': np.int64(16), 'epochs': np.int64(78), 'weight_decay': 0.00049740320014252, 'dropout': 0.1853993257090927, 'hidden_size': np.int64(30), 'd_model': np.int64(19), 't_pooled': np.int64(128), 'label_smoothing': 0.09087967526431262, 'use_focal_loss': np.False_, 'focal_gamma': 3.4736356391138346, 'grad_clip_norm': 4.974461764046135, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7956
2025-10-13 09:46:06,133 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 42: {'lr': 1.7566808400905703e-05, 'batch_size': np.int64(16), 'epochs': np.int64(78), 'weight_decay': 0.00049740320014252, 'dropout': 0.1853993257090927, 'hidden_size': np.int64(30), 'd_model': np.int64(19), 't_pooled': np.int64(128), 'label_smoothing': 0.09087967526431262, 'use_focal_loss': np.False_, 'focal_gamma': 3.4736356391138346, 'grad_clip_norm': 4.974461764046135, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7956
2025-10-13 09:46:06,134 - INFO - bo.run_bo - üîçBO Trial 43: Using RF surrogate + Expected Improvement
2025-10-13 09:46:06,134 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 09:46:06,134 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 43 (NaN monitoring active)
2025-10-13 09:46:06,134 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 09:46:06,134 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 09:46:06,134 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.7504530919506154e-05, 'batch_size': 32, 'epochs': 80, 'weight_decay': 0.00021720955995968482, 'dropout': 0.1338091323899264, 'hidden_size': 19, 'd_model': 32, 't_pooled': 192, 'label_smoothing': 0.1366900431363104, 'use_focal_loss': True, 'focal_gamma': 0.5845685018539699, 'grad_clip_norm': 3.6081366997732873, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:46:06,135 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.7504530919506154e-05, 'batch_size': 32, 'epochs': 80, 'weight_decay': 0.00021720955995968482, 'dropout': 0.1338091323899264, 'hidden_size': 19, 'd_model': 32, 't_pooled': 192, 'label_smoothing': 0.1366900431363104, 'use_focal_loss': True, 'focal_gamma': 0.5845685018539699, 'grad_clip_norm': 3.6081366997732873, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:46:13,969 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.3645 | val_loss=1.3093 | val_acc=0.3909 | time=7.8s
2025-10-13 09:46:18,967 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2239 | val_loss=1.1314 | val_acc=0.5746 | time=5.0s
2025-10-13 09:46:23,973 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.0758 | val_loss=1.0126 | val_acc=0.6033 | time=5.0s
2025-10-13 09:46:28,974 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9830 | val_loss=0.9304 | val_acc=0.6220 | time=5.0s
2025-10-13 09:46:33,973 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.9135 | val_loss=0.8627 | val_acc=0.6447 | time=5.0s
2025-10-13 09:46:38,976 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.8579 | val_loss=0.8175 | val_acc=0.6558 | time=5.0s
2025-10-13 09:46:43,973 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8268 | val_loss=0.7918 | val_acc=0.6636 | time=5.0s
2025-10-13 09:46:48,980 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.8047 | val_loss=0.7770 | val_acc=0.6714 | time=5.0s
2025-10-13 09:46:54,000 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.7921 | val_loss=0.7661 | val_acc=0.6773 | time=5.0s
2025-10-13 09:46:59,039 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.7827 | val_loss=0.7548 | val_acc=0.6853 | time=5.0s
2025-10-13 09:47:04,069 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.7740 | val_loss=0.7471 | val_acc=0.6894 | time=5.0s
2025-10-13 09:47:09,127 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.7665 | val_loss=0.7402 | val_acc=0.6979 | time=5.1s
2025-10-13 09:47:14,155 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.7561 | val_loss=0.7347 | val_acc=0.6936 | time=5.0s
2025-10-13 09:47:19,175 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.7483 | val_loss=0.7343 | val_acc=0.7088 | time=5.0s
2025-10-13 09:47:24,211 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.7439 | val_loss=0.7194 | val_acc=0.7069 | time=5.0s
2025-10-13 09:47:29,340 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7370 | val_loss=0.7124 | val_acc=0.7117 | time=5.1s
2025-10-13 09:47:34,389 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.7278 | val_loss=0.7023 | val_acc=0.7214 | time=5.0s
2025-10-13 09:47:39,432 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.7183 | val_loss=0.6985 | val_acc=0.7204 | time=5.0s
2025-10-13 09:47:44,461 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.7135 | val_loss=0.6877 | val_acc=0.7307 | time=5.0s
2025-10-13 09:47:49,485 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.7045 | val_loss=0.6802 | val_acc=0.7363 | time=5.0s
2025-10-13 09:47:54,496 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.6975 | val_loss=0.6715 | val_acc=0.7402 | time=5.0s
2025-10-13 09:47:59,519 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.6916 | val_loss=0.6652 | val_acc=0.7423 | time=5.0s
2025-10-13 09:48:04,607 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.6813 | val_loss=0.6561 | val_acc=0.7504 | time=5.1s
2025-10-13 09:48:09,698 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.6785 | val_loss=0.6511 | val_acc=0.7526 | time=5.1s
2025-10-13 09:48:14,756 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.6714 | val_loss=0.6472 | val_acc=0.7539 | time=5.1s
2025-10-13 09:48:19,784 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.6671 | val_loss=0.6493 | val_acc=0.7518 | time=5.0s
2025-10-13 09:48:24,802 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.6623 | val_loss=0.6385 | val_acc=0.7574 | time=5.0s
2025-10-13 09:48:29,827 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.6580 | val_loss=0.6319 | val_acc=0.7614 | time=5.0s
2025-10-13 09:48:34,858 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.6532 | val_loss=0.6274 | val_acc=0.7627 | time=5.0s
2025-10-13 09:48:39,899 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.6541 | val_loss=0.6251 | val_acc=0.7643 | time=5.0s
2025-10-13 09:48:44,929 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.6469 | val_loss=0.6223 | val_acc=0.7655 | time=5.0s
2025-10-13 09:48:49,964 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.6447 | val_loss=0.6191 | val_acc=0.7689 | time=5.0s
2025-10-13 09:48:54,992 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.6399 | val_loss=0.6140 | val_acc=0.7707 | time=5.0s
2025-10-13 09:49:00,002 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.6368 | val_loss=0.6108 | val_acc=0.7706 | time=5.0s
2025-10-13 09:49:05,026 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.6323 | val_loss=0.6154 | val_acc=0.7726 | time=5.0s
2025-10-13 09:49:10,054 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.6304 | val_loss=0.6061 | val_acc=0.7729 | time=5.0s
2025-10-13 09:49:15,111 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.6286 | val_loss=0.6019 | val_acc=0.7754 | time=5.1s
2025-10-13 09:49:20,170 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.6260 | val_loss=0.5999 | val_acc=0.7765 | time=5.1s
2025-10-13 09:49:25,207 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.6229 | val_loss=0.5967 | val_acc=0.7760 | time=5.0s
2025-10-13 09:49:30,241 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.6204 | val_loss=0.6025 | val_acc=0.7772 | time=5.0s
2025-10-13 09:49:35,302 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.6189 | val_loss=0.5931 | val_acc=0.7766 | time=5.1s
2025-10-13 09:49:40,320 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.6135 | val_loss=0.5899 | val_acc=0.7770 | time=5.0s
2025-10-13 09:49:45,337 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.6126 | val_loss=0.5873 | val_acc=0.7828 | time=5.0s
2025-10-13 09:49:50,391 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.6098 | val_loss=0.5846 | val_acc=0.7811 | time=5.1s
2025-10-13 09:49:55,432 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.6094 | val_loss=0.5833 | val_acc=0.7832 | time=5.0s
2025-10-13 09:50:00,456 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.6038 | val_loss=0.5847 | val_acc=0.7850 | time=5.0s
2025-10-13 09:50:05,483 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.6044 | val_loss=0.5837 | val_acc=0.7800 | time=5.0s
2025-10-13 09:50:10,524 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.6020 | val_loss=0.5758 | val_acc=0.7848 | time=5.0s
2025-10-13 09:50:15,619 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.6000 | val_loss=0.5756 | val_acc=0.7859 | time=5.1s
2025-10-13 09:50:20,662 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.5984 | val_loss=0.5740 | val_acc=0.7867 | time=5.0s
2025-10-13 09:50:25,736 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.5977 | val_loss=0.5742 | val_acc=0.7838 | time=5.1s
2025-10-13 09:50:30,769 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.5967 | val_loss=0.5765 | val_acc=0.7854 | time=5.0s
2025-10-13 09:50:35,816 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.5934 | val_loss=0.5688 | val_acc=0.7859 | time=5.0s
2025-10-13 09:50:40,842 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.5931 | val_loss=0.5707 | val_acc=0.7878 | time=5.0s
2025-10-13 09:50:45,867 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.5896 | val_loss=0.5666 | val_acc=0.7896 | time=5.0s
2025-10-13 09:50:50,900 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.5902 | val_loss=0.5644 | val_acc=0.7906 | time=5.0s
2025-10-13 09:50:55,931 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.5894 | val_loss=0.5640 | val_acc=0.7900 | time=5.0s
2025-10-13 09:51:00,963 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.5851 | val_loss=0.5619 | val_acc=0.7907 | time=5.0s
2025-10-13 09:51:06,046 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.5843 | val_loss=0.5608 | val_acc=0.7911 | time=5.1s
2025-10-13 09:51:11,078 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.5855 | val_loss=0.5590 | val_acc=0.7923 | time=5.0s
2025-10-13 09:51:16,116 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.5803 | val_loss=0.5590 | val_acc=0.7928 | time=5.0s
2025-10-13 09:51:21,145 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.5803 | val_loss=0.5598 | val_acc=0.7914 | time=5.0s
2025-10-13 09:51:26,181 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.5810 | val_loss=0.5553 | val_acc=0.7942 | time=5.0s
2025-10-13 09:51:31,224 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.5782 | val_loss=0.5601 | val_acc=0.7885 | time=5.0s
2025-10-13 09:51:36,267 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.5788 | val_loss=0.5555 | val_acc=0.7942 | time=5.0s
2025-10-13 09:51:41,296 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.5765 | val_loss=0.5534 | val_acc=0.7935 | time=5.0s
2025-10-13 09:51:46,319 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.5738 | val_loss=0.5521 | val_acc=0.7950 | time=5.0s
2025-10-13 09:51:51,376 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.5724 | val_loss=0.5532 | val_acc=0.7927 | time=5.1s
2025-10-13 09:51:56,409 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.5724 | val_loss=0.5512 | val_acc=0.7940 | time=5.0s
2025-10-13 09:52:01,443 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.5714 | val_loss=0.5494 | val_acc=0.7953 | time=5.0s
2025-10-13 09:52:06,474 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.5697 | val_loss=0.5493 | val_acc=0.7959 | time=5.0s
2025-10-13 09:52:11,516 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.5701 | val_loss=0.5468 | val_acc=0.7972 | time=5.0s
2025-10-13 09:52:16,562 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.5688 | val_loss=0.5486 | val_acc=0.7936 | time=5.0s
2025-10-13 09:52:21,614 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.5682 | val_loss=0.5531 | val_acc=0.7928 | time=5.1s
2025-10-13 09:52:26,677 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.5677 | val_loss=0.5436 | val_acc=0.7970 | time=5.1s
2025-10-13 09:52:31,720 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.5644 | val_loss=0.5487 | val_acc=0.7934 | time=5.0s
2025-10-13 09:52:36,762 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.5693 | val_loss=0.5476 | val_acc=0.7945 | time=5.0s
2025-10-13 09:52:41,802 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.5650 | val_loss=0.5463 | val_acc=0.7952 | time=5.0s
2025-10-13 09:52:46,827 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.5628 | val_loss=0.5414 | val_acc=0.7973 | time=5.0s
2025-10-13 09:52:51,853 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.5612 | val_loss=0.5438 | val_acc=0.7967 | time=5.0s
2025-10-13 09:52:51,861 - INFO - _models.training_function_executor - Quantized model size: 47227 bytes.
2025-10-13 09:52:52,953 - INFO - _models.training_function_executor - Model: 5,308 parameters, 5.7KB storage
2025-10-13 09:52:52,953 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.3645205962144706, 1.2239263031421777, 1.0757869912228637, 0.9830480445545371, 0.9135477963885854, 0.8578656713654622, 0.8268199785213851, 0.8047383901828395, 0.792092641083394, 0.7826655606602638, 0.7740172495322917, 0.7664903062058362, 0.756089052517263, 0.7483329235944124, 0.7439399754663093, 0.7370204770110227, 0.7278345653674466, 0.7182528543689262, 0.7135105911860067, 0.7044655961676581, 0.6974712817828306, 0.6916207309406789, 0.6812910472007326, 0.6785249093382518, 0.6714422944379012, 0.6671136744505549, 0.6623443949669026, 0.6579817177158659, 0.6532486173962229, 0.6541248999736841, 0.6468658788161633, 0.6447383652920067, 0.6398831281914008, 0.6368297714222383, 0.6322769002769224, 0.6303716786349199, 0.6285523529606847, 0.6260211929433781, 0.6229085101608134, 0.6203966521490776, 0.618892229830088, 0.6135091174303922, 0.6126007782148656, 0.6097903592961211, 0.6093987830669094, 0.6037660564081128, 0.6043883163819666, 0.6019858776542495, 0.599952142400094, 0.5984489184640945, 0.5976885773729185, 0.5967498850396851, 0.5934300949033591, 0.5930515813648096, 0.5896375801832808, 0.5902234430825497, 0.5893981233630349, 0.585118988885469, 0.5843418651750383, 0.5855192564399166, 0.580330104230374, 0.5803341380482501, 0.5810074900095389, 0.5781780368054209, 0.5787630402461857, 0.5764539658001014, 0.5737784370534855, 0.5723564269703754, 0.572393628342568, 0.571435050464486, 0.5696855096663468, 0.5701431883228464, 0.5687842212609574, 0.5681731871971101, 0.5676940035519585, 0.5644071055827209, 0.5693209995787837, 0.5649937726126962, 0.5627959044529585, 0.5611934703381946], 'val_losses': [1.30929555169427, 1.1313733446210008, 1.0125952529915572, 0.9304448755879814, 0.8626821054459286, 0.8175321007509269, 0.7918030611067582, 0.7770072050682097, 0.7661293269997925, 0.7548099349001549, 0.7470519418769839, 0.74023445997365, 0.7346998177335777, 0.7342910661870965, 0.719415128961242, 0.7124067555785721, 0.7022751156249829, 0.6984812571091129, 0.6877134802210444, 0.6801574078939743, 0.6714595510569911, 0.6652250391726816, 0.6561212151105645, 0.6511103640831055, 0.6471506053015282, 0.6492666595041398, 0.6384623397218626, 0.6318743611012133, 0.6273504217521353, 0.6251291189424883, 0.6222957291613938, 0.6190953177403519, 0.6140499058661029, 0.610832008920769, 0.6154154710912354, 0.6060530018213958, 0.6019373129600822, 0.5999210895276128, 0.5966598096013195, 0.6025078491205763, 0.5930573778487103, 0.5899451109217229, 0.5872931256551278, 0.5845890434254789, 0.5832814619722256, 0.5847195630875508, 0.5837277316175059, 0.5757558754911613, 0.5755795364326475, 0.574022104700921, 0.574187110406684, 0.5764643425890562, 0.5688074979908949, 0.5707051123527952, 0.5666086579854562, 0.5644295025756403, 0.5640384220851649, 0.5618895973448241, 0.5608040763128459, 0.5590417056097031, 0.5589854045476703, 0.5597561084811071, 0.555337268028553, 0.5600564442900957, 0.5554880660378019, 0.5534103311439224, 0.5520830372642461, 0.5531707180518557, 0.5512067827470744, 0.5493818180916565, 0.5493224266737877, 0.5468186019474199, 0.5486021762675325, 0.5531276426492223, 0.5436066382929375, 0.5487157568090397, 0.5475574826543299, 0.5462893887462422, 0.5414205680662909, 0.5438420952597322], 'val_acc': [0.3908820441022051, 0.5746412320616031, 0.603255162758138, 0.6219810990549528, 0.6447322366118305, 0.6558452922646132, 0.6636331816590829, 0.6714210710535526, 0.6772838641932096, 0.6853342667133356, 0.6893594679733986, 0.6979348967448372, 0.6936471823591179, 0.7087854392719636, 0.7069478473923696, 0.7116730836541827, 0.7213860693034652, 0.7204235211760588, 0.7306615330766538, 0.7362618130906545, 0.7401995099754988, 0.742299614980749, 0.750350017500875, 0.7526251312565628, 0.7539376968848442, 0.751837591879594, 0.7573503675183759, 0.7613755687784389, 0.7626881344067203, 0.764263213160658, 0.7654882744137207, 0.7689009450472524, 0.7707385369268464, 0.7705635281764088, 0.7725761288064403, 0.7729261463073154, 0.7753762688134407, 0.7765138256912846, 0.775988799439972, 0.7772138606930347, 0.7766013300665033, 0.7770388519425971, 0.7828141407070354, 0.7810640532026601, 0.7831641582079104, 0.7850017500875044, 0.780014000700035, 0.7848267413370669, 0.785876793839692, 0.7866643332166608, 0.7837766888344417, 0.7853517675883794, 0.785876793839692, 0.7878018900945047, 0.78955197759888, 0.7906020301015051, 0.7899894994749738, 0.7906895344767239, 0.7911270563528177, 0.7922646132306616, 0.7927896394819741, 0.7913895694784739, 0.7941897094854743, 0.7885019250962548, 0.7941897094854743, 0.7934896744837242, 0.7949772488624431, 0.7927021351067554, 0.7940147007350368, 0.7953272663633182, 0.7958522926146308, 0.7971648582429122, 0.793577178858943, 0.7927896394819741, 0.7969898494924746, 0.7934021701085054, 0.7944522226111306, 0.7952397619880994, 0.7972523626181309, 0.7967273363668184], 'model_size_bytes': 47227, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.7504530919506154e-05, 'batch_size': 32, 'epochs': 80, 'weight_decay': 0.00021720955995968482, 'dropout': 0.1338091323899264, 'hidden_size': 19, 'd_model': 32, 't_pooled': 192, 'label_smoothing': 0.1366900431363104, 'use_focal_loss': True, 'focal_gamma': 0.5845685018539699, 'grad_clip_norm': 3.6081366997732873, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 5308, 'model_storage_size_kb': 5.701953125, 'model_size_validation': 'PASS'}
2025-10-13 09:52:52,953 - INFO - _models.training_function_executor - BO Objective: base=0.7967, size_penalty=0.0000, final=0.7967
2025-10-13 09:52:52,953 - INFO - _models.training_function_executor - Model: 5,308 parameters, 5.7KB (PASS 256KB limit)
2025-10-13 09:52:52,954 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 406.820s
2025-10-13 09:52:53,063 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7967
2025-10-13 09:52:53,063 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.107s
2025-10-13 09:52:53,063 - INFO - bo.run_bo - Recorded observation #43: hparams={'lr': 1.7504530919506154e-05, 'batch_size': np.int64(32), 'epochs': np.int64(80), 'weight_decay': 0.00021720955995968482, 'dropout': 0.1338091323899264, 'hidden_size': np.int64(19), 'd_model': np.int64(32), 't_pooled': np.int64(192), 'label_smoothing': 0.1366900431363104, 'use_focal_loss': np.True_, 'focal_gamma': 0.5845685018539699, 'grad_clip_norm': 3.6081366997732873, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7967
2025-10-13 09:52:53,063 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 43: {'lr': 1.7504530919506154e-05, 'batch_size': np.int64(32), 'epochs': np.int64(80), 'weight_decay': 0.00021720955995968482, 'dropout': 0.1338091323899264, 'hidden_size': np.int64(19), 'd_model': np.int64(32), 't_pooled': np.int64(192), 'label_smoothing': 0.1366900431363104, 'use_focal_loss': np.True_, 'focal_gamma': 0.5845685018539699, 'grad_clip_norm': 3.6081366997732873, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7967
2025-10-13 09:52:53,063 - INFO - bo.run_bo - üîçBO Trial 44: Using RF surrogate + Expected Improvement
2025-10-13 09:52:53,064 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 09:52:53,064 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 44 (NaN monitoring active)
2025-10-13 09:52:53,064 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 09:52:53,064 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 09:52:53,064 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.746588893371882e-05, 'batch_size': 32, 'epochs': 82, 'weight_decay': 0.0024305591042650112, 'dropout': 0.13168878222919864, 'hidden_size': 21, 'd_model': 28, 't_pooled': 192, 'label_smoothing': 0.17458501280566285, 'use_focal_loss': False, 'focal_gamma': 3.637774111737782, 'grad_clip_norm': 4.375632072519856, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:52:53,065 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.746588893371882e-05, 'batch_size': 32, 'epochs': 82, 'weight_decay': 0.0024305591042650112, 'dropout': 0.13168878222919864, 'hidden_size': 21, 'd_model': 28, 't_pooled': 192, 'label_smoothing': 0.17458501280566285, 'use_focal_loss': False, 'focal_gamma': 3.637774111737782, 'grad_clip_norm': 4.375632072519856, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:53:00,864 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5542 | val_loss=1.5034 | val_acc=0.3858 | time=7.8s
2025-10-13 09:53:05,838 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.4227 | val_loss=1.3394 | val_acc=0.5793 | time=5.0s
2025-10-13 09:53:10,817 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.2943 | val_loss=1.2455 | val_acc=0.6171 | time=5.0s
2025-10-13 09:53:15,809 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.2306 | val_loss=1.1913 | val_acc=0.6386 | time=5.0s
2025-10-13 09:53:20,771 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.1894 | val_loss=1.1607 | val_acc=0.6450 | time=5.0s
2025-10-13 09:53:25,739 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.1629 | val_loss=1.1352 | val_acc=0.6492 | time=5.0s
2025-10-13 09:53:30,725 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.1447 | val_loss=1.1146 | val_acc=0.6574 | time=5.0s
2025-10-13 09:53:35,694 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.1312 | val_loss=1.1026 | val_acc=0.6656 | time=5.0s
2025-10-13 09:53:40,661 - INFO - _models.training_function_executor - Epoch 009 | train_loss=1.1186 | val_loss=1.0918 | val_acc=0.6778 | time=5.0s
2025-10-13 09:53:45,652 - INFO - _models.training_function_executor - Epoch 010 | train_loss=1.1107 | val_loss=1.0819 | val_acc=0.6865 | time=5.0s
2025-10-13 09:53:50,637 - INFO - _models.training_function_executor - Epoch 011 | train_loss=1.1021 | val_loss=1.0720 | val_acc=0.6966 | time=5.0s
2025-10-13 09:53:55,648 - INFO - _models.training_function_executor - Epoch 012 | train_loss=1.0913 | val_loss=1.0626 | val_acc=0.7077 | time=5.0s
2025-10-13 09:54:00,644 - INFO - _models.training_function_executor - Epoch 013 | train_loss=1.0826 | val_loss=1.0524 | val_acc=0.7205 | time=5.0s
2025-10-13 09:54:05,643 - INFO - _models.training_function_executor - Epoch 014 | train_loss=1.0727 | val_loss=1.0418 | val_acc=0.7309 | time=5.0s
2025-10-13 09:54:10,610 - INFO - _models.training_function_executor - Epoch 015 | train_loss=1.0602 | val_loss=1.0319 | val_acc=0.7354 | time=5.0s
2025-10-13 09:54:15,582 - INFO - _models.training_function_executor - Epoch 016 | train_loss=1.0484 | val_loss=1.0214 | val_acc=0.7435 | time=5.0s
2025-10-13 09:54:20,576 - INFO - _models.training_function_executor - Epoch 017 | train_loss=1.0386 | val_loss=1.0121 | val_acc=0.7469 | time=5.0s
2025-10-13 09:54:25,574 - INFO - _models.training_function_executor - Epoch 018 | train_loss=1.0335 | val_loss=1.0108 | val_acc=0.7474 | time=5.0s
2025-10-13 09:54:30,567 - INFO - _models.training_function_executor - Epoch 019 | train_loss=1.0272 | val_loss=1.0016 | val_acc=0.7526 | time=5.0s
2025-10-13 09:54:35,566 - INFO - _models.training_function_executor - Epoch 020 | train_loss=1.0214 | val_loss=0.9996 | val_acc=0.7509 | time=5.0s
2025-10-13 09:54:40,557 - INFO - _models.training_function_executor - Epoch 021 | train_loss=1.0144 | val_loss=0.9921 | val_acc=0.7571 | time=5.0s
2025-10-13 09:54:45,543 - INFO - _models.training_function_executor - Epoch 022 | train_loss=1.0142 | val_loss=0.9879 | val_acc=0.7591 | time=5.0s
2025-10-13 09:54:50,535 - INFO - _models.training_function_executor - Epoch 023 | train_loss=1.0106 | val_loss=0.9844 | val_acc=0.7594 | time=5.0s
2025-10-13 09:54:55,508 - INFO - _models.training_function_executor - Epoch 024 | train_loss=1.0036 | val_loss=0.9816 | val_acc=0.7619 | time=5.0s
2025-10-13 09:55:00,499 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.9998 | val_loss=0.9816 | val_acc=0.7614 | time=5.0s
2025-10-13 09:55:05,502 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.9970 | val_loss=0.9756 | val_acc=0.7645 | time=5.0s
2025-10-13 09:55:10,476 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.9959 | val_loss=0.9733 | val_acc=0.7658 | time=5.0s
2025-10-13 09:55:15,457 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.9913 | val_loss=0.9730 | val_acc=0.7668 | time=5.0s
2025-10-13 09:55:20,458 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.9889 | val_loss=0.9683 | val_acc=0.7697 | time=5.0s
2025-10-13 09:55:25,458 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.9880 | val_loss=0.9703 | val_acc=0.7684 | time=5.0s
2025-10-13 09:55:30,447 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.9853 | val_loss=0.9650 | val_acc=0.7717 | time=5.0s
2025-10-13 09:55:35,431 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.9854 | val_loss=0.9613 | val_acc=0.7743 | time=5.0s
2025-10-13 09:55:40,430 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.9809 | val_loss=0.9602 | val_acc=0.7749 | time=5.0s
2025-10-13 09:55:45,418 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.9804 | val_loss=0.9580 | val_acc=0.7759 | time=5.0s
2025-10-13 09:55:50,410 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.9778 | val_loss=0.9568 | val_acc=0.7758 | time=5.0s
2025-10-13 09:55:55,376 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.9769 | val_loss=0.9548 | val_acc=0.7784 | time=5.0s
2025-10-13 09:56:00,361 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.9756 | val_loss=0.9538 | val_acc=0.7781 | time=5.0s
2025-10-13 09:56:05,344 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.9734 | val_loss=0.9537 | val_acc=0.7797 | time=5.0s
2025-10-13 09:56:10,349 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.9719 | val_loss=0.9555 | val_acc=0.7792 | time=5.0s
2025-10-13 09:56:15,317 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.9721 | val_loss=0.9515 | val_acc=0.7791 | time=5.0s
2025-10-13 09:56:20,304 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.9688 | val_loss=0.9506 | val_acc=0.7806 | time=5.0s
2025-10-13 09:56:25,269 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.9695 | val_loss=0.9482 | val_acc=0.7832 | time=5.0s
2025-10-13 09:56:30,240 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.9686 | val_loss=0.9499 | val_acc=0.7824 | time=5.0s
2025-10-13 09:56:35,226 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.9661 | val_loss=0.9491 | val_acc=0.7801 | time=5.0s
2025-10-13 09:56:40,208 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.9641 | val_loss=0.9463 | val_acc=0.7811 | time=5.0s
2025-10-13 09:56:45,183 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.9645 | val_loss=0.9441 | val_acc=0.7868 | time=5.0s
2025-10-13 09:56:50,172 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.9646 | val_loss=0.9441 | val_acc=0.7854 | time=5.0s
2025-10-13 09:56:55,163 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.9617 | val_loss=0.9456 | val_acc=0.7868 | time=5.0s
2025-10-13 09:57:00,171 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.9623 | val_loss=0.9424 | val_acc=0.7872 | time=5.0s
2025-10-13 09:57:05,194 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.9598 | val_loss=0.9420 | val_acc=0.7882 | time=5.0s
2025-10-13 09:57:10,171 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.9611 | val_loss=0.9396 | val_acc=0.7876 | time=5.0s
2025-10-13 09:57:15,178 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.9603 | val_loss=0.9429 | val_acc=0.7865 | time=5.0s
2025-10-13 09:57:20,161 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.9586 | val_loss=0.9390 | val_acc=0.7880 | time=5.0s
2025-10-13 09:57:25,130 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.9588 | val_loss=0.9410 | val_acc=0.7869 | time=5.0s
2025-10-13 09:57:30,109 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.9575 | val_loss=0.9370 | val_acc=0.7907 | time=5.0s
2025-10-13 09:57:35,089 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.9579 | val_loss=0.9366 | val_acc=0.7897 | time=5.0s
2025-10-13 09:57:40,059 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.9572 | val_loss=0.9390 | val_acc=0.7875 | time=5.0s
2025-10-13 09:57:45,046 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.9566 | val_loss=0.9378 | val_acc=0.7898 | time=5.0s
2025-10-13 09:57:50,040 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.9549 | val_loss=0.9349 | val_acc=0.7909 | time=5.0s
2025-10-13 09:57:55,019 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.9556 | val_loss=0.9360 | val_acc=0.7924 | time=5.0s
2025-10-13 09:58:00,020 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.9518 | val_loss=0.9347 | val_acc=0.7911 | time=5.0s
2025-10-13 09:58:04,989 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.9528 | val_loss=0.9347 | val_acc=0.7890 | time=5.0s
2025-10-13 09:58:09,988 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.9506 | val_loss=0.9321 | val_acc=0.7923 | time=5.0s
2025-10-13 09:58:15,023 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.9517 | val_loss=0.9344 | val_acc=0.7902 | time=5.0s
2025-10-13 09:58:20,004 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.9514 | val_loss=0.9337 | val_acc=0.7910 | time=5.0s
2025-10-13 09:58:24,976 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.9486 | val_loss=0.9321 | val_acc=0.7916 | time=5.0s
2025-10-13 09:58:29,952 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.9496 | val_loss=0.9308 | val_acc=0.7924 | time=5.0s
2025-10-13 09:58:34,928 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.9488 | val_loss=0.9305 | val_acc=0.7938 | time=5.0s
2025-10-13 09:58:39,933 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.9486 | val_loss=0.9300 | val_acc=0.7931 | time=5.0s
2025-10-13 09:58:44,922 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.9475 | val_loss=0.9291 | val_acc=0.7944 | time=5.0s
2025-10-13 09:58:49,909 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.9464 | val_loss=0.9292 | val_acc=0.7942 | time=5.0s
2025-10-13 09:58:54,880 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.9480 | val_loss=0.9304 | val_acc=0.7922 | time=5.0s
2025-10-13 09:58:59,862 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.9466 | val_loss=0.9313 | val_acc=0.7913 | time=5.0s
2025-10-13 09:59:04,849 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.9457 | val_loss=0.9277 | val_acc=0.7934 | time=5.0s
2025-10-13 09:59:09,844 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.9450 | val_loss=0.9293 | val_acc=0.7950 | time=5.0s
2025-10-13 09:59:14,824 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.9458 | val_loss=0.9267 | val_acc=0.7952 | time=5.0s
2025-10-13 09:59:19,797 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.9449 | val_loss=0.9279 | val_acc=0.7973 | time=5.0s
2025-10-13 09:59:24,770 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.9445 | val_loss=0.9280 | val_acc=0.7936 | time=5.0s
2025-10-13 09:59:29,765 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.9422 | val_loss=0.9262 | val_acc=0.7977 | time=5.0s
2025-10-13 09:59:34,789 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.9421 | val_loss=0.9305 | val_acc=0.7936 | time=5.0s
2025-10-13 09:59:39,780 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.9432 | val_loss=0.9279 | val_acc=0.7930 | time=5.0s
2025-10-13 09:59:44,776 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.9405 | val_loss=0.9267 | val_acc=0.7973 | time=5.0s
2025-10-13 09:59:44,779 - INFO - _models.training_function_executor - Quantized model size: 64001 bytes.
2025-10-13 09:59:45,902 - INFO - _models.training_function_executor - Model: 11,720 parameters, 50.4KB storage
2025-10-13 09:59:45,903 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.5541702185137771, 1.4226886442502895, 1.294323849602934, 1.2306016843386534, 1.1893934989501265, 1.1628995641028084, 1.1446587237854458, 1.13117346907146, 1.1186432458322115, 1.110698044946822, 1.1021065386934719, 1.0912729010825646, 1.0826395414991314, 1.0726632094274753, 1.060209201230926, 1.0483760418155872, 1.038577839340995, 1.033452489553818, 1.027203550695914, 1.0213789268519688, 1.0143500215989707, 1.0141761844125627, 1.0106200038197577, 1.0036180785038606, 0.999832121859408, 0.9969699764151568, 0.9959434446939689, 0.9912845507175471, 0.9889173124234577, 0.988029739178266, 0.9852739636782044, 0.9854301641902851, 0.9809173548350937, 0.9804235283294507, 0.9777708296430332, 0.976925852856187, 0.9756406813932958, 0.9733551042998717, 0.9719370058211239, 0.9721471406297747, 0.9688096472880704, 0.9694559515294471, 0.9685952019182418, 0.9661289054194989, 0.9640673441114148, 0.9645142953087911, 0.9645798370727175, 0.961714187159086, 0.9623408163599422, 0.9597936408437129, 0.9611010332394614, 0.9602694200142555, 0.9586098569233099, 0.9587970783879884, 0.9574920878278488, 0.9578576949997135, 0.9571909489521498, 0.9565746670091406, 0.9548612659862921, 0.9556021419988464, 0.9518442028754651, 0.9527854487576349, 0.9505729775851033, 0.9516949416208317, 0.951366389594714, 0.9485700567744184, 0.9495785638173644, 0.9487768468382811, 0.9485881966563176, 0.9474931543925695, 0.94642013513754, 0.9479836173352971, 0.9466463536869032, 0.9456661973001241, 0.9450042222319761, 0.9457814231968694, 0.9449330476935109, 0.9445445916850458, 0.9422096186348472, 0.9421089038508398, 0.9431578949443269, 0.9404616558263883], 'val_losses': [1.5034088370764134, 1.3394131797320532, 1.2455095960245208, 1.1912638879047643, 1.1606548367407843, 1.1352399502094284, 1.1146098273927865, 1.102578344985994, 1.0917767136506698, 1.0819272304023526, 1.0719580406236364, 1.062604577799214, 1.0524232985884066, 1.0417913870040378, 1.0318520571286753, 1.0214114638529834, 1.012072042522624, 1.0108114059963633, 1.0015586881650926, 0.9995550847696099, 0.9921073449171212, 0.987870084767914, 0.9844224517229432, 0.9816197942176982, 0.9815917229126665, 0.9756245855939609, 0.9733298151151759, 0.9729634013090844, 0.9682866414610556, 0.9703080444683092, 0.9649881346475256, 0.9613090079065215, 0.9602426638084147, 0.9579884347107847, 0.956814458268399, 0.95479720601428, 0.9538109017536696, 0.953743056563343, 0.9554888804058199, 0.9514568502935531, 0.9505721264716667, 0.9482192354766397, 0.9498564536061619, 0.9490775433210881, 0.9463238428846539, 0.9440870598600092, 0.9440646945157584, 0.9455720070445709, 0.9424132314394269, 0.9420176742792046, 0.9395870015385019, 0.9429020642983901, 0.9390114819957611, 0.9410258461471868, 0.9370343405590384, 0.9366331903050736, 0.9390431949422207, 0.9378446121085637, 0.9349191956349842, 0.9360479402258381, 0.9346798308712643, 0.9347260087405129, 0.9321177508975393, 0.9343807129414298, 0.9337432898755753, 0.9320944150845237, 0.9307947514939233, 0.9304721185198855, 0.9299952310826506, 0.9290990713054081, 0.9291506552971616, 0.9303511095122102, 0.931336876684275, 0.9276766583015754, 0.9292823927862309, 0.926697483795441, 0.9278683891069401, 0.9280224265357937, 0.9262348792333472, 0.9305003788198338, 0.9278663861446962, 0.9267256059219339], 'val_acc': [0.385806790339517, 0.5792789639481974, 0.6170808540427022, 0.6386069303465173, 0.6449947497374868, 0.6491949597479874, 0.6574203710185509, 0.6656457822891144, 0.6778088904445222, 0.6864718235911795, 0.6966223311165558, 0.7077353867693384, 0.7205110255512776, 0.7309240462023101, 0.7353867693384669, 0.7435246762338117, 0.7469373468673434, 0.7473748687434372, 0.7526251312565628, 0.7508750437521876, 0.7570878543927196, 0.7591004550227511, 0.7593629681484074, 0.7619005950297515, 0.7613755687784389, 0.7645257262863143, 0.7658382919145957, 0.7668008400420021, 0.7696884844242212, 0.7683759187959398, 0.7717010850542527, 0.7743262163108156, 0.7749387469373469, 0.7759012950647532, 0.7758137906895345, 0.7784389219460973, 0.7780889044452223, 0.77966398319916, 0.7792264613230662, 0.7791389569478474, 0.7806265313265663, 0.7831641582079104, 0.7823766188309416, 0.7801015050752538, 0.7810640532026601, 0.7868393419670984, 0.7853517675883794, 0.7868393419670984, 0.7871893594679734, 0.7881519075953798, 0.7876268813440672, 0.7864893244662233, 0.7879768988449423, 0.7869268463423171, 0.7906895344767239, 0.7897269863493175, 0.7874518725936297, 0.7898144907245362, 0.7908645432271614, 0.7924396219810991, 0.7911270563528177, 0.7890269513475674, 0.7922646132306616, 0.7901645082254113, 0.7909520476023801, 0.7915645782289115, 0.7924396219810991, 0.7938396919845992, 0.7931396569828492, 0.7943647182359118, 0.7941897094854743, 0.7921771088554428, 0.7913020651032552, 0.7934021701085054, 0.7949772488624431, 0.7951522576128807, 0.7973398669933497, 0.793577178858943, 0.7976898844942247, 0.793577178858943, 0.7929646482324116, 0.7973398669933497], 'model_size_bytes': 64001, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.746588893371882e-05, 'batch_size': 32, 'epochs': 82, 'weight_decay': 0.0024305591042650112, 'dropout': 0.13168878222919864, 'hidden_size': 21, 'd_model': 28, 't_pooled': 192, 'label_smoothing': 0.17458501280566285, 'use_focal_loss': False, 'focal_gamma': 3.637774111737782, 'grad_clip_norm': 4.375632072519856, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 11720, 'model_storage_size_kb': 50.35937500000001, 'model_size_validation': 'PASS'}
2025-10-13 09:59:45,903 - INFO - _models.training_function_executor - BO Objective: base=0.7973, size_penalty=0.0000, final=0.7973
2025-10-13 09:59:45,903 - INFO - _models.training_function_executor - Model: 11,720 parameters, 50.4KB (PASS 256KB limit)
2025-10-13 09:59:45,903 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 412.839s
2025-10-13 09:59:46,016 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7973
2025-10-13 09:59:46,016 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 09:59:46,016 - INFO - bo.run_bo - Recorded observation #44: hparams={'lr': 1.746588893371882e-05, 'batch_size': np.int64(32), 'epochs': np.int64(82), 'weight_decay': 0.0024305591042650112, 'dropout': 0.13168878222919864, 'hidden_size': np.int64(21), 'd_model': np.int64(28), 't_pooled': np.int64(192), 'label_smoothing': 0.17458501280566285, 'use_focal_loss': np.False_, 'focal_gamma': 3.637774111737782, 'grad_clip_norm': 4.375632072519856, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7973
2025-10-13 09:59:46,016 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 44: {'lr': 1.746588893371882e-05, 'batch_size': np.int64(32), 'epochs': np.int64(82), 'weight_decay': 0.0024305591042650112, 'dropout': 0.13168878222919864, 'hidden_size': np.int64(21), 'd_model': np.int64(28), 't_pooled': np.int64(192), 'label_smoothing': 0.17458501280566285, 'use_focal_loss': np.False_, 'focal_gamma': 3.637774111737782, 'grad_clip_norm': 4.375632072519856, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7973
2025-10-13 09:59:46,017 - INFO - bo.run_bo - üîçBO Trial 45: Using RF surrogate + Expected Improvement
2025-10-13 09:59:46,017 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 09:59:46,017 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 45 (NaN monitoring active)
2025-10-13 09:59:46,017 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 09:59:46,017 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 09:59:46,017 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.626619022810857e-05, 'batch_size': 24, 'epochs': 79, 'weight_decay': 0.0004245713426871563, 'dropout': 0.043939830096603245, 'hidden_size': 20, 'd_model': 31, 't_pooled': 256, 'label_smoothing': 0.1992559515276209, 'use_focal_loss': True, 'focal_gamma': 4.500469865278282, 'grad_clip_norm': 1.3083873586343384, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:59:46,018 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.626619022810857e-05, 'batch_size': 24, 'epochs': 79, 'weight_decay': 0.0004245713426871563, 'dropout': 0.043939830096603245, 'hidden_size': 20, 'd_model': 31, 't_pooled': 256, 'label_smoothing': 0.1992559515276209, 'use_focal_loss': True, 'focal_gamma': 4.500469865278282, 'grad_clip_norm': 1.3083873586343384, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 09:59:54,911 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.5092 | val_loss=0.4309 | val_acc=0.5520 | time=8.8s
2025-10-13 10:00:00,832 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.3780 | val_loss=0.3240 | val_acc=0.6117 | time=5.9s
2025-10-13 10:00:06,739 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.3032 | val_loss=0.2692 | val_acc=0.6363 | time=5.9s
2025-10-13 10:00:12,674 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.2679 | val_loss=0.2425 | val_acc=0.6606 | time=5.9s
2025-10-13 10:00:18,597 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.2465 | val_loss=0.2221 | val_acc=0.6848 | time=5.9s
2025-10-13 10:00:24,512 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.2328 | val_loss=0.2077 | val_acc=0.7000 | time=5.9s
2025-10-13 10:00:30,437 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.2237 | val_loss=0.2001 | val_acc=0.7097 | time=5.9s
2025-10-13 10:00:36,342 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.2168 | val_loss=0.1938 | val_acc=0.7154 | time=5.9s
2025-10-13 10:00:42,299 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.2135 | val_loss=0.1885 | val_acc=0.7198 | time=6.0s
2025-10-13 10:00:48,232 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.2086 | val_loss=0.1847 | val_acc=0.7246 | time=5.9s
2025-10-13 10:00:54,167 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.2020 | val_loss=0.1802 | val_acc=0.7305 | time=5.9s
2025-10-13 10:01:00,104 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.1963 | val_loss=0.1763 | val_acc=0.7325 | time=5.9s
2025-10-13 10:01:06,049 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.1925 | val_loss=0.1730 | val_acc=0.7367 | time=5.9s
2025-10-13 10:01:11,994 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.1878 | val_loss=0.1678 | val_acc=0.7432 | time=5.9s
2025-10-13 10:01:17,935 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.1843 | val_loss=0.1648 | val_acc=0.7461 | time=5.9s
2025-10-13 10:01:23,875 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.1797 | val_loss=0.1636 | val_acc=0.7441 | time=5.9s
2025-10-13 10:01:29,841 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.1768 | val_loss=0.1587 | val_acc=0.7499 | time=6.0s
2025-10-13 10:01:35,789 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.1752 | val_loss=0.1554 | val_acc=0.7519 | time=5.9s
2025-10-13 10:01:41,750 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.1712 | val_loss=0.1543 | val_acc=0.7534 | time=6.0s
2025-10-13 10:01:47,657 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.1674 | val_loss=0.1504 | val_acc=0.7583 | time=5.9s
2025-10-13 10:01:53,568 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.1648 | val_loss=0.1475 | val_acc=0.7623 | time=5.9s
2025-10-13 10:01:59,498 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.1647 | val_loss=0.1448 | val_acc=0.7620 | time=5.9s
2025-10-13 10:02:05,404 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.1601 | val_loss=0.1441 | val_acc=0.7660 | time=5.9s
2025-10-13 10:02:11,313 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.1587 | val_loss=0.1406 | val_acc=0.7656 | time=5.9s
2025-10-13 10:02:17,252 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.1553 | val_loss=0.1423 | val_acc=0.7640 | time=5.9s
2025-10-13 10:02:23,162 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.1545 | val_loss=0.1392 | val_acc=0.7680 | time=5.9s
2025-10-13 10:02:29,157 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.1532 | val_loss=0.1405 | val_acc=0.7652 | time=6.0s
2025-10-13 10:02:35,073 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.1504 | val_loss=0.1339 | val_acc=0.7724 | time=5.9s
2025-10-13 10:02:41,009 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.1492 | val_loss=0.1344 | val_acc=0.7707 | time=5.9s
2025-10-13 10:02:46,961 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.1459 | val_loss=0.1322 | val_acc=0.7728 | time=6.0s
2025-10-13 10:02:52,909 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.1468 | val_loss=0.1308 | val_acc=0.7748 | time=5.9s
2025-10-13 10:02:58,832 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.1451 | val_loss=0.1300 | val_acc=0.7770 | time=5.9s
2025-10-13 10:03:04,753 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.1448 | val_loss=0.1288 | val_acc=0.7775 | time=5.9s
2025-10-13 10:03:10,679 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.1432 | val_loss=0.1288 | val_acc=0.7790 | time=5.9s
2025-10-13 10:03:16,617 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.1414 | val_loss=0.1273 | val_acc=0.7810 | time=5.9s
2025-10-13 10:03:22,530 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.1421 | val_loss=0.1257 | val_acc=0.7809 | time=5.9s
2025-10-13 10:03:28,540 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.1405 | val_loss=0.1247 | val_acc=0.7827 | time=6.0s
2025-10-13 10:03:34,490 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.1398 | val_loss=0.1260 | val_acc=0.7833 | time=5.9s
2025-10-13 10:03:40,461 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.1383 | val_loss=0.1244 | val_acc=0.7839 | time=6.0s
2025-10-13 10:03:46,417 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.1402 | val_loss=0.1227 | val_acc=0.7835 | time=6.0s
2025-10-13 10:03:52,397 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.1387 | val_loss=0.1249 | val_acc=0.7777 | time=6.0s
2025-10-13 10:03:58,322 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.1386 | val_loss=0.1213 | val_acc=0.7852 | time=5.9s
2025-10-13 10:04:04,300 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.1369 | val_loss=0.1216 | val_acc=0.7843 | time=6.0s
2025-10-13 10:04:10,261 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.1365 | val_loss=0.1215 | val_acc=0.7870 | time=6.0s
2025-10-13 10:04:16,219 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.1353 | val_loss=0.1223 | val_acc=0.7813 | time=6.0s
2025-10-13 10:04:22,184 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.1355 | val_loss=0.1212 | val_acc=0.7879 | time=6.0s
2025-10-13 10:04:28,136 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.1351 | val_loss=0.1213 | val_acc=0.7832 | time=6.0s
2025-10-13 10:04:34,142 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.1352 | val_loss=0.1195 | val_acc=0.7847 | time=6.0s
2025-10-13 10:04:40,064 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.1336 | val_loss=0.1199 | val_acc=0.7863 | time=5.9s
2025-10-13 10:04:46,002 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.1347 | val_loss=0.1187 | val_acc=0.7872 | time=5.9s
2025-10-13 10:04:51,937 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.1335 | val_loss=0.1188 | val_acc=0.7859 | time=5.9s
2025-10-13 10:04:57,849 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.1329 | val_loss=0.1180 | val_acc=0.7875 | time=5.9s
2025-10-13 10:05:03,754 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.1326 | val_loss=0.1182 | val_acc=0.7874 | time=5.9s
2025-10-13 10:05:09,677 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.1328 | val_loss=0.1201 | val_acc=0.7831 | time=5.9s
2025-10-13 10:05:15,642 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.1314 | val_loss=0.1182 | val_acc=0.7872 | time=6.0s
2025-10-13 10:05:21,573 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.1324 | val_loss=0.1171 | val_acc=0.7900 | time=5.9s
2025-10-13 10:05:27,512 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.1310 | val_loss=0.1182 | val_acc=0.7861 | time=5.9s
2025-10-13 10:05:33,522 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.1314 | val_loss=0.1180 | val_acc=0.7883 | time=6.0s
2025-10-13 10:05:39,451 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.1306 | val_loss=0.1184 | val_acc=0.7872 | time=5.9s
2025-10-13 10:05:45,398 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.1304 | val_loss=0.1180 | val_acc=0.7895 | time=5.9s
2025-10-13 10:05:51,328 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.1297 | val_loss=0.1164 | val_acc=0.7894 | time=5.9s
2025-10-13 10:05:57,240 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.1281 | val_loss=0.1163 | val_acc=0.7910 | time=5.9s
2025-10-13 10:06:03,160 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.1305 | val_loss=0.1174 | val_acc=0.7901 | time=5.9s
2025-10-13 10:06:09,113 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.1289 | val_loss=0.1159 | val_acc=0.7878 | time=6.0s
2025-10-13 10:06:15,085 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.1299 | val_loss=0.1159 | val_acc=0.7917 | time=6.0s
2025-10-13 10:06:21,020 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.1274 | val_loss=0.1155 | val_acc=0.7902 | time=5.9s
2025-10-13 10:06:26,946 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.1285 | val_loss=0.1154 | val_acc=0.7902 | time=5.9s
2025-10-13 10:06:32,862 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.1290 | val_loss=0.1187 | val_acc=0.7880 | time=5.9s
2025-10-13 10:06:38,782 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.1265 | val_loss=0.1155 | val_acc=0.7916 | time=5.9s
2025-10-13 10:06:44,736 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.1280 | val_loss=0.1151 | val_acc=0.7902 | time=6.0s
2025-10-13 10:06:50,687 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.1262 | val_loss=0.1142 | val_acc=0.7910 | time=6.0s
2025-10-13 10:06:56,626 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.1271 | val_loss=0.1154 | val_acc=0.7920 | time=5.9s
2025-10-13 10:07:02,565 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.1266 | val_loss=0.1164 | val_acc=0.7873 | time=5.9s
2025-10-13 10:07:08,486 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.1260 | val_loss=0.1175 | val_acc=0.7902 | time=5.9s
2025-10-13 10:07:14,437 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.1263 | val_loss=0.1139 | val_acc=0.7914 | time=6.0s
2025-10-13 10:07:20,373 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.1272 | val_loss=0.1143 | val_acc=0.7925 | time=5.9s
2025-10-13 10:07:26,352 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.1268 | val_loss=0.1154 | val_acc=0.7896 | time=6.0s
2025-10-13 10:07:32,296 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.1253 | val_loss=0.1143 | val_acc=0.7919 | time=5.9s
2025-10-13 10:07:38,226 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.1251 | val_loss=0.1138 | val_acc=0.7925 | time=5.9s
2025-10-13 10:07:38,229 - INFO - _models.training_function_executor - Quantized model size: 64193 bytes.
2025-10-13 10:07:39,313 - INFO - _models.training_function_executor - Model: 11,767 parameters, 50.6KB storage
2025-10-13 10:07:39,313 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.509169161032871, 0.3779711454407836, 0.30321743234986814, 0.267917095136196, 0.24649836077091783, 0.23277760714834955, 0.223684552137694, 0.2168397662856694, 0.21354617631811965, 0.20858536540971673, 0.20202756090833562, 0.1963305682423735, 0.19248593535820607, 0.1877743218245365, 0.1842946328358359, 0.17969613674523469, 0.176775806162625, 0.17517529860318834, 0.1712447052758277, 0.16743698724117528, 0.16475633734893894, 0.16466299907327492, 0.16005355651246883, 0.15869677019601192, 0.1552647220464355, 0.15448110882065066, 0.15316454299957363, 0.1504173279434474, 0.1491634628103409, 0.14586783402772488, 0.14683805229412872, 0.14510951425924526, 0.14484858463590364, 0.14322910082451856, 0.14141678413272551, 0.14214919147785463, 0.1405061839150358, 0.1398374206129961, 0.13834442928600318, 0.14020757883980134, 0.1386752586781139, 0.13864876443665575, 0.13690667003940818, 0.1364877842686807, 0.13530222126691854, 0.1355061995880636, 0.1351334706237647, 0.13515699917752405, 0.13361139792791188, 0.1347003670374768, 0.13350277465184981, 0.1328703115208842, 0.1326174364439259, 0.13279915575719106, 0.13136918596091451, 0.13240978659362404, 0.13099195121594834, 0.1313723535360074, 0.13060270399826626, 0.13036151623270564, 0.12967627073188615, 0.12805046654695246, 0.13048126679996083, 0.1288606945567399, 0.1299292340732545, 0.12744657251277158, 0.1285260675310708, 0.1289818262180009, 0.12646001853220917, 0.12795496580318413, 0.12624378573073816, 0.12712674419922734, 0.12660694350336904, 0.12595250857892906, 0.12629894581830373, 0.12720856878686126, 0.1268222644256208, 0.12525830543960229, 0.12511601780453552], 'val_losses': [0.4309475657236422, 0.32396815687491004, 0.26921942628761003, 0.24253970843576492, 0.2220927116167391, 0.20774238849483173, 0.20010956115746856, 0.19376575617177694, 0.18845816427045742, 0.1847328098088576, 0.1802244721215882, 0.17627858582559397, 0.17301692871789562, 0.16782125600378622, 0.16476158381530695, 0.16362935649918892, 0.1586993144949625, 0.155438564900318, 0.1542962082369285, 0.15035814499840439, 0.14747840014316002, 0.1448035189190193, 0.14411382728944427, 0.14060886658005753, 0.1422548407482066, 0.1391873581293875, 0.14045211921570225, 0.13385481955623726, 0.13444164563016037, 0.13223255849986132, 0.13082662266234146, 0.13003896075631088, 0.1287950612304717, 0.12877536471444156, 0.12729757622870108, 0.1257263064660891, 0.12474726798455532, 0.12603035810415586, 0.12440736119798067, 0.12273703977376964, 0.12494951600549853, 0.12130062567903982, 0.12155617808217055, 0.12145910077748867, 0.12225099440206379, 0.1212319117306745, 0.12129075309776075, 0.11951785676747216, 0.11989464100201229, 0.11873219307090879, 0.11875511551100472, 0.11802569161976681, 0.11823367221312879, 0.12008885669727028, 0.1182381934259774, 0.11710066507913702, 0.11819029450520878, 0.11803173177051177, 0.11843518648227487, 0.11801674206293584, 0.1163818829053655, 0.1163090003571562, 0.11736382451201803, 0.1159418399752459, 0.11586228871146281, 0.11553929253791986, 0.11535795717143203, 0.11873644634841371, 0.11554842090998908, 0.11512090976907108, 0.11417588805157194, 0.11539823225757063, 0.11641369159973956, 0.11748856878365134, 0.11387597484332221, 0.11425862986937368, 0.1153826124269853, 0.11433720748935457, 0.11376907077178197], 'val_acc': [0.551977598879944, 0.6117430871543578, 0.6363318165908295, 0.6605705285264263, 0.6848092404620231, 0.7000350017500875, 0.7096604830241512, 0.7154357717885894, 0.7198109905495275, 0.7246237311865593, 0.7304865243262163, 0.7324991249562478, 0.7366993349667483, 0.7431746587329366, 0.7461498074903745, 0.744137206860343, 0.7499124956247812, 0.7519250962548127, 0.7534126706335317, 0.7583129156457823, 0.7623381169058453, 0.7619880994049703, 0.7660133006650333, 0.7655757787889395, 0.7640007000350018, 0.7680259012950648, 0.7652257612880644, 0.7724011200560028, 0.7706510325516276, 0.7727511375568779, 0.7747637381869094, 0.7769513475673784, 0.777476373818691, 0.7789639481974099, 0.7809765488274414, 0.7808890444522226, 0.7827266363318166, 0.7832516625831292, 0.7838641932096605, 0.7835141757087855, 0.7776513825691285, 0.7851767588379419, 0.7843017150857543, 0.7870143507175359, 0.7813265663283164, 0.7878893944697235, 0.7831641582079104, 0.7847392369618481, 0.7863143157157858, 0.7871893594679734, 0.785876793839692, 0.7875393769688485, 0.7873643682184109, 0.7830766538326916, 0.7871893594679734, 0.7899894994749738, 0.7861393069653483, 0.7883269163458173, 0.7871893594679734, 0.7894644732236612, 0.7893769688484424, 0.7909520476023801, 0.7900770038501925, 0.7878018900945047, 0.7916520826041302, 0.7901645082254113, 0.7901645082254113, 0.7879768988449423, 0.7915645782289115, 0.7901645082254113, 0.7909520476023801, 0.7920021001050053, 0.7872768638431922, 0.7901645082254113, 0.7913895694784739, 0.7925271263563178, 0.78955197759888, 0.7919145957297865, 0.7925271263563178], 'model_size_bytes': 64193, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.626619022810857e-05, 'batch_size': 24, 'epochs': 79, 'weight_decay': 0.0004245713426871563, 'dropout': 0.043939830096603245, 'hidden_size': 20, 'd_model': 31, 't_pooled': 256, 'label_smoothing': 0.1992559515276209, 'use_focal_loss': True, 'focal_gamma': 4.500469865278282, 'grad_clip_norm': 1.3083873586343384, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 11767, 'model_storage_size_kb': 50.561328125, 'model_size_validation': 'PASS'}
2025-10-13 10:07:39,313 - INFO - _models.training_function_executor - BO Objective: base=0.7925, size_penalty=0.0000, final=0.7925
2025-10-13 10:07:39,313 - INFO - _models.training_function_executor - Model: 11,767 parameters, 50.6KB (PASS 256KB limit)
2025-10-13 10:07:39,313 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 473.296s
2025-10-13 10:07:39,426 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7925
2025-10-13 10:07:39,427 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 10:07:39,427 - INFO - bo.run_bo - Recorded observation #45: hparams={'lr': 1.626619022810857e-05, 'batch_size': np.int64(24), 'epochs': np.int64(79), 'weight_decay': 0.0004245713426871563, 'dropout': 0.043939830096603245, 'hidden_size': np.int64(20), 'd_model': np.int64(31), 't_pooled': np.int64(256), 'label_smoothing': 0.1992559515276209, 'use_focal_loss': np.True_, 'focal_gamma': 4.500469865278282, 'grad_clip_norm': 1.3083873586343384, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7925
2025-10-13 10:07:39,427 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 45: {'lr': 1.626619022810857e-05, 'batch_size': np.int64(24), 'epochs': np.int64(79), 'weight_decay': 0.0004245713426871563, 'dropout': 0.043939830096603245, 'hidden_size': np.int64(20), 'd_model': np.int64(31), 't_pooled': np.int64(256), 'label_smoothing': 0.1992559515276209, 'use_focal_loss': np.True_, 'focal_gamma': 4.500469865278282, 'grad_clip_norm': 1.3083873586343384, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7925
2025-10-13 10:07:39,427 - INFO - bo.run_bo - üîçBO Trial 46: Using RF surrogate + Expected Improvement
2025-10-13 10:07:39,427 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 10:07:39,427 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 46 (NaN monitoring active)
2025-10-13 10:07:39,427 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 10:07:39,427 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 10:07:39,427 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.570265852568054e-05, 'batch_size': 16, 'epochs': 96, 'weight_decay': 0.000810847585223415, 'dropout': 0.3551803749043084, 'hidden_size': 27, 'd_model': 28, 't_pooled': 192, 'label_smoothing': 0.09378526261075382, 'use_focal_loss': False, 'focal_gamma': 1.8905925754696444, 'grad_clip_norm': 0.8976976089082568, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 10:07:39,428 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.570265852568054e-05, 'batch_size': 16, 'epochs': 96, 'weight_decay': 0.000810847585223415, 'dropout': 0.3551803749043084, 'hidden_size': 27, 'd_model': 28, 't_pooled': 192, 'label_smoothing': 0.09378526261075382, 'use_focal_loss': False, 'focal_gamma': 1.8905925754696444, 'grad_clip_norm': 0.8976976089082568, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 10:07:49,546 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.5293 | val_loss=1.3928 | val_acc=0.5040 | time=10.1s
2025-10-13 10:07:56,838 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.2737 | val_loss=1.1594 | val_acc=0.6327 | time=7.3s
2025-10-13 10:08:04,127 - INFO - _models.training_function_executor - Epoch 003 | train_loss=1.1508 | val_loss=1.0687 | val_acc=0.6412 | time=7.3s
2025-10-13 10:08:11,420 - INFO - _models.training_function_executor - Epoch 004 | train_loss=1.0935 | val_loss=1.0230 | val_acc=0.6470 | time=7.3s
2025-10-13 10:08:18,731 - INFO - _models.training_function_executor - Epoch 005 | train_loss=1.0652 | val_loss=0.9971 | val_acc=0.6578 | time=7.3s
2025-10-13 10:08:26,139 - INFO - _models.training_function_executor - Epoch 006 | train_loss=1.0468 | val_loss=0.9827 | val_acc=0.6857 | time=7.4s
2025-10-13 10:08:33,455 - INFO - _models.training_function_executor - Epoch 007 | train_loss=1.0282 | val_loss=0.9576 | val_acc=0.6978 | time=7.3s
2025-10-13 10:08:40,704 - INFO - _models.training_function_executor - Epoch 008 | train_loss=1.0105 | val_loss=0.9438 | val_acc=0.7020 | time=7.2s
2025-10-13 10:08:47,995 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.9911 | val_loss=0.9234 | val_acc=0.7202 | time=7.3s
2025-10-13 10:08:55,295 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.9811 | val_loss=0.9129 | val_acc=0.7301 | time=7.3s
2025-10-13 10:09:02,634 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.9675 | val_loss=0.9050 | val_acc=0.7327 | time=7.3s
2025-10-13 10:09:09,935 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.9581 | val_loss=0.8933 | val_acc=0.7366 | time=7.3s
2025-10-13 10:09:17,213 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.9510 | val_loss=0.8851 | val_acc=0.7411 | time=7.3s
2025-10-13 10:09:24,512 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.9445 | val_loss=0.8792 | val_acc=0.7448 | time=7.3s
2025-10-13 10:09:31,798 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.9335 | val_loss=0.8731 | val_acc=0.7431 | time=7.3s
2025-10-13 10:09:39,114 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.9316 | val_loss=0.8674 | val_acc=0.7489 | time=7.3s
2025-10-13 10:09:46,373 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.9264 | val_loss=0.8624 | val_acc=0.7513 | time=7.3s
2025-10-13 10:09:53,665 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.9161 | val_loss=0.8558 | val_acc=0.7567 | time=7.3s
2025-10-13 10:10:00,970 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.9121 | val_loss=0.8500 | val_acc=0.7581 | time=7.3s
2025-10-13 10:10:08,275 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.9091 | val_loss=0.8473 | val_acc=0.7595 | time=7.3s
2025-10-13 10:10:15,557 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.9017 | val_loss=0.8427 | val_acc=0.7596 | time=7.3s
2025-10-13 10:10:22,883 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.8974 | val_loss=0.8403 | val_acc=0.7630 | time=7.3s
2025-10-13 10:10:30,170 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.8962 | val_loss=0.8360 | val_acc=0.7645 | time=7.3s
2025-10-13 10:10:37,487 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.8908 | val_loss=0.8315 | val_acc=0.7659 | time=7.3s
2025-10-13 10:10:44,763 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.8891 | val_loss=0.8281 | val_acc=0.7687 | time=7.3s
2025-10-13 10:10:52,086 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.8862 | val_loss=0.8243 | val_acc=0.7691 | time=7.3s
2025-10-13 10:10:59,359 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.8835 | val_loss=0.8236 | val_acc=0.7717 | time=7.3s
2025-10-13 10:11:06,666 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.8848 | val_loss=0.8235 | val_acc=0.7735 | time=7.3s
2025-10-13 10:11:13,963 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.8764 | val_loss=0.8232 | val_acc=0.7753 | time=7.3s
2025-10-13 10:11:21,243 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.8754 | val_loss=0.8144 | val_acc=0.7774 | time=7.3s
2025-10-13 10:11:28,577 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.8728 | val_loss=0.8245 | val_acc=0.7683 | time=7.3s
2025-10-13 10:11:35,864 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.8696 | val_loss=0.8094 | val_acc=0.7777 | time=7.3s
2025-10-13 10:11:43,169 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.8707 | val_loss=0.8081 | val_acc=0.7795 | time=7.3s
2025-10-13 10:11:50,493 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.8623 | val_loss=0.8086 | val_acc=0.7777 | time=7.3s
2025-10-13 10:11:57,808 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.8635 | val_loss=0.8040 | val_acc=0.7814 | time=7.3s
2025-10-13 10:12:05,095 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.8611 | val_loss=0.8026 | val_acc=0.7798 | time=7.3s
2025-10-13 10:12:12,371 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.8583 | val_loss=0.8064 | val_acc=0.7768 | time=7.3s
2025-10-13 10:12:19,700 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.8623 | val_loss=0.8119 | val_acc=0.7740 | time=7.3s
2025-10-13 10:12:26,973 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.8556 | val_loss=0.7973 | val_acc=0.7849 | time=7.3s
2025-10-13 10:12:34,269 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.8534 | val_loss=0.7972 | val_acc=0.7822 | time=7.3s
2025-10-13 10:12:41,516 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.8531 | val_loss=0.7952 | val_acc=0.7841 | time=7.2s
2025-10-13 10:12:48,803 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.8519 | val_loss=0.8024 | val_acc=0.7794 | time=7.3s
2025-10-13 10:12:56,121 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.8475 | val_loss=0.7928 | val_acc=0.7854 | time=7.3s
2025-10-13 10:13:03,464 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.8491 | val_loss=0.7922 | val_acc=0.7847 | time=7.3s
2025-10-13 10:13:10,800 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.8490 | val_loss=0.7903 | val_acc=0.7861 | time=7.3s
2025-10-13 10:13:18,130 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.8469 | val_loss=0.7871 | val_acc=0.7865 | time=7.3s
2025-10-13 10:13:25,437 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.8448 | val_loss=0.7942 | val_acc=0.7819 | time=7.3s
2025-10-13 10:13:32,734 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.8422 | val_loss=0.7904 | val_acc=0.7844 | time=7.3s
2025-10-13 10:13:40,076 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.8399 | val_loss=0.7868 | val_acc=0.7875 | time=7.3s
2025-10-13 10:13:47,421 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.8412 | val_loss=0.7865 | val_acc=0.7882 | time=7.3s
2025-10-13 10:13:54,741 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.8381 | val_loss=0.7911 | val_acc=0.7874 | time=7.3s
2025-10-13 10:14:02,060 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.8385 | val_loss=0.7889 | val_acc=0.7873 | time=7.3s
2025-10-13 10:14:09,372 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.8370 | val_loss=0.7838 | val_acc=0.7889 | time=7.3s
2025-10-13 10:14:16,680 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.8358 | val_loss=0.7822 | val_acc=0.7904 | time=7.3s
2025-10-13 10:14:24,009 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.8381 | val_loss=0.7853 | val_acc=0.7859 | time=7.3s
2025-10-13 10:14:31,313 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.8363 | val_loss=0.7883 | val_acc=0.7860 | time=7.3s
2025-10-13 10:14:38,585 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.8370 | val_loss=0.7830 | val_acc=0.7891 | time=7.3s
2025-10-13 10:14:45,941 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.8326 | val_loss=0.7810 | val_acc=0.7907 | time=7.4s
2025-10-13 10:14:53,282 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.8313 | val_loss=0.7801 | val_acc=0.7922 | time=7.3s
2025-10-13 10:15:00,622 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.8330 | val_loss=0.7816 | val_acc=0.7894 | time=7.3s
2025-10-13 10:15:07,890 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.8295 | val_loss=0.7850 | val_acc=0.7893 | time=7.3s
2025-10-13 10:15:15,149 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.8306 | val_loss=0.7844 | val_acc=0.7892 | time=7.3s
2025-10-13 10:15:22,456 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.8298 | val_loss=0.7825 | val_acc=0.7899 | time=7.3s
2025-10-13 10:15:29,810 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.8284 | val_loss=0.7832 | val_acc=0.7920 | time=7.4s
2025-10-13 10:15:37,116 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.8284 | val_loss=0.7780 | val_acc=0.7915 | time=7.3s
2025-10-13 10:15:44,406 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.8283 | val_loss=0.7775 | val_acc=0.7952 | time=7.3s
2025-10-13 10:15:51,720 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.8279 | val_loss=0.7774 | val_acc=0.7936 | time=7.3s
2025-10-13 10:15:59,001 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.8282 | val_loss=0.7795 | val_acc=0.7945 | time=7.3s
2025-10-13 10:16:06,264 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.8254 | val_loss=0.7786 | val_acc=0.7930 | time=7.3s
2025-10-13 10:16:13,618 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.8225 | val_loss=0.7796 | val_acc=0.7916 | time=7.4s
2025-10-13 10:16:20,884 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.8225 | val_loss=0.7769 | val_acc=0.7967 | time=7.3s
2025-10-13 10:16:28,155 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.8221 | val_loss=0.7746 | val_acc=0.7964 | time=7.3s
2025-10-13 10:16:35,451 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.8200 | val_loss=0.7776 | val_acc=0.7904 | time=7.3s
2025-10-13 10:16:42,744 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.8251 | val_loss=0.7737 | val_acc=0.7976 | time=7.3s
2025-10-13 10:16:49,999 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.8219 | val_loss=0.7784 | val_acc=0.7938 | time=7.3s
2025-10-13 10:16:57,331 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.8200 | val_loss=0.7785 | val_acc=0.7917 | time=7.3s
2025-10-13 10:17:04,570 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.8202 | val_loss=0.7725 | val_acc=0.7965 | time=7.2s
2025-10-13 10:17:11,888 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.8202 | val_loss=0.7823 | val_acc=0.7879 | time=7.3s
2025-10-13 10:17:19,232 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.8185 | val_loss=0.7730 | val_acc=0.7972 | time=7.3s
2025-10-13 10:17:26,517 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.8143 | val_loss=0.7786 | val_acc=0.7917 | time=7.3s
2025-10-13 10:17:33,824 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.8180 | val_loss=0.7731 | val_acc=0.7959 | time=7.3s
2025-10-13 10:17:41,139 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.8182 | val_loss=0.7752 | val_acc=0.7959 | time=7.3s
2025-10-13 10:17:48,381 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.8140 | val_loss=0.7729 | val_acc=0.7969 | time=7.2s
2025-10-13 10:17:55,683 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.8172 | val_loss=0.7695 | val_acc=0.7983 | time=7.3s
2025-10-13 10:18:02,984 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.8160 | val_loss=0.7728 | val_acc=0.7967 | time=7.3s
2025-10-13 10:18:10,300 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.8138 | val_loss=0.7725 | val_acc=0.7969 | time=7.3s
2025-10-13 10:18:17,614 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.8139 | val_loss=0.7717 | val_acc=0.7957 | time=7.3s
2025-10-13 10:18:24,906 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.8136 | val_loss=0.7720 | val_acc=0.7979 | time=7.3s
2025-10-13 10:18:32,211 - INFO - _models.training_function_executor - Epoch 089 | train_loss=0.8148 | val_loss=0.7850 | val_acc=0.7863 | time=7.3s
2025-10-13 10:18:39,483 - INFO - _models.training_function_executor - Epoch 090 | train_loss=0.8111 | val_loss=0.7727 | val_acc=0.7968 | time=7.3s
2025-10-13 10:18:46,749 - INFO - _models.training_function_executor - Epoch 091 | train_loss=0.8117 | val_loss=0.7707 | val_acc=0.7989 | time=7.3s
2025-10-13 10:18:54,053 - INFO - _models.training_function_executor - Epoch 092 | train_loss=0.8114 | val_loss=0.7781 | val_acc=0.7911 | time=7.3s
2025-10-13 10:19:01,335 - INFO - _models.training_function_executor - Epoch 093 | train_loss=0.8104 | val_loss=0.7690 | val_acc=0.7965 | time=7.3s
2025-10-13 10:19:08,680 - INFO - _models.training_function_executor - Epoch 094 | train_loss=0.8108 | val_loss=0.7714 | val_acc=0.7963 | time=7.3s
2025-10-13 10:19:15,957 - INFO - _models.training_function_executor - Epoch 095 | train_loss=0.8090 | val_loss=0.7722 | val_acc=0.7963 | time=7.3s
2025-10-13 10:19:23,243 - INFO - _models.training_function_executor - Epoch 096 | train_loss=0.8097 | val_loss=0.7739 | val_acc=0.7938 | time=7.3s
2025-10-13 10:19:23,247 - INFO - _models.training_function_executor - Quantized model size: 75585 bytes.
2025-10-13 10:19:24,359 - INFO - _models.training_function_executor - Model: 14,588 parameters, 62.7KB storage
2025-10-13 10:19:24,359 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.529331572288644, 1.2736881399722129, 1.1508254421145339, 1.0934500436829568, 1.0652357508220747, 1.0468085802515195, 1.0282490351294402, 1.0105476394415653, 0.9910757863567474, 0.9811243608693039, 0.967502877246595, 0.9580923760525614, 0.9509908080017563, 0.9445348051948734, 0.9334941658057405, 0.9315977296630611, 0.9263615884437068, 0.9160834106691325, 0.9120565444637856, 0.9090944050407342, 0.9016837215857527, 0.8974481663129777, 0.8961730841410339, 0.890777018725726, 0.8891097606897438, 0.8861885035960124, 0.8835047186985691, 0.8848479876453158, 0.8763750038407339, 0.8754150018351537, 0.8728391754802475, 0.8695578568145284, 0.8706858956838848, 0.8622786406248986, 0.8634557125657683, 0.8610734643638238, 0.8582536556481231, 0.8622574140276991, 0.8555965547090983, 0.8534469015121794, 0.8531213695242724, 0.8519399511384347, 0.8475366323028447, 0.8490842687090585, 0.8490316395601861, 0.8469470528025789, 0.8448452284213418, 0.8421712954602627, 0.8399437501437188, 0.8411846932911731, 0.8381071568766297, 0.8385384714307175, 0.8369635791368821, 0.8357947754367565, 0.838107129619553, 0.8362799174079621, 0.8370294022443289, 0.8326036197700241, 0.8313499234191679, 0.8330460486292713, 0.8294749302404262, 0.830578274427697, 0.829754494967726, 0.8283897902546623, 0.8284248912672417, 0.8282703260754555, 0.8278970431835033, 0.8281792387142021, 0.8253730874004004, 0.8224898683970567, 0.8224815242161982, 0.8221383962153053, 0.8199948162038634, 0.825149590146262, 0.8218989236437444, 0.8200217347838555, 0.8202136126501727, 0.8202475421300166, 0.8184636015240279, 0.8143239514286134, 0.8179614218457162, 0.818217940479882, 0.8139781019551628, 0.8171657807225317, 0.8160324145811273, 0.8137925668825918, 0.8139466175801027, 0.8136161706499341, 0.8147696632687178, 0.8110905582353207, 0.811718098863589, 0.8113616849310464, 0.8103832821871878, 0.8108316308600025, 0.8089693621150422, 0.8097382596647318], 'val_losses': [1.392837014530437, 1.1594289572955763, 1.0686583895761732, 1.0230252638871242, 0.9971069627847962, 0.982710379172256, 0.9575918303697644, 0.9438006209876515, 0.9234408950697178, 0.9128963354796349, 0.9050323364823942, 0.8932630194205691, 0.885067164000824, 0.8792204433777635, 0.8731263459751061, 0.867370170315204, 0.8624354745067414, 0.8558149733324755, 0.8500117855469247, 0.8473198707595254, 0.8426952508099228, 0.8403097109899764, 0.8359924596550167, 0.831522446309598, 0.8280537698625224, 0.8242612475067075, 0.8236211658275165, 0.8235281958711869, 0.8232131547180138, 0.8144186320403343, 0.8244659636961149, 0.8093599556916904, 0.8080576885026112, 0.8086362722706953, 0.8039684202606794, 0.8025606405622357, 0.8063746273914, 0.8118584855561662, 0.7972533968640743, 0.797242836827868, 0.7952237189713165, 0.8024234725830645, 0.792830817591781, 0.7921806561350196, 0.7902632821136143, 0.7870769133549451, 0.7942038687701655, 0.7903722449745963, 0.7868278231243592, 0.7865234329686284, 0.7910666705262716, 0.7889426753660328, 0.7838207951241287, 0.7822147133386256, 0.7852507822572831, 0.7883341128816962, 0.782989716379635, 0.781018020871389, 0.7800547182455654, 0.7815627685409349, 0.7850192550558037, 0.7843806411696765, 0.7824782918164644, 0.7832221759337832, 0.7779798374377976, 0.7775068621264916, 0.7773626413135041, 0.7794916038125973, 0.7786407853950351, 0.7795621578744295, 0.7768857670614758, 0.7746000384216255, 0.7776247484516254, 0.7737265258224268, 0.7783788576132775, 0.7785446350291596, 0.77248816695462, 0.7823057313419365, 0.7729920696911797, 0.778565584340628, 0.7731200328522476, 0.7752386235798577, 0.7728860775907849, 0.7695129789336395, 0.7727570865260248, 0.7724630211799095, 0.7717166774582521, 0.7720410237581028, 0.7849895841056416, 0.7727193153734845, 0.7706755987405359, 0.7780682865998358, 0.768965258271201, 0.7713781978685955, 0.7722285560348212, 0.773899680486625], 'val_acc': [0.504025201260063, 0.6326566328316415, 0.6412320616030801, 0.6470073503675183, 0.6577703885194259, 0.6856842842142107, 0.6978473923696185, 0.7019600980049002, 0.7202485124256213, 0.7301365068253413, 0.7326741337066853, 0.7366118305915296, 0.7410745537276864, 0.7448372418620931, 0.7430871543577179, 0.7488624431221561, 0.7513125656282814, 0.7567378368918446, 0.758050402520126, 0.7594504725236262, 0.7596254812740637, 0.7629506475323766, 0.7645257262863143, 0.7659257962898145, 0.7687259362968148, 0.7690759537976899, 0.7717010850542527, 0.7734511725586279, 0.7752887644382219, 0.7773888694434722, 0.768288414420721, 0.7776513825691285, 0.7794889744487224, 0.7777388869443472, 0.7814140707035352, 0.7798389919495975, 0.7767763388169409, 0.7739761988099405, 0.7849142457122856, 0.782201610080504, 0.7841267063353168, 0.7794014700735037, 0.7853517675883794, 0.7846517325866293, 0.7861393069653483, 0.7864893244662233, 0.7819390969548478, 0.7843892194609731, 0.7875393769688485, 0.7882394119705985, 0.7873643682184109, 0.7872768638431922, 0.7889394469723486, 0.7904270213510676, 0.785876793839692, 0.7859642982149108, 0.7891144557227862, 0.7906895344767239, 0.7921771088554428, 0.7893769688484424, 0.7892894644732237, 0.7892019600980049, 0.789901995099755, 0.7920021001050053, 0.7914770738536927, 0.7952397619880994, 0.793577178858943, 0.7944522226111306, 0.7929646482324116, 0.7915645782289115, 0.7967273363668184, 0.7963773188659433, 0.7904270213510676, 0.797602380119006, 0.7937521876093805, 0.791739586979349, 0.7964648232411621, 0.7878893944697235, 0.7971648582429122, 0.7916520826041302, 0.7958522926146308, 0.7958522926146308, 0.7969023451172559, 0.7983024151207561, 0.7967273363668184, 0.7969023451172559, 0.7956772838641932, 0.7978648932446623, 0.7863143157157858, 0.7968148407420371, 0.7989149457472874, 0.7911270563528177, 0.7964648232411621, 0.7962898144907246, 0.7962898144907246, 0.7938396919845992], 'model_size_bytes': 75585, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.570265852568054e-05, 'batch_size': 16, 'epochs': 96, 'weight_decay': 0.000810847585223415, 'dropout': 0.3551803749043084, 'hidden_size': 27, 'd_model': 28, 't_pooled': 192, 'label_smoothing': 0.09378526261075382, 'use_focal_loss': False, 'focal_gamma': 1.8905925754696444, 'grad_clip_norm': 0.8976976089082568, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 14588, 'model_storage_size_kb': 62.682812500000004, 'model_size_validation': 'PASS'}
2025-10-13 10:19:24,359 - INFO - _models.training_function_executor - BO Objective: base=0.7938, size_penalty=0.0000, final=0.7938
2025-10-13 10:19:24,359 - INFO - _models.training_function_executor - Model: 14,588 parameters, 62.7KB (PASS 256KB limit)
2025-10-13 10:19:24,359 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 704.932s
2025-10-13 10:19:24,469 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7938
2025-10-13 10:19:24,469 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.108s
2025-10-13 10:19:24,469 - INFO - bo.run_bo - Recorded observation #46: hparams={'lr': 1.570265852568054e-05, 'batch_size': np.int64(16), 'epochs': np.int64(96), 'weight_decay': 0.000810847585223415, 'dropout': 0.3551803749043084, 'hidden_size': np.int64(27), 'd_model': np.int64(28), 't_pooled': np.int64(192), 'label_smoothing': 0.09378526261075382, 'use_focal_loss': np.False_, 'focal_gamma': 1.8905925754696444, 'grad_clip_norm': 0.8976976089082568, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.7938
2025-10-13 10:19:24,469 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 46: {'lr': 1.570265852568054e-05, 'batch_size': np.int64(16), 'epochs': np.int64(96), 'weight_decay': 0.000810847585223415, 'dropout': 0.3551803749043084, 'hidden_size': np.int64(27), 'd_model': np.int64(28), 't_pooled': np.int64(192), 'label_smoothing': 0.09378526261075382, 'use_focal_loss': np.False_, 'focal_gamma': 1.8905925754696444, 'grad_clip_norm': 0.8976976089082568, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.7938
2025-10-13 10:19:24,470 - INFO - bo.run_bo - üîçBO Trial 47: Using RF surrogate + Expected Improvement
2025-10-13 10:19:24,470 - INFO - bo.run_bo - [PROFILE] suggest() took 0.000s
2025-10-13 10:19:24,470 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 47 (NaN monitoring active)
2025-10-13 10:19:24,470 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 10:19:24,470 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 10:19:24,470 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.508632593314141e-05, 'batch_size': 32, 'epochs': 80, 'weight_decay': 0.0004376291365980652, 'dropout': 0.3141380155850762, 'hidden_size': 20, 'd_model': 21, 't_pooled': 192, 'label_smoothing': 0.14220368632735753, 'use_focal_loss': True, 'focal_gamma': 4.2769818680863745, 'grad_clip_norm': 4.609068199268553, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 10:19:24,471 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.508632593314141e-05, 'batch_size': 32, 'epochs': 80, 'weight_decay': 0.0004376291365980652, 'dropout': 0.3141380155850762, 'hidden_size': 20, 'd_model': 21, 't_pooled': 192, 'label_smoothing': 0.14220368632735753, 'use_focal_loss': True, 'focal_gamma': 4.2769818680863745, 'grad_clip_norm': 4.609068199268553, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}
2025-10-13 10:19:32,364 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.5842 | val_loss=0.5342 | val_acc=0.4563 | time=7.9s
2025-10-13 10:19:37,400 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.4878 | val_loss=0.4282 | val_acc=0.5417 | time=5.0s
2025-10-13 10:19:42,439 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.3955 | val_loss=0.3445 | val_acc=0.6040 | time=5.0s
2025-10-13 10:19:47,497 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.3328 | val_loss=0.2961 | val_acc=0.6278 | time=5.1s
2025-10-13 10:19:52,589 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.2930 | val_loss=0.2573 | val_acc=0.6487 | time=5.1s
2025-10-13 10:19:57,679 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.2687 | val_loss=0.2355 | val_acc=0.6676 | time=5.1s
2025-10-13 10:20:02,771 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.2524 | val_loss=0.2214 | val_acc=0.6806 | time=5.1s
2025-10-13 10:20:07,839 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.2432 | val_loss=0.2128 | val_acc=0.6889 | time=5.1s
2025-10-13 10:20:12,916 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.2368 | val_loss=0.2120 | val_acc=0.6826 | time=5.1s
2025-10-13 10:20:17,989 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.2294 | val_loss=0.2064 | val_acc=0.6910 | time=5.1s
2025-10-13 10:20:23,056 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.2266 | val_loss=0.1993 | val_acc=0.7026 | time=5.1s
2025-10-13 10:20:28,132 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.2245 | val_loss=0.1965 | val_acc=0.7030 | time=5.1s
2025-10-13 10:20:33,226 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.2192 | val_loss=0.1997 | val_acc=0.6933 | time=5.1s
2025-10-13 10:20:38,334 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.2157 | val_loss=0.1919 | val_acc=0.7146 | time=5.1s
2025-10-13 10:20:43,399 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.2130 | val_loss=0.1887 | val_acc=0.7163 | time=5.1s
2025-10-13 10:20:48,471 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.2081 | val_loss=0.1866 | val_acc=0.7177 | time=5.1s
2025-10-13 10:20:53,568 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.2079 | val_loss=0.1848 | val_acc=0.7237 | time=5.1s
2025-10-13 10:20:58,638 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.2043 | val_loss=0.1817 | val_acc=0.7275 | time=5.1s
2025-10-13 10:21:03,705 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.2038 | val_loss=0.1803 | val_acc=0.7290 | time=5.1s
2025-10-13 10:21:08,810 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.1981 | val_loss=0.1801 | val_acc=0.7320 | time=5.1s
2025-10-13 10:21:13,899 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.1950 | val_loss=0.1754 | val_acc=0.7344 | time=5.1s
2025-10-13 10:21:18,975 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.1930 | val_loss=0.1740 | val_acc=0.7368 | time=5.1s
2025-10-13 10:21:24,077 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.1907 | val_loss=0.1735 | val_acc=0.7346 | time=5.1s
2025-10-13 10:21:29,158 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.1870 | val_loss=0.1694 | val_acc=0.7429 | time=5.1s
2025-10-13 10:21:34,239 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.1863 | val_loss=0.1692 | val_acc=0.7413 | time=5.1s
2025-10-13 10:21:39,361 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.1835 | val_loss=0.1681 | val_acc=0.7438 | time=5.1s
2025-10-13 10:21:44,428 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.1809 | val_loss=0.1627 | val_acc=0.7493 | time=5.1s
2025-10-13 10:21:49,502 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.1795 | val_loss=0.1610 | val_acc=0.7495 | time=5.1s
2025-10-13 10:21:54,570 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.1764 | val_loss=0.1594 | val_acc=0.7517 | time=5.1s
2025-10-13 10:21:59,641 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.1745 | val_loss=0.1573 | val_acc=0.7519 | time=5.1s
2025-10-13 10:22:04,713 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.1724 | val_loss=0.1565 | val_acc=0.7553 | time=5.1s
2025-10-13 10:22:09,779 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.1715 | val_loss=0.1535 | val_acc=0.7569 | time=5.1s
2025-10-13 10:22:14,844 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.1684 | val_loss=0.1519 | val_acc=0.7592 | time=5.1s
2025-10-13 10:22:19,949 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.1679 | val_loss=0.1505 | val_acc=0.7599 | time=5.1s
2025-10-13 10:22:25,019 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.1667 | val_loss=0.1498 | val_acc=0.7629 | time=5.1s
2025-10-13 10:22:30,098 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.1634 | val_loss=0.1482 | val_acc=0.7626 | time=5.1s
2025-10-13 10:22:35,196 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.1633 | val_loss=0.1473 | val_acc=0.7612 | time=5.1s
2025-10-13 10:22:40,272 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.1633 | val_loss=0.1463 | val_acc=0.7655 | time=5.1s
2025-10-13 10:22:45,355 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.1625 | val_loss=0.1455 | val_acc=0.7678 | time=5.1s
2025-10-13 10:22:50,427 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.1603 | val_loss=0.1444 | val_acc=0.7679 | time=5.1s
2025-10-13 10:22:55,498 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.1580 | val_loss=0.1434 | val_acc=0.7683 | time=5.1s
2025-10-13 10:23:00,592 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.1590 | val_loss=0.1432 | val_acc=0.7684 | time=5.1s
2025-10-13 10:23:05,651 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.1563 | val_loss=0.1430 | val_acc=0.7671 | time=5.1s
2025-10-13 10:23:10,734 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.1567 | val_loss=0.1402 | val_acc=0.7717 | time=5.1s
2025-10-13 10:23:15,800 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.1559 | val_loss=0.1403 | val_acc=0.7706 | time=5.1s
2025-10-13 10:23:20,912 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.1548 | val_loss=0.1398 | val_acc=0.7713 | time=5.1s
2025-10-13 10:23:25,968 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.1539 | val_loss=0.1382 | val_acc=0.7721 | time=5.1s
2025-10-13 10:23:31,058 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.1543 | val_loss=0.1386 | val_acc=0.7706 | time=5.1s
2025-10-13 10:23:36,161 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.1522 | val_loss=0.1379 | val_acc=0.7728 | time=5.1s
2025-10-13 10:23:41,231 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.1518 | val_loss=0.1373 | val_acc=0.7710 | time=5.1s
2025-10-13 10:23:46,302 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.1527 | val_loss=0.1374 | val_acc=0.7705 | time=5.1s
2025-10-13 10:23:51,388 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.1514 | val_loss=0.1364 | val_acc=0.7736 | time=5.1s
2025-10-13 10:23:56,491 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.1510 | val_loss=0.1356 | val_acc=0.7722 | time=5.1s
2025-10-13 10:24:01,636 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.1486 | val_loss=0.1355 | val_acc=0.7711 | time=5.1s
2025-10-13 10:24:06,726 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.1498 | val_loss=0.1345 | val_acc=0.7770 | time=5.1s
2025-10-13 10:24:11,808 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.1485 | val_loss=0.1339 | val_acc=0.7762 | time=5.1s
2025-10-13 10:24:16,888 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.1476 | val_loss=0.1340 | val_acc=0.7736 | time=5.1s
2025-10-13 10:24:21,972 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.1483 | val_loss=0.1333 | val_acc=0.7754 | time=5.1s
2025-10-13 10:24:27,072 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.1483 | val_loss=0.1333 | val_acc=0.7743 | time=5.1s
2025-10-13 10:24:32,143 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.1488 | val_loss=0.1319 | val_acc=0.7760 | time=5.1s
2025-10-13 10:24:37,227 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.1472 | val_loss=0.1333 | val_acc=0.7746 | time=5.1s
2025-10-13 10:24:42,310 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.1450 | val_loss=0.1332 | val_acc=0.7750 | time=5.1s
2025-10-13 10:24:47,378 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.1461 | val_loss=0.1314 | val_acc=0.7779 | time=5.1s
2025-10-13 10:24:52,464 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.1464 | val_loss=0.1317 | val_acc=0.7760 | time=5.1s
2025-10-13 10:24:57,543 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.1464 | val_loss=0.1312 | val_acc=0.7775 | time=5.1s
2025-10-13 10:25:02,668 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.1446 | val_loss=0.1303 | val_acc=0.7782 | time=5.1s
2025-10-13 10:25:07,763 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.1439 | val_loss=0.1291 | val_acc=0.7779 | time=5.1s
2025-10-13 10:25:12,836 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.1450 | val_loss=0.1300 | val_acc=0.7742 | time=5.1s
2025-10-13 10:25:17,930 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.1434 | val_loss=0.1299 | val_acc=0.7782 | time=5.1s
2025-10-13 10:25:23,029 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.1446 | val_loss=0.1301 | val_acc=0.7754 | time=5.1s
2025-10-13 10:25:28,121 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.1436 | val_loss=0.1287 | val_acc=0.7783 | time=5.1s
2025-10-13 10:25:33,183 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.1430 | val_loss=0.1285 | val_acc=0.7765 | time=5.1s
2025-10-13 10:25:38,262 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.1424 | val_loss=0.1299 | val_acc=0.7770 | time=5.1s
2025-10-13 10:25:43,349 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.1417 | val_loss=0.1273 | val_acc=0.7802 | time=5.1s
2025-10-13 10:25:48,478 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.1428 | val_loss=0.1270 | val_acc=0.7809 | time=5.1s
2025-10-13 10:25:53,552 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.1414 | val_loss=0.1269 | val_acc=0.7821 | time=5.1s
2025-10-13 10:25:58,639 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.1404 | val_loss=0.1264 | val_acc=0.7819 | time=5.1s
2025-10-13 10:26:03,716 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.1391 | val_loss=0.1265 | val_acc=0.7808 | time=5.1s
2025-10-13 10:26:08,769 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.1403 | val_loss=0.1286 | val_acc=0.7777 | time=5.1s
2025-10-13 10:26:13,831 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.1401 | val_loss=0.1325 | val_acc=0.7735 | time=5.1s
2025-10-13 10:26:13,836 - INFO - _models.training_function_executor - Quantized model size: 57473 bytes.
2025-10-13 10:26:14,935 - INFO - _models.training_function_executor - Model: 10,071 parameters, 43.3KB storage
2025-10-13 10:26:14,935 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.5842486661466052, 0.4878390454770303, 0.39550766339450605, 0.3327716670547034, 0.29297868789055986, 0.2686901221877843, 0.25235546593863023, 0.2431953027922664, 0.23683856289454344, 0.22944065492429389, 0.22660972732929321, 0.2245080644459753, 0.21919204782346433, 0.21574715310808742, 0.2130401246888595, 0.20807430250351772, 0.2078977201706386, 0.20427904281951684, 0.20376389715944423, 0.19807166062454515, 0.1949748559367586, 0.1930435467139799, 0.19071024054668564, 0.18700175715423273, 0.18630363525399637, 0.18350372574819232, 0.18087616932373343, 0.17951658476596535, 0.17638062310460817, 0.1744706745868719, 0.17239506007033625, 0.17145990767302027, 0.16840884770375264, 0.16794637552050806, 0.16668685159255126, 0.16344100570695402, 0.16327093243285998, 0.16327460987462752, 0.16254482400826237, 0.16032706384667994, 0.1580493594130249, 0.15896690167984764, 0.15633932972313183, 0.1567244314812554, 0.15589662615208513, 0.15477318726388734, 0.15388136952958995, 0.15430156962726346, 0.15223257350554448, 0.1518343323134316, 0.15267510764564216, 0.1513568125599992, 0.15101464439834128, 0.1485715650144598, 0.14983440153261646, 0.1484607934044256, 0.14764341882028736, 0.1482755375265199, 0.14826752714445052, 0.14875088953652663, 0.14716652052924897, 0.144957108843627, 0.1460806971606901, 0.1464230495553606, 0.1464120918610399, 0.144567135722749, 0.14390146718769586, 0.14499527142155952, 0.14343722300238237, 0.14463685808125015, 0.14360142519027985, 0.14301495449105717, 0.14235686699086902, 0.1417032291315363, 0.14280433277640261, 0.1413948857517229, 0.1404325767600499, 0.1390936288084231, 0.14028773087542667, 0.1400912228214144], 'val_losses': [0.5342429655183225, 0.4281523793382915, 0.3445072112318766, 0.29606700001957953, 0.25732710112589074, 0.23547677699402159, 0.22136800475666313, 0.21281561454693504, 0.21195391510014439, 0.20635985880620755, 0.19932090320243342, 0.19646989742191595, 0.19971284732394673, 0.19188348385141912, 0.18871328886630948, 0.18657997414328895, 0.1848103794281325, 0.18168704791694076, 0.18034996318157878, 0.18007746163597882, 0.17536700576658554, 0.17401396777085754, 0.17346955675176695, 0.16940753481627596, 0.16922336878332592, 0.16805883129555987, 0.16273602192890907, 0.16097981502824535, 0.15936062559824454, 0.1573199408639341, 0.1564949519324645, 0.1534722273870077, 0.15189612289387988, 0.15050467132666664, 0.1498331215400816, 0.14822298813041457, 0.14734342940462022, 0.14630560712001522, 0.14546968041285793, 0.1443816178801346, 0.14342563912027317, 0.14324673375530095, 0.14303786081995712, 0.1401862038008016, 0.14026102785113645, 0.1398028317639408, 0.138228022180156, 0.1386027140637399, 0.13788370983163334, 0.13731910330580796, 0.13744734906737188, 0.13640527539333347, 0.13561434228603014, 0.13549547336570525, 0.13451419066080983, 0.13388981005926, 0.13397639170471587, 0.13325564116291705, 0.13325911911584548, 0.13192711149870118, 0.133303126114876, 0.13322873319159198, 0.1314307237197187, 0.13169828545475573, 0.13117311317519287, 0.1303401849342469, 0.12910136860548552, 0.1300394342085011, 0.12986658343776022, 0.13009466911513862, 0.12870623830589834, 0.12851986946459204, 0.1298987567789871, 0.12732508734238912, 0.1270084988155021, 0.12690473832177, 0.12637708678262652, 0.1264699399106186, 0.12858953954646085, 0.13250162144995753], 'val_acc': [0.4563353167658383, 0.5416520826041302, 0.6040427021351068, 0.6278438921946097, 0.6486699334966748, 0.6675708785439272, 0.6806090304515225, 0.6889219460973048, 0.682621631081554, 0.6910220511025551, 0.7025726286314316, 0.7030101505075254, 0.6932971648582429, 0.7145607280364018, 0.716310815540777, 0.7177108855442772, 0.723661183059153, 0.7275113755687784, 0.7289989499474974, 0.7319740987049352, 0.7344242212110605, 0.7367868393419671, 0.7345992299614981, 0.7429121456072804, 0.7413370668533427, 0.743787189359468, 0.7492999649982499, 0.7494749737486874, 0.7516625831291565, 0.7519250962548127, 0.7552502625131257, 0.7569128456422821, 0.7591879593979699, 0.75988799439972, 0.7628631431571579, 0.7626006300315016, 0.7612005600280014, 0.7654882744137207, 0.7677633881694085, 0.767938396919846, 0.768288414420721, 0.7683759187959398, 0.7670633531676584, 0.7717010850542527, 0.7705635281764088, 0.7712635631781589, 0.7721386069303465, 0.7705635281764088, 0.7728386419320966, 0.7710010500525026, 0.7704760238011901, 0.7736261813090655, 0.7722261113055653, 0.7710885544277214, 0.7769513475673784, 0.7761638081904095, 0.7736261813090655, 0.7753762688134407, 0.7743262163108156, 0.775988799439972, 0.7745887294364718, 0.7750262513125656, 0.7779138956947848, 0.775988799439972, 0.777476373818691, 0.778176408820441, 0.7779138956947848, 0.774151207560378, 0.778176408820441, 0.7753762688134407, 0.7782639131956598, 0.7765138256912846, 0.7769513475673784, 0.7801890094504725, 0.7808890444522226, 0.7821141057052853, 0.7819390969548478, 0.7808015400770039, 0.7776513825691285, 0.7735386769338467], 'model_size_bytes': 57473, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.508632593314141e-05, 'batch_size': 32, 'epochs': 80, 'weight_decay': 0.0004376291365980652, 'dropout': 0.3141380155850762, 'hidden_size': 20, 'd_model': 21, 't_pooled': 192, 'label_smoothing': 0.14220368632735753, 'use_focal_loss': True, 'focal_gamma': 4.2769818680863745, 'grad_clip_norm': 4.609068199268553, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': True}, 'model_parameter_count': 10071, 'model_storage_size_kb': 43.273828125, 'model_size_validation': 'PASS'}
2025-10-13 10:26:14,936 - INFO - _models.training_function_executor - BO Objective: base=0.7735, size_penalty=0.0000, final=0.7735
2025-10-13 10:26:14,936 - INFO - _models.training_function_executor - Model: 10,071 parameters, 43.3KB (PASS 256KB limit)
2025-10-13 10:26:14,936 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 410.466s
2025-10-13 10:26:15,050 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7735
2025-10-13 10:26:15,050 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.112s
2025-10-13 10:26:15,050 - INFO - bo.run_bo - Recorded observation #47: hparams={'lr': 1.508632593314141e-05, 'batch_size': np.int64(32), 'epochs': np.int64(80), 'weight_decay': 0.0004376291365980652, 'dropout': 0.3141380155850762, 'hidden_size': np.int64(20), 'd_model': np.int64(21), 't_pooled': np.int64(192), 'label_smoothing': 0.14220368632735753, 'use_focal_loss': np.True_, 'focal_gamma': 4.2769818680863745, 'grad_clip_norm': 4.609068199268553, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_}, value=0.7735
2025-10-13 10:26:15,050 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 47: {'lr': 1.508632593314141e-05, 'batch_size': np.int64(32), 'epochs': np.int64(80), 'weight_decay': 0.0004376291365980652, 'dropout': 0.3141380155850762, 'hidden_size': np.int64(20), 'd_model': np.int64(21), 't_pooled': np.int64(192), 'label_smoothing': 0.14220368632735753, 'use_focal_loss': np.True_, 'focal_gamma': 4.2769818680863745, 'grad_clip_norm': 4.609068199268553, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.True_} -> 0.7735
2025-10-13 10:26:15,050 - INFO - bo.run_bo - üîçBO Trial 48: Using RF surrogate + Expected Improvement
2025-10-13 10:26:15,050 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 10:26:15,051 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 48 (NaN monitoring active)
2025-10-13 10:26:15,051 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 10:26:15,051 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 10:26:15,051 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 1.1726538144033314e-05, 'batch_size': 8, 'epochs': 81, 'weight_decay': 0.005622984874232739, 'dropout': 0.167447851667317, 'hidden_size': 27, 'd_model': 28, 't_pooled': 256, 'label_smoothing': 0.1826206198442919, 'use_focal_loss': True, 'focal_gamma': 1.868408802427348, 'grad_clip_norm': 3.590212034870517, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 10:26:15,052 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 1.1726538144033314e-05, 'batch_size': 8, 'epochs': 81, 'weight_decay': 0.005622984874232739, 'dropout': 0.167447851667317, 'hidden_size': 27, 'd_model': 28, 't_pooled': 256, 'label_smoothing': 0.1826206198442919, 'use_focal_loss': True, 'focal_gamma': 1.868408802427348, 'grad_clip_norm': 3.590212034870517, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}
2025-10-13 10:26:33,093 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9758 | val_loss=0.8223 | val_acc=0.5583 | time=18.0s
2025-10-13 10:26:48,363 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.7532 | val_loss=0.6604 | val_acc=0.6035 | time=15.3s
2025-10-13 10:27:03,603 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.6811 | val_loss=0.6016 | val_acc=0.6246 | time=15.2s
2025-10-13 10:27:18,654 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.6475 | val_loss=0.5610 | val_acc=0.6334 | time=15.1s
2025-10-13 10:27:33,894 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.6224 | val_loss=0.5283 | val_acc=0.6498 | time=15.2s
2025-10-13 10:27:49,012 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.6057 | val_loss=0.5139 | val_acc=0.6593 | time=15.1s
2025-10-13 10:28:04,250 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.5848 | val_loss=0.5072 | val_acc=0.6590 | time=15.2s
2025-10-13 10:28:19,514 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.5757 | val_loss=0.4927 | val_acc=0.6677 | time=15.3s
2025-10-13 10:28:34,698 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.5600 | val_loss=0.4914 | val_acc=0.6856 | time=15.2s
2025-10-13 10:28:49,818 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.5510 | val_loss=0.4701 | val_acc=0.6988 | time=15.1s
2025-10-13 10:29:05,055 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.5444 | val_loss=0.4603 | val_acc=0.7007 | time=15.2s
2025-10-13 10:29:20,261 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.5366 | val_loss=0.4669 | val_acc=0.6892 | time=15.2s
2025-10-13 10:29:35,375 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.5284 | val_loss=0.4543 | val_acc=0.6997 | time=15.1s
2025-10-13 10:29:50,452 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.5171 | val_loss=0.4542 | val_acc=0.7028 | time=15.1s
2025-10-13 10:30:05,679 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.5136 | val_loss=0.4401 | val_acc=0.7136 | time=15.2s
2025-10-13 10:30:20,821 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.5057 | val_loss=0.4279 | val_acc=0.7251 | time=15.1s
2025-10-13 10:30:35,900 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.4979 | val_loss=0.4240 | val_acc=0.7298 | time=15.1s
2025-10-13 10:30:51,101 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.4895 | val_loss=0.4233 | val_acc=0.7285 | time=15.2s
2025-10-13 10:31:06,321 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.4843 | val_loss=0.4201 | val_acc=0.7321 | time=15.2s
2025-10-13 10:31:21,316 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.4780 | val_loss=0.4073 | val_acc=0.7360 | time=15.0s
2025-10-13 10:31:36,566 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.4725 | val_loss=0.4012 | val_acc=0.7413 | time=15.2s
2025-10-13 10:31:51,760 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.4641 | val_loss=0.3962 | val_acc=0.7448 | time=15.2s
2025-10-13 10:32:07,026 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.4615 | val_loss=0.3996 | val_acc=0.7405 | time=15.3s
2025-10-13 10:32:22,253 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.4559 | val_loss=0.3899 | val_acc=0.7483 | time=15.2s
2025-10-13 10:32:37,474 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.4502 | val_loss=0.3888 | val_acc=0.7528 | time=15.2s
2025-10-13 10:32:52,727 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.4449 | val_loss=0.3850 | val_acc=0.7519 | time=15.3s
2025-10-13 10:33:07,845 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.4421 | val_loss=0.3788 | val_acc=0.7560 | time=15.1s
2025-10-13 10:33:22,980 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.4364 | val_loss=0.3779 | val_acc=0.7574 | time=15.1s
2025-10-13 10:33:38,139 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.4366 | val_loss=0.3750 | val_acc=0.7579 | time=15.2s
2025-10-13 10:33:53,285 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.4315 | val_loss=0.3708 | val_acc=0.7596 | time=15.1s
2025-10-13 10:34:08,475 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.4311 | val_loss=0.3763 | val_acc=0.7550 | time=15.2s
2025-10-13 10:34:23,544 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.4276 | val_loss=0.3691 | val_acc=0.7594 | time=15.1s
2025-10-13 10:34:38,758 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.4248 | val_loss=0.3679 | val_acc=0.7584 | time=15.2s
2025-10-13 10:34:53,822 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.4190 | val_loss=0.3612 | val_acc=0.7644 | time=15.1s
2025-10-13 10:35:08,839 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.4207 | val_loss=0.3635 | val_acc=0.7640 | time=15.0s
2025-10-13 10:35:24,010 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.4164 | val_loss=0.3643 | val_acc=0.7630 | time=15.2s
2025-10-13 10:35:39,188 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.4156 | val_loss=0.3665 | val_acc=0.7606 | time=15.2s
2025-10-13 10:35:54,254 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.4144 | val_loss=0.3665 | val_acc=0.7606 | time=15.1s
2025-10-13 10:36:09,312 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.4118 | val_loss=0.3579 | val_acc=0.7674 | time=15.1s
2025-10-13 10:36:24,470 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.4086 | val_loss=0.3628 | val_acc=0.7639 | time=15.2s
2025-10-13 10:36:39,664 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.4054 | val_loss=0.3557 | val_acc=0.7667 | time=15.2s
2025-10-13 10:36:54,823 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.4079 | val_loss=0.3603 | val_acc=0.7655 | time=15.2s
2025-10-13 10:37:10,037 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.4053 | val_loss=0.3723 | val_acc=0.7559 | time=15.2s
2025-10-13 10:37:25,218 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.4030 | val_loss=0.3496 | val_acc=0.7682 | time=15.2s
2025-10-13 10:37:40,400 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.4007 | val_loss=0.3471 | val_acc=0.7712 | time=15.2s
2025-10-13 10:37:55,577 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.3989 | val_loss=0.3510 | val_acc=0.7683 | time=15.2s
2025-10-13 10:38:10,800 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.3962 | val_loss=0.3486 | val_acc=0.7703 | time=15.2s
2025-10-13 10:38:25,902 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.3957 | val_loss=0.3548 | val_acc=0.7675 | time=15.1s
2025-10-13 10:38:41,035 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.3930 | val_loss=0.3481 | val_acc=0.7709 | time=15.1s
2025-10-13 10:38:56,026 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.3947 | val_loss=0.3514 | val_acc=0.7686 | time=15.0s
2025-10-13 10:39:11,220 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.3934 | val_loss=0.3454 | val_acc=0.7721 | time=15.2s
2025-10-13 10:39:26,389 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.3896 | val_loss=0.3413 | val_acc=0.7719 | time=15.2s
2025-10-13 10:39:41,552 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.3909 | val_loss=0.3414 | val_acc=0.7735 | time=15.2s
2025-10-13 10:39:56,750 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.3861 | val_loss=0.3413 | val_acc=0.7732 | time=15.2s
2025-10-13 10:40:11,885 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.3873 | val_loss=0.3475 | val_acc=0.7707 | time=15.1s
2025-10-13 10:40:27,084 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.3834 | val_loss=0.3409 | val_acc=0.7754 | time=15.2s
2025-10-13 10:40:42,277 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.3822 | val_loss=0.3387 | val_acc=0.7756 | time=15.2s
2025-10-13 10:40:57,466 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.3824 | val_loss=0.3382 | val_acc=0.7755 | time=15.2s
2025-10-13 10:41:12,441 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.3825 | val_loss=0.3395 | val_acc=0.7758 | time=15.0s
2025-10-13 10:41:27,591 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.3802 | val_loss=0.3430 | val_acc=0.7735 | time=15.1s
2025-10-13 10:41:42,802 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.3798 | val_loss=0.3414 | val_acc=0.7746 | time=15.2s
2025-10-13 10:41:57,971 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.3801 | val_loss=0.3395 | val_acc=0.7761 | time=15.2s
2025-10-13 10:42:13,097 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.3775 | val_loss=0.3452 | val_acc=0.7681 | time=15.1s
2025-10-13 10:42:28,396 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.3759 | val_loss=0.3379 | val_acc=0.7780 | time=15.3s
2025-10-13 10:42:43,499 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.3764 | val_loss=0.3371 | val_acc=0.7746 | time=15.1s
2025-10-13 10:42:58,665 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.3749 | val_loss=0.3363 | val_acc=0.7776 | time=15.2s
2025-10-13 10:43:13,779 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.3748 | val_loss=0.3427 | val_acc=0.7714 | time=15.1s
2025-10-13 10:43:28,988 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.3749 | val_loss=0.3340 | val_acc=0.7770 | time=15.2s
2025-10-13 10:43:44,139 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.3722 | val_loss=0.3462 | val_acc=0.7725 | time=15.2s
2025-10-13 10:43:59,398 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.3698 | val_loss=0.3337 | val_acc=0.7798 | time=15.3s
2025-10-13 10:44:14,354 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.3684 | val_loss=0.3367 | val_acc=0.7775 | time=15.0s
2025-10-13 10:44:29,518 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.3695 | val_loss=0.3331 | val_acc=0.7791 | time=15.2s
2025-10-13 10:44:44,554 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.3679 | val_loss=0.3355 | val_acc=0.7772 | time=15.0s
2025-10-13 10:44:59,768 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.3671 | val_loss=0.3313 | val_acc=0.7785 | time=15.2s
2025-10-13 10:45:14,901 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.3673 | val_loss=0.3292 | val_acc=0.7789 | time=15.1s
2025-10-13 10:45:29,853 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.3644 | val_loss=0.3334 | val_acc=0.7778 | time=15.0s
2025-10-13 10:45:45,029 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.3651 | val_loss=0.3326 | val_acc=0.7798 | time=15.2s
2025-10-13 10:46:00,247 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.3660 | val_loss=0.3344 | val_acc=0.7792 | time=15.2s
2025-10-13 10:46:15,435 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.3624 | val_loss=0.3340 | val_acc=0.7777 | time=15.2s
2025-10-13 10:46:30,701 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.3625 | val_loss=0.3314 | val_acc=0.7798 | time=15.3s
2025-10-13 10:46:45,854 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.3604 | val_loss=0.3311 | val_acc=0.7812 | time=15.2s
2025-10-13 10:46:45,858 - INFO - _models.training_function_executor - Quantized model size: 75585 bytes.
2025-10-13 10:46:46,968 - INFO - _models.training_function_executor - Model: 14,588 parameters, 62.7KB storage
2025-10-13 10:46:46,968 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9758130821849568, 0.7532297572108637, 0.6811281018451999, 0.6474724543633935, 0.6223620918556907, 0.6056966105092019, 0.5848177920819623, 0.5756643855116941, 0.5599599612324564, 0.551006585350446, 0.5444348107177163, 0.5366109428202976, 0.5284095521511671, 0.5171427215284241, 0.5135509070161551, 0.5056672680785304, 0.4978882592271832, 0.4895429768536656, 0.4842744547303924, 0.4779960481318918, 0.47253880424031874, 0.4641355571601413, 0.4615086290351642, 0.4558527199378694, 0.45023960788630923, 0.44491441859376357, 0.4420593690477888, 0.43637937867976817, 0.436621006687736, 0.4315020385132121, 0.43109096994178253, 0.42762176666733454, 0.42482736163195983, 0.4189712592401588, 0.4206521071032039, 0.4164458646291999, 0.41562266616456506, 0.41436643208258733, 0.4118374368351241, 0.40857971994885, 0.40540764107778643, 0.40786986876804593, 0.4052967040228769, 0.4029520461384675, 0.4007238064634088, 0.3988708090832497, 0.3961682609638729, 0.39568630907336416, 0.3929759493331716, 0.3946570817480241, 0.39337430387574984, 0.38955263667901285, 0.3909222002545066, 0.386061376989498, 0.3872611865379753, 0.383404867396953, 0.3821532310775195, 0.3823889876524489, 0.38252490557636315, 0.3802098422286798, 0.37981537595263487, 0.38014904111278225, 0.37749456600173603, 0.37587288838358435, 0.3763965373020391, 0.37486874740857645, 0.37484453459090034, 0.3749486583626986, 0.37221394743872066, 0.3698209770164646, 0.3683792636037071, 0.3695309798281782, 0.36793398005985006, 0.36706157275408735, 0.3672538283015355, 0.36438090858689587, 0.365107176122593, 0.36603823737891655, 0.3623878728473832, 0.3624732265370159, 0.36040281706988697], 'val_losses': [0.8222632063908054, 0.6604186051848221, 0.6016308316764691, 0.5610408134755864, 0.528302186783853, 0.5138500415500662, 0.5072380041623391, 0.4926912511014671, 0.4914294843453396, 0.47006544644990333, 0.4603317934794154, 0.46686134685325087, 0.45427567315166295, 0.45417058100942803, 0.44006812412358265, 0.4278705776113291, 0.4240074624125883, 0.4233420203757069, 0.42006572884907456, 0.40728721800261874, 0.4011644578826023, 0.39616554702469464, 0.39958307665463383, 0.3899445374518122, 0.38883919755989826, 0.38501338529803764, 0.37884397254484203, 0.3778618535233579, 0.37503618340173883, 0.370785757810618, 0.37625209418134253, 0.3691300446357308, 0.3678700419043093, 0.361192914685003, 0.3634896335440747, 0.3642942513572949, 0.36648526651107394, 0.366542604233904, 0.3578909611290971, 0.3627622486735959, 0.3557125110835056, 0.36031938193637797, 0.3723411962708102, 0.349583523094362, 0.3470631990038018, 0.3509586754786017, 0.3486279458104834, 0.3547714423253939, 0.34806257167535726, 0.35136303626911014, 0.34538832356541105, 0.3412514591747996, 0.3413546945942754, 0.34131201384944393, 0.34747008095525717, 0.34089437501728637, 0.33865845946371453, 0.338153724487914, 0.3395277357128562, 0.34297415471610004, 0.34144069348019573, 0.3395445431652063, 0.3451581434338586, 0.3379035114350125, 0.3371285896697452, 0.33633763405553396, 0.3426956521698571, 0.33396688286484977, 0.34624342681917647, 0.33370438434436556, 0.3367450292703673, 0.33312949258149566, 0.3354575688675917, 0.33134079874239897, 0.3292097397980508, 0.33343157222534253, 0.33256058834328867, 0.3343838535778623, 0.3339858644824158, 0.33142816746724124, 0.33111230440445616], 'val_acc': [0.5582779138956948, 0.6035176758837942, 0.6246062303115156, 0.6333566678333916, 0.6498074903745187, 0.6593454672733636, 0.6589954497724886, 0.6677458872943647, 0.6855967798389919, 0.6988099404970248, 0.7007350367518376, 0.6891844592229611, 0.6996849842492124, 0.7028351417570878, 0.7135981799089954, 0.7250612530626531, 0.7297864893244662, 0.7284739236961848, 0.7321491074553728, 0.7359992999649982, 0.7413370668533427, 0.7448372418620931, 0.7405495274763738, 0.7483374168708435, 0.7528001400070004, 0.7519250962548127, 0.7560378018900945, 0.7573503675183759, 0.7578753937696885, 0.7596254812740637, 0.7549877493874694, 0.7593629681484074, 0.758400420021001, 0.7643507175358768, 0.7640007000350018, 0.7629506475323766, 0.7605880294014701, 0.7605880294014701, 0.7674133706685334, 0.763913195659783, 0.7667133356667833, 0.7654882744137207, 0.755862793139657, 0.7682009100455023, 0.7711760588029402, 0.768288414420721, 0.7703010150507525, 0.7675008750437522, 0.7709135456772839, 0.7685509275463773, 0.7720511025551278, 0.7718760938046902, 0.7734511725586279, 0.7731886594329717, 0.7707385369268464, 0.7753762688134407, 0.775638781939097, 0.7754637731886594, 0.7758137906895345, 0.7734511725586279, 0.7745887294364718, 0.7760763038151908, 0.7681134056702835, 0.7780014000700035, 0.7745887294364718, 0.7775638781939097, 0.7713510675533777, 0.7769513475673784, 0.7724886244312216, 0.7797514875743787, 0.777476373818691, 0.7790514525726286, 0.7772138606930347, 0.7785264263213161, 0.7788764438221911, 0.777826391319566, 0.7798389919495975, 0.7792264613230662, 0.7776513825691285, 0.7797514875743787, 0.7811515575778789], 'model_size_bytes': 75585, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 1.1726538144033314e-05, 'batch_size': 8, 'epochs': 81, 'weight_decay': 0.005622984874232739, 'dropout': 0.167447851667317, 'hidden_size': 27, 'd_model': 28, 't_pooled': 256, 'label_smoothing': 0.1826206198442919, 'use_focal_loss': True, 'focal_gamma': 1.868408802427348, 'grad_clip_norm': 3.590212034870517, 'num_workers': 4, 'quantization_bits': 32, 'quantize_weights': False, 'quantize_activations': False}, 'model_parameter_count': 14588, 'model_storage_size_kb': 62.682812500000004, 'model_size_validation': 'PASS'}
2025-10-13 10:46:46,968 - INFO - _models.training_function_executor - BO Objective: base=0.7812, size_penalty=0.0000, final=0.7812
2025-10-13 10:46:46,968 - INFO - _models.training_function_executor - Model: 14,588 parameters, 62.7KB (PASS 256KB limit)
2025-10-13 10:46:46,968 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 1231.918s
2025-10-13 10:46:47,081 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7812
2025-10-13 10:46:47,081 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 10:46:47,081 - INFO - bo.run_bo - Recorded observation #48: hparams={'lr': 1.1726538144033314e-05, 'batch_size': np.int64(8), 'epochs': np.int64(81), 'weight_decay': 0.005622984874232739, 'dropout': 0.167447851667317, 'hidden_size': np.int64(27), 'd_model': np.int64(28), 't_pooled': np.int64(256), 'label_smoothing': 0.1826206198442919, 'use_focal_loss': np.True_, 'focal_gamma': 1.868408802427348, 'grad_clip_norm': 3.590212034870517, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_}, value=0.7812
2025-10-13 10:46:47,081 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 48: {'lr': 1.1726538144033314e-05, 'batch_size': np.int64(8), 'epochs': np.int64(81), 'weight_decay': 0.005622984874232739, 'dropout': 0.167447851667317, 'hidden_size': np.int64(27), 'd_model': np.int64(28), 't_pooled': np.int64(256), 'label_smoothing': 0.1826206198442919, 'use_focal_loss': np.True_, 'focal_gamma': 1.868408802427348, 'grad_clip_norm': 3.590212034870517, 'num_workers': np.int64(4), 'quantization_bits': np.int64(32), 'quantize_weights': np.False_, 'quantize_activations': np.False_} -> 0.7812
2025-10-13 10:46:47,082 - INFO - bo.run_bo - üîçBO Trial 49: Using RF surrogate + Expected Improvement
2025-10-13 10:46:47,082 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 10:46:47,082 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 49 (NaN monitoring active)
2025-10-13 10:46:47,082 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 10:46:47,082 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 10:46:47,082 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.00013872166367044452, 'batch_size': 32, 'epochs': 16, 'weight_decay': 0.0011129840736793686, 'dropout': 0.46094287566038167, 'hidden_size': 22, 'd_model': 31, 't_pooled': 320, 'label_smoothing': 0.08699763376415143, 'use_focal_loss': False, 'focal_gamma': 0.3518387708658794, 'grad_clip_norm': 3.5139262873818615, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 10:46:47,083 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.00013872166367044452, 'batch_size': 32, 'epochs': 16, 'weight_decay': 0.0011129840736793686, 'dropout': 0.46094287566038167, 'hidden_size': 22, 'd_model': 31, 't_pooled': 320, 'label_smoothing': 0.08699763376415143, 'use_focal_loss': False, 'focal_gamma': 0.3518387708658794, 'grad_clip_norm': 3.5139262873818615, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}
2025-10-13 10:46:55,417 - INFO - _models.training_function_executor - Epoch 001 | train_loss=1.2254 | val_loss=0.9912 | val_acc=0.6608 | time=8.3s
2025-10-13 10:47:00,934 - INFO - _models.training_function_executor - Epoch 002 | train_loss=1.0031 | val_loss=0.9314 | val_acc=0.6977 | time=5.5s
2025-10-13 10:47:06,451 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.9525 | val_loss=0.8834 | val_acc=0.7331 | time=5.5s
2025-10-13 10:47:11,970 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.9073 | val_loss=0.8438 | val_acc=0.7532 | time=5.5s
2025-10-13 10:47:17,487 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.8778 | val_loss=0.8163 | val_acc=0.7700 | time=5.5s
2025-10-13 10:47:23,000 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.8595 | val_loss=0.8027 | val_acc=0.7724 | time=5.5s
2025-10-13 10:47:28,492 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.8410 | val_loss=0.7866 | val_acc=0.7870 | time=5.5s
2025-10-13 10:47:33,999 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.8308 | val_loss=0.7760 | val_acc=0.7877 | time=5.5s
2025-10-13 10:47:39,520 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.8225 | val_loss=0.7691 | val_acc=0.7886 | time=5.5s
2025-10-13 10:47:45,051 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.8154 | val_loss=0.7687 | val_acc=0.7910 | time=5.5s
2025-10-13 10:47:50,591 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.8093 | val_loss=0.7657 | val_acc=0.7888 | time=5.5s
2025-10-13 10:47:56,128 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.8047 | val_loss=0.7592 | val_acc=0.7932 | time=5.5s
2025-10-13 10:48:01,660 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.8020 | val_loss=0.7583 | val_acc=0.7923 | time=5.5s
2025-10-13 10:48:07,203 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.7987 | val_loss=0.7660 | val_acc=0.7893 | time=5.5s
2025-10-13 10:48:12,740 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.7942 | val_loss=0.7514 | val_acc=0.7988 | time=5.5s
2025-10-13 10:48:18,275 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7911 | val_loss=0.7548 | val_acc=0.7952 | time=5.5s
2025-10-13 10:48:18,283 - INFO - _models.training_function_executor - Quantized model size: 47867 bytes.
2025-10-13 10:48:19,390 - INFO - _models.training_function_executor - Model: 5,202 parameters, 5.6KB storage
2025-10-13 10:48:19,390 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [1.2253739105724646, 1.0031477331405843, 0.952484593468193, 0.9073029547919332, 0.87782255896831, 0.8595417529125501, 0.8410159308550698, 0.8307761820538461, 0.8225169623903682, 0.8153627223596316, 0.8093380509325788, 0.804685892886034, 0.8019677162337312, 0.7987254920187721, 0.7941689597045704, 0.791089087672529], 'val_losses': [0.9912058080790717, 0.9313908981242128, 0.883362928845476, 0.8438052117177812, 0.8162971600645024, 0.8026696211773489, 0.7865503841361091, 0.775991066335839, 0.7691019826057202, 0.7686565889943343, 0.7657433797063884, 0.7591919108500296, 0.7583259348273486, 0.765968607112082, 0.7513535381782126, 0.7547728568889229], 'val_acc': [0.6608330416520826, 0.6976723836191809, 0.7331116555827791, 0.7531501575078754, 0.7700385019250963, 0.7724011200560028, 0.7870143507175359, 0.787714385719286, 0.7885894294714736, 0.7909520476023801, 0.7887644382219111, 0.7932271613580679, 0.7922646132306616, 0.7892894644732237, 0.7988274413720686, 0.7952397619880994], 'model_size_bytes': 47867, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.00013872166367044452, 'batch_size': 32, 'epochs': 16, 'weight_decay': 0.0011129840736793686, 'dropout': 0.46094287566038167, 'hidden_size': 22, 'd_model': 31, 't_pooled': 320, 'label_smoothing': 0.08699763376415143, 'use_focal_loss': False, 'focal_gamma': 0.3518387708658794, 'grad_clip_norm': 3.5139262873818615, 'num_workers': 4, 'quantization_bits': 8, 'quantize_weights': True, 'quantize_activations': False}, 'model_parameter_count': 5202, 'model_storage_size_kb': 5.588085937500001, 'model_size_validation': 'PASS'}
2025-10-13 10:48:19,390 - INFO - _models.training_function_executor - BO Objective: base=0.7952, size_penalty=0.0000, final=0.7952
2025-10-13 10:48:19,390 - INFO - _models.training_function_executor - Model: 5,202 parameters, 5.6KB (PASS 256KB limit)
2025-10-13 10:48:19,390 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 92.308s
2025-10-13 10:48:19,505 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.7952
2025-10-13 10:48:19,505 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 10:48:19,505 - INFO - bo.run_bo - Recorded observation #49: hparams={'lr': 0.00013872166367044452, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 0.0011129840736793686, 'dropout': 0.46094287566038167, 'hidden_size': np.int64(22), 'd_model': np.int64(31), 't_pooled': np.int64(320), 'label_smoothing': 0.08699763376415143, 'use_focal_loss': np.False_, 'focal_gamma': 0.3518387708658794, 'grad_clip_norm': 3.5139262873818615, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_}, value=0.7952
2025-10-13 10:48:19,505 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 49: {'lr': 0.00013872166367044452, 'batch_size': np.int64(32), 'epochs': np.int64(16), 'weight_decay': 0.0011129840736793686, 'dropout': 0.46094287566038167, 'hidden_size': np.int64(22), 'd_model': np.int64(31), 't_pooled': np.int64(320), 'label_smoothing': 0.08699763376415143, 'use_focal_loss': np.False_, 'focal_gamma': 0.3518387708658794, 'grad_clip_norm': 3.5139262873818615, 'num_workers': np.int64(4), 'quantization_bits': np.int64(8), 'quantize_weights': np.True_, 'quantize_activations': np.False_} -> 0.7952
2025-10-13 10:48:19,506 - INFO - bo.run_bo - üîçBO Trial 50: Using RF surrogate + Expected Improvement
2025-10-13 10:48:19,506 - INFO - bo.run_bo - [PROFILE] suggest() took 0.001s
2025-10-13 10:48:19,506 - INFO - evaluation.code_generation_pipeline_orchestrator - üèÉ Starting trial 50 (NaN monitoring active)
2025-10-13 10:48:19,506 - INFO - _models.training_function_executor - Using device: cuda
2025-10-13 10:48:19,506 - INFO - _models.training_function_executor - Executing training function: MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 10:48:19,506 - INFO - _models.training_function_executor - Hyperparameters: {'lr': 0.0015472727707073997, 'batch_size': 32, 'epochs': 91, 'weight_decay': 0.005430563353611926, 'dropout': 0.4076876362728341, 'hidden_size': 31, 'd_model': 24, 't_pooled': 320, 'label_smoothing': 0.08761086961719008, 'use_focal_loss': False, 'focal_gamma': 3.7783168186593743, 'grad_clip_norm': 0.07670495168824344, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 10:48:19,507 - INFO - _models.training_function_executor - Starting training with hyperparameters: {'lr': 0.0015472727707073997, 'batch_size': 32, 'epochs': 91, 'weight_decay': 0.005430563353611926, 'dropout': 0.4076876362728341, 'hidden_size': 31, 'd_model': 24, 't_pooled': 320, 'label_smoothing': 0.08761086961719008, 'use_focal_loss': False, 'focal_gamma': 3.7783168186593743, 'grad_clip_norm': 0.07670495168824344, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}
2025-10-13 10:48:27,992 - INFO - _models.training_function_executor - Epoch 001 | train_loss=0.9840 | val_loss=0.8285 | val_acc=0.7595 | time=8.5s
2025-10-13 10:48:33,669 - INFO - _models.training_function_executor - Epoch 002 | train_loss=0.8360 | val_loss=0.7795 | val_acc=0.7873 | time=5.7s
2025-10-13 10:48:39,374 - INFO - _models.training_function_executor - Epoch 003 | train_loss=0.7999 | val_loss=0.7682 | val_acc=0.7938 | time=5.7s
2025-10-13 10:48:45,064 - INFO - _models.training_function_executor - Epoch 004 | train_loss=0.7829 | val_loss=0.7787 | val_acc=0.7820 | time=5.7s
2025-10-13 10:48:50,729 - INFO - _models.training_function_executor - Epoch 005 | train_loss=0.7765 | val_loss=0.8068 | val_acc=0.7661 | time=5.7s
2025-10-13 10:48:56,413 - INFO - _models.training_function_executor - Epoch 006 | train_loss=0.7658 | val_loss=0.7497 | val_acc=0.7973 | time=5.7s
2025-10-13 10:49:02,117 - INFO - _models.training_function_executor - Epoch 007 | train_loss=0.7635 | val_loss=0.7291 | val_acc=0.8032 | time=5.7s
2025-10-13 10:49:07,813 - INFO - _models.training_function_executor - Epoch 008 | train_loss=0.7559 | val_loss=0.7229 | val_acc=0.8097 | time=5.7s
2025-10-13 10:49:13,483 - INFO - _models.training_function_executor - Epoch 009 | train_loss=0.7518 | val_loss=0.7235 | val_acc=0.8097 | time=5.7s
2025-10-13 10:49:19,160 - INFO - _models.training_function_executor - Epoch 010 | train_loss=0.7473 | val_loss=0.7517 | val_acc=0.7926 | time=5.7s
2025-10-13 10:49:24,857 - INFO - _models.training_function_executor - Epoch 011 | train_loss=0.7413 | val_loss=0.7150 | val_acc=0.8166 | time=5.7s
2025-10-13 10:49:30,536 - INFO - _models.training_function_executor - Epoch 012 | train_loss=0.7409 | val_loss=0.7259 | val_acc=0.8067 | time=5.7s
2025-10-13 10:49:36,213 - INFO - _models.training_function_executor - Epoch 013 | train_loss=0.7362 | val_loss=0.7678 | val_acc=0.7869 | time=5.7s
2025-10-13 10:49:41,895 - INFO - _models.training_function_executor - Epoch 014 | train_loss=0.7356 | val_loss=0.7126 | val_acc=0.8165 | time=5.7s
2025-10-13 10:49:47,581 - INFO - _models.training_function_executor - Epoch 015 | train_loss=0.7304 | val_loss=0.7133 | val_acc=0.8123 | time=5.7s
2025-10-13 10:49:53,281 - INFO - _models.training_function_executor - Epoch 016 | train_loss=0.7310 | val_loss=0.7281 | val_acc=0.8090 | time=5.7s
2025-10-13 10:49:58,960 - INFO - _models.training_function_executor - Epoch 017 | train_loss=0.7287 | val_loss=0.7220 | val_acc=0.8120 | time=5.7s
2025-10-13 10:50:04,637 - INFO - _models.training_function_executor - Epoch 018 | train_loss=0.7236 | val_loss=0.7006 | val_acc=0.8191 | time=5.7s
2025-10-13 10:50:10,330 - INFO - _models.training_function_executor - Epoch 019 | train_loss=0.7214 | val_loss=0.7271 | val_acc=0.8063 | time=5.7s
2025-10-13 10:50:16,003 - INFO - _models.training_function_executor - Epoch 020 | train_loss=0.7218 | val_loss=0.7232 | val_acc=0.8088 | time=5.7s
2025-10-13 10:50:21,678 - INFO - _models.training_function_executor - Epoch 021 | train_loss=0.7196 | val_loss=0.7257 | val_acc=0.8069 | time=5.7s
2025-10-13 10:50:27,361 - INFO - _models.training_function_executor - Epoch 022 | train_loss=0.7157 | val_loss=0.7043 | val_acc=0.8192 | time=5.7s
2025-10-13 10:50:33,060 - INFO - _models.training_function_executor - Epoch 023 | train_loss=0.7157 | val_loss=0.7243 | val_acc=0.8080 | time=5.7s
2025-10-13 10:50:38,747 - INFO - _models.training_function_executor - Epoch 024 | train_loss=0.7153 | val_loss=0.7242 | val_acc=0.8116 | time=5.7s
2025-10-13 10:50:44,426 - INFO - _models.training_function_executor - Epoch 025 | train_loss=0.7134 | val_loss=0.7133 | val_acc=0.8135 | time=5.7s
2025-10-13 10:50:50,101 - INFO - _models.training_function_executor - Epoch 026 | train_loss=0.7108 | val_loss=0.6987 | val_acc=0.8181 | time=5.7s
2025-10-13 10:50:55,802 - INFO - _models.training_function_executor - Epoch 027 | train_loss=0.7103 | val_loss=0.7185 | val_acc=0.8113 | time=5.7s
2025-10-13 10:51:01,481 - INFO - _models.training_function_executor - Epoch 028 | train_loss=0.7100 | val_loss=0.7145 | val_acc=0.8145 | time=5.7s
2025-10-13 10:51:07,163 - INFO - _models.training_function_executor - Epoch 029 | train_loss=0.7068 | val_loss=0.7001 | val_acc=0.8192 | time=5.7s
2025-10-13 10:51:12,843 - INFO - _models.training_function_executor - Epoch 030 | train_loss=0.7072 | val_loss=0.7037 | val_acc=0.8186 | time=5.7s
2025-10-13 10:51:18,537 - INFO - _models.training_function_executor - Epoch 031 | train_loss=0.7059 | val_loss=0.6965 | val_acc=0.8216 | time=5.7s
2025-10-13 10:51:24,243 - INFO - _models.training_function_executor - Epoch 032 | train_loss=0.7054 | val_loss=0.6971 | val_acc=0.8225 | time=5.7s
2025-10-13 10:51:29,914 - INFO - _models.training_function_executor - Epoch 033 | train_loss=0.7050 | val_loss=0.7088 | val_acc=0.8156 | time=5.7s
2025-10-13 10:51:35,600 - INFO - _models.training_function_executor - Epoch 034 | train_loss=0.7043 | val_loss=0.7218 | val_acc=0.8096 | time=5.7s
2025-10-13 10:51:41,305 - INFO - _models.training_function_executor - Epoch 035 | train_loss=0.7024 | val_loss=0.7172 | val_acc=0.8114 | time=5.7s
2025-10-13 10:51:46,991 - INFO - _models.training_function_executor - Epoch 036 | train_loss=0.7021 | val_loss=0.7238 | val_acc=0.8139 | time=5.7s
2025-10-13 10:51:52,681 - INFO - _models.training_function_executor - Epoch 037 | train_loss=0.7027 | val_loss=0.7111 | val_acc=0.8114 | time=5.7s
2025-10-13 10:51:58,355 - INFO - _models.training_function_executor - Epoch 038 | train_loss=0.6983 | val_loss=0.7213 | val_acc=0.8121 | time=5.7s
2025-10-13 10:52:04,050 - INFO - _models.training_function_executor - Epoch 039 | train_loss=0.6978 | val_loss=0.7161 | val_acc=0.8120 | time=5.7s
2025-10-13 10:52:09,748 - INFO - _models.training_function_executor - Epoch 040 | train_loss=0.6972 | val_loss=0.7152 | val_acc=0.8118 | time=5.7s
2025-10-13 10:52:15,417 - INFO - _models.training_function_executor - Epoch 041 | train_loss=0.6961 | val_loss=0.6983 | val_acc=0.8185 | time=5.7s
2025-10-13 10:52:21,099 - INFO - _models.training_function_executor - Epoch 042 | train_loss=0.6963 | val_loss=0.7032 | val_acc=0.8194 | time=5.7s
2025-10-13 10:52:26,806 - INFO - _models.training_function_executor - Epoch 043 | train_loss=0.6952 | val_loss=0.7031 | val_acc=0.8199 | time=5.7s
2025-10-13 10:52:32,485 - INFO - _models.training_function_executor - Epoch 044 | train_loss=0.6948 | val_loss=0.7001 | val_acc=0.8213 | time=5.7s
2025-10-13 10:52:38,170 - INFO - _models.training_function_executor - Epoch 045 | train_loss=0.6918 | val_loss=0.7069 | val_acc=0.8167 | time=5.7s
2025-10-13 10:52:43,860 - INFO - _models.training_function_executor - Epoch 046 | train_loss=0.6930 | val_loss=0.7223 | val_acc=0.8128 | time=5.7s
2025-10-13 10:52:49,550 - INFO - _models.training_function_executor - Epoch 047 | train_loss=0.6891 | val_loss=0.7185 | val_acc=0.8113 | time=5.7s
2025-10-13 10:52:55,233 - INFO - _models.training_function_executor - Epoch 048 | train_loss=0.6886 | val_loss=0.7187 | val_acc=0.8128 | time=5.7s
2025-10-13 10:53:00,909 - INFO - _models.training_function_executor - Epoch 049 | train_loss=0.6896 | val_loss=0.7361 | val_acc=0.8036 | time=5.7s
2025-10-13 10:53:06,576 - INFO - _models.training_function_executor - Epoch 050 | train_loss=0.6918 | val_loss=0.7255 | val_acc=0.8070 | time=5.7s
2025-10-13 10:53:12,290 - INFO - _models.training_function_executor - Epoch 051 | train_loss=0.6864 | val_loss=0.7056 | val_acc=0.8163 | time=5.7s
2025-10-13 10:53:17,967 - INFO - _models.training_function_executor - Epoch 052 | train_loss=0.6864 | val_loss=0.7293 | val_acc=0.8053 | time=5.7s
2025-10-13 10:53:23,652 - INFO - _models.training_function_executor - Epoch 053 | train_loss=0.6868 | val_loss=0.7055 | val_acc=0.8193 | time=5.7s
2025-10-13 10:53:29,329 - INFO - _models.training_function_executor - Epoch 054 | train_loss=0.6839 | val_loss=0.6975 | val_acc=0.8215 | time=5.7s
2025-10-13 10:53:35,029 - INFO - _models.training_function_executor - Epoch 055 | train_loss=0.6843 | val_loss=0.7117 | val_acc=0.8138 | time=5.7s
2025-10-13 10:53:40,713 - INFO - _models.training_function_executor - Epoch 056 | train_loss=0.6833 | val_loss=0.7033 | val_acc=0.8187 | time=5.7s
2025-10-13 10:53:46,383 - INFO - _models.training_function_executor - Epoch 057 | train_loss=0.6850 | val_loss=0.7026 | val_acc=0.8215 | time=5.7s
2025-10-13 10:53:52,052 - INFO - _models.training_function_executor - Epoch 058 | train_loss=0.6834 | val_loss=0.7148 | val_acc=0.8162 | time=5.7s
2025-10-13 10:53:57,754 - INFO - _models.training_function_executor - Epoch 059 | train_loss=0.6785 | val_loss=0.7127 | val_acc=0.8113 | time=5.7s
2025-10-13 10:54:03,429 - INFO - _models.training_function_executor - Epoch 060 | train_loss=0.6824 | val_loss=0.7084 | val_acc=0.8156 | time=5.7s
2025-10-13 10:54:09,105 - INFO - _models.training_function_executor - Epoch 061 | train_loss=0.6837 | val_loss=0.7070 | val_acc=0.8173 | time=5.7s
2025-10-13 10:54:14,784 - INFO - _models.training_function_executor - Epoch 062 | train_loss=0.6820 | val_loss=0.7154 | val_acc=0.8145 | time=5.7s
2025-10-13 10:54:20,478 - INFO - _models.training_function_executor - Epoch 063 | train_loss=0.6801 | val_loss=0.7116 | val_acc=0.8159 | time=5.7s
2025-10-13 10:54:26,175 - INFO - _models.training_function_executor - Epoch 064 | train_loss=0.6813 | val_loss=0.7429 | val_acc=0.8018 | time=5.7s
2025-10-13 10:54:31,852 - INFO - _models.training_function_executor - Epoch 065 | train_loss=0.6787 | val_loss=0.7134 | val_acc=0.8193 | time=5.7s
2025-10-13 10:54:37,549 - INFO - _models.training_function_executor - Epoch 066 | train_loss=0.6796 | val_loss=0.7478 | val_acc=0.7988 | time=5.7s
2025-10-13 10:54:43,251 - INFO - _models.training_function_executor - Epoch 067 | train_loss=0.6761 | val_loss=0.7069 | val_acc=0.8166 | time=5.7s
2025-10-13 10:54:48,925 - INFO - _models.training_function_executor - Epoch 068 | train_loss=0.6766 | val_loss=0.7090 | val_acc=0.8190 | time=5.7s
2025-10-13 10:54:54,606 - INFO - _models.training_function_executor - Epoch 069 | train_loss=0.6768 | val_loss=0.7188 | val_acc=0.8082 | time=5.7s
2025-10-13 10:55:00,286 - INFO - _models.training_function_executor - Epoch 070 | train_loss=0.6788 | val_loss=0.7076 | val_acc=0.8181 | time=5.7s
2025-10-13 10:55:05,976 - INFO - _models.training_function_executor - Epoch 071 | train_loss=0.6760 | val_loss=0.6999 | val_acc=0.8169 | time=5.7s
2025-10-13 10:55:11,667 - INFO - _models.training_function_executor - Epoch 072 | train_loss=0.6755 | val_loss=0.7437 | val_acc=0.8009 | time=5.7s
2025-10-13 10:55:17,341 - INFO - _models.training_function_executor - Epoch 073 | train_loss=0.6774 | val_loss=0.7024 | val_acc=0.8170 | time=5.7s
2025-10-13 10:55:23,024 - INFO - _models.training_function_executor - Epoch 074 | train_loss=0.6776 | val_loss=0.7362 | val_acc=0.8099 | time=5.7s
2025-10-13 10:55:28,731 - INFO - _models.training_function_executor - Epoch 075 | train_loss=0.6753 | val_loss=0.7191 | val_acc=0.8130 | time=5.7s
2025-10-13 10:55:34,411 - INFO - _models.training_function_executor - Epoch 076 | train_loss=0.6736 | val_loss=0.7260 | val_acc=0.8115 | time=5.7s
2025-10-13 10:55:40,082 - INFO - _models.training_function_executor - Epoch 077 | train_loss=0.6728 | val_loss=0.6981 | val_acc=0.8214 | time=5.7s
2025-10-13 10:55:45,763 - INFO - _models.training_function_executor - Epoch 078 | train_loss=0.6724 | val_loss=0.7432 | val_acc=0.8039 | time=5.7s
2025-10-13 10:55:51,466 - INFO - _models.training_function_executor - Epoch 079 | train_loss=0.6724 | val_loss=0.7339 | val_acc=0.8057 | time=5.7s
2025-10-13 10:55:57,170 - INFO - _models.training_function_executor - Epoch 080 | train_loss=0.6718 | val_loss=0.7199 | val_acc=0.8143 | time=5.7s
2025-10-13 10:56:02,851 - INFO - _models.training_function_executor - Epoch 081 | train_loss=0.6713 | val_loss=0.7171 | val_acc=0.8137 | time=5.7s
2025-10-13 10:56:08,547 - INFO - _models.training_function_executor - Epoch 082 | train_loss=0.6698 | val_loss=0.7090 | val_acc=0.8140 | time=5.7s
2025-10-13 10:56:14,247 - INFO - _models.training_function_executor - Epoch 083 | train_loss=0.6715 | val_loss=0.7254 | val_acc=0.8130 | time=5.7s
2025-10-13 10:56:19,919 - INFO - _models.training_function_executor - Epoch 084 | train_loss=0.6711 | val_loss=0.7207 | val_acc=0.8134 | time=5.7s
2025-10-13 10:56:25,607 - INFO - _models.training_function_executor - Epoch 085 | train_loss=0.6719 | val_loss=0.7271 | val_acc=0.8072 | time=5.7s
2025-10-13 10:56:31,289 - INFO - _models.training_function_executor - Epoch 086 | train_loss=0.6713 | val_loss=0.7279 | val_acc=0.8110 | time=5.7s
2025-10-13 10:56:36,983 - INFO - _models.training_function_executor - Epoch 087 | train_loss=0.6685 | val_loss=0.7064 | val_acc=0.8140 | time=5.7s
2025-10-13 10:56:42,677 - INFO - _models.training_function_executor - Epoch 088 | train_loss=0.6682 | val_loss=0.7028 | val_acc=0.8184 | time=5.7s
2025-10-13 10:56:48,346 - INFO - _models.training_function_executor - Epoch 089 | train_loss=0.6676 | val_loss=0.7054 | val_acc=0.8181 | time=5.7s
2025-10-13 10:56:54,019 - INFO - _models.training_function_executor - Epoch 090 | train_loss=0.6671 | val_loss=0.7065 | val_acc=0.8155 | time=5.7s
2025-10-13 10:56:59,719 - INFO - _models.training_function_executor - Epoch 091 | train_loss=0.6678 | val_loss=0.7417 | val_acc=0.8029 | time=5.7s
2025-10-13 10:56:59,726 - INFO - _models.training_function_executor - Quantized model size: 48513 bytes.
2025-10-13 10:57:00,836 - INFO - _models.training_function_executor - Model: 15,783 parameters, 33.9KB storage
2025-10-13 10:57:00,836 - INFO - _models.training_function_executor - Training completed successfully: {'train_losses': [0.9839880587047407, 0.8359854633798957, 0.7999299640708926, 0.7828525088239809, 0.7764806878871336, 0.7657926896881048, 0.7634640437220626, 0.7559039405187528, 0.7518075842894079, 0.7473262510059344, 0.7412644796618474, 0.7409027863683757, 0.7361867433041595, 0.7355748055946756, 0.7304468218746993, 0.7309997845121643, 0.7287284750015451, 0.7235646633197262, 0.72140825871283, 0.721753325544123, 0.7195519007791954, 0.7156891056320489, 0.7157249180303406, 0.715334487119921, 0.7133696703256575, 0.7107764010584601, 0.7103250673028361, 0.7099536725137048, 0.7068274455300819, 0.7072173222237047, 0.7059408564604284, 0.7053652429939526, 0.7050258903850573, 0.7043142403010768, 0.7024246896944724, 0.7021291195031935, 0.7026784653675319, 0.6982750584497542, 0.6977751394398028, 0.6972221789720553, 0.6960792988173645, 0.6962718495673386, 0.6951537310430376, 0.6947537864844282, 0.6917947673655741, 0.6929686822004989, 0.6890989317316504, 0.6885545447776482, 0.6896192663234141, 0.6918170160666437, 0.6864482853894138, 0.686449577602257, 0.6868261788998778, 0.6838764910060374, 0.6843149824120759, 0.6833121502236715, 0.6849611122624041, 0.6834439246396647, 0.6785073466012225, 0.6824357494174662, 0.683697368679741, 0.6819840301197226, 0.680111041405337, 0.6812692297101647, 0.6787368444491818, 0.6796450496846493, 0.6761014534953929, 0.6766173570857917, 0.6768309439567991, 0.6788148576453051, 0.6759848874642542, 0.6755058868264334, 0.6774398505708576, 0.677635646967943, 0.6752853329714921, 0.6736433979177291, 0.6728311842832275, 0.6724172587948827, 0.6723971592616401, 0.6718016829488993, 0.6712917818195302, 0.66982768422288, 0.6714566838169665, 0.6711095167825303, 0.6718893698516074, 0.6712524465301215, 0.6684845855155106, 0.6682198314262847, 0.6675997020942079, 0.6670667402261113, 0.6677856927761716], 'val_losses': [0.8285208762130163, 0.779528308361195, 0.7682088585241216, 0.7786892888259754, 0.8067800780464228, 0.7497081455752113, 0.729122040694854, 0.722924646669474, 0.7235474997064139, 0.7516594875263592, 0.7149726508337174, 0.7258654291036457, 0.7678396471488881, 0.7125867711400334, 0.7132614424147721, 0.7280502543401001, 0.722008882471845, 0.7005795833736522, 0.7271300212336371, 0.7231754867772685, 0.7256716188534933, 0.7043173488595914, 0.7243356538853697, 0.7241603487598591, 0.713260813947737, 0.698680013929333, 0.718530655700008, 0.7144587564435003, 0.7001414271472508, 0.7037431173362972, 0.6964731122757282, 0.6970992031780039, 0.7087731264586377, 0.7217913805749978, 0.7172431650176764, 0.7237609616308976, 0.7110836919805241, 0.7213211407142375, 0.7160549387257542, 0.7152395657008455, 0.6983381064571531, 0.7032338164884977, 0.7030521890355191, 0.7001376896627224, 0.7069215181410459, 0.7222926351504181, 0.7184563042464939, 0.7186604165137962, 0.7361030652467129, 0.7254874236441009, 0.7056140769683776, 0.7293093727942651, 0.7055393196629359, 0.6975003776743899, 0.7116631400681143, 0.7033349299163805, 0.7026214046122772, 0.7148171505458212, 0.7127395571216988, 0.7083560920779756, 0.7069529637011106, 0.7153845861903596, 0.7115900504618289, 0.7429183609509827, 0.713382731628952, 0.7477943766229754, 0.7068505108794592, 0.7090448960062087, 0.7187763281038769, 0.7076261737023695, 0.6999124163382947, 0.7437395633289269, 0.7023517817185816, 0.7361625067975749, 0.7191212177485238, 0.726045177456045, 0.698140896697707, 0.7431914128537858, 0.7339379066013981, 0.7198790854659997, 0.7170789950495631, 0.7089549673784434, 0.7253954152377452, 0.7207415873118952, 0.727074325168137, 0.7278858314121275, 0.7064306089249699, 0.7028173046655325, 0.7054215411769371, 0.7064848064249698, 0.7417246861227501], 'val_acc': [0.759537976898845, 0.7872768638431922, 0.7937521876093805, 0.7820266013300665, 0.766100805040252, 0.7972523626181309, 0.8032026601330067, 0.809677983899195, 0.809677983899195, 0.7926146307315366, 0.8165908295414771, 0.8067028351417571, 0.7869268463423171, 0.8165033251662583, 0.8123031151557578, 0.8089779488974449, 0.8120406020301015, 0.8191284564228212, 0.8062653132656633, 0.8088029401470074, 0.8068778438921946, 0.8192159607980399, 0.8080154007700385, 0.8116030801540077, 0.8135281764088205, 0.818078403920196, 0.8113405670283514, 0.8144907245362268, 0.8192159607980399, 0.8186034301715086, 0.8215785789289465, 0.8224536226811341, 0.8156282814140707, 0.8095904795239762, 0.8114280714035702, 0.8138781939096955, 0.8114280714035702, 0.8121281064053203, 0.8120406020301015, 0.8117780889044452, 0.8185159257962898, 0.8193909695484775, 0.81991599579979, 0.8213160658032902, 0.8166783339166959, 0.8128281414070704, 0.8113405670283514, 0.8128281414070704, 0.8035526776338817, 0.8069653482674134, 0.8163283164158208, 0.8053027651382569, 0.8193034651732587, 0.8214910745537277, 0.8137906895344768, 0.8186909345467274, 0.8214910745537277, 0.8161533076653833, 0.8113405670283514, 0.8156282814140707, 0.8172908645432272, 0.8144907245362268, 0.815890794539727, 0.8018025901295065, 0.8193034651732587, 0.7988274413720686, 0.8165908295414771, 0.8189534476723836, 0.808190409520476, 0.818078403920196, 0.8169408470423521, 0.8009275463773189, 0.8170283514175709, 0.8098529926496325, 0.8130031501575079, 0.811515575778789, 0.821403570178509, 0.8039026951347568, 0.805652782639132, 0.8143157157857893, 0.813703185159258, 0.8139656982849143, 0.8130031501575079, 0.813353167658383, 0.8072278613930697, 0.8109905495274764, 0.8139656982849143, 0.8184284214210711, 0.818078403920196, 0.815540777038852, 0.8029401470073504], 'model_size_bytes': 48513, 'model_name': 'MR-CNN + BiGRU (BiMamba-lite) for ISRUC', 'training_function_source': 'ai_generated', 'hyperparameters_used': {'lr': 0.0015472727707073997, 'batch_size': 32, 'epochs': 91, 'weight_decay': 0.005430563353611926, 'dropout': 0.4076876362728341, 'hidden_size': 31, 'd_model': 24, 't_pooled': 320, 'label_smoothing': 0.08761086961719008, 'use_focal_loss': False, 'focal_gamma': 3.7783168186593743, 'grad_clip_norm': 0.07670495168824344, 'num_workers': 4, 'quantization_bits': 16, 'quantize_weights': True, 'quantize_activations': True}, 'model_parameter_count': 15783, 'model_storage_size_kb': 33.908789062500006, 'model_size_validation': 'PASS'}
2025-10-13 10:57:00,836 - INFO - _models.training_function_executor - BO Objective: base=0.8029, size_penalty=0.0000, final=0.8029
2025-10-13 10:57:00,836 - INFO - _models.training_function_executor - Model: 15,783 parameters, 33.9KB (PASS 256KB limit)
2025-10-13 10:57:00,836 - INFO - _models.training_function_executor - [PROFILE] objective(train+eval) took 521.331s
2025-10-13 10:57:00,951 - INFO - bo.run_bo - Updated RF surrogate model with observation: 0.8029
2025-10-13 10:57:00,951 - INFO - bo.run_bo - [PROFILE] observe()->tell took 0.111s
2025-10-13 10:57:00,951 - INFO - bo.run_bo - Recorded observation #50: hparams={'lr': 0.0015472727707073997, 'batch_size': np.int64(32), 'epochs': np.int64(91), 'weight_decay': 0.005430563353611926, 'dropout': 0.4076876362728341, 'hidden_size': np.int64(31), 'd_model': np.int64(24), 't_pooled': np.int64(320), 'label_smoothing': 0.08761086961719008, 'use_focal_loss': np.False_, 'focal_gamma': 3.7783168186593743, 'grad_clip_norm': 0.07670495168824344, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_}, value=0.8029
2025-10-13 10:57:00,951 - INFO - evaluation.code_generation_pipeline_orchestrator - BO Trial 50: {'lr': 0.0015472727707073997, 'batch_size': np.int64(32), 'epochs': np.int64(91), 'weight_decay': 0.005430563353611926, 'dropout': 0.4076876362728341, 'hidden_size': np.int64(31), 'd_model': np.int64(24), 't_pooled': np.int64(320), 'label_smoothing': 0.08761086961719008, 'use_focal_loss': np.False_, 'focal_gamma': 3.7783168186593743, 'grad_clip_norm': 0.07670495168824344, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_} -> 0.8029
2025-10-13 10:57:00,951 - INFO - evaluation.code_generation_pipeline_orchestrator - BO completed - Best score: 0.8144
2025-10-13 10:57:00,951 - INFO - evaluation.code_generation_pipeline_orchestrator - Best params: {'lr': 0.00019784285076893693, 'batch_size': np.int64(8), 'epochs': np.int64(95), 'weight_decay': 2.2790780354299242e-06, 'dropout': 0.40984481537098816, 'hidden_size': np.int64(17), 'd_model': np.int64(16), 't_pooled': np.int64(192), 'label_smoothing': 0.007391155221791325, 'use_focal_loss': np.False_, 'focal_gamma': 4.205113941343911, 'grad_clip_norm': 1.3326993475638984, 'num_workers': np.int64(4), 'quantization_bits': np.int64(16), 'quantize_weights': np.True_, 'quantize_activations': np.True_}
2025-10-13 10:57:00,951 - INFO - visualization - Generating BO visualization charts with 50 trials...
2025-10-13 10:57:02,271 - INFO - visualization - BO summary saved to: charts/20251013_105700_BO_MR-CNN + BiGRU (BiMamba-lite) for ISRUC/bo_summary.txt
2025-10-13 10:57:02,285 - INFO - visualization - Raw data saved to: charts/20251013_105700_BO_MR-CNN + BiGRU (BiMamba-lite) for ISRUC/bo_raw_data.json
2025-10-13 10:57:02,285 - INFO - visualization - Numpy arrays saved to: charts/20251013_105700_BO_MR-CNN + BiGRU (BiMamba-lite) for ISRUC/bo_raw_data.npz
2025-10-13 10:57:02,285 - INFO - visualization - BO charts saved to: charts/20251013_105700_BO_MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 10:57:02,285 - INFO - evaluation.code_generation_pipeline_orchestrator - üìä BO charts saved to: charts/20251013_105700_BO_MR-CNN + BiGRU (BiMamba-lite) for ISRUC
2025-10-13 10:57:02,367 - INFO - evaluation.code_generation_pipeline_orchestrator - üöÄ STEP 4: Final Training Execution
2025-10-13 10:57:02,368 - INFO - evaluation.code_generation_pipeline_orchestrator - Using centralized splits - Train: (57140, 6, 6000), Val: (14286, 6, 6000), Test: (17857, 6, 6000)
