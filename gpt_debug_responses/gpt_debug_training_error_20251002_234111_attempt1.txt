=== GPT DEBUG RESPONSE ===
Timestamp: 20251002_234111
Attempt: 1/4
Error Type: training_error
Original Error: too many values to unpack (expected 2)
=== RAW GPT RESPONSE ===
{"training_code": "def train_model(\n    X_train: torch.Tensor, y_train: torch.Tensor,\n    X_val: torch.Tensor, y_val: torch.Tensor,\n    device,\n    # Architecture hyperparams\n    seq_len: int = 1000,\n    patch_size: int = 10,\n    head_dim: int = 12,\n    n_heads: int = 4,\n    n_layers: int = 2,\n    d_ff_factor: int = 2,\n    stem_channels: int = 8,\n    ds_kernel1: int = 7,\n    ds_kernel2: int = 5,\n    dropout: float = 0.1,\n    num_classes: int = 5,\n    max_rel_positions: int = 128,\n    # Optimization hyperparams\n    epochs: int = 15,\n    batch_size: int = 128,\n    lr: float = 5e-4,\n    weight_decay: float = 1e-4,\n    grad_clip_norm: float = 1.0,\n    use_focal_loss: bool = False,\n    focal_gamma: float = 2.0,\n    label_smoothing: float = 0.0,\n    compute_class_weights: bool = True,\n    # Augmentations\n    aug_prob: float = 0.5,\n    aug_jitter_std: float = 0.005,\n    aug_scale_low: float = 0.9,\n    aug_scale_high: float = 1.1,\n    aug_drift_max_amp: float = 0.05,\n    normalize: bool = True,\n    # Quantization params (post-training)\n    quantization_bits: int = 8,\n    quantize_weights: bool = True,\n    quantize_activations: bool = True,\n    # Reproducibility\n    seed: int = 42\n) -> Dict[str, Any]:\n    \"\"\"\n    Trains a compact CNN-Transformer Lite (2-lead ECG) model and returns a quantized model and metrics.\n\n    Notes:\n    - ALWAYS trains on the provided GPU device.\n    - All tensors and the model are moved to the same device during training.\n    - DataLoader pin_memory is set to False as required.\n    - Inputs X_* expected as float tensors shaped (N, 2, 1000) or (N, 1000, 2).\n    \"\"\"\n    # Normalize device argument\n    device = torch.device(device)\n\n    # Reproducibility\n    torch.manual_seed(seed)\n    random.seed(seed)\n\n    # Datasets & Loaders\n    train_ds = ECGDataset(\n        X_train, y_train, seq_len=seq_len, augment=True, aug_prob=aug_prob,\n        aug_jitter_std=aug_jitter_std, aug_scale_low=aug_scale_low, aug_scale_high=aug_scale_high,\n        aug_drift_max_amp=aug_drift_max_amp, normalize=normalize\n    )\n    val_ds = ECGDataset(\n        X_val, y_val, seq_len=seq_len, augment=False, normalize=normalize\n    )\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n\n    # Build model\n    model = CNNTransformerLite1D(\n        seq_len=seq_len, in_ch=2, stem_ch=stem_channels, ds_kernel1=ds_kernel1, ds_kernel2=ds_kernel2,\n        patch_size=patch_size, head_dim=head_dim, n_heads=n_heads, n_layers=n_layers,\n        d_ff_factor=d_ff_factor, dropout=dropout, num_classes=num_classes, max_rel_positions=max_rel_positions\n    )\n\n    # Move model to GPU\n    model = model.to(device)\n\n    # Class weights (optional)\n    if compute_class_weights:\n        with torch.no_grad():\n            classes = torch.arange(num_classes)\n            counts = torch.tensor([(y_train == c).sum().item() for c in classes], dtype=torch.float)\n            counts = torch.clamp(counts, min=1.0)\n            weights = counts.sum() / counts\n            weights = weights / weights.mean()\n            class_weights = weights.to(device)\n    else:\n        class_weights = None\n\n    # Loss\n    if use_focal_loss:\n        criterion = FocalLoss(gamma=focal_gamma, weight=class_weights, label_smoothing=label_smoothing)\n    else:\n        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=label_smoothing).to(device)\n\n    # Optimizer\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = None  # optionally add schedulers here if desired\n\n    # Helper to robustly unpack batches that may include extra items\n    def _unpack_batch(batch):\n        if isinstance(batch, (list, tuple)):\n            if len(batch) < 2:\n                raise ValueError(\"Batch must contain at least 2 elements (inputs, targets)\")\n            return batch[0], batch[1]\n        if isinstance(batch, dict):\n            # Try common key names\n            x_keys = [\"x\", \"inputs\", \"data\", \"features\"]\n            y_keys = [\"y\", \"labels\", \"target\", \"targets\"]\n            for xk in x_keys:\n                for yk in y_keys:\n                    if xk in batch and yk in batch:\n                        return batch[xk], batch[yk]\n            # Fallback: first two tensor values\n            tensors = [v for v in batch.values() if torch.is_tensor(v)]\n            if len(tensors) >= 2:\n                return tensors[0], tensors[1]\n            raise ValueError(\"Could not unpack batch dict into (inputs, targets)\")\n        raise ValueError(f\"Unexpected batch type: {type(batch)}\")\n\n    # Training loop\n    train_losses, val_losses, val_accs = [], [], []\n\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        total_train = 0\n\n        for batch in train_loader:\n            xb, yb = _unpack_batch(batch)\n\n            # Move to GPU\n            xb = xb.to(device, non_blocking=False)\n            yb = yb.to(device, non_blocking=False)\n\n            # Ensure shape (B, 2, T)\n            if xb.dim() == 3 and xb.shape[1] == seq_len and xb.shape[2] == 2:\n                xb = xb.permute(0, 2, 1).contiguous()\n\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            # Make sure loss is on the same device\n            loss = loss.to(device)\n\n            loss.backward()\n            if grad_clip_norm is not None and grad_clip_norm > 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n            optimizer.step()\n\n            running_loss += loss.item() * xb.size(0)\n            total_train += xb.size(0)\n\n        epoch_train_loss = running_loss / max(1, total_train)\n        train_losses.append(epoch_train_loss)\n\n        # Validation\n        model.eval()\n        val_running_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                xb, yb = _unpack_batch(batch)\n                xb = xb.to(device, non_blocking=False)\n                yb = yb.to(device, non_blocking=False)\n                if xb.dim() == 3 and xb.shape[1] == seq_len and xb.shape[2] == 2:\n                    xb = xb.permute(0, 2, 1).contiguous()\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                loss = loss.to(device)\n\n                val_running_loss += loss.item() * xb.size(0)\n                preds = torch.argmax(logits, dim=1)\n                correct += (preds == yb).sum().item()\n                total += xb.size(0)\n\n        epoch_val_loss = val_running_loss / max(1, total)\n        epoch_val_acc = correct / max(1, total)\n        val_losses.append(epoch_val_loss)\n        val_accs.append(epoch_val_acc)\n\n        if scheduler is not None:\n            scheduler.step()\n\n        print(f\"Epoch {epoch+1}/{epochs}: train_loss={epoch_train_loss:.5f} val_loss={epoch_val_loss:.5f} val_acc={epoch_val_acc:.4f}\")\n\n    # Move to CPU for post-training quantization\n    model_cpu = model.to('cpu')\n    model_cpu.eval()\n\n    quantized_model = apply_post_training_quantization(model_cpu, quantization_bits, quantize_weights, quantize_activations)\n\n    # Return artifacts\n    return {\n        'model': quantized_model,\n        'metrics': {\n            'train_losses': train_losses,\n            'val_losses': val_losses,\n            'val_acc': val_accs\n        },\n        'config': {\n            'seq_len': seq_len,\n            'patch_size': patch_size,\n            'head_dim': head_dim,\n            'n_heads': n_heads,\n            'n_layers': n_layers,\n            'd_ff_factor': d_ff_factor,\n            'stem_channels': stem_channels,\n            'ds_kernel1': ds_kernel1,\n            'ds_kernel2': ds_kernel2,\n            'dropout': dropout,\n            'num_classes': num_classes,\n            'epochs': epochs,\n            'batch_size': batch_size,\n            'lr': lr,\n            'weight_decay': weight_decay,\n            'grad_clip_norm': grad_clip_norm,\n            'use_focal_loss': use_focal_loss,\n            'focal_gamma': focal_gamma,\n            'label_smoothing': label_smoothing,\n            'compute_class_weights': compute_class_weights,\n            'augmentations': {\n                'aug_prob': aug_prob,\n                'aug_jitter_std': aug_jitter_std,\n                'aug_scale_low': aug_scale_low,\n                'aug_scale_high': aug_scale_high,\n                'aug_drift_max_amp': aug_drift_max_amp,\n                'normalize': normalize\n            },\n            'quantization': {\n                'quantization_bits': quantization_bits,\n                'quantize_weights': quantize_weights,\n                'quantize_activations': quantize_activations\n            },\n            'seed': seed\n        }\n    }\n"}
=== PROMPT USED ===
CRITICAL: You MUST respond with ONLY valid JSON. No text before or after the JSON.

Analyze this PyTorch training error and provide either hyperparameter corrections, fixed training code, OR indicate if it's a system/environment issue.

PyTorch Version: 2.8.0+cu128
Training Error: too many values to unpack (expected 2)
BO Config: {'lr': {'default': 0.0005, 'type': 'Real', 'low': 1e-06, 'high': 0.01, 'prior': 'log-uniform'}, 'batch_size': {'default': 128, 'type': 'Categorical', 'categories': [32, 64, 128, 256]}, 'epochs': {'default': 15, 'type': 'Integer', 'low': 5, 'high': 50}, 'head_dim': {'default': 12, 'type': 'Integer', 'low': 8, 'high': 24}, 'n_heads': {'default': 4, 'type': 'Categorical', 'categories': [2, 4, 6, 8]}, 'n_layers': {'default': 2, 'type': 'Integer', 'low': 1, 'high': 3}, 'd_ff_factor': {'default': 2, 'type': 'Integer', 'low': 1, 'high': 4}, 'stem_channels': {'default': 8, 'type': 'Categorical', 'categories': [8, 12, 16]}, 'ds_kernel1': {'default': 7, 'type': 'Categorical', 'categories': [3, 5, 7, 9]}, 'ds_kernel2': {'default': 5, 'type': 'Categorical', 'categories': [3, 5, 7]}, 'patch_size': {'default': 10, 'type': 'Categorical', 'categories': [5, 8, 10, 20, 25, 40, 50, 100]}, 'dropout': {'default': 0.1, 'type': 'Real', 'low': 0.0, 'high': 0.5}, 'weight_decay': {'default': 0.0001, 'type': 'Real', 'low': 1e-06, 'high': 0.01, 'prior': 'log-uniform'}, 'grad_clip_norm': {'default': 1.0, 'type': 'Real', 'low': 0.0, 'high': 5.0}, 'use_focal_loss': {'default': False, 'type': 'Categorical', 'categories': [True, False]}, 'focal_gamma': {'default': 2.0, 'type': 'Real', 'low': 0.5, 'high': 5.0}, 'label_smoothing': {'default': 0.0, 'type': 'Real', 'low': 0.0, 'high': 0.2}, 'compute_class_weights': {'default': True, 'type': 'Categorical', 'categories': [True, False]}, 'aug_prob': {'default': 0.5, 'type': 'Real', 'low': 0.0, 'high': 1.0}, 'aug_jitter_std': {'default': 0.005, 'type': 'Real', 'low': 0.0, 'high': 0.05}, 'aug_scale_low': {'default': 0.9, 'type': 'Real', 'low': 0.8, 'high': 1.0}, 'aug_scale_high': {'default': 1.1, 'type': 'Real', 'low': 1.0, 'high': 1.2}, 'aug_drift_max_amp': {'default': 0.05, 'type': 'Real', 'low': 0.0, 'high': 0.2}, 'normalize': {'default': True, 'type': 'Categorical', 'categories': [True, False]}, 'quantization_bits': {'default': 8, 'type': 'Categorical', 'categories': [8, 16, 32]}, 'quantize_weights': {'default': True, 'type': 'Categorical', 'categories': [True, False]}, 'quantize_activations': {'default': True, 'type': 'Categorical', 'categories': [True, False]}, 'seed': {'default': 42, 'type': 'Integer', 'low': 0, 'high': 1000000}}
Training Code: import math
import io
import random
from typing import Dict, Any, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, TensorDataset

# -------------------------
# Data utilities
# -------------------------
class ECGDataset(Dataset):
    def __init__(self, X: torch.Tensor, y: torch.Tensor,
                 seq_len: int = 1000,
                 augment: bool = False,
                 aug_prob: float = 0.5,
                 aug_jitter_std: float = 0.005,
                 aug_scale_low: float = 0.9,
                 aug_scale_high: float = 1.1,
                 aug_drift_max_amp: float = 0.05,
                 normalize: bool = True):
        assert isinstance(X, torch.Tensor) and isinstance(y, torch.Tensor)
        self.X = X
        self.y = y.long()
        self.seq_len = seq_len
        self.augment = augment
        self.aug_prob = aug_prob
        self.aug_jitter_std = aug_jitter_std
        self.aug_scale_low = aug_scale_low
        self.aug_scale_high = aug_scale_high
        self.aug_drift_max_amp = aug_drift_max_amp
        self.normalize = normalize

    def __len__(self):
        return self.X.shape[0]

    def _maybe_permute(self, x: torch.Tensor) -> torch.Tensor:
        # Expect (C=2, T=seq_len). If given (T, C), permute.
        if x.dim() == 2:
            if x.shape[0] == self.seq_len and x.shape[1] == 2:
                x = x.permute(1, 0).contiguous()
            elif x.shape[0] == 2 and x.shape[1] == self.seq_len:
                pass
            else:
                raise ValueError(f"Unexpected sample shape {tuple(x.shape)}; expected (2,{self.seq_len}) or ({self.seq_len},2)")
        elif x.dim() == 3:
            # If somehow batched, flatten assumption violated
            raise ValueError("Dataset expects individual samples, not batched tensors.")
        else:
            raise ValueError("Input sample must be 2D tensor.")
        return x

    def _augment(self, x: torch.Tensor) -> torch.Tensor:
        # x: (2, T)
        if random.random() > self.aug_prob:
            return x
        T = x.shape[1]
        # 1) Jitter (Gaussian noise)
        if self.aug_jitter_std > 0:
            noise = torch.randn_like(x) * self.aug_jitter_std
            x = x + noise
        # 2) Scaling
        scale = random.uniform(self.aug_scale_low, self.aug_scale_high)
        x = x * scale
        # 3) Baseline drift (low-frequency sinusoid)
        if self.aug_drift_max_amp > 0:
            amp = random.uniform(-self.aug_drift_max_amp, self.aug_drift_max_amp)
            freq = random.uniform(0.05, 0.3)  # cycles over the sequence
            t = torch.linspace(0, 1, T, device=x.device)
            drift = amp * torch.sin(2 * math.pi * freq * t)
            x = x + drift.unsqueeze(0)
        return x

    def _normalize(self, x: torch.Tensor) -> torch.Tensor:
        # Per-sample z-score per channel
        mean = x.mean(dim=1, keepdim=True)
        std = x.std(dim=1, keepdim=True) + 1e-6
        return (x - mean) / std

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        x = self.X[idx].float()
        y = self.y[idx]
        x = self._maybe_permute(x)
        if self.normalize:
            x = self._normalize(x)
        if self.augment:
            x = self._augment(x)
        return x, y

# -------------------------
# Model: CNN-Transformer Lite (1D)
# -------------------------
class DepthwiseSeparableConv1d(nn.Module):
    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, stride: int = 1, padding: int = None):
        super().__init__()
        if padding is None:
            padding = kernel_size // 2
        self.depthwise = nn.Conv1d(in_ch, in_ch, kernel_size, stride=stride, padding=padding, groups=in_ch, bias=False)
        self.pointwise = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)
        self.bn = nn.BatchNorm1d(out_ch)
        self.act = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        x = self.bn(x)
        x = self.act(x)
        return x

class PatchEmbed1D(nn.Module):
    def __init__(self, in_ch: int, embed_dim: int, patch_size: int):
        super().__init__()
        self.proj = nn.Conv1d(in_ch, embed_dim, kernel_size=patch_size, stride=patch_size, bias=True)

    def forward(self, x):  # x: (B, C, T)
        x = self.proj(x)  # (B, E, T//P)
        x = x.transpose(1, 2)  # (B, L, E)
        return x

class TinyTransformerBlock(nn.Module):
    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1, max_rel_positions: int = 128):
        super().__init__()
        assert d_model % n_heads == 0, "d_model must be divisible by n_heads"
        self.d_model = d_model
        self.n_heads = n_heads
        self.d_head = d_model // n_heads
        self.dropout = dropout
        self.max_rel_positions = max_rel_positions

        self.q_proj = nn.Linear(d_model, d_model, bias=True)
        self.k_proj = nn.Linear(d_model, d_model, bias=True)
        self.v_proj = nn.Linear(d_model, d_model, bias=True)
        self.o_proj = nn.Linear(d_model, d_model, bias=True)

        self.ln1 = nn.LayerNorm(d_model)
        self.ln2 = nn.LayerNorm(d_model)

        self.mlp = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_ff, d_model),
            nn.Dropout(dropout),
        )

        # Relative positional bias per head
        self.rel_bias = nn.Parameter(torch.zeros(n_heads, 2 * max_rel_positions - 1))
        nn.init.trunc_normal_(self.rel_bias, std=0.02)
        self._rel_index_cache = {}  # cache by L

    def _relative_position_index(self, L: int, device: torch.device):
        if L in self._rel_index_cache:
            idx = self._rel_index_cache[L]
            if idx.device == device:
                return idx
        pos = torch.arange(L, device=device)
        rel = pos[None, :] - pos[:, None]  # (L, L) in [-L+1, L-1]
        rel = rel.clamp(-self.max_rel_positions + 1, self.max_rel_positions - 1)
        rel += self.max_rel_positions - 1  # shift to [0, 2*max_rel_positions-2]
        self._rel_index_cache[L] = rel
        return rel

    def forward(self, x):  # x: (B, L, E)
        B, L, E = x.shape
        h, d = self.n_heads, self.d_head

        # Pre-norm attention
        x_norm = self.ln1(x)
        q = self.q_proj(x_norm).view(B, L, h, d).transpose(1, 2)  # (B, h, L, d)
        k = self.k_proj(x_norm).view(B, L, h, d).transpose(1, 2)
        v = self.v_proj(x_norm).view(B, L, h, d).transpose(1, 2)

        # Relative positional bias
        rel_index = self._relative_position_index(L, x.device)  # (L, L)
        # rel_bias per head: (h, L, L)
        rel_bias = self.rel_bias[:, rel_index]  # (h, L, L)
        rel_bias = rel_bias.unsqueeze(0)  # (1, h, L, L)

        # SDPA with additive bias via attn_mask
        attn_out = F.scaled_dot_product_attention(
            q, k, v,
            attn_mask=rel_bias,
            dropout_p=self.dropout if self.training else 0.0,
            is_causal=False
        )  # (B, h, L, d)
        attn_out = attn_out.transpose(1, 2).contiguous().view(B, L, E)
        x = x + self.o_proj(attn_out)

        # MLP
        x = x + self.mlp(self.ln2(x))
        return x

class CNNTransformerLite1D(nn.Module):
    def __init__(self, seq_len: int = 1000, in_ch: int = 2, stem_ch: int = 8,
                 ds_kernel1: int = 7, ds_kernel2: int = 5,
                 patch_size: int = 10, head_dim: int = 12, n_heads: int = 4,
                 n_layers: int = 2, d_ff_factor: int = 2, dropout: float = 0.1,
                 num_classes: int = 5, max_rel_positions: int = 128):
        super().__init__()
        assert seq_len % patch_size == 0, "patch_size must divide sequence length"
        d_model = head_dim * n_heads
        d_ff = d_model * d_ff_factor
        self.seq_len = seq_len
        self.patch_size = patch_size

        # CNN stem: 2 DS-Conv blocks (very light)
        self.stem1 = DepthwiseSeparableConv1d(in_ch, stem_ch, kernel_size=ds_kernel1)
        self.stem2 = DepthwiseSeparableConv1d(stem_ch, stem_ch, kernel_size=ds_kernel2)

        # Patch embedding to tokens
        self.patch_embed = PatchEmbed1D(stem_ch, d_model, patch_size=patch_size)

        # Transformer layers
        blocks = []
        for _ in range(n_layers):
            blocks.append(TinyTransformerBlock(d_model=d_model, n_heads=n_heads, d_ff=d_ff, dropout=dropout, max_rel_positions=max_rel_positions))
        self.blocks = nn.ModuleList(blocks)
        self.norm = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)

        # Attention pooling: mean across tokens
        self.head = nn.Linear(d_model, num_classes)

    def forward(self, x):  # x: (B, C=2, T=seq_len)
        if x.dim() != 3:
            raise ValueError(f"Expected input of shape (B, C, T), got {tuple(x.shape)}")
        if x.shape[2] != self.seq_len:
            raise ValueError(f"Expected T={self.seq_len}, got T={x.shape[2]}")
        x = self.stem1(x)
        x = self.stem2(x)
        x = self.patch_embed(x)  # (B, L, E)
        for blk in self.blocks:
            x = blk(x)
        x = self.norm(x)
        x = self.dropout(x)
        x = x.mean(dim=1)  # (B, E)
        logits = self.head(x)
        return logits

# -------------------------
# Losses
# -------------------------
class FocalLoss(nn.Module):
    def __init__(self, gamma: float = 2.0, weight: torch.Tensor = None, label_smoothing: float = 0.0):
        super().__init__()
        self.gamma = gamma
        self.weight = weight
        self.label_smoothing = label_smoothing

    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        # logits: (B, C), targets: (B,)
        log_probs = F.log_softmax(logits, dim=1)
        probs = log_probs.exp()
        if self.label_smoothing > 0.0:
            n_classes = logits.size(1)
            true_dist = torch.zeros_like(log_probs)
            true_dist.fill_(self.label_smoothing / (n_classes - 1))
            true_dist.scatter_(1, targets.unsqueeze(1), 1.0 - self.label_smoothing)
            ce = -(true_dist * log_probs).sum(dim=1)
            pt = (true_dist * probs).sum(dim=1)
        else:
            ce = F.nll_loss(log_probs, targets, weight=self.weight, reduction='none')
            pt = probs.gather(1, targets.unsqueeze(1)).squeeze(1)
        loss = ((1 - pt) ** self.gamma) * ce
        if self.weight is not None and self.label_smoothing > 0.0:
            # Approximate class weighting under smoothing by scaling per-sample by class weight
            w = self.weight[targets]
            loss = loss * w
        return loss.mean()

# -------------------------
# Quantization helper
# -------------------------
def apply_post_training_quantization(model: nn.Module, quantization_bits: int, quantize_weights: bool, quantize_activations: bool) -> nn.Module:
    # For 8-bit: dynamic quantization on Linear layers (weights + activations during ops).
    # For 16-bit: convert model to float16 (weights and activations if supported).
    # For 32-bit: no quantization.
    if not quantize_weights and not quantize_activations:
        return model

    if quantization_bits == 8:
        try:
            from torch.ao.quantization import quantize_dynamic
        except Exception:
            from torch.quantization import quantize_dynamic  # fallback alias
        # Note: dynamic quantization primarily targets weights of Linear layers; activations are quantized dynamically per op.
        qmodel = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)
        return qmodel
    elif quantization_bits == 16:
        # Half precision as a proxy for 16-bit quantization
        qmodel = model.half()
        return qmodel
    elif quantization_bits == 32:
        # Keep as-is
        return model
    else:
        # Unsupported bitwidth; return original
        return model

# -------------------------
# Training function
# -------------------------
def train_model(
    X_train: torch.Tensor, y_train: torch.Tensor,
    X_val: torch.Tensor, y_val: torch.Tensor,
    device,
    # Architecture hyperparams
    seq_len: int = 1000,
    patch_size: int = 10,
    head_dim: int = 12,
    n_heads: int = 4,
    n_layers: int = 2,
    d_ff_factor: int = 2,
    stem_channels: int = 8,
    ds_kernel1: int = 7,
    ds_kernel2: int = 5,
    dropout: float = 0.1,
    num_classes: int = 5,
    max_rel_positions: int = 128,
    # Optimization hyperparams
    epochs: int = 15,
    batch_size: int = 128,
    lr: float = 5e-4,
    weight_decay: float = 1e-4,
    grad_clip_norm: float = 1.0,
    use_focal_loss: bool = False,
    focal_gamma: float = 2.0,
    label_smoothing: float = 0.0,
    compute_class_weights: bool = True,
    # Augmentations
    aug_prob: float = 0.5,
    aug_jitter_std: float = 0.005,
    aug_scale_low: float = 0.9,
    aug_scale_high: float = 1.1,
    aug_drift_max_amp: float = 0.05,
    normalize: bool = True,
    # Quantization params (post-training)
    quantization_bits: int = 8,
    quantize_weights: bool = True,
    quantize_activations: bool = True,
    # Reproducibility
    seed: int = 42
) -> Dict[str, Any]:
    """
    Trains a compact CNN-Transformer Lite (2-lead ECG) model and returns a quantized model and metrics.

    Notes:
    - ALWAYS trains on the provided GPU device.
    - All tensors and the model are moved to the same device during training.
    - DataLoader pin_memory is set to False as required.
    - Inputs X_* expected as float tensors shaped (N, 2, 1000) or (N, 1000, 2).
    """
    # Normalize device argument
    device = torch.device(device)

    # Reproducibility
    torch.manual_seed(seed)
    random.seed(seed)

    # Datasets & Loaders
    train_ds = ECGDataset(
        X_train, y_train, seq_len=seq_len, augment=True, aug_prob=aug_prob,
        aug_jitter_std=aug_jitter_std, aug_scale_low=aug_scale_low, aug_scale_high=aug_scale_high,
        aug_drift_max_amp=aug_drift_max_amp, normalize=normalize
    )
    val_ds = ECGDataset(
        X_val, y_val, seq_len=seq_len, augment=False, normalize=normalize
    )

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)

    # Build model
    model = CNNTransformerLite1D(
        seq_len=seq_len, in_ch=2, stem_ch=stem_channels, ds_kernel1=ds_kernel1, ds_kernel2=ds_kernel2,
        patch_size=patch_size, head_dim=head_dim, n_heads=n_heads, n_layers=n_layers,
        d_ff_factor=d_ff_factor, dropout=dropout, num_classes=num_classes, max_rel_positions=max_rel_positions
    )

    # Move model to GPU
    model = model.to(device)

    # Class weights (optional)
    if compute_class_weights:
        with torch.no_grad():
            classes = torch.arange(num_classes)
            counts = torch.tensor([(y_train == c).sum().item() for c in classes], dtype=torch.float)
            counts = torch.clamp(counts, min=1.0)
            weights = counts.sum() / counts
            weights = weights / weights.mean()
            class_weights = weights.to(device)
    else:
        class_weights = None

    # Loss
    if use_focal_loss:
        criterion = FocalLoss(gamma=focal_gamma, weight=class_weights, label_smoothing=label_smoothing)
    else:
        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=label_smoothing).to(device)

    # Optimizer
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    scheduler = None  # optionally add schedulers here if desired

    # Training loop
    train_losses, val_losses, val_accs = [], [], []

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        total_train = 0

        for xb, yb in train_loader:
            # Move to GPU
            xb = xb.to(device, non_blocking=False)
            yb = yb.to(device, non_blocking=False)

            # Ensure shape (B, 2, T)
            if xb.dim() == 3 and xb.shape[1] == seq_len and xb.shape[2] == 2:
                xb = xb.permute(0, 2, 1).contiguous()

            optimizer.zero_grad(set_to_none=True)
            logits = model(xb)
            loss = criterion(logits, yb)
            # Make sure loss is on the same device
            loss = loss.to(device)

            loss.backward()
            if grad_clip_norm is not None and grad_clip_norm > 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)
            optimizer.step()

            running_loss += loss.item() * xb.size(0)
            total_train += xb.size(0)

        epoch_train_loss = running_loss / max(1, total_train)
        train_losses.append(epoch_train_loss)

        # Validation
        model.eval()
        val_running_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for xb, yb in val_loader:
                xb = xb.to(device, non_blocking=False)
                yb = yb.to(device, non_blocking=False)
                if xb.dim() == 3 and xb.shape[1] == seq_len and xb.shape[2] == 2:
                    xb = xb.permute(0, 2, 1).contiguous()
                logits = model(xb)
                loss = criterion(logits, yb)
                loss = loss.to(device)

                val_running_loss += loss.item() * xb.size(0)
                preds = torch.argmax(logits, dim=1)
                correct += (preds == yb).sum().item()
                total += xb.size(0)

        epoch_val_loss = val_running_loss / max(1, total)
        epoch_val_acc = correct / max(1, total)
        val_losses.append(epoch_val_loss)
        val_accs.append(epoch_val_acc)

        if scheduler is not None:
            scheduler.step()

        print(f"Epoch {epoch+1}/{epochs}: train_loss={epoch_train_loss:.5f} val_loss={epoch_val_loss:.5f} val_acc={epoch_val_acc:.4f}")

    # Move to CPU for post-training quantization
    model_cpu = model.to('cpu')
    model_cpu.eval()

    quantized_model = apply_post_training_quantization(model_cpu, quantization_bits, quantize_weights, quantize_activations)

    # Return artifacts
    return {
        'model': quantized_model,
        'metrics': {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'val_acc': val_accs
        },
        'config': {
            'seq_len': seq_len,
            'patch_size': patch_size,
            'head_dim': head_dim,
            'n_heads': n_heads,
            'n_layers': n_layers,
            'd_ff_factor': d_ff_factor,
            'stem_channels': stem_channels,
            'ds_kernel1': ds_kernel1,
            'ds_kernel2': ds_kernel2,
            'dropout': dropout,
            'num_classes': num_classes,
            'epochs': epochs,
            'batch_size': batch_size,
            'lr': lr,
            'weight_decay': weight_decay,
            'grad_clip_norm': grad_clip_norm,
            'use_focal_loss': use_focal_loss,
            'focal_gamma': focal_gamma,
            'label_smoothing': label_smoothing,
            'compute_class_weights': compute_class_weights,
            'augmentations': {
                'aug_prob': aug_prob,
                'aug_jitter_std': aug_jitter_std,
                'aug_scale_low': aug_scale_low,
                'aug_scale_high': aug_scale_high,
                'aug_drift_max_amp': aug_drift_max_amp,
                'normalize': normalize
            },
            'quantization': {
                'quantization_bits': quantization_bits,
                'quantize_weights': quantize_weights,
                'quantize_activations': quantize_activations
            },
            'seed': seed
        }
    }


RESPONSE OPTIONS:
1. HYPERPARAMETER FIX: If error can be fixed by changing hyperparameters
   Output: {"bo_config": {"param_name": new_value, "param2": new_value}}

2. CODE FIX: If error requires fixing bugs in the training code
   Output: {"training_code": "complete_corrected_training_function_code"}

3. SYSTEM/ENVIRONMENT ISSUE: If error is due to system/environment issues (GPU memory, CUDA, dependencies, data issues, etc.) that cannot be fixed by code or hyperparameter changes
   Output: {"system_issue": "STOP_PIPELINE"}

4. CANNOT FIX: If error cannot be resolved for any other reason
   Output: {}

RESPONSE FORMAT REQUIREMENTS:
1. Output ONLY a JSON object with either "bo_config", "training_code", "system_issue", or empty object
2. No explanations, no markdown, no ```json``` blocks
3. Start with { and end with }
4. For training_code fixes, include the COMPLETE corrected function
5. For system_issue, use exactly "STOP_PIPELINE" as the value

CORRECTION EXAMPLES:
- "Model has X KB storage, exceeds 256KB limit" → {"bo_config": {"d_model": 64, "hidden_size": 128}}
- "'str' object has no attribute 'type'" → {"training_code": "def train_model(...):\n    # fixed implementation"}
- "Quantization bug in code" → {"training_code": "corrected_training_function"}
- "AcceleratorError in DataLoader worker process" → {"bo_config": {"num_workers": 0}}
- "CUDA error: initialization error" → {"bo_config": {"num_workers": 0}}
- "DataLoader worker CUDA context" → {"bo_config": {"num_workers": 0}}
- "mat1 and mat2 shapes cannot be multiplied" → {"bo_config": {"d_model": 128}}
- "CUDA out of memory" → {"system_issue": "STOP_PIPELINE"}
- "No such file or directory" → {"system_issue": "STOP_PIPELINE"}
- "ImportError: No module named" → {"system_issue": "STOP_PIPELINE"}

OUTPUT ONLY THE JSON OBJECT: