=== GPT DEBUG RESPONSE ===
Timestamp: 20251012_094042
Attempt: 1/4
Error Type: training_error
Original Error: 'tuple' object has no attribute 'numel'
=== RAW GPT RESPONSE ===
{"training_code": "def train_model(X_train, y_train, X_val, y_val, device, **kwargs):\n    import torch\n    from torch.utils.data import TensorDataset, DataLoader\n    from torch import nn, optim\n    import torch.nn.functional as F\n    import torch.ao.quantization as tq\n    import math\n    import time\n    import copy\n\n    # --------------------\n    # Hyperparameters with defaults (can be overridden via kwargs)\n    # --------------------\n    hp = {\n        'lr': 1e-3,\n        'weight_decay': 1e-4,\n        'epochs': 15,\n        'batch_size': 8,\n        'dropout': 0.1,\n        'base_channels': 16,\n        'eca_kernel': 3,\n        'pool_stride': 4,\n        'label_smoothing': 0.05,\n        'grad_clip_norm': 1.0,\n        'scheduler_step_size': 0,\n        'scheduler_gamma': 0.5,\n        'num_workers': 4,\n        'use_amp': True,\n        'quantization_bits': 8,\n        'quantize_weights': True,\n        'quantize_activations': True,  # ignored in dynamic path\n        'calibrate_batches': 4,        # ignored in dynamic path\n    }\n    hp.update(kwargs or {})\n\n    # --------------------\n    # Helpers\n    # --------------------\n    def _to_tensor(x, dtype=None):\n        if isinstance(x, torch.Tensor):\n            return x.to(dtype=dtype) if dtype is not None else x\n        return torch.as_tensor(x, dtype=dtype)\n\n    def _normalize_targets(y, num_classes):\n        # Robustly extract label tensor from possibly nested structures\n        while isinstance(y, (list, tuple)):\n            y = y[0]\n        if not isinstance(y, torch.Tensor):\n            y = torch.as_tensor(y)\n        if y.ndim > 1:\n            if y.size(-1) == num_classes:\n                y = y.argmax(dim=-1)\n            else:\n                y = y.squeeze()\n        return y.long()\n\n    def _extract_xy(batch):\n        # Robustly unpack (xb, yb) from possibly nested tuples/lists\n        if isinstance(batch, (list, tuple)):\n            xb = batch[0]\n            yb = batch[1] if len(batch) > 1 else None\n        else:\n            xb, yb = batch, None\n        while isinstance(xb, (list, tuple)):\n            xb = xb[0]\n        while isinstance(yb, (list, tuple)):\n            yb = yb[0]\n        return xb, yb\n\n    # --------------------\n    # Device handling and checks\n    # --------------------\n    device = torch.device(device)\n    if device.type != 'cuda':\n        raise RuntimeError('This training function requires a CUDA device. Pass device=\"cuda\" or torch.device(\"cuda\").')\n\n    torch.backends.cudnn.benchmark = True\n\n    num_classes = 5\n\n    # --------------------\n    # Convert inputs to tensors and normalize shapes/dtypes\n    # Expect X_*: (N, 6, 6000), y_*: (N,) with class indices 0..4 or 1-hot (N,5)\n    # --------------------\n    X_train = _to_tensor(X_train, dtype=torch.float32)\n    X_val = _to_tensor(X_val, dtype=torch.float32)\n    y_train = _normalize_targets(y_train, num_classes)\n    y_val = _normalize_targets(y_val, num_classes)\n\n    if X_train.ndim != 3:\n        raise ValueError(f'X_train must be 3D (N, C=6, L=6000). Got shape {tuple(X_train.shape)}')\n    if X_val.ndim != 3:\n        raise ValueError(f'X_val must be 3D (N, C=6, L=6000). Got shape {tuple(X_val.shape)}')\n    if X_train.shape[1] != 6 or X_val.shape[1] != 6:\n        raise ValueError('Expected 6 EEG channels.')\n    if X_train.shape[2] != 6000 or X_val.shape[2] != 6000:\n        raise ValueError('Expected sequence length 6000 per epoch.')\n    if y_train.ndim != 1 or y_val.ndim != 1:\n        raise ValueError('y_train and y_val must be 1D label tensors of shape (N,) after normalization.')\n    if X_train.shape[0] != y_train.shape[0] or X_val.shape[0] != y_val.shape[0]:\n        raise ValueError('Mismatched number of samples between X and y.')\n\n    # --------------------\n    # Datasets and DataLoaders (avoid custom multiprocessing context to reduce edge cases)\n    # --------------------\n    train_ds = TensorDataset(X_train, y_train)\n    val_ds = TensorDataset(X_val, y_val)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=int(hp['batch_size']),\n        shuffle=True,\n        num_workers=int(hp['num_workers']),\n        pin_memory=True,\n        drop_last=False,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=max(1, int(hp['batch_size']) // 2),\n        shuffle=False,\n        num_workers=int(hp['num_workers']),\n        pin_memory=True,\n        drop_last=False,\n    )\n\n    # --------------------\n    # Model definition\n    # --------------------\n    class ChannelECA(nn.Module):\n        def __init__(self, channels: int, k: int = 3):\n            super().__init__()\n            k = max(1, k)\n            if k % 2 == 0:\n                k += 1\n            self.avg_pool = nn.AdaptiveAvgPool1d(1)\n            self.conv = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1) // 2, bias=False)\n            self.sig = nn.Sigmoid()\n\n        def forward(self, x):  # x: (B, C, L)\n            y = self.avg_pool(x)            # (B, C, 1)\n            y = y.permute(0, 2, 1)          # (B, 1, C)\n            y = self.conv(y)                # (B, 1, C)\n            y = self.sig(y).permute(0, 2, 1)  # (B, C, 1)\n            return x * y                    # broadcast over L\n\n    class DepthwiseSeparableConv1d(nn.Module):\n        def __init__(self, in_ch: int, out_ch: int, k: int = 7, stride: int = 1, p: float = 0.0):\n            super().__init__()\n            pad = (k - 1) // 2\n            self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=stride, padding=pad, groups=in_ch, bias=False)\n            self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.act = nn.GELU()\n            self.drop = nn.Dropout(p)\n        def forward(self, x):\n            x = self.dw(x)\n            x = self.pw(x)\n            x = self.bn(x)\n            x = self.act(x)\n            x = self.drop(x)\n            return x\n\n    class ConvBlock(nn.Module):\n        def __init__(self, in_ch, out_ch, k=5, s=2, p: float = 0.0):\n            super().__init__()\n            pad = (k - 1) // 2\n            self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=pad, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.act = nn.GELU()\n            self.drop = nn.Dropout(p)\n        def forward(self, x):\n            x = self.conv(x)\n            x = self.bn(x)\n            x = self.act(x)\n            x = self.drop(x)\n            return x\n\n    class ClassifierHead(nn.Module):\n        def __init__(self, in_dim, hidden, out_dim, p: float = 0.1):\n            super().__init__()\n            # Removed QuantStub/DeQuantStub to avoid static quantization issues\n            self.fc1 = nn.Linear(in_dim, hidden)\n            self.act = nn.GELU()\n            self.drop = nn.Dropout(p)\n            self.fc2 = nn.Linear(hidden, out_dim)\n        def forward(self, x):  # x: (B, in_dim)\n            x = self.fc1(x)\n            x = self.act(x)\n            x = self.drop(x)\n            x = self.fc2(x)\n            return x\n\n    class EEGSleepNet(nn.Module):\n        def __init__(self, base_channels=16, eca_k=3, pool_stride=4, dropout=0.1, num_classes=5):\n            super().__init__()\n            self.eca = ChannelECA(6, k=eca_k)\n            c1 = base_channels\n            c2 = base_channels * 2\n            c3 = base_channels * 4\n            self.conv1 = ConvBlock(6, c1, k=7, s=2, p=dropout)\n            self.conv2 = ConvBlock(c1, c2, k=5, s=2, p=dropout)\n            self.conv3 = ConvBlock(c2, c3, k=5, s=2, p=dropout)\n            self.ds = DepthwiseSeparableConv1d(c3, c3, k=7, stride=1, p=dropout)\n            self.pool = nn.AvgPool1d(kernel_size=pool_stride, stride=pool_stride)\n\n            d_model = c3\n            self.bigru = nn.GRU(input_size=d_model, hidden_size=d_model, num_layers=1, batch_first=False, bidirectional=True)\n\n            head_in = d_model * 2\n            head_hidden = max(32, d_model)\n            self.head = ClassifierHead(head_in, head_hidden, num_classes, p=dropout)\n\n        def forward(self, x):  # x: (B, 6, 6000)\n            x = self.eca(x)\n            x = self.conv1(x)\n            x = self.conv2(x)\n            x = self.conv3(x)\n            x = self.ds(x)\n            x = self.pool(x)  # (B, C, L')\n            x = x.transpose(1, 2)  # (B, L', C)\n            x = x.transpose(0, 1)  # (L', B, C)\n            out, _ = self.bigru(x)  # (L', B, 2C)\n            out = out.mean(dim=0)   # (B, 2C)\n            logits = self.head(out) # (B, num_classes)\n            return logits\n\n    # --------------------\n    # Instantiate model\n    # --------------------\n    model = EEGSleepNet(\n        base_channels=int(hp['base_channels']),\n        eca_k=int(hp['eca_kernel']),\n        pool_stride=int(hp['pool_stride']),\n        dropout=float(hp['dropout']),\n        num_classes=num_classes,\n    ).to(device)\n\n    # --------------------\n    # Optimizer, loss, scheduler\n    # --------------------\n    optimizer = optim.AdamW(model.parameters(), lr=float(hp['lr']), weight_decay=float(hp['weight_decay']))\n    criterion = nn.CrossEntropyLoss(label_smoothing=float(hp['label_smoothing'])).to(device)\n\n    scheduler = None\n    if int(hp['scheduler_step_size']) > 0:\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=int(hp['scheduler_step_size']), gamma=float(hp['scheduler_gamma']))\n\n    scaler = torch.cuda.amp.GradScaler(enabled=bool(hp['use_amp']))\n\n    # --------------------\n    # Training loop\n    # --------------------\n    train_losses, val_losses, val_accs = [], [], []\n\n    for epoch in range(1, int(hp['epochs']) + 1):\n        model.train()\n        epoch_loss = 0.0\n        n_train = 0\n        t0 = time.time()\n\n        for batch in train_loader:\n            xb, yb = _extract_xy(batch)\n\n            # Normalize targets\n            yb = _normalize_targets(yb, num_classes)\n\n            xb = xb.to(device, non_blocking=True).float()\n            yb = yb.to(device, non_blocking=True)\n\n            optimizer.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=bool(hp['use_amp'])):\n                logits = model(xb)\n                loss = criterion(logits, yb)\n\n            scaler.scale(loss).backward()\n            if hp['grad_clip_norm'] is not None and float(hp['grad_clip_norm']) > 0:\n                scaler.unscale_(optimizer)\n                nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(hp['grad_clip_norm']))\n            scaler.step(optimizer)\n            scaler.update()\n\n            batch_size_now = xb.size(0)\n            epoch_loss += loss.detach().item() * batch_size_now\n            n_train += batch_size_now\n\n        if scheduler is not None:\n            scheduler.step()\n\n        train_loss = epoch_loss / max(1, n_train)\n\n        # Validation\n        model.eval()\n        val_loss = 0.0\n        n_val = 0\n        correct = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                xb, yb = _extract_xy(batch)\n                yb = _normalize_targets(yb, num_classes)\n\n                xb = xb.to(device, non_blocking=True).float()\n                yb = yb.to(device, non_blocking=True)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                val_loss += loss.detach().item() * xb.size(0)\n                n_val += xb.size(0)\n                pred = logits.argmax(dim=1)\n                correct += (pred == yb).sum().item()\n\n        val_loss = val_loss / max(1, n_val)\n        val_acc = correct / max(1, n_val)\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n\n        print(f'Epoch {epoch:03d}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f} time={time.time()-t0:.1f}s')\n\n    # --------------------\n    # Post-Training Quantization (Dynamic quantization only for stability)\n    # --------------------\n    model_cpu = copy.deepcopy(model).to('cpu')\n    model_cpu.eval()\n\n    qb = int(hp['quantization_bits'])\n    qw = bool(hp['quantize_weights'])\n\n    if qw and qb == 8:\n        # Dynamic quantization for Linear and GRU layers\n        model_cpu = tq.quantize_dynamic(\n            model_cpu,\n            {nn.Linear, nn.GRU},\n            dtype=torch.qint8,\n            inplace=True\n        )\n    elif qw and qb == 16:\n        # Half precision weights\n        model_cpu = model_cpu.half()\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs\n    }\n\n    return model_cpu, metrics\n"}
=== PROMPT USED ===
CRITICAL: You MUST respond with ONLY valid JSON. No text before or after the JSON.

Analyze this PyTorch training error and provide either hyperparameter corrections, fixed training code, OR indicate if it's a system/environment issue.

PyTorch Version: 2.8.0+cu128
Training Error: 'tuple' object has no attribute 'numel'
BO Config: {'lr': {'default': 0.001, 'type': 'Real', 'low': 1e-05, 'high': 0.005, 'prior': 'log-uniform'}, 'weight_decay': {'default': 0.0001, 'type': 'Real', 'low': 1e-06, 'high': 0.01, 'prior': 'log-uniform'}, 'epochs': {'default': 15, 'type': 'Integer', 'low': 5, 'high': 50}, 'batch_size': {'default': 8, 'type': 'Categorical', 'categories': [4, 8, 12, 16]}, 'dropout': {'default': 0.1, 'type': 'Real', 'low': 0.0, 'high': 0.5}, 'base_channels': {'default': 16, 'type': 'Integer', 'low': 8, 'high': 32}, 'eca_kernel': {'default': 3, 'type': 'Categorical', 'categories': [3, 5]}, 'pool_stride': {'default': 4, 'type': 'Categorical', 'categories': [3, 4, 5]}, 'label_smoothing': {'default': 0.05, 'type': 'Real', 'low': 0.0, 'high': 0.1}, 'grad_clip_norm': {'default': 1.0, 'type': 'Real', 'low': 0.5, 'high': 5.0}, 'scheduler_step_size': {'default': 0, 'type': 'Integer', 'low': 0, 'high': 10}, 'scheduler_gamma': {'default': 0.5, 'type': 'Real', 'low': 0.1, 'high': 0.99}, 'num_workers': {'default': 4, 'type': 'Categorical', 'categories': [4]}, 'use_amp': {'default': True, 'type': 'Categorical', 'categories': [True, False]}, 'quantization_bits': {'default': 8, 'type': 'Categorical', 'categories': [8, 16, 32]}, 'quantize_weights': {'default': True, 'type': 'Categorical', 'categories': [True, False]}, 'quantize_activations': {'default': True, 'type': 'Categorical', 'categories': [True, False]}, 'calibrate_batches': {'default': 4, 'type': 'Integer', 'low': 1, 'high': 8}}
Training Code: def train_model(X_train, y_train, X_val, y_val, device, **kwargs):
    # Required imports
    import torch
    from torch.utils.data import TensorDataset, DataLoader
    from torch import nn, optim
    import torch.nn.functional as F
    import torch.ao.quantization as tq
    import math
    import time
    import copy
    import torch.multiprocessing as mp

    # --------------------
    # Hyperparameters with defaults (can be overridden via kwargs)
    # --------------------
    hp = {
        'lr': 1e-3,
        'weight_decay': 1e-4,
        'epochs': 15,
        'batch_size': 8,
        'dropout': 0.1,
        'base_channels': 16,
        'eca_kernel': 3,
        'pool_stride': 4,
        'label_smoothing': 0.05,
        'grad_clip_norm': 1.0,
        'scheduler_step_size': 0,
        'scheduler_gamma': 0.5,
        'num_workers': 4,
        'use_amp': True,
        # Quantization params
        'quantization_bits': 8,
        'quantize_weights': True,
        'quantize_activations': True,
        'calibrate_batches': 4,
    }
    hp.update(kwargs or {})

    # --------------------
    # Helpers
    # --------------------
    def _to_tensor(x, dtype=None):
        if isinstance(x, torch.Tensor):
            return x.to(dtype=dtype) if dtype is not None else x
        return torch.as_tensor(x, dtype=dtype)

    def _normalize_targets(y, num_classes):
        # Accept tensor, numpy, or (tensor,) tuples/lists
        if isinstance(y, (list, tuple)):
            # If tuple/list, take the first element (most loaders put labels here)
            y = y[0]
        if not isinstance(y, torch.Tensor):
            y = torch.as_tensor(y)
        # If one-hot or extra dims, convert/squeeze
        if y.ndim > 1:
            if y.size(-1) == num_classes:
                y = y.argmax(dim=-1)
            else:
                y = y.squeeze()
        return y.long()

    # --------------------
    # Device handling and checks
    # --------------------
    device = torch.device(device)
    if device.type != 'cuda':
        raise RuntimeError('This training function requires a CUDA device. Pass device="cuda" or torch.device("cuda").')

    torch.backends.cudnn.benchmark = True

    num_classes = 5

    # --------------------
    # Convert inputs to tensors and normalize shapes/dtypes
    # Expect X_*: (N, 6, 6000), y_*: (N,) with class indices 0..4 or 1-hot (N,5)
    # --------------------
    X_train = _to_tensor(X_train, dtype=torch.float32)
    X_val = _to_tensor(X_val, dtype=torch.float32)
    y_train = _normalize_targets(y_train, num_classes)
    y_val = _normalize_targets(y_val, num_classes)

    if X_train.ndim != 3:
        raise ValueError(f'X_train must be 3D (N, C=6, L=6000). Got shape {tuple(X_train.shape)}')
    if X_val.ndim != 3:
        raise ValueError(f'X_val must be 3D (N, C=6, L=6000). Got shape {tuple(X_val.shape)}')
    if X_train.shape[1] != 6 or X_val.shape[1] != 6:
        raise ValueError('Expected 6 EEG channels.')
    if X_train.shape[2] != 6000 or X_val.shape[2] != 6000:
        raise ValueError('Expected sequence length 6000 per epoch.')
    if y_train.ndim != 1 or y_val.ndim != 1:
        raise ValueError('y_train and y_val must be 1D label tensors of shape (N,) after normalization.')
    if X_train.shape[0] != y_train.shape[0] or X_val.shape[0] != y_val.shape[0]:
        raise ValueError('Mismatched number of samples between X and y.')

    # --------------------
    # Datasets and DataLoaders (with spawn context for CUDA safety)
    # --------------------
    mp_ctx = torch.multiprocessing.get_context('spawn')

    train_ds = TensorDataset(X_train, y_train)
    val_ds = TensorDataset(X_val, y_val)

    train_loader = DataLoader(
        train_ds,
        batch_size=int(hp['batch_size']),
        shuffle=True,
        num_workers=int(hp['num_workers']),
        pin_memory=True,
        multiprocessing_context=mp_ctx,
        drop_last=False,
    )
    val_loader = DataLoader(
        val_ds,
        batch_size=max(1, int(hp['batch_size']) // 2),
        shuffle=False,
        num_workers=int(hp['num_workers']),
        pin_memory=True,
        multiprocessing_context=mp_ctx,
        drop_last=False,
    )

    # --------------------
    # Model definition
    # --------------------
    class ChannelECA(nn.Module):
        def __init__(self, channels: int, k: int = 3):
            super().__init__()
            k = max(1, k)
            if k % 2 == 0:
                k += 1
            self.avg_pool = nn.AdaptiveAvgPool1d(1)
            self.conv = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1) // 2, bias=False)
            self.sig = nn.Sigmoid()

        def forward(self, x):  # x: (B, C, L)
            b, c, l = x.shape
            y = self.avg_pool(x)            # (B, C, 1)
            y = y.permute(0, 2, 1)          # (B, 1, C)
            y = self.conv(y)                # (B, 1, C)
            y = self.sig(y).permute(0, 2, 1)  # (B, C, 1)
            return x * y                    # broadcast over L

    class DepthwiseSeparableConv1d(nn.Module):
        def __init__(self, in_ch: int, out_ch: int, k: int = 7, stride: int = 1, p: float = 0.0):
            super().__init__()
            pad = (k - 1) // 2
            self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=stride, padding=pad, groups=in_ch, bias=False)
            self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)
            self.bn = nn.BatchNorm1d(out_ch)
            self.act = nn.GELU()
            self.drop = nn.Dropout(p)
        def forward(self, x):
            x = self.dw(x)
            x = self.pw(x)
            x = self.bn(x)
            x = self.act(x)
            x = self.drop(x)
            return x

    class ConvBlock(nn.Module):
        def __init__(self, in_ch, out_ch, k=5, s=2, p: float = 0.0):
            super().__init__()
            pad = (k - 1) // 2
            self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=pad, bias=False)
            self.bn = nn.BatchNorm1d(out_ch)
            self.act = nn.GELU()
            self.drop = nn.Dropout(p)
        def forward(self, x):
            x = self.conv(x)
            x = self.bn(x)
            x = self.act(x)
            x = self.drop(x)
            return x

    class ClassifierHead(nn.Module):
        def __init__(self, in_dim, hidden, out_dim, p: float = 0.1):
            super().__init__()
            self.quant = tq.QuantStub()
            self.fc1 = nn.Linear(in_dim, hidden)
            self.act = nn.GELU()
            self.drop = nn.Dropout(p)
            self.fc2 = nn.Linear(hidden, out_dim)
            self.dequant = tq.DeQuantStub()
        def forward(self, x):  # x: (B, in_dim)
            x = self.quant(x)
            x = self.fc1(x)
            x = self.act(x)
            x = self.drop(x)
            x = self.fc2(x)
            x = self.dequant(x)
            return x

    class EEGSleepNet(nn.Module):
        def __init__(self, base_channels=16, eca_k=3, pool_stride=4, dropout=0.1, num_classes=5):
            super().__init__()
            self.eca = ChannelECA(6, k=eca_k)
            c1 = base_channels
            c2 = base_channels * 2
            c3 = base_channels * 4
            self.conv1 = ConvBlock(6, c1, k=7, s=2, p=dropout)
            self.conv2 = ConvBlock(c1, c2, k=5, s=2, p=dropout)
            self.conv3 = ConvBlock(c2, c3, k=5, s=2, p=dropout)
            self.ds = DepthwiseSeparableConv1d(c3, c3, k=7, stride=1, p=dropout)
            self.pool = nn.AvgPool1d(kernel_size=pool_stride, stride=pool_stride)

            d_model = c3
            self.bigru = nn.GRU(input_size=d_model, hidden_size=d_model, num_layers=1, batch_first=False, bidirectional=True)

            head_in = d_model * 2
            head_hidden = max(32, d_model)
            self.head = ClassifierHead(head_in, head_hidden, num_classes, p=dropout)

        def forward(self, x):  # x: (B, 6, 6000)
            x = self.eca(x)
            x = self.conv1(x)
            x = self.conv2(x)
            x = self.conv3(x)
            x = self.ds(x)
            x = self.pool(x)  # (B, C, L')
            x = x.transpose(1, 2)  # (B, L', C)
            x = x.transpose(0, 1)  # (L', B, C)
            out, _ = self.bigru(x)  # (L', B, 2C)
            out = out.mean(dim=0)   # (B, 2C)
            logits = self.head(out) # (B, num_classes)
            return logits

    # --------------------
    # Instantiate model
    # --------------------
    model = EEGSleepNet(
        base_channels=int(hp['base_channels']),
        eca_k=int(hp['eca_kernel']),
        pool_stride=int(hp['pool_stride']),
        dropout=float(hp['dropout']),
        num_classes=num_classes,
    ).to(device)

    # --------------------
    # Optimizer, loss, scheduler
    # --------------------
    optimizer = optim.AdamW(model.parameters(), lr=float(hp['lr']), weight_decay=float(hp['weight_decay']))
    criterion = nn.CrossEntropyLoss(label_smoothing=float(hp['label_smoothing'])).to(device)

    scheduler = None
    if int(hp['scheduler_step_size']) > 0:
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=int(hp['scheduler_step_size']), gamma=float(hp['scheduler_gamma']))

    scaler = torch.cuda.amp.GradScaler(enabled=bool(hp['use_amp']))

    # --------------------
    # Training loop
    # --------------------
    train_losses, val_losses, val_accs = [], [], []

    for epoch in range(1, int(hp['epochs']) + 1):
        model.train()
        epoch_loss = 0.0
        n_train = 0
        t0 = time.time()

        for xb, yb in train_loader:
            # Normalize potential tuple/list targets coming from dataset/collate
            if isinstance(yb, (list, tuple)):
                yb = yb[0]
            if yb.ndim > 1:
                if yb.size(-1) == num_classes:
                    yb = yb.argmax(dim=-1)
                else:
                    yb = yb.squeeze()
            yb = yb.long()

            xb = xb.to(device, non_blocking=True)
            yb = yb.to(device, non_blocking=True)

            optimizer.zero_grad(set_to_none=True)
            with torch.cuda.amp.autocast(enabled=bool(hp['use_amp'])):
                logits = model(xb)
                loss = criterion(logits, yb)

            scaler.scale(loss).backward()
            if hp['grad_clip_norm'] is not None and float(hp['grad_clip_norm']) > 0:
                scaler.unscale_(optimizer)
                nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(hp['grad_clip_norm']))
            scaler.step(optimizer)
            scaler.update()

            batch_size_now = xb.size(0)
            epoch_loss += loss.detach().item() * batch_size_now
            n_train += batch_size_now

        if scheduler is not None:
            scheduler.step()

        train_loss = epoch_loss / max(1, n_train)

        # Validation
        model.eval()
        val_loss = 0.0
        n_val = 0
        correct = 0
        with torch.no_grad():
            for xb, yb in val_loader:
                if isinstance(yb, (list, tuple)):
                    yb = yb[0]
                if yb.ndim > 1:
                    if yb.size(-1) == num_classes:
                        yb = yb.argmax(dim=-1)
                    else:
                        yb = yb.squeeze()
                yb = yb.long()

                xb = xb.to(device, non_blocking=True)
                yb = yb.to(device, non_blocking=True)
                logits = model(xb)
                loss = criterion(logits, yb)
                val_loss += loss.detach().item() * xb.size(0)
                n_val += xb.size(0)
                pred = logits.argmax(dim=1)
                correct += (pred == yb).sum().item()

        val_loss = val_loss / max(1, n_val)
        val_acc = correct / max(1, n_val)

        train_losses.append(train_loss)
        val_losses.append(val_loss)
        val_accs.append(val_acc)

        print(f'Epoch {epoch:03d}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f} time={time.time()-t0:.1f}s')

    # --------------------
    # Post-Training Quantization (ensure final model <= 256KB)
    # --------------------
    model_cpu = copy.deepcopy(model).to('cpu')
    model_cpu.eval()

    qb = int(hp['quantization_bits'])
    qw = bool(hp['quantize_weights'])
    qa = bool(hp['quantize_activations'])

    if qw and qb == 8:
        if qa:
            torch.backends.quantized.engine = 'fbgemm'
            model_cpu.qconfig = tq.get_default_qconfig('fbgemm')
            tq.prepare(model_cpu, inplace=True)
            model_cpu.eval()
            with torch.inference_mode():
                steps = 0
                for xb, _ in train_loader:
                    xb = xb.to('cpu', non_blocking=False)
                    _ = model_cpu(xb)
                    steps += 1
                    if steps >= int(hp['calibrate_batches']):
                        break
            tq.convert(model_cpu, inplace=True)
        else:
            model_cpu = tq.quantize_dynamic(
                model_cpu,
                {nn.Linear, nn.GRU},
                dtype=torch.qint8,
                inplace=True
            )
    elif qw and qb == 16:
        model_cpu = model_cpu.half()
    else:
        pass

    metrics = {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'val_acc': val_accs
    }

    return model_cpu, metrics


RESPONSE OPTIONS:
1. HYPERPARAMETER FIX: If error can be fixed by changing hyperparameters
   Output: {"bo_config": {"param_name": new_value, "param2": new_value}}

2. CODE FIX: If error requires fixing bugs in the training code
   Output: {"training_code": "complete_corrected_training_function_code"}

3. SYSTEM/ENVIRONMENT ISSUE: If error is due to system/environment issues (GPU memory, CUDA, dependencies, data issues, etc.) that cannot be fixed by code or hyperparameter changes
   Output: {"system_issue": "STOP_PIPELINE"}

4. CANNOT FIX: If error cannot be resolved for any other reason
   Output: {}

RESPONSE FORMAT REQUIREMENTS:
1. Output ONLY a JSON object with either "bo_config", "training_code", "system_issue", or empty object
2. No explanations, no markdown, no ```json``` blocks
3. Start with { and end with }
4. For training_code fixes, include the COMPLETE corrected function
5. For system_issue, use exactly "STOP_PIPELINE" as the value

CORRECTION EXAMPLES:
- "Model has X KB storage, exceeds 256KB limit" → {"bo_config": {"d_model": 64, "hidden_size": 128}}
- "'str' object has no attribute 'type'" → {"training_code": "def train_model(...):\n    # fixed implementation"}
- "Quantization bug in code" → {"training_code": "corrected_training_function"}
- "mat1 and mat2 shapes cannot be multiplied" → {"bo_config": {"d_model": 128}}
- "CUDA out of memory" → {"system_issue": "STOP_PIPELINE"}
- "No such file or directory" → {"system_issue": "STOP_PIPELINE"}
- "ImportError: No module named" → {"system_issue": "STOP_PIPELINE"}

OUTPUT ONLY THE JSON OBJECT: