LITERATURE REVIEW
=================

Query: ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods
Generated: 2025-09-16 01:36:04
Confidence: 0.78

DATA PROFILE:
{
  "data_type": "numpy_array",
  "shape": [
    62352,
    1000,
    2
  ],
  "dtype": "float32",
  "feature_count": 2,
  "sample_count": 62352,
  "is_sequence": true,
  "is_image": false,
  "is_tabular": false,
  "has_labels": true,
  "label_count": 5,
  "sequence_lengths": null,
  "channels": null,
  "height": null,
  "width": null,
  "metadata": {}
}

COMPREHENSIVE REVIEW:
From 2023 to 2025, the strongest trends in ECG arrhythmia classification on MIT-BIH are (i) lightweight and local-attention Transformers tailored to long 1D signals, (ii) temporal-convolutional and hybrid CNN–RNN/attention stacks that fuse local morphology with longer-range rhythm, and (iii) self-supervised and multimodal pretraining to generalize across patients and leads. Examples include multi-scale/shifted-window Transformers for ECG, tiny Transformers that reach ~99% accuracy on 5-class MIT-BIH with only ~6k parameters, and CNN–Transformer hybrids (e.g., CAT-Net) that explicitly address class imbalance with SMOTE-Tomek while capturing both morphology and context. In parallel, advanced TCN variants with multi-branch kernels and attention provide strong efficiency–accuracy tradeoffs on 5-class AAMI tasks. Foundation-model style and multimodal ECG–text/metadata approaches, plus domain-aware SSL (masking, delineation priors), are emerging to improve robustness to noise, missing leads, and cross-dataset transfer. ([arxiv.org](https://arxiv.org/abs/2306.12098?utm_source=openai))

A key lesson from recent literature is that reported 5-class performance depends heavily on evaluation protocol. Papers that avoid patient leakage and use inter-patient splits typically report lower, more realistic metrics (macro-F1 in the low-to-mid 90s), while random beat-level splits can overstate accuracy (often 98–99%). Careful preprocessing (R-peak alignment, fixed windows of ~2–3 s), class-rebalancing (class-weighted or focal losses), and physiology-aware augmentations (bounded jitter, scaling, drift, motion-artifact simulation) consistently improve minority classes. For a two-lead input shaped (1000, 2), performant baselines include: (1) compact CNN/TCN backbones with residual/dilated kernels and squeeze–excitation, (2) local-window Transformers with patching and relative position encodings, and (3) SSL-pretrained encoders fine-tuned with class-balanced or focal losses. These choices align well with PyTorch implementations and moderate GPUs, while remaining deployable on edge hardware when using quantization and tiny-attention designs. ([journals.sagepub.com](https://journals.sagepub.com/doi/full/10.1177/20552076231187608?utm_source=openai))

KEY FINDINGS:
1. Evaluation protocol dominates results: inter-patient splits yield substantially lower but more realistic metrics than random beat splits; plan for macro-F1 in the low–mid 90s with strong models on MIT-BIH 5-class. ([journals.sagepub.com](https://journals.sagepub.com/doi/full/10.1177/20552076231187608?utm_source=openai))
2. Local-attention or windowed Transformers and hybrid CNN–Transformer stacks achieve state-of-the-art on ECG while staying compute-efficient; tiny models can reach ~99% 5-class accuracy on MIT-BIH with quantization. ([arxiv.org](https://arxiv.org/abs/2306.12098?utm_source=openai))
3. Multi-branch dilated TCNs with attention rival Transformers and are simpler to train; focal loss and Bayesian/semi-automatic hyperparameter tuning improve minority-class recognition. ([mdpi.com](https://www.mdpi.com/1424-8220/24/24/8124?utm_source=openai))
4. Self-supervised ECG encoders (masking/reconstruction, delineation-guided, physiology-aware contrastive) improve label efficiency and cross-dataset generalization; multimodal ECG–text pretraining enables zero-shot or robust transfer. ([arxiv.org](https://arxiv.org/abs/2405.19348?utm_source=openai))
5. Address class imbalance with class-weighted cross-entropy or focal loss (γ≈1–2), plus minority-focused augmentation (SMOTE-Tomek or physiology-bounded signal transforms) to stabilize S/V/F/Q classes. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))
6. For two-lead, 1000-sample inputs, best practice is R-peak–centered segmentation or fixed 2–3 s windows, per-lead z-normalization, and bandpass/denoising optional; avoid leakage by splitting at patient/record level. ([journals.sagepub.com](https://journals.sagepub.com/doi/full/10.1177/20552076231187608?utm_source=openai))
7. Edge deployment is feasible via depthwise 1D CNNs or tiny Transformers with INT8 inference and local attention; reported runtime can be a few milliseconds on embedded processors. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))

RECOMMENDED APPROACHES:
1. {'name': 'Local-window Transformer (Tiny/Light) for 1D ECG', 'description': 'Patch the 1000×2 signal into non-overlapping windows (e.g., patch_len 8–16), use 2–6 Transformer encoder blocks with 4–8 heads, d_model 64–256, relative positions, dropout 0.1–0.3; classify with a pooled token. Works well due to efficient local attention capturing morphology and rhythm without O(T^2) global cost. Consider INT8 quantization for deployment. Typical LR 1e-4–3e-4 (AdamW, wd 1e-4). ([arxiv.org](https://arxiv.org/abs/2306.12098?utm_source=openai))'}
2. {'name': 'Multi-branch Dilated TCN with Attention (MB-MHA-TCN)', 'description': 'Three 1D conv branches with different kernel sizes (e.g., 5/9/15) and dilations (1–16), residual stacks to receptive field > 1 s; channel or self-attention to fuse branches; focal loss (γ≈1–2) and class weights for imbalance; LR 1e-3 (Adam), cosine decay. Strong accuracy with low latency and easy PyTorch training. ([mdpi.com](https://www.mdpi.com/1424-8220/24/24/8124?utm_source=openai))'}
3. {'name': 'CNN–Transformer Hybrid (CAT-Net style)', 'description': 'Front-end depthwise-separable CNN (kernels 7–17) + SE blocks for morphology; 1–3 Transformer encoder layers for context; SMOTE-Tomek or similar for class balance; macro-F1 emphasis. Use LR 1e-3→1e-4, dropout 0.2–0.4. Effective because CNN captures sharp QRS/T details while attention models inter-beat dependencies. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))'}
4. {'name': 'SSL-pretrained ECG encoder + supervised fine-tune', 'description': 'Pretrain with masking/reconstruction or delineation/physiology-aware contrastive on large unlabeled ECG; fine-tune on MIT-BIH 5-class with class-weighted CE or focal loss. Typical heads: small MLP; LR 3e-4 (encoder) / 1e-3 (head), warmup+cosine. Improves generalization and minority classes under limited labels. ([arxiv.org](https://arxiv.org/abs/2405.19348?utm_source=openai))'}

RECENT PAPERS:
- A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers (2024): No description
- CAT-Net: Convolution, attention, and transformer based network for single-lead ECG arrhythmia classification (2024): No description
- Accurate Arrhythmia Classification with Multi-Branch, Multi-Head Attention TCN (2024): No description
- NERULA: Dual-Pathway Self-Supervised Learning for ECG (2024): No description
- ECGformer: Leveraging transformer for ECG heartbeat arrhythmia classification (2023): No description
- Local-Global Temporal Fusion with Attention for Arrhythmia Classification (2023): No description
- Self-Supervised Learning with ECG Delineation for Arrhythmia Detection (2021, influential to 2023–2025 SSL): No description
- Transformer-based ECG classification for early detection of arrhythmias (2025): No description
- TolerantECG: A Foundation Model for Imperfect ECG (2025): No description

==================================================
