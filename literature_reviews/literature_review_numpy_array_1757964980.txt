LITERATURE REVIEW
=================

Query: ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods
Generated: 2025-09-15 19:36:20
Confidence: 0.78

DATA PROFILE:
{
  "data_type": "numpy_array",
  "shape": [
    62352,
    1000,
    2
  ],
  "dtype": "float32",
  "feature_count": 2,
  "sample_count": 62352,
  "is_sequence": true,
  "is_image": false,
  "is_tabular": false,
  "has_labels": true,
  "label_count": 5,
  "sequence_lengths": null,
  "channels": null,
  "height": null,
  "width": null,
  "metadata": {}
}

COMPREHENSIVE REVIEW:
Between January 2023 and September 2025, arrhythmia classification on MIT‑BIH has seen strong movement toward lightweight CNN‑Transformer hybrids, self‑supervised ECG pretraining, and robustness methods for inter‑patient generalization. Compact Transformers with multi‑scale 1D CNN front‑ends deliver state‑of‑the‑art accuracy with small footprints: ECGTransForm couples multi‑scale convolutions, a bidirectional Transformer, and a class‑imbalance–aware loss; and a 6k‑parameter “Tiny Transformer” achieves 98.97% 5‑class accuracy on MIT‑BIH with 8‑bit inference and millijoule‑level energy on GAP9, illustrating practicality for wearables. Parallel lines of work convert beats to 2‑D time–frequency images for transfer learning (CWT spectrograms into ImageNet CNNs), build correlation/visibility‑graph representations consumed by GNNs, and integrate adaptive beat segmentation with relative heart‑rate (RR) context to boost challenging S and F classes. Recent surveys also highlight the continued dominance of 1D CNN/ResNet‑like backbones and the emergence of self‑supervised objectives tailored to ECG. ([github.com](https://github.com/emadeldeen24/ECGTransForm?utm_source=openai))

For your setting—two‑lead segments shaped (1000, 2) from the MIT‑BIH Arrhythmia Database (48 half‑hour, 360 Hz two‑channel records)—best practice is to adopt the AAMI EC57 five‑class mapping (N, S, V, F, Q), enforce strict inter‑patient evaluation to avoid record leakage, and incorporate rhythm‑timing features (e.g., RR intervals or adaptive multi‑beat windows). Although many papers report >98–99% accuracy, results vary widely with splits; strong inter‑patient studies typically report ~96–98% overall accuracy on 5‑class MIT‑BIH when temporal context and careful preprocessing are used, while cross‑dataset generalization is harder (macro‑F1 ~87% reported with adversarial training across datasets). Expect higher intra‑patient numbers, but prioritize macro‑F1 and per‑class sensitivity (especially S and F). Use denoising (0.5–40 Hz bandpass, baseline wander removal), per‑record z‑score, and class‑balanced sampling; augment with jitter, scaling, time‑warping, and realistic noise. ([physionet.org](https://physionet.org/physiobank/database/mitdb/?utm_source=openai))

KEY FINDINGS:
1. CNN‑Transformer hybrids are the 2024–2025 sweet spot: multi‑scale 1D CNNs extract morphology while lightweight self‑attention models global timing, yielding high accuracy with small models suitable for edge deployment. ([github.com](https://github.com/emadeldeen24/ECGTransForm?utm_source=openai))
2. Inter‑patient evaluation is essential; many extreme (>99%) claims derive from intra‑patient or non‑standard splits. With careful inter‑patient splits and rhythm context, 5‑class accuracy around 96–98% is realistic on MIT‑BIH. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/39021157/?utm_source=openai))
3. Adding rhythm‑timing cues (RR intervals, adaptive multi‑beat windows) consistently improves SVEB (S) and Fusion (F) detection compared with single‑beat windows alone. ([sciencedirect.com](https://www.sciencedirect.com/science/article/abs/pii/S0010482524011478?utm_source=openai))
4. 2‑D time–frequency pipelines (CWT→pretrained CNNs) remain competitive when GPU memory allows, especially for small labeled sets via transfer learning. ([asp-eurasipjournals.springeropen.com](https://asp-eurasipjournals.springeropen.com/articles/10.1186/s13634-024-01197-1?utm_source=openai))
5. Emerging representations—graph constructions from ECG (visibility/correlation graphs) with GNN classifiers—offer a viable alternative for modeling beat–beat relationships. ([arxiv.org](https://arxiv.org/html/2404.15367v1?utm_source=openai))
6. Self‑supervised ECG pretraining (non‑contrastive/dual‑path) improves downstream arrhythmia classification robustness when labeled data are limited. ([arxiv.org](https://arxiv.org/abs/2405.19348?utm_source=openai))
7. Across‑dataset generalization is markedly tougher than within‑dataset: adversarial/domain‑invariance techniques can help but macro‑F1 often drops into the 80s. Track macro‑F1, per‑class sensitivity, and calibration, not just accuracy. ([mdpi.com](https://www.mdpi.com/2076-3417/14/16/7227?utm_source=openai))

RECOMMENDED APPROACHES:
1. {'name': 'Multi‑scale 1D CNN + Lightweight Transformer (ECGTransForm/Tiny‑Transformer style)', 'why_it_works': 'CNNs capture local morphology; self‑attention aggregates global rhythm across the 1000‑sample window; small models generalize well and deploy easily.', 'typical_settings': 'Input B×C×L = B×2×1000; 3–4 conv blocks with kernels {5,7,9,15}, strides/pooling to 250–500 steps; Transformer d_model 64–128, 2–4 layers, 4–8 heads, dropout 0.1–0.3; AdamW lr 1e‑3→1e‑4 (cosine), weight decay 1e‑4; class‑weighted CE or focal loss (γ=1–2). ([github.com](https://github.com/emadeldeen24/ECGTransForm?utm_source=openai))'}
2. {'name': 'SE‑ResNet1D or InceptionTime (pure 1D‑CNN)', 'why_it_works': 'Deep residual/dilated stacks excel at ECG morphology; fewer moving parts than Transformers and strong baselines for 2‑lead inputs.', 'typical_settings': '8–20 residual blocks; kernel sizes 7–17; dilations up to 8; SE/CBAM; dropout 0.1–0.5; lr 1e‑3 with OneCycle; label smoothing 0.05; add RR interval as auxiliary scalar pathway if available. ([mdpi.com](https://www.mdpi.com/2076-3417/14/16/7227?utm_source=openai))'}
3. {'name': 'Adaptive multi‑beat segmentation + CNN (optionally with attention)', 'why_it_works': 'Adaptive windows centered on R‑peaks plus relative heart‑rate features improve S/F classes which rely on contextual timing.', 'typical_settings': 'Pan‑Tompkins R‑peaks; 2–5 beats per segment (e.g., ~1000 samples at 360\u202fHz); concatenate RR, ΔRR as features; class‑balanced sampler; AdamW lr 1e‑3. ([sciencedirect.com](https://www.sciencedirect.com/science/article/abs/pii/S0010482524011478?utm_source=openai))'}
4. {'name': 'Self‑supervised pretraining → 1D classifier (NERULA‑like)', 'why_it_works': 'Reconstruction + representation learning on unlabeled ECG improves downstream robustness and label‑efficiency.', 'typical_settings': 'Mask 30–60% of samples; non‑contrastive objective + decoder; pretrain 50–200 epochs on unlabeled MIT‑BIH segments; finetune small CNN/Transformer with lr 1e‑4–3e‑4. ([arxiv.org](https://arxiv.org/abs/2405.19348?utm_source=openai))'}
5. {'name': 'CWT spectrograms → pretrained 2‑D CNN', 'why_it_works': 'Leverages ImageNet features; helpful when 1D features underperform for minority classes.', 'typical_settings': 'CWT (Morse/Morlet), 224×224 RGB; pretrained ResNet/EfficientNet; freeze→unfreeze schedule; strong augmentation; lr 1e‑4–3e‑4; heavier memory usage. ([asp-eurasipjournals.springeropen.com](https://asp-eurasipjournals.springeropen.com/articles/10.1186/s13634-024-01197-1?utm_source=openai))'}

RECENT PAPERS:
- ECGTransForm: Empowering adaptive ECG arrhythmia classification framework with bidirectional transformer (BSPC, 2024): Multi‑scale CNN + bidirectional Transformer with context‑aware loss for class imbalance; code released; evaluated on MIT‑BIH/PTB.
- A Tiny Transformer for Low‑Power Arrhythmia Classification on Microcontrollers (2024): 6k‑parameter Transformer achieves 98.97% 5‑class MIT‑BIH accuracy with 8‑bit inference; 0.09 mJ per inference on GAP9.
- ECG classification via integration of adaptive beat segmentation and relative heart rate (Computers in Biology and Medicine, 2024): Combines adaptive segmentation with RR‑based features; reports SOTA PAC/PVC detection across datasets.
- Deep learning‑assisted arrhythmia classification using 2‑D ECG spectrograms (EURASIP JASP, 2024): CWT→RGB images + transfer learning with pretrained CNNs; strong multiclass performance.
- Leveraging Visibility Graphs for Enhanced Arrhythmia Classification with GCNs (arXiv, 2024): Constructs graph representations from ECG and applies GCN; follows AAMI five‑class mapping; discusses split ambiguity.
- Arrhythmia detection in inter‑patient ECG using entropy‑rate features and RR intervals with CNN (2024): Inter‑ and intra‑patient evaluation; ~97.9% 5‑class accuracy for inter‑patient; improved generalization via handcrafted+learned features.
- Enhancing inter‑patient performance with adversarial learning using beat‑score maps (Appl. Sci., 2024): Adversarial learning to remove patient‑specific cues; cross‑dataset inter‑patient macro‑F1 ≈ 87.4%.
- NERULA: Dual‑pathway self‑supervised learning for ECG (arXiv, 2024): Non‑contrastive + reconstruction pretraining improves ECG classification and robustness.
- MIT‑BIH Arrhythmia Database (PhysioNet, v1.0.0): 48 two‑lead, 30‑minute records at 360 Hz; gold‑standard annotations; standard benchmark source.

==================================================
