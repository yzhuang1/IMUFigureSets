{
  "query": "ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem focus: multiclass ECG sequence classification (5 classes) on MIT-BIH Arrhythmia with 1,000×2 input windows (≈2.78 s at 360 Hz) and unknown sample size. MIT-BIH contains 48 half‑hour, two‑channel ambulatory ECG records digitized at 360 Hz, annotated by cardiologists; many works evaluate using AAMI 5-class groupings and either intra‑patient (beat‑wise random) or inter‑patient (DS1/DS2) splits. The latter better reflects generalization. ([physionet.org](https://physionet.org/physiobank/database/mitdb/?utm_source=openai))\nRecent state of the art: (1) Tiny Transformer for Low‑Power Arrhythmia Classification (2024, IEEE TBCAS) introduces a 6k‑parameter ViT‑style 1D transformer that classifies 5 MIT‑BIH arrhythmia classes with 98.97% accuracy under 8‑bit inference; it uses a 198‑sample heartbeat window around R‑peaks plus RR‑interval features, achieves 0.97 MOPs/inference, and runs in 4.28 ms consuming 0.09 mJ on GAP9 MCU. This study evaluates primarily in an intra‑patient setting and details the preprocessing (median filtering + low‑pass, Pan‑Tompkins QRS detection). ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))\n(2) ECGTransForm (BSPC 2024) proposes a bidirectional transformer with multi‑scale convolutions and a class‑imbalance–aware loss, reports experiments on MIT‑BIH and PTB, and publishes a PyTorch codebase (configs, dataloader, models, trainer). While the GitHub readme and paper page outline architecture and training pipeline, headline MIT‑BIH metrics are not explicitly stated on the project page; however, the design directly targets long 1D sequences and imbalance, which match this task. ([github.com](https://github.com/emadeldeen24/ECGTransForm))\n(3) Source‑Free Intersubject Domain Adaptation (SF‑ECG, 2023, Applied Sciences) demonstrates cross‑patient generalization on MIT‑BIH with DS1→DS2 and DS2→DS1 protocols, reaching 98.4% and 96.5% overall accuracy respectively for N/S/V/F classes without accessing source data at adaptation time—evidence that domain adaptation helps inter‑patient robustness. ([mdpi.com](https://www.mdpi.com/2076-3417/13/14/8551?utm_source=openai))\n(4) A Tiny Matched‑Filter CNN (2023, Sensors) targets edge deployment and achieves 98.18% inter‑patient accuracy on MIT‑BIH (N/S/V) with only ~1.3k parameters, and reports cross‑dataset tests; it fuses RR‑interval features with compact 1D CNNs—useful for efficiency baselines. ([mdpi.com](https://www.mdpi.com/1424-8220/23/3/1365?utm_source=openai))\n(5) Surveys/meta-analyses: A 2024 review centered on MIT‑BIH highlights persistent issues—evaluation protocols, class imbalance, and generalization—and catalogs methods spanning CNNs, RNNs, Transformers, and graph‑based approaches. A 2023 systematic review of 368 studies similarly notes CNN dominance, growing hybrid/attention architectures, and the need for clearer evaluation paradigms and code availability. ([mdpi.com](https://www.mdpi.com/2079-3197/12/2/21?utm_source=openai))\nWhat these imply for your setting: Your two‑lead, 1,000‑sample windows can be handled by (a) pure 1D CNNs (ResNet1D/SE‑ResNet1D/Inception‑style) for strong accuracy at modest compute; (b) compact transformers or CNN‑Transformer hybrids to capture longer‑range dependencies within the 2.78‑s window; and (c) optional RR‑interval side‑channels (two scalars) that consistently boost performance. Prior work shows tiny models can reach high accuracy with careful preprocessing and R‑peak–centric windowing, but intra‑patient splits inflate metrics. For clinically meaningful estimates, use inter‑patient DS1/DS2 or leave‑patients‑out splits (and report per‑class F1, not only accuracy). ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))\nComputational considerations: The 2024 Tiny Transformer is a strong template when efficiency matters—6k params, <1 MOP/inference, MCU‑ready—yet assumes short (≈0.5 s) single‑lead segments plus RR features. Adapting its 1D patch embedding to 2 leads and ~1,000 samples is straightforward in PyTorch (increase patch length, flatten across channels or use a small conv stem to fuse leads). Expect token count to scale with window length; choose patch size (e.g., 16–32) and width (d≈64–128) to keep tokens and heads small, preserving sub‑million‑op complexity. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))\nRecommended direction: A compact Conv‑Transformer hybrid that follows ECGTransForm’s idea (multi‑scale conv + bidirectional transformer + imbalance‑aware loss) but capacity‑matched to your 1,000×2 input, trained with AAMI 5‑class mapping and inter‑patient DS1/DS2 split. Augment with RR‑intervals and class‑rebalanced loss; retain Pan‑Tompkins or a modern QRS detector for stable beat localization if you opt for beat‑centered windows within the 1,000‑sample segment. This balances accuracy and efficiency, has open PyTorch references, and aligns with recent evidence on robustness and deployability. ([github.com](https://github.com/emadeldeen24/ECGTransForm))",
  "key_findings": [
    "Tiny 1D Transformer reaches 98.97% 5‑class MIT‑BIH accuracy with only ~6k parameters and 0.97 MOPs/inference; 8‑bit inference runs in 4.28 ms at 0.09 mJ on GAP9, using 198‑sample heartbeat windows plus RR‑intervals. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))",
    "Inter‑patient evaluation matters: a source‑free domain adaptation method attains 98.4% (DS1→DS2) and 96.5% (DS2→DS1) on MIT‑BIH (N/S/V/F), showing cross‑patient robustness gains not visible under intra‑patient splits. ([mdpi.com](https://www.mdpi.com/2076-3417/13/14/8551?utm_source=openai))",
    "Compact CNN baselines can be extremely efficient: a matched‑filter 1D‑CNN with ~1.3k parameters achieved 98.18% inter‑patient accuracy on MIT‑BIH (N/S/V) and demonstrated cross‑dataset generalization. ([mdpi.com](https://www.mdpi.com/1424-8220/23/3/1365?utm_source=openai))",
    "Transformer‑CNN hybrids address long‑range dependencies and class imbalance; ECGTransForm provides a PyTorch reference with bidirectional transformers, multi‑scale convs, and context‑aware loss trained on MIT‑BIH/PTB. ([github.com](https://github.com/emadeldeen24/ECGTransForm))",
    "Dataset characteristics to honor in preprocessing and batching: two channels at 360 Hz, 48×30‑minute records with cardiologist annotations; use AAMI 5‑class mapping and inter‑patient DS1/DS2 patient splits for credible benchmarking. ([physionet.org](https://physionet.org/physiobank/database/mitdb/?utm_source=openai))"
  ],
  "recommended_approaches": [
    "Conv‑Transformer (PyTorch) for 1D ECG: a Tiny‑Transformer backbone adapted from Busia et al. (small ViT encoder with 1D patch embedding) preceded by a shallow 1D conv stem to fuse the 2 leads, plus a side‑channel for pre/post‑RR intervals; train with AAMI 5‑class labels under DS1/DS2 inter‑patient split using class‑balanced focal loss and moderate patch size (e.g., 16–32) to keep tokens and FLOPs low. Justification: matches your 1,000×2 input, has proven high accuracy/efficiency on MIT‑BIH (Tiny‑Transformer) and open PyTorch references for Conv‑Transformer training (ECGTransForm), and incorporates techniques shown to improve inter‑patient generalization (RR intervals, imbalance‑aware loss). ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))"
  ],
  "recent_papers": [
    {
      "title": "A Tiny Transformer for Low‑Power Arrhythmia Classification on Microcontrollers (IEEE TBCAS, 2024)",
      "contribution": "6k‑param 1D ViT variant; 98.97% 5‑class MIT‑BIH accuracy with 8‑bit inference; 0.97 MOPs/inference; 4.28 ms and 0.09 mJ on GAP9; heartbeat‑centric 198‑sample input + RR intervals. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))"
    },
    {
      "title": "ECGTransForm: Empowering adaptive ECG arrhythmia classification with bidirectional transformer (BSPC, 2024)",
      "contribution": "Hybrid multi‑scale conv + bidirectional transformer with context‑aware loss; code released in PyTorch covering MIT‑BIH/PTB pipelines; designed for long 1D sequences and class imbalance. ([github.com](https://github.com/emadeldeen24/ECGTransForm))"
    },
    {
      "title": "Source‑Free Intersubject Domain Adaptation for ECG Arrhythmia Classification (Applied Sciences, 2023)",
      "contribution": "Demonstrates DS1↔DS2 cross‑patient adaptation on MIT‑BIH with 98.4% and 96.5% overall accuracy (N/S/V/F), supporting domain adaptation for generalization. ([mdpi.com](https://www.mdpi.com/2076-3417/13/14/8551?utm_source=openai))"
    },
    {
      "title": "A Tiny Matched Filter‑Based CNN for Inter‑Patient ECG Classification at the Edge (Sensors, 2023)",
      "contribution": "Compact 1D CNN (~1.3k params) with RR‑feature fusion; 98.18% inter‑patient accuracy (N/S/V) and cross‑dataset tests; strong efficiency baseline for edge deployment. ([mdpi.com](https://www.mdpi.com/1424-8220/23/3/1365?utm_source=openai))"
    },
    {
      "title": "Unraveling Arrhythmias with Graph‑Based Analysis: A Survey of the MIT‑BIH Database (Computation, 2024)",
      "contribution": "Up‑to‑date survey focused on MIT‑BIH covering methods, evaluation issues, and trends (CNN/Transformer/graph approaches), useful for protocol and metric choices. ([mdpi.com](https://www.mdpi.com/2079-3197/12/2/21?utm_source=openai))"
    }
  ],
  "confidence": 0.74,
  "timestamp": 1758584596,
  "generated_time": "2025-09-22 18:43:16",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}