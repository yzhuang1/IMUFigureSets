{
  "query": "ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem analysis: You are classifying 2‑lead ECG beat/segment sequences of length 1000 (shape: [T=1000, C=2]) into 5 classes on MIT‑BIH Arrhythmia (commonly mapped to AAMI N/S/V/F/Q). This is a multiclass sequence classification problem with class imbalance and potential inter‑patient distribution shift; recent reviews stress using inter‑patient splits and reporting macro metrics for fairness and clinical relevance. ([arxiv.org](https://arxiv.org/abs/2503.07276?utm_source=openai))\n\nRecent state‑of‑the‑art models on MIT‑BIH: (1) CNN+Attention+Transformer hybrids. CAT‑Net (2024, open‑access BSPC) couples 1D convolutions for local morphology with a Transformer encoder for global context and evaluates class‑imbalance remedies. On MIT‑BIH 5‑class (AAMI), it reports 99.14% overall accuracy and 94.69% macro‑F1, and uses SMOTE‑Tomek to improve minority classes; code is available (PyTorch) for reproducibility. Although designed for single‑lead inputs, its convolutional stem and attention blocks are trivially extended to two leads by treating channels as feature maps or by adding simple channel attention. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))\n\n(2) Tiny/efficient Transformers. A Tiny Transformer (2024) targets low‑power deployment, reaching 98.97% accuracy on MIT‑BIH 5‑class with only ~6k parameters and demonstrates on‑device inference (~4.28 ms, ~0.09 mJ on GAP9), highlighting an attractive accuracy‑efficiency trade‑off. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))\n\n(3) Multi‑lead lightweight CNNs. A 2025 Sensors study proposes a CNN with channel‑attention explicitly supporting 2‑lead and 12‑lead ECGs; on MIT‑BIH it reports 99.18% accuracy and 99.18% F1 (5 classes), directly matching your two‑lead input setting while keeping the architecture simple and efficient. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942969/))\n\n(4) Transformer variants with open PyTorch code. ECGTransForm (BSPC 2024) combines multi‑scale 1D CNNs with a bidirectional Transformer plus a class‑imbalance‑aware loss; official PyTorch implementation is public, easing adoption and ablations on MIT‑BIH/PTB. ([github.com](https://github.com/emadeldeen24/ECGTransForm))\n\n(5) Broader 2025 SOTA benchmarking with compute reporting. rECGnition_v2.0 fuses ECG with patient metadata via a Self‑Attentive Canonical Correlation module in a dual‑path network; on MIT‑BIH it shows Accuracy 98.07% and F1 98.05% (10 classes) with 82.7M FLOPs/sample, providing explicit efficiency comparisons. While multi‑dataset and multi‑class, its FLOP accounting is useful when balancing accuracy vs. cost. ([arxiv.org](https://arxiv.org/abs/2502.16255?utm_source=openai))\n\nSurveys/meta‑analyses: A 2025 systematic review emphasizes fair evaluation (inter‑patient splits, AAMI mapping) and embedded feasibility reporting; a 2024 MIT‑BIH‑focused survey catalogs methodological trends and persistent issues such as class imbalance and minority‑class performance. These reinforce prioritizing macro metrics and computational reporting in your study design. ([arxiv.org](https://arxiv.org/abs/2503.07276?utm_source=openai))\n\nComputational considerations drawn from recent work: • Hybrid CNN+Transformer models like CAT‑Net achieve strong macro‑F1 with modest complexity; minority‑class handling (e.g., SMOTE‑Tomek or tailored loss) materially improves S/V/F/Q performance. • Tiny Transformer demonstrates that careful architectural downsizing can preserve high accuracy with orders‑of‑magnitude lower parameters and energy—useful for deployment. • Multi‑lead channel‑attention CNNs provide a clean inductive bias for two‑lead inputs with top‑tier accuracy and minimal overhead. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))\n\nSynthesis: For your 2‑lead, 1000‑sample, 5‑class MIT‑BIH task in PyTorch, the strongest evidence points to a CNN+Attention backbone augmented either with a lightweight Transformer encoder (CAT‑Net style) or with explicit channel attention for multi‑lead fusion. Among recent peer‑reviewed results, CAT‑Net provides the clearest macro‑F1 improvements on 5‑class MIT‑BIH with publicly available code, while the 2025 multi‑lead CNN with channel attention best matches your exact input modality and achieves state‑of‑the‑art accuracy/F1 with low complexity. To balance accuracy and efficiency and ensure easy PyTorch implementation, we recommend a two‑lead adaptation of CAT‑Net that integrates a simple channel‑attention fusion block before the Transformer encoder (effectively unifying the strengths of items (1) and (3)), trained with inter‑patient splits and a class‑imbalance‑aware objective. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))",
  "key_findings": [
    "Hybrid CNN+Transformer models are currently state‑of‑the‑art on MIT‑BIH 5‑class: CAT‑Net reports 99.14% accuracy and 94.69% macro‑F1 with explicit imbalance handling (SMOTE‑Tomek). ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))",
    "Ultra‑compact Transformers can retain high accuracy with minimal compute: a 6k‑parameter Tiny Transformer achieves 98.97% accuracy and ~0.09 mJ per inference on GAP9, indicating strong deployability. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))",
    "For multi‑lead inputs, a lightweight CNN with channel‑attention attains 99.18% accuracy and 99.18% F1 on MIT‑BIH 5‑class, matching two‑lead scenarios without heavy transformers. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942969/))",
    "Open PyTorch implementations exist for recent Transformer‑based ECG classifiers (e.g., ECGTransForm) combining multi‑scale 1D CNNs, bidirectional self‑attention, and imbalance‑aware loss, easing replication and extension. ([github.com](https://github.com/emadeldeen24/ECGTransForm))",
    "Systematic reviews recommend inter‑patient evaluation and macro metrics and call for reporting efficiency (params/FLOPs/latency) to ensure fair, clinically relevant comparisons. ([arxiv.org](https://arxiv.org/abs/2503.07276?utm_source=openai))"
  ],
  "recommended_approaches": [
    "Two‑Lead CAT‑Net with Channel Attention (PyTorch): start from CAT‑Net’s 1D CNN→Transformer encoder pipeline; accept input [B, C=2, T=1000]; add a lightweight channel‑attention (squeeze‑and‑excitation) fusion after the convolutional stem to combine MLII/V5 features; pass fused features to a small multi‑head self‑attention encoder; train with inter‑patient splits using class‑balanced/focal loss and optionally SMOTE‑Tomek. This matches your data shape, has proven 5‑class MIT‑BIH performance (CAT‑Net baseline), and stays computationally efficient while improving two‑lead integration. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))"
  ],
  "recent_papers": [
    {
      "title": "CAT‑Net: Convolution, attention, and transformer based network for single‑lead ECG arrhythmia classification (BSPC, 2024)",
      "contribution": "CNN+Transformer hybrid with explicit imbalance study; SOTA on MIT‑BIH 5‑class (Acc 99.14%, macro‑F1 94.69%); strong local‑global modeling baseline to extend to two leads. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))"
    },
    {
      "title": "Lightweight Deep Learning Architecture for Multi‑Lead ECG Arrhythmia Detection (Sensors, 2025)",
      "contribution": "CNN with channel‑attention designed for 2‑lead/12‑lead inputs; MIT‑BIH 5‑class Acc 99.18% and F1 99.18%; directly aligns with dual‑lead deployments. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942969/))"
    },
    {
      "title": "A Tiny Transformer for Low‑Power Arrhythmia Classification on Microcontrollers (arXiv, 2024)",
      "contribution": "98.97% MIT‑BIH accuracy with ~6k parameters; on‑device inference (4.28 ms, 0.09 mJ) demonstrating exceptional efficiency for embedded use. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))"
    },
    {
      "title": "ECGTransForm: Empowering adaptive ECG arrhythmia classification framework with bidirectional transformer (BSPC, 2024)",
      "contribution": "Public PyTorch code; multi‑scale CNN front‑end + bidirectional Transformer and context‑aware loss to address class imbalance on MIT‑BIH/PTB. ([github.com](https://github.com/emadeldeen24/ECGTransForm))"
    }
  ],
  "confidence": 0.78,
  "timestamp": 1759459374,
  "generated_time": "2025-10-02 21:42:54",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}