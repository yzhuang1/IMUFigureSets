{
  "query": "ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem framing: The task is multiclass sequence classification of 2‑lead ECG time series windows shaped (1000, 2) from the MIT‑BIH Arrhythmia Database, typically sampled at 360 Hz with two channels and ≈110k annotated beats across 48 half‑hour records. This aligns with beat/segment‑level arrhythmia recognition where inputs are short windows around R‑peaks or fixed‑length segments from MLII and a second lead (e.g., V1/V5). ([physionet.org](https://physionet.org/content/mitdb/1.0.0/))\n\nMethod and scope: We screened 2024–2025 peer‑reviewed and preprint literature emphasizing MIT‑BIH 5‑class AAMI labeling (N,S,V,F,Q), empirical benchmarks, and computational efficiency, plus recent surveys for context. Key recent contenders include lightweight CNNs with channel attention, tiny Transformers for embedded inference, and multi‑modal fusion models; several report >98% accuracy on MIT‑BIH in 5‑class setups. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942969/))\n\nExtracted evidence: (1) Elsheikhy et al. (Sensors, 2025) propose a simple 1D CNN with channel attention that explicitly supports both 2‑lead and 12‑lead inputs; on MIT‑BIH they report 99.18% accuracy and 99.18% F1 for 5‑class classification, indicating strong performance with modest architectural complexity. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942969/)) (2) Busia et al. (2024) present a “Tiny Transformer” with only ~6k parameters, achieving 98.97% 5‑class accuracy on MIT‑BIH; they further demonstrate 8‑bit inference with ~4.28 ms latency and ~0.09 mJ per inference on a GAP9 microcontroller, highlighting excellent efficiency. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40031438/?utm_source=openai)) (3) Srivastava et al. (rECGnition_v2.0, 2025) combine a Dual Pathway Network with Self‑Attentive Canonical Correlation (SACC) fusion; on MIT‑BIH (10‑class), they report 98.07% accuracy and 98.05% F1 at ~82.7M FLOPs/sample, offering strong accuracy with interpretability, though the method assumes access to patient attributes in some settings. ([arxiv.org](https://arxiv.org/abs/2502.16255?utm_source=openai)) (4) Huillcen Baca & Palomino Valdivia (Sensors, 2025) use a 4‑layer 1D CNN on 1000‑sample windows and report 99.57% accuracy on MIT‑BIH, with ~1.2M parameters and 68.48 MFLOPs, reinforcing that compact CNNs can be highly competitive on 5‑class AAMI tasks. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942673/)) (5) The FADLEC framework (2025) shows that classical multi‑resolution wavelet features plus optimized deep models (ACoFCN/ACoBi‑LSTM) can reach ~99.1% accuracy on 5‑class MIT‑BIH, underscoring the utility of hybrid feature+DL pipelines when data are imbalanced. ([link.springer.com](https://link.springer.com/article/10.1007/s44163-025-00290-0?utm_source=openai)) (6) Additional compact approaches (e.g., engineered‑feature compact neural nets) achieve ~97.36% accuracy on MIT‑BIH with lower complexity, relevant when extreme resource constraints dominate. ([arxiv.org](https://arxiv.org/abs/2412.17852?utm_source=openai))\n\nSurveys/meta‑analyses: Recent overviews note MIT‑BIH’s dominance in evaluation and caution that reported scores depend heavily on segmentation, patient‑wise splits, and class imbalance handling—context important when comparing SOTA claims. ([frontiersin.org](https://www.frontiersin.org/articles/10.3389/fphys.2023.1246746/full?utm_source=openai))\n\nSynthesis: For (1000, 2) inputs and 5 classes, a lightweight 1D CNN with channel‑attention (SE‑style) matches the data modality (2 leads), achieves near‑SOTA accuracy on MIT‑BIH with minimal complexity, and is straightforward to implement in PyTorch. Tiny Transformers are attractive for ultra‑low‑power targets but yield slightly lower accuracy in reported results; multi‑modal fusion models are strong but assume additional patient/meta data not guaranteed here. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942969/))",
  "key_findings": [
    "A simple 1D CNN + channel attention model achieved 99.18% accuracy and 99.18% F1 on MIT‑BIH 5‑class classification while supporting 2‑lead inputs, aligning directly with a (1000,2) setup. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942969/))",
    "A 6k‑parameter Tiny Transformer reached 98.97% 5‑class accuracy on MIT‑BIH and demonstrated 8‑bit, ~4.28 ms inference at ~0.09 mJ on GAP9, evidencing excellent compute efficiency for embedded use. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40031438/?utm_source=openai))",
    "A dual‑pathway CNN with Self‑Attentive Canonical Correlation (rECGnition_v2.0) reported 98.07% accuracy and 98.05% F1 on 10‑class MIT‑BIH with ~82.7M FLOPs/sample, showing strong accuracy but with higher complexity and reliance on auxiliary data in some variants. ([arxiv.org](https://arxiv.org/abs/2502.16255?utm_source=openai))"
  ],
  "recommended_approaches": [
    "Adopt a two‑lead 1D CNN with Squeeze‑and‑Excitation (channel‑attention) blocks and shallow residual/dilated layers (as in Elsheikhy et al., Sensors 2025): it matches (1000,2) inputs, attains ~99.2% accuracy/F1 on MIT‑BIH 5‑class, is easy to reproduce in PyTorch, and balances accuracy with compute efficiency; prioritize inter‑patient splits and class‑balanced training. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/40942969/))"
  ],
  "recent_papers": [
    {
      "title": "Lightweight Deep Learning Architecture for Multi‑Lead ECG Arrhythmia Detection (Sensors, 2025)",
      "contribution": "1D CNN + channel attention for 2‑lead/12‑lead; 99.18% accuracy and 99.18% F1 on MIT‑BIH 5‑class; simplicity with high performance."
    },
    {
      "title": "A Tiny Transformer for Low‑Power Arrhythmia Classification on Microcontrollers (2024)",
      "contribution": "~6k params, 98.97% accuracy on MIT‑BIH 5‑class; 8‑bit inference with ~4.28 ms latency and ~0.09 mJ on GAP9, enabling embedded deployment."
    },
    {
      "title": "rECGnition_v2.0: Self‑Attentive Canonical Fusion for ECG (2025)",
      "contribution": "Dual‑pathway CNN with SACC feature fusion; ~98.07% accuracy / 98.05% F1 on MIT‑BIH (10‑class); ~82.7M FLOPs/sample; interpretable fusion."
    },
    {
      "title": "Efficient DL‑Based Arrhythmia Detection Using Smartwatch ECGs (Sensors, 2025)",
      "contribution": "4‑layer 1D CNN on 1000‑sample windows; 99.57% accuracy on MIT‑BIH 5‑class; ~1.2M params and ~68.48 MFLOPs; practical efficiency focus."
    },
    {
      "title": "FADLEC: Feature Extraction + DL for Arrhythmia (2025)",
      "contribution": "Wavelet‑based features + optimized DL (ACoFCN/ACoBi‑LSTM); ~99.1% accuracy on MIT‑BIH 5‑class; highlights hybrid pipelines for imbalanced data."
    },
    {
      "title": "Compact Neural Network Algorithm for ECG Classification (2024)",
      "contribution": "Engineered feature augmentation + compact ANN; ~97.36% accuracy on MIT‑BIH with low complexity, relevant for constrained devices."
    }
  ],
  "confidence": 0.78,
  "timestamp": 1758837139,
  "generated_time": "2025-09-25 16:52:19",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}