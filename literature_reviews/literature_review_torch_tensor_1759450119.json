{
  "query": "ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem framing: You have 1D, two-lead ECG sequences of length 1000 samples (≈2.78 s at 360 Hz) from MIT‑BIH Arrhythmia Database, targeting 5-class AAMI heartbeat grouping (N, S, V, F, Q). MIT‑BIH contains 48 half‑hour, 2‑channel recordings at 360 Hz with cardiologist annotations, the standard benchmark for beat-level arrhythmia classification and inter‑patient evaluation. ([physionet.org](https://physionet.org/content/mitdb/1.0.0/))\nMethodological emphasis in 2024–2025 literature: (a) lightweight transformer or CNN‑transformer hybrids for 1D signals; (b) 2D time‑frequency pipelines with modern vision transformers; (c) cross‑database generalization via beat‑score maps; and (d) stronger evaluation guidance (AAMI groupings, inter‑patient splits, embedded feasibility). ([arxiv.org](https://arxiv.org/abs/2402.10748))\nKey recent models and evidence:\n• CAT‑Net (BSPC, 2024) is a single‑lead 1D CNN + transformer‑encoder hybrid that explicitly balances local (convolutional) and global (multi‑head self‑attention) features and tackles class imbalance with SMOTE‑Tomek. On MIT‑BIH 5‑class AAMI, it reports 99.14% overall accuracy and 94.69% macro‑F1; on INCART (3‑class) it reaches 99.58% accuracy and 96.15% macro‑F1. Open‑access article; authors state SOTA comparisons. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))\n• Tiny Transformer (IEEE TBCAS, 2024) shows that a 6k‑parameter, int8‑quantized 1D transformer can achieve 98.97% accuracy on MIT‑BIH 5‑class; robustness to motion artifacts via augmentation; and 4.28 ms / 0.09 mJ inference on GAP9 MCU, highlighting excellent accuracy–efficiency trade‑offs for sequence inputs similar to yours. ([arxiv.org](https://arxiv.org/abs/2402.10748))\n• Swin Transformer + time‑frequency maps (Frontiers in Cardiovascular Medicine, 2024) converts ECG to Morlet CWT spectrograms and uses hierarchical windowed self‑attention (W‑MSA/SW‑MSA). Reported accuracies on MIT‑BIH are 99.34% (intra‑patient) and 98.37% (inter‑patient), outperforming prior baselines, but the pipeline adds CWT preprocessing and a heavier 2D backbone. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))\n• Cross‑database Beat‑Score‑Map (BSM) representation (Applied Sciences, 2025) pretrains a fine‑grained MIT‑BIH beat classifier, then adapts to coarsely labeled datasets and feeds a 2D BSM into rhythm classifiers, achieving strong F1 on SPH (0.9301) and PTB‑XL (0.9267); useful for transfer but more complex than single‑dataset pipelines. ([mdpi.com](https://www.mdpi.com/2076-3417/15/10/5535))\n• Evaluation guidance: a 2017–2024 systematic review (2025) stresses that many ECG papers inflate results by not using patient‑independent splits or AAMI groupings and rarely report embedded feasibility; it recommends inter‑patient protocols and efficiency reporting for real‑world use. ([arxiv.org](https://arxiv.org/abs/2503.07276?utm_source=openai))\nInterpretation for your setting: With two leads and short sequences (1000×2), 1D models that fuse local morphology and longer‑range context (CNN + transformer) align best with the data shape and avoid the compute overhead of 2D time‑frequency pipelines, while recent evidence shows they can reach state‑of‑the‑art macro‑F1 on MIT‑BIH’s imbalanced AAMI classes. Tiny Transformer proves that very compact transformers can achieve near‑SOTA accuracy with orders‑of‑magnitude lower compute, but CAT‑Net‑style hybrids typically report stronger macro‑F1 across minority classes (S, F, Q), which is critical for 5‑class AAMI. Ensure inter‑patient splits (e.g., DS1/DS2) and report macro‑F1 and per‑class metrics as recommended. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))",
  "key_findings": [
    "CNN + Transformer hybrids tailored for 1D ECG achieve top MIT‑BIH results: CAT‑Net reports 99.14% accuracy and 94.69% macro‑F1 on 5‑class AAMI (single‑lead), balancing local morphology and global context via multi‑head self‑attention and using SMOTE‑Tomek to improve minority classes. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))",
    "Highly efficient transformers are viable for sequence ECG: a 6k‑parameter Tiny Transformer attains 98.97% accuracy on MIT‑BIH 5‑class with 8‑bit inference and 4.28 ms / 0.09 mJ per inference on GAP9, indicating strong accuracy–efficiency trade‑offs for deployment. ([arxiv.org](https://arxiv.org/abs/2402.10748))",
    "2D time‑frequency + Swin Transformer can push accuracy further (99.34% intra, 98.37% inter on MIT‑BIH) but adds CWT preprocessing and a heavier 2D attention backbone; useful when compute allows and interpretability on spectrograms is desired. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))"
  ],
  "recommended_approaches": [
    "Adopt a CAT‑Net–style 1D CNN + Transformer encoder in PyTorch for 1000×2 inputs: (i) 1D convolutional stem (e.g., 3–4 residual Conv1d blocks with kernel sizes 7–15 to capture P–QRS–T morphology per lead), (ii) channel fusion (concat or 1×1 Conv1d to mix two leads), (iii) 1–2 lightweight Transformer encoder blocks (d_model≈128–256, 4–8 heads, GELU, dropout 0.1) for long‑range beat context, (iv) global pooling + linear classifier to 5 AAMI classes. Train with inter‑patient splits, class‑balanced or focal loss, and optional RR‑interval feature injection as an auxiliary channel. This mirrors 2024 SOTA performance on MIT‑BIH while avoiding the heavier 2D CWT pipeline; it is straightforward to implement and optimize in PyTorch and scales to large datasets. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))"
  ],
  "recent_papers": [
    {
      "title": "CAT‑Net: Convolution, attention, and transformer based network for single‑lead ECG arrhythmia classification (BSPC, 2024)",
      "contribution": "1D CNN + Transformer hybrid; SMOTE‑Tomek for imbalance; 99.14% accuracy, 94.69% macro‑F1 on MIT‑BIH AAMI‑5; 99.58% / 96.15% (accuracy/macro‑F1) on INCART (3‑class). ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))"
    },
    {
      "title": "A Tiny Transformer for Low‑Power Arrhythmia Classification on Microcontrollers (IEEE TBCAS, 2024)",
      "contribution": "6k‑parameter 1D transformer; 98.97% accuracy on MIT‑BIH AAMI‑5; robust to motion artifacts; 4.28 ms and 0.09 mJ per inference on GAP9 at 8‑bit precision. ([arxiv.org](https://arxiv.org/abs/2402.10748))"
    },
    {
      "title": "A novel method of Swin Transformer with time‑frequency characteristics for ECG‑based arrhythmia detection (Frontiers in Cardiovascular Medicine, 2024)",
      "contribution": "CWT spectrograms + Swin Transformer; reports 99.34% intra‑patient and 98.37% inter‑patient accuracy on MIT‑BIH; demonstrates benefits of hierarchical self‑attention on 2D representations. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))"
    },
    {
      "title": "Cross‑Database Learning Framework for ECG Arrhythmia Classification Using Beat‑Score‑Map Representation (Applied Sciences, 2025)",
      "contribution": "Pretrain on MIT‑BIH beats, transfer via 2D beat‑score maps; strong F1 on SPH (0.9301) and PTB‑XL (0.9267); pathway for generalization across datasets. ([mdpi.com](https://www.mdpi.com/2076-3417/15/10/5535))"
    },
    {
      "title": "A Systematic Review of ECG Arrhythmia Classification: Adherence to Standards, Fair Evaluation, and Embedded Feasibility (arXiv, 2025)",
      "contribution": "Survey (2017–2024) highlighting the need for AAMI groupings, inter‑patient split protocols, and embedded metrics for fair, deployable ECG models. ([arxiv.org](https://arxiv.org/abs/2503.07276?utm_source=openai))"
    }
  ],
  "confidence": 0.78,
  "timestamp": 1759450119,
  "generated_time": "2025-10-02 19:08:39",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}