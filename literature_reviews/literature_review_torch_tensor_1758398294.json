{
  "query": "ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem analysis: You have 1D sequence inputs shaped (1000, 2) from the MIT-BIH Arrhythmia Database, targeting 5 classes (AAMI EC57 superclasses: N, S, V, F, Q). The dataset contains 48 half-hour, two-lead ambulatory ECG records at 360 Hz; most studies use MLII and map beat annotations to the AAMI 5-class scheme. Inter-patient evaluation (e.g., DS1→DS2 split) is the clinically relevant protocol and is notably harder than intra-patient splits. ([physionet.org](https://physionet.org/physiobank/database/mitdb/?utm_source=openai))\n\nState of the art (2024–2025):\n- Tiny Transformer (ViT-1D) for beat-wise arrhythmia classification achieves 98.97% accuracy on 5 AAMI classes on MIT-BIH, with only ~6k parameters and efficient 8-bit inference (≈0.09 mJ per inference; 4.28 ms on GAP9). The model embeds a short window around the R-peak and concatenates pre-/post-RR intervals; reported results are under an intra-patient paradigm. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))\n- Lightweight 1D CNN (two conv + pooling, fully connected head) reports inter-patient 5-class performance on MIT-BIH: accuracy 0.9842, F1 0.9095, sensitivity 0.876, specificity 0.9869, highlighting that compact CNNs can generalize well in DS1→DS2 settings. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/39998757/))\n- A 2024 graph-focused survey centered on MIT-BIH synthesizes methods and emphasizes that evaluation protocols (intra- vs inter-patient), class imbalance, and preprocessing profoundly affect reported SOTA, which explains wide variability across papers. ([mdpi.com](https://www.mdpi.com/2079-3197/12/2/21))\n- Image-based transfer learning on time–frequency transforms (e.g., CWT spectrograms into SqueezeNet) shows high accuracy on PhysioNet ECG sets (e.g., 98.7% average accuracy in a 2024 study), but adds 2D transform overhead and often uses protocol mixes not directly matching AAMI 5-class inter-patient benchmarking. ([asp-eurasipjournals.springeropen.com](https://asp-eurasipjournals.springeropen.com/articles/10.1186/s13634-024-01197-1))\n- Earlier inter-patient works and reviews compile DS1/DS2 studies, showing typical inter-patient 5-class accuracies in the 90–97% range depending on architecture and handling of class imbalance/RR features; extreme near-perfect inter-patient claims exist but should be scrutinized for protocol details. ([mdpi.com](https://www.mdpi.com/2076-3417/13/8/4964))\n\nMethodological takeaways for your setting: (a) integrate rhythm context via RR intervals in addition to morphology; (b) use inter-patient splits (Chazal DS1→DS2) for validation; (c) address severe class imbalance (S and F are scarce) with weighted/focal loss and/or targeted augmentation; (d) for (1000, 2) inputs, prefer models that accept multi-lead, multi-beat windows or pool beat-level decisions across the window. ([onlinelibrary.wiley.com](https://onlinelibrary.wiley.com/doi/10.1155/2022/9370517?utm_source=openai))",
  "key_findings": [
    "Ultra-compact transformers can match high accuracy while being deployment-friendly: a tiny ViT-1D (~6k params) reached 98.97% 5-class accuracy on MIT-BIH with 8-bit quantization and 0.09 mJ/inference, but under intra-patient evaluation; it fuses RR intervals with beat morphology. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))",
    "Compact 1D CNNs can generalize in inter-patient DS1→DS2 tests: a 2025 lightweight CNN reported accuracy 0.9842, F1 0.9095, sensitivity 0.876, specificity 0.9869 on AAMI 5-class MIT-BIH, demonstrating a strong accuracy–efficiency trade-off without heavy attention blocks. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/39998757/))",
    "Evaluation protocol drives reported SOTA: surveys aggregating MIT-BIH studies show inter-patient 5-class performance typically in the 90–97% range and caution against directly comparing intra-patient numbers to inter-patient results; class imbalance and preprocessing substantially sway metrics. ([mdpi.com](https://www.mdpi.com/2076-3417/13/8/4964))"
  ],
  "recommended_approaches": [
    "Tiny ViT-1D with RR-interval fusion, adapted for (1000, 2) inputs: Use a 1D patch-embedding transformer (few encoder blocks; small embedding and 2–4 heads) that (i) ingests 2-lead windows of length 1000 via strided 1D conv patching (e.g., patch size 16–32, stride 8–16), (ii) concatenates normalized pre-/post-RR intervals before the classifier, and (iii) trains with inter-patient DS1→DS2 splits, class-balanced focal or weighted cross-entropy, and moderate augmentations (noise, baseline wander). This choice is justified by its proven accuracy/efficiency on MIT-BIH, hardware-friendly footprint, and straightforward PyTorch implementability; adapting from beat-centric to 1000-sample windows is natural via patching and temporal pooling, while RR features retain rhythm context. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))"
  ],
  "recent_papers": [
    {
      "title": "A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers (IEEE TBCAS, 2024)",
      "contribution": "Introduces a ~6k-parameter ViT-1D that classifies AAMI 5 classes from MIT-BIH using short beat windows plus RR intervals; achieves 98.97% accuracy (intra-patient), 8-bit inference at 0.09 mJ and 4.28 ms on GAP9, showing strong accuracy–efficiency for embedded use. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))"
    },
    {
      "title": "A lightweight 1D convolutional neural network model for arrhythmia diagnosis from electrocardiogram signal (Phys Eng Sci Med, 2025)",
      "contribution": "Compact 1D CNN validated under inter-patient DS1→DS2: accuracy 0.9842, F1 0.9095, sensitivity 0.876, specificity 0.9869 on AAMI 5 classes of MIT-BIH, indicating practical generalization with low model complexity. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/39998757/))"
    },
    {
      "title": "Unraveling Arrhythmias with Graph-Based Analysis: A Survey of the MIT-BIH Database (Computation, 2024)",
      "contribution": "Survey focused on MIT-BIH highlighting evaluation protocol impacts, class imbalance, and methodological diversity; cautions on comparing results across differing splits and preprocessing. ([mdpi.com](https://www.mdpi.com/2079-3197/12/2/21))"
    },
    {
      "title": "Deep learning-assisted arrhythmia classification using 2-D ECG spectrograms (EURASIP J. Adv. Signal Process., 2024)",
      "contribution": "Transforms ECG to CWT images for transfer learning; reports up to 98.7% accuracy with SqueezeNet across PhysioNet sets, illustrating competitive performance of image-based pipelines albeit with added transform overhead. ([asp-eurasipjournals.springeropen.com](https://asp-eurasipjournals.springeropen.com/articles/10.1186/s13634-024-01197-1))"
    },
    {
      "title": "Deep Learning-Based ECG Arrhythmia Classification: A Systematic Review (Applied Sciences, 2023)",
      "contribution": "Compiles inter-patient DS1→DS2 studies for AAMI 5-class MIT-BIH, showing typical accuracies in the 90–97% band and underscoring the difficulty of SVEB/F classes, guiding realistic SOTA baselines. ([mdpi.com](https://www.mdpi.com/2076-3417/13/8/4964))"
    }
  ],
  "confidence": 0.76,
  "timestamp": 1758398294,
  "generated_time": "2025-09-20 14:58:14",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}