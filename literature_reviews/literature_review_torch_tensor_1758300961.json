{
  "query": "ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem framing. You are doing supervised, multiclass sequence classification on the MIT‑BIH Arrhythmia Database (two leads, typically 360 Hz) with five AAMI superclasses (N, S, V, F, Q). For fair evaluation on MIT‑BIH, the literature strongly recommends the inter‑patient DS1→DS2 split proposed by De Chazal et al. to avoid patient overlap; many very high accuracies reported in older work used intra‑patient splits and are overestimates. MIT‑BIH provides 48 half‑hour, two‑channel recordings; beats are annotated and sampling is 360 Hz. ([physionet.org](https://physionet.org/content/mitdb/1.0.0/?utm_source=openai))\n\nWhat recent state‑of‑the‑art shows. Hybrid CNN‑Transformer models remain the top performers on 5‑class MIT‑BIH. CAT‑Net (CNN + channel attention + Transformer encoder) reported 99.14% overall accuracy and 94.69% macro‑F1 on 5‑class MIT‑BIH (single‑lead heartbeat segments) and validated on INCART; class imbalance was addressed with SMOTE‑Tomek. Note that the paper does not clearly state a DS1/DS2 inter‑patient split, so results may be optimistic under inter‑patient evaluation. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))\n\nTransformer variants with efficiency. A Tiny Transformer designed for wearables reaches 98.97% accuracy on 5‑class MIT‑BIH with only ~6k parameters; 8‑bit inference on GAP9 runs in 4.28 ms at ~0.09 mJ, making it attractive when compute/power are tight. Again, verify the split before comparing to inter‑patient results. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))\n\nPyTorch‑ready ECG Transformer frameworks. ECGTransForm (Bi‑Transformer + multi‑scale 1D convolutions with a context‑aware loss to mitigate class imbalance) is available in PyTorch and targets MIT‑BIH; the architecture is well‑matched to fixed‑length segments and can be adapted to two‑lead inputs by setting in_channels=2. The paper and code report superior performance to CNN baselines, with explicit imbalance handling and public configs. ([github.com](https://github.com/emadeldeen24/ECGTransForm))\n\nInter‑patient generalization techniques. Recent work improves cross‑patient robustness by extracting patient‑invariant beat‑score maps and using adversarial learning during pretraining; on MIT‑BIH in inter‑patient cross‑validation this raised F1 by 14.27% (with the strongest gain on AF rhythms), illustrating that representation learning and debiasing are as important as backbone choice. ([mdpi.com](https://www.mdpi.com/2076-3417/14/16/7227?utm_source=openai))\n\nLightweight and interpretable alternatives. A 2025 arXiv study adapted a hierarchical attention network to MIT‑BIH and reported 98.55% accuracy with ~15.6× fewer parameters versus CAT‑Net, suggesting that simpler attention architectures can approach SOTA accuracy at much lower model size, though evaluation protocol details should be checked. ([arxiv.org](https://arxiv.org/abs/2504.03703))\n\nSurveys and guidance. A 2025 survey on Transformers and LLMs for ECG concludes that CNN front‑ends plus self‑attention are a strong default, emphasizes class imbalance remedies, and warns that many ECG papers still violate inter‑patient evaluation norms—so adhere to AAMI class mapping and DS1→DS2 when benchmarking. ([link.springer.com](https://link.springer.com/article/10.1007/s10462-025-11259-x?utm_source=openai))\n\nComputational notes for your setup. With 1000×2 windows, models that combine shallow multi‑scale 1D CNN blocks (to capture local QRS/T/P morphology) with a small Transformer encoder (2–4 heads, modest depth) balance accuracy and efficiency; this is exactly the ECGTransForm/CAT‑Net design pattern. On GPUs, such models typically train comfortably on a single 8–12 GB card; for edge inference, the Tiny Transformer shows that sub‑10k‑parameter designs are feasible with quantization. ([github.com](https://github.com/emadeldeen24/ECGTransForm))",
  "key_findings": [
    "Hybrid CNN + Transformer backbones are the most competitive for 5‑class MIT‑BIH: CAT‑Net reported 99.14% accuracy and 94.69% macro‑F1 on the 5‑class task (single‑lead beats) and used SMOTE‑Tomek to lift minority‑class performance, though the split appears not inter‑patient. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))",
    "For compute‑constrained use, a Tiny Transformer achieved 98.97% accuracy on 5‑class MIT‑BIH with ~6k parameters and 8‑bit inference at 4.28 ms and ~0.09 mJ on a GAP9 MCU, demonstrating state‑of‑the‑art efficiency. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))",
    "Inter‑patient evaluation is crucial: using patient‑invariant beat‑score maps with adversarial pretraining improved inter‑patient F1 by 14.27% on MIT‑BIH, highlighting that debiasing/representation learning materially improves cross‑patient generalization. ([mdpi.com](https://www.mdpi.com/2076-3417/14/16/7227?utm_source=openai))"
  ],
  "recommended_approaches": [
    "Use a CNN+Bidirectional‑Transformer hybrid in PyTorch (ECGTransForm‑style): multi‑scale 1D CNN front‑end (in_channels=2 for your 1000×2 segments) to extract morphology, followed by a small Bi‑Transformer encoder (2–4 heads, 2–4 layers) and a class‑imbalance‑aware loss (e.g., the published Context‑Aware Loss or class‑balanced focal). Train with the AAMI 5‑class mapping and the DS1→DS2 inter‑patient split; apply modest augmentation (baseline wander, noise, random time‑warp). This choice balances accuracy (comparable to SOTA hybrids), robustness (explicit imbalance handling), and practicality (public PyTorch code and configs). ([github.com](https://github.com/emadeldeen24/ECGTransForm))"
  ],
  "recent_papers": [
    {
      "title": "CAT‑Net: Convolution, attention, and transformer based network for single‑lead ECG arrhythmia classification (Biomed. Signal Process. Control, 2024)",
      "contribution": "Hybrid CNN+Transformer with SMOTE‑Tomek; reported 99.14% accuracy and 94.69% macro‑F1 on 5‑class MIT‑BIH and strong results on INCART; good baseline for heartbeat‑level classification. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))"
    },
    {
      "title": "A Tiny Transformer for Low‑Power Arrhythmia Classification on Microcontrollers (arXiv, 2024)",
      "contribution": "Extremely compact Transformer (~6k params) reaching 98.97% accuracy on 5‑class MIT‑BIH; 8‑bit MCU inference in 4.28 ms at ~0.09 mJ, illustrating efficient on‑device ECG classification. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))"
    },
    {
      "title": "ECGTransForm: Empowering adaptive ECG arrhythmia classification framework with bidirectional transformer (BSPC, 2024) + PyTorch code",
      "contribution": "Bi‑Transformer plus multi‑scale 1D CNNs with a context‑aware loss to handle class imbalance; public PyTorch implementation suitable for adapting to two‑lead 1000‑sample windows. ([github.com](https://github.com/emadeldeen24/ECGTransForm))"
    },
    {
      "title": "Enhancing inter‑patient performance with adversarial learning using patient‑invariant Beat‑Score Maps (Applied Sciences, 2024)",
      "contribution": "Adversarial pretraining to reduce patient‑specific bias; +14.27% F1 on MIT‑BIH inter‑patient validation, strongest lift on challenging AF rhythms. Useful add‑on to CNN/Transformer backbones. ([mdpi.com](https://www.mdpi.com/2076-3417/14/16/7227?utm_source=openai))"
    }
  ],
  "confidence": 0.78,
  "timestamp": 1758300961,
  "generated_time": "2025-09-19 11:56:01",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}