LITERATURE REVIEW
=================

Query: ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods
Generated: 2025-09-16 01:55:52
Confidence: 0.78

DATA PROFILE:
{
  "data_type": "numpy_array",
  "shape": [
    62352,
    1000,
    2
  ],
  "dtype": "float32",
  "feature_count": 2,
  "sample_count": 62352,
  "is_sequence": true,
  "is_image": false,
  "is_tabular": false,
  "has_labels": true,
  "label_count": 5,
  "sequence_lengths": null,
  "channels": null,
  "height": null,
  "width": null,
  "metadata": {}
}

COMPREHENSIVE REVIEW:
Between 2023 and 2025, ECG arrhythmia classification on MIT-BIH has seen three converging trends: lightweight Transformers for on-device inference, attention-augmented temporal CNNs, and representation learning (SSL/foundation models) to improve generalization under class imbalance and cross-patient shifts. Compact Transformers now reach near–state-of-the-art five-class performance with only thousands of parameters and millijoule-level inference costs, while CNN–Transformer hybrids and attention-augmented TCNs improve minority-class F1 by combining multi-scale convolutions with self-attention. Parallel lines of work fuse 1D time-series with image-like transforms (e.g., spectrograms or Gramian Angular Fields), and explore interpretable hierarchies (HAN) to highlight clinically relevant waveform regions. Across studies, careful evaluation matters: inter-patient (AAMI EC57) protocols typically yield lower but more realistic results than intra-patient splits, and mapping MIT-BIH beats to the AAMI 5 groups remains the common benchmark. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))

For a two-lead numpy_array shaped (1000, 2), strong baselines include: (1) 1D multi-branch CNN/TCN with dilation and SE/attention; (2) compact Transformer encoders (or CNN→Transformer) with patching over ~8–32 samples; and (3) SSL-pretrained encoders fine-tuned on MIT-BIH. Practical performance depends heavily on segmentation around R-peaks, inter-patient splitting (e.g., DS1/DS2), and imbalance handling (weighted or focal losses, or targeted augmentation). Expect macro-F1 in the high-80s to low-90s under strict inter-patient AAMI evaluation; higher headline accuracies (≈98–99%) are common under intra-patient or beat-level splits. Use wfdb to load MIT-BIH (48 records, 360 Hz, 2 channels), and design PyTorch dataloaders that emit [B, C=2, T=1000] tensors with label mapping to N/S/V/F/Q as per AAMI. ([mdpi.com](https://www.mdpi.com/1424-8220/24/24/8124?utm_source=openai))

KEY FINDINGS:
1. Evaluation protocol dominates reported performance: inter-patient AAMI EC57 splits (e.g., DS1/DS2) are substantially harder but clinically realistic; intra-patient results can overestimate generalization. Use patient-exclusive splits. ([arxiv.org](https://arxiv.org/html/2404.15367v2?utm_source=openai))
2. Lightweight Transformers are now competitive for five-class MIT-BIH while being deployable on wearables (≈6k params; ~0.09 mJ inference on GAP9). For server training, pair with AdamW and cosine decay. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))
3. Attention-augmented TCNs and multi-branch 1D CNNs with dilation capture local morphology and long-range context, improving minority-class recognition; focal loss or class-balanced re-weighting helps. ([mdpi.com](https://www.mdpi.com/1424-8220/24/24/8124?utm_source=openai))
4. Self-supervised pretraining (e.g., SwAV/BYOL-style or ECG-specific SSL) improves downstream arrhythmia detection and cross-dataset robustness; foundation models trained on millions of ECGs transfer well. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/37948139/?utm_source=openai))
5. Time–frequency or image-fusion approaches (e.g., Gramian Angular Fields + 1D stream) can boost accuracy but increase preprocessing cost; consider only if compute allows. ([arxiv.org](https://arxiv.org/abs/2501.01960?utm_source=openai))
6. For MIT-BIH five-class AAMI mapping, realistic inter-patient results often land around 90–96% accuracy or macro-F1 in the high-80s to low-90s; be cautious with papers reporting ≈99% without patient-exclusive splits. ([aimspress.com](https://www.aimspress.com/article/doi/10.3934/mbe.2024243?utm_source=openai))
7. Data specifics: MIT-BIH provides 48 half-hour, two-channel recordings at 360 Hz with cardiologist beat annotations; map to N/S/V/F/Q per AAMI before modeling. ([physionet.org](https://www.physionet.org/physiobank/database/mitdb/?utm_source=openai))

RECOMMENDED APPROACHES:
1. {'name': 'Multi-branch 1D CNN/TCN with dilation + attention', 'description': 'Three to four convolutional branches with varied kernels (e.g., 5/9/15) and dilations feed a TCN stack; add multi-head attention or SE blocks before a class head. Works well for (1000,2) windows; use focal loss (γ≈2) to address class imbalance.'}
2. {'name': 'Compact Transformer or CNN→Transformer encoder', 'description': 'Patch the 1D sequence into tokens (length 8–32), embed (d_model 128–256), 2–4 encoder blocks, 4–8 heads, dropout 0.1–0.3. Optionally precede with a small 1D CNN stem. Provides strong accuracy–efficiency trade-off and supports on-device inference. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))'}
3. {'name': 'SSL-pretrained encoder + linear/readout fine-tune', 'description': 'Pretrain on large ECG corpora (contrastive or masked modeling) or adopt a public ECG foundation model, then fine-tune on MIT-BIH with class-balanced sampling. Improves robustness and reduces labeled-data needs. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/37948139/?utm_source=openai))'}
4. {'name': 'Dual-stream fusion (1D time series + image transform)', 'description': 'Parallel 1D CNN/TCN stream and 2D CNN stream over spectrograms or GAF; late fusion with split attention. Gains on some setups, at the cost of more preprocessing and memory. ([arxiv.org](https://arxiv.org/abs/2501.01960?utm_source=openai))'}
5. {'name': 'Interpretable hierarchical attention network (HAN) baseline', 'description': 'Segment the 1000-sample window into subsegments; apply hierarchical attention to surface salient waveform regions for clinical review; competitive accuracy with far fewer parameters. ([arxiv.org](https://arxiv.org/abs/2504.03703?utm_source=openai))'}

RECENT PAPERS:
- A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers (2024): 6k-parameter Transformer achieves 98.97% five-class accuracy on MIT-BIH with efficient 8-bit inference; demonstrates real-time wearable deployment. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))
- ECGTransForm: Bidirectional Transformer with Multi-scale Convolutions (Biomed. Signal Process. Control, 2024): Hybrid CNN+Transformer with context-aware loss to mitigate imbalance; open-source implementation and strong MIT-BIH/PTB results. ([github.com](https://github.com/emadeldeen24/ECGTransForm?utm_source=openai))
- Accurate Arrhythmia Classification with Multi-Branch, Multi-Head Attention TCN (Sensors, 2024): Multi-branch dilated CNN + MHA-TCN achieves ≈98.75% accuracy on MIT-BIH (5-class), highlighting attention with dilation for temporal context. ([mdpi.com](https://www.mdpi.com/1424-8220/24/24/8124?utm_source=openai))
- GAF-FusionNet: Multimodal ECG via Gramian Angular Fields and Split Attention (arXiv, 2024): Fuses 1D temporal and 2D GAF representations, reporting up to 99.6% accuracy on MIT-BIH; demonstrates benefits of cross-modal fusion. ([arxiv.org](https://arxiv.org/abs/2501.01960?utm_source=openai))
- Hierarchical Attention Network for Interpretable ECG Classification (arXiv, 2025): Adapted HAN yields 98.55% test accuracy on MIT-BIH with 15.6× fewer parameters than a CNN–Attention–Transformer baseline; improved interpretability. ([arxiv.org](https://arxiv.org/abs/2504.03703?utm_source=openai))
- In-/Out-of-Distribution Self-Supervised ECG Representation Learning (JBHI, 2024): Compares SSL methods (SwAV/BYOL/SimCLR); shows SSL can match supervised SOTA and generalize OOD across ECG datasets. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/37948139/?utm_source=openai))
- TolerantECG: A Foundation Model for Imperfect Electrocardiogram (arXiv, 2025): Contrastive and SSL pretraining robust to noise and missing leads; top results on PTB-XL and strong transfer to MIT-BIH. ([arxiv.org](https://arxiv.org/abs/2507.09887?utm_source=openai))
- Local–Global Temporal Fusion with Attention for Multiclass Arrhythmia (arXiv, 2023): Captures local and global patterns to detect arrhythmia episodes with a constrained input length; competitive results on MITDB/AFDB. ([arxiv.org](https://arxiv.org/abs/2308.02416?utm_source=openai))
- Arrhythmia Classification with Multi-path CNN and Improved Focal Loss (MBE, 2024): Reports strong intra-patient and more modest inter-patient accuracy (≈91%), underscoring the gap between protocols. ([aimspress.com](https://www.aimspress.com/article/doi/10.3934/mbe.2024243?utm_source=openai))
- ECG DETR: Transformer-Based Detection on Continuous ECG (2022): End-to-end detection of beat positions and categories without explicit segmentation; a precursor to newer Transformer ECG models. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/35227968/?utm_source=openai))

==================================================
