{
  "query": "EEG classification brain signal analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem framing: You have 30 s EEG epochs shaped (channels=6, samples=6000), sampled at 200 Hz, with 5 classes (W, N1, N2, N3, REM) on ISRUC-Sleep. These settings match common ISRUC preprocessing (30 s epochs; many papers downsample to 100 Hz), so methods validated on ISRUC-S1/S3 are directly applicable with minor channel-count adaptation. ([ar5iv.org](https://ar5iv.org/pdf/2405.20142))\n\nEvidence base (2023–2025): On ISRUC, strong baselines include graph/CNN hybrids and more recent state-space/Transformer families. MixSleepNet (3D CNN + GCN over multi-channel PSG) reported on ISRUC-S3: Acc 0.830, F1 0.821, κ 0.782; ISRUC-S1: Acc 0.812, F1 0.786, κ 0.756. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/38218118/?utm_source=openai)) JK-STGCN (spatio-temporal GCN) reached Acc 0.831, F1 0.814, κ 0.782 on ISRUC-S3. ([research.usq.edu.au](https://research.usq.edu.au/item/q796v/jumping-knowledge-based-spatial-temporal-graph-convolutional-networks-for-automatic-sleep-stage-classification?utm_source=openai)) 3DSleepNet achieved ISRUC-S3 Acc 0.832, F1 0.814, κ 0.783 and ISRUC-S1 Acc 0.820, F1 0.797, κ 0.768, with a reported 4493 s training time on ISRUC-S3’s 10 subjects. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/37639413/?utm_source=openai)) A 2024 “hybrid intelligence” approach (temporal FCN/U-Net + knowledge-based transition smoothing) reported Macro-F1 0.804 on ISRUC and 0.780 on Sleep-EDF. ([dl.acm.org](https://dl.acm.org/doi/10.1016/j.compbiomed.2024.108314?utm_source=openai))\n\nMost notably, 2024 Mamba-based state space models show SOTA-level accuracy with far lower parameter counts. MSSC-BiMamba (CNN feature extractor + Efficient Channel Attention (ECA) + bidirectional Mamba) reports on ISRUC-S3 Acc 0.852, Macro-F1 0.824, κ 0.803 using 10 PSG channels; and on ISRUC-S1 Acc 0.830, Macro-F1 0.801, κ 0.773, all with just ~0.47M parameters for the best variant (CNN+ECA+1 BiMamba), trained in PyTorch 2.1.1 on an RTX 4090. Comparative tables in the paper list MixSleepNet and JK-STGCN at ~0.81–0.83 Acc on the same splits, highlighting the BiMamba model’s accuracy/efficiency balance. ([ar5iv.org](https://ar5iv.org/pdf/2405.20142)) Related EEG-only Mamba variants (e.g., BiT-MamSleep) focus on bidirectional temporal dependencies and class imbalance, further supporting Mamba as a compute-efficient backbone for long EEG sequences. ([arxiv.org](https://arxiv.org/abs/2411.01589?utm_source=openai))\n\nSurveys and context: A 2024 BMC review synthesizes ISRUC-SG1 size (≈16,266 epochs at 30 s) and compares classical ML vs deep nets, noting persistent N1/REM confusion and benefits of multimodal fusion; these insights help set expectations for EEG-only vs multimodal performance. ([bmcmedinformdecismak.biomedcentral.com](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-024-02522-2?utm_source=openai)) Recent graph/transformer hybrids (e.g., ST-USleepNet; Transformer + diffusion augmentation; Conv-Transformer) emphasize spatial-temporal coupling and data augmentation, with open-source PyTorch code for some models, but ISRUC-specific, peer-reviewed metrics are most clearly detailed in MixSleepNet/JK-STGCN/3DSleepNet and MSSC-BiMamba. ([arxiv.org](https://arxiv.org/abs/2408.11884?utm_source=openai))\n\nComputational considerations: MSSC-BiMamba’s top ISRUC setting uses ~0.47–0.99M parameters (depending on depth), demonstrating competitive or better accuracy than heavier models like MixSleepNet (≈2.4M params), and it reports a standard PyTorch stack and commodity GPU. For deployment on 6 EEG channels, ECA naturally re-weights channels and can operate without EOG/EMG/ECG; expect a small drop from multimodal numbers but retained efficiency. Hybrid post-processing (graph-based smoothing/transition correction) can further regularize hypnograms if needed. ([ar5iv.org](https://ar5iv.org/pdf/2405.20142))\n\nConclusion: For your 6×6000 EEG-only ISRUC pipeline, the most prudent, high-performing and efficient choice is a CNN + Efficient Channel Attention + Bidirectional Mamba (BiMamba) architecture implemented in PyTorch, optionally followed by a lightweight transition-smoothing step. It aligns with ISRUC sampling, delivers SOTA-level results on ISRUC with minimal parameters, and is straightforward to adapt to 6 EEG channels while preserving excellent accuracy/compute trade-offs. ([ar5iv.org](https://ar5iv.org/pdf/2405.20142))",
  "key_findings": [
    "Mamba-based sequence models achieve SOTA-level ISRUC performance with tiny parameter counts: MSSC-BiMamba (CNN+ECA+BiMamba) reports ISRUC-S3 Acc 0.852, Macro-F1 0.824, κ 0.803 at ~0.47M params; ISRUC-S1 Acc 0.830, Macro-F1 0.801, κ 0.773 (PyTorch 2.1.1 on RTX 4090). ([ar5iv.org](https://ar5iv.org/pdf/2405.20142))",
    "Prior ISRUC SOTA baselines cluster around 0.81–0.83 accuracy: MixSleepNet (S3 Acc 0.830, F1 0.821; S1 Acc 0.812, F1 0.786) and JK-STGCN (S3 Acc 0.831, F1 0.814). These serve as strong comparators for new models. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/38218118/?utm_source=openai))",
    "3DSleepNet demonstrates similar accuracy with reported training-time efficiency (ISRUC-S3 Acc 0.832, F1 0.814; ISRUC-S1 Acc 0.820, F1 0.797; 4493 s to train on 10 S3 subjects), highlighting compute–performance tradeoffs. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/37639413/?utm_source=openai))",
    "Knowledge-guided post-processing improves hypnogram plausibility; a 2024 hybrid FCN/U-Net + transition-correction method achieved Macro-F1 0.804 on ISRUC, illustrating the benefit of smoothing stage transitions. ([dl.acm.org](https://dl.acm.org/doi/10.1016/j.compbiomed.2024.108314?utm_source=openai))",
    "Reviews/meta-analyses (2024) confirm ISRUC 30 s epochs and note persistent N1/REM confusion and gains from multimodal input; for EEG-only setups, channel-attention backbones (e.g., ECA) mitigate performance gaps. ([bmcmedinformdecismak.biomedcentral.com](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-024-02522-2?utm_source=openai))"
  ],
  "recommended_approaches": [
    "CNN + Efficient Channel Attention + Bidirectional Mamba (BiMamba) in PyTorch: 1D CNN over each 30 s epoch (6×6000) for local time–frequency features; ECA to adaptively weight 6 EEG channels; a shallow BiMamba block to model long-range dependencies within and across epochs; linear head for 5-way classification; optional transition-smoothing post-process. Justification: SOTA-level ISRUC accuracy with ~0.5–1.0M params, strong empirical results vs ISRUC baselines (MixSleepNet/JK-STGCN), and straightforward adaptation to EEG-only multi-channel input. ([ar5iv.org](https://ar5iv.org/pdf/2405.20142))"
  ],
  "recent_papers": [
    {
      "title": "MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba (2024)",
      "contribution": "CNN+ECA+BiMamba achieves ISRUC-S3 Acc 0.852/Macro-F1 0.824/κ 0.803 with ~0.47M params; ISRUC-S1 Acc 0.830/Macro-F1 0.801/κ 0.773; PyTorch implementation details provided. ([ar5iv.org](https://ar5iv.org/pdf/2405.20142))"
    },
    {
      "title": "MixSleepNet: A Multi-Type Convolution Combined Sleep Stage Classification Model (2023)",
      "contribution": "3D CNN + GCN hybrid; ISRUC-S3 Acc 0.830/F1 0.821/κ 0.782; ISRUC-S1 Acc 0.812/F1 0.786/κ 0.756; competitive baseline for ISRUC comparisons. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/38218118/?utm_source=openai))"
    },
    {
      "title": "Jumping Knowledge Based Spatial-Temporal Graph Convolutional Networks (JK-STGCN) for Sleep Staging (2022)",
      "contribution": "Spatial-temporal GCN with jumping knowledge; ISRUC-S3 Acc 0.831/F1 0.814/κ 0.782; strong multi-channel PSG baseline. ([research.usq.edu.au](https://research.usq.edu.au/item/q796v/jumping-knowledge-based-spatial-temporal-graph-convolutional-networks-for-automatic-sleep-stage-classification?utm_source=openai))"
    },
    {
      "title": "3DSleepNet (2023)",
      "contribution": "Multi-channel 3D CNN; ISRUC-S3 Acc 0.832/F1 0.814/κ 0.783 and ISRUC-S1 Acc 0.820/F1 0.797/κ 0.768; reports faster training (4493 s on 10 S3 subjects). ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/37639413/?utm_source=openai))"
    },
    {
      "title": "Reliable automatic sleep stage classification based on hybrid intelligence (Computers in Biology and Medicine, 2024)",
      "contribution": "Temporal FCN/U-Net with knowledge-based transition correction; Macro-F1 0.804 on ISRUC; highlights value of post-hoc smoothing. ([dl.acm.org](https://dl.acm.org/doi/10.1016/j.compbiomed.2024.108314?utm_source=openai))"
    },
    {
      "title": "ST-USleepNet (2024)",
      "contribution": "Spatial-temporal graph construction + U-shaped network; code available; demonstrates gains from coupling spatial-temporal EEG structure across datasets. ([arxiv.org](https://arxiv.org/abs/2408.11884?utm_source=openai))"
    }
  ],
  "confidence": 0.78,
  "timestamp": 1760279115,
  "generated_time": "2025-10-12 09:25:15",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      89283,
      6,
      6000
    ],
    "dtype": "float32",
    "feature_count": 6000,
    "sample_count": 89283,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}