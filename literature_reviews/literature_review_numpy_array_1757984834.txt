LITERATURE REVIEW
=================

Query: ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods
Generated: 2025-09-16 01:07:14
Confidence: 0.78

DATA PROFILE:
{
  "data_type": "numpy_array",
  "shape": [
    62352,
    1000,
    2
  ],
  "dtype": "float32",
  "feature_count": 2,
  "sample_count": 62352,
  "is_sequence": true,
  "is_image": false,
  "is_tabular": false,
  "has_labels": true,
  "label_count": 5,
  "sequence_lengths": null,
  "channels": null,
  "height": null,
  "width": null,
  "metadata": {},
  "previous_attempts": [
    "failed_attempt_1"
  ]
}

COMPREHENSIVE REVIEW:
Recent work (2023–2025) on ECG arrhythmia classification has consolidated three trends: (1) lightweight Transformer family models tailored to 1D signals, (2) efficient state-space models (Mamba/SSM) for long sequences, and (3) hybrid CNN+attention stacks that fuse local morphology with longer-range rhythm context. On the canonical MIT-BIH Arrhythmia Database (two leads, 360 Hz, ~110k annotated beats), papers report strong five-class (AAMI EC57 N/S/V/F/Q) performance when splits are patient-disjoint; many recent models also target deployment, showing int8 quantization and sub-mJ inference on microcontrollers. Representative results include CAT-Net (CNN+attention+Transformer) with 99.14% accuracy and 94.69% macro-F1 on five-class MIT-BIH, a 6k-parameter Tiny Transformer reaching 98.97% accuracy on the same 5 classes with 8-bit inference, and ECGMamba, a bidirectional state-space model emphasizing linear-time sequence processing while remaining competitive with attention models. Hybrid CNN+Transformer inter-patient protocols typically report 97–99% accuracy, though metrics vary with the exact DS1→DS2 split and class mapping. Self-supervised pretraining (e.g., NERULA) is increasingly used to improve label efficiency and robustness before fine-tuning on MIT-BIH. ([physionet.org](https://www.physionet.org/physiobank/database/mitdb/?utm_source=openai))

Methodologically, best practice is to follow the AAMI EC57 evaluation paradigm and an inter-patient split such as the widely used DS1/DS2 partition (training: {101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230}; testing: {100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234}), avoid beat leakage across subjects, and report macro-F1 alongside accuracy because of severe class imbalance (especially F and Q). With your input shape (1000, 2), treat samples as two synchronized leads over ~2.8 s windows; architectures commonly use a 1D conv stem for denoising and morphology, followed by temporal modeling (Transformer/SSM/BiLSTM) and a five-way classifier. Augmentations that preserve ECG semantics (baseline wander, amplitude jitter, time-warp within QRS limits, random lead drop) and class-rebalancing (class weights, focal loss) are standard. ([array.aami.org](https://array.aami.org/doi/10.2345/9781570204784?utm_source=openai))

KEY FINDINGS:
1. Use patient-disjoint (inter-patient) evaluation per AAMI EC57; DS1→DS2 is a common, clinically realistic split. Leakage across patients inflates scores and should be avoided. ([array.aami.org](https://array.aami.org/doi/10.2345/9781570204784?utm_source=openai))
2. Lightweight attention works: hybrid CNN+Transformer (e.g., CAT-Net) delivers very strong five-class MIT-BIH performance while handling minority classes via rebalancing. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))
3. Efficiency-focused models are viable: Tiny Transformers (~6k params, int8) reach ~99% accuracy on 5-class MIT-BIH and run in milliseconds on embedded hardware. ([arxiv.org](https://arxiv.org/abs/2509.03066?utm_source=openai))
4. State-space models (Mamba/SSM) scale linearly in sequence length and match Transformer accuracy on ECG, offering better memory/runtime for longer windows. ([arxiv.org](https://arxiv.org/abs/2406.10098?utm_source=openai))
5. Self-supervised pretraining (e.g., masked/contrastive approaches like NERULA) improves downstream arrhythmia classification and robustness when fine-tuned on MIT-BIH. ([arxiv.org](https://arxiv.org/abs/2405.19348?utm_source=openai))
6. On five-class MIT-BIH inter-patient setups, recent strong baselines report ~97–99% accuracy; macro-F1 varies more with minority classes (F/Q), so report per-class metrics. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/38482492/?utm_source=openai))
7. MIT-BIH specifics matter for preprocessing: two channels at 360 Hz with cardiologist annotations; windowing around R peaks and per-record normalization are standard. ([physionet.org](https://www.physionet.org/physiobank/database/mitdb/?utm_source=openai))

RECOMMENDED APPROACHES:
1. {'name': 'Hybrid 1D CNN + Transformer encoder (local-global)', 'why_it_works': '1D conv stem captures morphology (QRS/P/T), Transformer models rhythm/context across ~1000 steps; handles two-lead fusion via early 1x1 conv or cross-lead attention.', 'typical_hyperparams': 'conv stem: 32–96 channels, kernels 7–15; Transformer: d_model 64–192, 2–6 layers, 4–8 heads, dropout 0.1–0.3; LR 1e-3→3e-4 (cosine/OneCycle), batch 64–256.'}
2. {'name': 'Tiny Transformer for deployment', 'why_it_works': 'Shrunk attention blocks and MLP heads preserve accuracy while enabling int8 quantization/distillation for MCU/edge use; good fit for (1000,2) beats.', 'typical_hyperparams': 'params 6k–100k; d_model 32–96, 1–3 layers, 2–4 heads; label smoothing 0.05–0.1; quant-aware training (fake quant) and post-training int8 calibration. ([arxiv.org](https://arxiv.org/abs/2509.03066?utm_source=openai))'}
3. {'name': 'Mamba/State-Space Model (SSM) encoder', 'why_it_works': 'Linear-time recurrent-style scanning captures long-range dynamics with lower memory than attention; bidirectional SSM recovers both forward/backward context.', 'typical_hyperparams': 'd_model 96–192; 4–8 SSM blocks; sequence length 1000 with chunking 256–512 if needed; AdamW 1e-3→1e-4; dropout 0.1–0.2. ([arxiv.org](https://arxiv.org/abs/2406.10098?utm_source=openai))'}
4. {'name': 'Strong CNN baseline (InceptionTime/ResNet1D + SE)', 'why_it_works': 'Dilated/multi-scale 1D convolutions remain competitive on ECG; SE/channel attention helps minority classes and two-lead integration.', 'typical_hyperparams': 'depth 6–12 blocks; width 32–128; kernel sizes 9–41 mixed; weight decay 1e-4–3e-4; mixup off or low (α≤0.2) due to ECG semantics.'}
5. {'name': 'Self-supervised pretrain + supervised fine-tune', 'why_it_works': 'Masked or contrastive pretraining on large ECG corpora (e.g., PTB-XL) yields robust features; fine-tune small heads on MIT-BIH 5-class improves sample efficiency.', 'typical_hyperparams': 'SSL: 100–300 epochs with ECG-preserving augments; fine-tune: LR 3e-4; freeze 50–90% of backbone initially; use class-balanced loss. ([arxiv.org](https://arxiv.org/abs/2405.19348?utm_source=openai))'}

RECENT PAPERS:
- CAT-Net: Convolution, attention, and transformer based network for single-lead ECG arrhythmia classification (2024): No description
- A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers (2024): No description
- ECGMamba: Towards Efficient ECG Classification with BiSSM (2024): No description
- Heartbeat classification combining multi-branch CNNs and Transformer (2024): No description
- NERULA: A Dual-Pathway Self-Supervised Learning Framework for ECG (2024): No description
- ECG DETR: Transformer-based detection on continuous ECG (2022, influential): No description
- MIT-BIH Arrhythmia Database (PhysioNet, reference): No description
- ANSI/AAMI EC57:2012(R2020) standard: No description

==================================================
