{
  "query": "ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Scope and data characteristics: You are solving multiclass sequence classification on 1D ECG time series with shape (T=1000, C=2), 5 classes (AAMI N, S, V, F, Q), using MIT-BIH Arrhythmia. MIT-BIH contains two channels (commonly lead II and V) sampled at 360 Hz; AAMI mapping to five heartbeat categories is standard in recent literature. This aligns with contemporary heartbeat-level methods (beat windows of ~200–300 samples) as well as short multi-beat segments (~2.8 s at 360 Hz ≈ length 1000) used by sequence models. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))\n\nWhat is state-of-the-art (2024–2025):\n- Tiny 1D Transformers demonstrate strong AAMI 5-class results with extremely low compute. Busia et al. (Feb 2024) report 98.97% accuracy on MIT-BIH 5-class with only ~6k parameters, quantized 8-bit deployment, and 4.28 ms / 0.09 mJ inference on GAP9; robustness under motion artifacts reached 98.36%. While designed for embedded inference, the architecture is generic and translatable to PyTorch for 1D signals and multi-channel inputs. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))\n- Bidirectional Transformer + multi-scale CNN hybrids (ECGTransForm) offer strong minority-class F1 via class-imbalance-aware loss. The 2024 BSPC paper provides open-source PyTorch code; reported MIT-BIH per-class metrics include macro-F1 ≈ 94.26% with notable gains on V and S vs standard CNNs, using a Context-Aware Loss, multi-scale convolutions, and a Bi-Transformer encoder. ([github.com](https://github.com/emadeldeen24/ECGTransForm))\n- Time-frequency + Swin Transformer pipelines (CWT spectrograms + Swin) report high intra- and inter-patient performance on MIT-BIH (99.34% intra-patient; 98.37% inter-patient), validating the competitiveness of transformer backbones when paired with wavelet features. However, they add preprocessing and tend to be heavier than compact 1D models. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))\n- State-space models (SSM) and Mamba variants target efficiency for long sequences. ECGMamba (Jun 2024) proposes a bidirectional SSM (BiSSM) layer over a 1D CNN stem to reduce quadratic attention costs while keeping accuracy “competitive,” making it appealing for longer sequences like T=1000 with multi-beat context. Although the paper emphasizes efficiency, it reports qualitative/competitive results rather than standardized 5-class MIT-BIH metrics in the abstract; still, the design aligns well with your sequence length and efficiency targets. ([arxiv.org](https://arxiv.org/abs/2406.10098))\n- Lightweight CNNs and dual-path fusions remain strong baselines. rECGnition v2.0 (Feb 2025) fuses global/local ECG features with depthwise-separable convs and a self-attentive CCA fusion, achieving 98.07% accuracy and 98.05% F1 on MIT-BIH (10-class setting) at 82.7M FLOPs/sample, and excellent AAMI performance on other databases—evidence that carefully designed CNN(+attention) can match transformer-level results with moderate compute. ([arxiv.org](https://arxiv.org/abs/2502.16255?utm_source=openai))\n\nRecent surveys/meta-analyses underscore trends: MIT-BIH remains the dominant benchmark; CNNs still prevalent but transformer and SSM uptake is rising; evaluation protocols (intra- vs inter-patient) drive wide metric variance. A 2024 survey centered on MIT-BIH highlights protocol inconsistency and growing interest in graph/advanced architectures, while a 2025 Information Fusion review synthesizes transformer designs for biosignals and discusses compute–performance trade-offs—relevant when choosing between 1D CNNs, Transformers, and SSMs. ([mdpi.com](https://www.mdpi.com/2079-3197/12/2/21?utm_source=openai))\n\nComputational considerations for your setting (T=1000, C=2, 5 classes):\n- Tiny 1D Transformer: ~6k params; easily extended to C=2 via a 1D conv stem; excellent accuracy/latency-energy profile; PyTorch implementation is straightforward (few encoder blocks, small d_model, depth 2–3, 4 heads, relative position encodings). ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))\n- ECGTransForm (PyTorch code available): hybrid CNN+Bi-Transformer with class-imbalance-aware loss; heavier than the tiny transformer but still tractable on a single GPU; strong per-class F1, particularly post imbalance handling. ([github.com](https://github.com/emadeldeen24/ECGTransForm))\n- Swin (CWT+2D): strong accuracy but requires spectrogram generation and 2D backbones; heavier compute and memory vs compact 1D models; additional preprocessing pipeline. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))\n- Mamba/BiSSM: promising for long sequences with linear-time inference and good hardware efficiency; current ECG reports emphasize efficiency and competitiveness rather than definitive 5-class SOTA numbers. ([arxiv.org](https://arxiv.org/abs/2406.10098))\n\nConclusion: For a two-channel, 1000-sample sequence classification on MIT-BIH (AAMI 5-class) with a balance of accuracy and compute, the most compelling choice is a compact 1D Tiny Transformer architecture augmented with a shallow 1D convolutional stem for C=2 and a class-imbalance-aware loss. It achieves near-SOTA accuracy on MIT-BIH 5-class with orders-of-magnitude fewer parameters and demonstrated embedded-class efficiency; it is trivial to implement in PyTorch and to scale slightly if needed (e.g., widening d_model or adding a block) while respecting your efficiency constraints. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))",
  "key_findings": [
    "Tiny 1D Transformers can achieve ≈98.97% accuracy on MIT-BIH AAMI 5-class with only ~6k parameters, and 4.28 ms / 0.09 mJ inference on GAP9 after 8-bit quantization—indicating an exceptional accuracy–efficiency trade-off suitable for T=1000, C=2 inputs. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))",
    "Hybrid CNN+Bidirectional Transformer with imbalance-aware loss (ECGTransForm) improves minority-class performance on MIT-BIH; reported macro-F1 ≈ 94.26% (per-class table), and provides open-source PyTorch training code for MIT-BIH/PTB. ([github.com](https://github.com/emadeldeen24/ECGTransForm))",
    "Time–frequency CWT + Swin Transformer achieves 99.34% (intra-patient) and 98.37% (inter-patient) on MIT-BIH, validating transformer efficacy but at higher preprocessing and model complexity than compact 1D models. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))",
    "State-space (Mamba/BiSSM) architectures specifically target linear-time sequence modeling and efficient inference on long ECG sequences; ECGMamba reports competitive performance while reducing attention overhead—promising for T=1000 sequences. ([arxiv.org](https://arxiv.org/abs/2406.10098))",
    "Depthwise-separable CNNs with dual-path/global–local fusion (rECGnition v2.0) reach ≈98.07% accuracy and 98.05% F1 on MIT-BIH (10-class), with 82.7M FLOPs/sample, showing that thoughtfully optimized CNNs remain highly competitive in 2025. ([arxiv.org](https://arxiv.org/abs/2502.16255?utm_source=openai))"
  ],
  "recommended_approaches": [
    "Tiny-Transformer-1D (PyTorch) with a 1D convolutional stem for 2-channel input: channels→(Conv1d[k=7,stride=2]→BN→GELU)→positional encoding→2–3 Transformer encoder blocks (d_model≈64–96, heads=4), depthwise FFN, dropout 0.1; global pooling→linear 5-way head; train with class-balanced focal loss or context-aware loss, strong augmentation (Gaussian noise, random time-warp, mixup), and inter-patient split. Justification: near-SOTA MIT-BIH 5-class accuracy (≈98.97%) with ≈6k params and proven embedded-class efficiency; trivially adapted to (1000,2) without heavy preprocessing; easy PyTorch implementation and scalable if more capacity is needed. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))"
  ],
  "recent_papers": [
    {
      "title": "A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers (2024)",
      "contribution": "MIT-BIH 5-class accuracy 98.97% with ~6k params; 8-bit quantization; 4.28 ms / 0.09 mJ inference—sets a high bar for accuracy–efficiency. ([arxiv.org](https://arxiv.org/abs/2402.10748?utm_source=openai))"
    },
    {
      "title": "ECGTransForm: Empowering adaptive ECG arrhythmia classification framework with bidirectional transformer (BSPC, 2024)",
      "contribution": "PyTorch hybrid CNN+Bi-Transformer with Context-Aware Loss; improved minority-class F1 on MIT-BIH; open-source code. ([github.com](https://github.com/emadeldeen24/ECGTransForm))"
    },
    {
      "title": "A novel method of Swin Transformer with time-frequency characteristics for ECG-based arrhythmia detection (Frontiers in Cardiovascular Medicine, 2024)",
      "contribution": "CWT spectrogram + Swin achieved 99.34% (intra) and 98.37% (inter) on MIT-BIH; shows transformer competitiveness with TF features. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))"
    },
    {
      "title": "ECGMamba: Towards Efficient ECG Classification with BiSSM (arXiv, 2024)",
      "contribution": "Introduces Mamba-based bidirectional SSM layer for linear-time inference on long sequences; competitive results with strong efficiency focus. ([arxiv.org](https://arxiv.org/abs/2406.10098))"
    },
    {
      "title": "rECGnition v2.0: Self-Attentive Canonical Fusion of ECG and Patient Data (arXiv, 2025)",
      "contribution": "Dual-path + depthwise CNN with self-attentive canonical fusion; 98.07% accuracy/98.05% F1 on MIT-BIH (10-class) at ~82.7M FLOPs/sample. ([arxiv.org](https://arxiv.org/abs/2502.16255?utm_source=openai))"
    },
    {
      "title": "Transformers in biosignal analysis: A review (Information Fusion, 2025)",
      "contribution": "Survey of transformer architectures for biosignals; discusses compute–performance trade-offs and best practices relevant to ECG. ([sciencedirect.com](https://www.sciencedirect.com/science/article/abs/pii/S1566253524004755?utm_source=openai))"
    }
  ],
  "confidence": 0.78,
  "timestamp": 1758570767,
  "generated_time": "2025-09-22 14:52:47",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}