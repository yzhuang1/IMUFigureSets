{
  "query": "ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem framing: You aim to classify 5 AAMI superclasses (N, S, V, F, Q) from 2‑lead ECG windows of length 1000 samples (sequence data) using the MIT‑BIH Arrhythmia Database. MIT‑BIH provides 48 half‑hour, two‑channel recordings digitized at 360 Hz (~110k annotated beats), making it the de‑facto benchmark for arrhythmia classification and suitable for your setup. ([physionet.org](https://physionet.org/physiobank/database/mitdb/?utm_source=openai))\n\nWhat recent evidence shows (2024–2025):\n- Lightweight multi‑lead CNNs with channel (lead) attention achieve very strong 5‑class performance on MIT‑BIH while remaining simple to deploy. A 2025 Sensors study proposed a compact CNN with channel attention that supports 2‑lead and 12‑lead inputs and reported 99.18% accuracy (F1 99.18%) on MIT‑BIH 5‑class; this closely matches your 2‑lead, long‑window setting. ([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC12431083/))\n- CNN–Transformer hybrids remain state of the art on beat‑level MIT‑BIH. CAT‑Net (CNN + attention + Transformer encoder) reported 99.14% overall accuracy and 94.69% macro‑F1 on 5‑class MIT‑BIH, using wavelet denoising and SMOTE‑Tomek to combat class imbalance; code is available in PyTorch notebooks, easing adoption. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))\n- For efficiency, a 2024 IEEE T‑BCAS study introduced a tiny ViT‑style 1D Transformer operating on heartbeat windows plus RR‑interval features: only ~6k parameters and ~0.97 MOPs/inference, with 8‑bit inference energy ~0.09 mJ on GAP9, achieving 98.97% 5‑class accuracy on MIT‑BIH. Note the authors evaluate in the intra‑patient regime. ([arxiv.org](https://arxiv.org/abs/2402.10748))\n- Inter‑patient (patient‑wise) evaluation is crucial for fair generalization estimates on MIT‑BIH; a 2025 systematic review (E3C criteria) stresses AAMI compliance and DS1/DS2 inter‑patient splits (De Chazal protocol). ([arxiv.org](https://arxiv.org/html/2503.07276v1))\n- Under inter‑patient splits, recent deep models that inject RR‑interval features remain competitive: a 2024 study combining 1D‑CNN with four RR features and entropy‑rate descriptors reported 97.91% (5‑class) inter‑patient accuracy on MIT‑BIH and strong cross‑dataset results on INCART, supporting the value of timing features for generalization. ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/39021157/))\n- For embedded feasibility under inter‑patient evaluation (3‑class AAMI), a tiny matched‑filter CNN achieved 98.18% accuracy with only ~1.3k parameters, validating that compact models can still generalize under DS1→DS2 testing. ([mdpi.com](https://www.mdpi.com/1424-8220/23/3/1365?utm_source=openai))\n\nModel design trends and ingredients that map to your data: (i) local morphology encoders via 1D depthwise/separable CNN blocks; (ii) channel/lead attention to fuse 2‑lead information; (iii) a lightweight Transformer (or multi‑head attention) stage for longer temporal context; (iv) auxiliary RR‑interval features concatenated late; (v) class‑imbalance handling (class‑weighted or focal loss, or SMOTE‑Tomek if doing beat‑level sampling) — all of which are present across the strongest recent works. ([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC12431083/))\n\nEvaluation protocol note: Report both intra‑patient and inter‑patient (DS1 train → DS2 test) results; the latter is the field’s recommended, more realistic protocol and often reduces headline numbers relative to random splits. ([arxiv.org](https://arxiv.org/html/2503.07276v1))",
  "key_findings": [
    "Evaluation protocol matters: the 2025 E3C systematic review urges AAMI compliance and inter‑patient DS1/DS2 splits; models evaluated intra‑patient can overstate performance. ([arxiv.org](https://arxiv.org/html/2503.07276v1))",
    "Hybrid CNN+attention models deliver top 5‑class MIT‑BIH accuracy with manageable complexity: CAT‑Net (CNN + attention + Transformer) achieved 99.14% accuracy and 94.69% macro‑F1; open PyTorch code eases replication. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))",
    "Efficiency without major accuracy loss is feasible: a tiny ViT‑style Transformer (~6k params; ~0.97 MOPs) reached 98.97% 5‑class accuracy (intra‑patient) and 0.09 mJ/inference on GAP9, while inter‑patient CNNs with RR‑features reached ~97.9% (5‑class). ([arxiv.org](https://arxiv.org/abs/2402.10748))"
  ],
  "recommended_approaches": [
    "Adopt a two‑lead CNN+Transformer with channel attention (CAT‑Net–style) and late RR‑interval injection: 1D depthwise‑separable CNN stem → Squeeze‑and‑Excitation (or ECA) channel attention to fuse 2 leads → 2–3 lightweight Transformer encoder blocks for longer context over the 1000‑sample window → concatenation with pre/post‑RR features → classifier trained with class‑weighted/focal loss; evaluate under DS1→DS2 inter‑patient split. Justification: matches your (1000,2) input; mirrors multi‑lead channel‑attention CNNs that reached 99.18% on MIT‑BIH, leverages proven CNN+Transformer hybrids with strong 5‑class results and available PyTorch code (CAT‑Net), and retains efficiency by using lightweight attention and separable convolutions; RR‑feature injection improves inter‑patient robustness. ([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC12431083/))"
  ],
  "recent_papers": [
    {
      "title": "Lightweight Deep Learning Architecture for Multi‑Lead ECG Arrhythmia Detection (Sensors, 2025)",
      "contribution": "Multi‑lead (2‑lead/12‑lead) CNN with channel attention; reported 99.18% accuracy (F1 99.18%) on MIT‑BIH 5‑class; demonstrates strong performance for multi‑lead windows like (1000,2). ([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC12431083/))"
    },
    {
      "title": "CAT‑Net: Convolution, attention, and transformer based network for single‑lead ECG arrhythmia classification (Biocybernetics and Biomedical Engineering, 2024) + PyTorch code",
      "contribution": "CNN + attention + Transformer encoder; 99.14% accuracy and 94.69% macro‑F1 on MIT‑BIH 5‑class; uses SMOTE‑Tomek; open notebooks ease replication/adaptation. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))"
    },
    {
      "title": "A Tiny Transformer for Low‑Power Arrhythmia Classification on Microcontrollers (IEEE T‑BCAS, 2024)",
      "contribution": "ViT‑style 1D Transformer with RR‑features; ~6k params, ~0.97 MOPs, 8‑bit inference ≈0.09 mJ on GAP9; 98.97% accuracy on MIT‑BIH 5‑class (intra‑patient); template for efficient attention blocks. ([arxiv.org](https://arxiv.org/abs/2402.10748))"
    },
    {
      "title": "Arrhythmia detection in inter‑patient ECG using entropy‑rate features and RR intervals with CNN (Comput. Methods Biomech. Biomed. Eng., 2024)",
      "contribution": "Inter‑patient 5‑class MIT‑BIH accuracy 97.91%; shows RR‑feature injection improves generalization and cross‑dataset robustness (INCART). ([pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov/39021157/))"
    },
    {
      "title": "A Tiny Matched Filter‑Based CNN for Inter‑Patient ECG Classification at the Edge (Sensors, 2023)",
      "contribution": "Inter‑patient DS1→DS2 (3‑class) 98.18% with ~1.3k params; demonstrates strong generalization with very small models and provides FLOPs/params baselines for embedded deployment. ([mdpi.com](https://www.mdpi.com/1424-8220/23/3/1365?utm_source=openai))"
    },
    {
      "title": "A Systematic Review of ECG Arrhythmia Classification: Adherence to Standards, Fair Evaluation, and Embedded Feasibility (arXiv, 2025)",
      "contribution": "Meta‑analysis (2017–2024) urging AAMI compliance and inter‑patient splits; provides E3C criteria and standardized reporting guidance. ([arxiv.org](https://arxiv.org/html/2503.07276v1))"
    }
  ],
  "confidence": 0.74,
  "timestamp": 1758926110,
  "generated_time": "2025-09-26 17:35:10",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}