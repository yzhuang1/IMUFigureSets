LITERATURE REVIEW
=================

Query: ECG classification arrhythmia detection heart rhythm analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods
Generated: 2025-09-17 15:23:12
Confidence: 0.78

DATA PROFILE:
{
  "data_type": "torch_tensor",
  "shape": [
    62352,
    1000,
    2
  ],
  "dtype": "float32",
  "feature_count": 2,
  "sample_count": 62352,
  "is_sequence": true,
  "is_image": false,
  "is_tabular": false,
  "has_labels": true,
  "label_count": 5,
  "sequence_lengths": null,
  "channels": null,
  "height": null,
  "width": null,
  "metadata": {}
}

COMPREHENSIVE REVIEW:
Problem framing and standards: The MIT-BIH Arrhythmia Database contains 48 half‑hour, two‑channel ambulatory ECG recordings sampled at 360 Hz, with expert beat annotations; AAMI EC57 recommends mapping heartbeat types into five superclasses (N, S, V, F, Q) and using inter‑patient evaluation (e.g., DS1/DS2 split) to avoid patient leakage. Your data shape (1000, 2) matches a 2‑lead 1D time‑series window, which can be modeled with multi‑channel 1D architectures or converted to 2D time‑frequency images if desired. ([physionet.org](https://physionet.org/content/mitdb/1.0.0/))

Recent evidence and SOTA models (2024–2025): (1) Tiny Transformer for low‑power deployment (ViT adapted to 1D ECG): 6k parameters, 0.97 MOPs/inference; on MIT‑BIH 5‑class, 8‑bit quantized inference achieves 98.97% accuracy; deployed on GAP9 at 4.28 ms/inference and 0.09 mJ; evaluated under intra‑patient and with robustness tests for motion artifacts. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748)) (2) CAT‑Net (CNN + channel attention + Transformer encoder) for single‑lead heartbeats: on MIT‑BIH 5‑class, reports 99.14% overall accuracy and 94.69% macro‑F1; class imbalance handled with SMOTE‑Tomek; code available. (Protocol appears single‑lead and not explicitly inter‑patient.) ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai)) (3) Swin Transformer on wavelet time‑frequency maps (2D): on MIT‑BIH, 99.34% (intra‑patient) and 98.37% (inter‑patient) accuracy, indicating stronger generalization when the inter‑patient protocol is enforced. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full)) (4) Hierarchical Attention Network (HAN) adapted from text: achieves near‑SOTA on MIT‑BIH while using 15.6× fewer parameters than a CNN–attention–Transformer baseline (CAT‑Net), emphasizing interpretability with attention over ECG segments. ([arxiv.org](https://arxiv.org/html/2504.03703?utm_source=openai)) (5) A 2025 systematic review stresses that only a minority of ECG arrhythmia papers jointly follow AAMI mapping, enforce inter‑patient evaluation, and report embedded feasibility; it highlights the need for fair benchmarking and resource reporting. ([arxiv.org](https://arxiv.org/html/2503.07276v1))

Model/metric comparability for your setting: Your input (1000, 2) is a longer window and two leads versus many single‑lead, ~0.5–3 s windows in prior work; however, 1D CNN–Transformer hybrids (e.g., CAT‑Net‑style) naturally extend to multi‑lead by stacking channels, and can ingest auxiliary RR‑interval features like the Tiny Transformer to boost performance. Inter‑patient DS1/DS2 splitting should be used for benchmarking, with macro‑F1 reported alongside accuracy to reflect class imbalance in S and F classes. ([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC5585360/?utm_source=openai))

Computational considerations: If deployment or training efficiency is critical, the Tiny Transformer provides documented microcontroller‑class efficiency (6k params; 4.28 ms @ GAP9) with competitive accuracy; CAT‑Net maximizes accuracy and macro‑F1 but reports focus on algorithmic gains (SMOTE‑Tomek, single‑lead) rather than hardware metrics; Swin‑based 2D approaches achieve strong inter‑patient accuracy but incur higher compute and image transforms. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))

Synthesis: For 5‑class heartbeat classification on MIT‑BIH with 2‑lead, 1000‑sample windows, the strongest balance of accuracy, interpretability, and PyTorch implementability is a CNN + attention + Transformer encoder (CAT‑Net‑style) adapted to two input leads and trained under DS1/DS2 inter‑patient protocol, optionally augmented with RR‑interval features (as in the Tiny Transformer) and class balancing (SMOTE‑Tomek). This choice is supported by high macro‑F1 on MIT‑BIH (94.69%), demonstrated effectiveness on class imbalance, easy adaptation to multi‑lead 1D input, and straightforward PyTorch implementation; practitioner guidance from the 2025 review further endorses inter‑patient evaluation and proper reporting. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))

KEY FINDINGS:
1. Transformer models tailored to 1D ECG can be very compact and fast: a 6k‑parameter Tiny Transformer achieved 98.97% accuracy (5‑class MIT‑BIH, 8‑bit) and 4.28 ms/inference at 0.09 mJ on GAP9, with robustness to motion artifacts. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))
2. Hybrid CNN+attention+Transformer (CAT‑Net) achieved state‑of‑the‑art MIT‑BIH performance—99.14% accuracy and 94.69% macro‑F1 on 5‑class heartbeats—using SMOTE‑Tomek to improve minority‑class detection; code is publicly available. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))
3. Inter‑patient evaluation substantially lowers inflated intra‑patient results; a Swin Transformer on wavelet time‑frequency maps attained 98.37% accuracy under inter‑patient splitting on MIT‑BIH, highlighting the importance of fair benchmarking. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))
4. A hierarchical attention network (HAN) matched a CNN–attention–Transformer baseline with 15.6× fewer parameters on MIT‑BIH, suggesting lighter models can retain accuracy while improving interpretability. ([arxiv.org](https://arxiv.org/html/2504.03703?utm_source=openai))
5. A 2025 systematic review finds few studies simultaneously follow AAMI mapping, inter‑patient protocol, and embedded feasibility; it calls for standardized reporting of accuracy, macro‑F1, latency, energy, and memory. ([arxiv.org](https://arxiv.org/html/2503.07276v1))

RECOMMENDED APPROACHES:
1. Adopt a CAT‑Net–style 1D CNN + channel attention + Transformer encoder in PyTorch, adapted for two‑lead input (shape: [batch, 2, 1000]) and trained with AAMI 5‑class labels under the DS1/DS2 inter‑patient split; include (a) RR‑interval features concatenated before the classifier (Tiny‑Transformer‑style) to improve rhythm context, (b) class balancing with SMOTE‑Tomek on the training set, and (c) standard ECG augmentations (baseline wander, Gaussian noise) to improve robustness. This architecture is empirically strong on MIT‑BIH (99.14% accuracy; 94.69% macro‑F1) and is straightforward to implement/extend in PyTorch for multi‑lead inputs, while inter‑patient evaluation aligns with best‑practice recommendations. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))

RECENT PAPERS:
- A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers (IEEE TBCAS, 2024): ViT adapted to 1D ECG with 6k params; 98.97% accuracy (5‑class MIT‑BIH, 8‑bit); 4.28 ms/0.09 mJ inference on GAP9; noise‑robust training. ([ar5iv.org](https://ar5iv.org/pdf/2402.10748))
- CAT‑Net: Convolution, attention, and transformer based network for single‑lead ECG arrhythmia classification (BSPC, 2024): Hybrid 1D CNN + attention + Transformer; reports 99.14% accuracy and 94.69% macro‑F1 on MIT‑BIH 5‑class; uses SMOTE‑Tomek; open code. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S1746809424002696?utm_source=openai))
- A novel method of Swin Transformer with time‑frequency characteristics for ECG‑based arrhythmia detection (Frontiers in Cardiovascular Medicine, 2024): Transforms ECG to wavelet time‑frequency maps and applies Swin Transformer; 99.34% (intra‑patient) and 98.37% (inter‑patient) accuracy on MIT‑BIH. ([frontiersin.org](https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2024.1401143/full))
- Hierarchical Attention Network for Interpretable ECG‑based Heart Disease Classification (arXiv, 2025): HAN adapted from text classification; comparable MIT‑BIH accuracy with 15.6× fewer parameters than a CNN–attention–Transformer (CAT‑Net) baseline; improves interpretability. ([arxiv.org](https://arxiv.org/html/2504.03703?utm_source=openai))
- A Systematic Review of ECG Arrhythmia Classification: Adherence to Standards, Fair Evaluation, and Embedded Feasibility (arXiv, 2025): Meta‑analysis (2017–2024) emphasizing AAMI mapping, inter‑patient evaluation, and embedded feasibility; urges standardized reporting and fair comparisons. ([arxiv.org](https://arxiv.org/html/2503.07276v1))

==================================================
