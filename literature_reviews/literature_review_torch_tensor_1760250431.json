{
  "query": "EEG classification brain signal analysis sequence classification time series machine learning multiclass sequence classification large dataset classification 2024 2025 PyTorch implementation state-of-the-art methods",
  "review_text": "Problem context: ISRUC-Sleep contains overnight PSG with 30 s epochs labeled into 5 AASM stages (W, N1, N2, N3, REM). Multi-channel EEG (e.g., 6 channels at 200 Hz → 6×6000 samples per epoch) is typical; many pipelines resample to 100 Hz while preserving 30 s epochs. Tooling like TorchEEG provides ISRUC loaders (default 6 EEG channels) and shows common preprocessing choices, which align with your input characteristics. ([torcheeg.readthedocs.io](https://torcheeg.readthedocs.io/en/stable/_modules/torcheeg/datasets/module/sleep_stage_detection/isruc.html?utm_source=openai))\nState of the art since 2024 emphasizes multi-channel spatial modeling plus short/medium temporal context: (a) graph-based models that learn inter-channel relationships; (b) modern sequence encoders (Transformers/S4) for across-epoch context; and (c) hybrid frameworks that fuse both. Recent surveys also argue for careful validation and generalization. ([ijcai.org](https://www.ijcai.org/Proceedings/2020/184?utm_source=openai))\nGraph/hypergraph models on ISRUC: An ICASSP’24 hypergraph approach (STHL) builds spatial–temporal hyperedges over multi-channel EEG and reports on ISRUC Subgroup 3: weighted F1≈0.831 and accuracy≈0.849 using 10 channels with CNN feature reduction to 256 per epoch (raw 6000 reduced), matching your epoch length and multi-channel setting; official PyTorch code is available. ([ar5iv.org](https://ar5iv.org/pdf/2309.02124)) Domain-alignment on top of spatial–temporal GNNs (SIDA) improves ISRUC performance; for ISRUC-S3, MSTGCN-family baselines reach up to ≈0.876 accuracy and ≈0.801 macro-F1 in subject-wise tests, indicating that spatial graphs plus robust training can outperform earlier CNN/RNN pipelines on ISRUC. ([dl.acm.org](https://dl.acm.org/doi/full/10.1145/3625238?utm_source=openai))\nTransformer/S4 sequence encoders: S4Sleep (PyTorch) explores encoder–predictor designs with S4 state-space layers, surpassing prior methods on large SHHS data and finding that expanding context far beyond ~15 epochs gives marginal gains—useful for efficient ISRUC training with moderate context windows. Code is public and easy to adapt to a 6×6000 input. ([github.com](https://github.com/AI4HealthUOL/s4sleep?utm_source=openai))\nNew multi-channel hybrid (2024–2025): ST-USleepNet constructs a spatial–temporal graph from raw signals and runs dual U-Nets (temporal 1D U-Net + graph U-Net) to extract characteristic sleep waveforms and salient spatial brain networks; the paper reports outperforming baselines across three datasets and provides a PyTorch implementation. This directly targets multi-channel EEG with explicit spatial–temporal coupling. ([arxiv.org](https://arxiv.org/abs/2408.11884))\nMulti-modal baselines (EEG+EOG+EMG) on ISRUC-SG1 achieve ≈91% subject-wise accuracy and κ≈0.89, but your constraint is EEG-only, so graph or S4-based EEG models are the closest match. ([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC11071240/?utm_source=openai))\nComputational notes: STHL reports PyTorch 1.13.1/CUDA 11.7 and trains on ISRUC-S3 with CNN feature extraction + hypergraph layers (moderate GPU). MSTGCN code targets ISRUC-S3 but is TensorFlow; replicating in PyTorch Geometric is straightforward. ST-USleepNet ships PyTorch code with 100 Hz resampling and W&B logging. S4Sleep is pure PyTorch and efficient on long sequences due to S4’s sub-quadratic recurrence, making it attractive for 6×6000 inputs and multi-epoch context. ([github.com](https://github.com/zhziming/STHL))",
  "key_findings": [
    "Hypergraph learning on ISRUC-S3 (STHL) achieved ~0.831 weighted F1 and ~0.849 accuracy using 10-channel inputs with a CNN feature reducer from 6000→256, demonstrating gains over classic CNN/RNN and prior GNN baselines on subject-wise evaluation. ([ar5iv.org](https://ar5iv.org/pdf/2309.02124))",
    "Spatial–temporal GNNs with domain alignment (MSTGCN+SIDA) reach ≈0.876 accuracy and ≈0.80 macro-F1 on ISRUC-S3, highlighting the value of learned inter-channel graphs plus robust training for generalization. ([dl.acm.org](https://dl.acm.org/doi/full/10.1145/3625238?utm_source=openai))",
    "Structured State Space (S4Sleep) sequence encoders surpass previous methods on large SHHS and show limited benefit beyond ~15-epoch context, informing efficient context windowing for ISRUC (e.g., 5–15 epochs). PyTorch code is available. ([github.com](https://github.com/AI4HealthUOL/s4sleep?utm_source=openai))"
  ],
  "recommended_approaches": [
    "ST-USleepNet (PyTorch): build a spatial–temporal graph from your 6×6000 EEG epochs (nodes = channel–time slices; edges weighted by similarity, temporal proximity, and channel priors) and feed it to dual U-Nets (temporal 1D U-Net for waveform features + graph U-Net for spatial networks), with a 5–15-epoch context window. Rationale: directly matches multi-channel raw-EEG, models spatial–temporal coupling shown effective on ISRUC-class datasets, offers state-of-the-art results in 2024–2025 literature, and is efficient to implement end-to-end in PyTorch. ([arxiv.org](https://arxiv.org/abs/2408.11884))"
  ],
  "recent_papers": [
    {
      "title": "ST-USleepNet: A Spatial-Temporal Coupling Prominence Network for Multi-Channel Sleep Staging (IJCAI 2025)",
      "contribution": "Constructs a spatial–temporal graph from raw multi-channel signals and applies dual U-Nets to jointly capture temporal waveforms and salient spatial brain networks; outperforms baselines across three datasets; PyTorch code provided. ([arxiv.org](https://arxiv.org/abs/2408.11884))"
    },
    {
      "title": "Exploiting Spatial-temporal Data for Sleep Stage Classification via Hypergraph Learning (STHL, ICASSP 2024)",
      "contribution": "Introduces dynamic spatial/temporal hyperedges over multi-channel EEG; on ISRUC-S3 reports ~0.831 F1 and ~0.849 accuracy; PyTorch implementation available. ([ar5iv.org](https://ar5iv.org/pdf/2309.02124))"
    },
    {
      "title": "Exploring Structure-Incentive Domain Adversarial Learning for Generalizable Sleep Stage Classification (SIDA, ACM TIST)",
      "contribution": "Adds multi-level domain alignment to ST-GCN backbones; achieves ≈0.876 accuracy and ≈0.80 macro-F1 on ISRUC-S3, indicating strong subject-wise performance. ([dl.acm.org](https://dl.acm.org/doi/full/10.1145/3625238?utm_source=openai))"
    },
    {
      "title": "S4Sleep: Elucidating the design space of deep-learning-based sleep stage classification models",
      "contribution": "Uses S4 state-space sequence layers on raw EEG; surpasses prior methods on SHHS and shows long-range (>15-epoch) context offers limited additional gains; official PyTorch repo facilitates adaptation. ([arxiv.org](https://arxiv.org/abs/2402.17779?utm_source=openai))"
    }
  ],
  "confidence": 0.72,
  "timestamp": 1760250431,
  "generated_time": "2025-10-12 01:27:11",
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      89283,
      6,
      6000
    ],
    "dtype": "float32",
    "feature_count": 6000,
    "sample_count": 89283,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  }
}