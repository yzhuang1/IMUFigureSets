{
  "model_name": "ECG-TCN-SE-Light",
  "training_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\nclass SqueezeExcite1D(nn.Module):\n    def __init__(self, channels: int, reduction: int = 8):\n        super().__init__()\n        hidden = max(1, channels // reduction)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.fc1 = nn.Conv1d(channels, hidden, kernel_size=1)\n        self.fc2 = nn.Conv1d(hidden, channels, kernel_size=1)\n        self.act = nn.SiLU()\n        self.gate = nn.Sigmoid()\n    def forward(self, x):\n        s = self.pool(x)\n        s = self.act(self.fc1(s))\n        s = self.gate(self.fc2(s))\n        return x * s\n\nclass DepthwiseSeparableConv1D(nn.Module):\n    def __init__(self, channels: int, kernel_size: int = 9, dilation: int = 1, dropout: float = 0.2):\n        super().__init__()\n        padding = (kernel_size - 1) // 2 * dilation\n        self.dw = nn.Conv1d(channels, channels, kernel_size=kernel_size, padding=padding, dilation=dilation, groups=channels, bias=False)\n        self.pw = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm1d(channels)\n        self.bn2 = nn.BatchNorm1d(channels)\n        self.act = nn.SiLU()\n        self.drop = nn.Dropout(dropout)\n    def forward(self, x):\n        y = self.dw(x)\n        y = self.bn1(y)\n        y = self.act(y)\n        y = self.pw(y)\n        y = self.bn2(y)\n        y = self.act(y)\n        y = self.drop(y)\n        return y\n\nclass TCNBlock(nn.Module):\n    def __init__(self, channels: int, kernel_size: int, dilation: int, dropout: float):\n        super().__init__()\n        self.conv = DepthwiseSeparableConv1D(channels, kernel_size=kernel_size, dilation=dilation, dropout=dropout)\n        self.se = SqueezeExcite1D(channels, reduction=8)\n    def forward(self, x):\n        y = self.conv(x)\n        y = self.se(y)\n        return x + y\n\nclass ECGTCNModel(nn.Module):\n    def __init__(self, in_channels: int = 2, num_classes: int = 5, hidden_size: int = 64, num_blocks: int = 5, kernel_size: int = 9, dropout: float = 0.2):\n        super().__init__()\n        self.stem = nn.Sequential(\n            nn.Conv1d(in_channels, hidden_size, kernel_size=7, padding=3, bias=False),\n            nn.BatchNorm1d(hidden_size),\n            nn.SiLU(),\n        )\n        dilations = [2 ** i for i in range(num_blocks)]\n        blocks = []\n        for d in dilations:\n            blocks.append(TCNBlock(hidden_size, kernel_size=kernel_size, dilation=d, dropout=dropout))\n        self.blocks = nn.Sequential(*blocks)\n        self.head = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Flatten(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size, num_classes)\n        )\n    def forward(self, x):\n        # x: (B, C, L)\n        x = self.stem(x)\n        x = self.blocks(x)\n        x = self.head(x)\n        return x\n\ndef _ensure_channel_first(x: torch.Tensor) -> torch.Tensor:\n    # Accept (B, C, L) or (B, L, C). Convert to (B, C, L).\n    if x.dim() != 3:\n        raise ValueError(f\"Expected 3D tensor (B, C, L) or (B, L, C), got shape {tuple(x.shape)}\")\n    if x.shape[1] == 2:  # (B, 2, L)\n        return x\n    if x.shape[-1] == 2:  # (B, L, 2)\n        return x.transpose(1, 2)\n    # Fallback: assume single-channel time series (B, L) or (B, 1, L)\n    if x.shape[1] != 1 and x.shape[-1] != 1:\n        # default to treat second dim as length\n        return x.unsqueeze(1)\n    return x if x.shape[1] == 1 else x.transpose(1, 2)\n\n@torch.no_grad()\ndef _evaluate(model, loader, device, num_classes: int = 5):\n    model.eval()\n    total, correct = 0, 0\n    total_loss = 0.0\n    all_preds = []\n    all_targs = []\n    for xb, yb in loader:\n        xb = _ensure_channel_first(xb).to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n        logits = model(xb)\n        loss = F.cross_entropy(logits, yb)\n        total_loss += loss.item() * yb.size(0)\n        preds = logits.argmax(dim=1)\n        correct += (preds == yb).sum().item()\n        total += yb.size(0)\n        all_preds.append(preds.detach().cpu())\n        all_targs.append(yb.detach().cpu())\n    val_loss = total_loss / max(1, total)\n    all_preds = torch.cat(all_preds)\n    all_targs = torch.cat(all_targs)\n    acc = (all_preds == all_targs).float().mean().item()\n    # Confusion matrix and macro-F1\n    num_classes = int(num_classes)\n    k = (all_targs * num_classes + all_preds).to(torch.long)\n    cm = torch.bincount(k, minlength=num_classes * num_classes).reshape(num_classes, num_classes)\n    tp = cm.diag().to(torch.float32)\n    fp = cm.sum(dim=0).to(torch.float32) - tp\n    fn = cm.sum(dim=1).to(torch.float32) - tp\n    f1 = 2 * tp / (2 * tp + fp + fn + 1e-12)\n    macro_f1 = f1.mean().item()\n    return val_loss, acc, macro_f1, f1.tolist()\n\ndef train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    \"\"\"\n    Train a lightweight Conv-TCN with Squeeze-and-Excitation for 5-class ECG classification.\n    Args:\n        X_train, y_train, X_val, y_val: PyTorch tensors. X_* shape (N, 1000, 2) or (N, 2, 1000); y_* long labels in [0..4].\n        device: torch.device\n        hyperparams: lr, batch_size, epochs, hidden_size, dropout, weight_decay, label_smoothing, class_weight_power\n    Returns: model, metrics_dict\n    \"\"\"\n    torch.backends.cudnn.benchmark = True\n    num_classes = 5\n    # Hyperparameters (simple; BO will tune)\n    lr = float(hyperparams.get('lr', 1e-3))\n    batch_size = int(hyperparams.get('batch_size', 128))\n    epochs = int(hyperparams.get('epochs', 20))\n    hidden_size = int(hyperparams.get('hidden_size', 64))  # 32..128 keeps params <256k\n    dropout = float(hyperparams.get('dropout', 0.2))\n    weight_decay = float(hyperparams.get('weight_decay', 1e-4))\n    label_smoothing = float(hyperparams.get('label_smoothing', 0.05))\n    class_weight_power = float(hyperparams.get('class_weight_power', 0.5))  # 0 disables reweighting\n\n    # DataLoaders\n    train_on_cpu = (X_train.device.type == 'cpu' and y_train.device.type == 'cpu')\n    val_on_cpu = (X_val.device.type == 'cpu' and y_val.device.type == 'cpu')\n    pin_mem_train = True if train_on_cpu else False\n    pin_mem_val = True if val_on_cpu else False\n    # If tensors are on GPU/MPS, safer to keep num_workers=0\n    nw_train = 2 if train_on_cpu else 0\n    nw_val = 2 if val_on_cpu else 0\n\n    train_ds = TensorDataset(X_train, y_train)\n    val_ds = TensorDataset(X_val, y_val)\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=nw_train, pin_memory=pin_mem_train)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=nw_val, pin_memory=pin_mem_val)\n\n    # Model\n    model = ECGTCNModel(in_channels=2, num_classes=num_classes, hidden_size=hidden_size, num_blocks=5, kernel_size=9, dropout=dropout)\n    model.to(device)\n\n    # Parameter count guard (< 256k)\n    param_count = sum(p.numel() for p in model.parameters())\n    if param_count > 256_000:\n        raise RuntimeError(f\"Model has {param_count} parameters; increase efficiency or reduce hidden_size to stay <256k.\")\n\n    # Class weights (help with S and F rarity)\n    with torch.no_grad():\n        y_cpu = y_train.detach().to('cpu').to(torch.long)\n        counts = torch.bincount(y_cpu, minlength=num_classes).float()\n        if class_weight_power > 0:\n            weights = (counts + 1e-6).pow(-class_weight_power)\n            weights = weights / weights.sum() * num_classes\n        else:\n            weights = torch.ones(num_classes)\n    weights = weights.to(device)\n\n    criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=label_smoothing)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n\n    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": [], \"val_macro_f1\": []}\n    best_acc = 0.0\n    best_macro = 0.0\n    best_epoch = -1\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        seen = 0\n        for xb, yb in train_loader:\n            xb = _ensure_channel_first(xb)\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n                logits = model(xb)\n                loss = criterion(logits, yb)\n            scaler.scale(loss).backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            running_loss += loss.item() * yb.size(0)\n            seen += yb.size(0)\n        train_loss = running_loss / max(1, seen)\n\n        val_loss, val_acc, val_macro_f1, class_f1 = _evaluate(model, val_loader, device, num_classes=num_classes)\n\n        history[\"train_loss\"].append(train_loss)\n        history[\"val_loss\"].append(val_loss)\n        history[\"val_acc\"].append(val_acc)\n        history[\"val_macro_f1\"].append(val_macro_f1)\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_macro = val_macro_f1\n            best_epoch = epoch\n\n    metrics = {\n        \"param_count\": int(param_count),\n        \"history\": history,\n        \"best_epoch\": int(best_epoch),\n        \"best_val_acc\": float(best_acc),\n        \"best_val_macro_f1\": float(best_macro),\n        \"final\": {\n            \"val_loss\": float(history[\"val_loss\"][-1]),\n            \"val_acc\": float(history[\"val_acc\"][-1]),\n            \"val_macro_f1\": float(history[\"val_macro_f1\"][-1])\n        }\n    }\n\n    return model, metrics\n",
  "hyperparameters": {
    "lr": 0.001,
    "epochs": 20,
    "batch_size": 128,
    "hidden_size": 64,
    "dropout": 0.2
  },
  "reasoning": "The model is a compact Conv-TCN with dilated depthwise-separable convolutions and Squeeze-and-Excitation, aligning with recent ECG literature that favors CNN/TCN backbones for local morphology plus longer temporal context on ~1000-sample segments. We include class-weighted cross-entropy (to mitigate S/F rarity) and label smoothing; AMP and gradient clipping improve stability/throughput. The network is lightweight (<256K params by default), suitable for fair AAMI 5-class evaluation and inter-patient splits (e.g., de Chazal DS1/DS2).",
  "confidence": 0.9,
  "bo_parameters": [
    "lr",
    "batch_size",
    "epochs",
    "hidden_size",
    "dropout"
  ],
  "bo_search_space": {
    "lr": {
      "type": "Real",
      "low": 1e-05,
      "high": 0.1,
      "prior": "log-uniform"
    },
    "batch_size": {
      "type": "Categorical",
      "categories": [
        8,
        16,
        32,
        64,
        128
      ]
    },
    "epochs": {
      "type": "Integer",
      "low": 5,
      "high": 50
    },
    "hidden_size": {
      "type": "Integer",
      "low": 32,
      "high": 512
    },
    "dropout": {
      "type": "Real",
      "low": 0.0,
      "high": 0.7
    }
  },
  "data_profile": {
    "data_type": "numpy_array",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  },
  "timestamp": 1757984699,
  "metadata": {
    "generated_by": "AI Code Generator",
    "api_model": "gpt-5",
    "version": "1.0"
  }
}