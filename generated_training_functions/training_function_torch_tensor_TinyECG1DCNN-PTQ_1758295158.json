{
  "model_name": "TinyECG1DCNN-PTQ",
  "training_code": "def train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    import copy\n    import math\n    import torch\n    import torch.nn as nn\n    import torch.optim as optim\n    from torch.utils.data import TensorDataset, DataLoader\n    from torch.ao.quantization import get_default_qconfig, prepare, convert, fuse_modules, quantize_dynamic\n\n    # -------------------- Hyperparameters with defaults --------------------\n    hp = {\n        'lr': 1e-3,\n        'batch_size': 256,\n        'epochs': 12,\n        'weight_decay': 1e-4,\n        'optimizer': 'adam',\n        'momentum': 0.9,\n        'base_channels': 32,\n        'dropout': 0.1,\n        'ks1': 7,\n        'ks2': 5,\n        'ks3': 5,\n        'linear_hidden': 64,\n        'label_smoothing': 0.0,\n        'quantization_bits': 8,               # {8,16,32}\n        'quantize_weights': True,\n        'quantize_activations': True,\n        'calibration_batches': 64,\n        'quant_backend': 'fbgemm'             # {'fbgemm','qnnpack'}\n    }\n    hp.update(hyperparams or {})\n\n    # -------------------- Utilities --------------------\n    def to_channel_first(X):\n        # Expect either (N, 2, 1000) or (N, 1000, 2). Convert to (N, 2, L)\n        if X.ndim != 3:\n            raise ValueError(f\"Expected 3D tensor for X (N, L, C) or (N, C, L), got shape {tuple(X.shape)}\")\n        if X.shape[1] <= 4 and X.shape[2] > 4:\n            # likely (N, C, L)\n            return X.contiguous()\n        elif X.shape[2] <= 4 and X.shape[1] > 4:\n            # likely (N, L, C)\n            return X.permute(0, 2, 1).contiguous()\n        else:\n            # ambiguous shapes, try to infer by assuming channels=2\n            if X.shape[-1] == 2:\n                return X.permute(0, 2, 1).contiguous()\n            elif X.shape[1] == 2:\n                return X.contiguous()\n            else:\n                raise ValueError(f\"Cannot infer channels-last/first layout from shape {tuple(X.shape)}\")\n\n    def count_parameters(m):\n        return sum(p.numel() for p in m.parameters())\n\n    @torch.no_grad()\n    def evaluate(model, loader, device):\n        model.eval()\n        total, correct, total_loss = 0, 0, 0.0\n        ce = nn.CrossEntropyLoss(label_smoothing=hp['label_smoothing']).to(device)\n        for xb, yb in loader:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n            logits = model(xb)\n            loss = ce(logits, yb)\n            total_loss += loss.item() * xb.size(0)\n            pred = logits.argmax(dim=1)\n            correct += (pred == yb).sum().item()\n            total += xb.size(0)\n        avg_loss = total_loss / max(1, total)\n        acc = correct / max(1, total)\n        return avg_loss, acc\n\n    # -------------------- Model definition --------------------\n    class TinyECG1DCNN(nn.Module):\n        \"\"\"\n        Lightweight 1D CNN for ECG with depthwise-separable blocks to keep params < 256K.\n        Blocks:\n          - Conv1 (standard)\n          - DS-Block2: DepthwiseConv(stride=2) -> BN -> ReLU -> PointwiseConv -> BN -> ReLU\n          - DS-Block3: DepthwiseConv(stride=2) -> BN -> ReLU -> PointwiseConv -> BN -> ReLU\n        Followed by GAP -> MLP -> logits\n        \"\"\"\n        def __init__(self, input_channels=2, num_classes=5, base_channels=32, ks=(7,5,5), dropout=0.1, linear_hidden=64):\n            super().__init__()\n            k1, k2, k3 = ks\n            c1 = base_channels\n            c2 = base_channels * 2\n            c3 = base_channels * 4\n            # First stem conv\n            self.conv1 = nn.Conv1d(input_channels, c1, kernel_size=k1, stride=2, padding=k1//2, bias=False)\n            self.bn1 = nn.BatchNorm1d(c1)\n            self.relu1 = nn.ReLU(inplace=True)\n            # Depthwise-separable Block 2\n            self.dw2 = nn.Conv1d(c1, c1, kernel_size=k2, stride=2, padding=k2//2, groups=c1, bias=False)\n            self.bn2a = nn.BatchNorm1d(c1)\n            self.relu2a = nn.ReLU(inplace=True)\n            self.pw2 = nn.Conv1d(c1, c2, kernel_size=1, stride=1, padding=0, bias=False)\n            self.bn2b = nn.BatchNorm1d(c2)\n            self.relu2b = nn.ReLU(inplace=True)\n            # Depthwise-separable Block 3\n            self.dw3 = nn.Conv1d(c2, c2, kernel_size=k3, stride=2, padding=k3//2, groups=c2, bias=False)\n            self.bn3a = nn.BatchNorm1d(c2)\n            self.relu3a = nn.ReLU(inplace=True)\n            self.pw3 = nn.Conv1d(c2, c3, kernel_size=1, stride=1, padding=0, bias=False)\n            self.bn3b = nn.BatchNorm1d(c3)\n            self.relu3b = nn.ReLU(inplace=True)\n            # Head\n            self.pool = nn.AdaptiveAvgPool1d(1)\n            self.drop = nn.Dropout(dropout)\n            self.fc1 = nn.Linear(c3, linear_hidden)\n            self.relu_fc = nn.ReLU(inplace=True)\n            self.fc2 = nn.Linear(linear_hidden, num_classes)\n\n        def forward(self, x):\n            x = self.conv1(x); x = self.bn1(x); x = self.relu1(x)\n            x = self.dw2(x);   x = self.bn2a(x); x = self.relu2a(x)\n            x = self.pw2(x);   x = self.bn2b(x); x = self.relu2b(x)\n            x = self.dw3(x);   x = self.bn3a(x); x = self.relu3a(x)\n            x = self.pw3(x);   x = self.bn3b(x); x = self.relu3b(x)\n            x = self.pool(x).squeeze(-1)\n            x = self.drop(x)\n            x = self.fc1(x)\n            x = self.relu_fc(x)\n            x = self.drop(x)\n            x = self.fc2(x)\n            return x\n\n        def fuse_model(self):\n            # Fuse conv/bn/relu tuples for quantization\n            fuse_modules(self, [['conv1','bn1','relu1'],\n                               ['dw2','bn2a','relu2a'],\n                               ['pw2','bn2b','relu2b'],\n                               ['dw3','bn3a','relu3a'],\n                               ['pw3','bn3b','relu3b']], inplace=True)\n\n    # -------------------- Data prep --------------------\n    X_train = to_channel_first(X_train.float())\n    X_val = to_channel_first(X_val.float())\n    y_train = y_train.long()\n    y_val = y_val.long()\n\n    train_ds = TensorDataset(X_train, y_train)\n    val_ds = TensorDataset(X_val, y_val)\n\n    pin_mem = isinstance(device, torch.device) and device.type == 'cuda' or (isinstance(device, str) and 'cuda' in device)\n    train_loader = DataLoader(train_ds, batch_size=hp['batch_size'], shuffle=True, num_workers=0, pin_memory=pin_mem)\n    val_loader = DataLoader(val_ds, batch_size=hp['batch_size'], shuffle=False, num_workers=0, pin_memory=pin_mem)\n\n    # -------------------- Model, Optimizer, Loss --------------------\n    ks = (int(hp['ks1']), int(hp['ks2']), int(hp['ks3']))\n    model = TinyECG1DCNN(input_channels=X_train.shape[1], num_classes=5,\n                         base_channels=int(hp['base_channels']), ks=ks,\n                         dropout=float(hp['dropout']), linear_hidden=int(hp['linear_hidden']))\n    model = model.to(device)\n\n    params_count = count_parameters(model)\n    if params_count > 256_000:\n        raise RuntimeError(f\"Model parameter count {params_count} exceeds 256K limit. Reduce base_channels/linear_hidden or kernel sizes.\")\n\n    if hp['optimizer'].lower() == 'sgd':\n        optimizer = optim.SGD(model.parameters(), lr=hp['lr'], momentum=hp['momentum'], weight_decay=hp['weight_decay'])\n    else:\n        optimizer = optim.Adam(model.parameters(), lr=hp['lr'], weight_decay=hp['weight_decay'])\n\n    criterion = nn.CrossEntropyLoss(label_smoothing=float(hp['label_smoothing']))\n\n    # -------------------- Training loop --------------------\n    train_loss_hist, val_loss_hist, val_acc_hist = [], [], []\n    best_val_acc = 0.0\n\n    for epoch in range(int(hp['epochs'])):\n        model.train()\n        running_loss = 0.0\n        seen = 0\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            loss.backward()\n            optimizer.step()\n            bs = xb.size(0)\n            running_loss += loss.item() * bs\n            seen += bs\n        avg_train_loss = running_loss / max(1, seen)\n        val_loss, val_acc = evaluate(model, val_loader, device)\n        train_loss_hist.append(avg_train_loss)\n        val_loss_hist.append(val_loss)\n        val_acc_hist.append(val_acc)\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n\n    # -------------------- Post-training quantization --------------------\n    quant_bits = int(hp['quantization_bits'])\n    qw = bool(hp['quantize_weights'])\n    qa = bool(hp['quantize_activations'])\n\n    quantization_info = {\n        'quantization_bits': quant_bits,\n        'quantize_weights': qw,\n        'quantize_activations': qa,\n        'method': 'none',\n        'backend': None\n    }\n\n    # Quantization is performed on CPU\n    quantized_model = copy.deepcopy(model).to('cpu').eval()\n\n    # Strategy:\n    # - If bits==8 and qw & qa: Static PTQ with calibration (full int8 weights & activations)\n    # - If bits==8 and qw & not qa: Dynamic quantization of Linear layers (weights int8)\n    # - If bits==16: cast to fp16 (weights & activations in float16)\n    # - If bits==32 or flags don't align: return fp32 model\n    if quant_bits == 8 and qw and qa:\n        # Static quantization via eager mode PTQ\n        torch.backends.quantized.engine = hp['quant_backend']\n        quantized_model.fuse_model()\n        quantized_model.qconfig = get_default_qconfig(hp['quant_backend'])\n        prepare(quantized_model, inplace=True)\n        # Calibration on a subset of training data (CPU)\n        cal_loader = DataLoader(train_ds, batch_size=hp['batch_size'], shuffle=True, num_workers=0)\n        with torch.no_grad():\n            for i, (xb, _) in enumerate(cal_loader):\n                if i >= int(hp['calibration_batches']):\n                    break\n                xb = to_channel_first(xb.float()).to('cpu')\n                quantized_model(xb)\n        convert(quantized_model, inplace=True)\n        quantization_info['method'] = 'static_int8_ptq'\n        quantization_info['backend'] = hp['quant_backend']\n    elif quant_bits == 8 and qw and not qa:\n        # Dynamic quantization for Linear layers only (Conv not supported dynamically)\n        quantized_model = quantize_dynamic(quantized_model, {nn.Linear}, dtype=torch.qint8)\n        quantization_info['method'] = 'dynamic_int8_linear_only'\n        quantization_info['backend'] = 'dynamic'\n    elif quant_bits == 16:\n        # FP16 cast (note: CPU support is limited; best used on CUDA for inference)\n        try:\n            quantized_model = quantized_model.half()\n            quantization_info['method'] = 'fp16_cast'\n            quantization_info['backend'] = 'fp16'\n        except Exception:\n            # Fallback: keep FP32 if fp16 unsupported\n            quantization_info['method'] = 'none_fp16_failed'\n            quantization_info['backend'] = None\n    else:\n        # 32-bit or unsupported combination: keep FP32\n        quantization_info['method'] = 'none_fp32'\n        quantization_info['backend'] = None\n\n    metrics = {\n        'train_loss_history': train_loss_hist,\n        'val_loss_history': val_loss_hist,\n        'val_acc_history': val_acc_hist,\n        'best_val_acc': best_val_acc,\n        'params_count': int(params_count),\n        'quantization': quantization_info\n    }\n\n    return quantized_model, metrics\n",
  "bo_config": {
    "lr": {
      "default": 0.001,
      "type": "Real",
      "low": 1e-05,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "batch_size": {
      "default": 256,
      "type": "Categorical",
      "categories": [
        64,
        128,
        256,
        512
      ]
    },
    "epochs": {
      "default": 12,
      "type": "Integer",
      "low": 5,
      "high": 50
    },
    "weight_decay": {
      "default": 0.0001,
      "type": "Real",
      "low": 1e-08,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "optimizer": {
      "default": "adam",
      "type": "Categorical",
      "categories": [
        "adam",
        "sgd"
      ]
    },
    "momentum": {
      "default": 0.9,
      "type": "Real",
      "low": 0.0,
      "high": 0.95
    },
    "base_channels": {
      "default": 32,
      "type": "Integer",
      "low": 16,
      "high": 64
    },
    "dropout": {
      "default": 0.1,
      "type": "Real",
      "low": 0.0,
      "high": 0.5
    },
    "ks1": {
      "default": 7,
      "type": "Integer",
      "low": 3,
      "high": 11
    },
    "ks2": {
      "default": 5,
      "type": "Integer",
      "low": 3,
      "high": 11
    },
    "ks3": {
      "default": 5,
      "type": "Integer",
      "low": 3,
      "high": 11
    },
    "linear_hidden": {
      "default": 64,
      "type": "Integer",
      "low": 32,
      "high": 256
    },
    "label_smoothing": {
      "default": 0.0,
      "type": "Real",
      "low": 0.0,
      "high": 0.2
    },
    "quantization_bits": {
      "default": 8,
      "type": "Categorical",
      "categories": [
        8,
        16,
        32
      ]
    },
    "quantize_weights": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "quantize_activations": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "calibration_batches": {
      "default": 64,
      "type": "Integer",
      "low": 8,
      "high": 128
    },
    "quant_backend": {
      "default": "fbgemm",
      "type": "Categorical",
      "categories": [
        "fbgemm",
        "qnnpack"
      ]
    }
  },
  "confidence": 0.86,
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  },
  "timestamp": 1758295158,
  "metadata": {
    "generated_by": "AI Code Generator",
    "api_model": "gpt-5",
    "version": "1.0"
  }
}