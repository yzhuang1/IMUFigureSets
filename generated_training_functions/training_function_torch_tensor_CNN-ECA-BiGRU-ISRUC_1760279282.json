{
  "model_name": "CNN-ECA-BiGRU-ISRUC",
  "training_code": "def train_model(X_train, y_train, X_val, y_val, device, **kwargs):\n    import torch\n    from torch.utils.data import TensorDataset, DataLoader\n    from torch import nn, optim\n    import torch.nn.functional as F\n    import torch.ao.quantization as tq\n    import math\n    import time\n    import copy\n\n    # --------------------\n    # Hyperparameters with defaults (can be overridden via kwargs)\n    # --------------------\n    hp = {\n        'lr': 1e-3,\n        'weight_decay': 1e-4,\n        'epochs': 15,\n        'batch_size': 8,\n        'dropout': 0.1,\n        'base_channels': 16,\n        'eca_kernel': 3,\n        'pool_stride': 4,\n        'label_smoothing': 0.05,\n        'grad_clip_norm': 1.0,\n        'scheduler_step_size': 0,\n        'scheduler_gamma': 0.5,\n        'num_workers': 4,\n        'use_amp': True,\n        'quantization_bits': 8,\n        'quantize_weights': True,\n        'quantize_activations': True,  # ignored in dynamic path\n        'calibrate_batches': 4,        # ignored in dynamic path\n    }\n    hp.update(kwargs or {})\n\n    # --------------------\n    # Helpers\n    # --------------------\n    def _to_tensor(x, dtype=None):\n        if isinstance(x, torch.Tensor):\n            return x.to(dtype=dtype) if dtype is not None else x\n        return torch.as_tensor(x, dtype=dtype)\n\n    def _normalize_targets(y, num_classes):\n        # Robustly extract label tensor from possibly nested structures\n        while isinstance(y, (list, tuple)):\n            y = y[0]\n        if not isinstance(y, torch.Tensor):\n            y = torch.as_tensor(y)\n        if y.ndim > 1:\n            if y.size(-1) == num_classes:\n                y = y.argmax(dim=-1)\n            else:\n                y = y.squeeze()\n        return y.long()\n\n    def _extract_xy(batch):\n        # Robustly unpack (xb, yb) from possibly nested tuples/lists\n        if isinstance(batch, (list, tuple)):\n            xb = batch[0]\n            yb = batch[1] if len(batch) > 1 else None\n        else:\n            xb, yb = batch, None\n        while isinstance(xb, (list, tuple)):\n            xb = xb[0]\n        while isinstance(yb, (list, tuple)):\n            yb = yb[0]\n        return xb, yb\n\n    # --------------------\n    # Device handling and checks\n    # --------------------\n    device = torch.device(device)\n    if device.type != 'cuda':\n        raise RuntimeError('This training function requires a CUDA device. Pass device=\"cuda\" or torch.device(\"cuda\").')\n\n    torch.backends.cudnn.benchmark = True\n\n    num_classes = 5\n\n    # --------------------\n    # Convert inputs to tensors and normalize shapes/dtypes\n    # Expect X_*: (N, 6, 6000), y_*: (N,) with class indices 0..4 or 1-hot (N,5)\n    # --------------------\n    X_train = _to_tensor(X_train, dtype=torch.float32)\n    X_val = _to_tensor(X_val, dtype=torch.float32)\n    y_train = _normalize_targets(y_train, num_classes)\n    y_val = _normalize_targets(y_val, num_classes)\n\n    if X_train.ndim != 3:\n        raise ValueError(f'X_train must be 3D (N, C=6, L=6000). Got shape {tuple(X_train.shape)}')\n    if X_val.ndim != 3:\n        raise ValueError(f'X_val must be 3D (N, C=6, L=6000). Got shape {tuple(X_val.shape)}')\n    if X_train.shape[1] != 6 or X_val.shape[1] != 6:\n        raise ValueError('Expected 6 EEG channels.')\n    if X_train.shape[2] != 6000 or X_val.shape[2] != 6000:\n        raise ValueError('Expected sequence length 6000 per epoch.')\n    if y_train.ndim != 1 or y_val.ndim != 1:\n        raise ValueError('y_train and y_val must be 1D label tensors of shape (N,) after normalization.')\n    if X_train.shape[0] != y_train.shape[0] or X_val.shape[0] != y_val.shape[0]:\n        raise ValueError('Mismatched number of samples between X and y.')\n\n    # --------------------\n    # Datasets and DataLoaders (avoid custom multiprocessing context to reduce edge cases)\n    # --------------------\n    train_ds = TensorDataset(X_train, y_train)\n    val_ds = TensorDataset(X_val, y_val)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=int(hp['batch_size']),\n        shuffle=True,\n        num_workers=int(hp['num_workers']),\n        pin_memory=True,\n        drop_last=False,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=max(1, int(hp['batch_size']) // 2),\n        shuffle=False,\n        num_workers=int(hp['num_workers']),\n        pin_memory=True,\n        drop_last=False,\n    )\n\n    # --------------------\n    # Model definition\n    # --------------------\n    class ChannelECA(nn.Module):\n        def __init__(self, channels: int, k: int = 3):\n            super().__init__()\n            k = max(1, k)\n            if k % 2 == 0:\n                k += 1\n            self.avg_pool = nn.AdaptiveAvgPool1d(1)\n            self.conv = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1) // 2, bias=False)\n            self.sig = nn.Sigmoid()\n\n        def forward(self, x):  # x: (B, C, L)\n            y = self.avg_pool(x)            # (B, C, 1)\n            y = y.permute(0, 2, 1)          # (B, 1, C)\n            y = self.conv(y)                # (B, 1, C)\n            y = self.sig(y).permute(0, 2, 1)  # (B, C, 1)\n            return x * y                    # broadcast over L\n\n    class DepthwiseSeparableConv1d(nn.Module):\n        def __init__(self, in_ch: int, out_ch: int, k: int = 7, stride: int = 1, p: float = 0.0):\n            super().__init__()\n            pad = (k - 1) // 2\n            self.dw = nn.Conv1d(in_ch, in_ch, kernel_size=k, stride=stride, padding=pad, groups=in_ch, bias=False)\n            self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.act = nn.GELU()\n            self.drop = nn.Dropout(p)\n        def forward(self, x):\n            x = self.dw(x)\n            x = self.pw(x)\n            x = self.bn(x)\n            x = self.act(x)\n            x = self.drop(x)\n            return x\n\n    class ConvBlock(nn.Module):\n        def __init__(self, in_ch, out_ch, k=5, s=2, p: float = 0.0):\n            super().__init__()\n            pad = (k - 1) // 2\n            self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=pad, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.act = nn.GELU()\n            self.drop = nn.Dropout(p)\n        def forward(self, x):\n            x = self.conv(x)\n            x = self.bn(x)\n            x = self.act(x)\n            x = self.drop(x)\n            return x\n\n    class ClassifierHead(nn.Module):\n        def __init__(self, in_dim, hidden, out_dim, p: float = 0.1):\n            super().__init__()\n            # Removed QuantStub/DeQuantStub to avoid static quantization issues\n            self.fc1 = nn.Linear(in_dim, hidden)\n            self.act = nn.GELU()\n            self.drop = nn.Dropout(p)\n            self.fc2 = nn.Linear(hidden, out_dim)\n        def forward(self, x):  # x: (B, in_dim)\n            x = self.fc1(x)\n            x = self.act(x)\n            x = self.drop(x)\n            x = self.fc2(x)\n            return x\n\n    class EEGSleepNet(nn.Module):\n        def __init__(self, base_channels=16, eca_k=3, pool_stride=4, dropout=0.1, num_classes=5):\n            super().__init__()\n            self.eca = ChannelECA(6, k=eca_k)\n            c1 = base_channels\n            c2 = base_channels * 2\n            c3 = base_channels * 4\n            self.conv1 = ConvBlock(6, c1, k=7, s=2, p=dropout)\n            self.conv2 = ConvBlock(c1, c2, k=5, s=2, p=dropout)\n            self.conv3 = ConvBlock(c2, c3, k=5, s=2, p=dropout)\n            self.ds = DepthwiseSeparableConv1d(c3, c3, k=7, stride=1, p=dropout)\n            self.pool = nn.AvgPool1d(kernel_size=pool_stride, stride=pool_stride)\n\n            d_model = c3\n            self.bigru = nn.GRU(input_size=d_model, hidden_size=d_model, num_layers=1, batch_first=False, bidirectional=True)\n\n            head_in = d_model * 2\n            head_hidden = max(32, d_model)\n            self.head = ClassifierHead(head_in, head_hidden, num_classes, p=dropout)\n\n        def forward(self, x):  # x: (B, 6, 6000)\n            x = self.eca(x)\n            x = self.conv1(x)\n            x = self.conv2(x)\n            x = self.conv3(x)\n            x = self.ds(x)\n            x = self.pool(x)  # (B, C, L')\n            x = x.transpose(1, 2)  # (B, L', C)\n            x = x.transpose(0, 1)  # (L', B, C)\n            out, _ = self.bigru(x)  # (L', B, 2C)\n            out = out.mean(dim=0)   # (B, 2C)\n            logits = self.head(out) # (B, num_classes)\n            return logits\n\n    # --------------------\n    # Instantiate model\n    # --------------------\n    model = EEGSleepNet(\n        base_channels=int(hp['base_channels']),\n        eca_k=int(hp['eca_kernel']),\n        pool_stride=int(hp['pool_stride']),\n        dropout=float(hp['dropout']),\n        num_classes=num_classes,\n    ).to(device)\n\n    # --------------------\n    # Optimizer, loss, scheduler\n    # --------------------\n    optimizer = optim.AdamW(model.parameters(), lr=float(hp['lr']), weight_decay=float(hp['weight_decay']))\n    criterion = nn.CrossEntropyLoss(label_smoothing=float(hp['label_smoothing'])).to(device)\n\n    scheduler = None\n    if int(hp['scheduler_step_size']) > 0:\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=int(hp['scheduler_step_size']), gamma=float(hp['scheduler_gamma']))\n\n    scaler = torch.cuda.amp.GradScaler(enabled=bool(hp['use_amp']))\n\n    # --------------------\n    # Training loop\n    # --------------------\n    train_losses, val_losses, val_accs = [], [], []\n\n    for epoch in range(1, int(hp['epochs']) + 1):\n        model.train()\n        epoch_loss = 0.0\n        n_train = 0\n        t0 = time.time()\n\n        for batch in train_loader:\n            xb, yb = _extract_xy(batch)\n\n            # Normalize targets\n            yb = _normalize_targets(yb, num_classes)\n\n            xb = xb.to(device, non_blocking=True).float()\n            yb = yb.to(device, non_blocking=True)\n\n            optimizer.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=bool(hp['use_amp'])):\n                logits = model(xb)\n                loss = criterion(logits, yb)\n\n            scaler.scale(loss).backward()\n            if hp['grad_clip_norm'] is not None and float(hp['grad_clip_norm']) > 0:\n                scaler.unscale_(optimizer)\n                nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(hp['grad_clip_norm']))\n            scaler.step(optimizer)\n            scaler.update()\n\n            batch_size_now = xb.size(0)\n            epoch_loss += loss.detach().item() * batch_size_now\n            n_train += batch_size_now\n\n        if scheduler is not None:\n            scheduler.step()\n\n        train_loss = epoch_loss / max(1, n_train)\n\n        # Validation\n        model.eval()\n        val_loss = 0.0\n        n_val = 0\n        correct = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                xb, yb = _extract_xy(batch)\n                yb = _normalize_targets(yb, num_classes)\n\n                xb = xb.to(device, non_blocking=True).float()\n                yb = yb.to(device, non_blocking=True)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                val_loss += loss.detach().item() * xb.size(0)\n                n_val += xb.size(0)\n                pred = logits.argmax(dim=1)\n                correct += (pred == yb).sum().item()\n\n        val_loss = val_loss / max(1, n_val)\n        val_acc = correct / max(1, n_val)\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n\n        print(f'Epoch {epoch:03d}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f} time={time.time()-t0:.1f}s')\n\n    # --------------------\n    # Post-Training Quantization (Dynamic quantization only for stability)\n    # --------------------\n    model_cpu = copy.deepcopy(model).to('cpu')\n    model_cpu.eval()\n\n    qb = int(hp['quantization_bits'])\n    qw = bool(hp['quantize_weights'])\n\n    if qw and qb == 8:\n        # Dynamic quantization for Linear and GRU layers\n        model_cpu = tq.quantize_dynamic(\n            model_cpu,\n            {nn.Linear, nn.GRU},\n            dtype=torch.qint8,\n            inplace=True\n        )\n    elif qw and qb == 16:\n        # Half precision weights\n        model_cpu = model_cpu.half()\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs\n    }\n\n    return model_cpu, metrics\n",
  "bo_config": {
    "lr": {
      "default": 0.001,
      "type": "Real",
      "low": 1e-05,
      "high": 0.005,
      "prior": "log-uniform"
    },
    "weight_decay": {
      "default": 0.0001,
      "type": "Real",
      "low": 1e-06,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "epochs": {
      "default": 15,
      "type": "Integer",
      "low": 5,
      "high": 50
    },
    "batch_size": {
      "default": 8,
      "type": "Categorical",
      "categories": [
        4,
        8,
        12,
        16
      ]
    },
    "dropout": {
      "default": 0.1,
      "type": "Real",
      "low": 0.0,
      "high": 0.5
    },
    "base_channels": {
      "default": 16,
      "type": "Integer",
      "low": 8,
      "high": 32
    },
    "eca_kernel": {
      "default": 3,
      "type": "Categorical",
      "categories": [
        3,
        5
      ]
    },
    "pool_stride": {
      "default": 4,
      "type": "Categorical",
      "categories": [
        3,
        4,
        5
      ]
    },
    "label_smoothing": {
      "default": 0.05,
      "type": "Real",
      "low": 0.0,
      "high": 0.1
    },
    "grad_clip_norm": {
      "default": 1.0,
      "type": "Real",
      "low": 0.5,
      "high": 5.0
    },
    "scheduler_step_size": {
      "default": 0,
      "type": "Integer",
      "low": 0,
      "high": 10
    },
    "scheduler_gamma": {
      "default": 0.5,
      "type": "Real",
      "low": 0.1,
      "high": 0.99
    },
    "num_workers": {
      "default": 4,
      "type": "Categorical",
      "categories": [
        4
      ]
    },
    "use_amp": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "quantization_bits": {
      "default": 8,
      "type": "Categorical",
      "categories": [
        8,
        16,
        32
      ]
    },
    "quantize_weights": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "quantize_activations": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "calibrate_batches": {
      "default": 4,
      "type": "Integer",
      "low": 1,
      "high": 8
    }
  },
  "confidence": 0.86,
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      89283,
      6,
      6000
    ],
    "dtype": "float32",
    "feature_count": 6000,
    "sample_count": 89283,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  },
  "timestamp": 1760279282,
  "metadata": {
    "generated_by": "AI Code Generator",
    "api_model": "gpt-5",
    "version": "1.0"
  }
}