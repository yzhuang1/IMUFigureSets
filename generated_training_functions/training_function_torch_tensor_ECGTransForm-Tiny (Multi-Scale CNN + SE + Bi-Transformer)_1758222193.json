{
  "model_name": "ECGTransForm-Tiny (Multi-Scale CNN + SE + Bi-Transformer)",
  "training_code": "import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\ndef train_model(X_train, y_train, X_val, y_val, device, **hyperparams):\n    \"\"\"\n    Train a lightweight ECGTransForm-like model for 5-class classification on (length=1000, in_channels=2) signals.\n\n    Args:\n        X_train, y_train, X_val, y_val: torch.Tensor\n            - X_* shape: (N, 1000, 2) or (N, 2, 1000)\n            - y_* shape: (N,), dtype long with labels [0..C-1]\n        device: torch.device\n        **hyperparams: model and training hyperparameters\n\n    Returns:\n        model: trained PyTorch model\n        metrics: dict with final training/validation loss, accuracy, macro-F1, and parameter count\n    \"\"\"\n    # =====================\n    # Defaults and parsing\n    # =====================\n    hp = {\n        'lr': 1e-3,\n        'batch_size': 128,\n        'epochs': 20,\n        'd_model': 64,\n        'num_heads': 4,\n        'num_transformer_layers': 2,\n        'ms_channels': 16,  # channels per multi-scale branch\n        'ff_mult': 3,       # feed-forward dimension multiplier\n        'dropout': 0.1,\n        'se_reduction': 8,\n        'focal_gamma': 2.0,\n        'class_balance_beta': 0.999,\n        'weight_decay': 1e-4,\n        'label_smoothing': 0.0,\n        'max_grad_norm': 1.0,\n    }\n    hp.update(hyperparams or {})\n\n    # =====================\n    # Helpers\n    # =====================\n    def ensure_channel_first(x):\n        # Accept (N, 1000, 2) or (N, 2, 1000)\n        if x.dim() != 3:\n            raise ValueError('X tensors must be 3D: (N, L, C) or (N, C, L)')\n        if x.shape[-1] == 2:  # (N, L, C)\n            return x.permute(0, 2, 1).contiguous()\n        elif x.shape[1] == 2:  # (N, C, L)\n            return x\n        else:\n            raise ValueError('Expected 2 input channels; got shape {}'.format(list(x.shape)))\n\n    def count_parameters(model):\n        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n    def make_class_weights(y, num_classes, beta=0.999):\n        # Effective number of samples (Cui et al., Class-Balanced Loss)\n        y = y.view(-1)\n        counts = torch.bincount(y, minlength=num_classes).float()\n        counts = torch.clamp(counts, min=1.0)\n        eff_num = 1.0 - torch.pow(torch.tensor(beta, device=counts.device), counts)\n        weights = (1.0 - beta) / eff_num\n        weights = weights / weights.sum() * num_classes  # normalize\n        return weights\n\n    class FocalLoss(nn.Module):\n        def __init__(self, num_classes, alpha=None, gamma=2.0, label_smoothing=0.0):\n            super().__init__()\n            self.num_classes = num_classes\n            if alpha is None:\n                alpha = torch.ones(num_classes)\n            self.register_buffer('alpha', alpha)\n            self.gamma = gamma\n            self.ls = label_smoothing\n        def forward(self, logits, target):\n            # logits: (B, C), target: (B,)\n            log_probs = F.log_softmax(logits, dim=-1)\n            probs = log_probs.exp()\n            if self.ls > 0.0:\n                # label smoothing: uniform on non-target classes\n                smooth = self.ls / (self.num_classes - 1)\n                true_dist = torch.zeros_like(log_probs).fill_(smooth)\n                true_dist.scatter_(1, target.unsqueeze(1), 1.0 - self.ls)\n                p_t = (probs * true_dist).sum(dim=-1)\n                alpha_t = (self.alpha.unsqueeze(0) * true_dist).sum(dim=-1)\n                focal_factor = (1.0 - p_t).pow(self.gamma)\n                loss = -alpha_t * focal_factor * (log_probs * true_dist).sum(dim=-1)\n            else:\n                # standard focal on hard target\n                pt = probs.gather(1, target.unsqueeze(1)).squeeze(1)\n                log_pt = log_probs.gather(1, target.unsqueeze(1)).squeeze(1)\n                alpha_t = self.alpha.gather(0, target)\n                focal_factor = (1.0 - pt).pow(self.gamma)\n                loss = -alpha_t * focal_factor * log_pt\n            return loss.mean()\n\n    class SqueezeExcite1D(nn.Module):\n        def __init__(self, channels, reduction=8):\n            super().__init__()\n            hidden = max(1, channels // reduction)\n            self.pool = nn.AdaptiveAvgPool1d(1)\n            self.fc1 = nn.Conv1d(channels, hidden, kernel_size=1)\n            self.fc2 = nn.Conv1d(hidden, channels, kernel_size=1)\n        def forward(self, x):\n            s = self.pool(x)\n            s = F.relu(self.fc1(s), inplace=True)\n            s = torch.sigmoid(self.fc2(s))\n            return x * s\n\n    class PositionalEncoding(nn.Module):\n        def __init__(self, d_model, max_len=3000):\n            super().__init__()\n            pe = torch.zeros(max_len, d_model)\n            position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n            div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n            pe[:, 0::2] = torch.sin(position * div_term)\n            pe[:, 1::2] = torch.cos(position * div_term)\n            self.register_buffer('pe', pe.unsqueeze(0))  # (1, L, D)\n        def forward(self, x):  # x: (B, L, D)\n            L = x.size(1)\n            return x + self.pe[:, :L]\n\n    class MultiScaleCNNFront(nn.Module):\n        def __init__(self, in_ch=2, out_d=64, branch_ch=16, kernels=(3,5,7), dropout=0.1, se_reduction=8):\n            super().__init__()\n            branches = []\n            for k in kernels:\n                pad = k // 2\n                branches.append(nn.Sequential(\n                    nn.Conv1d(in_ch, branch_ch, kernel_size=k, stride=2, padding=pad, bias=False),\n                    nn.BatchNorm1d(branch_ch),\n                    nn.GELU(),\n                    nn.Conv1d(branch_ch, branch_ch, kernel_size=3, padding=1, groups=branch_ch, bias=False),  # depthwise\n                    nn.BatchNorm1d(branch_ch),\n                    nn.GELU(),\n                    nn.MaxPool1d(kernel_size=2, stride=2)\n                ))\n            self.branches = nn.ModuleList(branches)\n            concat_ch = branch_ch * len(kernels)\n            self.se = SqueezeExcite1D(concat_ch, reduction=se_reduction)\n            self.proj = nn.Conv1d(concat_ch, out_d, kernel_size=1, bias=False)\n            self.bn = nn.BatchNorm1d(out_d)\n            self.dropout = nn.Dropout(dropout)\n        def forward(self, x):  # x: (B, C, L)\n            xs = [b(x) for b in self.branches]\n            x = torch.cat(xs, dim=1)  # (B, concat_ch, L//4)\n            x = self.se(x)\n            x = self.proj(x)\n            x = self.bn(x)\n            x = F.gelu(x)\n            x = self.dropout(x)\n            return x  # (B, D, L')\n\n    class ECGTransFormTiny(nn.Module):\n        def __init__(self, in_ch, num_classes, d_model=64, n_heads=4, n_layers=2, ff_mult=3, dropout=0.1, ms_channels=16, se_reduction=8):\n            super().__init__()\n            self.front = MultiScaleCNNFront(in_ch=in_ch, out_d=d_model, branch_ch=ms_channels, dropout=dropout, se_reduction=se_reduction)\n            self.pos = PositionalEncoding(d_model)\n            encoder_layer = nn.TransformerEncoderLayer(\n                d_model=d_model,\n                nhead=n_heads,\n                dim_feedforward=ff_mult * d_model,\n                dropout=dropout,\n                activation='gelu',\n                batch_first=True,\n                norm_first=True,\n            )\n            self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n            self.norm = nn.LayerNorm(d_model)\n            self.head = nn.Linear(d_model, num_classes)\n        def forward(self, x):  # x: (B, C, L)\n            x = self.front(x)            # (B, D, L')\n            x = x.transpose(1, 2)        # (B, L', D)\n            x = self.pos(x)              # add positional encodings\n            x = self.encoder(x)          # (B, L', D)\n            x = self.norm(x)\n            x = x.mean(dim=1)            # global average pooling over time\n            logits = self.head(x)        # (B, C)\n            return logits\n\n    def adjust_heads(d_model, n_heads):\n        n_heads = min(int(n_heads), int(d_model))\n        if n_heads < 1:\n            n_heads = 1\n        # ensure divisibility by reducing to a divisor\n        for h in [8, 6, 5, 4, 3, 2, 1]:\n            if n_heads >= h and d_model % h == 0:\n                return h\n        # fallback\n        return 1\n\n    # =====================\n    # Data prep\n    # =====================\n    X_train = ensure_channel_first(X_train)\n    X_val = ensure_channel_first(X_val)\n    num_classes = int(max(int(y_train.max().item()), int(y_val.max().item()))) + 1\n\n    train_ds = TensorDataset(X_train, y_train.long())\n    val_ds = TensorDataset(X_val, y_val.long())\n\n    train_loader = DataLoader(train_ds, batch_size=hp['batch_size'], shuffle=True, drop_last=False)\n    val_loader = DataLoader(val_ds, batch_size=hp['batch_size'], shuffle=False, drop_last=False)\n\n    # =====================\n    # Model, loss, optimizer\n    # =====================\n    d_model = int(hp['d_model'])\n    n_heads = adjust_heads(d_model, hp['num_heads'])\n    n_layers = int(hp['num_transformer_layers'])\n    ff_mult = int(hp['ff_mult'])\n\n    model = ECGTransFormTiny(\n        in_ch=2, num_classes=num_classes, d_model=d_model, n_heads=n_heads,\n        n_layers=n_layers, ff_mult=ff_mult, dropout=hp['dropout'],\n        ms_channels=int(hp['ms_channels']), se_reduction=int(hp['se_reduction'])\n    ).to(device)\n\n    # Class-balanced alpha for focal loss\n    with torch.no_grad():\n        alpha = make_class_weights(y_train.to(device), num_classes, beta=float(hp['class_balance_beta']))\n    criterion = FocalLoss(num_classes=num_classes, alpha=alpha, gamma=float(hp['focal_gamma']), label_smoothing=float(hp['label_smoothing']))\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=float(hp['lr']), weight_decay=float(hp['weight_decay']))\n\n    # =====================\n    # Training utilities\n    # =====================\n    def step(loader, train=True):\n        if train:\n            model.train()\n        else:\n            model.eval()\n        total_loss = 0.0\n        total_correct = 0\n        total_samples = 0\n        all_preds = []\n        all_targets = []\n        for xb, yb in loader:\n            xb = xb.to(device)\n            yb = yb.to(device)\n            if train:\n                optimizer.zero_grad(set_to_none=True)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                loss.backward()\n                if hp['max_grad_norm'] and hp['max_grad_norm'] > 0:\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), float(hp['max_grad_norm']))\n                optimizer.step()\n            else:\n                with torch.no_grad():\n                    logits = model(xb)\n                    loss = criterion(logits, yb)\n            total_loss += loss.item() * xb.size(0)\n            preds = logits.argmax(dim=-1)\n            total_correct += (preds == yb).sum().item()\n            total_samples += xb.size(0)\n            all_preds.append(preds.detach().cpu())\n            all_targets.append(yb.detach().cpu())\n        avg_loss = total_loss / max(1, total_samples)\n        acc = total_correct / max(1, total_samples)\n        preds = torch.cat(all_preds, dim=0)\n        targets = torch.cat(all_targets, dim=0)\n        macro_f1, f1_per_class = compute_macro_f1(preds, targets, num_classes)\n        return avg_loss, acc, macro_f1, f1_per_class\n\n    def compute_macro_f1(preds, targets, C):\n        # Confusion components per class\n        f1s = []\n        for c in range(C):\n            tp = ((preds == c) & (targets == c)).sum().item()\n            fp = ((preds == c) & (targets != c)).sum().item()\n            fn = ((preds != c) & (targets == c)).sum().item()\n            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n            f1s.append(f1)\n        macro_f1 = float(sum(f1s) / len(f1s)) if f1s else 0.0\n        return macro_f1, f1s\n\n    # =====================\n    # Train loop\n    # =====================\n    history = {\n        'train_loss': [], 'val_loss': [], 'val_accuracy': [], 'val_macro_f1': []\n    }\n\n    for epoch in range(int(hp['epochs'])):\n        train_loss, train_acc, train_f1, _ = step(train_loader, train=True)\n        val_loss, val_acc, val_f1, f1_per_class = step(val_loader, train=False)\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_accuracy'].append(val_acc)\n        history['val_macro_f1'].append(val_f1)\n\n    metrics = {\n        'params_count': count_parameters(model),\n        'final_train_loss': history['train_loss'][-1] if history['train_loss'] else None,\n        'final_val_loss': history['val_loss'][-1] if history['val_loss'] else None,\n        'final_val_accuracy': history['val_accuracy'][-1] if history['val_accuracy'] else None,\n        'final_val_macro_f1': history['val_macro_f1'][-1] if history['val_macro_f1'] else None,\n        'history': history,\n    }\n\n    return model, metrics\n",
  "bo_config": {
    "lr": {
      "default": 0.001,
      "type": "Real",
      "low": 1e-05,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "batch_size": {
      "default": 128,
      "type": "Categorical",
      "categories": [
        32,
        64,
        128,
        256
      ]
    },
    "epochs": {
      "default": 20,
      "type": "Integer",
      "low": 10,
      "high": 50
    },
    "d_model": {
      "default": 64,
      "type": "Integer",
      "low": 48,
      "high": 96
    },
    "num_heads": {
      "default": 4,
      "type": "Categorical",
      "categories": [
        1,
        2,
        3,
        4
      ]
    },
    "num_transformer_layers": {
      "default": 2,
      "type": "Integer",
      "low": 1,
      "high": 3
    },
    "ms_channels": {
      "default": 16,
      "type": "Integer",
      "low": 8,
      "high": 24
    },
    "ff_mult": {
      "default": 3,
      "type": "Integer",
      "low": 2,
      "high": 3
    },
    "dropout": {
      "default": 0.1,
      "type": "Real",
      "low": 0.0,
      "high": 0.5
    },
    "se_reduction": {
      "default": 8,
      "type": "Integer",
      "low": 4,
      "high": 16
    },
    "focal_gamma": {
      "default": 2.0,
      "type": "Real",
      "low": 1.0,
      "high": 3.0
    },
    "class_balance_beta": {
      "default": 0.999,
      "type": "Real",
      "low": 0.9,
      "high": 0.9999
    },
    "weight_decay": {
      "default": 0.0001,
      "type": "Real",
      "low": 1e-06,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "label_smoothing": {
      "default": 0.0,
      "type": "Real",
      "low": 0.0,
      "high": 0.1
    },
    "max_grad_norm": {
      "default": 1.0,
      "type": "Real",
      "low": 0.5,
      "high": 5.0
    }
  },
  "confidence": 0.84,
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  },
  "timestamp": 1758222193,
  "metadata": {
    "generated_by": "AI Code Generator",
    "api_model": "gpt-5",
    "version": "1.0"
  }
}