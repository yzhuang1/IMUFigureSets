{
  "model_name": "ECGTransForm-Light-1D-CNN-BiTransformer",
  "training_code": "import math\nimport io\nfrom typing import Dict, Any\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# -------------------------------\n# Model components\n# -------------------------------\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model: int, max_len: int = 5000, dropout: float = 0.0):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):  # x: (B, L, D)\n        x = x + self.pe[:, :x.size(1), :]\n        return self.dropout(x)\n\nclass MultiScaleConvStem(nn.Module):\n    def __init__(self, in_channels: int, branch_channels: int, kernel_sizes=(3,5,7), activation='relu', norm=True):\n        super().__init__()\n        self.branches = nn.ModuleList()\n        padding_modes = []\n        for k in kernel_sizes:\n            pad = k // 2\n            conv = nn.Conv1d(in_channels, branch_channels, kernel_size=k, stride=1, padding=pad, bias=not norm)\n            seq = [conv]\n            if norm:\n                seq.append(nn.BatchNorm1d(branch_channels))\n            if activation == 'relu':\n                seq.append(nn.ReLU(inplace=True))\n            elif activation == 'gelu':\n                seq.append(nn.GELU())\n            else:\n                seq.append(nn.ReLU(inplace=True))\n            self.branches.append(nn.Sequential(*seq))\n        self.out_channels = branch_channels * len(kernel_sizes)\n\n    def forward(self, x):  # x: (B, C, L)\n        outs = [b(x) for b in self.branches]\n        return torch.cat(outs, dim=1)  # (B, C_out, L)\n\nclass ECGTransformerClassifier(nn.Module):\n    def __init__(\n        self,\n        in_channels: int = 2,\n        seq_len: int = 1000,\n        num_classes: int = 5,\n        d_model: int = 64,\n        n_heads: int = 4,\n        num_layers: int = 2,\n        dim_ff: int = 128,\n        dropout: float = 0.1,\n        stem_branch_channels: int = 12,\n        stem_kernel_sizes=(3,5,7),\n        pool_type: str = 'mean'\n    ):\n        super().__init__()\n        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n        self.seq_len = seq_len\n        self.pool_type = pool_type\n        self.stem = MultiScaleConvStem(in_channels, stem_branch_channels, kernel_sizes=stem_kernel_sizes, activation='gelu', norm=True)\n        self.proj = nn.Conv1d(self.stem.out_channels, d_model, kernel_size=1)\n        self.posenc = PositionalEncoding(d_model, max_len=seq_len, dropout=dropout)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=n_heads,\n            dim_feedforward=dim_ff,\n            dropout=dropout,\n            batch_first=True,\n            activation='gelu',\n            norm_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.dropout = nn.Dropout(dropout)\n        self.cls = nn.Linear(d_model, num_classes)\n\n    def forward(self, x):  # x: (B, C, L)\n        # stem\n        x = self.stem(x)                 # (B, C1, L)\n        x = self.proj(x)                 # (B, d_model, L)\n        x = x.transpose(1, 2).contiguous()  # (B, L, d_model)\n        x = self.posenc(x)               # (B, L, d_model)\n        x = self.encoder(x)              # (B, L, d_model)\n        if self.pool_type == 'mean':\n            x = x.mean(dim=1)            # (B, d_model)\n        elif self.pool_type == 'max':\n            x, _ = x.max(dim=1)\n        else:  # mean+max concat then project back\n            x_mean = x.mean(dim=1)\n            x_max, _ = x.max(dim=1)\n            x = 0.5 * (x_mean + x_max)\n        x = self.dropout(x)\n        logits = self.cls(x)             # (B, num_classes)\n        return logits\n\n# -------------------------------\n# Dataset wrapper\n# -------------------------------\nclass ECGTensorDataset(Dataset):\n    def __init__(self, X: torch.Tensor, y: torch.Tensor, seq_len: int = 1000):\n        super().__init__()\n        assert X.dim() == 3, \"X must be (N, 1000, C=2) or (N, C=2, 1000)\"\n        self.seq_len = seq_len\n        # Ensure channel-first: (N, C, L)\n        if X.shape[-1] == 2 and X.shape[1] == seq_len:\n            # (N, L, C)\n            X = X.transpose(1, 2).contiguous()\n        elif X.shape[1] == 2 and X.shape[2] == seq_len:\n            pass\n        else:\n            raise ValueError(f\"Unexpected X shape {tuple(X.shape)}. Expected (N, {seq_len}, 2) or (N, 2, {seq_len}).\")\n        self.X = X.float()\n        self.y = y.long().view(-1)\n\n    def __len__(self):\n        return self.X.size(0)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n# -------------------------------\n# Loss: Class-weighted CE with optional label smoothing and focal modulator\n# -------------------------------\nclass WeightedFocalLabelSmoothingLoss(nn.Module):\n    def __init__(self, class_weights: torch.Tensor = None, label_smoothing: float = 0.1, focal_gamma: float = 1.5):\n        super().__init__()\n        self.label_smoothing = float(label_smoothing)\n        self.focal_gamma = float(focal_gamma)\n        # weight applied inside CE; must be on same device at call time\n        self.register_buffer('class_weights', class_weights if class_weights is not None else None)\n\n    def forward(self, logits: torch.Tensor, targets: torch.Tensor):\n        # Compute per-sample CE with label smoothing and class weights\n        ce = F.cross_entropy(\n            logits, targets,\n            weight=self.class_weights,\n            reduction='none',\n            label_smoothing=self.label_smoothing\n        )\n        if self.focal_gamma > 0.0:\n            probs = F.softmax(logits, dim=-1)\n            pt = probs.gather(1, targets.view(-1, 1)).squeeze(1).clamp(min=1e-8, max=1.0)\n            focal_factor = (1.0 - pt) ** self.focal_gamma\n            ce = focal_factor * ce\n        return ce.mean()\n\n# -------------------------------\n# Utility\n# -------------------------------\ndef _ensure_cuda_device(device):\n    dev = torch.device(device) if not isinstance(device, torch.device) else device\n    if dev.type != 'cuda' or not torch.cuda.is_available():\n        raise RuntimeError(\"A CUDA-capable GPU is required. Pass device='cuda' and ensure CUDA is available.\")\n    return dev\n\ndef _dynamic_quantize_model(model: nn.Module, quantization_bits: int = 8, quantize_weights: bool = True, quantize_activations: bool = True) -> nn.Module:\n    # Quantization runs on CPU\n    model_cpu = model.to('cpu').eval()\n    if not quantize_weights:\n        return model_cpu  # no quantization\n    import torch.ao.quantization as aoq\n    dtype = None\n    if quantization_bits == 8:\n        # dynamic int8 quantization (weights int8, activations dynamically quantized for Linear ops)\n        dtype = torch.qint8\n    elif quantization_bits == 16:\n        dtype = torch.float16\n    elif quantization_bits == 32:\n        return model_cpu\n    else:\n        raise ValueError(\"quantization_bits must be one of {8,16,32}\")\n    qmodel = aoq.quantize_dynamic(\n        model_cpu,\n        {nn.Linear},  # Transformer internals use Linear; conv stays in float\n        dtype=dtype\n    )\n    return qmodel\n\ndef _bytes_of_state_dict(model: nn.Module) -> int:\n    buf = io.BytesIO()\n    torch.save(model.state_dict(), buf)\n    return buf.tell()\n\n# -------------------------------\n# Main training function\n# -------------------------------\n\ndef train_model(\n    X_train: torch.Tensor,\n    y_train: torch.Tensor,\n    X_val: torch.Tensor,\n    y_val: torch.Tensor,\n    device,\n    # Architecture / training hyperparameters (defaults chosen to meet <=256KB post-quantization)\n    lr: float = 1e-3,\n    batch_size: int = 64,\n    epochs: int = 20,\n    weight_decay: float = 1e-4,\n    dropout: float = 0.1,\n    d_model: int = 64,\n    n_heads: int = 4,\n    num_layers: int = 2,\n    dim_ff: int = 128,\n    stem_branch_channels: int = 12,\n    stem_kernel_sizes=(3,5,7),\n    label_smoothing: float = 0.1,\n    focal_gamma: float = 1.5,\n    grad_clip_norm: float = 1.0,\n    lr_scheduler: str = 'none',  # one of {'none','cosine','onecycle'}\n    use_amp: bool = True,\n    # Quantization parameters\n    quantization_bits: int = 8,\n    quantize_weights: bool = True,\n    quantize_activations: bool = True\n) -> Any:\n    \"\"\"\n    Train an ECGTransForm-style 1D CNN + Transformer classifier on GPU and return a post-training quantized model and metrics.\n\n    Notes:\n    - Always trains on GPU (CUDA). All tensors and the model are moved to the same device.\n    - DataLoader uses pin_memory=False per requirement.\n    - Input tensors X_* may be (N, 1000, 2) or (N, 2, 1000); function will align to (N, 2, 1000).\n    - Returns: (quantized_model_on_cpu, metrics_dict)\n    \"\"\"\n    # Device handling (critical)\n    device = _ensure_cuda_device(device)\n\n    # Create datasets and loaders\n    seq_len = 1000\n    train_ds = ECGTensorDataset(X_train, y_train, seq_len=seq_len)\n    val_ds = ECGTensorDataset(X_val, y_val, seq_len=seq_len)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n\n    # Build model\n    # Ensure n_heads divides d_model; if not, adjust n_heads downward to a divisor.\n    if d_model % n_heads != 0:\n        # find greatest divisor of d_model among [8,4,2,1]\n        for h in [8, 4, 2, 1]:\n            if d_model % h == 0:\n                n_heads = h\n                break\n    model = ECGTransformerClassifier(\n        in_channels=2,\n        seq_len=seq_len,\n        num_classes=5,\n        d_model=d_model,\n        n_heads=n_heads,\n        num_layers=num_layers,\n        dim_ff=dim_ff,\n        dropout=dropout,\n        stem_branch_channels=stem_branch_channels,\n        stem_kernel_sizes=tuple(stem_kernel_sizes) if isinstance(stem_kernel_sizes, (list, tuple)) else (3,5,7),\n        pool_type='mean'\n    ).to(device)\n\n    # Class weights for imbalance (inter-patient splits recommended upstream)\n    with torch.no_grad():\n        num_classes = 5\n        counts = torch.bincount(train_ds.y, minlength=num_classes).float()\n        counts = torch.clamp(counts, min=1.0)\n        inv = 1.0 / counts\n        class_weights = (inv / inv.sum() * num_classes).to(device)\n\n    criterion = WeightedFocalLabelSmoothingLoss(class_weights=class_weights, label_smoothing=label_smoothing, focal_gamma=focal_gamma).to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    if lr_scheduler == 'onecycle':\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer, max_lr=lr, total_steps=epochs * max(1, len(train_loader)), pct_start=0.15, anneal_strategy='cos'\n        )\n    elif lr_scheduler == 'cosine':\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(1, epochs))\n    else:\n        scheduler = None\n\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    train_losses, val_losses, val_accs = [], [], []\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        n_train = 0\n\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=False)\n            yb = yb.to(device, non_blocking=False)\n            optimizer.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                logits = model(xb)\n                loss = criterion(logits, yb)\n            scaler.scale(loss).backward()\n            if grad_clip_norm and grad_clip_norm > 0:\n                scaler.unscale_(optimizer)\n                nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n            scaler.step(optimizer)\n            scaler.update()\n            if scheduler is not None and lr_scheduler == 'onecycle':\n                scheduler.step()\n            running_loss += loss.detach().item() * xb.size(0)\n            n_train += xb.size(0)\n\n        train_epoch_loss = running_loss / max(1, n_train)\n        train_losses.append(train_epoch_loss)\n\n        # Validation\n        model.eval()\n        val_running_loss = 0.0\n        correct = 0\n        n_val = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb = xb.to(device, non_blocking=False)\n                yb = yb.to(device, non_blocking=False)\n                with torch.cuda.amp.autocast(enabled=False):  # eval in fp32 for stable metrics\n                    logits = model(xb)\n                    loss = criterion(logits, yb)\n                    preds = logits.argmax(dim=-1)\n                val_running_loss += loss.detach().item() * xb.size(0)\n                correct += (preds == yb).sum().item()\n                n_val += xb.size(0)\n        val_epoch_loss = val_running_loss / max(1, n_val)\n        val_epoch_acc = correct / max(1, n_val)\n        val_losses.append(val_epoch_loss)\n        val_accs.append(val_epoch_acc)\n\n        if scheduler is not None and lr_scheduler == 'cosine':\n            scheduler.step()\n\n        print(f\"Epoch {epoch:03d} | train_loss={train_epoch_loss:.5f} | val_loss={val_epoch_loss:.5f} | val_acc={val_epoch_acc:.4f}\")\n\n    # Post-training quantization on CPU\n    qmodel = _dynamic_quantize_model(model, quantization_bits=quantization_bits, quantize_weights=quantize_weights, quantize_activations=quantize_activations)\n    qmodel.eval()\n\n    model_size_bytes = _bytes_of_state_dict(qmodel)\n    if model_size_bytes > 256 * 1024:\n        print(f\"Warning: Quantized model size {model_size_bytes} bytes exceeds 256KB. Consider reducing d_model/num_layers/dim_ff.\")\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs,\n        'best_val_acc': max(val_accs) if len(val_accs) > 0 else None,\n        'quantized_model_size_bytes': int(model_size_bytes),\n        'config': {\n            'lr': lr,\n            'batch_size': batch_size,\n            'epochs': epochs,\n            'weight_decay': weight_decay,\n            'dropout': dropout,\n            'd_model': d_model,\n            'n_heads': n_heads,\n            'num_layers': num_layers,\n            'dim_ff': dim_ff,\n            'stem_branch_channels': stem_branch_channels,\n            'stem_kernel_sizes': list(stem_kernel_sizes) if isinstance(stem_kernel_sizes, (list, tuple)) else [3,5,7],\n            'label_smoothing': label_smoothing,\n            'focal_gamma': focal_gamma,\n            'grad_clip_norm': grad_clip_norm,\n            'lr_scheduler': lr_scheduler,\n            'use_amp': use_amp,\n            'quantization_bits': quantization_bits,\n            'quantize_weights': quantize_weights,\n            'quantize_activations': quantize_activations\n        }\n    }\n\n    return qmodel, metrics\n",
  "bo_config": {
    "lr": {
      "default": 0.001,
      "type": "Real",
      "low": 1e-05,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "batch_size": {
      "default": 64,
      "type": "Categorical",
      "categories": [
        32,
        64,
        128
      ]
    },
    "epochs": {
      "default": 20,
      "type": "Integer",
      "low": 5,
      "high": 100
    },
    "weight_decay": {
      "default": 0.0001,
      "type": "Real",
      "low": 1e-06,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "dropout": {
      "default": 0.1,
      "type": "Real",
      "low": 0.0,
      "high": 0.5
    },
    "d_model": {
      "default": 64,
      "type": "Integer",
      "low": 48,
      "high": 128
    },
    "n_heads": {
      "default": 4,
      "type": "Categorical",
      "categories": [
        2,
        4,
        8
      ]
    },
    "num_layers": {
      "default": 2,
      "type": "Integer",
      "low": 1,
      "high": 4
    },
    "dim_ff": {
      "default": 128,
      "type": "Integer",
      "low": 64,
      "high": 256
    },
    "stem_branch_channels": {
      "default": 12,
      "type": "Integer",
      "low": 8,
      "high": 24
    },
    "stem_kernel_sizes": {
      "default": [
        3,
        5,
        7
      ],
      "type": "Categorical",
      "categories": [
        [
          3,
          5,
          7
        ],
        [
          5,
          7,
          11
        ],
        [
          3,
          7,
          11
        ]
      ]
    },
    "label_smoothing": {
      "default": 0.1,
      "type": "Real",
      "low": 0.0,
      "high": 0.2
    },
    "focal_gamma": {
      "default": 1.5,
      "type": "Real",
      "low": 0.0,
      "high": 4.0
    },
    "grad_clip_norm": {
      "default": 1.0,
      "type": "Real",
      "low": 0.0,
      "high": 5.0
    },
    "lr_scheduler": {
      "default": "none",
      "type": "Categorical",
      "categories": [
        "none",
        "cosine",
        "onecycle"
      ]
    },
    "use_amp": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "quantization_bits": {
      "default": 8,
      "type": "Categorical",
      "categories": [
        8,
        16,
        32
      ]
    },
    "quantize_weights": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "quantize_activations": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    }
  },
  "confidence": 0.78,
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  },
  "timestamp": 1758930281,
  "metadata": {
    "generated_by": "AI Code Generator",
    "api_model": "gpt-5",
    "version": "1.0"
  }
}