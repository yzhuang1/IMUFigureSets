{
  "model_name": "RRFusionRes1DCNN-5C",
  "training_code": "def train_model(X_train, y_train, X_val, y_val, device, **kwargs):\n    \"\"\"\n    Train a 5-class inter-patient 1D CNN + RR feature-fusion classifier.\n\n    Inputs:\n      - X_train, X_val: torch.Tensor of shape (N, 2, 1000) or (N, 1000, 2), dtype float32.\n      - y_train, y_val: torch.Tensor of shape (N,), dtype long.\n      - device: str or torch.device; training will run on GPU.\n    Hyperparameters (kwargs):\n      - lr (float), batch_size (int), epochs (int), weight_decay (float)\n      - dropout (float), base_channels (int)\n      - loss_type in {\"focal\", \"ce\", \"class_balanced\"}\n      - gamma (float, focal loss focusing)\n      - label_smoothing (float)\n      - scheduler in {\"none\", \"onecycle\", \"plateau\"}\n      - patience (int) for ReduceLROnPlateau\n      - use_amp (bool), grad_clip (float)\n      - quantization_bits in {8,16,32}, quantize_weights (bool), quantize_activations (bool)\n      - calibration_batches (int) for PTQ calibration (best-effort; dynamic quant used by default)\n    Returns: (quantized_model, metrics_dict) where metrics_dict has lists: train_losses, val_losses, val_acc\n    \"\"\"\n    import math\n    import copy\n    import torch\n    from torch import nn\n    from torch.utils.data import TensorDataset, DataLoader\n    from torch.cuda.amp import autocast, GradScaler\n    import torch.nn.functional as F\n\n    # -------------------- Helper: ensure channels-first layout (B, 2, L) --------------------\n    def _to_channels_first(X):\n        if X.dim() == 3:\n            if X.shape[-1] == 2 and X.shape[1] != 2:\n                return X.permute(0, 2, 1).contiguous()\n        return X\n\n    # -------------------- Robust device handling --------------------\n    device = torch.device(device)\n    if device.type != 'cuda':\n        if torch.cuda.is_available():\n            print(\"[Info] Overriding device to CUDA for training per requirement.\")\n            device = torch.device('cuda')\n        else:\n            raise RuntimeError(\"CUDA device required for training per spec but not available.\")\n\n    torch.backends.cudnn.benchmark = True\n\n    # -------------------- Defaults --------------------\n    lr = float(kwargs.get('lr', 1e-3))\n    batch_size = int(kwargs.get('batch_size', 128))\n    epochs = int(kwargs.get('epochs', 15))\n    weight_decay = float(kwargs.get('weight_decay', 1e-4))\n    dropout = float(kwargs.get('dropout', 0.1))\n    base_channels = int(kwargs.get('base_channels', 16))\n    loss_type = str(kwargs.get('loss_type', 'focal'))\n    gamma = float(kwargs.get('gamma', 2.0))\n    label_smoothing = float(kwargs.get('label_smoothing', 0.0))\n    scheduler_type = str(kwargs.get('scheduler', 'onecycle'))\n    patience = int(kwargs.get('patience', 5))\n    use_amp = bool(kwargs.get('use_amp', True))\n    grad_clip = float(kwargs.get('grad_clip', 1.0))\n\n    quantization_bits = int(kwargs.get('quantization_bits', 8))\n    quantize_weights = bool(kwargs.get('quantize_weights', True))\n    quantize_activations = bool(kwargs.get('quantize_activations', False))\n    calibration_batches = int(kwargs.get('calibration_batches', 2))\n\n    num_classes = 5\n\n    # -------------------- Datasets and loaders --------------------\n    X_train = _to_channels_first(X_train.float())\n    X_val = _to_channels_first(X_val.float())\n    y_train = y_train.long()\n    y_val = y_val.long()\n\n    if X_train.dim() != 3 or X_train.shape[1] != 2:\n        raise ValueError(f\"X_train must be (N,2,L). Got {tuple(X_train.shape)}\")\n    if X_val.dim() != 3 or X_val.shape[1] != 2:\n        raise ValueError(f\"X_val must be (N,2,L). Got {tuple(X_val.shape)}\")\n\n    train_ds = TensorDataset(X_train, y_train)\n    val_ds = TensorDataset(X_val, y_val)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=False, num_workers=0)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=False, num_workers=0)\n\n    # -------------------- Define missing components --------------------\n    class ResBlock1D(nn.Module):\n        def __init__(self, ch, dropout=0.0, kernel_size=7):\n            super().__init__()\n            pad = kernel_size // 2\n            self.conv1 = nn.Conv1d(ch, ch, kernel_size=kernel_size, padding=pad, bias=False)\n            self.bn1 = nn.BatchNorm1d(ch)\n            self.conv2 = nn.Conv1d(ch, ch, kernel_size=kernel_size, padding=pad, bias=False)\n            self.bn2 = nn.BatchNorm1d(ch)\n            self.act = nn.ReLU(inplace=True)\n            self.drop = nn.Dropout(dropout)\n        def forward(self, x):\n            out = self.conv1(x)\n            out = self.bn1(out)\n            out = self.act(out)\n            out = self.drop(out)\n            out = self.conv2(out)\n            out = self.bn2(out)\n            out = out + x\n            out = self.act(out)\n            return out\n\n    class RRFusionRes1DCNN(nn.Module):\n        def __init__(self, in_ch=2, base_ch=16, num_classes=5, dropout=0.1, rr_feat_dim=5, rr_embed=8):\n            super().__init__()\n            ch1 = base_ch\n            ch2 = base_ch * 2\n            ch3 = base_ch * 4\n            self.stem = nn.Sequential(\n                nn.Conv1d(in_ch, ch1, kernel_size=9, padding=4, bias=False),\n                nn.BatchNorm1d(ch1),\n                nn.ReLU(inplace=True),\n                nn.Dropout(dropout),\n            )\n            self.layer1 = nn.Sequential(\n                ResBlock1D(ch1, dropout=dropout, kernel_size=7),\n                nn.Conv1d(ch1, ch2, kernel_size=5, stride=2, padding=2, bias=False),\n                nn.BatchNorm1d(ch2),\n                nn.ReLU(inplace=True),\n            )\n            self.layer2 = nn.Sequential(\n                ResBlock1D(ch2, dropout=dropout, kernel_size=5),\n                nn.Conv1d(ch2, ch3, kernel_size=3, stride=2, padding=1, bias=False),\n                nn.BatchNorm1d(ch3),\n                nn.ReLU(inplace=True),\n                ResBlock1D(ch3, dropout=dropout, kernel_size=3),\n            )\n            self.gap = nn.AdaptiveAvgPool1d(1)\n            self.ecg_proj = nn.Sequential(\n                nn.Linear(ch3, ch3),\n                nn.ReLU(inplace=True),\n                nn.Dropout(dropout),\n            )\n            self.rr_embed = nn.Sequential(\n                nn.Linear(rr_feat_dim, rr_embed),\n                nn.ReLU(inplace=True),\n                nn.Dropout(dropout),\n            )\n            self.classifier = nn.Sequential(\n                nn.Linear(ch3 + rr_embed, max(32, base_ch * 4)),\n                nn.ReLU(inplace=True),\n                nn.Dropout(dropout),\n                nn.Linear(max(32, base_ch * 4), num_classes),\n            )\n        def forward(self, x, rr_feats):\n            x = self.stem(x)\n            x = self.layer1(x)\n            x = self.layer2(x)\n            x = self.gap(x).squeeze(-1)  # (B, ch3)\n            x = self.ecg_proj(x)\n            rr = self.rr_embed(rr_feats)\n            z = torch.cat([x, rr], dim=1)\n            logits = self.classifier(z)\n            return logits\n\n    def make_class_weights(y, num_classes, smoothing=0.0, device='cpu'):\n        counts = torch.bincount(y.cpu(), minlength=num_classes).float()\n        eps = 1e-6\n        inv = 1.0 / (counts + eps)\n        w = inv / inv.mean()\n        return w.to(device)\n\n    class FocalLoss(nn.Module):\n        def __init__(self, gamma=2.0, weight=None, label_smoothing=0.0, reduction='mean'):\n            super().__init__()\n            self.gamma = gamma\n            # Avoid registering None or non-tensor buffers to prevent state_dict dtype issues\n            self.weight = weight  # tensor or None\n            self.label_smoothing = float(label_smoothing)\n            self.reduction = reduction\n        def forward(self, logits, target):\n            num_classes = logits.size(1)\n            log_probs = F.log_softmax(logits, dim=1)\n            probs = log_probs.exp()\n            one_hot = F.one_hot(target, num_classes=num_classes).float()\n            if self.label_smoothing > 0.0:\n                one_hot = one_hot * (1.0 - self.label_smoothing) + self.label_smoothing / num_classes\n            ce = -(one_hot * log_probs).sum(dim=1)\n            pt = (one_hot * probs).sum(dim=1).clamp_min(1e-6)\n            loss = ((1.0 - pt) ** self.gamma) * ce\n            weight = self.weight\n            if weight is not None:\n                if weight.device != logits.device:\n                    weight = weight.to(logits.device)\n                w_per = (one_hot * weight.unsqueeze(0)).sum(dim=1)\n                loss = loss * w_per\n            if self.reduction == 'mean':\n                return loss.mean()\n            elif self.reduction == 'sum':\n                return loss.sum()\n            else:\n                return loss\n\n    def compute_rr_entropy_features(x):\n        # x: (B,2,L). Use lead-0 to compute simple surrogate RR-like features.\n        sig = x[:, 0, :]\n        B, L = sig.shape\n        eps = 1e-8\n        mean = sig.mean(dim=1)\n        std = sig.std(dim=1, unbiased=False)\n        abs_mean = sig.abs().mean(dim=1)\n        ptp = sig.max(dim=1).values - sig.min(dim=1).values\n        # Spectral entropy\n        spec = torch.fft.rfft(sig, dim=1)\n        psd = (spec.real.pow(2) + spec.imag.pow(2)) + eps\n        p = psd / psd.sum(dim=1, keepdim=True)\n        se = -(p * (p + eps).log()).sum(dim=1)\n        # Normalize by log of number of freq bins\n        denom = torch.log(torch.tensor(p.size(1), device=p.device, dtype=sig.dtype))\n        se = se / denom\n        feats = torch.stack([mean, std, abs_mean, ptp, se], dim=1)\n        return feats\n\n    # -------------------- Model --------------------\n    model = RRFusionRes1DCNN(in_ch=2, base_ch=base_channels, num_classes=num_classes, dropout=dropout, rr_feat_dim=5, rr_embed=8)\n    model = model.to(device)\n\n    # -------------------- Loss --------------------\n    class_weights = make_class_weights(y_train, num_classes, smoothing=0.0, device=device)\n    if loss_type == 'focal':\n        criterion = FocalLoss(gamma=gamma, weight=class_weights, label_smoothing=label_smoothing)\n    elif loss_type == 'class_balanced':\n        beta = float(kwargs.get('beta_cb', 0.999))\n        counts = torch.bincount(y_train.cpu(), minlength=num_classes).float()\n        eff_num = (1.0 - torch.pow(torch.tensor(beta), counts)) / (1.0 - beta + 1e-8)\n        cb_w = (eff_num.sum() / (eff_num + 1e-8))\n        cb_w = (cb_w / cb_w.mean()).to(device)\n        criterion = nn.CrossEntropyLoss(weight=cb_w, label_smoothing=label_smoothing)\n    else:\n        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=label_smoothing)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    if scheduler_type == 'onecycle':\n        steps_per_epoch = max(1, len(train_loader))\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, epochs=epochs, steps_per_epoch=steps_per_epoch)\n    elif scheduler_type == 'plateau':\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=patience, factor=0.5, min_lr=1e-6)\n    else:\n        scheduler = None\n\n    scaler = GradScaler(enabled=use_amp)\n\n    train_losses, val_losses, val_accs = [], [], []\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        total = 0\n        for xb, yb in train_loader:\n            if xb.dim() == 3 and xb.shape[1] != 2 and xb.shape[-1] == 2:\n                xb = xb.permute(0, 2, 1).contiguous()\n\n            xb = xb.to(device, non_blocking=False)\n            yb = yb.to(device, non_blocking=False)\n\n            rr_feats = compute_rr_entropy_features(xb).to(device)\n\n            optimizer.zero_grad(set_to_none=True)\n            with autocast(enabled=use_amp):\n                logits = model(xb, rr_feats)\n                loss = criterion(logits, yb)\n            scaler.scale(loss).backward()\n            if grad_clip and grad_clip > 0.0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n            scaler.step(optimizer)\n            scaler.update()\n\n            if scheduler_type == 'onecycle' and scheduler is not None:\n                scheduler.step()\n\n            running_loss += loss.detach().item() * xb.size(0)\n            total += xb.size(0)\n\n        train_epoch_loss = running_loss / max(1, total)\n        train_losses.append(train_epoch_loss)\n\n        # Validation\n        model.eval()\n        v_loss = 0.0\n        v_total = 0\n        v_correct = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                if xb.dim() == 3 and xb.shape[1] != 2 and xb.shape[-1] == 2:\n                    xb = xb.permute(0, 2, 1).contiguous()\n                xb = xb.to(device, non_blocking=False)\n                yb = yb.to(device, non_blocking=False)\n                rr_feats = compute_rr_entropy_features(xb).to(device)\n                logits = model(xb, rr_feats)\n                loss = criterion(logits, yb)\n                v_loss += loss.detach().item() * xb.size(0)\n                preds = logits.argmax(dim=1)\n                v_correct += (preds == yb).sum().item()\n                v_total += xb.size(0)\n\n        val_epoch_loss = v_loss / max(1, v_total)\n        val_epoch_acc = (v_correct / max(1, v_total))\n        val_losses.append(val_epoch_loss)\n        val_accs.append(val_epoch_acc)\n\n        if scheduler_type == 'plateau' and scheduler is not None:\n            scheduler.step(val_epoch_acc)\n\n        print(f\"Epoch {epoch:03d}: train_loss={train_epoch_loss:.6f} val_loss={val_epoch_loss:.6f} val_acc={val_epoch_acc:.4f}\")\n\n    # -------- Post-Training Quantization (best-effort, keep model size <= 256KB) --------\n    def approximate_model_size_bytes(m):\n        nbytes = 0\n        for k, v in m.state_dict().items():\n            # Some quantized models may store non-tensor entries (e.g., packed params metadata)\n            if isinstance(v, torch.Tensor):\n                nbytes += v.numel() * v.element_size()\n            else:\n                # skip non-tensors to avoid errors like \"torch.dtype has no attribute numel\"\n                continue\n        return int(nbytes)\n\n    q_model = None\n    if quantization_bits == 8 and quantize_weights:\n        try:\n            q_model = torch.ao.quantization.quantize_dynamic(\n                copy.deepcopy(model).to('cpu').eval(),\n                {nn.Linear},\n                dtype=torch.qint8\n            )\n            if quantize_activations:\n                print(\"[Info] quantize_activations requested, but dynamic quantization only quantizes weights of Linear layers. Proceeding with weight-only int8.\")\n        except Exception as e:\n            print(f\"[Warn] Dynamic quantization failed: {e}. Falling back to FP32 CPU model.\")\n            q_model = copy.deepcopy(model).to('cpu').eval()\n    elif quantization_bits == 16:\n        q_model = copy.deepcopy(model).to('cpu').eval().half()\n    else:\n        q_model = copy.deepcopy(model).to('cpu').eval()\n\n    size_bytes = approximate_model_size_bytes(q_model)\n    if size_bytes > 256 * 1024:\n        print(f\"[Warn] Quantized model size {size_bytes/1024:.1f}KB exceeds 256KB. Consider reducing base_channels or enabling int8.\")\n    else:\n        print(f\"[Info] Quantized model size ≈ {size_bytes/1024:.1f}KB (<= 256KB).\")\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs,\n        'quantized_model_size_bytes': size_bytes\n    }\n\n    return q_model, metrics\n",
  "bo_config": {
    "lr": {
      "default": 0.001,
      "type": "Real",
      "low": 1e-06,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "batch_size": {
      "default": 128,
      "type": "Categorical",
      "categories": [
        32,
        64,
        128,
        256
      ]
    },
    "epochs": {
      "default": 15,
      "type": "Integer",
      "low": 5,
      "high": 50
    },
    "weight_decay": {
      "default": 0.0001,
      "type": "Real",
      "low": 1e-06,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "dropout": {
      "default": 0.1,
      "type": "Real",
      "low": 0.0,
      "high": 0.5
    },
    "base_channels": {
      "default": 16,
      "type": "Integer",
      "low": 8,
      "high": 24
    },
    "loss_type": {
      "default": "focal",
      "type": "Categorical",
      "categories": [
        "focal",
        "ce",
        "class_balanced"
      ]
    },
    "gamma": {
      "default": 2.0,
      "type": "Real",
      "low": 0.0,
      "high": 5.0
    },
    "label_smoothing": {
      "default": 0.0,
      "type": "Real",
      "low": 0.0,
      "high": 0.1
    },
    "scheduler": {
      "default": "onecycle",
      "type": "Categorical",
      "categories": [
        "none",
        "onecycle",
        "plateau"
      ]
    },
    "patience": {
      "default": 5,
      "type": "Integer",
      "low": 2,
      "high": 10
    },
    "use_amp": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "grad_clip": {
      "default": 1.0,
      "type": "Real",
      "low": 0.0,
      "high": 2.0
    },
    "quantization_bits": {
      "default": 8,
      "type": "Categorical",
      "categories": [
        8,
        16,
        32
      ]
    },
    "quantize_weights": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "quantize_activations": {
      "default": false,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "calibration_batches": {
      "default": 2,
      "type": "Integer",
      "low": 1,
      "high": 10
    },
    "beta_cb": {
      "default": 0.999,
      "type": "Real",
      "low": 0.9,
      "high": 0.9999
    }
  },
  "confidence": 0.86,
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  },
  "timestamp": 1758759913,
  "metadata": {
    "generated_by": "AI Code Generator",
    "api_model": "gpt-5",
    "version": "1.0"
  }
}