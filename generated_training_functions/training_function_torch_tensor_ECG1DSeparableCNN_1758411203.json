{
  "model_name": "ECG1DSeparableCNN",
  "training_code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom copy import deepcopy\n\ndef train_model(X_train, y_train, X_val, y_val, device, **kwargs):\n    \"\"\"\n    Train a compact 1D CNN for 5-class arrhythmia classification on (1000,2) ECG beats.\n    Inputs:\n      - X_train, y_train, X_val, y_val: torch.Tensors\n      - device: torch.device ('cpu' or 'cuda')\n      - kwargs: hyperparameters and quantization parameters\n    Returns:\n      - quantized_model: post-training quantized model as requested\n      - metrics: dict with train_losses, val_losses, val_acc, param_count\n    \"\"\"\n    # ---------------------- Hyperparameters ----------------------\n    num_classes = 5\n    lr = kwargs.get('lr', 1e-3)\n    batch_size = int(kwargs.get('batch_size', 256))\n    epochs = int(kwargs.get('epochs', 20))\n    weight_decay = float(kwargs.get('weight_decay', 1e-4))\n    dropout = float(kwargs.get('dropout', 0.1))\n    ch1 = int(kwargs.get('channels1', 32))\n    ch2 = int(kwargs.get('channels2', 64))\n    ch3 = int(kwargs.get('channels3', 128))\n    k1 = int(kwargs.get('kernel_size1', 7))\n    k2 = int(kwargs.get('kernel_size2', 5))\n    k3 = int(kwargs.get('kernel_size3', 5))\n    pool_size = int(kwargs.get('pool_size', 2))\n    scheduler_type = kwargs.get('lr_scheduler', 'none')\n    step_size = int(kwargs.get('step_size', 5))\n    gamma = float(kwargs.get('gamma', 0.5))\n    label_smoothing = float(kwargs.get('label_smoothing', 0.0))\n    early_patience = int(kwargs.get('early_stopping_patience', 0))  # 0 disables early stopping\n\n    # Quantization parameters\n    quantization_bits = int(kwargs.get('quantization_bits', 8))  # {8,16,32}\n    quantize_weights = bool(kwargs.get('quantize_weights', True))\n    quantize_activations = bool(kwargs.get('quantize_activations', True))\n    calibration_batches = int(kwargs.get('calibration_batches', 20))\n    per_channel = bool(kwargs.get('per_channel', True))\n\n    # ---------------------- Datasets & Loaders ----------------------\n    class ECGDataset(torch.utils.data.Dataset):\n        def __init__(self, X, y):\n            assert isinstance(X, torch.Tensor) and isinstance(y, torch.Tensor)\n            self.X = X\n            self.y = y.long()\n        def __len__(self):\n            return self.X.shape[0]\n        def __getitem__(self, idx):\n            x = self.X[idx].float()\n            # Ensure channel-first (C, L)\n            if x.ndim == 1:\n                # Assume (L,) single-channel; expand to (C=1,L) then pad to 2 channels if needed\n                x = x.unsqueeze(0)\n                if x.shape[0] == 1:\n                    # duplicate channel to reach 2 if possible\n                    x = x.repeat(2, 1)\n            elif x.ndim == 2:\n                # Either (L, C) or (C, L)\n                if x.shape[0] in (1, 2) and x.shape[1] not in (1, 2):\n                    # already (C, L)\n                    pass\n                else:\n                    # assume (L, C)\n                    x = x.permute(1, 0)\n            else:\n                raise ValueError('Expected input dim of 1 or 2 per sample, got shape: %s' % (tuple(x.shape),))\n            # If channels != 2, project/trim to 2 channels for safety\n            if x.shape[0] < 2:\n                x = torch.cat([x, x[:1, :]], dim=0)\n            elif x.shape[0] > 2:\n                x = x[:2, :]\n            return x, self.y[idx]\n\n    train_ds = ECGDataset(X_train, y_train)\n    val_ds = ECGDataset(X_val, y_val)\n\n    # Important: pin_memory=False per requirements\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=False, drop_last=False)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, pin_memory=False, drop_last=False)\n\n    # ---------------------- Model Definition ----------------------\n    class DepthwiseSeparableConv(nn.Module):\n        def __init__(self, in_ch, out_ch, kernel, stride=1, padding=None):\n            super().__init__()\n            if padding is None:\n                padding = kernel // 2\n            self.depthwise = nn.Conv1d(in_ch, in_ch, kernel, stride=stride, padding=padding, groups=in_ch, bias=False)\n            self.pointwise = nn.Conv1d(in_ch, out_ch, 1, bias=False)\n            self.bn = nn.BatchNorm1d(out_ch)\n            self.act = nn.ReLU(inplace=True)\n        def forward(self, x):\n            x = self.depthwise(x)\n            x = self.pointwise(x)\n            x = self.bn(x)\n            return self.act(x)\n\n    class ECGNet(nn.Module):\n        def __init__(self, ch1, ch2, ch3, k1, k2, k3, pool_size, dropout, num_classes):\n            super().__init__()\n            self.conv1 = nn.Conv1d(2, ch1, k1, padding=k1 // 2, bias=False)\n            self.bn1 = nn.BatchNorm1d(ch1)\n            self.act1 = nn.ReLU(inplace=True)\n            self.block2 = DepthwiseSeparableConv(ch1, ch2, k2)\n            self.pool2 = nn.MaxPool1d(pool_size)\n            self.block3 = DepthwiseSeparableConv(ch2, ch3, k3)\n            self.pool3 = nn.MaxPool1d(pool_size)\n            self.block4 = DepthwiseSeparableConv(ch3, ch3, k3)\n            self.gap = nn.AdaptiveAvgPool1d(1)\n            self.dropout = nn.Dropout(dropout)\n            self.fc = nn.Linear(ch3, num_classes)\n        def forward(self, x):\n            x = self.act1(self.bn1(self.conv1(x)))\n            x = self.pool2(self.block2(x))\n            x = self.pool3(self.block3(x))\n            x = self.block4(x)\n            x = self.gap(x).squeeze(-1)\n            x = self.dropout(x)\n            return self.fc(x)\n\n    model = ECGNet(ch1, ch2, ch3, k1, k2, k3, pool_size, dropout, num_classes).to(device)\n\n    def count_params(m):\n        return sum(p.numel() for p in m.parameters() if p.requires_grad)\n\n    param_count = count_params(model)\n    assert param_count <= 256000, f\"Model has too many parameters: {param_count} (> 256000)\"\n\n    # ---------------------- Optimization ----------------------\n    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    scheduler = None\n    if scheduler_type == 'cosine':\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(1, epochs))\n    elif scheduler_type == 'step':\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=max(1, step_size), gamma=gamma)\n\n    # ---------------------- Training Loop ----------------------\n    train_losses, val_losses, val_accs = [], [], []\n    best_val_loss = float('inf')\n    best_state = deepcopy(model.state_dict())\n    no_improve = 0\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        running_loss = 0.0\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=False)\n            yb = yb.to(device, non_blocking=False)\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * xb.size(0)\n        train_loss = running_loss / len(train_ds)\n\n        model.eval()\n        val_running_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb = xb.to(device, non_blocking=False)\n                yb = yb.to(device, non_blocking=False)\n                logits = model(xb)\n                vloss = criterion(logits, yb)\n                val_running_loss += vloss.item() * xb.size(0)\n                preds = logits.argmax(dim=1)\n                correct += (preds == yb).sum().item()\n                total += yb.numel()\n        val_loss = val_running_loss / len(val_ds)\n        val_acc = correct / max(1, total)\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n\n        print(f\"Epoch {epoch}/{epochs} - train_loss: {train_loss:.4f} - val_loss: {val_loss:.4f} - val_acc: {val_acc:.4f}\")\n\n        if val_loss < best_val_loss - 1e-6:\n            best_val_loss = val_loss\n            best_state = deepcopy(model.state_dict())\n            no_improve = 0\n        else:\n            no_improve += 1\n\n        if scheduler is not None:\n            scheduler.step()\n\n        if early_patience > 0 and no_improve >= early_patience:\n            print(f\"Early stopping at epoch {epoch} (no improvement for {early_patience} epochs)\")\n            break\n\n    # Load best weights\n    model.load_state_dict(best_state)\n    model.eval()\n\n    # ---------------------- Post-Training Quantization ----------------------\n    def quantize_post_training(model_float):\n        # No quantization\n        if not quantize_weights and not quantize_activations:\n            return model_float\n        if quantization_bits == 32:\n            return model_float\n\n        if quantization_bits == 8:\n            # Int8 quantization\n            if quantize_activations:\n                # Static FX graph mode quantization (weights + activations) on CPU\n                import torch.ao.quantization as tq\n                from torch.ao.quantization.qconfig import default_qconfig, default_per_channel_qconfig\n                from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n                torch.backends.quantized.engine = 'fbgemm'\n                qconfig = default_per_channel_qconfig if per_channel else default_qconfig\n                qconfig_mapping = tq.qconfig.QConfigMapping().set_global(qconfig)\n\n                model_cpu = deepcopy(model_float).to('cpu')\n                model_cpu.eval()\n                # Example input for FX tracing\n                try:\n                    example_input = next(iter(val_loader))[0][:1].to('cpu')\n                except StopIteration:\n                    example_input = torch.randn(1, 2, 1000)\n\n                prepared = prepare_fx(model_cpu, qconfig_mapping, example_input)\n                # Calibration with a few batches\n                prepared.eval()\n                with torch.no_grad():\n                    ncal = 0\n                    for xb, _ in train_loader:\n                        prepared(xb.to('cpu'))\n                        ncal += 1\n                        if ncal >= max(1, calibration_batches):\n                            break\n                quantized_model = convert_fx(prepared)\n                quantized_model.eval()\n                return quantized_model\n            else:\n                # Dynamic quantization (weights only) for Linear layers\n                import torch.ao.quantization as tq\n                modules = {nn.Linear}\n                model_cpu = deepcopy(model_float).to('cpu')\n                qdtype = torch.qint8\n                quantized_model = tq.quantize_dynamic(model_cpu, modules, dtype=qdtype)\n                quantized_model.eval()\n                return quantized_model\n\n        if quantization_bits == 16:\n            # 16-bit: use half precision (fp16 on CUDA, bfloat16 on CPU). Acts on weights and activations when running.\n            model_16 = deepcopy(model_float)\n            if device.type == 'cuda':\n                model_16 = model_16.half().to(device)\n            else:\n                model_16 = model_16.to(dtype=torch.bfloat16)\n            model_16.eval()\n            return model_16\n\n        # Fallback\n        return model_float\n\n    quantized_model = quantize_post_training(model)\n\n    metrics = {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_acc': val_accs,\n        'param_count': int(param_count)\n    }\n\n    return quantized_model, metrics\n",
  "bo_config": {
    "lr": {
      "default": 0.001,
      "type": "Real",
      "low": 1e-05,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "batch_size": {
      "default": 256,
      "type": "Categorical",
      "categories": [
        64,
        128,
        256,
        512
      ]
    },
    "epochs": {
      "default": 20,
      "type": "Integer",
      "low": 5,
      "high": 100
    },
    "weight_decay": {
      "default": 0.0001,
      "type": "Real",
      "low": 1e-06,
      "high": 0.01,
      "prior": "log-uniform"
    },
    "dropout": {
      "default": 0.1,
      "type": "Real",
      "low": 0.0,
      "high": 0.5
    },
    "channels1": {
      "default": 32,
      "type": "Integer",
      "low": 16,
      "high": 64
    },
    "channels2": {
      "default": 64,
      "type": "Integer",
      "low": 32,
      "high": 128
    },
    "channels3": {
      "default": 128,
      "type": "Integer",
      "low": 64,
      "high": 160
    },
    "kernel_size1": {
      "default": 7,
      "type": "Categorical",
      "categories": [
        5,
        7,
        9,
        11
      ]
    },
    "kernel_size2": {
      "default": 5,
      "type": "Categorical",
      "categories": [
        3,
        5,
        7
      ]
    },
    "kernel_size3": {
      "default": 5,
      "type": "Categorical",
      "categories": [
        3,
        5,
        7
      ]
    },
    "pool_size": {
      "default": 2,
      "type": "Categorical",
      "categories": [
        2,
        4
      ]
    },
    "lr_scheduler": {
      "default": "none",
      "type": "Categorical",
      "categories": [
        "none",
        "cosine",
        "step"
      ]
    },
    "step_size": {
      "default": 5,
      "type": "Integer",
      "low": 1,
      "high": 10
    },
    "gamma": {
      "default": 0.5,
      "type": "Real",
      "low": 0.1,
      "high": 0.9
    },
    "label_smoothing": {
      "default": 0.0,
      "type": "Real",
      "low": 0.0,
      "high": 0.1
    },
    "early_stopping_patience": {
      "default": 0,
      "type": "Integer",
      "low": 0,
      "high": 15
    },
    "quantization_bits": {
      "default": 8,
      "type": "Categorical",
      "categories": [
        8,
        16,
        32
      ]
    },
    "quantize_weights": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "quantize_activations": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    },
    "calibration_batches": {
      "default": 20,
      "type": "Integer",
      "low": 5,
      "high": 200
    },
    "per_channel": {
      "default": true,
      "type": "Categorical",
      "categories": [
        true,
        false
      ]
    }
  },
  "confidence": 0.9,
  "data_profile": {
    "data_type": "torch_tensor",
    "shape": [
      62352,
      1000,
      2
    ],
    "dtype": "float32",
    "feature_count": 2,
    "sample_count": 62352,
    "is_sequence": true,
    "is_image": false,
    "is_tabular": false,
    "has_labels": true,
    "label_count": 5,
    "sequence_lengths": null,
    "channels": null,
    "height": null,
    "width": null,
    "metadata": {}
  },
  "timestamp": 1758411203,
  "metadata": {
    "generated_by": "AI Code Generator",
    "api_model": "gpt-5",
    "version": "1.0"
  }
}