Original JSON:
{
    "model_name": "TinyECGTransformer1D (Two-Lead Conv-SE + CLS)",
    "training_code": "import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\n# ----- Positional Encoding -----\nclass SinusoidalPositionalEncoding(nn.Module):\n    def __init__(self, d_model: int, max_len: int = 5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n        self.register_buffer('pe', pe, persistent=False)\n\n    def forward(self, x):\n        # x: (B, L, D)\n        L = x.size(1)\n        return x + self.pe[:, :L]\n\n# ----- Depthwise-Separable Conv + SE block -----\nclass SEBlock1D(nn.Module):\n    def __init__(self, channels: int, reduction: int = 8):\n        super().__init__()\n        hidden = max(1, channels // reduction)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channels, hidden, bias=False),\n            nn.SiLU(),\n            nn.Linear(hidden, channels, bias=False),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        # x: (B, C, L)\n        w = self.pool(x).squeeze(-1)  # (B, C)\n        w = self.fc(w).unsqueeze(-1)  # (B, C, 1)\n        return x * w\n\nclass DepthwiseSeparableConv1D(nn.Module):\n    def __init__(self, in_ch: int, out_ch: int, kernel_size: int = 7, stride: int = 1):\n        super().__init__()\n        pad = kernel_size // 2\n        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size, stride=stride, padding=pad, groups=in_ch, bias=False)\n        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n        self.bn = nn.BatchNorm1d(out_ch)\n        self.act = nn.SiLU()\n\n    def forward(self, x):\n        x = self.dw(x)\n        x = self.pw(x)\n        x = self.bn(x)\n        return self.act(x)\n\n# ----- Tiny ECG Transformer -----\nclass TinyECGTransformer1D(nn.Module):\n    def __init__(self, seq_len: int, num_classes: int = 5, embed_dim: int = 64, hidden_size: int = 128,\n                 num_heads: int = 4, num_layers: int = 2, dropout: float = 0.1, kernel_size: int = 7,\n                 se_reduction: int = 8, use_cls_token: bool = True):\n        super().__init__()\n        self.use_cls_token = use_cls_token\n        in_ch = 2\n        # Two-lead fusion: depthwise-separable conv + SE\n        self.conv = DepthwiseSeparableConv1D(in_ch, embed_dim, kernel_size=kernel_size)\n        self.se = SEBlock1D(embed_dim, reduction=se_reduction)\n        self.proj_drop = nn.Dropout(dropout)\n        # Positional encoding\n        self.posenc = SinusoidalPositionalEncoding(embed_dim, max_len=seq_len + (1 if use_cls_token else 0))\n        # CLS token\n        if use_cls_token:\n            self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        else:\n            self.register_parameter('cls_token', None)\n        # Transformer encoder\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=hidden_size,\n            dropout=dropout,\n            batch_first=True,\n            norm_first=True,\n            activation='gelu',\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(embed_dim, num_classes)\n        )\n        self.seq_len = seq_len\n\n    def forward(self, x):\n        # Accept x shape (B, L, 2) or (B, 2, L)\n        if x.dim() != 3:\n            raise ValueError('Input must be 3D tensor (B, L, 2) or (B, 2, L)')\n        if x.shape[-1] == 2:\n            # (B, L, C) -> (B, C, L)\n            x = x.transpose(1, 2)\n        elif x.shape[1] == 2:\n            pass\n        else:\n            raise ValueError('Expected 2 ECG leads (channels). Got shape: {}'.format(tuple(x.shape)))\n        # Conv + SE fusion\n        x = self.conv(x)           # (B, E, L)\n        x = self.se(x)             # (B, E, L)\n        x = self.proj_drop(x)\n        x = x.transpose(1, 2)      # (B, L, E)\n        # Add CLS token if used\n        if self.cls_token is not None:\n            cls_tok = self.cls_token.expand(x.size(0), -1, -1)  # (B, 1, E)\n            x = torch.cat([cls_tok, x], dim=1)                  # (B, 1+L, E)\n        # Positional encoding\n        x = self.posenc(x)\n        # Transformer\n        x = self.encoder(x)\n        # Pool\n        if self.cls_token is not None:\n            x = x[:, 0, :]  # (B, E)\n        else:\n            x = x.mean(dim=1)\n        x = self.norm(x)\n        return self.head(x)\n\n# ----- Focal Loss (multi-class) -----\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma: float = 2.0, alpha=None, reduction: str = 'mean'):\n        super().__init__()\n        self.gamma = gamma\n        if alpha is not None:\n            self.register_buffer('alpha', torch.as_tensor(alpha, dtype=torch.float))\n        else:\n            self.alpha = None\n        self.reduction = reduction\n\n    def forward(self, logits, targets):\n        # logits: (B, C); targets: (B,)\n        logpt = F.log_softmax(logits, dim=-1)\n        pt = torch.exp(logpt)\n        logpt_t = logpt.gather(1, targets.unsqueeze(1)).squeeze(1)\n        pt_t = pt.gather(1, targets.unsqueeze(1)).squeeze(1)\n        if self.alpha is not None:\n            at = self.alpha.to(logits.device)[targets]\n        else:\n            at = 1.0\n        loss = -at * (1 - pt_t).clamp(min=1e-6).pow(self.gamma) * logpt_t\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss\n\n# ----- Simple ECG Dataset with optional augmentation -----\nclass ECGDataset(Dataset):\n    def __init__(self, X: torch.Tensor, y: torch.Tensor, augment: bool = False):\n        self.X = X\n        self.y = y.long()\n        self.augment = augment\n\n    def __len__(self):\n        return self.X.size(0)\n\n    def _augment(self, x: torch.Tensor) -> torch.Tensor:\n        # Expect x shape (L, C=2) or (C=2, L)\n        if x.dim() != 2:\n            return x\n        transposed_back = False\n        if x.shape[0] == 2 and x.shape[1] != 2:\n            x = x.transpose(0, 1)  # (L, 2)\n            transposed_back = True\n        elif x.shape[-1] == 2:\n            pass\n        else:\n            return x\n        # Jitter noise\n        if torch.rand(1, device=x.device).item() < 0.5:\n            std = x.std(dim=0, keepdim=True).clamp_min(1e-6)\n            noise = torch.randn_like(x) * (0.01 * std)\n            x = x + noise\n        # Amplitude scaling per lead\n        if torch.rand(1, device=x.device).item() < 0.3:\n            scale = 0.9 + 0.2 * torch.rand((1, x.size(1)), device=x.device)\n            x = x * scale\n        # Temporal shift (roll up to 2% of length)\n        if torch.rand(1, device=x.device).item() < 0.5:\n            max_shift = max(1, int(0.02 * x.size(0)))\n            shift = int(torch.randint(-max_shift, max_shift + 1, (1,), device=x.device).item())\n            x = torch.roll(x, shifts=shift, dims=0)\n        if transposed_back:\n            x = x.transpose(0, 1)\n        return x\n\n    def __getitem__(self, idx):\n        x = self.X[idx]\n        y = self.y[idx]\n        if self.augment:\n            x = self._augment(x)\n        return x, y\n\n# ----- Utility -----\n@torch.no_grad()\ndef _compute_class_alpha(y: torch.Tensor, num_classes: int):\n    # Inverse frequency weights normalized to mean 1.0\n    counts = torch.bincount(y.view(-1).long(), minlength=num_classes).float()\n    counts = torch.clamp(counts, min=1.0)\n    inv = 1.0 / counts\n    alpha = inv * (num_classes / inv.sum())\n    return alpha\n\n# ----- Training Function -----\ndef train_model(X_train: torch.Tensor, y_train: torch.Tensor,\n                X_val: torch.Tensor, y_val: torch.Tensor,\n                device: torch.device,\n                **hyperparams):\n    # Defaults (BayesOpt can override)\n    hp = {\n        'lr': 1e-3,\n        'batch_size': 64,\n        'epochs': 15,\n        'dropout': 0.1,\n        'embed_dim': 64,\n        'hidden_size': 128,\n        'num_heads': 4,\n        'num_layers': 2,\n        'weight_decay': 1e-4,\n        'gamma': 2.0,\n        'kernel_size': 7,\n        'se_reduction': 8,\n        'augment': True,\n        'num_workers': 0,\n        'max_grad_norm': 1.0,\n        'use_cls_token': True,\n        'seed': 42,\n    }\n    hp.update(hyperparams)\n\n    torch.manual_seed(hp['seed'])\n\n    # Infer sequence length\n    # X expected shape (N, L, 2) or (N, 2, L)\n    if X_train.dim() != 3:\n        raise ValueError('X_train must be 3D: (N, L, 2) or (N, 2, L)')\n    if X_train.shape[-1] == 2:\n        seq_len = X_train.shape[1]\n    elif X_train.shape[1] == 2:\n        seq_len = X_train.shape[-1]\n    else:\n        raise ValueError('Expected 2 ECG leads in X_train. Got shape: {}'.format(tuple(X_train.shape)))\n\n    num_classes = int(y_train.max().item() + 1)\n\n    # DataLoaders with pin_memory only if CPU tensors\n    pin_mem_train = (X_train.device.type == 'cpu' and y_train.device.type == 'cpu')\n    pin_mem_val = (X_val.device.type == 'cpu' and y_val.device.type == 'cpu')\n\n    train_ds = ECGDataset(X_train, y_train, augment=bool(hp['augment']))\n    val_ds = ECGDataset(X_val, y_val, augment=False)\n\n    train_loader = DataLoader(train_ds, batch_size=int(hp['batch_size']), shuffle=True,\n                              num_workers=int(hp['num_workers']), pin_memory=pin_mem_train, drop_last=False)\n    val_loader = DataLoader(val_ds, batch_size=int(hp['batch_size']), shuffle=False,\n                            num_workers=int(hp['num_workers']), pin_memory=pin_mem_val, drop_last=False)\n\n    # Model\n    model = TinyECGTransformer1D(\n        seq_len=seq_len,\n        num_classes=num_classes,\n        embed_dim=int(hp['embed_dim']),\n        hidden_size=int(hp['hidden_size']),\n        num_heads=int(hp['num_heads']),\n        num_layers=int(hp['num_layers']),\n        dropout=float(hp['dropout']),\n        kernel_size=int(hp['kernel_size']),\n        se_reduction=int(hp['se_reduction']),\n        use_cls_token=bool(hp['use_cls_token'])\n    ).to(device)\n\n    # Focal loss with class alpha from training labels\n    alpha = _compute_class_alpha(y_train.detach().cpu(), num_classes)\n    criterion = FocalLoss(gamma=float(hp['gamma']), alpha=alpha)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=float(hp['lr']), weight_decay=float(hp['weight_decay']))\n\n    def _to_device(t, dev, non_blocking=False):\n        return t if t.device == dev else t.to(dev, non_blocking=non_blocking)\n\n    history = {\n        'train_loss': [], 'val_loss': [],\n        'train_acc': [], 'val_acc': [],\n    }\n\n    best_val_acc = 0.0\n    best_epoch = -1\n    best_state = None\n\n    for epoch in range(int(hp['epochs'])):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        for xb, yb in train_loader:\n            xb = _to_device(xb, device, non_blocking=pin_mem_train)\n            yb = _to_device(yb, device, non_blocking=pin_mem_train)\n\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            loss.backward()\n            if hp['max_grad_norm'] is not None and hp['max_grad_norm'] > 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(hp['max_grad_norm']))\n            optimizer.step()\n\n            running_loss += loss.item() * xb.size(0)\n            pred = logits.argmax(dim=1)\n            correct += (pred == yb).sum().item()\n            total += yb.size(0)\n\n        train_loss = running_loss / max(1, total)\n        train_acc = correct / max(1, total)\n\n        # Validation\n        model.eval()\n        val_loss_sum = 0.0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb = _to_device(xb, device, non_blocking=pin_mem_val)\n                yb = _to_device(yb, device, non_blocking=pin_mem_val)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                val_loss_sum += loss.item() * xb.size(0)\n                pred = logits.argmax(dim=1)\n                val_correct += (pred == yb).sum().item()\n                val_total += yb.size(0)\n\n        val_loss = val_loss_sum / max(1, val_total)\n        val_acc = val_correct / max(1, val_total)\n\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['train_acc'].append(train_acc)\n        history['val_acc'].append(val_acc)\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_epoch = epoch\n            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n\n    if best_state is not None:\n        model.load_state_dict(best_state)\n\n    history['best_val_acc'] = best_val_acc\n    history['best_epoch'] = best_epoch\n\n    return model, history\n",
    "hyperparameters": {
        "lr": 0.001,
        "batch_size": 64,
        "epochs": 15,
        "dropout": 0.1,
        "embed_dim": 64,
        "hidden_size": 128,
        "num_heads": 4,
        "num_layers": 2,
        "weight_decay": 0.0001,
        "gamma": 2.0,
        "kernel_size": 7,
        "se_reduction": 8,
        "augment": true,
        "num_workers": 0,
        "max_grad_norm": 1.0,
        "use_cls_token": true,
        "seed": 42
    },
    "reasoning": "Implements a tiny 1D ECG Transformer tailored to 1000¡Á2 inputs following literature: two-lead depthwise-separable convolution with SE for channel fusion, sinusoidal positional encoding, 2¨C3 compact Transformer encoder layers with small embed_dim and heads, and a [CLS] token classifier head. Focal loss addresses class imbalance common in AAMI 5-class MIT-BIH setups. Light augmentations (noise, scale, shift) improve robustness. DataLoader respects pin_memory only for CPU tensors. The default configuration stays well under 256K parameters and is suitable for Bayesian Optimization.",
    "confidence": 0.86,
    "bo_parameters": [
        "lr",
        "batch_size",
        "epochs",
        "embed_dim",
        "hidden_size",
        "num_heads",
        "num_layers",
        "dropout",
        "weight_decay",
        "gamma",
        "kernel_size"
    ],
    "bo_search_space": {
        "lr": {"type": "Real", "low": 1e-5, "high": 5e-3, "prior": "log-uniform"},
        "batch_size": {"type": "Categorical", "categories": [32, 64, 96, 128]},
        "epochs": {"type": "Integer", "low": 8, "high": 40},
        "embed_dim": {"type": "Integer", "low": 32, "high": 128},
        "hidden_size": {"type": "Integer", "low": 64, "high": 512},
        "num_heads": {"type": "Integer", "low": 2, "high": 8},
        "num_layers": {"type": "Integer", "low": 1, "high": 4},
        "dropout": {"type": "Real", "low": 0.0, "high": 0.5},
        "weight_decay": {"type": "Real", "low": 1e-6, "high": 1e-2, "prior": "log-uniform"},
        "gamma": {"type": "Real", "low": 1.0, "high": 3.0},
        "kernel_size": {"type": "Integer", "low": 3, "high":  nine}
    }
}

Fixed JSON:
{
    "model_name": "TinyECGTransformer1D (Two-Lead Conv-SE + CLS)",
    "training_code": "import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\n# ----- Positional Encoding -----\nclass SinusoidalPositionalEncoding(nn.Module):\n    def __init__(self, d_model: int, max_len: int = 5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n        self.register_buffer('pe', pe, persistent=False)\n\n    def forward(self, x):\n        # x: (B, L, D)\n        L = x.size(1)\n        return x + self.pe[:, :L]\n\n# ----- Depthwise-Separable Conv + SE block -----\nclass SEBlock1D(nn.Module):\n    def __init__(self, channels: int, reduction: int = 8):\n        super().__init__()\n        hidden = max(1, channels // reduction)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channels, hidden, bias=False),\n            nn.SiLU(),\n            nn.Linear(hidden, channels, bias=False),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        # x: (B, C, L)\n        w = self.pool(x).squeeze(-1)  # (B, C)\n        w = self.fc(w).unsqueeze(-1)  # (B, C, 1)\n        return x * w\n\nclass DepthwiseSeparableConv1D(nn.Module):\n    def __init__(self, in_ch: int, out_ch: int, kernel_size: int = 7, stride: int = 1):\n        super().__init__()\n        pad = kernel_size // 2\n        self.dw = nn.Conv1d(in_ch, in_ch, kernel_size, stride=stride, padding=pad, groups=in_ch, bias=False)\n        self.pw = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)\n        self.bn = nn.BatchNorm1d(out_ch)\n        self.act = nn.SiLU()\n\n    def forward(self, x):\n        x = self.dw(x)\n        x = self.pw(x)\n        x = self.bn(x)\n        return self.act(x)\n\n# ----- Tiny ECG Transformer -----\nclass TinyECGTransformer1D(nn.Module):\n    def __init__(self, seq_len: int, num_classes: int = 5, embed_dim: int = 64, hidden_size: int = 128,\n                 num_heads: int = 4, num_layers: int = 2, dropout: float = 0.1, kernel_size: int = 7,\n                 se_reduction: int = 8, use_cls_token: bool = True):\n        super().__init__()\n        self.use_cls_token = use_cls_token\n        in_ch = 2\n        # Two-lead fusion: depthwise-separable conv + SE\n        self.conv = DepthwiseSeparableConv1D(in_ch, embed_dim, kernel_size=kernel_size)\n        self.se = SEBlock1D(embed_dim, reduction=se_reduction)\n        self.proj_drop = nn.Dropout(dropout)\n        # Positional encoding\n        self.posenc = SinusoidalPositionalEncoding(embed_dim, max_len=seq_len + (1 if use_cls_token else 0))\n        # CLS token\n        if use_cls_token:\n            self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        else:\n            self.register_parameter('cls_token', None)\n        # Transformer encoder\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=hidden_size,\n            dropout=dropout,\n            batch_first=True,\n            norm_first=True,\n            activation='gelu',\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(embed_dim, num_classes)\n        )\n        self.seq_len = seq_len\n\n    def forward(self, x):\n        # Accept x shape (B, L, 2) or (B, 2, L)\n        if x.dim() != 3:\n            raise ValueError('Input must be 3D tensor (B, L, 2) or (B, 2, L)')\n        if x.shape[-1] == 2:\n            # (B, L, C) -> (B, C, L)\n            x = x.transpose(1, 2)\n        elif x.shape[1] == 2:\n            pass\n        else:\n            raise ValueError('Expected 2 ECG leads (channels). Got shape: {}'.format(tuple(x.shape)))\n        # Conv + SE fusion\n        x = self.conv(x)           # (B, E, L)\n        x = self.se(x)             # (B, E, L)\n        x = self.proj_drop(x)\n        x = x.transpose(1, 2)      # (B, L, E)\n        # Add CLS token if used\n        if self.cls_token is not None:\n            cls_tok = self.cls_token.expand(x.size(0), -1, -1)  # (B, 1, E)\n            x = torch.cat([cls_tok, x], dim=1)                  # (B, 1+L, E)\n        # Positional encoding\n        x = self.posenc(x)\n        # Transformer\n        x = self.encoder(x)\n        # Pool\n        if self.cls_token is not None:\n            x = x[:, 0, :]  # (B, E)\n        else:\n            x = x.mean(dim=1)\n        x = self.norm(x)\n        return self.head(x)\n\n# ----- Focal Loss (multi-class) -----\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma: float = 2.0, alpha=None, reduction: str = 'mean'):\n        super().__init__()\n        self.gamma = gamma\n        if alpha is not None:\n            self.register_buffer('alpha', torch.as_tensor(alpha, dtype=torch.float))\n        else:\n            self.alpha = None\n        self.reduction = reduction\n\n    def forward(self, logits, targets):\n        # logits: (B, C); targets: (B,)\n        logpt = F.log_softmax(logits, dim=-1)\n        pt = torch.exp(logpt)\n        logpt_t = logpt.gather(1, targets.unsqueeze(1)).squeeze(1)\n        pt_t = pt.gather(1, targets.unsqueeze(1)).squeeze(1)\n        if self.alpha is not None:\n            at = self.alpha.to(logits.device)[targets]\n        else:\n            at = 1.0\n        loss = -at * (1 - pt_t).clamp(min=1e-6).pow(self.gamma) * logpt_t\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss\n\n# ----- Simple ECG Dataset with optional augmentation -----\nclass ECGDataset(Dataset):\n    def __init__(self, X: torch.Tensor, y: torch.Tensor, augment: bool = False):\n        self.X = X\n        self.y = y.long()\n        self.augment = augment\n\n    def __len__(self):\n        return self.X.size(0)\n\n    def _augment(self, x: torch.Tensor) -> torch.Tensor:\n        # Expect x shape (L, C=2) or (C=2, L)\n        if x.dim() != 2:\n            return x\n        transposed_back = False\n        if x.shape[0] == 2 and x.shape[1] != 2:\n            x = x.transpose(0, 1)  # (L, 2)\n            transposed_back = True\n        elif x.shape[-1] == 2:\n            pass\n        else:\n            return x\n        # Jitter noise\n        if torch.rand(1, device=x.device).item() < 0.5:\n            std = x.std(dim=0, keepdim=True).clamp_min(1e-6)\n            noise = torch.randn_like(x) * (0.01 * std)\n            x = x + noise\n        # Amplitude scaling per lead\n        if torch.rand(1, device=x.device).item() < 0.3:\n            scale = 0.9 + 0.2 * torch.rand((1, x.size(1)), device=x.device)\n            x = x * scale\n        # Temporal shift (roll up to 2% of length)\n        if torch.rand(1, device=x.device).item() < 0.5:\n            max_shift = max(1, int(0.02 * x.size(0)))\n            shift = int(torch.randint(-max_shift, max_shift + 1, (1,), device=x.device).item())\n            x = torch.roll(x, shifts=shift, dims=0)\n        if transposed_back:\n            x = x.transpose(0, 1)\n        return x\n\n    def __getitem__(self, idx):\n        x = self.X[idx]\n        y = self.y[idx]\n        if self.augment:\n            x = self._augment(x)\n        return x, y\n\n# ----- Utility -----\n@torch.no_grad()\ndef _compute_class_alpha(y: torch.Tensor, num_classes: int):\n    # Inverse frequency weights normalized to mean 1.0\n    counts = torch.bincount(y.view(-1).long(), minlength=num_classes).float()\n    counts = torch.clamp(counts, min=1.0)\n    inv = 1.0 / counts\n    alpha = inv * (num_classes / inv.sum())\n    return alpha\n\n# ----- Training Function -----\ndef train_model(X_train: torch.Tensor, y_train: torch.Tensor,\n                X_val: torch.Tensor, y_val: torch.Tensor,\n                device: torch.device,\n                **hyperparams):\n    # Defaults (BayesOpt can override)\n    hp = {\n        'lr': 1e-3,\n        'batch_size': 64,\n        'epochs': 15,\n        'dropout': 0.1,\n        'embed_dim': 64,\n        'hidden_size': 128,\n        'num_heads': 4,\n        'num_layers': 2,\n        'weight_decay': 1e-4,\n        'gamma': 2.0,\n        'kernel_size': 7,\n        'se_reduction': 8,\n        'augment': True,\n        'num_workers': 0,\n        'max_grad_norm': 1.0,\n        'use_cls_token': True,\n        'seed': 42,\n    }\n    hp.update(hyperparams)\n\n    torch.manual_seed(hp['seed'])\n\n    # Infer sequence length\n    # X expected shape (N, L, 2) or (N, 2, L)\n    if X_train.dim() != 3:\n        raise ValueError('X_train must be 3D: (N, L, 2) or (N, 2, L)')\n    if X_train.shape[-1] == 2:\n        seq_len = X_train.shape[1]\n    elif X_train.shape[1] == 2:\n        seq_len = X_train.shape[-1]\n    else:\n        raise ValueError('Expected 2 ECG leads in X_train. Got shape: {}'.format(tuple(X_train.shape)))\n\n    num_classes = int(y_train.max().item() + 1)\n\n    # DataLoaders with pin_memory only if CPU tensors\n    pin_mem_train = (X_train.device.type == 'cpu' and y_train.device.type == 'cpu')\n    pin_mem_val = (X_val.device.type == 'cpu' and y_val.device.type == 'cpu')\n\n    train_ds = ECGDataset(X_train, y_train, augment=bool(hp['augment']))\n    val_ds = ECGDataset(X_val, y_val, augment=False)\n\n    train_loader = DataLoader(train_ds, batch_size=int(hp['batch_size']), shuffle=True,\n                              num_workers=int(hp['num_workers']), pin_memory=pin_mem_train, drop_last=False)\n    val_loader = DataLoader(val_ds, batch_size=int(hp['batch_size']), shuffle=False,\n                            num_workers=int(hp['num_workers']), pin_memory=pin_mem_val, drop_last=False)\n\n    # Model\n    model = TinyECGTransformer1D(\n        seq_len=seq_len,\n        num_classes=num_classes,\n        embed_dim=int(hp['embed_dim']),\n        hidden_size=int(hp['hidden_size']),\n        num_heads=int(hp['num_heads']),\n        num_layers=int(hp['num_layers']),\n        dropout=float(hp['dropout']),\n        kernel_size=int(hp['kernel_size']),\n        se_reduction=int(hp['se_reduction']),\n        use_cls_token=bool(hp['use_cls_token'])\n    ).to(device)\n\n    # Focal loss with class alpha from training labels\n    alpha = _compute_class_alpha(y_train.detach().cpu(), num_classes)\n    criterion = FocalLoss(gamma=float(hp['gamma']), alpha=alpha)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=float(hp['lr']), weight_decay=float(hp['weight_decay']))\n\n    def _to_device(t, dev, non_blocking=False):\n        return t if t.device == dev else t.to(dev, non_blocking=non_blocking)\n\n    history = {\n        'train_loss': [], 'val_loss': [],\n        'train_acc': [], 'val_acc': [],\n    }\n\n    best_val_acc = 0.0\n    best_epoch = -1\n    best_state = None\n\n    for epoch in range(int(hp['epochs'])):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        for xb, yb in train_loader:\n            xb = _to_device(xb, device, non_blocking=pin_mem_train)\n            yb = _to_device(yb, device, non_blocking=pin_mem_train)\n\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            loss.backward()\n            if hp['max_grad_norm'] is not None and hp['max_grad_norm'] > 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(hp['max_grad_norm']))\n            optimizer.step()\n\n            running_loss += loss.item() * xb.size(0)\n            pred = logits.argmax(dim=1)\n            correct += (pred == yb).sum().item()\n            total += yb.size(0)\n\n        train_loss = running_loss / max(1, total)\n        train_acc = correct / max(1, total)\n\n        # Validation\n        model.eval()\n        val_loss_sum = 0.0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb = _to_device(xb, device, non_blocking=pin_mem_val)\n                yb = _to_device(yb, device, non_blocking=pin_mem_val)\n                logits = model(xb)\n                loss = criterion(logits, yb)\n                val_loss_sum += loss.item() * xb.size(0)\n                pred = logits.argmax(dim=1)\n                val_correct += (pred == yb).sum().item()\n                val_total += yb.size(0)\n\n        val_loss = val_loss_sum / max(1, val_total)\n        val_acc = val_correct / max(1, val_total)\n\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['train_acc'].append(train_acc)\n        history['val_acc'].append(val_acc)\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_epoch = epoch\n            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n\n    if best_state is not None:\n        model.load_state_dict(best_state)\n\n    history['best_val_acc'] = best_val_acc\n    history['best_epoch'] = best_epoch\n\n    return model, history\n",
    "hyperparameters": {
        "lr": 0.001,
        "batch_size": 64,
        "epochs": 15,
        "dropout": 0.1,
        "embed_dim": 64,
        "hidden_size": 128,
        "num_heads": 4,
        "num_layers": 2,
        "weight_decay": 0.0001,
        "gamma": 2.0,
        "kernel_size": 7,
        "se_reduction": 8,
        "augment": true,
        "num_workers": 0,
        "max_grad_norm": 1.0,
        "use_cls_token": true,
        "seed": 42
    },
    "reasoning": "Implements a tiny 1D ECG Transformer tailored to 1000¡Á2 inputs following literature: two-lead depthwise-separable convolution with SE for channel fusion, sinusoidal positional encoding, 2¨C3 compact Transformer encoder layers with small embed_dim and heads, and a [CLS] token classifier head. Focal loss addresses class imbalance common in AAMI 5-class MIT-BIH setups. Light augmentations (noise, scale, shift) improve robustness. DataLoader respects pin_memory only for CPU tensors. The default configuration stays well under 256K parameters and is suitable for Bayesian Optimization.",
    "confidence": 0.86,
    "bo_parameters": [
        "lr",
        "batch_size",
        "epochs",
        "embed_dim",
        "hidden_size",
        "num_heads",
        "num_layers",
        "dropout",
        "weight_decay",
        "gamma",
        "kernel_size"
],
    "bo_search_space": {
        "lr": {"type": "Real", "low": 1e-5, "high": 5e-3, "prior": "log-uniform"},
        "batch_size": {"type": "Categorical", "categories": [32, 64, 96, 128]},
        "epochs": {"type": "Integer", "low": 8, "high": 40},
        "embed_dim": {"type": "Integer", "low": 32, "high": 128},
        "hidden_size": {"type": "Integer", "low": 64, "high": 512},
        "num_heads": {"type": "Integer", "low": 2, "high": 8},
        "num_layers": {"type": "Integer", "low": 1, "high": 4},
        "dropout": {"type": "Real", "low": 0.0, "high": 0.5},
        "weight_decay": {"type": "Real", "low": 1e-6, "high": 1e-2, "prior": "log-uniform"},
        "gamma": {"type": "Real", "low": 1.0, "high": 3.0},
        "kernel_size": {"type": "Integer", "low": 3, "high":  nine}
    }
}